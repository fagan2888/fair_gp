[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.825650495644241,
            "auditor_fn_violation": 0.02922748046587056,
            "auditor_fp_violation": 0.017350213262514087,
            "ave_precision_score": 0.8268620324804319,
            "fpr": 0.10416666666666667,
            "logloss": 1.5936981685267184,
            "mae": 0.2805627182368632,
            "precision": 0.7785547785547785,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8610518159738559,
            "auditor_fn_violation": 0.022316733186667825,
            "auditor_fp_violation": 0.021000702220487093,
            "ave_precision_score": 0.8611700257547195,
            "fpr": 0.0867178924259056,
            "logloss": 1.349587285113239,
            "mae": 0.2615838171426231,
            "precision": 0.8096385542168675,
            "recall": 0.702928870292887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.81778635979594,
            "auditor_fn_violation": 0.027460655314757495,
            "auditor_fp_violation": 0.010914614517946243,
            "ave_precision_score": 0.8185552852297717,
            "fpr": 0.08881578947368421,
            "logloss": 1.029824029243839,
            "mae": 0.2997224849549123,
            "precision": 0.7879581151832461,
            "recall": 0.6323529411764706
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8549040946248001,
            "auditor_fn_violation": 0.013613253172521806,
            "auditor_fp_violation": 0.02020721842099259,
            "ave_precision_score": 0.8551380884327257,
            "fpr": 0.07464324917672886,
            "logloss": 0.8986985388445632,
            "mae": 0.28272583691071707,
            "precision": 0.820580474934037,
            "recall": 0.6506276150627615
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8395654120188231,
            "auditor_fn_violation": 0.030171937195931014,
            "auditor_fp_violation": 0.007421434894575891,
            "ave_precision_score": 0.8398592911227112,
            "fpr": 0.03179824561403509,
            "logloss": 1.7225704072579298,
            "mae": 0.31528750380854403,
            "precision": 0.8849206349206349,
            "recall": 0.4684873949579832
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.862134595328215,
            "auditor_fn_violation": 0.010604926307473984,
            "auditor_fp_violation": 0.007328951004276701,
            "ave_precision_score": 0.8625926576673099,
            "fpr": 0.025246981339187707,
            "logloss": 1.508155396394125,
            "mae": 0.30253390197719204,
            "precision": 0.9118773946360154,
            "recall": 0.497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8437945126655507,
            "auditor_fn_violation": 0.012641898864809082,
            "auditor_fp_violation": 0.009433345404796392,
            "ave_precision_score": 0.8450294852324108,
            "fpr": 0.10635964912280702,
            "logloss": 0.744951839986956,
            "mae": 0.2692477494465636,
            "precision": 0.7829977628635347,
            "recall": 0.7352941176470589
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8672335978218335,
            "auditor_fn_violation": 0.009617460237267427,
            "auditor_fp_violation": 0.009321533325052037,
            "ave_precision_score": 0.8674124740540602,
            "fpr": 0.10647639956092206,
            "logloss": 0.6647683271554298,
            "mae": 0.26430895072074867,
            "precision": 0.7858719646799117,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7173768969973686,
            "auditor_fn_violation": 0.024113592805543278,
            "auditor_fp_violation": 0.02164815708997264,
            "ave_precision_score": 0.7114281092655124,
            "fpr": 0.08771929824561403,
            "logloss": 1.7970194375199726,
            "mae": 0.32956129292974135,
            "precision": 0.7674418604651163,
            "recall": 0.5546218487394958
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.703935523063999,
            "auditor_fn_violation": 0.01081390168512233,
            "auditor_fp_violation": 0.03581070974971036,
            "ave_precision_score": 0.6975433366487774,
            "fpr": 0.09001097694840834,
            "logloss": 1.9891119733124938,
            "mae": 0.33209083537590106,
            "precision": 0.7636887608069164,
            "recall": 0.5543933054393305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 12092,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8435645425574212,
            "auditor_fn_violation": 0.0005090852130325797,
            "auditor_fp_violation": 0.01049714308707549,
            "ave_precision_score": 0.8440369086506194,
            "fpr": 0.05482456140350877,
            "logloss": 0.5878847635999654,
            "mae": 0.3198689085310865,
            "precision": 0.8489425981873112,
            "recall": 0.5903361344537815
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8721033779890307,
            "auditor_fn_violation": 0.004997037601789388,
            "auditor_fp_violation": 0.005975211870314833,
            "ave_precision_score": 0.8722699374524863,
            "fpr": 0.04720087815587267,
            "logloss": 0.5343922420841897,
            "mae": 0.30512018775315414,
            "precision": 0.8716417910447761,
            "recall": 0.6108786610878661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 12092,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7356423417418113,
            "auditor_fn_violation": 0.0043352867462774615,
            "auditor_fp_violation": 0.00037471833252856633,
            "ave_precision_score": 0.7317506453460321,
            "fpr": 0.13267543859649122,
            "logloss": 1.5807166064713267,
            "mae": 0.32846573985656097,
            "precision": 0.724373576309795,
            "recall": 0.6680672268907563
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7642024384805463,
            "auditor_fn_violation": 0.00903186989330774,
            "auditor_fp_violation": 0.00898436608756715,
            "ave_precision_score": 0.7623847805998203,
            "fpr": 0.09989023051591657,
            "logloss": 1.3892903278907447,
            "mae": 0.3156553796821336,
            "precision": 0.7666666666666667,
            "recall": 0.6255230125523012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7876180144459651,
            "auditor_fn_violation": 0.0018796992481203022,
            "auditor_fp_violation": 0.015157230806373738,
            "ave_precision_score": 0.7882588973428565,
            "fpr": 0.15460526315789475,
            "logloss": 0.5756185729883967,
            "mae": 0.34552164498363547,
            "precision": 0.7304015296367112,
            "recall": 0.8025210084033614
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8431576401376446,
            "auditor_fn_violation": 0.006051100220916832,
            "auditor_fp_violation": 0.009270831484828749,
            "ave_precision_score": 0.8436767930157301,
            "fpr": 0.1207464324917673,
            "logloss": 0.48963979548947734,
            "mae": 0.32034768602171715,
            "precision": 0.7821782178217822,
            "recall": 0.8263598326359832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7974264352467785,
            "auditor_fn_violation": 0.02476780185758514,
            "auditor_fp_violation": 0.012514083373571547,
            "ave_precision_score": 0.7977951170177342,
            "fpr": 0.0712719298245614,
            "logloss": 1.1825833747773422,
            "mae": 0.32599206972254996,
            "precision": 0.8036253776435045,
            "recall": 0.5588235294117647
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8469572643661543,
            "auditor_fn_violation": 0.021797739391629056,
            "auditor_fp_violation": 0.0182399870203289,
            "ave_precision_score": 0.8471872355787708,
            "fpr": 0.052689352360043906,
            "logloss": 1.021073492597292,
            "mae": 0.30275566700380274,
            "precision": 0.8558558558558559,
            "recall": 0.5962343096234309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.8352075026200835,
            "auditor_fn_violation": 0.01615251363703377,
            "auditor_fp_violation": 0.0059627997746660244,
            "ave_precision_score": 0.8355137366623793,
            "fpr": 0.03179824561403509,
            "logloss": 1.1778212008123203,
            "mae": 0.3328797705604546,
            "precision": 0.8765957446808511,
            "recall": 0.4327731092436975
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8450242052631722,
            "auditor_fn_violation": 0.0033872382640805832,
            "auditor_fp_violation": 0.006408712604223972,
            "ave_precision_score": 0.8453121058843849,
            "fpr": 0.030735455543358946,
            "logloss": 1.110363277886837,
            "mae": 0.3280650128870537,
            "precision": 0.8828451882845189,
            "recall": 0.44142259414225943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8373786413924098,
            "auditor_fn_violation": 0.015530554326993953,
            "auditor_fp_violation": 0.0093604136488009,
            "ave_precision_score": 0.837710550974359,
            "fpr": 0.09868421052631579,
            "logloss": 0.8154790102704175,
            "mae": 0.2762462242913634,
            "precision": 0.788235294117647,
            "recall": 0.7037815126050421
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8469822908967948,
            "auditor_fn_violation": 0.010053782454335441,
            "auditor_fp_violation": 0.011101167916889544,
            "ave_precision_score": 0.847255077790888,
            "fpr": 0.09440175631174534,
            "logloss": 0.7439951632350461,
            "mae": 0.2668034858436176,
            "precision": 0.7952380952380952,
            "recall": 0.698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8230357221691771,
            "auditor_fn_violation": 0.012851522187822501,
            "auditor_fp_violation": 0.009722557540640593,
            "ave_precision_score": 0.823372998637871,
            "fpr": 0.1162280701754386,
            "logloss": 0.888220224092303,
            "mae": 0.2796451239852495,
            "precision": 0.7639198218262806,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8193005912361621,
            "auditor_fn_violation": 0.009107652173114286,
            "auditor_fp_violation": 0.0144576297396714,
            "ave_precision_score": 0.8198687602462515,
            "fpr": 0.10757409440175632,
            "logloss": 0.8313790558263423,
            "mae": 0.2747926964753214,
            "precision": 0.7782805429864253,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8193188871076669,
            "auditor_fn_violation": 0.023827952233524997,
            "auditor_fp_violation": 0.031360655078062134,
            "ave_precision_score": 0.8196649819622844,
            "fpr": 0.15570175438596492,
            "logloss": 0.9292003657710574,
            "mae": 0.27765855361390357,
            "precision": 0.7279693486590039,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8464567011964761,
            "auditor_fn_violation": 0.01457775491551424,
            "auditor_fp_violation": 0.03078615738358224,
            "ave_precision_score": 0.8467026069872892,
            "fpr": 0.14270032930845225,
            "logloss": 0.7949526122232637,
            "mae": 0.2586102857478219,
            "precision": 0.74609375,
            "recall": 0.799163179916318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 12092,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8382607948388573,
            "auditor_fn_violation": 0.011391069585729031,
            "auditor_fp_violation": 0.009066171736681153,
            "ave_precision_score": 0.8385653739259091,
            "fpr": 0.10635964912280702,
            "logloss": 0.790401169513293,
            "mae": 0.27179108674675434,
            "precision": 0.7834821428571429,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.847991004687346,
            "auditor_fn_violation": 0.010871312503157602,
            "auditor_fp_violation": 0.01077921123147165,
            "ave_precision_score": 0.8482675820482141,
            "fpr": 0.1119648737650933,
            "logloss": 0.7121829680856989,
            "mae": 0.26373719110531435,
            "precision": 0.7777777777777778,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8134323904724288,
            "auditor_fn_violation": 0.011674406604747167,
            "auditor_fp_violation": 0.02085345243843554,
            "ave_precision_score": 0.8137307626777088,
            "fpr": 0.13815789473684212,
            "logloss": 1.018075434318922,
            "mae": 0.2707657393885544,
            "precision": 0.7464788732394366,
            "recall": 0.7794117647058824
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8109647933706156,
            "auditor_fn_violation": 0.013335384813231129,
            "auditor_fp_violation": 0.01957598051021262,
            "ave_precision_score": 0.8115796440702329,
            "fpr": 0.13830954994511527,
            "logloss": 0.9634278017630516,
            "mae": 0.26873543821869067,
            "precision": 0.744421906693712,
            "recall": 0.7677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8092059194045327,
            "auditor_fn_violation": 0.032620614035087724,
            "auditor_fp_violation": 0.027990704973442793,
            "ave_precision_score": 0.809563824820345,
            "fpr": 0.1337719298245614,
            "logloss": 1.0780049868559494,
            "mae": 0.28300542826175223,
            "precision": 0.7453027139874739,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8289064853433679,
            "auditor_fn_violation": 0.02799351487399474,
            "auditor_fp_violation": 0.032920704856982785,
            "ave_precision_score": 0.8302445544861061,
            "fpr": 0.12294182217343579,
            "logloss": 0.9133601975326748,
            "mae": 0.26222326121504463,
            "precision": 0.7627118644067796,
            "recall": 0.7531380753138075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7970585695741317,
            "auditor_fn_violation": 0.021162741412354417,
            "auditor_fp_violation": 0.026625120714630628,
            "ave_precision_score": 0.7966951490880789,
            "fpr": 0.14802631578947367,
            "logloss": 1.1880338211994002,
            "mae": 0.28005814420055786,
            "precision": 0.7310756972111554,
            "recall": 0.7710084033613446
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7590630775666712,
            "auditor_fn_violation": 0.020948059284707134,
            "auditor_fp_violation": 0.02610384243896133,
            "ave_precision_score": 0.7593536567198605,
            "fpr": 0.1394072447859495,
            "logloss": 1.3325235474921082,
            "mae": 0.2723409580229062,
            "precision": 0.7402862985685071,
            "recall": 0.7573221757322176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.823538735552724,
            "auditor_fn_violation": 0.008776536930561704,
            "auditor_fp_violation": 0.021532472235634963,
            "ave_precision_score": 0.8238470671404796,
            "fpr": 0.1337719298245614,
            "logloss": 0.939891892477598,
            "mae": 0.2725466096101967,
            "precision": 0.75,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8273129356264839,
            "auditor_fn_violation": 0.006110807471673504,
            "auditor_fp_violation": 0.012574056375376143,
            "ave_precision_score": 0.8276900664427802,
            "fpr": 0.12733260153677278,
            "logloss": 0.8673845277523997,
            "mae": 0.26849792446489396,
            "precision": 0.7608247422680412,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8372052247055227,
            "auditor_fn_violation": 0.013941102756892237,
            "auditor_fp_violation": 0.02391155641397071,
            "ave_precision_score": 0.8374747956287935,
            "fpr": 0.14144736842105263,
            "logloss": 0.902827913870021,
            "mae": 0.26261206356311584,
            "precision": 0.7440476190476191,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.842718377676049,
            "auditor_fn_violation": 0.009943553683707735,
            "auditor_fp_violation": 0.018318574872675006,
            "ave_precision_score": 0.8430623433583663,
            "fpr": 0.1350164654226125,
            "logloss": 0.8082322393074678,
            "mae": 0.25874951033723653,
            "precision": 0.7525150905432596,
            "recall": 0.7824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8184558267700144,
            "auditor_fn_violation": 0.004759140498304587,
            "auditor_fp_violation": 0.010285892483502337,
            "ave_precision_score": 0.8188026921200107,
            "fpr": 0.17214912280701755,
            "logloss": 0.5830282196349279,
            "mae": 0.33736682160649745,
            "precision": 0.7020872865275142,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8387209933916834,
            "auditor_fn_violation": 0.00567218882188409,
            "auditor_fp_violation": 0.014447489371626746,
            "ave_precision_score": 0.838978424472524,
            "fpr": 0.14270032930845225,
            "logloss": 0.5390862134058407,
            "mae": 0.3208466747721492,
            "precision": 0.7470817120622568,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8230355350959815,
            "auditor_fn_violation": 0.010439702196668146,
            "auditor_fp_violation": 0.007310779816513762,
            "ave_precision_score": 0.8233622336864712,
            "fpr": 0.10416666666666667,
            "logloss": 0.9008248947141041,
            "mae": 0.2839687208852716,
            "precision": 0.7764705882352941,
            "recall": 0.6932773109243697
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8251755686610487,
            "auditor_fn_violation": 0.0067882551244896165,
            "auditor_fp_violation": 0.01234336300236017,
            "ave_precision_score": 0.8256452077528249,
            "fpr": 0.10208562019758508,
            "logloss": 0.8371815505379826,
            "mae": 0.2739742745591531,
            "precision": 0.7806603773584906,
            "recall": 0.6924686192468619
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8282308206141984,
            "auditor_fn_violation": 0.025527974347633795,
            "auditor_fp_violation": 0.009013359085787865,
            "ave_precision_score": 0.8286711644228307,
            "fpr": 0.03399122807017544,
            "logloss": 1.7176807652661548,
            "mae": 0.3273423716347276,
            "precision": 0.8734693877551021,
            "recall": 0.4495798319327731
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8554976691425479,
            "auditor_fn_violation": 0.016734105240918756,
            "auditor_fp_violation": 0.009301252588962717,
            "ave_precision_score": 0.8557492135648739,
            "fpr": 0.025246981339187707,
            "logloss": 1.4965108994145724,
            "mae": 0.315278540847315,
            "precision": 0.9065040650406504,
            "recall": 0.4665271966527197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 12092,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.815815227622962,
            "auditor_fn_violation": 0.022574819401444794,
            "auditor_fp_violation": 0.006936061483985193,
            "ave_precision_score": 0.8161488464906504,
            "fpr": 0.06798245614035088,
            "logloss": 1.5718651741700804,
            "mae": 0.31285812655517314,
            "precision": 0.8068535825545171,
            "recall": 0.5441176470588235
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8333597825803231,
            "auditor_fn_violation": 0.009906810760165165,
            "auditor_fp_violation": 0.009286042036895729,
            "ave_precision_score": 0.8337249212856531,
            "fpr": 0.050493962678375415,
            "logloss": 1.3822168893723275,
            "mae": 0.29543847880421026,
            "precision": 0.8506493506493507,
            "recall": 0.5481171548117155
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8552335747490485,
            "auditor_fn_violation": 0.012722523219814244,
            "auditor_fp_violation": 0.020513942539835836,
            "ave_precision_score": 0.8557322881952488,
            "fpr": 0.14802631578947367,
            "logloss": 0.5180961842866214,
            "mae": 0.2983124893416971,
            "precision": 0.7471910112359551,
            "recall": 0.8382352941176471
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8890276453231529,
            "auditor_fn_violation": 0.008967569777108246,
            "auditor_fp_violation": 0.01331683833464736,
            "ave_precision_score": 0.8891712841852197,
            "fpr": 0.1251372118551043,
            "logloss": 0.453033323301133,
            "mae": 0.2766464745450336,
            "precision": 0.7820267686424475,
            "recall": 0.8556485355648535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8002442329722261,
            "auditor_fn_violation": 0.02309081527347782,
            "auditor_fp_violation": 0.03756739900209239,
            "ave_precision_score": 0.8006014088664677,
            "fpr": 0.20833333333333334,
            "logloss": 0.5992862376043472,
            "mae": 0.36446043670998496,
            "precision": 0.6695652173913044,
            "recall": 0.8088235294117647
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8292086413836396,
            "auditor_fn_violation": 0.02335472077674541,
            "auditor_fp_violation": 0.037894555382887635,
            "ave_precision_score": 0.8295464278362771,
            "fpr": 0.18551042810098792,
            "logloss": 0.5441532445521955,
            "mae": 0.3494842546019789,
            "precision": 0.6916058394160584,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8095727008389322,
            "auditor_fn_violation": 0.03014199100692909,
            "auditor_fp_violation": 0.012685095766940288,
            "ave_precision_score": 0.8101191762276161,
            "fpr": 0.08114035087719298,
            "logloss": 1.089644612148209,
            "mae": 0.30573649509908096,
            "precision": 0.8016085790884718,
            "recall": 0.6281512605042017
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8530556982245828,
            "auditor_fn_violation": 0.016846630444267874,
            "auditor_fp_violation": 0.016222053779441928,
            "ave_precision_score": 0.8532815225988175,
            "fpr": 0.06805708013172337,
            "logloss": 0.9461806127727773,
            "mae": 0.2878258112468207,
            "precision": 0.8315217391304348,
            "recall": 0.6401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8395162162854022,
            "auditor_fn_violation": 0.015507518796992489,
            "auditor_fp_violation": 0.01265491710928698,
            "ave_precision_score": 0.8398624046672469,
            "fpr": 0.11403508771929824,
            "logloss": 0.7675625515121791,
            "mae": 0.2698149654993162,
            "precision": 0.7734204793028322,
            "recall": 0.7457983193277311
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8505245538473037,
            "auditor_fn_violation": 0.013183820253618032,
            "auditor_fp_violation": 0.013121636249787691,
            "ave_precision_score": 0.8507884232164212,
            "fpr": 0.11525795828759605,
            "logloss": 0.6964679221066815,
            "mae": 0.261392271513872,
            "precision": 0.7756410256410257,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8409043043867651,
            "auditor_fn_violation": 0.008656752174554036,
            "auditor_fp_violation": 0.017506136327056176,
            "ave_precision_score": 0.8413013901550759,
            "fpr": 0.12828947368421054,
            "logloss": 0.7205545694400451,
            "mae": 0.26830704060966837,
            "precision": 0.7597535934291582,
            "recall": 0.7773109243697479
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.855403108872478,
            "auditor_fn_violation": 0.007467999210027146,
            "auditor_fp_violation": 0.015519833292349346,
            "ave_precision_score": 0.8556555598977924,
            "fpr": 0.12952799121844127,
            "logloss": 0.6521747044570052,
            "mae": 0.2607642274668113,
            "precision": 0.7611336032388664,
            "recall": 0.7866108786610879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7528321913835063,
            "auditor_fn_violation": 0.00829279080053074,
            "auditor_fp_violation": 0.010577619507484311,
            "ave_precision_score": 0.7452273152635551,
            "fpr": 0.18530701754385964,
            "logloss": 1.365233105276998,
            "mae": 0.2955413457548275,
            "precision": 0.700354609929078,
            "recall": 0.8298319327731093
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.741251846584344,
            "auditor_fn_violation": 0.004133578898539014,
            "auditor_fp_violation": 0.014860709369446565,
            "ave_precision_score": 0.7348985758747313,
            "fpr": 0.1800219538968167,
            "logloss": 1.3893975773525786,
            "mae": 0.295146834696311,
            "precision": 0.7007299270072993,
            "recall": 0.803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8124808923415678,
            "auditor_fn_violation": 0.012312490785788,
            "auditor_fp_violation": 0.009918718815387096,
            "ave_precision_score": 0.8131190975681095,
            "fpr": 0.10087719298245613,
            "logloss": 0.5951174381573798,
            "mae": 0.31411181670096144,
            "precision": 0.7835294117647059,
            "recall": 0.6995798319327731
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8174233358349577,
            "auditor_fn_violation": 0.00832916148055611,
            "auditor_fp_violation": 0.003067461333509099,
            "ave_precision_score": 0.8183005114237739,
            "fpr": 0.08122941822173436,
            "logloss": 0.5828134554171682,
            "mae": 0.3022830410900533,
            "precision": 0.8181818181818182,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 12092,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8507041484376433,
            "auditor_fn_violation": 0.009361639392599144,
            "auditor_fp_violation": 0.01098000160952841,
            "ave_precision_score": 0.8519272826182956,
            "fpr": 0.09978070175438597,
            "logloss": 0.7539628415087984,
            "mae": 0.2507420411987143,
            "precision": 0.796420581655481,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8697209870097475,
            "auditor_fn_violation": 4.3632221706802505e-05,
            "auditor_fp_violation": 0.007283319348075738,
            "ave_precision_score": 0.8699228763225093,
            "fpr": 0.09330406147091108,
            "logloss": 0.6845053536934058,
            "mae": 0.2434901086737974,
            "precision": 0.8094170403587444,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.40765609140322256,
            "auditor_fn_violation": 0.0014189886480908103,
            "auditor_fp_violation": 0.004999597617897956,
            "ave_precision_score": 0.5244905370477736,
            "fpr": 0.013157894736842105,
            "logloss": 17.595187223705395,
            "mae": 0.5247288180481566,
            "precision": 0.45454545454545453,
            "recall": 0.02100840336134454
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.4340293472983518,
            "auditor_fn_violation": 0.002340064943117368,
            "auditor_fp_violation": 6.84474843014428e-05,
            "ave_precision_score": 0.528043927210188,
            "fpr": 0.006586169045005488,
            "logloss": 17.629305286757084,
            "mae": 0.5223461592982479,
            "precision": 0.6470588235294118,
            "recall": 0.02301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7595292204780981,
            "auditor_fn_violation": 0.012945967860828543,
            "auditor_fp_violation": 0.01435246660228553,
            "ave_precision_score": 0.7602488268607126,
            "fpr": 0.1962719298245614,
            "logloss": 1.258057267881593,
            "mae": 0.2966210168918077,
            "precision": 0.6854130052724078,
            "recall": 0.819327731092437
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7313078055085345,
            "auditor_fn_violation": 0.00706841991650171,
            "auditor_fp_violation": 0.01600657095849294,
            "ave_precision_score": 0.7307426166506925,
            "fpr": 0.18880351262349068,
            "logloss": 1.2624057663812736,
            "mae": 0.2907500821046124,
            "precision": 0.6950354609929078,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 12092,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.792399402482722,
            "auditor_fn_violation": 0.005897095680377424,
            "auditor_fp_violation": 0.004934210526315789,
            "ave_precision_score": 0.7927537675939429,
            "fpr": 0.01644736842105263,
            "logloss": 2.430009958959049,
            "mae": 0.4146057314324757,
            "precision": 0.8790322580645161,
            "recall": 0.22899159663865545
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.8007867720987459,
            "auditor_fn_violation": 0.005153195026845307,
            "auditor_fp_violation": 0.004193042186466158,
            "ave_precision_score": 0.8012906813556829,
            "fpr": 0.013172338090010977,
            "logloss": 2.400298108110831,
            "mae": 0.4195629099449747,
            "precision": 0.9024390243902439,
            "recall": 0.23221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8240550615216397,
            "auditor_fn_violation": 0.010723039215686278,
            "auditor_fp_violation": 0.019988330919040724,
            "ave_precision_score": 0.8244169740816955,
            "fpr": 0.14583333333333334,
            "logloss": 0.9232118461867882,
            "mae": 0.27085243028743616,
            "precision": 0.7392156862745098,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8274767464319075,
            "auditor_fn_violation": 0.01142475278901754,
            "auditor_fp_violation": 0.017656915857761062,
            "ave_precision_score": 0.828108578625843,
            "fpr": 0.14818880351262348,
            "logloss": 0.844445070809031,
            "mae": 0.26690445790101897,
            "precision": 0.733201581027668,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 12092,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8046593452389057,
            "auditor_fn_violation": 0.01832246056317264,
            "auditor_fp_violation": 0.03154675680025753,
            "ave_precision_score": 0.8049880763829901,
            "fpr": 0.17105263157894737,
            "logloss": 1.133788987931609,
            "mae": 0.2773349256873908,
            "precision": 0.712707182320442,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7981629679942894,
            "auditor_fn_violation": 0.013273381129753042,
            "auditor_fp_violation": 0.033212240438266705,
            "ave_precision_score": 0.7986685275245394,
            "fpr": 0.16136114160263446,
            "logloss": 1.0572048107826908,
            "mae": 0.27473916470418164,
            "precision": 0.7183908045977011,
            "recall": 0.7845188284518828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8437396615078318,
            "auditor_fn_violation": 0.011059357953707804,
            "auditor_fp_violation": 0.011568485433767905,
            "ave_precision_score": 0.8449683166651758,
            "fpr": 0.11074561403508772,
            "logloss": 0.7168575652216623,
            "mae": 0.26756614947915774,
            "precision": 0.7804347826086957,
            "recall": 0.7542016806722689
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8587019336401829,
            "auditor_fn_violation": 0.00896068047894401,
            "auditor_fp_violation": 0.011970704476718986,
            "ave_precision_score": 0.8589256998261752,
            "fpr": 0.11745334796926454,
            "logloss": 0.6670944707806787,
            "mae": 0.2650334196046452,
            "precision": 0.772823779193206,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7873907047714018,
            "auditor_fn_violation": 0.006569733156420466,
            "auditor_fp_violation": 0.00300529132464188,
            "ave_precision_score": 0.7877618249807442,
            "fpr": 0.01644736842105263,
            "logloss": 2.5794908942964567,
            "mae": 0.4188033933024594,
            "precision": 0.8760330578512396,
            "recall": 0.22268907563025211
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7955576413284976,
            "auditor_fn_violation": 0.005341502510000973,
            "auditor_fp_violation": 0.003858410040992437,
            "ave_precision_score": 0.7961769148786741,
            "fpr": 0.014270032930845226,
            "logloss": 2.5464782730609166,
            "mae": 0.4229534286452278,
            "precision": 0.8888888888888888,
            "recall": 0.2175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8208811980902002,
            "auditor_fn_violation": 0.027725563909774435,
            "auditor_fp_violation": 0.016708916787381296,
            "ave_precision_score": 0.8212483543666828,
            "fpr": 0.10855263157894737,
            "logloss": 1.8859838605203962,
            "mae": 0.2944694300253683,
            "precision": 0.7744874715261959,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8553838745411986,
            "auditor_fn_violation": 0.02224784020502552,
            "auditor_fp_violation": 0.019355427505241305,
            "ave_precision_score": 0.8550652282366854,
            "fpr": 0.09001097694840834,
            "logloss": 1.8329011287155486,
            "mae": 0.27437367513291017,
            "precision": 0.8075117370892019,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 12092,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8018051874835966,
            "auditor_fn_violation": 0.014963880288957695,
            "auditor_fp_violation": 0.01746086834057621,
            "ave_precision_score": 0.8021539176534316,
            "fpr": 0.14583333333333334,
            "logloss": 0.7881377079548575,
            "mae": 0.2966226988406442,
            "precision": 0.7323943661971831,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8009148564341573,
            "auditor_fn_violation": 0.008907862526351574,
            "auditor_fp_violation": 0.019015725175745252,
            "ave_precision_score": 0.8016221627512035,
            "fpr": 0.14489571899012074,
            "logloss": 0.7367039195554819,
            "mae": 0.29057195689127374,
            "precision": 0.7278350515463917,
            "recall": 0.7384937238493724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8061132567954349,
            "auditor_fn_violation": 0.018709457467197405,
            "auditor_fp_violation": 0.01865041042974409,
            "ave_precision_score": 0.8064694276583906,
            "fpr": 0.14035087719298245,
            "logloss": 1.009517558939474,
            "mae": 0.28370106036154286,
            "precision": 0.7382413087934561,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8051303086270145,
            "auditor_fn_violation": 0.012210132779739955,
            "auditor_fp_violation": 0.018767286158651135,
            "ave_precision_score": 0.8065053038338864,
            "fpr": 0.13721185510428102,
            "logloss": 0.9176125269697393,
            "mae": 0.27833234427704245,
            "precision": 0.742798353909465,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8171601364667753,
            "auditor_fn_violation": 0.03125000000000001,
            "auditor_fp_violation": 0.027120553677772417,
            "ave_precision_score": 0.8174910173292665,
            "fpr": 0.13267543859649122,
            "logloss": 1.5439388973838573,
            "mae": 0.28092428989213725,
            "precision": 0.7468619246861925,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8357741570512499,
            "auditor_fn_violation": 0.02249126207349503,
            "auditor_fp_violation": 0.024757708581032954,
            "ave_precision_score": 0.8360806240767945,
            "fpr": 0.1207464324917673,
            "logloss": 1.3048724117856603,
            "mae": 0.263558723632538,
            "precision": 0.7659574468085106,
            "recall": 0.7531380753138075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8328237869520155,
            "auditor_fn_violation": 0.02650007371369601,
            "auditor_fp_violation": 0.017533800096571704,
            "ave_precision_score": 0.8335194548751628,
            "fpr": 0.10526315789473684,
            "logloss": 1.3856354413299048,
            "mae": 0.2771623886645336,
            "precision": 0.782312925170068,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8675872501173162,
            "auditor_fn_violation": 0.021848260911500078,
            "auditor_fp_violation": 0.023497767851484174,
            "ave_precision_score": 0.8677099476474615,
            "fpr": 0.10098792535675083,
            "logloss": 1.1520939745021144,
            "mae": 0.25750089437402,
            "precision": 0.7918552036199095,
            "recall": 0.7322175732217573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8214018001748893,
            "auditor_fn_violation": 0.011791887807754683,
            "auditor_fp_violation": 0.016366892000643816,
            "ave_precision_score": 0.8217301604642211,
            "fpr": 0.12719298245614036,
            "logloss": 0.9841675746290341,
            "mae": 0.27459792639204084,
            "precision": 0.7568134171907757,
            "recall": 0.7584033613445378
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8265463879026389,
            "auditor_fn_violation": 0.009684056786188337,
            "auditor_fp_violation": 0.014006383361684121,
            "ave_precision_score": 0.8269193311650203,
            "fpr": 0.12403951701427003,
            "logloss": 0.8973462121765778,
            "mae": 0.26765058091158433,
            "precision": 0.7626050420168067,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6209669210547402,
            "auditor_fn_violation": 0.016617831343063542,
            "auditor_fp_violation": 0.010532351521004351,
            "ave_precision_score": 0.622357697971683,
            "fpr": 0.15570175438596492,
            "logloss": 0.7962928967050705,
            "mae": 0.42056142100007393,
            "precision": 0.6586538461538461,
            "recall": 0.5756302521008403
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.663969278478379,
            "auditor_fn_violation": 0.012777351661928367,
            "auditor_fp_violation": 0.002780995936247515,
            "ave_precision_score": 0.6654762665239741,
            "fpr": 0.14709110867178923,
            "logloss": 0.7337834137469312,
            "mae": 0.39641608030695785,
            "precision": 0.6794258373205742,
            "recall": 0.5941422594142259
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7935269974426618,
            "auditor_fn_violation": 0.00632094943240455,
            "auditor_fp_violation": 0.004934210526315789,
            "ave_precision_score": 0.7938800075625553,
            "fpr": 0.01644736842105263,
            "logloss": 2.446963331030171,
            "mae": 0.4127642630201656,
            "precision": 0.8818897637795275,
            "recall": 0.23529411764705882
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7992103577377865,
            "auditor_fn_violation": 0.0029003945271415393,
            "auditor_fp_violation": 0.004692455312665573,
            "ave_precision_score": 0.7997047936846884,
            "fpr": 0.014270032930845226,
            "logloss": 2.426079894616518,
            "mae": 0.41809388324618146,
            "precision": 0.8951612903225806,
            "recall": 0.23221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.8283622576833978,
            "auditor_fn_violation": 0.02606470219666815,
            "auditor_fp_violation": 0.006589006920972154,
            "ave_precision_score": 0.8287235686308173,
            "fpr": 0.027412280701754384,
            "logloss": 1.6858240392485773,
            "mae": 0.34477821170311196,
            "precision": 0.8873873873873874,
            "recall": 0.41386554621848737
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8512176701833757,
            "auditor_fn_violation": 0.01548943870591424,
            "auditor_fp_violation": 0.0035972955638424895,
            "ave_precision_score": 0.8515420941155811,
            "fpr": 0.01756311745334797,
            "logloss": 1.4885046637659574,
            "mae": 0.335702960711838,
            "precision": 0.9248826291079812,
            "recall": 0.4121338912133891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8322039100861988,
            "auditor_fn_violation": 0.01075759251068849,
            "auditor_fp_violation": 0.014033075808788027,
            "ave_precision_score": 0.8329451962949332,
            "fpr": 0.11403508771929824,
            "logloss": 0.7639901728268736,
            "mae": 0.27353142441380607,
            "precision": 0.7683741648106904,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8398852103759542,
            "auditor_fn_violation": 0.008652958494274993,
            "auditor_fp_violation": 0.014069760661963233,
            "ave_precision_score": 0.8402000419374849,
            "fpr": 0.11086717892425905,
            "logloss": 0.7197813253083979,
            "mae": 0.2702836547843206,
            "precision": 0.7755555555555556,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7921209251828837,
            "auditor_fn_violation": 0.02192982456140351,
            "auditor_fp_violation": 0.018026718171575737,
            "ave_precision_score": 0.7924892155400554,
            "fpr": 0.15570175438596492,
            "logloss": 1.0281061444185016,
            "mae": 0.29150542763023635,
            "precision": 0.7193675889328063,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7805339094497064,
            "auditor_fn_violation": 0.012465036811816526,
            "auditor_fp_violation": 0.02161165939517775,
            "ave_precision_score": 0.7815888477242017,
            "fpr": 0.15367727771679474,
            "logloss": 0.9747998529423565,
            "mae": 0.28712959583382536,
            "precision": 0.7233201581027668,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 12092,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8414690168876562,
            "auditor_fn_violation": 0.008974642488574382,
            "auditor_fp_violation": 0.013354056011588606,
            "ave_precision_score": 0.8418705608821982,
            "fpr": 0.1074561403508772,
            "logloss": 0.7142832243146513,
            "mae": 0.2709151425329209,
            "precision": 0.7792792792792793,
            "recall": 0.726890756302521
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8547305746353909,
            "auditor_fn_violation": 0.009557752986510756,
            "auditor_fp_violation": 0.012865591956660063,
            "ave_precision_score": 0.8549820257687621,
            "fpr": 0.10318331503841932,
            "logloss": 0.652187737653418,
            "mae": 0.2652825058404576,
            "precision": 0.7887640449438202,
            "recall": 0.7343096234309623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.8049335571320959,
            "auditor_fn_violation": 0.019550254312251228,
            "auditor_fp_violation": 0.009209520360534365,
            "ave_precision_score": 0.805367119872142,
            "fpr": 0.046052631578947366,
            "logloss": 1.211334736575906,
            "mae": 0.34512274754671474,
            "precision": 0.83399209486166,
            "recall": 0.4432773109243697
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.8132281552309379,
            "auditor_fn_violation": 0.008763187264902713,
            "auditor_fp_violation": 0.006976573214724831,
            "ave_precision_score": 0.8136231827142567,
            "fpr": 0.042810098792535674,
            "logloss": 1.151249827784409,
            "mae": 0.3396288255705824,
            "precision": 0.8482490272373541,
            "recall": 0.4560669456066946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8503138926466142,
            "auditor_fn_violation": 0.015341662980981871,
            "auditor_fp_violation": 0.015625,
            "ave_precision_score": 0.8505637219547504,
            "fpr": 0.11951754385964912,
            "logloss": 0.6551138796823546,
            "mae": 0.2650262897553105,
            "precision": 0.7714884696016772,
            "recall": 0.773109243697479
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8560334997766279,
            "auditor_fn_violation": 0.014837251813033633,
            "auditor_fp_violation": 0.012766723368224653,
            "ave_precision_score": 0.8563467625836603,
            "fpr": 0.11855104281009879,
            "logloss": 0.601164331917822,
            "mae": 0.2582826000868786,
            "precision": 0.7763975155279503,
            "recall": 0.7845188284518828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8134222359452375,
            "auditor_fn_violation": 0.026930838124723584,
            "auditor_fp_violation": 0.014329832609045553,
            "ave_precision_score": 0.8138009638498543,
            "fpr": 0.1118421052631579,
            "logloss": 0.9184298437441709,
            "mae": 0.28667174874479523,
            "precision": 0.7676537585421412,
            "recall": 0.707983193277311
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8231452229987325,
            "auditor_fn_violation": 0.01660780144124118,
            "auditor_fp_violation": 0.023267074478468194,
            "ave_precision_score": 0.8244712020764939,
            "fpr": 0.10428100987925357,
            "logloss": 0.801133002412133,
            "mae": 0.26968742752832825,
            "precision": 0.7845804988662132,
            "recall": 0.7238493723849372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.8178229299704592,
            "auditor_fn_violation": 0.02822082780480613,
            "auditor_fp_violation": 0.008105484468050862,
            "ave_precision_score": 0.8181631633421587,
            "fpr": 0.025219298245614034,
            "logloss": 2.0228116671016765,
            "mae": 0.35184250954367474,
            "precision": 0.8883495145631068,
            "recall": 0.38445378151260506
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.8392140137903566,
            "auditor_fn_violation": 0.008910158959072979,
            "auditor_fp_violation": 0.005318623039423216,
            "ave_precision_score": 0.8395573514570502,
            "fpr": 0.02305159165751921,
            "logloss": 1.7971497683751445,
            "mae": 0.3416643106483843,
            "precision": 0.9036697247706422,
            "recall": 0.4121338912133891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7996119496818144,
            "auditor_fn_violation": 0.014963880288957695,
            "auditor_fp_violation": 0.02052400209238694,
            "ave_precision_score": 0.7999631788132715,
            "fpr": 0.1524122807017544,
            "logloss": 0.8099032507939045,
            "mae": 0.2964950993786069,
            "precision": 0.7236580516898609,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7976770786755712,
            "auditor_fn_violation": 0.00816381832461455,
            "auditor_fp_violation": 0.021261816697637045,
            "ave_precision_score": 0.7985666610043995,
            "fpr": 0.14709110867178923,
            "logloss": 0.7576169068893073,
            "mae": 0.2910245725776812,
            "precision": 0.7281947261663286,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 12092,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7404220889183468,
            "auditor_fn_violation": 0.00369259545923633,
            "auditor_fp_violation": 0.0002917270239819772,
            "ave_precision_score": 0.7374824505399522,
            "fpr": 0.11403508771929824,
            "logloss": 1.5125278260990849,
            "mae": 0.3280174086369056,
            "precision": 0.7432098765432099,
            "recall": 0.6323529411764706
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7712122064860567,
            "auditor_fn_violation": 0.013548953056322317,
            "auditor_fp_violation": 0.012868127048671234,
            "ave_precision_score": 0.7696136540678474,
            "fpr": 0.0889132821075741,
            "logloss": 1.3224117451149306,
            "mae": 0.31432282071089307,
            "precision": 0.7868421052631579,
            "recall": 0.6255230125523012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.7920145469759547,
            "auditor_fn_violation": 0.005897095680377424,
            "auditor_fp_violation": 0.004526798647996138,
            "ave_precision_score": 0.7923701969579193,
            "fpr": 0.015350877192982455,
            "logloss": 2.4802306480514935,
            "mae": 0.4154632753400285,
            "precision": 0.8861788617886179,
            "recall": 0.22899159663865545
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7998167503468913,
            "auditor_fn_violation": 0.004661758424463444,
            "auditor_fp_violation": 0.004193042186466158,
            "ave_precision_score": 0.8003277339684902,
            "fpr": 0.013172338090010977,
            "logloss": 2.4519606200148667,
            "mae": 0.42055215362812054,
            "precision": 0.9016393442622951,
            "recall": 0.2301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7962663975700188,
            "auditor_fn_violation": 0.019386702049240753,
            "auditor_fp_violation": 0.017020762916465475,
            "ave_precision_score": 0.7965450679057493,
            "fpr": 0.12828947368421054,
            "logloss": 1.240472053957905,
            "mae": 0.28733791003369735,
            "precision": 0.7505330490405118,
            "recall": 0.7394957983193278
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7915462652478593,
            "auditor_fn_violation": 0.011174441622383796,
            "auditor_fp_violation": 0.018310969596641514,
            "ave_precision_score": 0.792193199931091,
            "fpr": 0.12294182217343579,
            "logloss": 1.1393544396642237,
            "mae": 0.2807318544354753,
            "precision": 0.7586206896551724,
            "recall": 0.7364016736401674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 12092,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.833066214752484,
            "auditor_fn_violation": 0.015608875128998983,
            "auditor_fp_violation": 0.006463262514083375,
            "ave_precision_score": 0.833394469345925,
            "fpr": 0.03837719298245614,
            "logloss": 1.1583458854290576,
            "mae": 0.32714724680109714,
            "precision": 0.8627450980392157,
            "recall": 0.46218487394957986
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.8433591294002204,
            "auditor_fn_violation": 0.0019404856495919458,
            "auditor_fp_violation": 0.004563165620096182,
            "ave_precision_score": 0.84365962602458,
            "fpr": 0.036223929747530186,
            "logloss": 1.0433436992744851,
            "mae": 0.32144105930064637,
            "precision": 0.875,
            "recall": 0.48326359832635984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7951401585160907,
            "auditor_fn_violation": 0.02192982456140351,
            "auditor_fp_violation": 0.018026718171575737,
            "ave_precision_score": 0.795499536371968,
            "fpr": 0.15570175438596492,
            "logloss": 0.9987652075993659,
            "mae": 0.29100367716374076,
            "precision": 0.7193675889328063,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7840648332981148,
            "auditor_fn_violation": 0.015827014315961587,
            "auditor_fp_violation": 0.022197265649756763,
            "ave_precision_score": 0.7850866700451744,
            "fpr": 0.15477497255762898,
            "logloss": 0.9412868355505183,
            "mae": 0.2868079947268195,
            "precision": 0.7229862475442044,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8354419923862376,
            "auditor_fn_violation": 0.026394110275689227,
            "auditor_fp_violation": 0.01575325929502656,
            "ave_precision_score": 0.8358560859977846,
            "fpr": 0.11842105263157894,
            "logloss": 1.7747102943907727,
            "mae": 0.28384647515340194,
            "precision": 0.7682403433476395,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8644761345675438,
            "auditor_fn_violation": 0.021974564711177657,
            "auditor_fp_violation": 0.019903007379652844,
            "ave_precision_score": 0.8642297664253097,
            "fpr": 0.10098792535675083,
            "logloss": 1.7714010197717518,
            "mae": 0.26530187913654474,
            "precision": 0.7969094922737306,
            "recall": 0.7552301255230126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 12092,
        "test": {
            "accuracy": 0.48026315789473684,
            "auc_prc": 0.6141212730925243,
            "auditor_fn_violation": 0.0017276647501105811,
            "auditor_fp_violation": 0.0006086029293417028,
            "ave_precision_score": 0.6152367897804328,
            "fpr": 0.0010964912280701754,
            "logloss": 3.048433982300046,
            "mae": 0.5208210010613701,
            "precision": 0.75,
            "recall": 0.0063025210084033615
        },
        "train": {
            "accuracy": 0.4774972557628979,
            "auc_prc": 0.6273923686985712,
            "auditor_fn_violation": 0.00108850910994861,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6286741908248535,
            "fpr": 0.0,
            "logloss": 3.0357183015260953,
            "mae": 0.524643854156008,
            "precision": 1.0,
            "recall": 0.0041841004184100415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7550635887625747,
            "auditor_fn_violation": 0.006689517912428132,
            "auditor_fp_violation": 0.008973120875583456,
            "ave_precision_score": 0.7469062122458061,
            "fpr": 0.18640350877192982,
            "logloss": 1.4114154242557597,
            "mae": 0.2948107620373943,
            "precision": 0.6985815602836879,
            "recall": 0.8277310924369747
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7417344786336189,
            "auditor_fn_violation": 0.002758015698414084,
            "auditor_fp_violation": 0.016909063714467515,
            "ave_precision_score": 0.7351754805797055,
            "fpr": 0.18111964873765093,
            "logloss": 1.4352800055198718,
            "mae": 0.29490153434278943,
            "precision": 0.6966911764705882,
            "recall": 0.7928870292887029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7925421661680628,
            "auditor_fn_violation": 0.007841294412501847,
            "auditor_fp_violation": 0.004934210526315789,
            "ave_precision_score": 0.7928940179907196,
            "fpr": 0.01644736842105263,
            "logloss": 2.4348595275947504,
            "mae": 0.41095721690299075,
            "precision": 0.8846153846153846,
            "recall": 0.2415966386554622
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.8007045159762036,
            "auditor_fn_violation": 0.0038580069719697414,
            "auditor_fp_violation": 0.004193042186466158,
            "ave_precision_score": 0.8012038579347434,
            "fpr": 0.013172338090010977,
            "logloss": 2.405695270418381,
            "mae": 0.41594898886596376,
            "precision": 0.9024390243902439,
            "recall": 0.23221757322175732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 12092,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8451857821913547,
            "auditor_fn_violation": 0.011582264484741273,
            "auditor_fp_violation": 0.011638902301625625,
            "ave_precision_score": 0.845662183197681,
            "fpr": 0.09210526315789473,
            "logloss": 0.5720026061541492,
            "mae": 0.3038815743918149,
            "precision": 0.8009478672985783,
            "recall": 0.7100840336134454
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.8844014735720103,
            "auditor_fn_violation": 0.015124305903209958,
            "auditor_fp_violation": 0.012064502881132073,
            "ave_precision_score": 0.884551484392843,
            "fpr": 0.07244785949506037,
            "logloss": 0.4754375071014907,
            "mae": 0.2772670159236817,
            "precision": 0.8428571428571429,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8202987867011539,
            "auditor_fn_violation": 0.010439702196668137,
            "auditor_fp_violation": 0.017574038306776115,
            "ave_precision_score": 0.8206301822276522,
            "fpr": 0.13157894736842105,
            "logloss": 1.0044422017875412,
            "mae": 0.27437287489535356,
            "precision": 0.7515527950310559,
            "recall": 0.7626050420168067
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8258930810365043,
            "auditor_fn_violation": 0.009486563572147026,
            "auditor_fp_violation": 0.013950611337438495,
            "ave_precision_score": 0.8261743744841734,
            "fpr": 0.1251372118551043,
            "logloss": 0.9141200657351288,
            "mae": 0.2673060225496293,
            "precision": 0.7610062893081762,
            "recall": 0.7594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8234280804469132,
            "auditor_fn_violation": 0.020174517175291177,
            "auditor_fp_violation": 0.01879627394173508,
            "ave_precision_score": 0.823823153102049,
            "fpr": 0.1425438596491228,
            "logloss": 0.7272471873089327,
            "mae": 0.28322646156763454,
            "precision": 0.7379032258064516,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8351162741718452,
            "auditor_fn_violation": 0.015156455961309706,
            "auditor_fp_violation": 0.020673675351046868,
            "ave_precision_score": 0.8363824199183516,
            "fpr": 0.13611416026344675,
            "logloss": 0.6504901624328475,
            "mae": 0.27480229554036956,
            "precision": 0.746938775510204,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8358138229055541,
            "auditor_fn_violation": 0.01345274952086098,
            "auditor_fp_violation": 0.01907039674875262,
            "ave_precision_score": 0.8361311739822987,
            "fpr": 0.14364035087719298,
            "logloss": 0.8879624340157646,
            "mae": 0.2664273991532545,
            "precision": 0.7436399217221135,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8398343514273563,
            "auditor_fn_violation": 0.012885283999834664,
            "auditor_fp_violation": 0.017862258310665388,
            "ave_precision_score": 0.8401967998837055,
            "fpr": 0.13830954994511527,
            "logloss": 0.8055672374779927,
            "mae": 0.26287649141072794,
            "precision": 0.7485029940119761,
            "recall": 0.7845188284518828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7870329694218485,
            "auditor_fn_violation": 0.009361639392599144,
            "auditor_fp_violation": 0.005404494608079833,
            "ave_precision_score": 0.7873971303554473,
            "fpr": 0.01864035087719298,
            "logloss": 2.488219966516641,
            "mae": 0.40908470012798803,
            "precision": 0.8740740740740741,
            "recall": 0.24789915966386555
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7933814234811951,
            "auditor_fn_violation": 0.009231659540070459,
            "auditor_fp_violation": 0.004444016295571448,
            "ave_precision_score": 0.7939029869368209,
            "fpr": 0.018660812294182216,
            "logloss": 2.462841372718852,
            "mae": 0.41434964720738166,
            "precision": 0.8712121212121212,
            "recall": 0.2405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8223863723718959,
            "auditor_fn_violation": 0.02339718782249742,
            "auditor_fp_violation": 0.013771527442459361,
            "ave_precision_score": 0.8228107215537417,
            "fpr": 0.09978070175438597,
            "logloss": 0.9097227137945904,
            "mae": 0.2874553405658518,
            "precision": 0.7833333333333333,
            "recall": 0.6911764705882353
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8397070419877255,
            "auditor_fn_violation": 0.015505513734964114,
            "auditor_fp_violation": 0.01708144997122671,
            "ave_precision_score": 0.8402711524957436,
            "fpr": 0.09330406147091108,
            "logloss": 0.7968388884054988,
            "mae": 0.2703199965102712,
            "precision": 0.7995283018867925,
            "recall": 0.7092050209205021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.8285722246403171,
            "auditor_fn_violation": 0.020520050125313286,
            "auditor_fp_violation": 0.00524605665539997,
            "ave_precision_score": 0.8288992241789368,
            "fpr": 0.05043859649122807,
            "logloss": 1.110930491839543,
            "mae": 0.3197507407293722,
            "precision": 0.8362989323843416,
            "recall": 0.49369747899159666
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8353302752792507,
            "auditor_fn_violation": 0.0070431591565661995,
            "auditor_fp_violation": 0.004900332857581066,
            "ave_precision_score": 0.83566266970105,
            "fpr": 0.042810098792535674,
            "logloss": 1.0520267016917437,
            "mae": 0.3143315845147214,
            "precision": 0.8607142857142858,
            "recall": 0.50418410041841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 12092,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.83350876753924,
            "auditor_fn_violation": 0.016705366357069158,
            "auditor_fp_violation": 0.006277160791887978,
            "ave_precision_score": 0.83381949394404,
            "fpr": 0.03508771929824561,
            "logloss": 1.1586648295597832,
            "mae": 0.3285949181763203,
            "precision": 0.8714859437751004,
            "recall": 0.45588235294117646
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8433827143349741,
            "auditor_fn_violation": 0.0055275135604352385,
            "auditor_fp_violation": 0.0055290356763498735,
            "ave_precision_score": 0.8436739400643429,
            "fpr": 0.03512623490669594,
            "logloss": 1.0877989643887436,
            "mae": 0.32314073830379236,
            "precision": 0.8745098039215686,
            "recall": 0.4665271966527197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8399138551550207,
            "auditor_fn_violation": 0.010974126492702345,
            "auditor_fp_violation": 0.00666948334138098,
            "ave_precision_score": 0.8411489667690484,
            "fpr": 0.10307017543859649,
            "logloss": 0.7384363672400911,
            "mae": 0.2719122021322637,
            "precision": 0.7839080459770115,
            "recall": 0.7163865546218487
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8587358500180271,
            "auditor_fn_violation": 0.006384082965521365,
            "auditor_fp_violation": 0.011126518837001192,
            "ave_precision_score": 0.8589504389425504,
            "fpr": 0.09769484083424808,
            "logloss": 0.6794661447170098,
            "mae": 0.2682786257096846,
            "precision": 0.7925407925407926,
            "recall": 0.7112970711297071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7915880956482627,
            "auditor_fn_violation": 0.0128998968008256,
            "auditor_fp_violation": 0.024635844197650095,
            "ave_precision_score": 0.7918802791017808,
            "fpr": 0.16666666666666666,
            "logloss": 0.9045357213018101,
            "mae": 0.28930445142351235,
            "precision": 0.7205882352941176,
            "recall": 0.8235294117647058
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7808971172146205,
            "auditor_fn_violation": 0.014394040297801395,
            "auditor_fp_violation": 0.021236465777525398,
            "ave_precision_score": 0.7820489374242818,
            "fpr": 0.15916575192096596,
            "logloss": 0.874695944223915,
            "mae": 0.278718626083742,
            "precision": 0.7274436090225563,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8164994418932696,
            "auditor_fn_violation": 0.027108211705734925,
            "auditor_fp_violation": 0.02623531305327539,
            "ave_precision_score": 0.8168434001198595,
            "fpr": 0.1206140350877193,
            "logloss": 1.5479952837395532,
            "mae": 0.28189920126027485,
            "precision": 0.7592997811816192,
            "recall": 0.7289915966386554
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8353948409502405,
            "auditor_fn_violation": 0.02160024617758774,
            "auditor_fp_violation": 0.02403267226583989,
            "ave_precision_score": 0.8357024545935637,
            "fpr": 0.10537870472008781,
            "logloss": 1.307626255849871,
            "mae": 0.263873428445167,
            "precision": 0.7842696629213484,
            "recall": 0.7301255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8304117442600123,
            "auditor_fn_violation": 0.018437638213180008,
            "auditor_fp_violation": 0.024688656848543385,
            "ave_precision_score": 0.8307328765335826,
            "fpr": 0.18530701754385964,
            "logloss": 0.8921713066312683,
            "mae": 0.27486931430205086,
            "precision": 0.7050610820244329,
            "recall": 0.8487394957983193
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.839544523707307,
            "auditor_fn_violation": 0.010604926307473974,
            "auditor_fp_violation": 0.024689261096731512,
            "ave_precision_score": 0.8398951761448822,
            "fpr": 0.1756311745334797,
            "logloss": 0.7964611457190349,
            "mae": 0.269185349489971,
            "precision": 0.7122302158273381,
            "recall": 0.8284518828451883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7242988360003535,
            "auditor_fn_violation": 0.031298374613003103,
            "auditor_fp_violation": 0.012820899726380177,
            "ave_precision_score": 0.724533749396546,
            "fpr": 0.12828947368421054,
            "logloss": 2.519355765599383,
            "mae": 0.33313149421981325,
            "precision": 0.7200956937799043,
            "recall": 0.6323529411764706
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7664190637698962,
            "auditor_fn_violation": 0.025086231048688977,
            "auditor_fp_violation": 0.014777051333078134,
            "ave_precision_score": 0.7652215659057884,
            "fpr": 0.08562019758507135,
            "logloss": 2.3019369032574097,
            "mae": 0.30947334774460544,
            "precision": 0.7891891891891892,
            "recall": 0.6108786610878661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.802201631360429,
            "auditor_fn_violation": 0.010485773256671093,
            "auditor_fp_violation": 0.017377877032029622,
            "ave_precision_score": 0.8025429360202206,
            "fpr": 0.1524122807017544,
            "logloss": 0.8523668114528234,
            "mae": 0.28619651338018964,
            "precision": 0.7295719844357976,
            "recall": 0.7878151260504201
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7998603318899289,
            "auditor_fn_violation": 0.007199316581622112,
            "auditor_fp_violation": 0.017834372298542574,
            "ave_precision_score": 0.8006059429261294,
            "fpr": 0.14270032930845225,
            "logloss": 0.7917177734810491,
            "mae": 0.2819291059343035,
            "precision": 0.7405189620758483,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8237588527176335,
            "auditor_fn_violation": 0.005487063246351182,
            "auditor_fp_violation": 0.012136850152905198,
            "ave_precision_score": 0.8241707573673328,
            "fpr": 0.08881578947368421,
            "logloss": 0.5738418332385488,
            "mae": 0.34013234174033824,
            "precision": 0.7969924812030075,
            "recall": 0.6680672268907563
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8661309221271822,
            "auditor_fn_violation": 0.008267157797078024,
            "auditor_fp_violation": 0.00833791762472019,
            "ave_precision_score": 0.8663410220077656,
            "fpr": 0.07025246981339188,
            "logloss": 0.48770022351104547,
            "mae": 0.3120377255139695,
            "precision": 0.8407960199004975,
            "recall": 0.7071129707112971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8356123474109773,
            "auditor_fn_violation": 0.012033760872770168,
            "auditor_fp_violation": 0.010733542572026397,
            "ave_precision_score": 0.8359338101461555,
            "fpr": 0.11842105263157894,
            "logloss": 0.8066210957458071,
            "mae": 0.27078659960219664,
            "precision": 0.7682403433476395,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8449087186676751,
            "auditor_fn_violation": 0.010664633558230647,
            "auditor_fp_violation": 0.012738837356101838,
            "ave_precision_score": 0.8452012334834648,
            "fpr": 0.11964873765093303,
            "logloss": 0.7359110724804523,
            "mae": 0.2631036556029574,
            "precision": 0.7705263157894737,
            "recall": 0.7656903765690377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 12092,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8269982445232957,
            "auditor_fn_violation": 0.02653693056169837,
            "auditor_fp_violation": 0.015738169966199905,
            "ave_precision_score": 0.8269995913506206,
            "fpr": 0.1162280701754386,
            "logloss": 1.7755516853413,
            "mae": 0.3254973516536388,
            "precision": 0.7665198237885462,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8642593746898625,
            "auditor_fn_violation": 0.026317118987365027,
            "auditor_fp_violation": 0.01515478004274165,
            "ave_precision_score": 0.8639551635002065,
            "fpr": 0.08342480790340286,
            "logloss": 1.753538874010749,
            "mae": 0.2973704096933243,
            "precision": 0.8236658932714617,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7534413176730916,
            "auditor_fn_violation": 0.023606811145510838,
            "auditor_fp_violation": 0.034695396748752626,
            "ave_precision_score": 0.7550534571905562,
            "fpr": 0.21271929824561403,
            "logloss": 1.0796468380864943,
            "mae": 0.32359839951853436,
            "precision": 0.6666666666666666,
            "recall": 0.8151260504201681
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8020122397802729,
            "auditor_fn_violation": 0.023687703521349933,
            "auditor_fp_violation": 0.03190666805251697,
            "ave_precision_score": 0.8030155060273851,
            "fpr": 0.18111964873765093,
            "logloss": 0.8535929729445708,
            "mae": 0.30065204638853177,
            "precision": 0.698905109489051,
            "recall": 0.801255230125523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 12092,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8260460346244383,
            "auditor_fn_violation": 0.02922748046587056,
            "auditor_fp_violation": 0.015381055850635768,
            "ave_precision_score": 0.8272581374164011,
            "fpr": 0.10087719298245613,
            "logloss": 1.568256002886809,
            "mae": 0.2802873718865817,
            "precision": 0.784037558685446,
            "recall": 0.7016806722689075
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8614064579985472,
            "auditor_fn_violation": 0.022523412131594787,
            "auditor_fp_violation": 0.021401246758251093,
            "ave_precision_score": 0.861531784389832,
            "fpr": 0.0867178924259056,
            "logloss": 1.3203692836481724,
            "mae": 0.26178104816977804,
            "precision": 0.8091787439613527,
            "recall": 0.700836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8349951024601381,
            "auditor_fn_violation": 0.0065559118384195805,
            "auditor_fp_violation": 0.02433405762111701,
            "ave_precision_score": 0.8349198794569269,
            "fpr": 0.3333333333333333,
            "logloss": 1.903278190368624,
            "mae": 0.3521143975014128,
            "precision": 0.6005256241787122,
            "recall": 0.9600840336134454
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.841911480820555,
            "auditor_fn_violation": 0.0019519678131989767,
            "auditor_fp_violation": 0.02600243875851475,
            "ave_precision_score": 0.8414915728360663,
            "fpr": 0.3238199780461032,
            "logloss": 1.7473007121262516,
            "mae": 0.33840918503949313,
            "precision": 0.6123521681997371,
            "recall": 0.9748953974895398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.841814839353364,
            "auditor_fn_violation": 0.014037851982898432,
            "auditor_fp_violation": 0.014422883470143245,
            "ave_precision_score": 0.8421774317861448,
            "fpr": 0.11293859649122807,
            "logloss": 0.7033038840390085,
            "mae": 0.27180808178026267,
            "precision": 0.7741228070175439,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8512318910254105,
            "auditor_fn_violation": 0.0052909809901299345,
            "auditor_fp_violation": 0.0132281101142566,
            "ave_precision_score": 0.851476156075121,
            "fpr": 0.11306256860592755,
            "logloss": 0.6616125974207228,
            "mae": 0.26839475319539113,
            "precision": 0.774617067833698,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7936517948594893,
            "auditor_fn_violation": 0.008458646616541353,
            "auditor_fp_violation": 0.034982093996459046,
            "ave_precision_score": 0.7943726947123002,
            "fpr": 0.40899122807017546,
            "logloss": 1.4068212549143442,
            "mae": 0.40769059240363037,
            "precision": 0.5543608124253285,
            "recall": 0.9747899159663865
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8114457895628486,
            "auditor_fn_violation": 0.004480340239472004,
            "auditor_fp_violation": 0.027708555682028475,
            "ave_precision_score": 0.8123474322356758,
            "fpr": 0.4105378704720088,
            "logloss": 1.329411315389551,
            "mae": 0.40070962611554334,
            "precision": 0.5563463819691578,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.842391924363268,
            "auditor_fn_violation": 0.010716128556685838,
            "auditor_fp_violation": 0.009870935940769357,
            "ave_precision_score": 0.8436213634691054,
            "fpr": 0.10855263157894737,
            "logloss": 0.7772274032805758,
            "mae": 0.2691924665194115,
            "precision": 0.7824175824175824,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8629274646287385,
            "auditor_fn_violation": 0.008618512003453836,
            "auditor_fp_violation": 0.011017509880521116,
            "ave_precision_score": 0.8631212992786098,
            "fpr": 0.10976948408342481,
            "logloss": 0.691745553232038,
            "mae": 0.2645713711325891,
            "precision": 0.7802197802197802,
            "recall": 0.7426778242677824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8312040716881783,
            "auditor_fn_violation": 0.033459107327141385,
            "auditor_fp_violation": 0.02988693062932561,
            "ave_precision_score": 0.8315142471186452,
            "fpr": 0.14473684210526316,
            "logloss": 0.8487334241096925,
            "mae": 0.27434926359783407,
            "precision": 0.7406679764243614,
            "recall": 0.792016806722689
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8520765353540698,
            "auditor_fn_violation": 0.023788746561092006,
            "auditor_fp_violation": 0.03227679148614699,
            "ave_precision_score": 0.8525079199362493,
            "fpr": 0.132821075740944,
            "logloss": 0.7305299174109188,
            "mae": 0.2545414394533047,
            "precision": 0.7570281124497992,
            "recall": 0.7887029288702929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.7907568599653809,
            "auditor_fn_violation": 0.011987689812767214,
            "auditor_fp_violation": 0.00612626750362144,
            "ave_precision_score": 0.7911093678457188,
            "fpr": 0.020833333333333332,
            "logloss": 2.1795359813113864,
            "mae": 0.39464082744077034,
            "precision": 0.8758169934640523,
            "recall": 0.2815126050420168
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7958279203738896,
            "auditor_fn_violation": 0.005559663618534975,
            "auditor_fp_violation": 0.004646823656464612,
            "ave_precision_score": 0.7963231329847027,
            "fpr": 0.02305159165751921,
            "logloss": 2.153539503555054,
            "mae": 0.39839912224923413,
            "precision": 0.8653846153846154,
            "recall": 0.2824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8253764019392948,
            "auditor_fn_violation": 0.02851107548282471,
            "auditor_fp_violation": 0.017013218252052157,
            "ave_precision_score": 0.8265923125786622,
            "fpr": 0.10416666666666667,
            "logloss": 1.5630559498795942,
            "mae": 0.28068139022070104,
            "precision": 0.7769953051643192,
            "recall": 0.6953781512605042
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8609231403501931,
            "auditor_fn_violation": 0.023733632175778147,
            "auditor_fp_violation": 0.022909626504893997,
            "ave_precision_score": 0.8610540273468767,
            "fpr": 0.09110867178924259,
            "logloss": 1.3125010995674886,
            "mae": 0.2623023606365619,
            "precision": 0.8004807692307693,
            "recall": 0.696652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.8330361869071605,
            "auditor_fn_violation": 0.015783945157010183,
            "auditor_fp_violation": 0.007006478351842911,
            "ave_precision_score": 0.8333169893610032,
            "fpr": 0.025219298245614034,
            "logloss": 1.2739049176879476,
            "mae": 0.34688717377214473,
            "precision": 0.892018779342723,
            "recall": 0.39915966386554624
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.8408786208233415,
            "auditor_fn_violation": 0.0061636254242659625,
            "auditor_fp_violation": 0.004910473225625725,
            "ave_precision_score": 0.8412057307228773,
            "fpr": 0.026344676180021953,
            "logloss": 1.207466995711555,
            "mae": 0.34460464678042896,
            "precision": 0.8878504672897196,
            "recall": 0.39748953974895396
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8027065631846599,
            "auditor_fn_violation": 0.02806879330679641,
            "auditor_fp_violation": 0.021356430065990667,
            "ave_precision_score": 0.8029945884830703,
            "fpr": 0.12719298245614036,
            "logloss": 0.8777588324512253,
            "mae": 0.3388270151474631,
            "precision": 0.7404921700223713,
            "recall": 0.6953781512605042
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8374167130475624,
            "auditor_fn_violation": 0.019799842924001856,
            "auditor_fp_violation": 0.027100133599348993,
            "ave_precision_score": 0.8378365221286218,
            "fpr": 0.09879253567508232,
            "logloss": 0.7489803444606697,
            "mae": 0.3069053693628585,
            "precision": 0.7916666666666666,
            "recall": 0.7154811715481172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 12092,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8003539599501832,
            "auditor_fn_violation": 0.019561772077251956,
            "auditor_fp_violation": 0.018230424110735558,
            "ave_precision_score": 0.8006573205133533,
            "fpr": 0.13706140350877194,
            "logloss": 1.1509677537497602,
            "mae": 0.28462613507829726,
            "precision": 0.7401247401247402,
            "recall": 0.7478991596638656
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7971557706492325,
            "auditor_fn_violation": 0.011495942203381274,
            "auditor_fp_violation": 0.016835546046143752,
            "ave_precision_score": 0.7987737975686167,
            "fpr": 0.12843029637760703,
            "logloss": 1.0495453827897225,
            "mae": 0.2787628311445272,
            "precision": 0.7531645569620253,
            "recall": 0.7468619246861925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.762891012156188,
            "auditor_fn_violation": 0.0006864587940439336,
            "auditor_fp_violation": 0.0032743843553838772,
            "ave_precision_score": 0.5355904679054566,
            "fpr": 0.44956140350877194,
            "logloss": 15.339663955755723,
            "mae": 0.454909780576936,
            "precision": 0.5346197502837684,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7621232664130139,
            "auditor_fn_violation": 0.002468665175516353,
            "auditor_fp_violation": 0.003064926241497935,
            "ave_precision_score": 0.5349489672257757,
            "fpr": 0.4500548847420417,
            "logloss": 15.420259334148646,
            "mae": 0.45587388533448014,
            "precision": 0.535673839184598,
            "recall": 0.9895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8401568926169302,
            "auditor_fn_violation": 0.007246977738463821,
            "auditor_fp_violation": 0.008892644455174636,
            "ave_precision_score": 0.8404987272207539,
            "fpr": 0.1074561403508772,
            "logloss": 0.7416784426946195,
            "mae": 0.2718832066268674,
            "precision": 0.7787810383747178,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8513355522929922,
            "auditor_fn_violation": 0.00607176811540952,
            "auditor_fp_violation": 0.013387820910959969,
            "ave_precision_score": 0.8515963006331349,
            "fpr": 0.10428100987925357,
            "logloss": 0.6800627156002081,
            "mae": 0.26766665007800755,
            "precision": 0.7835990888382688,
            "recall": 0.7196652719665272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7628922679925405,
            "auditor_fn_violation": 0.0006864587940439336,
            "auditor_fp_violation": 0.004662602607436037,
            "ave_precision_score": 0.5355917236568776,
            "fpr": 0.44846491228070173,
            "logloss": 15.337265203533388,
            "mae": 0.45521489097000073,
            "precision": 0.5352272727272728,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7621245246073431,
            "auditor_fn_violation": 0.0011528092261481016,
            "auditor_fp_violation": 0.0028976101687610838,
            "ave_precision_score": 0.5349502253254795,
            "fpr": 0.4489571899012075,
            "logloss": 15.42289391476312,
            "mae": 0.45572745118637403,
            "precision": 0.5368063420158551,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.7624376607304365,
            "auditor_fn_violation": 0.0008200648680524842,
            "auditor_fp_violation": 0.004644998390471598,
            "ave_precision_score": 0.5356655617458163,
            "fpr": 0.45285087719298245,
            "logloss": 15.324961761485191,
            "mae": 0.45727690933374004,
            "precision": 0.5333333333333333,
            "recall": 0.9915966386554622
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7609284913327621,
            "auditor_fn_violation": 0.0011528092261481016,
            "auditor_fp_violation": 0.003064926241497935,
            "ave_precision_score": 0.5345073010121377,
            "fpr": 0.4500548847420417,
            "logloss": 15.392491919700735,
            "mae": 0.4561921226191737,
            "precision": 0.5361990950226244,
            "recall": 0.9916317991631799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8394460574968831,
            "auditor_fn_violation": 0.007113371664455254,
            "auditor_fp_violation": 0.008892644455174636,
            "ave_precision_score": 0.8399860795667792,
            "fpr": 0.1074561403508772,
            "logloss": 0.7362004038196487,
            "mae": 0.2709378530534666,
            "precision": 0.7802690582959642,
            "recall": 0.7310924369747899
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8523888118605929,
            "auditor_fn_violation": 0.004310404218087621,
            "auditor_fp_violation": 0.012006195764875294,
            "ave_precision_score": 0.8526467718415572,
            "fpr": 0.10318331503841932,
            "logloss": 0.6764316676310951,
            "mae": 0.26698114435969206,
            "precision": 0.7848970251716247,
            "recall": 0.7175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8034558370556804,
            "auditor_fn_violation": 0.0203265516733009,
            "auditor_fp_violation": 0.021892101239336874,
            "ave_precision_score": 0.8027156296405025,
            "fpr": 0.18311403508771928,
            "logloss": 1.6761705592475555,
            "mae": 0.29505073398100296,
            "precision": 0.7001795332136446,
            "recall": 0.819327731092437
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8199293838328814,
            "auditor_fn_violation": 0.016171479224173172,
            "auditor_fp_violation": 0.013296557598558042,
            "ave_precision_score": 0.8196734948373827,
            "fpr": 0.14928649835345773,
            "logloss": 1.4328149393796503,
            "mae": 0.26781797996526563,
            "precision": 0.7424242424242424,
            "recall": 0.8200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.8019025782376896,
            "auditor_fn_violation": 0.013139466312840926,
            "auditor_fp_violation": 0.0025048285852245296,
            "ave_precision_score": 0.803151881051144,
            "fpr": 0.006578947368421052,
            "logloss": 2.581445281354534,
            "mae": 0.4068971830927032,
            "precision": 0.95,
            "recall": 0.23949579831932774
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.8320710605696179,
            "auditor_fn_violation": 0.011725585475522337,
            "auditor_fp_violation": 0.0029305663649062145,
            "ave_precision_score": 0.8323035551765967,
            "fpr": 0.007683863885839737,
            "logloss": 2.4254746113141197,
            "mae": 0.4121892954498735,
            "precision": 0.9369369369369369,
            "recall": 0.2175732217573222
        }
    }
]