[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8343864988571142,
            "auditor_fn_violation": 0.01644736842105264,
            "auditor_fp_violation": 0.030348469622744213,
            "ave_precision_score": 0.8348831366299975,
            "fpr": 0.13596491228070176,
            "logloss": 0.9105357089495693,
            "mae": 0.27296938595019304,
            "precision": 0.751004016064257,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8261487577858835,
            "auditor_fn_violation": 0.019284664893528366,
            "auditor_fp_violation": 0.02100256128796195,
            "ave_precision_score": 0.8264287229714701,
            "fpr": 0.13172338090010977,
            "logloss": 0.8542166549443715,
            "mae": 0.26482568750557167,
            "precision": 0.7478991596638656,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6962059432177932,
            "auditor_fn_violation": 0.04903962492437992,
            "auditor_fp_violation": 0.019543189716534782,
            "ave_precision_score": 0.6960979048864964,
            "fpr": 0.10964912280701754,
            "logloss": 0.6218713752903515,
            "mae": 0.42688510499143023,
            "precision": 0.726775956284153,
            "recall": 0.539553752535497
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6902506233795496,
            "auditor_fn_violation": 0.04404589840727098,
            "auditor_fp_violation": 0.013318697402122211,
            "ave_precision_score": 0.6805895360506096,
            "fpr": 0.12952799121844127,
            "logloss": 0.6099315432151469,
            "mae": 0.4205393752841735,
            "precision": 0.6902887139107612,
            "recall": 0.5704989154013015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6007900984114806,
            "auditor_fn_violation": 0.014289971887121455,
            "auditor_fp_violation": 0.011637461792907106,
            "ave_precision_score": 0.5901576425411557,
            "fpr": 0.3399122807017544,
            "logloss": 0.6916736883973339,
            "mae": 0.45320135645829795,
            "precision": 0.5931758530183727,
            "recall": 0.9168356997971603
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.5481356022040912,
            "auditor_fn_violation": 0.009864966866759847,
            "auditor_fp_violation": 0.0172923527259422,
            "ave_precision_score": 0.5515548117460499,
            "fpr": 0.3589462129527991,
            "logloss": 0.7044002684266133,
            "mae": 0.45621846684967254,
            "precision": 0.5708661417322834,
            "recall": 0.9436008676789588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8346351018137486,
            "auditor_fn_violation": 0.005437973737589413,
            "auditor_fp_violation": 0.01080266298203744,
            "ave_precision_score": 0.8184492123814274,
            "fpr": 0.12609649122807018,
            "logloss": 0.5533466732321045,
            "mae": 0.35101511194207297,
            "precision": 0.7510822510822511,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8361043491192967,
            "auditor_fn_violation": 0.007924356681770883,
            "auditor_fp_violation": 0.014489571899012085,
            "ave_precision_score": 0.8165259970982699,
            "fpr": 0.13391877058177826,
            "logloss": 0.5107843709026075,
            "mae": 0.33203610116626114,
            "precision": 0.7426160337552743,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7771404787254165,
            "auditor_fn_violation": 0.001968346322194946,
            "auditor_fp_violation": 0.012809843821965419,
            "ave_precision_score": 0.7276249199006132,
            "fpr": 0.10416666666666667,
            "logloss": 0.587453922249265,
            "mae": 0.39848686357666,
            "precision": 0.7939262472885033,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.7699124852591901,
            "auditor_fn_violation": 0.0068790464103473834,
            "auditor_fp_violation": 0.009354799365776316,
            "ave_precision_score": 0.7215120762777252,
            "fpr": 0.09989023051591657,
            "logloss": 0.5642540856721012,
            "mae": 0.38727124580044126,
            "precision": 0.7908045977011494,
            "recall": 0.7462039045553145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.790620243295551,
            "auditor_fn_violation": 0.010733603786342126,
            "auditor_fp_violation": 0.018834003265921367,
            "ave_precision_score": 0.7682844921401346,
            "fpr": 0.17434210526315788,
            "logloss": 1.752336296040608,
            "mae": 0.29958021923646394,
            "precision": 0.7066420664206642,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.773896761279561,
            "auditor_fn_violation": 0.011081717547163975,
            "auditor_fp_violation": 0.022295401878277846,
            "ave_precision_score": 0.7442923964031121,
            "fpr": 0.17892425905598244,
            "logloss": 1.9872206967533852,
            "mae": 0.29675838243600666,
            "precision": 0.693609022556391,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8608264123138349,
            "auditor_fn_violation": 0.019883634034376006,
            "auditor_fp_violation": 0.016371477620064488,
            "ave_precision_score": 0.8610119433235439,
            "fpr": 0.09868421052631579,
            "logloss": 0.7766394879704063,
            "mae": 0.3147657367408077,
            "precision": 0.801762114537445,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8518930356470593,
            "auditor_fn_violation": 0.01678211114576959,
            "auditor_fp_violation": 0.01710940358580315,
            "ave_precision_score": 0.8522758263695347,
            "fpr": 0.10757409440175632,
            "logloss": 0.7398529666636159,
            "mae": 0.301366709317133,
            "precision": 0.7846153846153846,
            "recall": 0.7744034707158352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 22571,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.6739802543330065,
            "auditor_fn_violation": 0.005922831927689406,
            "auditor_fp_violation": 0.026907214336557413,
            "ave_precision_score": 0.6747883571972114,
            "fpr": 0.3059210526315789,
            "logloss": 0.6614349392059058,
            "mae": 0.45205337137572077,
            "precision": 0.6097902097902098,
            "recall": 0.8843813387423936
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6367388889784101,
            "auditor_fn_violation": 0.0060789911684378225,
            "auditor_fp_violation": 0.02709598731552628,
            "ave_precision_score": 0.637695259125052,
            "fpr": 0.32491767288693746,
            "logloss": 0.6667392099675039,
            "mae": 0.45440350090174986,
            "precision": 0.5836849507735584,
            "recall": 0.9002169197396963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7734804137487405,
            "auditor_fn_violation": 0.024967972670011742,
            "auditor_fp_violation": 0.02466974416949295,
            "ave_precision_score": 0.7656746193332236,
            "fpr": 0.11732456140350878,
            "logloss": 2.8219962741620446,
            "mae": 0.3097352014188593,
            "precision": 0.7545871559633027,
            "recall": 0.6673427991886409
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7606587952706134,
            "auditor_fn_violation": 0.023339706789278308,
            "auditor_fp_violation": 0.021441639224295646,
            "ave_precision_score": 0.7470734779985777,
            "fpr": 0.1141602634467618,
            "logloss": 2.6904740153774145,
            "mae": 0.2871819835158483,
            "precision": 0.7547169811320755,
            "recall": 0.6941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8140648174788092,
            "auditor_fn_violation": 0.00770212803814811,
            "auditor_fp_violation": 0.00847360046895281,
            "ave_precision_score": 0.8100076922746897,
            "fpr": 0.10855263157894737,
            "logloss": 0.5575749805051797,
            "mae": 0.35876999090409334,
            "precision": 0.7765237020316027,
            "recall": 0.6977687626774848
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8165653398513126,
            "auditor_fn_violation": 0.006631410264042041,
            "auditor_fp_violation": 0.008522990608610809,
            "ave_precision_score": 0.8118924156613363,
            "fpr": 0.11086717892425905,
            "logloss": 0.5426975110493203,
            "mae": 0.3479690722012984,
            "precision": 0.764018691588785,
            "recall": 0.7093275488069414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6451116456305657,
            "auditor_fn_violation": 0.00671684281698161,
            "auditor_fp_violation": 0.0037003307792153415,
            "ave_precision_score": 0.6461462866350329,
            "fpr": 0.044956140350877194,
            "logloss": 9.983661034861889,
            "mae": 0.442251992987861,
            "precision": 0.8127853881278538,
            "recall": 0.36105476673427994
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6219331341605588,
            "auditor_fn_violation": 0.01182462598608,
            "auditor_fp_violation": 0.0037809488962068545,
            "ave_precision_score": 0.6224047389727505,
            "fpr": 0.054884742041712405,
            "logloss": 9.434124414061055,
            "mae": 0.4281956268181568,
            "precision": 0.75,
            "recall": 0.32537960954446854
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8355943795191986,
            "auditor_fn_violation": 0.013280221344436146,
            "auditor_fp_violation": 0.008921094502365704,
            "ave_precision_score": 0.8369559937884863,
            "fpr": 0.11732456140350878,
            "logloss": 0.5273818199046982,
            "mae": 0.32804342065202563,
            "precision": 0.7829614604462475,
            "recall": 0.7829614604462475
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8535355609920485,
            "auditor_fn_violation": 0.008881565631912681,
            "auditor_fp_violation": 0.009403585803146729,
            "ave_precision_score": 0.8360149470043315,
            "fpr": 0.12623490669593854,
            "logloss": 0.49904540171051515,
            "mae": 0.3164280095709126,
            "precision": 0.7594142259414226,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7284299069786817,
            "auditor_fn_violation": 0.012777570193231563,
            "auditor_fp_violation": 0.0184938031235607,
            "ave_precision_score": 0.7114505818713353,
            "fpr": 0.16666666666666666,
            "logloss": 0.6416204633457055,
            "mae": 0.4321472723519005,
            "precision": 0.6984126984126984,
            "recall": 0.7139959432048681
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7187410737688206,
            "auditor_fn_violation": 0.013796190689357123,
            "auditor_fp_violation": 0.025334796926454444,
            "ave_precision_score": 0.7016696519188262,
            "fpr": 0.18221734357848518,
            "logloss": 0.6174434734289737,
            "mae": 0.4211271790303004,
            "precision": 0.6706349206349206,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.823290105850018,
            "auditor_fn_violation": 0.0059206078075513405,
            "auditor_fp_violation": 0.008955114516601768,
            "ave_precision_score": 0.8229885138287292,
            "fpr": 0.1118421052631579,
            "logloss": 0.7993006472780391,
            "mae": 0.2671462491903265,
            "precision": 0.7866108786610879,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8158431501892565,
            "auditor_fn_violation": 0.007026675651414029,
            "auditor_fp_violation": 0.00562019758507135,
            "ave_precision_score": 0.8161466012832922,
            "fpr": 0.13062568605927552,
            "logloss": 0.7482104653817455,
            "mae": 0.2686834710668164,
            "precision": 0.7468085106382979,
            "recall": 0.7613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7366926934000213,
            "auditor_fn_violation": 0.011830095014412303,
            "auditor_fp_violation": 0.0208647364233974,
            "ave_precision_score": 0.7375606889022793,
            "fpr": 0.1611842105263158,
            "logloss": 0.804251176287131,
            "mae": 0.3391684241645986,
            "precision": 0.7054108216432866,
            "recall": 0.7139959432048681
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7058398392694036,
            "auditor_fn_violation": 0.01693926485400183,
            "auditor_fp_violation": 0.026088547383827296,
            "ave_precision_score": 0.7069649281160686,
            "fpr": 0.18111964873765093,
            "logloss": 0.7872533031120139,
            "mae": 0.3356173770036037,
            "precision": 0.6706586826347305,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8494212044330367,
            "auditor_fn_violation": 0.005862780683961434,
            "auditor_fp_violation": 0.011077440020097976,
            "ave_precision_score": 0.8232884175266756,
            "fpr": 0.08662280701754387,
            "logloss": 0.5171299460950673,
            "mae": 0.3242735974572338,
            "precision": 0.819634703196347,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8480370972302735,
            "auditor_fn_violation": 0.0005548002123956244,
            "auditor_fp_violation": 0.005415294548115625,
            "ave_precision_score": 0.8210300048929067,
            "fpr": 0.09330406147091108,
            "logloss": 0.48698617543963607,
            "mae": 0.3149292007432157,
            "precision": 0.8,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5772743852531939,
            "auditor_fn_violation": 0.0023909291484288785,
            "auditor_fp_violation": 0.0031743290206422987,
            "ave_precision_score": 0.5423783851108501,
            "fpr": 0.010964912280701754,
            "logloss": 0.7223725689226346,
            "mae": 0.4973712814481635,
            "precision": 0.6,
            "recall": 0.030425963488843813
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5361539513707164,
            "auditor_fn_violation": 0.0001333425403182855,
            "auditor_fp_violation": 0.0037614343212586904,
            "ave_precision_score": 0.507111469866041,
            "fpr": 0.008781558726673985,
            "logloss": 0.7179891391924503,
            "mae": 0.49893569141528216,
            "precision": 0.5555555555555556,
            "recall": 0.021691973969631236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.851883973428797,
            "auditor_fn_violation": 0.011563200597843486,
            "auditor_fp_violation": 0.005649939287359211,
            "ave_precision_score": 0.8518728987724242,
            "fpr": 0.039473684210526314,
            "logloss": 0.5795946306893308,
            "mae": 0.3834423520467112,
            "precision": 0.8754325259515571,
            "recall": 0.513184584178499
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8470586763328485,
            "auditor_fn_violation": 0.017413107095489936,
            "auditor_fp_violation": 0.003941944139529212,
            "ave_precision_score": 0.8468618669937086,
            "fpr": 0.04171240395170143,
            "logloss": 0.5394082250581738,
            "mae": 0.37069113744484705,
            "precision": 0.8657243816254417,
            "recall": 0.5314533622559653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7864562671265602,
            "auditor_fn_violation": 0.006843617664851786,
            "auditor_fp_violation": 0.009384290080810619,
            "ave_precision_score": 0.7821684426289013,
            "fpr": 0.15570175438596492,
            "logloss": 1.2601168122113706,
            "mae": 0.32000646797077753,
            "precision": 0.7290076335877863,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7551929661091605,
            "auditor_fn_violation": 0.006471875439018407,
            "auditor_fp_violation": 0.007288693743139407,
            "ave_precision_score": 0.7523043040399959,
            "fpr": 0.1712403951701427,
            "logloss": 1.4869732749354179,
            "mae": 0.3332443931897837,
            "precision": 0.691089108910891,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8383992626398551,
            "auditor_fn_violation": 0.0025110316358848465,
            "auditor_fp_violation": 0.005867143993635641,
            "ave_precision_score": 0.8140680796195282,
            "fpr": 0.046052631578947366,
            "logloss": 0.5863164605455947,
            "mae": 0.30405816271811265,
            "precision": 0.8753709198813057,
            "recall": 0.5983772819472617
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7941111547943609,
            "auditor_fn_violation": 0.0021668162801717337,
            "auditor_fp_violation": 0.010150018294914015,
            "ave_precision_score": 0.8078407411747205,
            "fpr": 0.042810098792535674,
            "logloss": 0.5454150113493249,
            "mae": 0.29312687608261073,
            "precision": 0.875,
            "recall": 0.5921908893709328
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8409347804337409,
            "auditor_fn_violation": 0.00037810042347247603,
            "auditor_fp_violation": 0.012532449859732864,
            "ave_precision_score": 0.836229844330198,
            "fpr": 0.06469298245614036,
            "logloss": 0.539580879320284,
            "mae": 0.3215066478291543,
            "precision": 0.8455497382198953,
            "recall": 0.6551724137931034
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8433503396586997,
            "auditor_fn_violation": 0.002657326339199618,
            "auditor_fp_violation": 0.011057446030003663,
            "ave_precision_score": 0.8397223123452384,
            "fpr": 0.06476399560922064,
            "logloss": 0.5202823534752797,
            "mae": 0.31827306830780183,
            "precision": 0.8333333333333334,
            "recall": 0.6399132321041214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8417258101526744,
            "auditor_fn_violation": 0.022581491761859016,
            "auditor_fp_violation": 0.009826550265879499,
            "ave_precision_score": 0.8319585410545354,
            "fpr": 0.09978070175438597,
            "logloss": 0.5180012340769996,
            "mae": 0.32630370439258977,
            "precision": 0.8026030368763557,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8467089014370868,
            "auditor_fn_violation": 0.01386762419309905,
            "auditor_fp_violation": 0.016314184656665447,
            "ave_precision_score": 0.8389460026717492,
            "fpr": 0.10757409440175632,
            "logloss": 0.49810016334315566,
            "mae": 0.32286224732610974,
            "precision": 0.7831858407079646,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 22571,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5977958770277987,
            "auditor_fn_violation": 0.09900225970606029,
            "auditor_fp_violation": 0.08249591759829168,
            "ave_precision_score": 0.5995829700603157,
            "fpr": 0.24013157894736842,
            "logloss": 1.3633469826180151,
            "mae": 0.501103097717505,
            "precision": 0.512249443207127,
            "recall": 0.4665314401622718
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.5691559109878068,
            "auditor_fn_violation": 0.09338025720823581,
            "auditor_fp_violation": 0.08749847542383218,
            "ave_precision_score": 0.5701951271313249,
            "fpr": 0.24478594950603733,
            "logloss": 1.3845737503143467,
            "mae": 0.5039973561830232,
            "precision": 0.471563981042654,
            "recall": 0.4316702819956616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6577303036388775,
            "auditor_fn_violation": 0.01025764207679445,
            "auditor_fp_violation": 0.0031507767030942535,
            "ave_precision_score": 0.6629884264011146,
            "fpr": 0.0537280701754386,
            "logloss": 5.08608292690665,
            "mae": 0.4716011093343044,
            "precision": 0.751269035532995,
            "recall": 0.3002028397565923
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.6502453261306756,
            "auditor_fn_violation": 0.012593726709701391,
            "auditor_fp_violation": 0.007249664593243078,
            "ave_precision_score": 0.655517587633448,
            "fpr": 0.05159165751920966,
            "logloss": 5.105154860920304,
            "mae": 0.4480889517056753,
            "precision": 0.7638190954773869,
            "recall": 0.3297180043383948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7413559510660898,
            "auditor_fn_violation": 0.027443418383687426,
            "auditor_fp_violation": 0.0294351630867144,
            "ave_precision_score": 0.7363367283340604,
            "fpr": 0.10197368421052631,
            "logloss": 0.6282875667926107,
            "mae": 0.4158510443787172,
            "precision": 0.7584415584415585,
            "recall": 0.592292089249493
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7406541857499594,
            "auditor_fn_violation": 0.02418024101664163,
            "auditor_fp_violation": 0.02548115623856568,
            "ave_precision_score": 0.7362008694863108,
            "fpr": 0.10647639956092206,
            "logloss": 0.5890521266873902,
            "mae": 0.40074818751454744,
            "precision": 0.7413333333333333,
            "recall": 0.6030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8591854590663447,
            "auditor_fn_violation": 0.016160456923241168,
            "auditor_fp_violation": 0.0045508311351170295,
            "ave_precision_score": 0.8594868600802553,
            "fpr": 0.046052631578947366,
            "logloss": 0.669950357666257,
            "mae": 0.3284231732015558,
            "precision": 0.875,
            "recall": 0.5963488843813387
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8660603037874778,
            "auditor_fn_violation": 0.004028849611044579,
            "auditor_fp_violation": 0.005481156238565679,
            "ave_precision_score": 0.8662466929482664,
            "fpr": 0.042810098792535674,
            "logloss": 0.5884049611823446,
            "mae": 0.3056266991829609,
            "precision": 0.878125,
            "recall": 0.6095444685466378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5136993740101796,
            "auditor_fn_violation": 0.00970383616241415,
            "auditor_fp_violation": 0.013066302390821927,
            "ave_precision_score": 0.515353177434317,
            "fpr": 0.35964912280701755,
            "logloss": 0.7035038594883221,
            "mae": 0.5002232610591149,
            "precision": 0.5294117647058824,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5180720216526586,
            "auditor_fn_violation": 0.0133485407325744,
            "auditor_fp_violation": 0.009720697646054408,
            "ave_precision_score": 0.519610280506518,
            "fpr": 0.3545554335894621,
            "logloss": 0.6991818188854426,
            "mae": 0.49798407921675925,
            "precision": 0.5120845921450151,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8524940931193056,
            "auditor_fn_violation": 0.002515479876160997,
            "auditor_fp_violation": 0.007233178411422357,
            "ave_precision_score": 0.8528399792750035,
            "fpr": 0.15899122807017543,
            "logloss": 0.5147578294006777,
            "mae": 0.3205077607684424,
            "precision": 0.7415329768270945,
            "recall": 0.8438133874239351
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8485543542913101,
            "auditor_fn_violation": 0.0009881634684299671,
            "auditor_fp_violation": 0.01450420783022321,
            "ave_precision_score": 0.8486684119829028,
            "fpr": 0.15587266739846323,
            "logloss": 0.4986879953218016,
            "mae": 0.31544820371908916,
            "precision": 0.7365491651205937,
            "recall": 0.8611713665943601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6826165422840924,
            "auditor_fn_violation": 0.006643446852425187,
            "auditor_fp_violation": 0.01129464472637441,
            "ave_precision_score": 0.6831235840704273,
            "fpr": 0.08552631578947369,
            "logloss": 0.6795544905393172,
            "mae": 0.4740977558356367,
            "precision": 0.6904761904761905,
            "recall": 0.35294117647058826
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7013291504684155,
            "auditor_fn_violation": 0.0050289186634315305,
            "auditor_fp_violation": 0.008122941822173437,
            "ave_precision_score": 0.7017175295204696,
            "fpr": 0.08781558726673985,
            "logloss": 0.6517505176383559,
            "mae": 0.46075027181667766,
            "precision": 0.708029197080292,
            "recall": 0.420824295010846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 22571,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5006860663326136,
            "auditor_fn_violation": 0.010809223871036618,
            "auditor_fp_violation": 0.017117301009085963,
            "ave_precision_score": 0.502549393474388,
            "fpr": 0.4276315789473684,
            "logloss": 1.2906873361908868,
            "mae": 0.4968174432052203,
            "precision": 0.5506912442396313,
            "recall": 0.9695740365111561
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.4717844352074252,
            "auditor_fn_violation": 0.00992925702012758,
            "auditor_fp_violation": 0.013782168557141134,
            "ave_precision_score": 0.4737142112096179,
            "fpr": 0.4665203073545554,
            "logloss": 1.4320522633970396,
            "mae": 0.5105842991984475,
            "precision": 0.5120551090700345,
            "recall": 0.9674620390455532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6850795245348417,
            "auditor_fn_violation": 0.01920750151240171,
            "auditor_fp_violation": 0.002972825859397899,
            "ave_precision_score": 0.6244662563731751,
            "fpr": 0.01864035087719298,
            "logloss": 0.8423088755122577,
            "mae": 0.46931167506294225,
            "precision": 0.8229166666666666,
            "recall": 0.16024340770791076
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6730652007780633,
            "auditor_fn_violation": 0.01992280419362291,
            "auditor_fp_violation": 0.0055567752164898164,
            "ave_precision_score": 0.6012984702513167,
            "fpr": 0.020856201975850714,
            "logloss": 0.7957526386603031,
            "mae": 0.4525918622678054,
            "precision": 0.8272727272727273,
            "recall": 0.19739696312364424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.839602270541183,
            "auditor_fn_violation": 0.00466620404967796,
            "auditor_fp_violation": 0.011608675627015032,
            "ave_precision_score": 0.8424147946116735,
            "fpr": 0.0800438596491228,
            "logloss": 0.5156812928077701,
            "mae": 0.31580326691874416,
            "precision": 0.8298368298368298,
            "recall": 0.7221095334685599
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8379926148951714,
            "auditor_fn_violation": 0.0012810408337718595,
            "auditor_fp_violation": 0.008825466520307359,
            "ave_precision_score": 0.8311087409766272,
            "fpr": 0.0889132821075741,
            "logloss": 0.4862584411377442,
            "mae": 0.3065597741986276,
            "precision": 0.8048192771084337,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 22571,
        "test": {
            "accuracy": 0.43201754385964913,
            "auc_prc": 0.5961589549226216,
            "auditor_fn_violation": 0.011038308245258175,
            "auditor_fp_violation": 0.0147149646191852,
            "ave_precision_score": 0.532564730701311,
            "fpr": 0.21929824561403508,
            "logloss": 0.7928852918551444,
            "mae": 0.4818303585946029,
            "precision": 0.4666666666666667,
            "recall": 0.35496957403651114
        },
        "train": {
            "accuracy": 0.40504939626783754,
            "auc_prc": 0.5410163690900491,
            "auditor_fn_violation": 0.019003693112143474,
            "auditor_fp_violation": 0.009484083424807903,
            "ave_precision_score": 0.4798723346181211,
            "fpr": 0.25686059275521406,
            "logloss": 0.8279811881734764,
            "mae": 0.4963661936151618,
            "precision": 0.3953488372093023,
            "recall": 0.3318872017353579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6117653146820834,
            "auditor_fn_violation": 0.012277143162165048,
            "auditor_fp_violation": 0.021136896537285944,
            "ave_precision_score": 0.6107631549932702,
            "fpr": 0.14364035087719298,
            "logloss": 1.2611756355193113,
            "mae": 0.4570883399822372,
            "precision": 0.6410958904109589,
            "recall": 0.4746450304259635
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6098660968105549,
            "auditor_fn_violation": 0.0035264339680597073,
            "auditor_fp_violation": 0.015243322356384929,
            "ave_precision_score": 0.6083171949441927,
            "fpr": 0.141602634467618,
            "logloss": 1.1081169465817775,
            "mae": 0.4353470285632914,
            "precision": 0.6228070175438597,
            "recall": 0.46203904555314534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 0.6916556055611873,
            "mae": 0.49914267619973735,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 0.6931153106384017,
            "mae": 0.49987242008537935,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7323123874797903,
            "auditor_fn_violation": 0.001890502117362374,
            "auditor_fp_violation": 0.007285516894862458,
            "ave_precision_score": 0.7340982507200229,
            "fpr": 0.09429824561403509,
            "logloss": 0.5562733937489185,
            "mae": 0.3571673583304673,
            "precision": 0.8058690744920993,
            "recall": 0.7241379310344828
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7459129464079421,
            "auditor_fn_violation": 0.005102733283964854,
            "auditor_fp_violation": 0.00997682644224906,
            "ave_precision_score": 0.7454190261345963,
            "fpr": 0.09001097694840834,
            "logloss": 0.5330321049354944,
            "mae": 0.34668497930962744,
            "precision": 0.8028846153846154,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7938962652601637,
            "auditor_fn_violation": 0.0026177894025123704,
            "auditor_fp_violation": 0.01228645898756438,
            "ave_precision_score": 0.7778193340980725,
            "fpr": 0.09978070175438597,
            "logloss": 0.5559483260952107,
            "mae": 0.3729411344811843,
            "precision": 0.7973273942093542,
            "recall": 0.7261663286004056
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7872252067490589,
            "auditor_fn_violation": 0.005719442532936812,
            "auditor_fp_violation": 0.005920234174899376,
            "ave_precision_score": 0.7767318932270683,
            "fpr": 0.09549945115257959,
            "logloss": 0.5436807414971719,
            "mae": 0.36717453152432006,
            "precision": 0.7938388625592417,
            "recall": 0.7266811279826464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7482022161822457,
            "auditor_fn_violation": 0.019509981851179678,
            "auditor_fp_violation": 0.005691810074111305,
            "ave_precision_score": 0.6879422353677482,
            "fpr": 0.31798245614035087,
            "logloss": 0.6833232427064793,
            "mae": 0.44167778446551476,
            "precision": 0.5903954802259888,
            "recall": 0.847870182555781
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.67511443902378,
            "auditor_fn_violation": 0.00900776482185675,
            "auditor_fp_violation": 0.019429198682766203,
            "ave_precision_score": 0.6306500728590477,
            "fpr": 0.3589462129527991,
            "logloss": 0.7339171436045616,
            "mae": 0.4626148284364872,
            "precision": 0.5483425414364641,
            "recall": 0.8611713665943601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8486601743642573,
            "auditor_fn_violation": 0.01550211736237145,
            "auditor_fp_violation": 0.01051741824728887,
            "ave_precision_score": 0.8429691741440818,
            "fpr": 0.1074561403508772,
            "logloss": 0.5151533416049829,
            "mae": 0.31361243715142145,
            "precision": 0.789247311827957,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.846405355247658,
            "auditor_fn_violation": 0.019341811696521907,
            "auditor_fp_violation": 0.007208196121478231,
            "ave_precision_score": 0.8416745021347819,
            "fpr": 0.12184412733260154,
            "logloss": 0.48721595496222214,
            "mae": 0.3060716417107964,
            "precision": 0.7607758620689655,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 22571,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.5272406183271774,
            "auditor_fn_violation": 0.018331198178000784,
            "auditor_fp_violation": 0.01762760122262698,
            "ave_precision_score": 0.5972752873952858,
            "fpr": 0.30153508771929827,
            "logloss": 0.6767647898263237,
            "mae": 0.4804202546610644,
            "precision": 0.611032531824611,
            "recall": 0.8762677484787018
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.5247111845127319,
            "auditor_fn_violation": 0.014643868267094632,
            "auditor_fp_violation": 0.02082693011342847,
            "ave_precision_score": 0.5827119823040622,
            "fpr": 0.31394072447859495,
            "logloss": 0.6504338882292677,
            "mae": 0.4675117052936135,
            "precision": 0.5954738330975955,
            "recall": 0.913232104121475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 22571,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.46706902395727057,
            "auditor_fn_violation": 0.007935660652645813,
            "auditor_fp_violation": 0.01601819285684379,
            "ave_precision_score": 0.552198881003402,
            "fpr": 0.24780701754385964,
            "logloss": 0.6923271904302409,
            "mae": 0.4988269271949927,
            "precision": 0.5043859649122807,
            "recall": 0.4665314401622718
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.47057865970415347,
            "auditor_fn_violation": 0.009462558129013693,
            "auditor_fp_violation": 0.002663739480424452,
            "ave_precision_score": 0.5140054633659039,
            "fpr": 0.2502744237102086,
            "logloss": 0.693219732259467,
            "mae": 0.4993188673656937,
            "precision": 0.4709976798143852,
            "recall": 0.4403470715835141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8668816126225398,
            "auditor_fn_violation": 0.002642254724031177,
            "auditor_fp_violation": 0.00504542980362601,
            "ave_precision_score": 0.8672051322695158,
            "fpr": 0.1337719298245614,
            "logloss": 0.49225071566462614,
            "mae": 0.3057948366857314,
            "precision": 0.7685009487666035,
            "recall": 0.821501014198783
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8713872451693563,
            "auditor_fn_violation": 0.006845710775267817,
            "auditor_fp_violation": 0.012352725942188078,
            "ave_precision_score": 0.8715816550622164,
            "fpr": 0.12403951701427003,
            "logloss": 0.45716856991370824,
            "mae": 0.2912506478604514,
            "precision": 0.7749003984063745,
            "recall": 0.8438177874186551
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8231223866029553,
            "auditor_fn_violation": 0.00921897797231416,
            "auditor_fp_violation": 0.0033862998785747197,
            "ave_precision_score": 0.7137425052739589,
            "fpr": 0.08442982456140351,
            "logloss": 0.5859270184731873,
            "mae": 0.37138971258281617,
            "precision": 0.8065326633165829,
            "recall": 0.6511156186612576
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7951858814154348,
            "auditor_fn_violation": 0.006359962949822728,
            "auditor_fp_violation": 0.005649469447493597,
            "ave_precision_score": 0.6750555278770182,
            "fpr": 0.0845225027442371,
            "logloss": 0.6000216855615544,
            "mae": 0.3785566325114404,
            "precision": 0.7843137254901961,
            "recall": 0.6073752711496746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6997835567095808,
            "auditor_fn_violation": 0.012263798441336606,
            "auditor_fp_violation": 0.011477829418414779,
            "ave_precision_score": 0.7005353538624142,
            "fpr": 0.18969298245614036,
            "logloss": 0.9759401949894488,
            "mae": 0.41982057815983714,
            "precision": 0.6490872210953347,
            "recall": 0.6490872210953347
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7141785179918203,
            "auditor_fn_violation": 0.009710194275319018,
            "auditor_fp_violation": 0.004193194291986831,
            "ave_precision_score": 0.7146499057420909,
            "fpr": 0.20087815587266739,
            "logloss": 1.0363471045268169,
            "mae": 0.41857169798537913,
            "precision": 0.6354581673306773,
            "recall": 0.6919739696312365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7847182284102652,
            "auditor_fn_violation": 0.004087932813778868,
            "auditor_fp_violation": 0.009214190009630288,
            "ave_precision_score": 0.8425010294065441,
            "fpr": 0.13596491228070176,
            "logloss": 0.5217513892770119,
            "mae": 0.31805666081051814,
            "precision": 0.7573385518590998,
            "recall": 0.7849898580121704
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8348337691637688,
            "auditor_fn_violation": 0.003509766150519918,
            "auditor_fp_violation": 0.011525795828759611,
            "ave_precision_score": 0.8284332147000086,
            "fpr": 0.14818880351262348,
            "logloss": 0.527108804222018,
            "mae": 0.3225682228967204,
            "precision": 0.725050916496945,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8593504230288946,
            "auditor_fn_violation": 0.011665510124194875,
            "auditor_fp_violation": 0.008884457563957629,
            "ave_precision_score": 0.8393903689669061,
            "fpr": 0.08662280701754387,
            "logloss": 0.5232837036041877,
            "mae": 0.31965362496690397,
            "precision": 0.8162790697674419,
            "recall": 0.7119675456389453
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8481773266773318,
            "auditor_fn_violation": 0.004347919261091838,
            "auditor_fp_violation": 0.010311013538236373,
            "ave_precision_score": 0.8242070448920888,
            "fpr": 0.09549945115257959,
            "logloss": 0.4894680382432679,
            "mae": 0.31118039435959544,
            "precision": 0.7918660287081339,
            "recall": 0.7180043383947939
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6469076034256211,
            "auditor_fn_violation": 0.017216913988826046,
            "auditor_fp_violation": 0.006272767240296448,
            "ave_precision_score": 0.6483700642819374,
            "fpr": 0.08552631578947369,
            "logloss": 0.6825900024076692,
            "mae": 0.47710380608444675,
            "precision": 0.6666666666666666,
            "recall": 0.31643002028397565
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6698410847601965,
            "auditor_fn_violation": 0.024496929549897503,
            "auditor_fp_violation": 0.007815587266739846,
            "ave_precision_score": 0.6707760192450636,
            "fpr": 0.08562019758507135,
            "logloss": 0.652663512168288,
            "mae": 0.46253863062083916,
            "precision": 0.6842105263157895,
            "recall": 0.3665943600867679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.4558071986192884,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4661036514750011,
            "fpr": 0.4594298245614035,
            "logloss": 0.6893933146907641,
            "mae": 0.4975744773421371,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.41863314594668743,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.42824058582078556,
            "fpr": 0.49396267837541163,
            "logloss": 0.6926320148781618,
            "mae": 0.49918297224327446,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.794413662298812,
            "auditor_fn_violation": 0.01628723177111135,
            "auditor_fp_violation": 0.024028597747351676,
            "ave_precision_score": 0.7347323005197225,
            "fpr": 0.16557017543859648,
            "logloss": 5.935009450566887,
            "mae": 0.28711149620155907,
            "precision": 0.7182835820895522,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7841543695212069,
            "auditor_fn_violation": 0.013003278797821758,
            "auditor_fp_violation": 0.03193072325893402,
            "ave_precision_score": 0.718090304539989,
            "fpr": 0.1756311745334797,
            "logloss": 5.564352443454192,
            "mae": 0.28135905265161576,
            "precision": 0.6952380952380952,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8497857244145213,
            "auditor_fn_violation": 0.012884327959859084,
            "auditor_fp_violation": 0.01054882133735293,
            "ave_precision_score": 0.85005243216259,
            "fpr": 0.09539473684210527,
            "logloss": 0.5094819720963293,
            "mae": 0.32523946398705766,
            "precision": 0.8079470198675497,
            "recall": 0.742393509127789
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8461992523007071,
            "auditor_fn_violation": 0.012231796957408964,
            "auditor_fp_violation": 0.007927796072691791,
            "ave_precision_score": 0.8464365332349729,
            "fpr": 0.08781558726673985,
            "logloss": 0.4847401029763528,
            "mae": 0.31468152885379436,
            "precision": 0.8095238095238095,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8043570157122976,
            "auditor_fn_violation": 0.03205624355005161,
            "auditor_fp_violation": 0.024784888833061177,
            "ave_precision_score": 0.8044152631626256,
            "fpr": 0.11074561403508772,
            "logloss": 2.2382755044967926,
            "mae": 0.29714292501394207,
            "precision": 0.7750556792873051,
            "recall": 0.7058823529411765
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8049383723835806,
            "auditor_fn_violation": 0.03503575246862283,
            "auditor_fp_violation": 0.020526893523600445,
            "ave_precision_score": 0.8047954128301205,
            "fpr": 0.11525795828759605,
            "logloss": 2.108352057457126,
            "mae": 0.2753557758497643,
            "precision": 0.7676991150442478,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7735946985267658,
            "auditor_fn_violation": 0.013629408206113674,
            "auditor_fp_violation": 0.018287066113972284,
            "ave_precision_score": 0.7280735462648892,
            "fpr": 0.13925438596491227,
            "logloss": 2.897338086556342,
            "mae": 0.3218458454924219,
            "precision": 0.7268817204301076,
            "recall": 0.6855983772819473
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7634052344752711,
            "auditor_fn_violation": 0.009474463712970664,
            "auditor_fp_violation": 0.020504939626783757,
            "ave_precision_score": 0.7095022050161508,
            "fpr": 0.14928649835345773,
            "logloss": 3.0986451721307837,
            "mae": 0.3118645714025466,
            "precision": 0.7094017094017094,
            "recall": 0.720173535791757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8090717791475611,
            "auditor_fn_violation": 0.029434005907263087,
            "auditor_fp_violation": 0.019019804882133735,
            "ave_precision_score": 0.8011713862287694,
            "fpr": 0.14144736842105263,
            "logloss": 0.5604118360857777,
            "mae": 0.3646256260230745,
            "precision": 0.736734693877551,
            "recall": 0.7322515212981744
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.778309803562451,
            "auditor_fn_violation": 0.026699462581940187,
            "auditor_fp_violation": 0.02419319429198683,
            "ave_precision_score": 0.7758441620480457,
            "fpr": 0.13611416026344675,
            "logloss": 0.5509204521663228,
            "mae": 0.3643490840915006,
            "precision": 0.7333333333333333,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.53851678750557,
            "auditor_fn_violation": 0.012094765310843032,
            "auditor_fp_violation": 0.01136006783067454,
            "ave_precision_score": 0.6813729711592625,
            "fpr": 0.06030701754385965,
            "logloss": 0.6243261908356957,
            "mae": 0.41248702672882037,
            "precision": 0.8148148148148148,
            "recall": 0.4908722109533469
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.5291181199593467,
            "auditor_fn_violation": 0.01050786840043717,
            "auditor_fp_violation": 0.011306256860592754,
            "ave_precision_score": 0.6673268692936262,
            "fpr": 0.06037321624588365,
            "logloss": 0.6089260637809972,
            "mae": 0.40651688984013545,
            "precision": 0.8049645390070922,
            "recall": 0.4924078091106291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6550201530234933,
            "auditor_fn_violation": 0.0051466139995017994,
            "auditor_fp_violation": 0.006607733534313114,
            "ave_precision_score": 0.6560787491762985,
            "fpr": 0.17105263157894737,
            "logloss": 0.6573547146570504,
            "mae": 0.4602235918374438,
            "precision": 0.6525612472160356,
            "recall": 0.5943204868154158
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6379732041792607,
            "auditor_fn_violation": 0.008493443594914886,
            "auditor_fp_violation": 0.015170142700329308,
            "ave_precision_score": 0.6399913787786238,
            "fpr": 0.20087815587266739,
            "logloss": 0.6634775068408937,
            "mae": 0.4622924149886968,
            "precision": 0.6030368763557483,
            "recall": 0.6030368763557483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.739763324984718,
            "auditor_fn_violation": 0.007746610440909577,
            "auditor_fp_violation": 0.0174339488338986,
            "ave_precision_score": 0.7408513237924884,
            "fpr": 0.2817982456140351,
            "logloss": 0.9277232490626125,
            "mae": 0.3511732246312702,
            "precision": 0.6253644314868805,
            "recall": 0.8701825557809331
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7398280815767286,
            "auditor_fn_violation": 0.009712575392110408,
            "auditor_fp_violation": 0.009937797292352736,
            "ave_precision_score": 0.7412501201612802,
            "fpr": 0.270032930845225,
            "logloss": 0.8198621437373685,
            "mae": 0.3356691939434588,
            "precision": 0.6261398176291794,
            "recall": 0.8937093275488069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7573626666472562,
            "auditor_fn_violation": 0.008600672573929755,
            "auditor_fp_violation": 0.0031717120964703024,
            "ave_precision_score": 0.5354656984060743,
            "fpr": 0.44846491228070173,
            "logloss": 0.6982536649731512,
            "mae": 0.5014680208344209,
            "precision": 0.5352272727272728,
            "recall": 0.9553752535496958
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.7282972193181264,
            "auditor_fn_violation": 0.007641003783594584,
            "auditor_fp_violation": 0.0030198804732284473,
            "ave_precision_score": 0.49296215499499324,
            "fpr": 0.48518111964873767,
            "logloss": 0.7049906707080511,
            "mae": 0.5044932372287391,
            "precision": 0.49195402298850577,
            "recall": 0.928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 22571,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7533533971835975,
            "auditor_fn_violation": 0.011532062915910477,
            "auditor_fp_violation": 0.0031769459448143028,
            "ave_precision_score": 0.754660046275313,
            "fpr": 0.04824561403508772,
            "logloss": 1.284173974011977,
            "mae": 0.4339364813388289,
            "precision": 0.7659574468085106,
            "recall": 0.2920892494929006
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7022351724592748,
            "auditor_fn_violation": 0.007567189163061268,
            "auditor_fp_violation": 0.007725332357604588,
            "ave_precision_score": 0.7041246111829367,
            "fpr": 0.05159165751920966,
            "logloss": 1.214878604236074,
            "mae": 0.42405450366787323,
            "precision": 0.7202380952380952,
            "recall": 0.26247288503253796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.7152621142895869,
            "auditor_fn_violation": 0.005529162663250431,
            "auditor_fp_violation": 0.007343089226646571,
            "ave_precision_score": 0.7178690034357628,
            "fpr": 0.051535087719298246,
            "logloss": 1.6169596323270816,
            "mae": 0.42619779752497206,
            "precision": 0.8104838709677419,
            "recall": 0.4077079107505071
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.664494811843578,
            "auditor_fn_violation": 0.01408430582111624,
            "auditor_fp_violation": 0.006820343944383462,
            "ave_precision_score": 0.6701747717286978,
            "fpr": 0.052689352360043906,
            "logloss": 1.5466773168135328,
            "mae": 0.42108361753268997,
            "precision": 0.7837837837837838,
            "recall": 0.3774403470715835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7467686109117757,
            "auditor_fn_violation": 0.0095325789117825,
            "auditor_fp_violation": 0.026082883222375768,
            "ave_precision_score": 0.6565306594353517,
            "fpr": 0.2642543859649123,
            "logloss": 5.724952134607175,
            "mae": 0.34887825784361726,
            "precision": 0.6491994177583698,
            "recall": 0.9046653144016227
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7472276432115129,
            "auditor_fn_violation": 0.006140900205014158,
            "auditor_fp_violation": 0.026837419197463113,
            "ave_precision_score": 0.6560165632394471,
            "fpr": 0.2722283205268935,
            "logloss": 5.481895919152279,
            "mae": 0.3403204364989319,
            "precision": 0.6325925925925926,
            "recall": 0.9262472885032538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 22571,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6022647406595041,
            "auditor_fn_violation": 0.0045349809615316235,
            "auditor_fp_violation": 0.00016224929866432284,
            "ave_precision_score": 0.5485733684663439,
            "fpr": 0.03728070175438596,
            "logloss": 0.6955432089165814,
            "mae": 0.49763742742831246,
            "precision": 0.6136363636363636,
            "recall": 0.10953346855983773
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6125510295259735,
            "auditor_fn_violation": 0.0053503694302701865,
            "auditor_fp_violation": 0.009703622392974754,
            "ave_precision_score": 0.525752818271036,
            "fpr": 0.036223929747530186,
            "logloss": 0.6884638933179659,
            "mae": 0.49392579533527764,
            "precision": 0.6526315789473685,
            "recall": 0.13449023861171366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7819708150955482,
            "auditor_fn_violation": 0.001058681185722928,
            "auditor_fp_violation": 0.00416614328183229,
            "ave_precision_score": 0.5842487070448265,
            "fpr": 0.44846491228070173,
            "logloss": 0.6823015844651986,
            "mae": 0.4917730418475051,
            "precision": 0.5455555555555556,
            "recall": 0.9959432048681541
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.7668817204953629,
            "auditor_fn_violation": 0.0015715370823223508,
            "auditor_fp_violation": 0.0001390413465056683,
            "ave_precision_score": 0.5533577192027948,
            "fpr": 0.4862788144895719,
            "logloss": 0.6888627416992043,
            "mae": 0.4950582678833594,
            "precision": 0.5083240843507214,
            "recall": 0.9934924078091106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8299939915498477,
            "auditor_fn_violation": 0.001890502117362374,
            "auditor_fp_violation": 0.011909621906795634,
            "ave_precision_score": 0.819713560360886,
            "fpr": 0.09320175438596491,
            "logloss": 0.7854504160999232,
            "mae": 0.30213633559174413,
            "precision": 0.8076923076923077,
            "recall": 0.7241379310344828
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8406816269960569,
            "auditor_fn_violation": 0.007340983067878499,
            "auditor_fp_violation": 0.0075082327113062605,
            "ave_precision_score": 0.8281894349998986,
            "fpr": 0.0889132821075741,
            "logloss": 0.657033755160864,
            "mae": 0.27911244978614275,
            "precision": 0.8057553956834532,
            "recall": 0.7288503253796096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8546450384824029,
            "auditor_fn_violation": 0.008333778157360956,
            "auditor_fp_violation": 0.007089247581962067,
            "ave_precision_score": 0.826184275468492,
            "fpr": 0.10307017543859649,
            "logloss": 0.5178729958466741,
            "mae": 0.3151240392931198,
            "precision": 0.7952069716775599,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8606466427720074,
            "auditor_fn_violation": 0.008300573134811693,
            "auditor_fp_violation": 0.0027320404927430185,
            "ave_precision_score": 0.8337389609559359,
            "fpr": 0.10428100987925357,
            "logloss": 0.48220401997990203,
            "mae": 0.3041470266559645,
            "precision": 0.782608695652174,
            "recall": 0.7418655097613883
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7872268311185776,
            "auditor_fn_violation": 0.009537027152058645,
            "auditor_fp_violation": 0.010294979692668432,
            "ave_precision_score": 0.6540336030849729,
            "fpr": 0.19956140350877194,
            "logloss": 0.6400734814396838,
            "mae": 0.41471328949065583,
            "precision": 0.6773049645390071,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.763713677245518,
            "auditor_fn_violation": 0.0054027539996809315,
            "auditor_fp_violation": 0.001122088059519456,
            "ave_precision_score": 0.6135228283760855,
            "fpr": 0.2261251372118551,
            "logloss": 0.668056862533728,
            "mae": 0.4257243432178194,
            "precision": 0.6373239436619719,
            "recall": 0.7852494577006508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8001616186968643,
            "auditor_fn_violation": 0.021331536244261776,
            "auditor_fp_violation": 0.03081428212536115,
            "ave_precision_score": 0.7909664881786023,
            "fpr": 0.13706140350877194,
            "logloss": 2.792745208246591,
            "mae": 0.2871074562778999,
            "precision": 0.7422680412371134,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7717184973700321,
            "auditor_fn_violation": 0.02643277750130367,
            "auditor_fp_violation": 0.025232345407976583,
            "ave_precision_score": 0.7539360643278366,
            "fpr": 0.12952799121844127,
            "logloss": 3.1281298377346216,
            "mae": 0.2730326017835588,
            "precision": 0.7456896551724138,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8187662555212606,
            "auditor_fn_violation": 0.05236690865093769,
            "auditor_fp_violation": 0.06777048528241846,
            "ave_precision_score": 0.8189111634956483,
            "fpr": 0.24890350877192982,
            "logloss": 1.0564162911989623,
            "mae": 0.36320026995661336,
            "precision": 0.6391096979332274,
            "recall": 0.8154158215010142
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7980976343126156,
            "auditor_fn_violation": 0.047667577046986584,
            "auditor_fp_violation": 0.07671667276497135,
            "ave_precision_score": 0.798388607914067,
            "fpr": 0.27442371020856204,
            "logloss": 1.0341868076883234,
            "mae": 0.3656592397777199,
            "precision": 0.6062992125984252,
            "recall": 0.8351409978308026
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6943308183319431,
            "auditor_fn_violation": 0.0025599622789224583,
            "auditor_fp_violation": 0.012603106812377024,
            "ave_precision_score": 0.6953717643538857,
            "fpr": 0.40899122807017546,
            "logloss": 1.2333395052315272,
            "mae": 0.421041687328589,
            "precision": 0.5662790697674419,
            "recall": 0.9878296146044625
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6725165329670015,
            "auditor_fn_violation": 0.0008476775777375104,
            "auditor_fp_violation": 0.008588852299060888,
            "ave_precision_score": 0.6733815183020724,
            "fpr": 0.446761800219539,
            "logloss": 1.344201609786691,
            "mae": 0.4526794669243919,
            "precision": 0.5278422273781903,
            "recall": 0.9869848156182213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7271571776083726,
            "auditor_fn_violation": 0.001890502117362374,
            "auditor_fp_violation": 0.007285516894862458,
            "ave_precision_score": 0.7410211458212982,
            "fpr": 0.09429824561403509,
            "logloss": 0.5530843362374441,
            "mae": 0.3616721272926059,
            "precision": 0.8058690744920993,
            "recall": 0.7241379310344828
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.7435160488149644,
            "auditor_fn_violation": 0.005102733283964854,
            "auditor_fp_violation": 0.00997682644224906,
            "ave_precision_score": 0.7362229759550045,
            "fpr": 0.09001097694840834,
            "logloss": 0.5343999910865317,
            "mae": 0.3536452587068277,
            "precision": 0.8028846153846154,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8259414205206236,
            "auditor_fn_violation": 0.026435891961140177,
            "auditor_fp_violation": 0.016575597705480886,
            "ave_precision_score": 0.8423886211449152,
            "fpr": 0.12390350877192982,
            "logloss": 0.5248967311884416,
            "mae": 0.33425994107720297,
            "precision": 0.7753479125248509,
            "recall": 0.7910750507099391
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8382999072921317,
            "auditor_fn_violation": 0.02109431365499047,
            "auditor_fp_violation": 0.029027930235394576,
            "ave_precision_score": 0.8268773666957115,
            "fpr": 0.14270032930845225,
            "logloss": 0.5344790623961221,
            "mae": 0.33936695729992655,
            "precision": 0.7263157894736842,
            "recall": 0.7483731019522777
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8347860673063222,
            "auditor_fn_violation": 0.014979449129924204,
            "auditor_fp_violation": 0.00968523636059122,
            "ave_precision_score": 0.8350729339271555,
            "fpr": 0.11513157894736842,
            "logloss": 0.5448718806851859,
            "mae": 0.33396299700436766,
            "precision": 0.78125,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8116160564750359,
            "auditor_fn_violation": 0.003083546244859767,
            "auditor_fp_violation": 0.005025003049152341,
            "ave_precision_score": 0.8120883362816899,
            "fpr": 0.12623490669593854,
            "logloss": 0.5052918519589706,
            "mae": 0.3256715904887685,
            "precision": 0.7526881720430108,
            "recall": 0.7592190889370932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.7314435727395345,
            "auditor_fn_violation": 0.00431034482758621,
            "auditor_fp_violation": 0.016449985345224634,
            "ave_precision_score": 0.6109495710678292,
            "fpr": 0.16228070175438597,
            "logloss": 0.6719800763736334,
            "mae": 0.48063230053766776,
            "precision": 0.6581986143187067,
            "recall": 0.5780933062880325
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.717459234524895,
            "auditor_fn_violation": 0.011438885065873598,
            "auditor_fp_violation": 0.006483717526527627,
            "ave_precision_score": 0.5831047297964094,
            "fpr": 0.18880351262349068,
            "logloss": 0.6658939929306421,
            "mae": 0.47724823681504747,
            "precision": 0.621978021978022,
            "recall": 0.613882863340564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6961128647154275,
            "auditor_fn_violation": 0.011002722323049005,
            "auditor_fp_violation": 0.015377046434702512,
            "ave_precision_score": 0.6660943908943381,
            "fpr": 0.1600877192982456,
            "logloss": 0.6300306967955169,
            "mae": 0.4292450934125666,
            "precision": 0.7142857142857143,
            "recall": 0.7403651115618661
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.5869163162725507,
            "auditor_fn_violation": 0.0069861966659602705,
            "auditor_fp_violation": 0.023688254665203082,
            "ave_precision_score": 0.6391452061367131,
            "fpr": 0.16355653128430298,
            "logloss": 0.6197026037489409,
            "mae": 0.42725191935978657,
            "precision": 0.6989898989898989,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6902627067141878,
            "auditor_fn_violation": 0.04487607202590656,
            "auditor_fp_violation": 0.06658501863250012,
            "ave_precision_score": 0.6912338939221436,
            "fpr": 0.24890350877192982,
            "logloss": 0.6618437777219016,
            "mae": 0.4425602365222063,
            "precision": 0.6092943201376936,
            "recall": 0.718052738336714
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6490284106042192,
            "auditor_fn_violation": 0.04511025761302566,
            "auditor_fp_violation": 0.05980973289425542,
            "ave_precision_score": 0.650093500632448,
            "fpr": 0.28869374313940727,
            "logloss": 0.6769289972390109,
            "mae": 0.45810340721585824,
            "precision": 0.562396006655574,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6439055461924452,
            "auditor_fn_violation": 0.03248327461656169,
            "auditor_fp_violation": 0.030746242096889007,
            "ave_precision_score": 0.6405323522418609,
            "fpr": 0.14583333333333334,
            "logloss": 0.676614238934296,
            "mae": 0.4584119831244543,
            "precision": 0.6580976863753213,
            "recall": 0.5192697768762677
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6069665991927838,
            "auditor_fn_violation": 0.03476192403761213,
            "auditor_fp_violation": 0.025042078302231985,
            "ave_precision_score": 0.612434986898064,
            "fpr": 0.1394072447859495,
            "logloss": 0.6860913565784463,
            "mae": 0.4646414492962193,
            "precision": 0.6586021505376344,
            "recall": 0.5314533622559653
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.6320580027721993,
            "auditor_fn_violation": 0.00082959681150137,
            "auditor_fp_violation": 0.00211185780680819,
            "ave_precision_score": 0.6426954980520565,
            "fpr": 0.4517543859649123,
            "logloss": 0.8324635253494929,
            "mae": 0.4469795649903908,
            "precision": 0.5391498881431768,
            "recall": 0.9776876267748479
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.5756405549262565,
            "auditor_fn_violation": 0.0015334392136599911,
            "auditor_fp_violation": 0.0011562385656787486,
            "ave_precision_score": 0.5895542022464221,
            "fpr": 0.4807903402854007,
            "logloss": 0.8877776175802689,
            "mae": 0.4631584445024819,
            "precision": 0.509518477043673,
            "recall": 0.9869848156182213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8446795452719169,
            "auditor_fn_violation": 0.04629283655385931,
            "auditor_fp_violation": 0.010818364527069465,
            "ave_precision_score": 0.8448996561708444,
            "fpr": 0.03179824561403509,
            "logloss": 0.800251244130542,
            "mae": 0.3480545027087638,
            "precision": 0.8937728937728938,
            "recall": 0.4949290060851927
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8298142421536586,
            "auditor_fn_violation": 0.04536741822649659,
            "auditor_fp_violation": 0.015216489815831203,
            "ave_precision_score": 0.8306022198381223,
            "fpr": 0.048298572996706916,
            "logloss": 0.7003466860858745,
            "mae": 0.3232032902302086,
            "precision": 0.8547854785478548,
            "recall": 0.561822125813449
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7702850877192983,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405701754385965,
            "fpr": 0.4594298245614035,
            "logloss": 15.868511338586435,
            "mae": 0.4594298245614035,
            "precision": 0.5405701754385965,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7530186608122942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5060373216245884,
            "fpr": 0.49396267837541163,
            "logloss": 17.061261467127764,
            "mae": 0.49396267837541163,
            "precision": 0.5060373216245884,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7497001234919561,
            "auditor_fn_violation": 0.03358421408490801,
            "auditor_fp_violation": 0.027776033161663105,
            "ave_precision_score": 0.7465499063383371,
            "fpr": 0.15460526315789475,
            "logloss": 0.6159793421508954,
            "mae": 0.41039084817952753,
            "precision": 0.6914660831509847,
            "recall": 0.640973630831643
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7634679000659672,
            "auditor_fn_violation": 0.026392298515849906,
            "auditor_fp_violation": 0.02167093547993658,
            "ave_precision_score": 0.7591754855284348,
            "fpr": 0.14928649835345773,
            "logloss": 0.5725934810242168,
            "mae": 0.3893442284131809,
            "precision": 0.7136842105263158,
            "recall": 0.735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.5330145255362138,
            "auditor_fn_violation": 0.08837763780648375,
            "auditor_fp_violation": 0.04262969476196458,
            "ave_precision_score": 0.5261341349142818,
            "fpr": 0.1425438596491228,
            "logloss": 2.1796954787138296,
            "mae": 0.5405143980091803,
            "precision": 0.5,
            "recall": 0.26369168356997974
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.5050851779047336,
            "auditor_fn_violation": 0.07220260446554642,
            "auditor_fp_violation": 0.05233809001097695,
            "ave_precision_score": 0.494150639980536,
            "fpr": 0.13830954994511527,
            "logloss": 2.08861325390817,
            "mae": 0.5157060959306367,
            "precision": 0.4661016949152542,
            "recall": 0.2386117136659436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.5370123895823393,
            "auditor_fn_violation": 0.004886391943347225,
            "auditor_fp_violation": 0.009224657706318301,
            "ave_precision_score": 0.5390839896525901,
            "fpr": 0.05482456140350877,
            "logloss": 0.6950468243232655,
            "mae": 0.5007214805666815,
            "precision": 0.5238095238095238,
            "recall": 0.11156186612576065
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5205834378037757,
            "auditor_fn_violation": 0.004278866874141312,
            "auditor_fp_violation": 0.005927552140504943,
            "ave_precision_score": 0.5209089183434685,
            "fpr": 0.04939626783754116,
            "logloss": 0.6921706287979009,
            "mae": 0.49897054227071064,
            "precision": 0.5360824742268041,
            "recall": 0.11279826464208242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.7643012887514368,
            "auditor_fn_violation": 0.04605263157894737,
            "auditor_fp_violation": 0.021393355106142445,
            "ave_precision_score": 0.7389319282311828,
            "fpr": 0.1074561403508772,
            "logloss": 0.6046061153998691,
            "mae": 0.4029497781752102,
            "precision": 0.7270194986072424,
            "recall": 0.5294117647058824
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7542973494501775,
            "auditor_fn_violation": 0.04109331358593808,
            "auditor_fp_violation": 0.025422612513721184,
            "ave_precision_score": 0.716986773333337,
            "fpr": 0.1163556531284303,
            "logloss": 0.5887932228611097,
            "mae": 0.39329858839871723,
            "precision": 0.7150537634408602,
            "recall": 0.5770065075921909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7057700447154434,
            "auditor_fn_violation": 0.12490658695420091,
            "auditor_fp_violation": 0.11174266214462171,
            "ave_precision_score": 0.5811715672890424,
            "fpr": 0.19188596491228072,
            "logloss": 0.6836917969816572,
            "mae": 0.49249240429255,
            "precision": 0.6128318584070797,
            "recall": 0.5618661257606491
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6924035007774346,
            "auditor_fn_violation": 0.11840103245224075,
            "auditor_fp_violation": 0.1176728869374314,
            "ave_precision_score": 0.5566481078455416,
            "fpr": 0.19978046103183314,
            "logloss": 0.6804905912509535,
            "mae": 0.49089768901876246,
            "precision": 0.59375,
            "recall": 0.5770065075921909
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4649122807017544,
            "auc_prc": 0.630210223058833,
            "auditor_fn_violation": 0.007739938080495376,
            "auditor_fp_violation": 0.02146139513461458,
            "ave_precision_score": 0.6248816769337617,
            "fpr": 0.12171052631578948,
            "logloss": 0.7229838309618615,
            "mae": 0.4592347149614637,
            "precision": 0.5110132158590308,
            "recall": 0.23529411764705882
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.6350009442020892,
            "auditor_fn_violation": 0.011693664562553127,
            "auditor_fp_violation": 0.026047078912062455,
            "ave_precision_score": 0.611068185333616,
            "fpr": 0.13391877058177826,
            "logloss": 0.6754171782031251,
            "mae": 0.44091310539373846,
            "precision": 0.5158730158730159,
            "recall": 0.28199566160520606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.8530884503946589,
            "auditor_fn_violation": 0.001040888224618341,
            "auditor_fp_violation": 0.002436356404136834,
            "ave_precision_score": 0.8534160422352068,
            "fpr": 0.006578947368421052,
            "logloss": 0.9941348200227531,
            "mae": 0.42172562145551956,
            "precision": 0.9423076923076923,
            "recall": 0.19878296146044624
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.8627000443200638,
            "auditor_fn_violation": 0.003462143814691971,
            "auditor_fp_violation": 0.002914989632882059,
            "ave_precision_score": 0.862896613021408,
            "fpr": 0.005488474204171241,
            "logloss": 0.8890391792045581,
            "mae": 0.38482279728000507,
            "precision": 0.9565217391304348,
            "recall": 0.2386117136659436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7606996605107152,
            "auditor_fn_violation": 0.026088929219600727,
            "auditor_fp_violation": 0.030377255788636266,
            "ave_precision_score": 0.7424628688915819,
            "fpr": 0.1524122807017544,
            "logloss": 0.6019872959726769,
            "mae": 0.39106276364212755,
            "precision": 0.7055084745762712,
            "recall": 0.6754563894523327
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.741676756423908,
            "auditor_fn_violation": 0.022749189825011736,
            "auditor_fp_violation": 0.02689108427857056,
            "ave_precision_score": 0.7206781884432413,
            "fpr": 0.150384193194292,
            "logloss": 0.582885198457126,
            "mae": 0.38290713693942513,
            "precision": 0.702819956616052,
            "recall": 0.702819956616052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7998241308292046,
            "auditor_fn_violation": 0.00010230952635137768,
            "auditor_fp_violation": 0.01407120127287192,
            "ave_precision_score": 0.7531389270697331,
            "fpr": 0.14583333333333334,
            "logloss": 0.567681110462927,
            "mae": 0.34650446142870606,
            "precision": 0.7481060606060606,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7955932714385872,
            "auditor_fn_violation": 0.0031906965004726536,
            "auditor_fp_violation": 0.007866813025978782,
            "ave_precision_score": 0.743219387081249,
            "fpr": 0.13721185510428102,
            "logloss": 0.5609203624589443,
            "mae": 0.34996414531337183,
            "precision": 0.7395833333333334,
            "recall": 0.7700650759219089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7431889121572277,
            "auditor_fn_violation": 0.0007739938080495445,
            "auditor_fp_violation": 0.015568081899258892,
            "ave_precision_score": 0.7436712963103866,
            "fpr": 0.13048245614035087,
            "logloss": 2.9937674589403995,
            "mae": 0.40328485240975726,
            "precision": 0.7090464547677262,
            "recall": 0.5882352941176471
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6787124460224336,
            "auditor_fn_violation": 0.013731900535989399,
            "auditor_fp_violation": 0.017387486278814493,
            "ave_precision_score": 0.6792791347718818,
            "fpr": 0.13830954994511527,
            "logloss": 2.5902846376858,
            "mae": 0.40364095841617514,
            "precision": 0.6735751295336787,
            "recall": 0.5639913232104121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.4201701749060255,
            "auditor_fn_violation": 0.0009941817017188126,
            "auditor_fp_violation": 0.0022139178495163927,
            "ave_precision_score": 0.5394732516982041,
            "fpr": 0.005482456140350877,
            "logloss": 18.29060894442189,
            "mae": 0.5455688662179071,
            "precision": 0.4444444444444444,
            "recall": 0.008113590263691683
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.5097960619367187,
            "auditor_fn_violation": 0.0009881634684299684,
            "auditor_fp_violation": 0.000592755214050494,
            "ave_precision_score": 0.5130561947271346,
            "fpr": 0.0010976948408342481,
            "logloss": 16.92973072655228,
            "mae": 0.5025391590942012,
            "precision": 0.875,
            "recall": 0.015184381778741865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.719854765208534,
            "auditor_fn_violation": 0.012830949076545327,
            "auditor_fp_violation": 0.019464681991374622,
            "ave_precision_score": 0.6750578899018309,
            "fpr": 0.1600877192982456,
            "logloss": 0.6270629455543318,
            "mae": 0.429639607667923,
            "precision": 0.7038539553752535,
            "recall": 0.7038539553752535
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6881244662122459,
            "auditor_fn_violation": 0.011967492993563847,
            "auditor_fp_violation": 0.0261007439931699,
            "ave_precision_score": 0.6481477820264305,
            "fpr": 0.1756311745334797,
            "logloss": 0.6227599115363845,
            "mae": 0.4273735607363913,
            "precision": 0.6761133603238867,
            "recall": 0.7245119305856833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8537582289197418,
            "auditor_fn_violation": 0.014387833173196689,
            "auditor_fp_violation": 0.014874596993677514,
            "ave_precision_score": 0.8550896838489359,
            "fpr": 0.11951754385964912,
            "logloss": 0.5013002389570544,
            "mae": 0.31833096704315067,
            "precision": 0.7780040733197556,
            "recall": 0.7748478701825557
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8608580298821085,
            "auditor_fn_violation": 0.022077714889837632,
            "auditor_fp_violation": 0.01659714599341383,
            "ave_precision_score": 0.8612075215261189,
            "fpr": 0.11855104281009879,
            "logloss": 0.4731260751178995,
            "mae": 0.30656581733510735,
            "precision": 0.7726315789473684,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7036278933515983,
            "auditor_fn_violation": 0.04436674851428775,
            "auditor_fp_violation": 0.03632814135577608,
            "ave_precision_score": 0.6880899963925721,
            "fpr": 0.11293859649122807,
            "logloss": 0.6484484536652232,
            "mae": 0.4537692261500317,
            "precision": 0.7154696132596685,
            "recall": 0.5253549695740365
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7085000633640026,
            "auditor_fn_violation": 0.04836762538365745,
            "auditor_fp_violation": 0.03175509208440054,
            "ave_precision_score": 0.6908173981883373,
            "fpr": 0.11086717892425905,
            "logloss": 0.6259026605555091,
            "mae": 0.4448317545501906,
            "precision": 0.7209944751381215,
            "recall": 0.5661605206073753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.720224692236089,
            "auditor_fn_violation": 0.01939432760399986,
            "auditor_fp_violation": 0.00842649583385672,
            "ave_precision_score": 0.7214132134077166,
            "fpr": 0.08662280701754387,
            "logloss": 0.6400072428663994,
            "mae": 0.3830895673303881,
            "precision": 0.7729885057471264,
            "recall": 0.5456389452332657
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7475032593618341,
            "auditor_fn_violation": 0.008298192018020288,
            "auditor_fp_violation": 0.012474692035614104,
            "ave_precision_score": 0.7501074011790299,
            "fpr": 0.0801317233809001,
            "logloss": 0.5867244148507599,
            "mae": 0.3665355592557156,
            "precision": 0.7840236686390533,
            "recall": 0.5748373101952278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 22571,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.772445008930143,
            "auditor_fn_violation": 0.000676132521974307,
            "auditor_fp_violation": 0.007748712473307393,
            "ave_precision_score": 0.5494584808465988,
            "fpr": 0.43859649122807015,
            "logloss": 0.6922146565725296,
            "mae": 0.49951962858699916,
            "precision": 0.5495495495495496,
            "recall": 0.9898580121703854
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.7485414671969716,
            "auditor_fn_violation": 0.0026954242078619716,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.5067130035553491,
            "fpr": 0.4829857299670692,
            "logloss": 0.6930622316772215,
            "mae": 0.499943812938998,
            "precision": 0.5067264573991032,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 22571,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8669190437084635,
            "auditor_fn_violation": 0.008587327853101316,
            "auditor_fp_violation": 0.006291085709500487,
            "ave_precision_score": 0.863816559753892,
            "fpr": 0.09868421052631579,
            "logloss": 0.49179040976287447,
            "mae": 0.308960028809675,
            "precision": 0.8051948051948052,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8508366808289585,
            "auditor_fn_violation": 0.004078853063663925,
            "auditor_fp_violation": 0.016941090376875228,
            "ave_precision_score": 0.8483954057512475,
            "fpr": 0.10208562019758508,
            "logloss": 0.46651288852109707,
            "mae": 0.3020208510892255,
            "precision": 0.7910112359550562,
            "recall": 0.7635574837310195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7649355350793879,
            "auditor_fn_violation": 0.0006516672004554998,
            "auditor_fp_violation": 0.004671209647029272,
            "ave_precision_score": 0.5500978984558549,
            "fpr": 0.4517543859649123,
            "logloss": 0.690545314793517,
            "mae": 0.49807860069159415,
            "precision": 0.5442477876106194,
            "recall": 0.9979716024340771
        },
        "train": {
            "accuracy": 0.5093304061470911,
            "auc_prc": 0.7387319163933507,
            "auditor_fn_violation": 0.0008310097601977281,
            "auditor_fp_violation": 0.003146725210391516,
            "ave_precision_score": 0.5094304589077432,
            "fpr": 0.48737650933040616,
            "logloss": 0.7647491424188649,
            "mae": 0.4991989158969025,
            "precision": 0.5077605321507761,
            "recall": 0.9934924078091106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.670632415231324,
            "mae": 0.5405701754385965,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.477909899071157,
            "mae": 0.5060373216245884,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8480215729297482,
            "auditor_fn_violation": 0.0006338742393509155,
            "auditor_fp_violation": 0.008402943516308676,
            "ave_precision_score": 0.8345202418596687,
            "fpr": 0.11951754385964912,
            "logloss": 0.5099427007173641,
            "mae": 0.3276694205900033,
            "precision": 0.7747933884297521,
            "recall": 0.7606490872210954
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.838057144857294,
            "auditor_fn_violation": 0.008424391207964359,
            "auditor_fp_violation": 0.011135504329796323,
            "ave_precision_score": 0.8261178625806719,
            "fpr": 0.13062568605927552,
            "logloss": 0.48334581627061723,
            "mae": 0.3189096556062494,
            "precision": 0.750524109014675,
            "recall": 0.7765726681127982
        }
    }
]