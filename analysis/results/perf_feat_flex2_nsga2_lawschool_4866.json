[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5496114806709511,
            "auditor_fn_violation": 0.028124230917976303,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5510576255250789,
            "fpr": 0.07675438596491228,
            "logloss": 0.6944944591327029,
            "mae": 0.4994169791604866,
            "precision": 0.5652173913043478,
            "recall": 0.18236472945891782
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5243225850649345,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.0214772661621122,
            "ave_precision_score": 0.5261675506143273,
            "fpr": 0.07354555433589462,
            "logloss": 0.6903644426453375,
            "mae": 0.4975278796924587,
            "precision": 0.5620915032679739,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 4866,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.7101258437928488,
            "auditor_fn_violation": 0.004381570157859576,
            "auditor_fp_violation": 0.0005628477974597512,
            "ave_precision_score": 0.5788998415168785,
            "fpr": 0.01206140350877193,
            "logloss": 0.6826878005040109,
            "mae": 0.4917876832187176,
            "precision": 0.828125,
            "recall": 0.1062124248496994
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6330141523608918,
            "auditor_fn_violation": 0.0027164931665480414,
            "auditor_fp_violation": 0.0018583781077281564,
            "ave_precision_score": 0.5311912183052497,
            "fpr": 0.027442371020856202,
            "logloss": 0.6837427096690974,
            "mae": 0.4913273741594392,
            "precision": 0.6987951807228916,
            "recall": 0.12747252747252746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951201277686314,
            "mae": 0.500971139392309,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.694534588421295,
            "mae": 0.5006783971671346,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6952484517280155,
            "mae": 0.5010325782523867,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6946039697259353,
            "mae": 0.5007103816999693,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6952609490571305,
            "mae": 0.501038536886897,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6946103552112611,
            "mae": 0.5007132864613434,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 4866,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.7101221118472161,
            "auditor_fn_violation": 0.004381570157859576,
            "auditor_fp_violation": 0.0005628477974597512,
            "ave_precision_score": 0.5789035959759535,
            "fpr": 0.01206140350877193,
            "logloss": 0.6824572276230646,
            "mae": 0.49154417916086685,
            "precision": 0.828125,
            "recall": 0.1062124248496994
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6330065908674959,
            "auditor_fn_violation": 0.0027164931665480414,
            "auditor_fp_violation": 0.0018583781077281564,
            "ave_precision_score": 0.5312009324898146,
            "fpr": 0.027442371020856202,
            "logloss": 0.6836019476956485,
            "mae": 0.4910491960763146,
            "precision": 0.6987951807228916,
            "recall": 0.12747252747252746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951800753030322,
            "mae": 0.5009998955616826,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945678363789538,
            "mae": 0.5006938107254476,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5392944954594269,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.026196317063846054,
            "ave_precision_score": 0.5405881077349938,
            "fpr": 0.0756578947368421,
            "logloss": 0.6957014740239048,
            "mae": 0.5001079219867263,
            "precision": 0.5660377358490566,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5103440751602912,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5117640730490343,
            "fpr": 0.07135016465422613,
            "logloss": 0.6904780304875701,
            "mae": 0.4976417260361032,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.897861207303105,
            "mae": 0.5471491228070176,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.25043167912663,
            "mae": 0.4994511525795829,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.3454568912260611,
            "auditor_fn_violation": 0.0006108708645360903,
            "auditor_fp_violation": 0.002312454865978506,
            "ave_precision_score": 0.5463389184383804,
            "fpr": 0.006578947368421052,
            "logloss": 0.7850995341827665,
            "mae": 0.5165259399892468,
            "precision": 0.14285714285714285,
            "recall": 0.002004008016032064
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026142469235657757,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.006586169045005488,
            "logloss": 0.7527248285725665,
            "mae": 0.5009180606720084,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6356150106411189,
            "auditor_fn_violation": 0.012092166789719814,
            "auditor_fp_violation": 0.00023363493479461412,
            "ave_precision_score": 0.5804663253394824,
            "fpr": 0.15789473684210525,
            "logloss": 0.6926681638141404,
            "mae": 0.49970973002021774,
            "precision": 0.5609756097560976,
            "recall": 0.3687374749498998
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5773781478147236,
            "auditor_fn_violation": 0.008426918855019856,
            "auditor_fp_violation": 0.008759893696920679,
            "ave_precision_score": 0.5136474373219835,
            "fpr": 0.18990120746432493,
            "logloss": 0.6931701516963716,
            "mae": 0.49996208333288666,
            "precision": 0.4820359281437126,
            "recall": 0.35384615384615387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 4866,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.47017392770880706,
            "auditor_fn_violation": 0.004381570157859576,
            "auditor_fp_violation": 0.0005628477974597512,
            "ave_precision_score": 0.47175918458796395,
            "fpr": 0.01206140350877193,
            "logloss": 0.6818787043272265,
            "mae": 0.490883445497929,
            "precision": 0.828125,
            "recall": 0.1062124248496994
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.4318408290681101,
            "auditor_fn_violation": 0.0027164931665480414,
            "auditor_fp_violation": 0.0018583781077281564,
            "ave_precision_score": 0.4319833902049924,
            "fpr": 0.027442371020856202,
            "logloss": 0.6831132142857615,
            "mae": 0.49041696213406605,
            "precision": 0.6987951807228916,
            "recall": 0.12747252747252746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7167574146355935,
            "auditor_fn_violation": 0.044349664240762234,
            "auditor_fp_violation": 0.02466972516035853,
            "ave_precision_score": 0.6820308381853563,
            "fpr": 0.10964912280701754,
            "logloss": 0.6385396040222051,
            "mae": 0.43281937991840796,
            "precision": 0.7435897435897436,
            "recall": 0.5811623246492986
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.4979625743618727,
            "auditor_fn_violation": 0.041888517629461657,
            "auditor_fp_violation": 0.03579785082904848,
            "ave_precision_score": 0.6106764837774548,
            "fpr": 0.1394072447859495,
            "logloss": 0.6901384785141463,
            "mae": 0.455829078063745,
            "precision": 0.6640211640211641,
            "recall": 0.5516483516483517
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 4866,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7946673098445982,
            "auditor_fn_violation": 0.03359570017227439,
            "auditor_fp_violation": 0.019991716579584554,
            "ave_precision_score": 0.683335783780939,
            "fpr": 0.09539473684210527,
            "logloss": 0.6206937343539831,
            "mae": 0.4234718346085988,
            "precision": 0.7722513089005235,
            "recall": 0.591182364729459
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.738564680538687,
            "auditor_fn_violation": 0.029155257475784367,
            "auditor_fp_violation": 0.032295337685597086,
            "ave_precision_score": 0.6113633192233213,
            "fpr": 0.1207464324917673,
            "logloss": 0.6645917863590897,
            "mae": 0.4439325153042535,
            "precision": 0.6986301369863014,
            "recall": 0.5604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7591734543801945,
            "auditor_fn_violation": 0.024896283795661497,
            "auditor_fp_violation": 0.021616541353383464,
            "ave_precision_score": 0.7465943507663295,
            "fpr": 0.1118421052631579,
            "logloss": 0.5856152866332366,
            "mae": 0.38835314293637085,
            "precision": 0.7697516930022573,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7660233077253403,
            "auditor_fn_violation": 0.02928794586313797,
            "auditor_fp_violation": 0.03476515107747415,
            "ave_precision_score": 0.7014652423009092,
            "fpr": 0.12952799121844127,
            "logloss": 0.5980084627302952,
            "mae": 0.4015161816590965,
            "precision": 0.7142857142857143,
            "recall": 0.6483516483516484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 4866,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7946673098445982,
            "auditor_fn_violation": 0.03359570017227439,
            "auditor_fp_violation": 0.019991716579584554,
            "ave_precision_score": 0.683335783780939,
            "fpr": 0.09539473684210527,
            "logloss": 0.6206937343539831,
            "mae": 0.4234718346085988,
            "precision": 0.7722513089005235,
            "recall": 0.591182364729459
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.738564680538687,
            "auditor_fn_violation": 0.029155257475784367,
            "auditor_fp_violation": 0.032295337685597086,
            "ave_precision_score": 0.6113633192233213,
            "fpr": 0.1207464324917673,
            "logloss": 0.6645917863590897,
            "mae": 0.4439325153042535,
            "precision": 0.6986301369863014,
            "recall": 0.5604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.693197644302836,
            "mae": 0.5000251606760318,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005271823906638165,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6931939682566179,
            "mae": 0.5000228341403045,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.548756419722035,
            "auditor_fn_violation": 0.002120469008191839,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5525768135461206,
            "fpr": 0.0,
            "logloss": 0.7811544125310489,
            "mae": 0.5133640036771172,
            "precision": 1.0,
            "recall": 0.012024048096192385
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.5650252510021995,
            "auditor_fn_violation": 0.0028636566507038446,
            "auditor_fp_violation": 0.0005969919309800298,
            "ave_precision_score": 0.5095376814915783,
            "fpr": 0.0010976948408342481,
            "logloss": 0.7447397602564284,
            "mae": 0.49528753620078614,
            "precision": 0.9166666666666666,
            "recall": 0.024175824175824177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 4866,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5497305776797777,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5530291954228509,
            "fpr": 0.07675438596491228,
            "logloss": 0.6952291342956988,
            "mae": 0.5001270176614063,
            "precision": 0.5625,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5411082286639253,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5452581151434568,
            "fpr": 0.07135016465422613,
            "logloss": 0.6919595970589626,
            "mae": 0.4986375632780705,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 4866,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5497305776797777,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5530291954228509,
            "fpr": 0.07675438596491228,
            "logloss": 0.6952306286300365,
            "mae": 0.5001266250027376,
            "precision": 0.5625,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5411082286639253,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5452581151434568,
            "fpr": 0.07135016465422613,
            "logloss": 0.6919586898511413,
            "mae": 0.49863611346542114,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 4866,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5095728609217024,
            "auditor_fn_violation": 0.026210315367577255,
            "auditor_fp_violation": 0.034519561615904165,
            "ave_precision_score": 0.5164512372278223,
            "fpr": 0.17434210526315788,
            "logloss": 0.6970335512839616,
            "mae": 0.5014738118308678,
            "precision": 0.4854368932038835,
            "recall": 0.30060120240480964
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.4861843143927621,
            "auditor_fn_violation": 0.02409862365954574,
            "auditor_fp_violation": 0.03859023244169701,
            "ave_precision_score": 0.49270133998350485,
            "fpr": 0.15697036223929747,
            "logloss": 0.6941890015832639,
            "mae": 0.5000977022522236,
            "precision": 0.4929078014184397,
            "recall": 0.3054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5393390052369547,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.026196317063846054,
            "ave_precision_score": 0.5406345528139909,
            "fpr": 0.0756578947368421,
            "logloss": 0.6956991029739001,
            "mae": 0.5001087288388557,
            "precision": 0.5660377358490566,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5104006851640885,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5118206692090713,
            "fpr": 0.07135016465422613,
            "logloss": 0.6904808243190976,
            "mae": 0.4976449961458158,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6229157320034774,
            "auditor_fn_violation": 0.007194212987378269,
            "auditor_fp_violation": 0.015210165243617514,
            "ave_precision_score": 0.5370368219751356,
            "fpr": 0.2807017543859649,
            "logloss": 7.190115401116578,
            "mae": 0.45933406633782414,
            "precision": 0.5910543130990416,
            "recall": 0.7414829659318637
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.597909221676881,
            "auditor_fn_violation": 0.011049323892353528,
            "auditor_fp_violation": 0.015237737593159642,
            "ave_precision_score": 0.5113775174138961,
            "fpr": 0.2996706915477497,
            "logloss": 6.978034459449027,
            "mae": 0.46094034512810467,
            "precision": 0.5589660743134087,
            "recall": 0.7604395604395604
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.3454568912260611,
            "auditor_fn_violation": 0.0006108708645360903,
            "auditor_fp_violation": 0.002312454865978506,
            "ave_precision_score": 0.5463389184383804,
            "fpr": 0.006578947368421052,
            "logloss": 0.7850995341827665,
            "mae": 0.5165259399892468,
            "precision": 0.14285714285714285,
            "recall": 0.002004008016032064
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026142469235657757,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.006586169045005488,
            "logloss": 0.7527248285725665,
            "mae": 0.5009180606720084,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.693197644302836,
            "mae": 0.5000251606760318,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005271823906638165,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.0010976948408342481,
            "logloss": 0.6931939682566179,
            "mae": 0.5000228341403045,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7880745506024691,
            "auditor_fn_violation": 0.044132123896916654,
            "auditor_fp_violation": 0.023212161760333038,
            "ave_precision_score": 0.6797460214918922,
            "fpr": 0.09210526315789473,
            "logloss": 0.6242271017989215,
            "mae": 0.43709084345844756,
            "precision": 0.774798927613941,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7351328457597319,
            "auditor_fn_violation": 0.039862004077152256,
            "auditor_fp_violation": 0.03574248464190113,
            "ave_precision_score": 0.6133976461789777,
            "fpr": 0.1141602634467618,
            "logloss": 0.6414762490313549,
            "mae": 0.44538205646133844,
            "precision": 0.7037037037037037,
            "recall": 0.5428571428571428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 4866,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7494947314717127,
            "auditor_fn_violation": 0.0054934430264036984,
            "auditor_fp_violation": 0.016906673463319317,
            "ave_precision_score": 0.7280257745697757,
            "fpr": 0.1425438596491228,
            "logloss": 0.6131081663800858,
            "mae": 0.4168389047283614,
            "precision": 0.7291666666666666,
            "recall": 0.7014028056112225
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7293372161580054,
            "auditor_fn_violation": 0.015765792933740246,
            "auditor_fp_violation": 0.023629325784274083,
            "ave_precision_score": 0.6832551275798255,
            "fpr": 0.16245883644346873,
            "logloss": 0.6118914730880282,
            "mae": 0.42369653857042183,
            "precision": 0.6666666666666666,
            "recall": 0.6505494505494506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7669734467068735,
            "auditor_fn_violation": 0.04360914812080301,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6932078221511012,
            "fpr": 0.09320175438596491,
            "logloss": 0.6124069459245658,
            "mae": 0.4154615207460889,
            "precision": 0.7733333333333333,
            "recall": 0.5811623246492986
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.740683289519169,
            "auditor_fn_violation": 0.037671439427751176,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6423081662606931,
            "fpr": 0.11086717892425905,
            "logloss": 0.6262858558869143,
            "mae": 0.42649514395764054,
            "precision": 0.7154929577464789,
            "recall": 0.5582417582417583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7015615065501093,
            "auditor_fn_violation": 0.026506961291003064,
            "auditor_fp_violation": 0.01959878509833907,
            "ave_precision_score": 0.6952677681723161,
            "fpr": 0.1600877192982456,
            "logloss": 0.6554732869380985,
            "mae": 0.4249755928595142,
            "precision": 0.6711711711711712,
            "recall": 0.5971943887775552
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6564230722668065,
            "auditor_fn_violation": 0.01604081977298224,
            "auditor_fp_violation": 0.019924605696458497,
            "ave_precision_score": 0.6506268666831351,
            "fpr": 0.17453347969264543,
            "logloss": 0.6505999384010233,
            "mae": 0.43253839208154593,
            "precision": 0.6285046728971962,
            "recall": 0.5912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.743348179497443,
            "auditor_fn_violation": 0.00879829835108815,
            "auditor_fp_violation": 0.010441888619854732,
            "ave_precision_score": 0.7387310385369662,
            "fpr": 0.13157894736842105,
            "logloss": 0.6054536431795001,
            "mae": 0.38616779516859534,
            "precision": 0.7446808510638298,
            "recall": 0.7014028056112225
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7575332313757122,
            "auditor_fn_violation": 0.013075837444662923,
            "auditor_fp_violation": 0.019758507135016465,
            "ave_precision_score": 0.6916083908724184,
            "fpr": 0.145993413830955,
            "logloss": 0.6273927454736439,
            "mae": 0.40514208749345576,
            "precision": 0.6892523364485982,
            "recall": 0.6483516483516484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7015260688948778,
            "auditor_fn_violation": 0.026506961291003064,
            "auditor_fp_violation": 0.01959878509833907,
            "ave_precision_score": 0.695178332880959,
            "fpr": 0.1600877192982456,
            "logloss": 0.655474227361729,
            "mae": 0.4249762165188593,
            "precision": 0.6711711711711712,
            "recall": 0.5971943887775552
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6564898370856517,
            "auditor_fn_violation": 0.01604081977298224,
            "auditor_fp_violation": 0.019924605696458497,
            "ave_precision_score": 0.6506904569144376,
            "fpr": 0.17453347969264543,
            "logloss": 0.6506008998993184,
            "mae": 0.4325391174335969,
            "precision": 0.6285046728971962,
            "recall": 0.5912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951842548675413,
            "mae": 0.5010018865986351,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945699288960535,
            "mae": 0.5006947595581134,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5495946799980187,
            "auditor_fn_violation": 0.028124230917976303,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5510408641498192,
            "fpr": 0.07675438596491228,
            "logloss": 0.6944928198310761,
            "mae": 0.4994167889746135,
            "precision": 0.5652173913043478,
            "recall": 0.18236472945891782
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5243225518452148,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.0214772661621122,
            "ave_precision_score": 0.5261661408291716,
            "fpr": 0.07354555433589462,
            "logloss": 0.6903645728625363,
            "mae": 0.49752851051373487,
            "precision": 0.5620915032679739,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5392873801903164,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.026196317063846054,
            "ave_precision_score": 0.5405829420107048,
            "fpr": 0.0756578947368421,
            "logloss": 0.6957184299946277,
            "mae": 0.5001153809002095,
            "precision": 0.5660377358490566,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5103864971173164,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5118033975385516,
            "fpr": 0.07135016465422613,
            "logloss": 0.6904771528576661,
            "mae": 0.4976403573538155,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5495781386418608,
            "auditor_fn_violation": 0.02938113068241747,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.551024569277954,
            "fpr": 0.07675438596491228,
            "logloss": 0.6944899838804716,
            "mae": 0.49940817933856396,
            "precision": 0.5679012345679012,
            "recall": 0.1843687374749499
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5242871449873532,
            "auditor_fn_violation": 0.01792499487340324,
            "auditor_fp_violation": 0.021732432068095598,
            "ave_precision_score": 0.526131986404394,
            "fpr": 0.07464324917672886,
            "logloss": 0.6903585073191929,
            "mae": 0.49751955126826247,
            "precision": 0.5612903225806452,
            "recall": 0.1912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5495836830677961,
            "auditor_fn_violation": 0.02938113068241747,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5510300019067025,
            "fpr": 0.07675438596491228,
            "logloss": 0.6944892926421009,
            "mae": 0.49941244113602135,
            "precision": 0.5679012345679012,
            "recall": 0.1843687374749499
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5242238783610567,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.021732432068095598,
            "ave_precision_score": 0.5260674386872809,
            "fpr": 0.07464324917672886,
            "logloss": 0.6903569760832107,
            "mae": 0.4975221869908887,
            "precision": 0.5584415584415584,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5502211062145459,
            "auditor_fn_violation": 0.06478087754456281,
            "auditor_fp_violation": 0.05772110360647382,
            "ave_precision_score": 0.5516893349096073,
            "fpr": 0.17214912280701755,
            "logloss": 0.6926037157007694,
            "mae": 0.4986704562774353,
            "precision": 0.5857519788918206,
            "recall": 0.44488977955911824
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5260686616945152,
            "auditor_fn_violation": 0.05560367184955549,
            "auditor_fp_violation": 0.06037321624588366,
            "ave_precision_score": 0.5279177920351846,
            "fpr": 0.1877058177826564,
            "logloss": 0.6903581591697879,
            "mae": 0.497698650663692,
            "precision": 0.565989847715736,
            "recall": 0.4901098901098901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 4866,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6452054276335385,
            "auditor_fn_violation": 0.007220581513905003,
            "auditor_fp_violation": 0.01443226710844911,
            "ave_precision_score": 0.5487167442561633,
            "fpr": 0.3201754385964912,
            "logloss": 7.570513723844912,
            "mae": 0.437686982760696,
            "precision": 0.5966850828729282,
            "recall": 0.8657314629258517
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6176061813830591,
            "auditor_fn_violation": 0.0031700461996839596,
            "auditor_fp_violation": 0.014910354921331874,
            "ave_precision_score": 0.5181360816227976,
            "fpr": 0.3545554335894621,
            "logloss": 7.570272293088779,
            "mae": 0.45856183718247945,
            "precision": 0.5544827586206896,
            "recall": 0.8835164835164835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7645698508378341,
            "auditor_fn_violation": 0.0010679253243328763,
            "auditor_fp_violation": 0.005124038910836421,
            "ave_precision_score": 0.5676445695051406,
            "fpr": 0.4331140350877193,
            "logloss": 13.641528945779733,
            "mae": 0.43433339646840624,
            "precision": 0.5571748878923767,
            "recall": 0.9959919839679359
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7362832242472952,
            "auditor_fn_violation": 0.00037394000072375495,
            "auditor_fp_violation": 0.00603732162458836,
            "ave_precision_score": 0.5164822997839474,
            "fpr": 0.4807903402854007,
            "logloss": 15.259304008430583,
            "mae": 0.4833553807501212,
            "precision": 0.5084175084175084,
            "recall": 0.9956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.720660409458495,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6882230995297781,
            "fpr": 0.09320175438596491,
            "logloss": 0.6151842693868101,
            "mae": 0.4167963363998161,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7502519824329157,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6368885494425071,
            "fpr": 0.11086717892425905,
            "logloss": 0.6300112101245252,
            "mae": 0.42963386398998754,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 4866,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7498345956911613,
            "auditor_fn_violation": 0.0054934430264036984,
            "auditor_fp_violation": 0.016906673463319317,
            "ave_precision_score": 0.7289948786793565,
            "fpr": 0.1425438596491228,
            "logloss": 0.611947435032907,
            "mae": 0.4169723176184976,
            "precision": 0.7291666666666666,
            "recall": 0.7014028056112225
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7299666778252205,
            "auditor_fn_violation": 0.015765792933740246,
            "auditor_fp_violation": 0.023629325784274083,
            "ave_precision_score": 0.6845140509142557,
            "fpr": 0.16245883644346873,
            "logloss": 0.6066173125055838,
            "mae": 0.4218146747998427,
            "precision": 0.6666666666666666,
            "recall": 0.6505494505494506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6950952122269601,
            "mae": 0.5009591617343718,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945203690541839,
            "mae": 0.5006717649890615,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.3454568912260611,
            "auditor_fn_violation": 0.0006108708645360903,
            "auditor_fp_violation": 0.002312454865978506,
            "ave_precision_score": 0.5463389184383804,
            "fpr": 0.006578947368421052,
            "logloss": 0.7850995341827665,
            "mae": 0.5165259399892468,
            "precision": 0.14285714285714285,
            "recall": 0.002004008016032064
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026142469235657757,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.006586169045005488,
            "logloss": 0.7527248285725665,
            "mae": 0.5009180606720084,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951049628706685,
            "mae": 0.500963850992552,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945259659367994,
            "mae": 0.5006743783681243,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951002465731345,
            "mae": 0.500961583009676,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945232626168065,
            "mae": 0.5006731163984335,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7212280945240885,
            "auditor_fn_violation": 0.008134690433498577,
            "auditor_fp_violation": 0.015425215581326196,
            "ave_precision_score": 0.6896814713323484,
            "fpr": 0.37609649122807015,
            "logloss": 0.6257461674477931,
            "mae": 0.41245911236068133,
            "precision": 0.5817073170731707,
            "recall": 0.9559118236472945
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7511302233400263,
            "auditor_fn_violation": 0.004825032267403289,
            "auditor_fp_violation": 0.021780576578658516,
            "ave_precision_score": 0.6386112486313615,
            "fpr": 0.41822173435784854,
            "logloss": 0.652294138021361,
            "mae": 0.4299512698706628,
            "precision": 0.5398550724637681,
            "recall": 0.9824175824175824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.897861207303105,
            "mae": 0.5471491228070176,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.25043167912663,
            "mae": 0.4994511525795829,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951009222712612,
            "mae": 0.5009619080249155,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945236492013741,
            "mae": 0.5006732969134883,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.720660409458495,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6882230995297781,
            "fpr": 0.09320175438596491,
            "logloss": 0.6151842687321025,
            "mae": 0.41679633673476546,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7502519824329157,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6368885494425071,
            "fpr": 0.11086717892425905,
            "logloss": 0.6300112101508539,
            "mae": 0.4296338643253046,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7171274262697671,
            "auditor_fn_violation": 0.009343247899307393,
            "auditor_fp_violation": 0.0027133511745465353,
            "ave_precision_score": 0.6525701067485081,
            "fpr": 0.025219298245614034,
            "logloss": 0.6398186657649797,
            "mae": 0.4356058351777233,
            "precision": 0.8614457831325302,
            "recall": 0.2865731462925852
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.7203454997483528,
            "auditor_fn_violation": 0.012508896153243028,
            "auditor_fp_violation": 0.00540181408515801,
            "ave_precision_score": 0.6184574290409671,
            "fpr": 0.029637760702524697,
            "logloss": 0.6216320850135353,
            "mae": 0.4338287168379738,
            "precision": 0.8333333333333334,
            "recall": 0.2967032967032967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7953411766029688,
            "auditor_fn_violation": 0.00704259395984953,
            "auditor_fp_violation": 0.018847436387579124,
            "ave_precision_score": 0.7968025304539008,
            "fpr": 0.21052631578947367,
            "logloss": 0.9310046292087819,
            "mae": 0.30776351094453624,
            "precision": 0.6867862969004894,
            "recall": 0.843687374749499
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7658559840126495,
            "auditor_fn_violation": 0.007785189563455209,
            "auditor_fp_violation": 0.02747125772719395,
            "ave_precision_score": 0.7664309988682665,
            "fpr": 0.24807903402854006,
            "logloss": 0.976186675590098,
            "mae": 0.3276603620719449,
            "precision": 0.630718954248366,
            "recall": 0.8483516483516483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5392886478359216,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.026196317063846054,
            "ave_precision_score": 0.540584209442271,
            "fpr": 0.0756578947368421,
            "logloss": 0.6957185874228613,
            "mae": 0.500115473673009,
            "precision": 0.5660377358490566,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5103855284448358,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5118055161368861,
            "fpr": 0.07135016465422613,
            "logloss": 0.6904772041482998,
            "mae": 0.4976403905583789,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.5527584902115504,
            "auditor_fn_violation": 0.00508912561966038,
            "auditor_fp_violation": 0.003841701711906894,
            "ave_precision_score": 0.5535610009338545,
            "fpr": 0.20614035087719298,
            "logloss": 0.6931077697048637,
            "mae": 0.4999794407110465,
            "precision": 0.5607476635514018,
            "recall": 0.48096192384769537
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5129106905041797,
            "auditor_fn_violation": 0.0014933474867613124,
            "auditor_fp_violation": 0.010664009089683592,
            "ave_precision_score": 0.5130990555094007,
            "fpr": 0.265642151481888,
            "logloss": 0.6931224979349557,
            "mae": 0.49998672481556755,
            "precision": 0.5071283095723014,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 4866,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5095728609217024,
            "auditor_fn_violation": 0.026210315367577255,
            "auditor_fp_violation": 0.034519561615904165,
            "ave_precision_score": 0.5164512372278223,
            "fpr": 0.17434210526315788,
            "logloss": 0.697029889191736,
            "mae": 0.501478069772323,
            "precision": 0.4854368932038835,
            "recall": 0.30060120240480964
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.4861843143927621,
            "auditor_fn_violation": 0.02409862365954574,
            "auditor_fp_violation": 0.03859023244169701,
            "ave_precision_score": 0.49270133998350485,
            "fpr": 0.15697036223929747,
            "logloss": 0.6941989953784878,
            "mae": 0.50010779418223,
            "precision": 0.4929078014184397,
            "recall": 0.3054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8008343138705444,
            "auditor_fn_violation": 0.0048430193720774995,
            "auditor_fp_violation": 0.01756244424620874,
            "ave_precision_score": 0.8012304689503947,
            "fpr": 0.1074561403508772,
            "logloss": 0.6105773238398212,
            "mae": 0.3584261823613033,
            "precision": 0.7632850241545893,
            "recall": 0.6332665330661322
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7724982932138973,
            "auditor_fn_violation": 0.009184448921002168,
            "auditor_fp_violation": 0.019734434879735016,
            "ave_precision_score": 0.7728722973045803,
            "fpr": 0.12403951701427003,
            "logloss": 0.6025248371187362,
            "mae": 0.35525066417798407,
            "precision": 0.7131979695431472,
            "recall": 0.6175824175824176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 4866,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.5095728609217024,
            "auditor_fn_violation": 0.026210315367577255,
            "auditor_fp_violation": 0.034519561615904165,
            "ave_precision_score": 0.5164512372278223,
            "fpr": 0.17434210526315788,
            "logloss": 0.6970359588138867,
            "mae": 0.5014740242704487,
            "precision": 0.4854368932038835,
            "recall": 0.30060120240480964
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.4861843143927621,
            "auditor_fn_violation": 0.02409862365954574,
            "auditor_fp_violation": 0.03859023244169701,
            "ave_precision_score": 0.49270133998350485,
            "fpr": 0.15697036223929747,
            "logloss": 0.6941864703116672,
            "mae": 0.5000955218737526,
            "precision": 0.4929078014184397,
            "recall": 0.3054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.720660409458495,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6882230995297781,
            "fpr": 0.09320175438596491,
            "logloss": 0.6151842687321025,
            "mae": 0.41679633673476546,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7502519824329157,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6368885494425071,
            "fpr": 0.11086717892425905,
            "logloss": 0.6300112101508539,
            "mae": 0.4296338643253046,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6449658743623788,
            "auditor_fn_violation": 0.0014656505994445016,
            "auditor_fp_violation": 0.01443226710844911,
            "ave_precision_score": 0.5484772502806382,
            "fpr": 0.3201754385964912,
            "logloss": 7.5916893677614095,
            "mae": 0.43776111182217536,
            "precision": 0.5972413793103448,
            "recall": 0.8677354709418837
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6166018633199848,
            "auditor_fn_violation": 0.002759918456954682,
            "auditor_fp_violation": 0.013629710940358586,
            "ave_precision_score": 0.5171318359304664,
            "fpr": 0.3534577387486279,
            "logloss": 7.607930213043496,
            "mae": 0.460706383088025,
            "precision": 0.5558620689655173,
            "recall": 0.8857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.695271364113815,
            "mae": 0.5010434968495056,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6946155776470219,
            "mae": 0.5007156520002367,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6242338996511712,
            "auditor_fn_violation": 0.009503656435678376,
            "auditor_fp_violation": 0.016062401767129697,
            "ave_precision_score": 0.5385973149199018,
            "fpr": 0.27521929824561403,
            "logloss": 7.139437596062413,
            "mae": 0.45827926262772006,
            "precision": 0.5938511326860841,
            "recall": 0.7354709418837675
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5996146306182699,
            "auditor_fn_violation": 0.010687446472298284,
            "auditor_fp_violation": 0.01188206520692513,
            "ave_precision_score": 0.5130827298723968,
            "fpr": 0.29418221734357847,
            "logloss": 6.930755601930966,
            "mae": 0.45791656398403524,
            "precision": 0.5628058727569332,
            "recall": 0.7582417582417582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7600773360633285,
            "auditor_fn_violation": 0.0005031993812185776,
            "auditor_fp_violation": 0.0011442801920054425,
            "ave_precision_score": 0.5585169852899039,
            "fpr": 0.44846491228070173,
            "logloss": 14.13386968663646,
            "mae": 0.4485877903404176,
            "precision": 0.5490628445424476,
            "recall": 0.9979959919839679
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7339495314771223,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015165520827315462,
            "ave_precision_score": 0.5101670454138988,
            "fpr": 0.49396267837541163,
            "logloss": 15.638443647114242,
            "mae": 0.4943323267703522,
            "precision": 0.5027624309392266,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 4866,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7494947314717127,
            "auditor_fn_violation": 0.0054934430264036984,
            "auditor_fp_violation": 0.016906673463319317,
            "ave_precision_score": 0.7280257745697757,
            "fpr": 0.1425438596491228,
            "logloss": 0.6125979880641835,
            "mae": 0.4164947681986776,
            "precision": 0.7291666666666666,
            "recall": 0.7014028056112225
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7293372161580054,
            "auditor_fn_violation": 0.015765792933740246,
            "auditor_fp_violation": 0.023629325784274083,
            "ave_precision_score": 0.6832551275798255,
            "fpr": 0.16245883644346873,
            "logloss": 0.6108696657642545,
            "mae": 0.42315117138490066,
            "precision": 0.6666666666666666,
            "recall": 0.6505494505494506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8032105169629068,
            "auditor_fn_violation": 0.013560014766374856,
            "auditor_fp_violation": 0.015645575803916574,
            "ave_precision_score": 0.8046374852667677,
            "fpr": 0.19736842105263158,
            "logloss": 0.8948252465154632,
            "mae": 0.2960111403597533,
            "precision": 0.7009966777408638,
            "recall": 0.845691382765531
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7809025843819395,
            "auditor_fn_violation": 0.014504046995814281,
            "auditor_fp_violation": 0.034895141255993994,
            "ave_precision_score": 0.7813765942497057,
            "fpr": 0.2239297475301866,
            "logloss": 0.9307020780906244,
            "mae": 0.31093496159907347,
            "precision": 0.6548223350253807,
            "recall": 0.8505494505494505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6444929498252948,
            "auditor_fn_violation": 0.0014656505994445016,
            "auditor_fp_violation": 0.01539601121447687,
            "ave_precision_score": 0.5480044279392948,
            "fpr": 0.32456140350877194,
            "logloss": 7.60517512919257,
            "mae": 0.43834447460412457,
            "precision": 0.5939643347050755,
            "recall": 0.8677354709418837
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6162337771534224,
            "auditor_fn_violation": 0.0031362709738121377,
            "auditor_fp_violation": 0.014910354921331867,
            "ave_precision_score": 0.5167667844999048,
            "fpr": 0.3578485181119649,
            "logloss": 7.62863024205872,
            "mae": 0.4613791011952673,
            "precision": 0.5528120713305898,
            "recall": 0.8857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7596167771992554,
            "auditor_fn_violation": 0.0005031993812185776,
            "auditor_fp_violation": 0.0010407374368123815,
            "ave_precision_score": 0.5593884465319134,
            "fpr": 0.44627192982456143,
            "logloss": 14.022772677229506,
            "mae": 0.44755734655406915,
            "precision": 0.5502762430939226,
            "recall": 0.9979959919839679
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.7338228837732793,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0015165520827315462,
            "ave_precision_score": 0.5120011977979942,
            "fpr": 0.49396267837541163,
            "logloss": 15.479562846690722,
            "mae": 0.4944250107662084,
            "precision": 0.5027624309392266,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7747244759915768,
            "auditor_fn_violation": 0.024896283795661497,
            "auditor_fp_violation": 0.021616541353383464,
            "ave_precision_score": 0.7736837817271984,
            "fpr": 0.1118421052631579,
            "logloss": 0.5864763117763184,
            "mae": 0.38780477037244854,
            "precision": 0.7697516930022573,
            "recall": 0.6833667334669339
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7430800789844957,
            "auditor_fn_violation": 0.02928794586313797,
            "auditor_fp_violation": 0.03476515107747415,
            "ave_precision_score": 0.7394720466652587,
            "fpr": 0.12952799121844127,
            "logloss": 0.6008185142973071,
            "mae": 0.4017614772426768,
            "precision": 0.7142857142857143,
            "recall": 0.6483516483516484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7731732170387747,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005256786032878862,
            "ave_precision_score": 0.5472537432012915,
            "fpr": 0.4517543859649123,
            "logloss": 15.603509094700781,
            "mae": 0.4518546374318631,
            "precision": 0.5477497255762898,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.7502750275027503,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00017332023802646516,
            "ave_precision_score": 0.5005500550055005,
            "fpr": 0.4983534577387486,
            "logloss": 17.21340344087733,
            "mae": 0.4987658281226844,
            "precision": 0.5005500550055005,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6952114616751291,
            "mae": 0.5010149035145316,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945845016434408,
            "mae": 0.500701463183247,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6444922812357156,
            "auditor_fn_violation": 0.0014656505994445016,
            "auditor_fp_violation": 0.01539601121447687,
            "ave_precision_score": 0.5480037598423044,
            "fpr": 0.32456140350877194,
            "logloss": 7.605067375397539,
            "mae": 0.4383413149697477,
            "precision": 0.5939643347050755,
            "recall": 0.8677354709418837
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6162338609681329,
            "auditor_fn_violation": 0.0031362709738121377,
            "auditor_fp_violation": 0.014910354921331867,
            "ave_precision_score": 0.5167668685874482,
            "fpr": 0.3578485181119649,
            "logloss": 7.628558013693413,
            "mae": 0.4613713600992764,
            "precision": 0.5528120713305898,
            "recall": 0.8857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6945183026103017,
            "auditor_fn_violation": 0.001470045353865626,
            "auditor_fp_violation": 0.004866509494074171,
            "ave_precision_score": 0.5596132888830605,
            "fpr": 0.42543859649122806,
            "logloss": 10.597977003036537,
            "mae": 0.42970782108482364,
            "precision": 0.5610859728506787,
            "recall": 0.9939879759519038
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.6501736285720783,
            "auditor_fn_violation": 0.00037394000072375495,
            "auditor_fp_violation": 0.005864001386561906,
            "ave_precision_score": 0.5129802577175817,
            "fpr": 0.47859495060373214,
            "logloss": 11.153066360854531,
            "mae": 0.47802375378056494,
            "precision": 0.5095613048368954,
            "recall": 0.9956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 4866,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.509577392927782,
            "auditor_fn_violation": 0.026210315367577255,
            "auditor_fp_violation": 0.034519561615904165,
            "ave_precision_score": 0.5164540023693417,
            "fpr": 0.17434210526315788,
            "logloss": 0.6970375547466302,
            "mae": 0.5014732529392891,
            "precision": 0.4854368932038835,
            "recall": 0.30060120240480964
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.4860521145694214,
            "auditor_fn_violation": 0.02409862365954574,
            "auditor_fp_violation": 0.03859023244169701,
            "ave_precision_score": 0.4925699879394824,
            "fpr": 0.15697036223929747,
            "logloss": 0.6941841176213361,
            "mae": 0.5000930154035695,
            "precision": 0.4929078014184397,
            "recall": 0.3054945054945055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4758771929824561,
            "auc_prc": 0.5521474208944759,
            "auditor_fn_violation": 0.030482016664908785,
            "auditor_fp_violation": 0.02359978335669683,
            "ave_precision_score": 0.5555003411066719,
            "fpr": 0.07346491228070176,
            "logloss": 0.694432767437808,
            "mae": 0.4998996365946113,
            "precision": 0.567741935483871,
            "recall": 0.17635270541082165
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.544415367215461,
            "auditor_fn_violation": 0.02195389681668497,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5486708463238964,
            "fpr": 0.07135016465422613,
            "logloss": 0.6906954021644354,
            "mae": 0.4980983689312877,
            "precision": 0.5666666666666667,
            "recall": 0.18681318681318682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 4866,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5497305776797777,
            "auditor_fn_violation": 0.02957669725415744,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5530291954228509,
            "fpr": 0.07675438596491228,
            "logloss": 0.6952358902719379,
            "mae": 0.5001250687463764,
            "precision": 0.5625,
            "recall": 0.18036072144288579
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5411082286639253,
            "auditor_fn_violation": 0.0178815695829966,
            "auditor_fp_violation": 0.02063955167831764,
            "ave_precision_score": 0.5452581151434568,
            "fpr": 0.07135016465422613,
            "logloss": 0.6919551398736355,
            "mae": 0.4986306594441411,
            "precision": 0.5695364238410596,
            "recall": 0.189010989010989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5496409286265294,
            "auditor_fn_violation": 0.02938113068241747,
            "auditor_fp_violation": 0.02401129943502825,
            "ave_precision_score": 0.5510874971985185,
            "fpr": 0.07675438596491228,
            "logloss": 0.6944827056853443,
            "mae": 0.4994088265587363,
            "precision": 0.5679012345679012,
            "recall": 0.1843687374749499
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5242295671992667,
            "auditor_fn_violation": 0.01792499487340324,
            "auditor_fp_violation": 0.021732432068095598,
            "ave_precision_score": 0.526072018793393,
            "fpr": 0.07464324917672886,
            "logloss": 0.6903613036538111,
            "mae": 0.4975248009588009,
            "precision": 0.5612903225806452,
            "recall": 0.1912087912087912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7836676285356879,
            "auditor_fn_violation": 0.04386184650001758,
            "auditor_fp_violation": 0.021443970094728346,
            "ave_precision_score": 0.6791428400383417,
            "fpr": 0.08881578947368421,
            "logloss": 0.625416399700839,
            "mae": 0.4346777960135226,
            "precision": 0.775623268698061,
            "recall": 0.561122244488978
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7423397139168908,
            "auditor_fn_violation": 0.038974198139950074,
            "auditor_fp_violation": 0.034779594430643025,
            "ave_precision_score": 0.6255011841853161,
            "fpr": 0.10757409440175632,
            "logloss": 0.634409164020486,
            "mae": 0.4369941190882912,
            "precision": 0.7151162790697675,
            "recall": 0.5406593406593406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 4866,
        "test": {
            "accuracy": 0.45285087719298245,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6924079514100764,
            "mae": 0.4995025065319057,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6916314087000994,
            "mae": 0.49913776954625755,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.708986331478008,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.7074705847693322,
            "fpr": 0.09320175438596491,
            "logloss": 0.6150664953357422,
            "mae": 0.41568775238926736,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6642883484989635,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6585233521362234,
            "fpr": 0.11086717892425905,
            "logloss": 0.6321330027583745,
            "mae": 0.4295461665916652,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4473684210526316,
            "auc_prc": 0.3454568912260611,
            "auditor_fn_violation": 0.0006108708645360903,
            "auditor_fp_violation": 0.002312454865978506,
            "ave_precision_score": 0.5463389184383804,
            "fpr": 0.006578947368421052,
            "logloss": 0.7850995341827665,
            "mae": 0.5165259399892468,
            "precision": 0.14285714285714285,
            "recall": 0.002004008016032064
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.24972557628979145,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026142469235657757,
            "ave_precision_score": 0.4994511525795829,
            "fpr": 0.006586169045005488,
            "logloss": 0.7527248285725665,
            "mae": 0.5009180606720084,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7217969360856222,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6890972583236454,
            "fpr": 0.09320175438596491,
            "logloss": 0.6150038328231364,
            "mae": 0.4158308122290723,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7500900181751811,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6347698936944944,
            "fpr": 0.11086717892425905,
            "logloss": 0.6313203919083806,
            "mae": 0.4294256386638473,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8082254032919229,
            "auditor_fn_violation": 0.008112716661392962,
            "auditor_fp_violation": 0.015332292595896524,
            "ave_precision_score": 0.8090725963720866,
            "fpr": 0.19956140350877194,
            "logloss": 0.9436855112561346,
            "mae": 0.29597416260439385,
            "precision": 0.6956521739130435,
            "recall": 0.8336673346693386
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7851877964132316,
            "auditor_fn_violation": 0.010142217826081715,
            "auditor_fp_violation": 0.03329915073083367,
            "ave_precision_score": 0.7856074898032,
            "fpr": 0.21844127332601537,
            "logloss": 0.9822960090596176,
            "mae": 0.30905966053673267,
            "precision": 0.6557093425605537,
            "recall": 0.832967032967033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7590897675431973,
            "auditor_fn_violation": 0.018328323313293253,
            "auditor_fp_violation": 0.019564270846608056,
            "ave_precision_score": 0.758478760122238,
            "fpr": 0.21710526315789475,
            "logloss": 1.5675048997713312,
            "mae": 0.29850834554539407,
            "precision": 0.6857142857142857,
            "recall": 0.8657314629258517
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7200096070049815,
            "auditor_fn_violation": 0.007104860013751343,
            "auditor_fp_violation": 0.035046796464267144,
            "ave_precision_score": 0.7194466131662687,
            "fpr": 0.23819978046103182,
            "logloss": 1.5087239705423683,
            "mae": 0.3169760684197105,
            "precision": 0.6454248366013072,
            "recall": 0.8681318681318682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8013041452513717,
            "auditor_fn_violation": 0.009749762683261264,
            "auditor_fp_violation": 0.015056178582048345,
            "ave_precision_score": 0.8021920643191078,
            "fpr": 0.20942982456140352,
            "logloss": 0.918563241488942,
            "mae": 0.3054158914783808,
            "precision": 0.6879084967320261,
            "recall": 0.843687374749499
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.779554951135583,
            "auditor_fn_violation": 0.0073533491755226115,
            "auditor_fp_violation": 0.025969148997631294,
            "ave_precision_score": 0.780124111331913,
            "fpr": 0.24039517014270034,
            "logloss": 0.9365660502956392,
            "mae": 0.32157559234505595,
            "precision": 0.6368159203980099,
            "recall": 0.843956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.7642396368719145,
            "auditor_fn_violation": 0.0010679253243328763,
            "auditor_fp_violation": 0.005601928550189036,
            "ave_precision_score": 0.566992171004427,
            "fpr": 0.43201754385964913,
            "logloss": 13.657658113657462,
            "mae": 0.43422427175452566,
            "precision": 0.5578002244668911,
            "recall": 0.9959919839679359
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7359758438873891,
            "auditor_fn_violation": 0.00037394000072375495,
            "auditor_fp_violation": 0.005743640110154666,
            "ave_precision_score": 0.515885084629195,
            "fpr": 0.4818880351262349,
            "logloss": 15.282385116911346,
            "mae": 0.48436956191036756,
            "precision": 0.507847533632287,
            "recall": 0.9956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6449696767454584,
            "auditor_fn_violation": 0.0014656505994445016,
            "auditor_fp_violation": 0.015661505458561664,
            "ave_precision_score": 0.5484810519678878,
            "fpr": 0.3190789473684211,
            "logloss": 7.591099982354123,
            "mae": 0.43775335189543274,
            "precision": 0.5980662983425414,
            "recall": 0.8677354709418837
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6166193799981015,
            "auditor_fn_violation": 0.002759918456954682,
            "auditor_fp_violation": 0.013629710940358586,
            "ave_precision_score": 0.5171501657643792,
            "fpr": 0.3534577387486279,
            "logloss": 7.607089070171063,
            "mae": 0.4607311328699246,
            "precision": 0.5558620689655173,
            "recall": 0.8857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 4866,
        "test": {
            "accuracy": 0.34210526315789475,
            "auc_prc": 0.44256417320265595,
            "auditor_fn_violation": 0.009710209893471163,
            "auditor_fp_violation": 0.030032708890871253,
            "ave_precision_score": 0.5158354636602419,
            "fpr": 0.17982456140350878,
            "logloss": 0.6951232422423802,
            "mae": 0.5009726358152795,
            "precision": 0.2775330396475771,
            "recall": 0.12625250501002003
        },
        "train": {
            "accuracy": 0.36663007683863885,
            "auc_prc": 0.3895191824749836,
            "auditor_fn_violation": 0.007599425821160193,
            "auditor_fp_violation": 0.042947310647639965,
            "ave_precision_score": 0.4726047985164007,
            "fpr": 0.1877058177826564,
            "logloss": 0.6945363543824925,
            "mae": 0.5006792196588904,
            "precision": 0.22272727272727272,
            "recall": 0.1076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7974123455281544,
            "auditor_fn_violation": 0.009404774461203108,
            "auditor_fp_violation": 0.018584597085935184,
            "ave_precision_score": 0.7988565862956183,
            "fpr": 0.20723684210526316,
            "logloss": 0.9093301433282556,
            "mae": 0.30725328963384546,
            "precision": 0.687603305785124,
            "recall": 0.8336673346693386
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7681326018914028,
            "auditor_fn_violation": 0.00665854452901654,
            "auditor_fp_violation": 0.022430527471257726,
            "ave_precision_score": 0.7687165337324633,
            "fpr": 0.24368825466520308,
            "logloss": 0.9509983190955554,
            "mae": 0.3261700312749142,
            "precision": 0.6312292358803987,
            "recall": 0.8351648351648352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.787611246727939,
            "auditor_fn_violation": 0.00661410540379004,
            "auditor_fp_violation": 0.016906673463319317,
            "ave_precision_score": 0.7295556836314333,
            "fpr": 0.1425438596491228,
            "logloss": 0.6118935684946077,
            "mae": 0.4180289118207599,
            "precision": 0.7274633123689728,
            "recall": 0.6953907815631263
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7490551240894409,
            "auditor_fn_violation": 0.016477485193182238,
            "auditor_fp_violation": 0.022820498006817264,
            "ave_precision_score": 0.6830567319160301,
            "fpr": 0.1602634467618002,
            "logloss": 0.608169251710113,
            "mae": 0.4232115662042317,
            "precision": 0.6674259681093394,
            "recall": 0.643956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7836676285356879,
            "auditor_fn_violation": 0.04386184650001758,
            "auditor_fp_violation": 0.021443970094728346,
            "ave_precision_score": 0.6791428400383417,
            "fpr": 0.08881578947368421,
            "logloss": 0.6766571753128797,
            "mae": 0.44663680013138474,
            "precision": 0.775623268698061,
            "recall": 0.561122244488978
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7423397139168908,
            "auditor_fn_violation": 0.038974198139950074,
            "auditor_fp_violation": 0.034779594430643025,
            "ave_precision_score": 0.6255011841853161,
            "fpr": 0.10757409440175632,
            "logloss": 0.6692696235220509,
            "mae": 0.44061379415994156,
            "precision": 0.7151162790697675,
            "recall": 0.5406593406593406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7997631169238337,
            "auditor_fn_violation": 0.006027405688570115,
            "auditor_fp_violation": 0.015762393271313884,
            "ave_precision_score": 0.8001724612900053,
            "fpr": 0.10416666666666667,
            "logloss": 0.6189192031252829,
            "mae": 0.35967711480634235,
            "precision": 0.763681592039801,
            "recall": 0.6152304609218436
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.775338121283178,
            "auditor_fn_violation": 0.012062580668508219,
            "auditor_fp_violation": 0.017086486798775207,
            "ave_precision_score": 0.7756945613968543,
            "fpr": 0.11306256860592755,
            "logloss": 0.6067585150309848,
            "mae": 0.355178474991071,
            "precision": 0.7275132275132276,
            "recall": 0.6043956043956044
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6446412672893114,
            "auditor_fn_violation": 0.006135077171887635,
            "auditor_fp_violation": 0.010338345864661654,
            "ave_precision_score": 0.5412409660990307,
            "fpr": 0.3980263157894737,
            "logloss": 8.418561758470867,
            "mae": 0.4313556668849815,
            "precision": 0.5683709869203329,
            "recall": 0.9579158316633266
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6149049343933014,
            "auditor_fn_violation": 0.0022074522623370045,
            "auditor_fp_violation": 0.013822288982610207,
            "ave_precision_score": 0.505179947330337,
            "fpr": 0.4281009879253567,
            "logloss": 8.707309544669222,
            "mae": 0.4554057024810564,
            "precision": 0.5272727272727272,
            "recall": 0.9560439560439561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.720660409458495,
            "auditor_fn_violation": 0.04430571669655101,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.6882230995297781,
            "fpr": 0.09320175438596491,
            "logloss": 0.6151842687321025,
            "mae": 0.41679633673476546,
            "precision": 0.7727272727272727,
            "recall": 0.5791583166332666
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7502519824329157,
            "auditor_fn_violation": 0.0418306172422528,
            "auditor_fp_violation": 0.036057831186088164,
            "ave_precision_score": 0.6368885494425071,
            "fpr": 0.11086717892425905,
            "logloss": 0.6300112101508539,
            "mae": 0.4296338643253046,
            "precision": 0.7114285714285714,
            "recall": 0.5472527472527473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6939044123271831,
            "auditor_fn_violation": 0.001470045353865626,
            "auditor_fp_violation": 0.004866509494074171,
            "ave_precision_score": 0.5600071660728938,
            "fpr": 0.42543859649122806,
            "logloss": 10.493692191283094,
            "mae": 0.42925750730935025,
            "precision": 0.5610859728506787,
            "recall": 0.9939879759519038
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6491976699848825,
            "auditor_fn_violation": 0.00037394000072375495,
            "auditor_fp_violation": 0.00647784389623895,
            "ave_precision_score": 0.5130877058660525,
            "fpr": 0.4774972557628979,
            "logloss": 11.035242398706803,
            "mae": 0.4774667431082082,
            "precision": 0.5101351351351351,
            "recall": 0.9956043956043956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 4866,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.39988649607798143,
            "auditor_fn_violation": 0.0006108708645360903,
            "auditor_fp_violation": 0.0016805785650567096,
            "ave_precision_score": 0.5466099944964761,
            "fpr": 0.003289473684210526,
            "logloss": 0.7851821669197365,
            "mae": 0.5165275439554662,
            "precision": 0.25,
            "recall": 0.002004008016032064
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.31201975850713504,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026142469235657757,
            "ave_precision_score": 0.4998636928384459,
            "fpr": 0.006586169045005488,
            "logloss": 0.752767421601963,
            "mae": 0.5009170253766224,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6445003386513971,
            "auditor_fn_violation": 0.0014656505994445016,
            "auditor_fp_violation": 0.01539601121447687,
            "ave_precision_score": 0.5480118162522101,
            "fpr": 0.32456140350877194,
            "logloss": 7.6050304921297895,
            "mae": 0.4383372112683821,
            "precision": 0.5939643347050755,
            "recall": 0.8677354709418837
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6162400927663071,
            "auditor_fn_violation": 0.0031362709738121377,
            "auditor_fp_violation": 0.014910354921331867,
            "ave_precision_score": 0.5167731004263907,
            "fpr": 0.3578485181119649,
            "logloss": 7.6284236944979655,
            "mae": 0.4613587383904651,
            "precision": 0.5528120713305898,
            "recall": 0.8857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 4866,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6446383463201927,
            "auditor_fn_violation": 0.006135077171887635,
            "auditor_fp_violation": 0.010338345864661654,
            "ave_precision_score": 0.5412421340935323,
            "fpr": 0.3980263157894737,
            "logloss": 8.418664212720733,
            "mae": 0.4313573680483347,
            "precision": 0.5683709869203329,
            "recall": 0.9579158316633266
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6149084733839217,
            "auditor_fn_violation": 0.0022074522623370045,
            "auditor_fp_violation": 0.013822288982610207,
            "ave_precision_score": 0.5051807146119006,
            "fpr": 0.4281009879253567,
            "logloss": 8.707399426849578,
            "mae": 0.45540928227681005,
            "precision": 0.5272727272727272,
            "recall": 0.9560439560439561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 4866,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7204974501375705,
            "auditor_fn_violation": 0.04280710543894809,
            "auditor_fp_violation": 0.020368718406184955,
            "ave_precision_score": 0.680981051908561,
            "fpr": 0.09320175438596491,
            "logloss": 0.6156599636950335,
            "mae": 0.4309104050983462,
            "precision": 0.7751322751322751,
            "recall": 0.5871743486973948
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7399621680217832,
            "auditor_fn_violation": 0.04150734008033678,
            "auditor_fp_violation": 0.03506123981743602,
            "ave_precision_score": 0.6188476747442633,
            "fpr": 0.11745334796926454,
            "logloss": 0.6485959361294986,
            "mae": 0.4472264760673766,
            "precision": 0.7002801120448179,
            "recall": 0.5494505494505495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8045070422428993,
            "auditor_fn_violation": 0.012199838273037307,
            "auditor_fp_violation": 0.020220041629497476,
            "ave_precision_score": 0.805931179318769,
            "fpr": 0.19517543859649122,
            "logloss": 0.8954890965881548,
            "mae": 0.29362189491801927,
            "precision": 0.7033333333333334,
            "recall": 0.845691382765531
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7818339174657136,
            "auditor_fn_violation": 0.014504046995814281,
            "auditor_fp_violation": 0.035855624241723956,
            "ave_precision_score": 0.7822970345235803,
            "fpr": 0.22502744237102085,
            "logloss": 0.933651354568889,
            "mae": 0.3102444508299368,
            "precision": 0.6537162162162162,
            "recall": 0.8505494505494505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 4866,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7600004222700596,
            "auditor_fn_violation": 0.018785377773090042,
            "auditor_fp_violation": 0.019659848774478583,
            "ave_precision_score": 0.7594728085582858,
            "fpr": 0.21162280701754385,
            "logloss": 1.5156919446899806,
            "mae": 0.29832968982821295,
            "precision": 0.6892109500805152,
            "recall": 0.8577154308617234
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7228703691563279,
            "auditor_fn_violation": 0.01433758338258887,
            "auditor_fp_violation": 0.0343101854526547,
            "ave_precision_score": 0.7231366964758029,
            "fpr": 0.23600439077936333,
            "logloss": 1.4302630872922346,
            "mae": 0.3162117959371574,
            "precision": 0.6457990115321252,
            "recall": 0.8615384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.8348545091498197,
            "auditor_fn_violation": 0.008310480610343495,
            "auditor_fp_violation": 0.004266492502442547,
            "ave_precision_score": 0.8351629196569037,
            "fpr": 0.027412280701754384,
            "logloss": 1.8587746660124531,
            "mae": 0.3904979347329897,
            "precision": 0.8648648648648649,
            "recall": 0.32064128256513025
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7896611039033253,
            "auditor_fn_violation": 0.014530584673285028,
            "auditor_fp_violation": 0.007308336703449073,
            "ave_precision_score": 0.7899875190876309,
            "fpr": 0.038419319429198684,
            "logloss": 1.6469393759267643,
            "mae": 0.36574489399497995,
            "precision": 0.8097826086956522,
            "recall": 0.3274725274725275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 4866,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8008374265371179,
            "auditor_fn_violation": 0.0048430193720774995,
            "auditor_fp_violation": 0.01756244424620874,
            "ave_precision_score": 0.8012335795149284,
            "fpr": 0.1074561403508772,
            "logloss": 0.6105699634006396,
            "mae": 0.35842304211761483,
            "precision": 0.7632850241545893,
            "recall": 0.6332665330661322
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7724982932138973,
            "auditor_fn_violation": 0.009184448921002168,
            "auditor_fp_violation": 0.019734434879735016,
            "ave_precision_score": 0.7728722973045803,
            "fpr": 0.12403951701427003,
            "logloss": 0.6025228440259538,
            "mae": 0.3552509830266865,
            "precision": 0.7131979695431472,
            "recall": 0.6175824175824176
        }
    }
]