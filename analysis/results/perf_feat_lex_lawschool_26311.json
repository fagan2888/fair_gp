[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7013816197554192,
            "auditor_fn_violation": 0.08479849297865054,
            "auditor_fp_violation": 0.027028144085268605,
            "ave_precision_score": 0.6640845837517287,
            "fpr": 0.06359649122807018,
            "logloss": 9.34476321043374,
            "mae": 0.3633796346711869,
            "precision": 0.7819548872180451,
            "recall": 0.4511930585683297
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7586430859536585,
            "auditor_fn_violation": 0.08813175900588481,
            "auditor_fp_violation": 0.020869332296913325,
            "ave_precision_score": 0.7163004956827199,
            "fpr": 0.05598243688254665,
            "logloss": 10.273707201058748,
            "mae": 0.3830903915138394,
            "precision": 0.7976190476190477,
            "recall": 0.4077079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8044195761852252,
            "auditor_fn_violation": 0.021715759028808464,
            "auditor_fp_violation": 0.03879779826506399,
            "ave_precision_score": 0.8053189395081362,
            "fpr": 0.16666666666666666,
            "logloss": 0.6897204754494817,
            "mae": 0.2944103309622047,
            "precision": 0.7148217636022514,
            "recall": 0.8264642082429501
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8510439211005731,
            "auditor_fn_violation": 0.029713463794996026,
            "auditor_fp_violation": 0.028209181770912663,
            "ave_precision_score": 0.8512315780084683,
            "fpr": 0.1712403951701427,
            "logloss": 0.676282037128142,
            "mae": 0.29355416447743055,
            "precision": 0.7209302325581395,
            "recall": 0.8174442190669371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7954674409042732,
            "auditor_fn_violation": 0.009454561022947828,
            "auditor_fp_violation": 0.025802796903567123,
            "ave_precision_score": 0.7959131716943737,
            "fpr": 0.15350877192982457,
            "logloss": 0.7469449314963069,
            "mae": 0.28280778285178604,
            "precision": 0.7188755020080321,
            "recall": 0.7765726681127982
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8263921338296967,
            "auditor_fn_violation": 0.022488271587070806,
            "auditor_fp_violation": 0.023629325784274086,
            "ave_precision_score": 0.826712300550956,
            "fpr": 0.14489571899012074,
            "logloss": 0.7351514532439326,
            "mae": 0.2888113846949225,
            "precision": 0.7375745526838966,
            "recall": 0.7525354969574036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.793101060341896,
            "auditor_fn_violation": 0.013276820032728245,
            "auditor_fp_violation": 0.013257575757575758,
            "ave_precision_score": 0.7789278846676193,
            "fpr": 0.09978070175438597,
            "logloss": 3.9148082260092734,
            "mae": 0.2686814091356242,
            "precision": 0.7828162291169452,
            "recall": 0.7114967462039046
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8462901460559263,
            "auditor_fn_violation": 0.013134486543775317,
            "auditor_fp_violation": 0.007232180841285936,
            "ave_precision_score": 0.8315631774409975,
            "fpr": 0.09220636663007684,
            "logloss": 4.07142165553329,
            "mae": 0.2803430922227706,
            "precision": 0.8041958041958042,
            "recall": 0.6997971602434077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8340853801967743,
            "auditor_fn_violation": 0.01240628686684173,
            "auditor_fp_violation": 0.019661473528610886,
            "ave_precision_score": 0.8343605027983059,
            "fpr": 0.15021929824561403,
            "logloss": 0.5972892957123682,
            "mae": 0.28214100145106114,
            "precision": 0.7232323232323232,
            "recall": 0.7765726681127982
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8628780912143679,
            "auditor_fn_violation": 0.01924862454160664,
            "auditor_fp_violation": 0.02466924721243284,
            "ave_precision_score": 0.8630460145226411,
            "fpr": 0.14489571899012074,
            "logloss": 0.5836313824602164,
            "mae": 0.28816727404468606,
            "precision": 0.7386138613861386,
            "recall": 0.7565922920892495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7631749892725879,
            "auditor_fn_violation": 0.015469802488868598,
            "auditor_fp_violation": 0.03485918232388067,
            "ave_precision_score": 0.7648724342840929,
            "fpr": 0.23903508771929824,
            "logloss": 0.9928862321906688,
            "mae": 0.32501826254690774,
            "precision": 0.6489533011272142,
            "recall": 0.8741865509761388
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7837743429237145,
            "auditor_fn_violation": 0.0218203031240885,
            "auditor_fp_violation": 0.030798481084459494,
            "ave_precision_score": 0.7845285547127929,
            "fpr": 0.2327113062568606,
            "logloss": 0.9946656926735177,
            "mae": 0.31807974545594647,
            "precision": 0.6692667706708268,
            "recall": 0.8701825557809331
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8286389446952785,
            "auditor_fn_violation": 0.015938368154659967,
            "auditor_fp_violation": 0.03129984051036683,
            "ave_precision_score": 0.8299646532207501,
            "fpr": 0.13486842105263158,
            "logloss": 0.6187231611284378,
            "mae": 0.26961244608472107,
            "precision": 0.7453416149068323,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8732572422824301,
            "auditor_fn_violation": 0.023180732227029117,
            "auditor_fp_violation": 0.025107799935924036,
            "ave_precision_score": 0.8734007178456134,
            "fpr": 0.1437980241492865,
            "logloss": 0.6116263282471811,
            "mae": 0.2771823061023763,
            "precision": 0.7421259842519685,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7924789722101536,
            "auditor_fn_violation": 0.007406667427788563,
            "auditor_fp_violation": 0.021684268876181582,
            "ave_precision_score": 0.7930804439112809,
            "fpr": 0.15460526315789475,
            "logloss": 0.7825016401115661,
            "mae": 0.28079351609038594,
            "precision": 0.7196819085487077,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8137191665827039,
            "auditor_fn_violation": 0.01859624200942726,
            "auditor_fp_violation": 0.019044217669210453,
            "ave_precision_score": 0.8141235255962684,
            "fpr": 0.13611416026344675,
            "logloss": 0.806069668655956,
            "mae": 0.2921159887959149,
            "precision": 0.7484787018255578,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7370920823935052,
            "auditor_fn_violation": 0.04215426037979982,
            "auditor_fp_violation": 0.007976912903100333,
            "ave_precision_score": 0.723014308408173,
            "fpr": 0.14802631578947367,
            "logloss": 4.1423204335563035,
            "mae": 0.3137666982491187,
            "precision": 0.6993318485523385,
            "recall": 0.6811279826464208
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8078274480605797,
            "auditor_fn_violation": 0.03174854104554877,
            "auditor_fp_violation": 0.016601977951564872,
            "ave_precision_score": 0.7936062521647709,
            "fpr": 0.11745334796926454,
            "logloss": 4.225479574713329,
            "mae": 0.2892587961890724,
            "precision": 0.7627494456762749,
            "recall": 0.6977687626774848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.791665987203787,
            "auditor_fn_violation": 0.022239030330707468,
            "auditor_fp_violation": 0.025914634146341466,
            "ave_precision_score": 0.7589648090251588,
            "fpr": 0.1524122807017544,
            "logloss": 3.3702664833513323,
            "mae": 0.26754317936681155,
            "precision": 0.7236580516898609,
            "recall": 0.789587852494577
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7975844693592067,
            "auditor_fn_violation": 0.030800025828113906,
            "auditor_fp_violation": 0.027951827478085497,
            "ave_precision_score": 0.7692699448386874,
            "fpr": 0.15477497255762898,
            "logloss": 3.808351387195608,
            "mae": 0.2840403280540281,
            "precision": 0.7277992277992278,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6958407885113118,
            "auditor_fn_violation": 0.0023808844236404454,
            "auditor_fp_violation": 0.015674232699264795,
            "ave_precision_score": 0.6847523735224572,
            "fpr": 0.25219298245614036,
            "logloss": 1.997823335766599,
            "mae": 0.3424251211126204,
            "precision": 0.6466973886328725,
            "recall": 0.913232104121475
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.690455842280399,
            "auditor_fn_violation": 0.011090503047049474,
            "auditor_fp_violation": 0.01466919469114859,
            "ave_precision_score": 0.6842608051770187,
            "fpr": 0.24478594950603733,
            "logloss": 2.073461169536786,
            "mae": 0.3461976464297582,
            "precision": 0.6646616541353384,
            "recall": 0.896551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8201632491563103,
            "auditor_fn_violation": 0.005901073181870078,
            "auditor_fp_violation": 0.027334480880693974,
            "ave_precision_score": 0.8205636165595248,
            "fpr": 0.14583333333333334,
            "logloss": 0.6409235053712857,
            "mae": 0.2825283197732795,
            "precision": 0.7274590163934426,
            "recall": 0.7700650759219089
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.862580607676668,
            "auditor_fn_violation": 0.02128147523061612,
            "auditor_fp_violation": 0.019065226182910636,
            "ave_precision_score": 0.8627405332026694,
            "fpr": 0.14489571899012074,
            "logloss": 0.6105289560313292,
            "mae": 0.2867934896614383,
            "precision": 0.736,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8187481806097533,
            "auditor_fn_violation": 0.00806075655516231,
            "auditor_fp_violation": 0.0269503442642082,
            "ave_precision_score": 0.8201086442737237,
            "fpr": 0.14364035087719298,
            "logloss": 0.595767571183442,
            "mae": 0.2762989751930977,
            "precision": 0.733739837398374,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.864162007961567,
            "auditor_fn_violation": 0.02076045982948992,
            "auditor_fp_violation": 0.02373436835277496,
            "ave_precision_score": 0.864326869575309,
            "fpr": 0.141602634467618,
            "logloss": 0.5812874708982716,
            "mae": 0.28280859699732963,
            "precision": 0.7425149700598802,
            "recall": 0.7545638945233266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8582184691428807,
            "auditor_fn_violation": 0.0065813258743387774,
            "auditor_fp_violation": 0.021582156611039793,
            "ave_precision_score": 0.8584442692480875,
            "fpr": 0.14473684210526316,
            "logloss": 0.5230239511092328,
            "mae": 0.26907289011966534,
            "precision": 0.7416829745596869,
            "recall": 0.8221258134490239
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8788793051910981,
            "auditor_fn_violation": 0.015846438503483464,
            "auditor_fp_violation": 0.009532613091455311,
            "ave_precision_score": 0.8790914837044617,
            "fpr": 0.1207464324917673,
            "logloss": 0.5047039544843238,
            "mae": 0.2686411812385277,
            "precision": 0.7859922178988327,
            "recall": 0.8194726166328601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 26311,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8012466915744335,
            "auditor_fn_violation": 0.016452125432888078,
            "auditor_fp_violation": 0.017033298323413864,
            "ave_precision_score": 0.7976660135500736,
            "fpr": 0.11074561403508772,
            "logloss": 2.8564267220823427,
            "mae": 0.27554560505640874,
            "precision": 0.7709750566893424,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8582676322534633,
            "auditor_fn_violation": 0.01533210278698709,
            "auditor_fp_violation": 0.015572560780256203,
            "ave_precision_score": 0.853409920294255,
            "fpr": 0.10757409440175632,
            "logloss": 2.813185992755067,
            "mae": 0.28050618899396,
            "precision": 0.7855579868708972,
            "recall": 0.7281947261663286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.744597971010659,
            "auditor_fn_violation": 0.002932697796552118,
            "auditor_fp_violation": 0.01876920683082429,
            "ave_precision_score": 0.5201892839513728,
            "fpr": 0.44298245614035087,
            "logloss": 15.130857443397836,
            "mae": 0.4564012130965255,
            "precision": 0.5291375291375291,
            "recall": 0.9848156182212582
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.771277708053005,
            "auditor_fn_violation": 0.005252458680584161,
            "auditor_fp_violation": 0.009774210999007367,
            "ave_precision_score": 0.5662806278858137,
            "fpr": 0.4061470911086718,
            "logloss": 13.590875256096465,
            "mae": 0.41632997164759716,
            "precision": 0.5677570093457944,
            "recall": 0.9858012170385395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7902282058831043,
            "auditor_fn_violation": 0.05305971001255851,
            "auditor_fp_violation": 0.02148490683471429,
            "ave_precision_score": 0.79082804149163,
            "fpr": 0.15460526315789475,
            "logloss": 0.9756569543367699,
            "mae": 0.2989117800723532,
            "precision": 0.7110655737704918,
            "recall": 0.7527114967462039
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8406331425933414,
            "auditor_fn_violation": 0.04541962892125321,
            "auditor_fp_violation": 0.02470601211140815,
            "ave_precision_score": 0.84092617267736,
            "fpr": 0.12952799121844127,
            "logloss": 0.973612713820672,
            "mae": 0.2816447083564431,
            "precision": 0.7635270541082164,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8203750606089748,
            "auditor_fn_violation": 0.00779436389237737,
            "auditor_fp_violation": 0.008020675302446807,
            "ave_precision_score": 0.810928352195979,
            "fpr": 0.11732456140350878,
            "logloss": 2.504504705787118,
            "mae": 0.2525281869099231,
            "precision": 0.7584650112866818,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8304463666429385,
            "auditor_fn_violation": 0.00027609363136602623,
            "auditor_fp_violation": 0.009330406147091106,
            "ave_precision_score": 0.82135286956101,
            "fpr": 0.10208562019758508,
            "logloss": 2.8044118791583883,
            "mae": 0.26460798258581125,
            "precision": 0.7871853546910755,
            "recall": 0.6977687626774848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8207562931469798,
            "auditor_fn_violation": 0.008281957605510523,
            "auditor_fp_violation": 0.020551308981989338,
            "ave_precision_score": 0.8211868182517827,
            "fpr": 0.13048245614035087,
            "logloss": 0.7394614806341522,
            "mae": 0.2682617515051113,
            "precision": 0.7515657620041754,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8518242442918227,
            "auditor_fn_violation": 0.01922858548771718,
            "auditor_fp_violation": 0.021021644021239613,
            "ave_precision_score": 0.8520600222764563,
            "fpr": 0.11964873765093303,
            "logloss": 0.7093106782870573,
            "mae": 0.27299951729546185,
            "precision": 0.7743271221532091,
            "recall": 0.7586206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 26311,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7900155136073903,
            "auditor_fn_violation": 0.021618240286181832,
            "auditor_fp_violation": 0.03590947990819622,
            "ave_precision_score": 0.7910383182142933,
            "fpr": 0.14583333333333334,
            "logloss": 0.6899149144874197,
            "mae": 0.2880529540104917,
            "precision": 0.7302231237322515,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8487636284614299,
            "auditor_fn_violation": 0.034046352558207885,
            "auditor_fp_violation": 0.03301487927982815,
            "ave_precision_score": 0.8489774740164148,
            "fpr": 0.15148188803512624,
            "logloss": 0.6581932168637128,
            "mae": 0.2908358233924613,
            "precision": 0.7325581395348837,
            "recall": 0.7667342799188641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7966645957192102,
            "auditor_fn_violation": 0.01579565779959661,
            "auditor_fp_violation": 0.026019177655891394,
            "ave_precision_score": 0.7970671687714963,
            "fpr": 0.1787280701754386,
            "logloss": 0.8519779501973757,
            "mae": 0.315711442585381,
            "precision": 0.7014652014652014,
            "recall": 0.8308026030368764
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8310145968694337,
            "auditor_fn_violation": 0.0207359676525139,
            "auditor_fp_violation": 0.019291067705187532,
            "ave_precision_score": 0.8312345784356845,
            "fpr": 0.17672886937431395,
            "logloss": 0.7642987451138117,
            "mae": 0.3126683888729952,
            "precision": 0.7185314685314685,
            "recall": 0.8336713995943205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6849935281524224,
            "auditor_fn_violation": 0.09154631426722991,
            "auditor_fp_violation": 0.045410783055198974,
            "ave_precision_score": 0.6848661435102436,
            "fpr": 0.09758771929824561,
            "logloss": 7.447451523816476,
            "mae": 0.37366194900732164,
            "precision": 0.7119741100323624,
            "recall": 0.4772234273318872
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7407721465802962,
            "auditor_fn_violation": 0.09984569928505109,
            "auditor_fp_violation": 0.035281172695234744,
            "ave_precision_score": 0.7392393804944533,
            "fpr": 0.08232711306256861,
            "logloss": 8.184844931558034,
            "mae": 0.37840093588988954,
            "precision": 0.7491638795986622,
            "recall": 0.4543610547667343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8189274911724003,
            "auditor_fn_violation": 0.008662518552346158,
            "auditor_fp_violation": 0.021540825456101458,
            "ave_precision_score": 0.8192764107772308,
            "fpr": 0.14144736842105263,
            "logloss": 0.6366218924088268,
            "mae": 0.2843816775395617,
            "precision": 0.7306889352818372,
            "recall": 0.7592190889370932
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8621200791961372,
            "auditor_fn_violation": 0.024452098868238768,
            "auditor_fp_violation": 0.02389718433395134,
            "ave_precision_score": 0.8622769157523835,
            "fpr": 0.1437980241492865,
            "logloss": 0.6047823304642848,
            "mae": 0.28960520449607163,
            "precision": 0.7374749498997996,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8191552461548343,
            "auditor_fn_violation": 0.009694790120637824,
            "auditor_fp_violation": 0.02938158867234606,
            "ave_precision_score": 0.8195054585162669,
            "fpr": 0.13925438596491227,
            "logloss": 0.6336861745727123,
            "mae": 0.27550633278926334,
            "precision": 0.7370600414078675,
            "recall": 0.7722342733188721
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8646590840738655,
            "auditor_fn_violation": 0.02840201904600744,
            "auditor_fp_violation": 0.02108729562655266,
            "ave_precision_score": 0.8648245733085825,
            "fpr": 0.132821075740944,
            "logloss": 0.6014033152392458,
            "mae": 0.28024161735020015,
            "precision": 0.753061224489796,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6715553303260678,
            "auditor_fn_violation": 0.014487479544849108,
            "auditor_fp_violation": 0.024003676041545116,
            "ave_precision_score": 0.671218985233586,
            "fpr": 0.20175438596491227,
            "logloss": 1.356207519453979,
            "mae": 0.34414088617898386,
            "precision": 0.6541353383458647,
            "recall": 0.754880694143167
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7341912451808216,
            "auditor_fn_violation": 0.01589764941897877,
            "auditor_fp_violation": 0.026005913896606603,
            "ave_precision_score": 0.7346688793413868,
            "fpr": 0.18331503841931943,
            "logloss": 1.1303707475349047,
            "mae": 0.32282324581651994,
            "precision": 0.6913123844731978,
            "recall": 0.7586206896551724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7807171745204492,
            "auditor_fn_violation": 0.0167684667199452,
            "auditor_fp_violation": 0.030446473723110438,
            "ave_precision_score": 0.7818113131062474,
            "fpr": 0.1699561403508772,
            "logloss": 0.5578446028686563,
            "mae": 0.3014983105979474,
            "precision": 0.7150735294117647,
            "recall": 0.8438177874186551
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8293494445377582,
            "auditor_fn_violation": 0.02255506843336904,
            "auditor_fp_violation": 0.022552639457140013,
            "ave_precision_score": 0.8297682199068033,
            "fpr": 0.1668496158068057,
            "logloss": 0.5582448168164877,
            "mae": 0.30010281175707365,
            "precision": 0.7295373665480427,
            "recall": 0.8316430020283976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 26311,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8264995110354557,
            "auditor_fn_violation": 0.004811717471553076,
            "auditor_fp_violation": 0.0016216400202279542,
            "ave_precision_score": 0.8222939150375109,
            "fpr": 0.11513157894736842,
            "logloss": 2.268720442050207,
            "mae": 0.25249846578374124,
            "precision": 0.7597254004576659,
            "recall": 0.720173535791757
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8413008988463572,
            "auditor_fn_violation": 0.0013982806491762872,
            "auditor_fp_violation": 0.008471683149596374,
            "ave_precision_score": 0.8373016541352947,
            "fpr": 0.0889132821075741,
            "logloss": 2.4800011539865254,
            "mae": 0.25604770328455484,
            "precision": 0.8085106382978723,
            "recall": 0.6937119675456389
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7415573832979836,
            "auditor_fn_violation": 0.01078176732503711,
            "auditor_fp_violation": 0.010400863578013774,
            "ave_precision_score": 0.7272387275929695,
            "fpr": 0.14912280701754385,
            "logloss": 3.9592906449265453,
            "mae": 0.31169418942309884,
            "precision": 0.7049891540130152,
            "recall": 0.7049891540130152
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7655758343107617,
            "auditor_fn_violation": 0.006252184813514341,
            "auditor_fp_violation": 0.008442796443258639,
            "ave_precision_score": 0.7514745781022859,
            "fpr": 0.12403951701427003,
            "logloss": 4.122449504804586,
            "mae": 0.30748242871418213,
            "precision": 0.7610993657505285,
            "recall": 0.7302231237322515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8227283681875042,
            "auditor_fn_violation": 0.017289359515926476,
            "auditor_fp_violation": 0.017680009335978526,
            "ave_precision_score": 0.8230927352770527,
            "fpr": 0.11513157894736842,
            "logloss": 1.4779811334486714,
            "mae": 0.28136721684736465,
            "precision": 0.7640449438202247,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8638910408888357,
            "auditor_fn_violation": 0.01679050059783178,
            "auditor_fp_violation": 0.020877210489550897,
            "ave_precision_score": 0.8640006894295822,
            "fpr": 0.10318331503841932,
            "logloss": 1.9591459895495753,
            "mae": 0.2932789677405175,
            "precision": 0.7906458797327395,
            "recall": 0.7200811359026369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 26311,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8169446805572541,
            "auditor_fn_violation": 0.009349906762568026,
            "auditor_fp_violation": 0.027268837281674254,
            "ave_precision_score": 0.8173443122387984,
            "fpr": 0.12938596491228072,
            "logloss": 0.837034248308103,
            "mae": 0.26211709448068077,
            "precision": 0.751578947368421,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8506734595376662,
            "auditor_fn_violation": 0.020346319382440893,
            "auditor_fp_violation": 0.01342969238283815,
            "ave_precision_score": 0.8510167493870036,
            "fpr": 0.1141602634467618,
            "logloss": 0.8213449274165865,
            "mae": 0.26011428682934035,
            "precision": 0.7819706498951782,
            "recall": 0.7565922920892495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7924023777665822,
            "auditor_fn_violation": 0.01209232408570233,
            "auditor_fp_violation": 0.010442194732952112,
            "ave_precision_score": 0.7782303925502543,
            "fpr": 0.09868421052631579,
            "logloss": 3.9042074889479563,
            "mae": 0.2700357170328253,
            "precision": 0.7831325301204819,
            "recall": 0.7049891540130152
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8487679872775025,
            "auditor_fn_violation": 0.011658276240584431,
            "auditor_fp_violation": 0.008030504361892656,
            "ave_precision_score": 0.8340375569832685,
            "fpr": 0.09110867178924259,
            "logloss": 4.055858576828566,
            "mae": 0.28002700988002915,
            "precision": 0.8056206088992974,
            "recall": 0.6977687626774848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6441931472328986,
            "auditor_fn_violation": 0.015077349012444344,
            "auditor_fp_violation": 0.05631977671451357,
            "ave_precision_score": 0.5451970448794021,
            "fpr": 0.3223684210526316,
            "logloss": 7.361061836741051,
            "mae": 0.39126343133077107,
            "precision": 0.5893854748603352,
            "recall": 0.9154013015184381
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6756139994502406,
            "auditor_fn_violation": 0.018997023087216642,
            "auditor_fp_violation": 0.06628711285248348,
            "ave_precision_score": 0.5790683381466454,
            "fpr": 0.287596048298573,
            "logloss": 7.1532115501547615,
            "mae": 0.3590899074981927,
            "precision": 0.6299435028248588,
            "recall": 0.9046653144016227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.802950494206186,
            "auditor_fn_violation": 0.011335959203866507,
            "auditor_fp_violation": 0.031632920994281714,
            "ave_precision_score": 0.80380269594182,
            "fpr": 0.14912280701754385,
            "logloss": 0.6634426214691181,
            "mae": 0.29231947419254556,
            "precision": 0.7241379310344828,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.852748191757875,
            "auditor_fn_violation": 0.026166551256560013,
            "auditor_fp_violation": 0.024044243929852573,
            "ave_precision_score": 0.8529236936279543,
            "fpr": 0.14818880351262348,
            "logloss": 0.6301406264629361,
            "mae": 0.2951513758590128,
            "precision": 0.7352941176470589,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8244724803616124,
            "auditor_fn_violation": 0.004742740799939113,
            "auditor_fp_violation": 0.023271871474695612,
            "ave_precision_score": 0.8247966342966013,
            "fpr": 0.14583333333333334,
            "logloss": 0.6268659190416385,
            "mae": 0.282789814976416,
            "precision": 0.7291242362525459,
            "recall": 0.7765726681127982
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8658099747169763,
            "auditor_fn_violation": 0.021695615677665144,
            "auditor_fp_violation": 0.024495926974406383,
            "ave_precision_score": 0.8659687133619098,
            "fpr": 0.13172338090010977,
            "logloss": 0.5760175990089821,
            "mae": 0.28182799928835933,
            "precision": 0.7556008146639511,
            "recall": 0.7525354969574036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8247505602208298,
            "auditor_fn_violation": 0.005199413936141879,
            "auditor_fp_violation": 0.01236287781538103,
            "ave_precision_score": 0.8251078510707117,
            "fpr": 0.11293859649122807,
            "logloss": 0.6244419342688468,
            "mae": 0.2721711394024488,
            "precision": 0.7690582959641256,
            "recall": 0.7440347071583514
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8523688882973194,
            "auditor_fn_violation": 0.01153136223261779,
            "auditor_fp_violation": 0.016654499235815315,
            "ave_precision_score": 0.8525761202394357,
            "fpr": 0.10318331503841932,
            "logloss": 0.6127338751975991,
            "mae": 0.28010619122434804,
            "precision": 0.7952069716775599,
            "recall": 0.7403651115618661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8041945465845496,
            "auditor_fn_violation": 0.018224112341591506,
            "auditor_fp_violation": 0.026320651962500486,
            "ave_precision_score": 0.8055418931681102,
            "fpr": 0.16337719298245615,
            "logloss": 0.6674717827546763,
            "mae": 0.2976335415413926,
            "precision": 0.7084148727984344,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8416878466978273,
            "auditor_fn_violation": 0.019593741580814165,
            "auditor_fp_violation": 0.02198015745881019,
            "ave_precision_score": 0.8423841445181485,
            "fpr": 0.14928649835345773,
            "logloss": 0.630698710042782,
            "mae": 0.29623538418468515,
            "precision": 0.7374517374517374,
            "recall": 0.7748478701825557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8223732032045863,
            "auditor_fn_violation": 0.005901073181870077,
            "auditor_fp_violation": 0.026644007468782826,
            "ave_precision_score": 0.8227028921661197,
            "fpr": 0.1337719298245614,
            "logloss": 0.6240997814374529,
            "mae": 0.282823515350046,
            "precision": 0.7426160337552743,
            "recall": 0.7635574837310195
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8626615969656555,
            "auditor_fn_violation": 0.023198544719375314,
            "auditor_fp_violation": 0.019325206539950318,
            "ave_precision_score": 0.8628315700306417,
            "fpr": 0.132821075740944,
            "logloss": 0.583434466208294,
            "mae": 0.28467318210343173,
            "precision": 0.7489626556016598,
            "recall": 0.7322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7445742427644573,
            "auditor_fn_violation": 0.0029659968794002365,
            "auditor_fp_violation": 0.01778698408993661,
            "ave_precision_score": 0.5201655561438538,
            "fpr": 0.44298245614035087,
            "logloss": 15.121821657997614,
            "mae": 0.4570669394157763,
            "precision": 0.5291375291375291,
            "recall": 0.9848156182212582
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.771239314427469,
            "auditor_fn_violation": 0.0043818731171638954,
            "auditor_fp_violation": 0.010215389786711077,
            "ave_precision_score": 0.5662422387896537,
            "fpr": 0.40504939626783754,
            "logloss": 13.587897955155723,
            "mae": 0.4172580019205233,
            "precision": 0.5679156908665105,
            "recall": 0.9837728194726166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.7659394820379126,
            "auditor_fn_violation": 0.0070165924572820355,
            "auditor_fp_violation": 0.012161084529505588,
            "ave_precision_score": 0.7667218083079423,
            "fpr": 0.13486842105263158,
            "logloss": 0.6541300578585092,
            "mae": 0.2806540977056631,
            "precision": 0.7554671968190855,
            "recall": 0.824295010845987
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7392229994581546,
            "auditor_fn_violation": 0.007124996938477878,
            "auditor_fp_violation": 0.013989044060105366,
            "ave_precision_score": 0.7403372982674219,
            "fpr": 0.12403951701427003,
            "logloss": 0.7400881106703426,
            "mae": 0.29968047285348065,
            "precision": 0.77079107505071,
            "recall": 0.77079107505071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8090075916104491,
            "auditor_fn_violation": 0.005028161510065845,
            "auditor_fp_violation": 0.022822091259190106,
            "ave_precision_score": 0.8092568417053854,
            "fpr": 0.12719298245614036,
            "logloss": 1.459713326999751,
            "mae": 0.2725984122018793,
            "precision": 0.7494600431965442,
            "recall": 0.7527114967462039
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8411845452799399,
            "auditor_fn_violation": 0.01579300102644488,
            "auditor_fp_violation": 0.015349345322191827,
            "ave_precision_score": 0.8413272389856699,
            "fpr": 0.11525795828759605,
            "logloss": 1.126956060460552,
            "mae": 0.2741671264236434,
            "precision": 0.7751605995717344,
            "recall": 0.7342799188640974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8000671202711852,
            "auditor_fn_violation": 0.012993777828519234,
            "auditor_fp_violation": 0.03174475823705607,
            "ave_precision_score": 0.8005964040813323,
            "fpr": 0.1513157894736842,
            "logloss": 0.6679542731371321,
            "mae": 0.29072619530173444,
            "precision": 0.7212121212121212,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8048740422674859,
            "auditor_fn_violation": 0.02219436546335859,
            "auditor_fp_violation": 0.027431866764006118,
            "ave_precision_score": 0.8064675815737403,
            "fpr": 0.14818880351262348,
            "logloss": 0.6575559068022079,
            "mae": 0.299162242168118,
            "precision": 0.731610337972167,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8294663374520154,
            "auditor_fn_violation": 0.016054914944628382,
            "auditor_fp_violation": 0.0324984440035788,
            "ave_precision_score": 0.8307978854871936,
            "fpr": 0.13596491228070176,
            "logloss": 0.6028039695489499,
            "mae": 0.2701051743965205,
            "precision": 0.7443298969072165,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8738240188640749,
            "auditor_fn_violation": 0.02279331051849939,
            "auditor_fp_violation": 0.024942357890535144,
            "ave_precision_score": 0.8739676563077994,
            "fpr": 0.141602634467618,
            "logloss": 0.5903234445203184,
            "mae": 0.27674382042348095,
            "precision": 0.7460629921259843,
            "recall": 0.768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.5968964435391048,
            "auditor_fn_violation": 0.011350230239372839,
            "auditor_fp_violation": 0.02011368498852454,
            "ave_precision_score": 0.5839959743972813,
            "fpr": 0.18201754385964913,
            "logloss": 4.064237531508888,
            "mae": 0.3248626541049465,
            "precision": 0.6856060606060606,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6350572113844495,
            "auditor_fn_violation": 0.011135034277914957,
            "auditor_fp_violation": 0.008524204433846811,
            "ave_precision_score": 0.6196620106689256,
            "fpr": 0.1756311745334797,
            "logloss": 3.6326427078366006,
            "mae": 0.32204990044283976,
            "precision": 0.7053406998158379,
            "recall": 0.7768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8068442914139369,
            "auditor_fn_violation": 0.0057583628268067155,
            "auditor_fp_violation": 0.02869597774925118,
            "ave_precision_score": 0.8072475621879351,
            "fpr": 0.15021929824561403,
            "logloss": 0.8864508064133536,
            "mae": 0.2711954465199043,
            "precision": 0.7276341948310139,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8251275024720216,
            "auditor_fn_violation": 0.017957218846507535,
            "auditor_fp_violation": 0.023634577912699118,
            "ave_precision_score": 0.8254712259909339,
            "fpr": 0.14050493962678376,
            "logloss": 0.8981701725867183,
            "mae": 0.28226703141311466,
            "precision": 0.744,
            "recall": 0.7545638945233266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8122800296945506,
            "auditor_fn_violation": 0.011652300490923622,
            "auditor_fp_violation": 0.029999124752013072,
            "ave_precision_score": 0.8136403102969509,
            "fpr": 0.13925438596491227,
            "logloss": 0.6360141001884063,
            "mae": 0.28018432436389656,
            "precision": 0.7397540983606558,
            "recall": 0.7830802603036876
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8606421402918549,
            "auditor_fn_violation": 0.02675436350398443,
            "auditor_fp_violation": 0.023692351325374613,
            "ave_precision_score": 0.8608092465507062,
            "fpr": 0.13611416026344675,
            "logloss": 0.6103483386899307,
            "mae": 0.2856361219708263,
            "precision": 0.7479674796747967,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7402859330257607,
            "auditor_fn_violation": 0.014977451763899988,
            "auditor_fp_violation": 0.03437293344225312,
            "ave_precision_score": 0.7423160773481308,
            "fpr": 0.29714912280701755,
            "logloss": 1.1595701420013695,
            "mae": 0.3622245240703067,
            "precision": 0.6078147612156295,
            "recall": 0.911062906724512
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7499470363876877,
            "auditor_fn_violation": 0.020076905435704697,
            "auditor_fp_violation": 0.03343767561804422,
            "ave_precision_score": 0.7522418985085801,
            "fpr": 0.29088913282107576,
            "logloss": 1.1494649834016097,
            "mae": 0.3549622608631044,
            "precision": 0.6262341325811002,
            "recall": 0.9006085192697769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8186898179897023,
            "auditor_fn_violation": 0.0042932031814895185,
            "auditor_fp_violation": 0.025763896993036918,
            "ave_precision_score": 0.8190758540773573,
            "fpr": 0.17434210526315788,
            "logloss": 0.8758733375762201,
            "mae": 0.2763955944895851,
            "precision": 0.7071823204419889,
            "recall": 0.8329718004338394
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8392149650262697,
            "auditor_fn_violation": 0.018284523393368862,
            "auditor_fp_violation": 0.025288998366588062,
            "ave_precision_score": 0.8394972808494794,
            "fpr": 0.15587266739846323,
            "logloss": 0.9036962716989864,
            "mae": 0.28279315691230955,
            "precision": 0.7404021937842779,
            "recall": 0.821501014198783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7879292397569768,
            "auditor_fn_violation": 0.05702230087148458,
            "auditor_fp_violation": 0.032111876142684875,
            "ave_precision_score": 0.7886017985642235,
            "fpr": 0.14692982456140352,
            "logloss": 0.8247744632986787,
            "mae": 0.3135314280524745,
            "precision": 0.7202505219206681,
            "recall": 0.7483731019522777
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8265563592773513,
            "auditor_fn_violation": 0.051478102880502676,
            "auditor_fp_violation": 0.027489640176681616,
            "ave_precision_score": 0.8268071158067096,
            "fpr": 0.1394072447859495,
            "logloss": 0.8460626151556897,
            "mae": 0.30663088560086976,
            "precision": 0.742914979757085,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7939092480678339,
            "auditor_fn_violation": 0.009533051718232677,
            "auditor_fp_violation": 0.023339946318123472,
            "ave_precision_score": 0.7943900617166053,
            "fpr": 0.15570175438596492,
            "logloss": 0.7199729871193934,
            "mae": 0.28541788112440036,
            "precision": 0.7204724409448819,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8221168599118398,
            "auditor_fn_violation": 0.01996335079699771,
            "auditor_fp_violation": 0.016213320448111607,
            "ave_precision_score": 0.8224826209419804,
            "fpr": 0.13830954994511527,
            "logloss": 0.7297312658309697,
            "mae": 0.29366704951980394,
            "precision": 0.7454545454545455,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8057488861439684,
            "auditor_fn_violation": 0.006705008182060363,
            "auditor_fp_violation": 0.02573472206013926,
            "ave_precision_score": 0.8060685000297851,
            "fpr": 0.15460526315789475,
            "logloss": 0.6663364059783072,
            "mae": 0.3022950937955644,
            "precision": 0.7157258064516129,
            "recall": 0.7700650759219089
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8465098923219818,
            "auditor_fn_violation": 0.01934436668796744,
            "auditor_fp_violation": 0.026260642125221254,
            "ave_precision_score": 0.8466974634749546,
            "fpr": 0.15367727771679474,
            "logloss": 0.6257528545564579,
            "mae": 0.3019914667931734,
            "precision": 0.724950884086444,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8281379476666565,
            "auditor_fn_violation": 0.0159312326369068,
            "auditor_fp_violation": 0.019031781226903178,
            "ave_precision_score": 0.8267327527379889,
            "fpr": 0.11074561403508772,
            "logloss": 1.7742905047996822,
            "mae": 0.25914865494095257,
            "precision": 0.7770419426048565,
            "recall": 0.7635574837310195
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8640821807200718,
            "auditor_fn_violation": 0.01718905511407788,
            "auditor_fp_violation": 0.01756311745334797,
            "ave_precision_score": 0.8625482188542595,
            "fpr": 0.09659714599341383,
            "logloss": 1.5933766243071033,
            "mae": 0.2604106656052954,
            "precision": 0.8057395143487859,
            "recall": 0.7403651115618661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 26311,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7842938798774413,
            "auditor_fn_violation": 0.014021292384975459,
            "auditor_fp_violation": 0.010670731707317077,
            "ave_precision_score": 0.7672033019652216,
            "fpr": 0.09758771929824561,
            "logloss": 4.387503918055042,
            "mae": 0.2778189420452946,
            "precision": 0.7802469135802469,
            "recall": 0.6854663774403471
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8475734445382279,
            "auditor_fn_violation": 0.018823351286841258,
            "auditor_fp_violation": 0.00652839563233,
            "ave_precision_score": 0.8306017073785741,
            "fpr": 0.08562019758507135,
            "logloss": 4.310346143589456,
            "mae": 0.28094447782221244,
            "precision": 0.8129496402877698,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8232226817051291,
            "auditor_fn_violation": 0.009663869543707425,
            "auditor_fp_violation": 0.02603619636674836,
            "ave_precision_score": 0.8214776607078783,
            "fpr": 0.1600877192982456,
            "logloss": 0.8541850258443839,
            "mae": 0.28835352295866695,
            "precision": 0.7234848484848485,
            "recall": 0.8286334056399133
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8397852032963349,
            "auditor_fn_violation": 0.019377765111116555,
            "auditor_fp_violation": 0.029435553758160503,
            "ave_precision_score": 0.8390233279259707,
            "fpr": 0.15697036223929747,
            "logloss": 0.7721034618783131,
            "mae": 0.29396038288179005,
            "precision": 0.7342007434944238,
            "recall": 0.8012170385395537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8083066241414428,
            "auditor_fn_violation": 0.010246603493549488,
            "auditor_fp_violation": 0.028567121795619873,
            "ave_precision_score": 0.8095486086432306,
            "fpr": 0.1337719298245614,
            "logloss": 1.4108390866487255,
            "mae": 0.26180222348035853,
            "precision": 0.7468879668049793,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8579837677471129,
            "auditor_fn_violation": 0.021372764253890356,
            "auditor_fp_violation": 0.015966470412134528,
            "ave_precision_score": 0.8580759167908245,
            "fpr": 0.11964873765093303,
            "logloss": 1.058196897955869,
            "mae": 0.2602397677824403,
            "precision": 0.7775510204081633,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8342317398922081,
            "auditor_fn_violation": 0.013407637858202993,
            "auditor_fp_violation": 0.028029816781421402,
            "ave_precision_score": 0.8347358805451672,
            "fpr": 0.15021929824561403,
            "logloss": 0.6530258837099044,
            "mae": 0.2636492441738431,
            "precision": 0.7380497131931166,
            "recall": 0.8373101952277657
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8666975090001029,
            "auditor_fn_violation": 0.016721477189990275,
            "auditor_fp_violation": 0.02099275731490187,
            "ave_precision_score": 0.8670511028321647,
            "fpr": 0.13391877058177826,
            "logloss": 0.6403059008695038,
            "mae": 0.26152172884872144,
            "precision": 0.7715355805243446,
            "recall": 0.8356997971602435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7952915138087011,
            "auditor_fn_violation": 0.005882045134528303,
            "auditor_fp_violation": 0.020806589644843818,
            "ave_precision_score": 0.7910409031053929,
            "fpr": 0.11732456140350878,
            "logloss": 2.790337857892837,
            "mae": 0.2914724151315152,
            "precision": 0.7505827505827506,
            "recall": 0.6984815618221258
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8397805451184425,
            "auditor_fn_violation": 0.01670589125918735,
            "auditor_fp_violation": 0.020856201975850714,
            "ave_precision_score": 0.8350625492544351,
            "fpr": 0.1141602634467618,
            "logloss": 2.7587726827696244,
            "mae": 0.2972511232036212,
            "precision": 0.7581395348837209,
            "recall": 0.6612576064908722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8189826830254019,
            "auditor_fn_violation": 0.004735605282185942,
            "auditor_fp_violation": 0.027431730657019492,
            "ave_precision_score": 0.8194153753231048,
            "fpr": 0.14692982456140352,
            "logloss": 0.6406974047374921,
            "mae": 0.2819988704215033,
            "precision": 0.726530612244898,
            "recall": 0.7722342733188721
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8631418890060408,
            "auditor_fn_violation": 0.020448741213431508,
            "auditor_fp_violation": 0.02132364140567966,
            "ave_precision_score": 0.8633004137142889,
            "fpr": 0.1437980241492865,
            "logloss": 0.6106958828347556,
            "mae": 0.28642996667027343,
            "precision": 0.738,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6574136424593079,
            "auditor_fn_violation": 0.09735224721239108,
            "auditor_fp_violation": 0.05380586999649901,
            "ave_precision_score": 0.6574196971760023,
            "fpr": 0.12719298245614036,
            "logloss": 7.528969512754645,
            "mae": 0.3959787570281892,
            "precision": 0.6647398843930635,
            "recall": 0.49891540130151846
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.713784441855232,
            "auditor_fn_violation": 0.10536979847391473,
            "auditor_fp_violation": 0.04601389713181267,
            "ave_precision_score": 0.7124043823230362,
            "fpr": 0.10537870472008781,
            "logloss": 8.177227888023605,
            "mae": 0.3895067986851945,
            "precision": 0.7159763313609467,
            "recall": 0.4908722109533469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8034178680303476,
            "auditor_fn_violation": 0.05123063896182975,
            "auditor_fp_violation": 0.018253783016299065,
            "ave_precision_score": 0.8039795927419903,
            "fpr": 0.14583333333333334,
            "logloss": 0.8796669165349712,
            "mae": 0.2922664536755171,
            "precision": 0.7234927234927235,
            "recall": 0.754880694143167
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8473725490357802,
            "auditor_fn_violation": 0.0441015044876348,
            "auditor_fp_violation": 0.02238457134753859,
            "ave_precision_score": 0.84766392764028,
            "fpr": 0.12184412733260154,
            "logloss": 0.8921469984009548,
            "mae": 0.2794723943294854,
            "precision": 0.7725409836065574,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8532479973462236,
            "auditor_fn_violation": 0.005296932678768508,
            "auditor_fp_violation": 0.023271871474695612,
            "ave_precision_score": 0.8534926120843263,
            "fpr": 0.14583333333333334,
            "logloss": 0.5521610787645971,
            "mae": 0.26858808932763917,
            "precision": 0.7397260273972602,
            "recall": 0.8199566160520607
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8787371837772071,
            "auditor_fn_violation": 0.015512454271992306,
            "auditor_fp_violation": 0.008723785313998502,
            "ave_precision_score": 0.8789405497073435,
            "fpr": 0.1207464324917673,
            "logloss": 0.5232085947031518,
            "mae": 0.26440977767622975,
            "precision": 0.7855750487329435,
            "recall": 0.8174442190669371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8215809835460057,
            "auditor_fn_violation": 0.007504186170415193,
            "auditor_fp_violation": 0.025917065390749613,
            "ave_precision_score": 0.8219081448725367,
            "fpr": 0.14144736842105263,
            "logloss": 0.6356343492158913,
            "mae": 0.28356333245127435,
            "precision": 0.7345679012345679,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8701828172008963,
            "auditor_fn_violation": 0.023755185105193907,
            "auditor_fp_violation": 0.02340873639042222,
            "ave_precision_score": 0.870334498949562,
            "fpr": 0.13391877058177826,
            "logloss": 0.5714398419985228,
            "mae": 0.27905340347512914,
            "precision": 0.7535353535353535,
            "recall": 0.7565922920892495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8363869020123357,
            "auditor_fn_violation": 0.01059148685161929,
            "auditor_fp_violation": 0.02834101606566306,
            "ave_precision_score": 0.8368867614312411,
            "fpr": 0.14802631578947367,
            "logloss": 0.639756809091882,
            "mae": 0.26345952622415564,
            "precision": 0.7428571428571429,
            "recall": 0.8459869848156182
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8677527721769167,
            "auditor_fn_violation": 0.016142571188738946,
            "auditor_fp_violation": 0.017145573243556957,
            "ave_precision_score": 0.8681070402276662,
            "fpr": 0.1350164654226125,
            "logloss": 0.6308639200587601,
            "mae": 0.26152299487561403,
            "precision": 0.7692307692307693,
            "recall": 0.8316430020283976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8015959604772771,
            "auditor_fn_violation": 0.010051566008296238,
            "auditor_fp_violation": 0.015679095188081065,
            "ave_precision_score": 0.7866035619221105,
            "fpr": 0.09210526315789473,
            "logloss": 3.903817840940605,
            "mae": 0.27171800030995846,
            "precision": 0.7951219512195122,
            "recall": 0.7071583514099783
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8489257521382685,
            "auditor_fn_violation": 0.014056283022690902,
            "auditor_fp_violation": 0.012163929432402487,
            "ave_precision_score": 0.834195104738254,
            "fpr": 0.09440175631174534,
            "logloss": 4.048574794322094,
            "mae": 0.27942024252114717,
            "precision": 0.8013856812933026,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6451015559391693,
            "auditor_fn_violation": 0.01252521216272786,
            "auditor_fp_violation": 0.02731259968102073,
            "ave_precision_score": 0.6343092025950811,
            "fpr": 0.22478070175438597,
            "logloss": 1.9725953357798296,
            "mae": 0.3464246762621873,
            "precision": 0.6513605442176871,
            "recall": 0.8308026030368764
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7208109789279499,
            "auditor_fn_violation": 0.029965065249386028,
            "auditor_fp_violation": 0.025105173871711517,
            "ave_precision_score": 0.712209134746358,
            "fpr": 0.19209659714599342,
            "logloss": 1.5831014586996774,
            "mae": 0.32162386028537715,
            "precision": 0.6929824561403509,
            "recall": 0.8012170385395537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8214573827612897,
            "auditor_fn_violation": 0.009680519085131482,
            "auditor_fp_violation": 0.02945452600459019,
            "ave_precision_score": 0.8217938420513815,
            "fpr": 0.13596491228070176,
            "logloss": 0.6249267485799708,
            "mae": 0.27625654572298036,
            "precision": 0.743801652892562,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8594799676660758,
            "auditor_fn_violation": 0.029228073378562227,
            "auditor_fp_violation": 0.022542135200289925,
            "ave_precision_score": 0.8596497746140049,
            "fpr": 0.13062568605927552,
            "logloss": 0.6144833266636415,
            "mae": 0.2849709940436588,
            "precision": 0.75564681724846,
            "recall": 0.7464503042596349
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 26311,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8390940375034383,
            "auditor_fn_violation": 0.015474559500704034,
            "auditor_fp_violation": 0.025559672462753338,
            "ave_precision_score": 0.8393805941601442,
            "fpr": 0.15021929824561403,
            "logloss": 0.5529396356279425,
            "mae": 0.27914080606748476,
            "precision": 0.7297830374753451,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8562040098198714,
            "auditor_fn_violation": 0.01907272617968797,
            "auditor_fp_violation": 0.026607282601274172,
            "ave_precision_score": 0.8573810078405897,
            "fpr": 0.14270032930845225,
            "logloss": 0.5536481632429376,
            "mae": 0.28569808051194057,
            "precision": 0.746588693957115,
            "recall": 0.7768762677484787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8262848873681421,
            "auditor_fn_violation": 0.01602637287361571,
            "auditor_fp_violation": 0.039821352160890035,
            "ave_precision_score": 0.8268754635728155,
            "fpr": 0.15679824561403508,
            "logloss": 0.7184823483447413,
            "mae": 0.27222680748870604,
            "precision": 0.7322097378277154,
            "recall": 0.8481561822125814
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8659494663116736,
            "auditor_fn_violation": 0.023997880313410803,
            "auditor_fp_violation": 0.019212285778811875,
            "ave_precision_score": 0.8662622859757899,
            "fpr": 0.15916575192096596,
            "logloss": 0.6735388201816856,
            "mae": 0.271620496118694,
            "precision": 0.7396768402154399,
            "recall": 0.8356997971602435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8151661900943807,
            "auditor_fn_violation": 0.018033831868173693,
            "auditor_fp_violation": 0.02826321624460264,
            "ave_precision_score": 0.8165835782381033,
            "fpr": 0.15350877192982457,
            "logloss": 0.7010963452126415,
            "mae": 0.267435681737253,
            "precision": 0.7353497164461248,
            "recall": 0.8438177874186551
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.866779836496968,
            "auditor_fn_violation": 0.023474638350741334,
            "auditor_fp_violation": 0.018912914458584344,
            "ave_precision_score": 0.8669533561320304,
            "fpr": 0.14709110867178923,
            "logloss": 0.6772043388621646,
            "mae": 0.26403136231813346,
            "precision": 0.7541284403669725,
            "recall": 0.8336713995943205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7656102742555513,
            "auditor_fn_violation": 0.015959774707919473,
            "auditor_fp_violation": 0.02778912358501576,
            "ave_precision_score": 0.7673594933586289,
            "fpr": 0.24013157894736842,
            "logloss": 1.004206933583338,
            "mae": 0.3253333134931297,
            "precision": 0.6501597444089456,
            "recall": 0.8828633405639913
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7869318773755282,
            "auditor_fn_violation": 0.019776319627362662,
            "auditor_fp_violation": 0.024826811065184164,
            "ave_precision_score": 0.7875512191337739,
            "fpr": 0.2349066959385291,
            "logloss": 1.0039100615609706,
            "mae": 0.3193089065409107,
            "precision": 0.6682170542635659,
            "recall": 0.8742393509127789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8181335683423715,
            "auditor_fn_violation": 0.0064076949423450226,
            "auditor_fp_violation": 0.028788365036760414,
            "ave_precision_score": 0.8184619580071758,
            "fpr": 0.1611842105263158,
            "logloss": 0.6481538847681005,
            "mae": 0.29349411691165234,
            "precision": 0.7083333333333334,
            "recall": 0.7744034707158352
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8552477313196276,
            "auditor_fn_violation": 0.023808622582232486,
            "auditor_fp_violation": 0.027473883791406476,
            "ave_precision_score": 0.8554212048826311,
            "fpr": 0.15477497255762898,
            "logloss": 0.6145291568169807,
            "mae": 0.29597254268289364,
            "precision": 0.7235294117647059,
            "recall": 0.7484787018255578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8286945729204922,
            "auditor_fn_violation": 0.0050638390988316795,
            "auditor_fp_violation": 0.022051386781810404,
            "ave_precision_score": 0.8290456063352958,
            "fpr": 0.12828947368421054,
            "logloss": 1.1211204463593143,
            "mae": 0.274724569310349,
            "precision": 0.7473002159827213,
            "recall": 0.7505422993492408
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8546412038751338,
            "auditor_fn_violation": 0.022688662125965493,
            "auditor_fp_violation": 0.01926480706306231,
            "ave_precision_score": 0.8548301269030367,
            "fpr": 0.11855104281009879,
            "logloss": 1.347378086830193,
            "mae": 0.2825112433374203,
            "precision": 0.7697228144989339,
            "recall": 0.7322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 26311,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8016199121384182,
            "auditor_fn_violation": 0.0046476005632302055,
            "auditor_fp_violation": 0.009707958921694484,
            "ave_precision_score": 0.7864697063878282,
            "fpr": 0.13925438596491227,
            "logloss": 3.9692400318569336,
            "mae": 0.27192799109769494,
            "precision": 0.7392197125256673,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.84681509385852,
            "auditor_fn_violation": 0.007917652847883545,
            "auditor_fp_violation": 0.011819915020562087,
            "ave_precision_score": 0.8320940512819812,
            "fpr": 0.12403951701427003,
            "logloss": 4.0961653968357865,
            "mae": 0.2757467714380616,
            "precision": 0.7689161554192229,
            "recall": 0.7626774847870182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8067060297769972,
            "auditor_fn_violation": 0.005339745785287517,
            "auditor_fp_violation": 0.027575174077099626,
            "ave_precision_score": 0.8071159848461258,
            "fpr": 0.14692982456140352,
            "logloss": 0.9046513502268029,
            "mae": 0.26985428723877514,
            "precision": 0.732,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8248137052519849,
            "auditor_fn_violation": 0.01852499204004248,
            "auditor_fp_violation": 0.024170295012053634,
            "ave_precision_score": 0.8251637329529333,
            "fpr": 0.1394072447859495,
            "logloss": 0.9204757117806717,
            "mae": 0.2814119019224535,
            "precision": 0.7449799196787149,
            "recall": 0.7525354969574036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8061431022089249,
            "auditor_fn_violation": 0.017405906305894895,
            "auditor_fp_violation": 0.01821245186136072,
            "ave_precision_score": 0.7911743251089884,
            "fpr": 0.0800438596491228,
            "logloss": 3.9426422794938603,
            "mae": 0.2704401374784124,
            "precision": 0.8048128342245989,
            "recall": 0.6529284164859002
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8476417396694085,
            "auditor_fn_violation": 0.01302538502815487,
            "auditor_fp_violation": 0.006502134990204782,
            "ave_precision_score": 0.8329099358809557,
            "fpr": 0.07135016465422613,
            "logloss": 4.210496655864238,
            "mae": 0.290327330567669,
            "precision": 0.8266666666666667,
            "recall": 0.6288032454361054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.710042734164064,
            "auditor_fn_violation": 0.08181108954599081,
            "auditor_fp_violation": 0.025618022328548644,
            "ave_precision_score": 0.6722466082349741,
            "fpr": 0.06359649122807018,
            "logloss": 9.449166015630642,
            "mae": 0.35928758324341387,
            "precision": 0.7725490196078432,
            "recall": 0.42733188720173537
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7572870011468366,
            "auditor_fn_violation": 0.08679136895683368,
            "auditor_fp_violation": 0.0194066145305385,
            "ave_precision_score": 0.7149513137158102,
            "fpr": 0.05378704720087816,
            "logloss": 10.341348200688207,
            "mae": 0.3813527582504513,
            "precision": 0.8,
            "recall": 0.3975659229208925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8273184166909343,
            "auditor_fn_violation": 0.005594245918483851,
            "auditor_fp_violation": 0.022345567355195085,
            "ave_precision_score": 0.8276986592664131,
            "fpr": 0.11951754385964912,
            "logloss": 1.1706355503245132,
            "mae": 0.2756123711608926,
            "precision": 0.7609649122807017,
            "recall": 0.7527114967462039
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8588330260757964,
            "auditor_fn_violation": 0.02165999069297275,
            "auditor_fp_violation": 0.014472239875209437,
            "ave_precision_score": 0.8590158462226879,
            "fpr": 0.10867178924259056,
            "logloss": 1.5026094934724785,
            "mae": 0.28611316520483904,
            "precision": 0.7833698030634574,
            "recall": 0.7261663286004056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8304213426376008,
            "auditor_fn_violation": 0.015343741675229288,
            "auditor_fp_violation": 0.029442369782549497,
            "ave_precision_score": 0.831027453578642,
            "fpr": 0.14692982456140352,
            "logloss": 0.6640329575929271,
            "mae": 0.26614859875774116,
            "precision": 0.7423076923076923,
            "recall": 0.8373101952277657
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.867473441395654,
            "auditor_fn_violation": 0.01792827354644496,
            "auditor_fp_violation": 0.020170799216382443,
            "ave_precision_score": 0.8678012163317608,
            "fpr": 0.13062568605927552,
            "logloss": 0.6556335987130958,
            "mae": 0.2602299181081778,
            "precision": 0.7729007633587787,
            "recall": 0.821501014198783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.794883812611419,
            "auditor_fn_violation": 0.014782414278646728,
            "auditor_fp_violation": 0.01881296923017077,
            "ave_precision_score": 0.79066321598232,
            "fpr": 0.12719298245614036,
            "logloss": 2.7327666120522895,
            "mae": 0.2918046891924033,
            "precision": 0.7381489841986456,
            "recall": 0.7093275488069414
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.839926153597447,
            "auditor_fn_violation": 0.017026516121418856,
            "auditor_fp_violation": 0.02100063550753943,
            "ave_precision_score": 0.8352136683241996,
            "fpr": 0.11745334796926454,
            "logloss": 2.7091713176611503,
            "mae": 0.2952440370123245,
            "precision": 0.7611607142857143,
            "recall": 0.691683569979716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8228209601137644,
            "auditor_fn_violation": 0.0149465311869696,
            "auditor_fp_violation": 0.02984838759870852,
            "ave_precision_score": 0.8237473259122521,
            "fpr": 0.15021929824561403,
            "logloss": 0.7018489661685884,
            "mae": 0.2669121330785649,
            "precision": 0.7243460764587525,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8589843551788554,
            "auditor_fn_violation": 0.017681125215141508,
            "auditor_fp_violation": 0.021922384046134693,
            "ave_precision_score": 0.8592091005471068,
            "fpr": 0.15148188803512624,
            "logloss": 0.7085633931306614,
            "mae": 0.27709985946128046,
            "precision": 0.7341040462427746,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8047864300888447,
            "auditor_fn_violation": 0.006693115652471744,
            "auditor_fp_violation": 0.026709651067802542,
            "ave_precision_score": 0.8051032667814261,
            "fpr": 0.14144736842105263,
            "logloss": 0.6554494408618441,
            "mae": 0.300350821422558,
            "precision": 0.7266949152542372,
            "recall": 0.7440347071583514
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8475308849589691,
            "auditor_fn_violation": 0.022902412034119836,
            "auditor_fp_violation": 0.01763402118708607,
            "ave_precision_score": 0.8477265668268912,
            "fpr": 0.12843029637760703,
            "logloss": 0.621694004756031,
            "mae": 0.29949516705459683,
            "precision": 0.7542016806722689,
            "recall": 0.7281947261663286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8067757938917087,
            "auditor_fn_violation": 0.005339745785287517,
            "auditor_fp_violation": 0.027575174077099626,
            "ave_precision_score": 0.807183481214228,
            "fpr": 0.14692982456140352,
            "logloss": 0.9044556919391337,
            "mae": 0.2698530956786886,
            "precision": 0.732,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8248252997671606,
            "auditor_fn_violation": 0.01852499204004248,
            "auditor_fp_violation": 0.024170295012053634,
            "ave_precision_score": 0.8251752931950138,
            "fpr": 0.1394072447859495,
            "logloss": 0.9203217798977222,
            "mae": 0.28140501892738506,
            "precision": 0.7449799196787149,
            "recall": 0.7525354969574036
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8095865450342066,
            "auditor_fn_violation": 0.0038412870571222033,
            "auditor_fp_violation": 0.021377932080756223,
            "ave_precision_score": 0.8101173383904121,
            "fpr": 0.1524122807017544,
            "logloss": 0.623530260083489,
            "mae": 0.2873166815695361,
            "precision": 0.7214428857715431,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8071909343011374,
            "auditor_fn_violation": 0.015174016917414603,
            "auditor_fp_violation": 0.028666116943891512,
            "ave_precision_score": 0.8088007243934235,
            "fpr": 0.15587266739846323,
            "logloss": 0.6343553906413288,
            "mae": 0.2997964639955279,
            "precision": 0.7263969171483622,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 26311,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8210187920936923,
            "auditor_fn_violation": 0.0122041138638353,
            "auditor_fp_violation": 0.03279505582137161,
            "ave_precision_score": 0.8191996906936825,
            "fpr": 0.13486842105263158,
            "logloss": 1.4790190117674487,
            "mae": 0.26049886985454657,
            "precision": 0.7463917525773196,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8599158506872694,
            "auditor_fn_violation": 0.021372764253890356,
            "auditor_fp_violation": 0.014653438305873458,
            "ave_precision_score": 0.8590083418171328,
            "fpr": 0.11855104281009879,
            "logloss": 1.0802354142248851,
            "mae": 0.25694452784865607,
            "precision": 0.7791411042944786,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8197484903712373,
            "auditor_fn_violation": 0.005389694409559691,
            "auditor_fp_violation": 0.028829696191698766,
            "ave_precision_score": 0.8211036077928044,
            "fpr": 0.14473684210526316,
            "logloss": 0.5886508216899443,
            "mae": 0.27658569993729,
            "precision": 0.7338709677419355,
            "recall": 0.789587852494577
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.86516776974313,
            "auditor_fn_violation": 0.022590693418061428,
            "auditor_fp_violation": 0.02381577634336315,
            "ave_precision_score": 0.8653319293288626,
            "fpr": 0.141602634467618,
            "logloss": 0.5729549647535032,
            "mae": 0.28255927590015634,
            "precision": 0.7455621301775148,
            "recall": 0.7667342799188641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7441202282483277,
            "auditor_fn_violation": 0.011790253834151538,
            "auditor_fp_violation": 0.013933461703038092,
            "ave_precision_score": 0.5197115623790639,
            "fpr": 0.44627192982456143,
            "logloss": 15.230519931779023,
            "mae": 0.4692034438521397,
            "precision": 0.5200471698113207,
            "recall": 0.9566160520607375
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7709837818575143,
            "auditor_fn_violation": 0.007904293478623895,
            "auditor_fp_violation": 0.014393457948833779,
            "ave_precision_score": 0.5659867372190893,
            "fpr": 0.40285400658616904,
            "logloss": 13.653300625369608,
            "mae": 0.41810166757937606,
            "precision": 0.566193853427896,
            "recall": 0.9716024340770791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8368188147727538,
            "auditor_fn_violation": 0.016480667503900752,
            "auditor_fp_violation": 0.028272941222235195,
            "ave_precision_score": 0.8371147909167866,
            "fpr": 0.1425438596491228,
            "logloss": 0.6333704062434229,
            "mae": 0.26366096055007565,
            "precision": 0.7405189620758483,
            "recall": 0.8047722342733189
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8614957877822236,
            "auditor_fn_violation": 0.019420069780438774,
            "auditor_fp_violation": 0.01892604477964695,
            "ave_precision_score": 0.8616717216727492,
            "fpr": 0.141602634467618,
            "logloss": 0.6461130880856976,
            "mae": 0.2739753168284479,
            "precision": 0.7514450867052023,
            "recall": 0.7910750507099391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8316803781699711,
            "auditor_fn_violation": 0.014278171024089513,
            "auditor_fp_violation": 0.03175691445909675,
            "ave_precision_score": 0.832276782141062,
            "fpr": 0.1524122807017544,
            "logloss": 0.6673361354796409,
            "mae": 0.26509543655906487,
            "precision": 0.7362428842504743,
            "recall": 0.841648590021692
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8662941429416352,
            "auditor_fn_violation": 0.018789952863692137,
            "auditor_fp_violation": 0.02053844820613554,
            "ave_precision_score": 0.8665946799374409,
            "fpr": 0.132821075740944,
            "logloss": 0.6589098113482952,
            "mae": 0.2612394953062621,
            "precision": 0.7703984819734345,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8292307204450347,
            "auditor_fn_violation": 0.007037999010541537,
            "auditor_fp_violation": 0.022206986423931232,
            "ave_precision_score": 0.8295982531016196,
            "fpr": 0.12938596491228072,
            "logloss": 1.1376412097902013,
            "mae": 0.2748354645633895,
            "precision": 0.7445887445887446,
            "recall": 0.7462039045553145
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8584903926769867,
            "auditor_fn_violation": 0.02184256873952125,
            "auditor_fp_violation": 0.02262091712666558,
            "ave_precision_score": 0.8586713962071084,
            "fpr": 0.12294182217343579,
            "logloss": 1.3878777963446303,
            "mae": 0.28173398850046444,
            "precision": 0.7637130801687764,
            "recall": 0.7342799188640974
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8328606964098176,
            "auditor_fn_violation": 0.00322525402443202,
            "auditor_fp_violation": 0.016527599486521185,
            "ave_precision_score": 0.833179760762647,
            "fpr": 0.09649122807017543,
            "logloss": 1.1651381457693593,
            "mae": 0.2737450194447705,
            "precision": 0.7929411764705883,
            "recall": 0.7310195227765727
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8541827432528895,
            "auditor_fn_violation": 0.01631178986602779,
            "auditor_fp_violation": 0.014044191408568323,
            "ave_precision_score": 0.8543795372522038,
            "fpr": 0.09220636663007684,
            "logloss": 1.5250221083635713,
            "mae": 0.29020517736565254,
            "precision": 0.8037383177570093,
            "recall": 0.6977687626774848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7959882396010138,
            "auditor_fn_violation": 0.010106271644403851,
            "auditor_fp_violation": 0.007631676197144752,
            "ave_precision_score": 0.7813540291839408,
            "fpr": 0.09100877192982457,
            "logloss": 3.9069656501209824,
            "mae": 0.27322775233136654,
            "precision": 0.7970660146699267,
            "recall": 0.7071583514099783
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8465935490882643,
            "auditor_fn_violation": 0.014276712615475046,
            "auditor_fp_violation": 0.012599856091681155,
            "ave_precision_score": 0.8318679570299712,
            "fpr": 0.09110867178924259,
            "logloss": 4.052472104766974,
            "mae": 0.28074824551384153,
            "precision": 0.8028503562945368,
            "recall": 0.6855983772819473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6437024575799756,
            "auditor_fn_violation": 0.014135460669026146,
            "auditor_fp_violation": 0.05631977671451357,
            "ave_precision_score": 0.5447064861020176,
            "fpr": 0.3223684210526316,
            "logloss": 7.403352704407991,
            "mae": 0.3897390959058963,
            "precision": 0.5905292479108635,
            "recall": 0.9197396963123644
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6754572136349912,
            "auditor_fn_violation": 0.02066917080621567,
            "auditor_fp_violation": 0.06522618291062454,
            "ave_precision_score": 0.5789115916077782,
            "fpr": 0.2897914379802415,
            "logloss": 7.174504300616348,
            "mae": 0.35866646179009937,
            "precision": 0.6281690140845071,
            "recall": 0.9046653144016227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 26311,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8201827635417842,
            "auditor_fn_violation": 0.005389694409559692,
            "auditor_fp_violation": 0.029736550355934182,
            "ave_precision_score": 0.8206015177763906,
            "fpr": 0.15350877192982457,
            "logloss": 0.6661563516189073,
            "mae": 0.2715046428674987,
            "precision": 0.7302504816955684,
            "recall": 0.8221258134490239
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8560140330321576,
            "auditor_fn_violation": 0.015013704486298858,
            "auditor_fp_violation": 0.017723307370311824,
            "ave_precision_score": 0.8565096846600562,
            "fpr": 0.13721185510428102,
            "logloss": 0.6291720558636161,
            "mae": 0.2736815357475727,
            "precision": 0.7553816046966731,
            "recall": 0.7829614604462475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8167961218140705,
            "auditor_fn_violation": 0.0049211287437683155,
            "auditor_fp_violation": 0.02733448088069398,
            "ave_precision_score": 0.8169750215543443,
            "fpr": 0.1513157894736842,
            "logloss": 1.2918784694114762,
            "mae": 0.28525390153909375,
            "precision": 0.7261904761904762,
            "recall": 0.7939262472885033
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8554343400104253,
            "auditor_fn_violation": 0.013633236329468772,
            "auditor_fp_violation": 0.010520013235363637,
            "ave_precision_score": 0.8555646289092849,
            "fpr": 0.13172338090010977,
            "logloss": 0.9083957364601922,
            "mae": 0.2700990593806535,
            "precision": 0.7674418604651163,
            "recall": 0.8032454361054767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7922058343321111,
            "auditor_fn_violation": 0.009276173079118625,
            "auditor_fp_violation": 0.024086338351421797,
            "ave_precision_score": 0.7926916621494366,
            "fpr": 0.14583333333333334,
            "logloss": 0.8481409200895265,
            "mae": 0.2813967759985551,
            "precision": 0.7263374485596708,
            "recall": 0.7657266811279827
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8112783529027194,
            "auditor_fn_violation": 0.02010585073576727,
            "auditor_fp_violation": 0.01983466299717961,
            "ave_precision_score": 0.8116716196964111,
            "fpr": 0.13721185510428102,
            "logloss": 0.8762595989853675,
            "mae": 0.292224698878085,
            "precision": 0.7438524590163934,
            "recall": 0.7363083164300203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8362291376797337,
            "auditor_fn_violation": 0.017769817711306465,
            "auditor_fp_violation": 0.02769187380869025,
            "ave_precision_score": 0.8366059521053677,
            "fpr": 0.14802631578947367,
            "logloss": 0.6134227896778108,
            "mae": 0.27303481520358963,
            "precision": 0.736328125,
            "recall": 0.8177874186550976
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8585502696430608,
            "auditor_fn_violation": 0.018792179425235412,
            "auditor_fp_violation": 0.022993818244843724,
            "ave_precision_score": 0.8590526859586662,
            "fpr": 0.14818880351262348,
            "logloss": 0.6213472225573142,
            "mae": 0.2774961326288526,
            "precision": 0.7476635514018691,
            "recall": 0.8113590263691683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8033127280355453,
            "auditor_fn_violation": 0.006024755489591657,
            "auditor_fp_violation": 0.028545240595946632,
            "ave_precision_score": 0.8036416509310181,
            "fpr": 0.15789473684210525,
            "logloss": 0.6680949206299432,
            "mae": 0.3001384827684409,
            "precision": 0.7131474103585658,
            "recall": 0.7765726681127982
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8477457766221325,
            "auditor_fn_violation": 0.018248898408676467,
            "auditor_fp_violation": 0.025415049448789126,
            "ave_precision_score": 0.8479411210183612,
            "fpr": 0.15148188803512624,
            "logloss": 0.6201670721098832,
            "mae": 0.2990880474107264,
            "precision": 0.7283464566929134,
            "recall": 0.7505070993914807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6787439617719547,
            "auditor_fn_violation": 0.09061156144156486,
            "auditor_fp_violation": 0.033094098883572565,
            "ave_precision_score": 0.678483051362328,
            "fpr": 0.10416666666666667,
            "logloss": 7.304291569306365,
            "mae": 0.3885340364496714,
            "precision": 0.703125,
            "recall": 0.4880694143167028
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7300554329634703,
            "auditor_fn_violation": 0.10019749600888844,
            "auditor_fp_violation": 0.03418610391861302,
            "ave_precision_score": 0.728575641153238,
            "fpr": 0.0889132821075741,
            "logloss": 8.021820128967791,
            "mae": 0.39243471855374357,
            "precision": 0.7452830188679245,
            "recall": 0.48073022312373226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7761079875050428,
            "auditor_fn_violation": 0.054912566122464514,
            "auditor_fp_violation": 0.0210108141751274,
            "ave_precision_score": 0.7767516760599876,
            "fpr": 0.1600877192982456,
            "logloss": 1.0287990733629402,
            "mae": 0.30677580524282266,
            "precision": 0.7032520325203252,
            "recall": 0.7505422993492408
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8321868715258647,
            "auditor_fn_violation": 0.04871271344375594,
            "auditor_fp_violation": 0.027342580580780363,
            "ave_precision_score": 0.8324910556502335,
            "fpr": 0.1350164654226125,
            "logloss": 1.0055916836651486,
            "mae": 0.28463784953657556,
            "precision": 0.7559523809523809,
            "recall": 0.7728194726166329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.788045758352339,
            "auditor_fn_violation": 0.022586292194694987,
            "auditor_fp_violation": 0.012482008791379782,
            "ave_precision_score": 0.7739664631866277,
            "fpr": 0.13048245614035087,
            "logloss": 4.043549523439849,
            "mae": 0.2774145762698601,
            "precision": 0.7384615384615385,
            "recall": 0.7288503253796096
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8507277826598846,
            "auditor_fn_violation": 0.018422570209051865,
            "auditor_fp_violation": 0.014170242490769385,
            "ave_precision_score": 0.8359967366710652,
            "fpr": 0.10976948408342481,
            "logloss": 4.143042306458003,
            "mae": 0.27005746469843045,
            "precision": 0.7854077253218884,
            "recall": 0.742393509127789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8392394060648307,
            "auditor_fn_violation": 0.006317311717471557,
            "auditor_fp_violation": 0.024533687322519163,
            "ave_precision_score": 0.8395514706689011,
            "fpr": 0.13815789473684212,
            "logloss": 0.6110408858343355,
            "mae": 0.2688627737033561,
            "precision": 0.7418032786885246,
            "recall": 0.7852494577006508
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8662237008074082,
            "auditor_fn_violation": 0.016993117698269743,
            "auditor_fp_violation": 0.025225972825487532,
            "ave_precision_score": 0.8664085065118816,
            "fpr": 0.1394072447859495,
            "logloss": 0.5944266116791296,
            "mae": 0.277543573344201,
            "precision": 0.7485148514851485,
            "recall": 0.7667342799188641
        }
    }
]