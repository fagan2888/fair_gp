[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5112203258869835,
            "auditor_fn_violation": 0.0031406805112991487,
            "auditor_fp_violation": 0.007834974271706981,
            "ave_precision_score": 0.5204332645891266,
            "fpr": 0.046052631578947366,
            "logloss": 0.6965388631080587,
            "mae": 0.5012472435309175,
            "precision": 0.46153846153846156,
            "recall": 0.07515657620041753
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.525405294245493,
            "auditor_fn_violation": 0.0018603038881506878,
            "auditor_fp_violation": 0.006190898196356461,
            "ave_precision_score": 0.5185298867366,
            "fpr": 0.04720087815587267,
            "logloss": 0.695746635822717,
            "mae": 0.5008375127150644,
            "precision": 0.4880952380952381,
            "recall": 0.0863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7662432018746523,
            "auditor_fn_violation": 0.005656429696370382,
            "auditor_fp_violation": 0.0017396985535432115,
            "ave_precision_score": 0.5993674358437175,
            "fpr": 0.005482456140350877,
            "logloss": 0.6502582650964494,
            "mae": 0.463300664892845,
            "precision": 0.9358974358974359,
            "recall": 0.1524008350730689
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7627692805403028,
            "auditor_fn_violation": 0.0023941302212721737,
            "auditor_fp_violation": 0.00042044733582412725,
            "ave_precision_score": 0.5793199670401796,
            "fpr": 0.003293084522502744,
            "logloss": 0.6596292897904739,
            "mae": 0.47216522647834636,
            "precision": 0.9491525423728814,
            "recall": 0.11789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7676381629366087,
            "auditor_fn_violation": 0.00529245870417171,
            "auditor_fp_violation": 0.0017396985535432115,
            "ave_precision_score": 0.5887897108260465,
            "fpr": 0.005482456140350877,
            "logloss": 0.6541597187926788,
            "mae": 0.4673827548691055,
            "precision": 0.9367088607594937,
            "recall": 0.1544885177453027
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7671200504004247,
            "auditor_fn_violation": 0.001582991507308343,
            "auditor_fp_violation": 0.00042044733582412725,
            "ave_precision_score": 0.5758441108259122,
            "fpr": 0.003293084522502744,
            "logloss": 0.6598866713020607,
            "mae": 0.4730635841513047,
            "precision": 0.9523809523809523,
            "recall": 0.12631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.48560676960002647,
            "auditor_fn_violation": 0.014746547998388461,
            "auditor_fp_violation": 0.0035604311008468055,
            "ave_precision_score": 0.4863812196942708,
            "fpr": 0.03837719298245614,
            "logloss": 0.6862390746160016,
            "mae": 0.49230589949640263,
            "precision": 0.5679012345679012,
            "recall": 0.09603340292275574
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.521901663237083,
            "auditor_fn_violation": 0.007750881044543302,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5226167731583524,
            "fpr": 0.02854006586169045,
            "logloss": 0.6805090633632737,
            "mae": 0.49029633307954223,
            "precision": 0.6486486486486487,
            "recall": 0.10105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5112203258869835,
            "auditor_fn_violation": 0.0031406805112991487,
            "auditor_fp_violation": 0.007834974271706981,
            "ave_precision_score": 0.5204332645891266,
            "fpr": 0.046052631578947366,
            "logloss": 0.6965388631080587,
            "mae": 0.5012472435309175,
            "precision": 0.46153846153846156,
            "recall": 0.07515657620041753
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.525405294245493,
            "auditor_fn_violation": 0.0018603038881506878,
            "auditor_fp_violation": 0.006190898196356461,
            "ave_precision_score": 0.5185298867366,
            "fpr": 0.04720087815587267,
            "logloss": 0.695746635822717,
            "mae": 0.5008375127150644,
            "precision": 0.4880952380952381,
            "recall": 0.0863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5032211399621684,
            "auditor_fn_violation": 0.008689521298025854,
            "auditor_fp_violation": 0.005842044487662576,
            "ave_precision_score": 0.5050573139413832,
            "fpr": 0.07346491228070176,
            "logloss": 0.6957719564599331,
            "mae": 0.5010497650752465,
            "precision": 0.48854961832061067,
            "recall": 0.1336116910229645
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5514735585382823,
            "auditor_fn_violation": 0.015178230978103903,
            "auditor_fp_violation": 0.006012145137413266,
            "ave_precision_score": 0.5525847365481061,
            "fpr": 0.06476399560922064,
            "logloss": 0.693467339097552,
            "mae": 0.4999082352471273,
            "precision": 0.5317460317460317,
            "recall": 0.14105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7630206862806036,
            "auditor_fn_violation": 0.0015611837527011703,
            "auditor_fp_violation": 0.012993294437016332,
            "ave_precision_score": 0.7627850047035271,
            "fpr": 0.20285087719298245,
            "logloss": 1.087510594327371,
            "mae": 0.33902108582071633,
            "precision": 0.6972176759410802,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8042205885538379,
            "auditor_fn_violation": 0.008746894679068695,
            "auditor_fp_violation": 0.028409148128379948,
            "ave_precision_score": 0.8042092322511566,
            "fpr": 0.21075740944017562,
            "logloss": 0.966465356018981,
            "mae": 0.32803236870718744,
            "precision": 0.6847290640394089,
            "recall": 0.8778947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.48572275197070613,
            "auditor_fn_violation": 0.014746547998388461,
            "auditor_fp_violation": 0.0035604311008468055,
            "ave_precision_score": 0.4866131844356301,
            "fpr": 0.03837719298245614,
            "logloss": 0.6862390725529804,
            "mae": 0.49230589946372466,
            "precision": 0.5679012345679012,
            "recall": 0.09603340292275574
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.521901663237083,
            "auditor_fn_violation": 0.007750881044543302,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5226167731583524,
            "fpr": 0.02854006586169045,
            "logloss": 0.6805090633558554,
            "mae": 0.49029633311225607,
            "precision": 0.6486486486486487,
            "recall": 0.10105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5121680888974325,
            "auditor_fn_violation": 0.0031406805112991487,
            "auditor_fp_violation": 0.007834974271706981,
            "ave_precision_score": 0.522645215955968,
            "fpr": 0.046052631578947366,
            "logloss": 0.6964539424531538,
            "mae": 0.5012087966397143,
            "precision": 0.46153846153846156,
            "recall": 0.07515657620041753
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.5275755215748064,
            "auditor_fn_violation": 0.0018603038881506878,
            "auditor_fp_violation": 0.006190898196356461,
            "ave_precision_score": 0.5224532987887107,
            "fpr": 0.04720087815587267,
            "logloss": 0.695685200552462,
            "mae": 0.5008075972681643,
            "precision": 0.4880952380952381,
            "recall": 0.0863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7428496141477933,
            "auditor_fn_violation": 0.0018404570926271859,
            "auditor_fp_violation": 0.011544811798549494,
            "ave_precision_score": 0.7396360956726544,
            "fpr": 0.21162280701754385,
            "logloss": 1.270924244581073,
            "mae": 0.3415344240503353,
            "precision": 0.6897106109324759,
            "recall": 0.8956158663883089
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7615990000831147,
            "auditor_fn_violation": 0.008746894679068695,
            "auditor_fp_violation": 0.025085851821267085,
            "ave_precision_score": 0.7567685213534208,
            "fpr": 0.2217343578485181,
            "logloss": 1.2794147865822494,
            "mae": 0.33423590583728807,
            "precision": 0.6736672051696284,
            "recall": 0.8778947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.7636745862951415,
            "auditor_fn_violation": 0.0020785261692854284,
            "auditor_fp_violation": 0.015145759896276489,
            "ave_precision_score": 0.7633837106753194,
            "fpr": 0.17763157894736842,
            "logloss": 1.0536395396121276,
            "mae": 0.3299679626148294,
            "precision": 0.71875,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8054191866463172,
            "auditor_fn_violation": 0.008192269917384021,
            "auditor_fp_violation": 0.025795828759604834,
            "ave_precision_score": 0.805438186855546,
            "fpr": 0.17892425905598244,
            "logloss": 0.924541695904413,
            "mae": 0.31505108008909516,
            "precision": 0.7130281690140845,
            "recall": 0.8526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.7099139242255565,
            "auditor_fn_violation": 0.004234882613632217,
            "auditor_fp_violation": 0.0011851221587455938,
            "ave_precision_score": 0.5572630852739597,
            "fpr": 0.008771929824561403,
            "logloss": 0.6905867332264211,
            "mae": 0.486399496202929,
            "precision": 0.8490566037735849,
            "recall": 0.09394572025052192
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.713789388905668,
            "auditor_fn_violation": 0.0046981339187706014,
            "auditor_fp_violation": 0.0001661648153556434,
            "ave_precision_score": 0.5530333232658814,
            "fpr": 0.006586169045005488,
            "logloss": 0.6902455524653914,
            "mae": 0.4872187581138213,
            "precision": 0.8636363636363636,
            "recall": 0.08
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7667368547834981,
            "auditor_fn_violation": 0.005656429696370382,
            "auditor_fp_violation": 0.0017396985535432115,
            "ave_precision_score": 0.5878069893700044,
            "fpr": 0.005482456140350877,
            "logloss": 0.6547937902059231,
            "mae": 0.46799188773883016,
            "precision": 0.9358974358974359,
            "recall": 0.1524008350730689
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7634907087622682,
            "auditor_fn_violation": 0.0023941302212721737,
            "auditor_fp_violation": 0.00042044733582412725,
            "ave_precision_score": 0.571834227515616,
            "fpr": 0.003293084522502744,
            "logloss": 0.6627344467390772,
            "mae": 0.4751382055319232,
            "precision": 0.9491525423728814,
            "recall": 0.11789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5082580210965828,
            "auditor_fn_violation": 0.007361828370508756,
            "auditor_fp_violation": 0.004193509177099794,
            "ave_precision_score": 0.5221163883089771,
            "fpr": 0.03728070175438596,
            "logloss": 0.6964337013159015,
            "mae": 0.5012248145383701,
            "precision": 0.46875,
            "recall": 0.06263048016701461
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5485120567865546,
            "auditor_fn_violation": 0.006264948870529792,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5231574034541585,
            "fpr": 0.02854006586169045,
            "logloss": 0.6950524195152373,
            "mae": 0.5005400972164815,
            "precision": 0.543859649122807,
            "recall": 0.06526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5462890295207287,
            "auditor_fn_violation": 0.0010026370728491649,
            "auditor_fp_violation": 9.369555528544274e-05,
            "ave_precision_score": 0.5377221652817831,
            "fpr": 0.02631578947368421,
            "logloss": 0.6954716668867834,
            "mae": 0.4994067706559834,
            "precision": 0.5555555555555556,
            "recall": 0.06263048016701461
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5814053589696672,
            "auditor_fn_violation": 0.01012190190074529,
            "auditor_fp_violation": 0.004702967804308201,
            "ave_precision_score": 0.5348204299064755,
            "fpr": 0.026344676180021953,
            "logloss": 0.6944622025038069,
            "mae": 0.49905170632769585,
            "precision": 0.5932203389830508,
            "recall": 0.07368421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7666927394960288,
            "auditor_fn_violation": 0.012379591986228618,
            "auditor_fp_violation": 0.019516530934727123,
            "ave_precision_score": 0.7657613681284517,
            "fpr": 0.14692982456140352,
            "logloss": 1.0831483078754292,
            "mae": 0.3227438729046027,
            "precision": 0.7377690802348337,
            "recall": 0.7870563674321504
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8037106884296542,
            "auditor_fn_violation": 0.018563752960887404,
            "auditor_fp_violation": 0.02074542543228029,
            "ave_precision_score": 0.80311424423431,
            "fpr": 0.14489571899012074,
            "logloss": 0.9724946075858082,
            "mae": 0.3081859037807594,
            "precision": 0.7431906614785992,
            "recall": 0.8042105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5819713126421395,
            "auditor_fn_violation": 0.004234882613632217,
            "auditor_fp_violation": 0.0011851221587455938,
            "ave_precision_score": 0.5835839328584963,
            "fpr": 0.008771929824561403,
            "logloss": 0.7029011557988529,
            "mae": 0.48793765796315774,
            "precision": 0.8490566037735849,
            "recall": 0.09394572025052192
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6041113083642231,
            "auditor_fn_violation": 0.0046981339187706014,
            "auditor_fp_violation": 0.0001661648153556434,
            "ave_precision_score": 0.6054785459019681,
            "fpr": 0.006586169045005488,
            "logloss": 0.6993667632063483,
            "mae": 0.4868770127402441,
            "precision": 0.8636363636363636,
            "recall": 0.08
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.5250062970315642,
            "auditor_fn_violation": 0.012841995385122526,
            "auditor_fp_violation": 0.007067683643288358,
            "ave_precision_score": 0.48593753560165465,
            "fpr": 0.03508771929824561,
            "logloss": 1.4118862916841304,
            "mae": 0.488871654389892,
            "precision": 0.5733333333333334,
            "recall": 0.08977035490605428
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5642772598750426,
            "auditor_fn_violation": 0.00675486741001793,
            "auditor_fp_violation": 0.0033132257122428233,
            "ave_precision_score": 0.5039926604214009,
            "fpr": 0.026344676180021953,
            "logloss": 1.5277484602308773,
            "mae": 0.48202594968007456,
            "precision": 0.6619718309859155,
            "recall": 0.09894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.763655429006296,
            "auditor_fn_violation": 0.0015039556092737063,
            "auditor_fp_violation": 0.012669158461974802,
            "ave_precision_score": 0.7633418816233142,
            "fpr": 0.17543859649122806,
            "logloss": 1.052371621966378,
            "mae": 0.32941238851772303,
            "precision": 0.7207678883071553,
            "recall": 0.8622129436325678
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8054038780064152,
            "auditor_fn_violation": 0.008795424345716101,
            "auditor_fp_violation": 0.024149286498353458,
            "ave_precision_score": 0.8054125615999315,
            "fpr": 0.1778265642151482,
            "logloss": 0.9231104581265223,
            "mae": 0.314429546068027,
            "precision": 0.7137809187279152,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7600080874700809,
            "auditor_fn_violation": 0.0024653884188550724,
            "auditor_fp_violation": 0.010597726996475024,
            "ave_precision_score": 0.7598282116406939,
            "fpr": 0.1787280701754386,
            "logloss": 1.0344221417631003,
            "mae": 0.33555370335122,
            "precision": 0.7165217391304348,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8008634616274279,
            "auditor_fn_violation": 0.00792651221907678,
            "auditor_fp_violation": 0.025257051934057754,
            "ave_precision_score": 0.800886870733166,
            "fpr": 0.1800219538968167,
            "logloss": 0.9193757459958287,
            "mae": 0.3229463814132112,
            "precision": 0.712280701754386,
            "recall": 0.8547368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7603052729305104,
            "auditor_fn_violation": 0.009751675640039557,
            "auditor_fp_violation": 0.017353936226246914,
            "ave_precision_score": 0.7597096803531412,
            "fpr": 0.12828947368421054,
            "logloss": 1.0609663180935485,
            "mae": 0.325989026105641,
            "precision": 0.7291666666666666,
            "recall": 0.6576200417536534
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8002054770496005,
            "auditor_fn_violation": 0.0122017447570628,
            "auditor_fp_violation": 0.014098832818054562,
            "ave_precision_score": 0.7996140065069005,
            "fpr": 0.1207464324917673,
            "logloss": 0.9299013014668782,
            "mae": 0.29825464008850355,
            "precision": 0.7528089887640449,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.557871283733197,
            "auditor_fn_violation": 0.0018770831044207688,
            "auditor_fp_violation": 0.0005621733317126536,
            "ave_precision_score": 0.555266221765537,
            "fpr": 0.0010964912280701754,
            "logloss": 12.009631124679947,
            "mae": 0.5177945681448731,
            "precision": 0.875,
            "recall": 0.014613778705636743
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.49294245268923786,
            "auditor_fn_violation": 0.0012687041423537024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4990034500348358,
            "fpr": 0.0,
            "logloss": 13.266631459668702,
            "mae": 0.5305016193280307,
            "precision": 1.0,
            "recall": 0.008421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5736807530166496,
            "auditor_fn_violation": 0.009831795040838004,
            "auditor_fp_violation": 0.00438343259997569,
            "ave_precision_score": 0.5357788286122591,
            "fpr": 0.03179824561403509,
            "logloss": 0.6961310344027755,
            "mae": 0.5007958226886234,
            "precision": 0.5245901639344263,
            "recall": 0.06680584551148225
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5393985318950708,
            "auditor_fn_violation": 0.010521693916459652,
            "auditor_fp_violation": 0.004702967804308201,
            "ave_precision_score": 0.5385106611369307,
            "fpr": 0.026344676180021953,
            "logloss": 0.6941136230125324,
            "mae": 0.4997945425277484,
            "precision": 0.6,
            "recall": 0.07578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 8653,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.8068482076842993,
            "auditor_fn_violation": 0.016728930886715756,
            "auditor_fp_violation": 0.007108200640168551,
            "ave_precision_score": 0.8072899902981943,
            "fpr": 0.05482456140350877,
            "logloss": 0.5825867147920751,
            "mae": 0.40736234112920466,
            "precision": 0.8333333333333334,
            "recall": 0.5219206680584552
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8054983151650752,
            "auditor_fn_violation": 0.011681784042983426,
            "auditor_fp_violation": 0.0025982134764700577,
            "ave_precision_score": 0.8059700552139891,
            "fpr": 0.0570801317233809,
            "logloss": 0.5838225463365695,
            "mae": 0.4099027293271147,
            "precision": 0.8306188925081434,
            "recall": 0.5368421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 8653,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6969406590078001,
            "auditor_fn_violation": 0.0012681756583525622,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5160098337721611,
            "fpr": 0.4375,
            "logloss": 13.195748174731616,
            "mae": 0.4628906212685826,
            "precision": 0.5365853658536586,
            "recall": 0.964509394572025
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7249129146845261,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.0036908730198692862,
            "ave_precision_score": 0.5375412484618112,
            "fpr": 0.42371020856201974,
            "logloss": 12.978648648791854,
            "mae": 0.44401745274933885,
            "precision": 0.5474794841735052,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5032211399621684,
            "auditor_fn_violation": 0.008689521298025854,
            "auditor_fp_violation": 0.005842044487662576,
            "ave_precision_score": 0.5050573139413832,
            "fpr": 0.07346491228070176,
            "logloss": 0.695771954714866,
            "mae": 0.5010497643890088,
            "precision": 0.48854961832061067,
            "recall": 0.1336116910229645
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5514735585382823,
            "auditor_fn_violation": 0.015178230978103903,
            "auditor_fp_violation": 0.006012145137413266,
            "ave_precision_score": 0.5525847365481061,
            "fpr": 0.06476399560922064,
            "logloss": 0.6934673383492346,
            "mae": 0.4999082350508442,
            "precision": 0.5317460317460317,
            "recall": 0.14105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.670956340187432,
            "auditor_fn_violation": 0.0016962421711899792,
            "auditor_fp_violation": 0.0011977837202706665,
            "ave_precision_score": 0.5530169061976501,
            "fpr": 0.4166666666666667,
            "logloss": 9.081023655647419,
            "mae": 0.432631184513397,
            "precision": 0.5529411764705883,
            "recall": 0.9812108559498957
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7033047996002136,
            "auditor_fn_violation": 0.0006239528568952568,
            "auditor_fp_violation": 0.0039174614044451585,
            "ave_precision_score": 0.5778950269886529,
            "fpr": 0.4105378704720088,
            "logloss": 9.100848738335147,
            "mae": 0.4247359025914061,
            "precision": 0.5531660692951016,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7668094440456796,
            "auditor_fn_violation": 0.012752719481375673,
            "auditor_fp_violation": 0.019516530934727123,
            "ave_precision_score": 0.7659489205445575,
            "fpr": 0.14692982456140352,
            "logloss": 1.0869233510835068,
            "mae": 0.3226613078282721,
            "precision": 0.73828125,
            "recall": 0.7891440501043842
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8036474084887848,
            "auditor_fn_violation": 0.01951816973828644,
            "auditor_fp_violation": 0.02074542543228029,
            "ave_precision_score": 0.8029488762768825,
            "fpr": 0.14489571899012074,
            "logloss": 0.9762788771434393,
            "mae": 0.3081652210937439,
            "precision": 0.7436893203883496,
            "recall": 0.8063157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.758654066871378,
            "auditor_fn_violation": 0.010166007398454385,
            "auditor_fp_violation": 0.017867995624164343,
            "ave_precision_score": 0.7591559703178139,
            "fpr": 0.1337719298245614,
            "logloss": 0.9803282318080866,
            "mae": 0.32717677930614036,
            "precision": 0.7398720682302772,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8006239421178305,
            "auditor_fn_violation": 0.010413079900629726,
            "auditor_fp_violation": 0.01956213053505071,
            "ave_precision_score": 0.8007192079510117,
            "fpr": 0.13721185510428102,
            "logloss": 0.8543187540231894,
            "mae": 0.3058668042872506,
            "precision": 0.7390396659707724,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7677479933719296,
            "auditor_fn_violation": 0.0037083836940995504,
            "auditor_fp_violation": 0.013342753535107988,
            "ave_precision_score": 0.7672110742212991,
            "fpr": 0.17324561403508773,
            "logloss": 1.0208008672759532,
            "mae": 0.32651695431712524,
            "precision": 0.7228070175438597,
            "recall": 0.860125260960334
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8088606189928707,
            "auditor_fn_violation": 0.008469582298226358,
            "auditor_fp_violation": 0.02007069557598768,
            "ave_precision_score": 0.8088289820133884,
            "fpr": 0.18111964873765093,
            "logloss": 0.9035532470280148,
            "mae": 0.31401081703210704,
            "precision": 0.7130434782608696,
            "recall": 0.8631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7504255046529087,
            "auditor_fn_violation": 0.012755008607112775,
            "auditor_fp_violation": 0.01800220817632997,
            "ave_precision_score": 0.7498868678517066,
            "fpr": 0.12719298245614036,
            "logloss": 1.0846940619793541,
            "mae": 0.33483882351279853,
            "precision": 0.7270588235294118,
            "recall": 0.6450939457202505
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7923915827351253,
            "auditor_fn_violation": 0.011489976312900803,
            "auditor_fp_violation": 0.01709987008932618,
            "ave_precision_score": 0.7917904308420181,
            "fpr": 0.12294182217343579,
            "logloss": 0.95102085946838,
            "mae": 0.3055060597522027,
            "precision": 0.7477477477477478,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6663812201821946,
            "auditor_fn_violation": 0.0014925099805882136,
            "auditor_fp_violation": 0.0026082816741623363,
            "ave_precision_score": 0.5258403544840566,
            "fpr": 0.4243421052631579,
            "logloss": 10.948781538009634,
            "mae": 0.4445742163588866,
            "precision": 0.54524089306698,
            "recall": 0.9686847599164927
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6967462715140801,
            "auditor_fn_violation": 0.003928592061933098,
            "auditor_fp_violation": 0.004723108994048283,
            "ave_precision_score": 0.5462054131161744,
            "fpr": 0.41712403951701427,
            "logloss": 10.981852758655874,
            "mae": 0.43348493141541117,
            "precision": 0.5492289442467378,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 8653,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7054595524193643,
            "auditor_fn_violation": 0.0020419001574918517,
            "auditor_fp_violation": 0.00042796077954702455,
            "ave_precision_score": 0.5252827044186273,
            "fpr": 0.4407894736842105,
            "logloss": 13.040370057314268,
            "mae": 0.4504704288829202,
            "precision": 0.5363321799307958,
            "recall": 0.9707724425887265
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7322767379428264,
            "auditor_fn_violation": 0.001215552602692241,
            "auditor_fp_violation": 0.00669694558857591,
            "ave_precision_score": 0.5474089741496552,
            "fpr": 0.42590559824368823,
            "logloss": 12.732000025491017,
            "mae": 0.43314811539196796,
            "precision": 0.5472578763127188,
            "recall": 0.9873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6264101570924498,
            "auditor_fn_violation": 0.013634032890158609,
            "auditor_fp_violation": 7.09047445403383e-05,
            "ave_precision_score": 0.6096651429928988,
            "fpr": 0.16885964912280702,
            "logloss": 1.382093566537204,
            "mae": 0.464014065357022,
            "precision": 0.5710306406685237,
            "recall": 0.4279749478079332
        },
        "train": {
            "accuracy": 0.5115257958287596,
            "auc_prc": 0.6234050654395427,
            "auditor_fn_violation": 0.000734877809232191,
            "auditor_fp_violation": 0.008489511475442855,
            "ave_precision_score": 0.6022591592627198,
            "fpr": 0.1800219538968167,
            "logloss": 1.5026933389697672,
            "mae": 0.4645610613902268,
            "precision": 0.5418994413407822,
            "recall": 0.40842105263157896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6099651002454438,
            "auditor_fn_violation": 0.002362377760685643,
            "auditor_fp_violation": 0.0005520440824926058,
            "ave_precision_score": 0.5713642143300638,
            "fpr": 0.003289473684210526,
            "logloss": 0.6964459203311804,
            "mae": 0.49474990341747016,
            "precision": 0.8636363636363636,
            "recall": 0.03966597077244259
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5973978870309417,
            "auditor_fn_violation": 0.0009197527297937506,
            "auditor_fp_violation": 0.001158118410054482,
            "ave_precision_score": 0.556522452960459,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6981072639742238,
            "mae": 0.4964579106620324,
            "precision": 0.875,
            "recall": 0.029473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6921174900496146,
            "auditor_fn_violation": 0.0018198549609932976,
            "auditor_fp_violation": 0.0026158786110773535,
            "ave_precision_score": 0.5252220899017793,
            "fpr": 0.4375,
            "logloss": 12.426839216889766,
            "mae": 0.4496387446784831,
            "precision": 0.5397923875432526,
            "recall": 0.9770354906054279
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.7283583097854187,
            "auditor_fn_violation": 0.001998960078571842,
            "auditor_fp_violation": 0.0029003313225712335,
            "ave_precision_score": 0.5545723939444609,
            "fpr": 0.429198682766191,
            "logloss": 12.11498031548951,
            "mae": 0.44094428334831454,
            "precision": 0.5432242990654206,
            "recall": 0.9789473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6174296142925046,
            "auditor_fn_violation": 0.009252646229352103,
            "auditor_fp_violation": 0.007374093432194807,
            "ave_precision_score": 0.5565863819465218,
            "fpr": 0.03728070175438596,
            "logloss": 1.3835394266886616,
            "mae": 0.46486853234183334,
            "precision": 0.711864406779661,
            "recall": 0.17536534446764093
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6208486252039926,
            "auditor_fn_violation": 0.0050609509503726354,
            "auditor_fp_violation": 0.003079084381514417,
            "ave_precision_score": 0.5498562222976907,
            "fpr": 0.027442371020856202,
            "logloss": 1.5029879335437473,
            "mae": 0.4648868623636071,
            "precision": 0.7619047619047619,
            "recall": 0.16842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7667368547834981,
            "auditor_fn_violation": 0.005656429696370382,
            "auditor_fp_violation": 0.0017396985535432115,
            "ave_precision_score": 0.5878069893700044,
            "fpr": 0.005482456140350877,
            "logloss": 0.6547937902059231,
            "mae": 0.46799188773883016,
            "precision": 0.9358974358974359,
            "recall": 0.1524008350730689
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.7634907087622682,
            "auditor_fn_violation": 0.0023941302212721737,
            "auditor_fp_violation": 0.00042044733582412725,
            "ave_precision_score": 0.571834227515616,
            "fpr": 0.003293084522502744,
            "logloss": 0.6627344467390772,
            "mae": 0.4751382055319232,
            "precision": 0.9491525423728814,
            "recall": 0.11789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4682017543859649,
            "auc_prc": 0.5114759118459365,
            "auditor_fn_violation": 0.0031406805112991487,
            "auditor_fp_violation": 0.007834974271706981,
            "ave_precision_score": 0.5136755134074269,
            "fpr": 0.046052631578947366,
            "logloss": 0.6964783253617356,
            "mae": 0.5012206328346541,
            "precision": 0.46153846153846156,
            "recall": 0.07515657620041753
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.5257967029843806,
            "auditor_fn_violation": 0.0017516898723207565,
            "auditor_fp_violation": 0.009146617790712899,
            "ave_precision_score": 0.5275228636213465,
            "fpr": 0.04939626783754116,
            "logloss": 0.6957129723929769,
            "mae": 0.5008289763288886,
            "precision": 0.4827586206896552,
            "recall": 0.08842105263157894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6775298905282052,
            "auditor_fn_violation": 0.0028087572794198443,
            "auditor_fp_violation": 0.002988128519914105,
            "ave_precision_score": 0.5238801287479232,
            "fpr": 0.4331140350877193,
            "logloss": 11.685695719120078,
            "mae": 0.4476420272565238,
            "precision": 0.5417633410672854,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7054522283782664,
            "auditor_fn_violation": 0.004587208966433647,
            "auditor_fp_violation": 0.0046803089658506315,
            "ave_precision_score": 0.5450959682348525,
            "fpr": 0.424807903402854,
            "logloss": 11.54250910815491,
            "mae": 0.4372010735649095,
            "precision": 0.54524089306698,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8049652585787591,
            "auditor_fn_violation": 0.01618640808702342,
            "auditor_fp_violation": 0.0068777602204124644,
            "ave_precision_score": 0.8054089842550635,
            "fpr": 0.0537280701754386,
            "logloss": 0.5864988649046358,
            "mae": 0.40847294035841497,
            "precision": 0.835016835016835,
            "recall": 0.5177453027139874
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8087771751962505,
            "auditor_fn_violation": 0.015349240279623326,
            "auditor_fp_violation": 0.0014879303920482597,
            "ave_precision_score": 0.8092754316940551,
            "fpr": 0.05378704720087816,
            "logloss": 0.5822772156983174,
            "mae": 0.4079489004067283,
            "precision": 0.8377483443708609,
            "recall": 0.5326315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5543283202657366,
            "auditor_fn_violation": 0.007501465040471764,
            "auditor_fp_violation": 0.002129674648515052,
            "ave_precision_score": 0.5542143307441258,
            "fpr": 0.04276315789473684,
            "logloss": 11.659443648915065,
            "mae": 0.5158335422687916,
            "precision": 0.5517241379310345,
            "recall": 0.10020876826722339
        },
        "train": {
            "accuracy": 0.4489571899012075,
            "auc_prc": 0.49104978163325297,
            "auditor_fn_violation": 0.0009336183488358663,
            "auditor_fp_violation": 0.005037815083736997,
            "ave_precision_score": 0.4990694611798295,
            "fpr": 0.06037321624588365,
            "logloss": 12.943689845813653,
            "mae": 0.535894589275944,
            "precision": 0.3373493975903614,
            "recall": 0.05894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5560307906846441,
            "auditor_fn_violation": 0.0018770831044207688,
            "auditor_fp_violation": 0.0005621733317126536,
            "ave_precision_score": 0.5549466282678407,
            "fpr": 0.0010964912280701754,
            "logloss": 12.195296865578461,
            "mae": 0.5179261325798483,
            "precision": 0.875,
            "recall": 0.014613778705636743
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.4917790119401027,
            "auditor_fn_violation": 0.0012687041423537024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4988876102957501,
            "fpr": 0.0,
            "logloss": 13.450773633504062,
            "mae": 0.5307624258701915,
            "precision": 1.0,
            "recall": 0.008421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7117810537704613,
            "auditor_fn_violation": 0.008703256052448455,
            "auditor_fp_violation": 0.0189822130383696,
            "ave_precision_score": 0.7065066149563191,
            "fpr": 0.14583333333333334,
            "logloss": 1.6589789886274144,
            "mae": 0.3189077551939284,
            "precision": 0.72,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7336418294230086,
            "auditor_fn_violation": 0.017884337627823682,
            "auditor_fp_violation": 0.024317968962426616,
            "ave_precision_score": 0.7269350824665576,
            "fpr": 0.150384193194292,
            "logloss": 1.655722716708578,
            "mae": 0.30563865004574176,
            "precision": 0.7181069958847737,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47039473684210525,
            "auc_prc": 0.5082580210965828,
            "auditor_fn_violation": 0.007361828370508756,
            "auditor_fp_violation": 0.004193509177099794,
            "ave_precision_score": 0.5221163883089771,
            "fpr": 0.03728070175438596,
            "logloss": 0.6964337863598355,
            "mae": 0.5012248411382499,
            "precision": 0.46875,
            "recall": 0.06263048016701461
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5485120567865546,
            "auditor_fn_violation": 0.006264948870529792,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5231574034541585,
            "fpr": 0.02854006586169045,
            "logloss": 0.6950524934758314,
            "mae": 0.5005401179243522,
            "precision": 0.543859649122807,
            "recall": 0.06526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6972282896863408,
            "auditor_fn_violation": 0.0012979342929348426,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5165687537650165,
            "fpr": 0.4375,
            "logloss": 13.166109604498788,
            "mae": 0.4629778707606244,
            "precision": 0.536046511627907,
            "recall": 0.9624217118997912
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.7252545850815492,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.0036908730198692862,
            "ave_precision_score": 0.5381861083968211,
            "fpr": 0.42371020856201974,
            "logloss": 12.944518650163557,
            "mae": 0.4434248661698056,
            "precision": 0.5474794841735052,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.67894307479214,
            "auditor_fn_violation": 0.0028087572794198443,
            "auditor_fp_violation": 0.0025551031157570667,
            "ave_precision_score": 0.5248138087992202,
            "fpr": 0.43201754385964913,
            "logloss": 11.70325763983242,
            "mae": 0.448193525288009,
            "precision": 0.5423925667828107,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7086881038704814,
            "auditor_fn_violation": 0.003928592061933098,
            "auditor_fp_violation": 0.005362591768295757,
            "ave_precision_score": 0.5468146786141611,
            "fpr": 0.42371020856201974,
            "logloss": 11.582344388908883,
            "mae": 0.4371959655261043,
            "precision": 0.5453474676089517,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7168038003334064,
            "auditor_fn_violation": 0.00844916309563052,
            "auditor_fp_violation": 0.01748308415380252,
            "ave_precision_score": 0.709021381104799,
            "fpr": 0.16228070175438597,
            "logloss": 1.7624443036182604,
            "mae": 0.3123672988294021,
            "precision": 0.7120622568093385,
            "recall": 0.7640918580375783
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7437294529604428,
            "auditor_fn_violation": 0.01535155121613034,
            "auditor_fp_violation": 0.02229629704226629,
            "ave_precision_score": 0.7336835209137664,
            "fpr": 0.1690450054884742,
            "logloss": 1.7140270201863155,
            "mae": 0.30458857553131924,
            "precision": 0.7049808429118773,
            "recall": 0.7747368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.710419035778848,
            "auditor_fn_violation": 0.006121122221001355,
            "auditor_fp_violation": 0.013545338519508942,
            "ave_precision_score": 0.7047834767777965,
            "fpr": 0.1524122807017544,
            "logloss": 1.725364446338714,
            "mae": 0.32019324976441405,
            "precision": 0.7203219315895373,
            "recall": 0.7473903966597077
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7405693738249448,
            "auditor_fn_violation": 0.017505344040672485,
            "auditor_fp_violation": 0.023006273980604036,
            "ave_precision_score": 0.7314538516133773,
            "fpr": 0.1690450054884742,
            "logloss": 1.6867898056747905,
            "mae": 0.3095207150682998,
            "precision": 0.7032755298651252,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7622671742314702,
            "auditor_fn_violation": 0.0021586455700838727,
            "auditor_fp_violation": 0.009035290304282658,
            "ave_precision_score": 0.7611872303640959,
            "fpr": 0.20285087719298245,
            "logloss": 1.1216896491042667,
            "mae": 0.338240158262922,
            "precision": 0.6957236842105263,
            "recall": 0.8830897703549061
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8032702472661277,
            "auditor_fn_violation": 0.010145011265815471,
            "auditor_fp_violation": 0.02523187544688265,
            "ave_precision_score": 0.8026442034501047,
            "fpr": 0.20417124039517015,
            "logloss": 0.9980333697381619,
            "mae": 0.32708389002806276,
            "precision": 0.6894824707846411,
            "recall": 0.8694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7094254176867382,
            "auditor_fn_violation": 0.010811540856316153,
            "auditor_fp_violation": 0.014396195453992953,
            "ave_precision_score": 0.7050944703703823,
            "fpr": 0.13486842105263158,
            "logloss": 1.6775034859552718,
            "mae": 0.3216880189109191,
            "precision": 0.7204545454545455,
            "recall": 0.6617954070981211
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7337543485848392,
            "auditor_fn_violation": 0.015795251025478074,
            "auditor_fp_violation": 0.02171723783723905,
            "ave_precision_score": 0.7269914290831329,
            "fpr": 0.13830954994511527,
            "logloss": 1.6621284354857988,
            "mae": 0.3032093504948322,
            "precision": 0.7296137339055794,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6775400584883701,
            "auditor_fn_violation": 0.002538640442442223,
            "auditor_fp_violation": 0.002524715368096929,
            "ave_precision_score": 0.5238946985288562,
            "fpr": 0.4309210526315789,
            "logloss": 11.688934250850036,
            "mae": 0.4475046733973868,
            "precision": 0.5435540069686411,
            "recall": 0.9770354906054279
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7061988011723175,
            "auditor_fn_violation": 0.004587208966433647,
            "auditor_fp_violation": 0.0046803089658506315,
            "ave_precision_score": 0.5455768798108194,
            "fpr": 0.424807903402854,
            "logloss": 11.545576970929938,
            "mae": 0.4374454454463626,
            "precision": 0.54524089306698,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.556911411428533,
            "auditor_fn_violation": 0.0018770831044207688,
            "auditor_fp_violation": 0.0005621733317126536,
            "ave_precision_score": 0.5554575076061095,
            "fpr": 0.0010964912280701754,
            "logloss": 11.90897685375035,
            "mae": 0.5177498849365828,
            "precision": 0.875,
            "recall": 0.014613778705636743
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.4930577883523096,
            "auditor_fn_violation": 0.0012687041423537024,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4996764657183468,
            "fpr": 0.0,
            "logloss": 13.167354853634947,
            "mae": 0.530366754676276,
            "precision": 1.0,
            "recall": 0.008421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7810578168834554,
            "auditor_fn_violation": 0.0028911658059553908,
            "auditor_fp_violation": 0.008549086341720368,
            "ave_precision_score": 0.7815433992972559,
            "fpr": 0.3607456140350877,
            "logloss": 0.6579556875672923,
            "mae": 0.41097996134735776,
            "precision": 0.5808917197452229,
            "recall": 0.9519832985386222
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7638022496180332,
            "auditor_fn_violation": 0.0007279449997111334,
            "auditor_fp_violation": 0.00492703854016658,
            "ave_precision_score": 0.764366263645663,
            "fpr": 0.3677277716794731,
            "logloss": 0.6734473847732303,
            "mae": 0.41572530225786236,
            "precision": 0.5759493670886076,
            "recall": 0.9578947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.48477659740464724,
            "auditor_fn_violation": 0.014746547998388461,
            "auditor_fp_violation": 0.0035604311008468055,
            "ave_precision_score": 0.48545941182335595,
            "fpr": 0.03837719298245614,
            "logloss": 0.6862995887695312,
            "mae": 0.49230446215522916,
            "precision": 0.5679012345679012,
            "recall": 0.09603340292275574
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5061688465318934,
            "auditor_fn_violation": 0.007750881044543302,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5068964572511632,
            "fpr": 0.02854006586169045,
            "logloss": 0.6809546415528087,
            "mae": 0.4904891674199298,
            "precision": 0.6486486486486487,
            "recall": 0.10105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7148571554380093,
            "auditor_fn_violation": 0.006317987034391827,
            "auditor_fp_violation": 0.01368208338397958,
            "ave_precision_score": 0.707731528765905,
            "fpr": 0.15021929824561403,
            "logloss": 1.7601487420555921,
            "mae": 0.31464919006518566,
            "precision": 0.7181069958847737,
            "recall": 0.7286012526096033
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7420101787505597,
            "auditor_fn_violation": 0.01878329192905425,
            "auditor_fp_violation": 0.02386479219327486,
            "ave_precision_score": 0.7321804260068178,
            "fpr": 0.16136114160263446,
            "logloss": 1.7106515639050441,
            "mae": 0.30418762472206384,
            "precision": 0.7089108910891089,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7518690008738009,
            "auditor_fn_violation": 0.012130077280884895,
            "auditor_fp_violation": 0.017353936226246914,
            "ave_precision_score": 0.751288544596388,
            "fpr": 0.12828947368421054,
            "logloss": 1.0800776417344486,
            "mae": 0.3339435772480404,
            "precision": 0.7266355140186916,
            "recall": 0.6492693110647182
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7932647157223296,
            "auditor_fn_violation": 0.010902998440117863,
            "auditor_fp_violation": 0.018187494335290384,
            "ave_precision_score": 0.7926542871774764,
            "fpr": 0.1251372118551043,
            "logloss": 0.9475514404599412,
            "mae": 0.30536269032652974,
            "precision": 0.7449664429530202,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.759053018511347,
            "auditor_fn_violation": 0.011912610335860527,
            "auditor_fp_violation": 0.019316478262631172,
            "ave_precision_score": 0.7583234722107611,
            "fpr": 0.14473684210526316,
            "logloss": 1.0882546989984299,
            "mae": 0.3322497557720022,
            "precision": 0.7338709677419355,
            "recall": 0.7599164926931107
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7965249563312382,
            "auditor_fn_violation": 0.015254491882835524,
            "auditor_fp_violation": 0.020010272006767447,
            "ave_precision_score": 0.7959666560979086,
            "fpr": 0.14928649835345773,
            "logloss": 0.9789691984142354,
            "mae": 0.3161169214789581,
            "precision": 0.7322834645669292,
            "recall": 0.783157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6769334866157101,
            "auditor_fn_violation": 0.002538640442442223,
            "auditor_fp_violation": 0.00398839188039383,
            "ave_precision_score": 0.5230058214216892,
            "fpr": 0.43530701754385964,
            "logloss": 11.726694487498454,
            "mae": 0.45018876097391775,
            "precision": 0.5410404624277456,
            "recall": 0.9770354906054279
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7082524212822019,
            "auditor_fn_violation": 0.004587208966433647,
            "auditor_fp_violation": 0.0028399077533510036,
            "ave_precision_score": 0.546932711043074,
            "fpr": 0.42590559824368823,
            "logloss": 11.560583585864421,
            "mae": 0.4402000357978466,
            "precision": 0.5446009389671361,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7141941750239658,
            "auditor_fn_violation": 0.007174120060066667,
            "auditor_fp_violation": 0.016057392326080795,
            "ave_precision_score": 0.7068481145633816,
            "fpr": 0.1611842105263158,
            "logloss": 1.7831110257655136,
            "mae": 0.31393192370146716,
            "precision": 0.7100591715976331,
            "recall": 0.7515657620041754
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7419899201079694,
            "auditor_fn_violation": 0.020209139753885264,
            "auditor_fp_violation": 0.02501032235974179,
            "ave_precision_score": 0.7316049628996029,
            "fpr": 0.17233809001097694,
            "logloss": 1.7545351000130074,
            "mae": 0.30567333050680945,
            "precision": 0.6992337164750958,
            "recall": 0.7684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.4845443619625617,
            "auditor_fn_violation": 0.014746547998388461,
            "auditor_fp_violation": 0.0035604311008468055,
            "ave_precision_score": 0.48501145368348497,
            "fpr": 0.03837719298245614,
            "logloss": 0.6862995889918775,
            "mae": 0.4923044623512971,
            "precision": 0.5679012345679012,
            "recall": 0.09603340292275574
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5061688465318934,
            "auditor_fn_violation": 0.007750881044543302,
            "auditor_fp_violation": 0.0075730873422693076,
            "ave_precision_score": 0.5068964572511632,
            "fpr": 0.02854006586169045,
            "logloss": 0.6809546419186062,
            "mae": 0.4904891676162129,
            "precision": 0.6486486486486487,
            "recall": 0.10105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6703623289943041,
            "auditor_fn_violation": 0.0011766106288686232,
            "auditor_fp_violation": 0.0013573193954863963,
            "ave_precision_score": 0.5341511875576993,
            "fpr": 0.42653508771929827,
            "logloss": 10.506526176723034,
            "mae": 0.4390596188200964,
            "precision": 0.5466200466200466,
            "recall": 0.9791231732776617
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7080645591249339,
            "auditor_fn_violation": 0.0013657634756485068,
            "auditor_fp_violation": 0.003784026022417156,
            "ave_precision_score": 0.5608223611501135,
            "fpr": 0.4226125137211855,
            "logloss": 10.5017239188047,
            "mae": 0.4299808988913529,
            "precision": 0.5481220657276995,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.678657968912152,
            "auditor_fn_violation": 0.0028087572794198443,
            "auditor_fp_violation": 0.00398839188039383,
            "ave_precision_score": 0.5237086389908855,
            "fpr": 0.43530701754385964,
            "logloss": 11.801244180808853,
            "mae": 0.4513920719592856,
            "precision": 0.5405092592592593,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7180161714610128,
            "auditor_fn_violation": 0.003928592061933098,
            "auditor_fp_violation": 0.003816755455744787,
            "ave_precision_score": 0.5532715873114085,
            "fpr": 0.424807903402854,
            "logloss": 11.635484471010848,
            "mae": 0.44006469023898465,
            "precision": 0.5447058823529412,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7772707776662564,
            "auditor_fn_violation": 0.008130974618173853,
            "auditor_fp_violation": 0.0028944329646286623,
            "ave_precision_score": 0.622758472808838,
            "fpr": 0.008771929824561403,
            "logloss": 0.6349211503564121,
            "mae": 0.4488813954879317,
            "precision": 0.9279279279279279,
            "recall": 0.2150313152400835
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7832031701911826,
            "auditor_fn_violation": 0.010514761106938613,
            "auditor_fp_violation": 0.0015206598253758848,
            "ave_precision_score": 0.6188707087116216,
            "fpr": 0.006586169045005488,
            "logloss": 0.6325299409672606,
            "mae": 0.44981032420199213,
            "precision": 0.9444444444444444,
            "recall": 0.21473684210526317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.766802300166993,
            "auditor_fn_violation": 0.004580540599934074,
            "auditor_fp_violation": 0.017510939589157653,
            "ave_precision_score": 0.766441123670365,
            "fpr": 0.16447368421052633,
            "logloss": 1.0041704663306326,
            "mae": 0.32372973882644274,
            "precision": 0.7302158273381295,
            "recall": 0.8475991649269311
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8084597426902101,
            "auditor_fn_violation": 0.00902882893292507,
            "auditor_fp_violation": 0.02365582734972156,
            "ave_precision_score": 0.8084863112116417,
            "fpr": 0.1668496158068057,
            "logloss": 0.8833917594549688,
            "mae": 0.3088143371243917,
            "precision": 0.7280858676207513,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6932556993901522,
            "auditor_fn_violation": 0.0012979342929348426,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5215556425878978,
            "fpr": 0.4375,
            "logloss": 12.693946344038801,
            "mae": 0.4627777442934498,
            "precision": 0.536046511627907,
            "recall": 0.9624217118997912
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7224000045411726,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.005193909304222594,
            "ave_precision_score": 0.5429664198333102,
            "fpr": 0.42041712403951703,
            "logloss": 12.54163431660566,
            "mae": 0.4418924147414982,
            "precision": 0.5494117647058824,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7600698090283919,
            "auditor_fn_violation": 0.010825275610738748,
            "auditor_fp_violation": 0.02168165795551234,
            "ave_precision_score": 0.7592075152399003,
            "fpr": 0.1513157894736842,
            "logloss": 1.1058006302897525,
            "mae": 0.33056749147005593,
            "precision": 0.7272727272727273,
            "recall": 0.7682672233820459
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7959826834081987,
            "auditor_fn_violation": 0.01953434629383558,
            "auditor_fp_violation": 0.02184312027311454,
            "ave_precision_score": 0.7953348700777046,
            "fpr": 0.15148188803512624,
            "logloss": 0.9990863440027998,
            "mae": 0.31601911511897846,
            "precision": 0.7341040462427746,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.712018441868447,
            "auditor_fn_violation": 0.0038113943522689836,
            "auditor_fp_violation": 0.016994347878935213,
            "ave_precision_score": 0.7061624489853853,
            "fpr": 0.15679824561403508,
            "logloss": 1.7137699818213519,
            "mae": 0.3173613621253131,
            "precision": 0.7168316831683168,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7411308480714145,
            "auditor_fn_violation": 0.01808076723092033,
            "auditor_fp_violation": 0.022842626813965903,
            "ave_precision_score": 0.7321758988923726,
            "fpr": 0.17672886937431395,
            "logloss": 1.683857767832227,
            "mae": 0.3090795333316382,
            "precision": 0.6973684210526315,
            "recall": 0.7810526315789473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8072200554461633,
            "auditor_fn_violation": 0.009671556239241116,
            "auditor_fp_violation": 0.009488574206879787,
            "ave_precision_score": 0.8076622800684546,
            "fpr": 0.06469298245614036,
            "logloss": 0.5743017969571688,
            "mae": 0.4056746545206886,
            "precision": 0.8264705882352941,
            "recall": 0.5866388308977035
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8056215670631248,
            "auditor_fn_violation": 0.02311167600670172,
            "auditor_fp_violation": 0.007150122357727672,
            "ave_precision_score": 0.8060850048527952,
            "fpr": 0.07464324917672886,
            "logloss": 0.5765632056044235,
            "mae": 0.40869765308747963,
            "precision": 0.8011695906432749,
            "recall": 0.5768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7503278241514495,
            "auditor_fn_violation": 0.012755008607112775,
            "auditor_fp_violation": 0.01800220817632997,
            "ave_precision_score": 0.7497947821734474,
            "fpr": 0.12719298245614036,
            "logloss": 1.0835798799073781,
            "mae": 0.3352323930941342,
            "precision": 0.7270588235294118,
            "recall": 0.6450939457202505
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7923044304368684,
            "auditor_fn_violation": 0.011489976312900803,
            "auditor_fp_violation": 0.01709987008932618,
            "ave_precision_score": 0.7917246605620863,
            "fpr": 0.12294182217343579,
            "logloss": 0.9491299513561181,
            "mae": 0.30598537957972544,
            "precision": 0.7477477477477478,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6812660190622252,
            "auditor_fn_violation": 0.0018496135955755775,
            "auditor_fp_violation": 0.0021398038977351046,
            "ave_precision_score": 0.5347967973988323,
            "fpr": 0.42872807017543857,
            "logloss": 11.141724266242335,
            "mae": 0.4418371128835215,
            "precision": 0.5442890442890443,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7158332073530822,
            "auditor_fn_violation": 0.0013657634756485068,
            "auditor_fp_violation": 0.0023187544688264778,
            "ave_precision_score": 0.5592454418921771,
            "fpr": 0.41822173435784854,
            "logloss": 11.080763436196357,
            "mae": 0.4301528762544616,
            "precision": 0.5507075471698113,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6904562055650005,
            "auditor_fn_violation": 0.0012979342929348426,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5200240291646113,
            "fpr": 0.4375,
            "logloss": 12.670241047698482,
            "mae": 0.46280229491949604,
            "precision": 0.536046511627907,
            "recall": 0.9624217118997912
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7226843105829558,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.005946686270758024,
            "ave_precision_score": 0.5435578899134478,
            "fpr": 0.41931942919868276,
            "logloss": 12.515969886886577,
            "mae": 0.4416376924020587,
            "precision": 0.5500588928150766,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7374124361409322,
            "auditor_fn_violation": 0.006210398124748195,
            "auditor_fp_violation": 0.01656891941169321,
            "ave_precision_score": 0.7368901431634891,
            "fpr": 0.16666666666666666,
            "logloss": 1.5163066496924582,
            "mae": 0.2850978615092442,
            "precision": 0.7185185185185186,
            "recall": 0.8100208768267223
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7667647962156685,
            "auditor_fn_violation": 0.015954705644462417,
            "auditor_fp_violation": 0.019637659996576,
            "ave_precision_score": 0.766555508178707,
            "fpr": 0.1690450054884742,
            "logloss": 1.4320054118587666,
            "mae": 0.2760602199013771,
            "precision": 0.7121495327102804,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.798550603552441,
            "auditor_fn_violation": 0.005940281287770577,
            "auditor_fp_violation": 0.006135792715043963,
            "ave_precision_score": 0.7990076174218252,
            "fpr": 0.3432017543859649,
            "logloss": 0.627489015826514,
            "mae": 0.4065885060842623,
            "precision": 0.5908496732026144,
            "recall": 0.9436325678496869
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7955542101430365,
            "auditor_fn_violation": 0.005021665029753309,
            "auditor_fp_violation": 0.004108802706975901,
            "ave_precision_score": 0.7960553432196897,
            "fpr": 0.35016465422612514,
            "logloss": 0.6330497082098849,
            "mae": 0.40882347709817235,
            "precision": 0.5862516212710766,
            "recall": 0.9515789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.7038441496605434,
            "auditor_fn_violation": 0.002362377760685643,
            "auditor_fp_violation": 0.0005520440824926058,
            "ave_precision_score": 0.5386429396702993,
            "fpr": 0.003289473684210526,
            "logloss": 0.6912423541047358,
            "mae": 0.4947470482112023,
            "precision": 0.8636363636363636,
            "recall": 0.03966597077244259
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.7052555029175573,
            "auditor_fn_violation": 0.0009197527297937506,
            "auditor_fp_violation": 0.001158118410054482,
            "ave_precision_score": 0.5318267953087988,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6925711054680918,
            "mae": 0.4962407276279709,
            "precision": 0.875,
            "recall": 0.029473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6670685909491973,
            "auditor_fn_violation": 0.0006569790865472657,
            "auditor_fp_violation": 0.0026082816741623363,
            "ave_precision_score": 0.5254649335216666,
            "fpr": 0.4243421052631579,
            "logloss": 11.032036098504925,
            "mae": 0.4448099521159077,
            "precision": 0.545774647887324,
            "recall": 0.9707724425887265
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6979860858743049,
            "auditor_fn_violation": 0.003928592061933098,
            "auditor_fp_violation": 0.004723108994048283,
            "ave_precision_score": 0.5450285269654647,
            "fpr": 0.41712403951701427,
            "logloss": 11.113968979531537,
            "mae": 0.43391442305731437,
            "precision": 0.5492289442467378,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5196601021020756,
            "auditor_fn_violation": 0.002362377760685643,
            "auditor_fp_violation": 0.0005520440824926058,
            "ave_precision_score": 0.5207913442468224,
            "fpr": 0.003289473684210526,
            "logloss": 0.6959582224847023,
            "mae": 0.4946744842291401,
            "precision": 0.8636363636363636,
            "recall": 0.03966597077244259
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.4956550739546852,
            "auditor_fn_violation": 0.0009197527297937506,
            "auditor_fp_violation": 0.001158118410054482,
            "ave_precision_score": 0.496775960829099,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6973418552356339,
            "mae": 0.49624075500946796,
            "precision": 0.875,
            "recall": 0.029473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.697277604339993,
            "auditor_fn_violation": 0.0012979342929348426,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5166188355564946,
            "fpr": 0.4375,
            "logloss": 13.144321745076743,
            "mae": 0.46310562314261405,
            "precision": 0.536046511627907,
            "recall": 0.9624217118997912
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7252840307325958,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.005193909304222594,
            "ave_precision_score": 0.5382155510548718,
            "fpr": 0.42041712403951703,
            "logloss": 12.917481298920542,
            "mae": 0.4422326397340393,
            "precision": 0.5494117647058824,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7582872008901603,
            "auditor_fn_violation": 0.00971733875398308,
            "auditor_fp_violation": 0.020808010210283213,
            "ave_precision_score": 0.7579867944227732,
            "fpr": 0.13267543859649122,
            "logloss": 0.9955125648217823,
            "mae": 0.32639732797249227,
            "precision": 0.734065934065934,
            "recall": 0.697286012526096
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8001960506190071,
            "auditor_fn_violation": 0.013227800566179445,
            "auditor_fp_violation": 0.02093676673481103,
            "ave_precision_score": 0.8000604084362788,
            "fpr": 0.13391877058177826,
            "logloss": 0.8676800342313153,
            "mae": 0.30464084057927615,
            "precision": 0.7404255319148936,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7589262745951365,
            "auditor_fn_violation": 0.012258268322162405,
            "auditor_fp_violation": 0.01925570276731089,
            "ave_precision_score": 0.7581339789000763,
            "fpr": 0.14802631578947367,
            "logloss": 1.0897629807658396,
            "mae": 0.32845059975577323,
            "precision": 0.7278225806451613,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7938631170234226,
            "auditor_fn_violation": 0.01695071927898781,
            "auditor_fp_violation": 0.02287787389601104,
            "ave_precision_score": 0.7933385850522654,
            "fpr": 0.150384193194292,
            "logloss": 0.9889914238598995,
            "mae": 0.31474919050152933,
            "precision": 0.732943469785575,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7639370377365269,
            "auditor_fn_violation": 0.003848020364062559,
            "auditor_fp_violation": 0.009584802074470244,
            "ave_precision_score": 0.7632031307533722,
            "fpr": 0.18201754385964913,
            "logloss": 1.0771502229738086,
            "mae": 0.3300164752213995,
            "precision": 0.7147766323024055,
            "recall": 0.8684759916492694
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7978447186596997,
            "auditor_fn_violation": 0.010639551678317639,
            "auditor_fp_violation": 0.020901519652765894,
            "ave_precision_score": 0.7980873040615871,
            "fpr": 0.19538968166849616,
            "logloss": 0.9943879440452842,
            "mae": 0.3220900466275104,
            "precision": 0.6993243243243243,
            "recall": 0.871578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7030238862579447,
            "auditor_fn_violation": 0.001632146650551222,
            "auditor_fp_violation": 0.003616141971557087,
            "ave_precision_score": 0.5262687148654777,
            "fpr": 0.43640350877192985,
            "logloss": 12.866636231234128,
            "mae": 0.44932848268748776,
            "precision": 0.5398843930635838,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7317844138870109,
            "auditor_fn_violation": 0.001215552602692241,
            "auditor_fp_violation": 0.009788618213677887,
            "ave_precision_score": 0.549141266614925,
            "fpr": 0.42371020856201974,
            "logloss": 12.591328915026203,
            "mae": 0.43175808833461765,
            "precision": 0.5485380116959064,
            "recall": 0.9873684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7676958531484963,
            "auditor_fn_violation": 0.002790444273523056,
            "auditor_fp_violation": 0.015371135691422561,
            "ave_precision_score": 0.7671334228035254,
            "fpr": 0.16885964912280702,
            "logloss": 1.0012830933675467,
            "mae": 0.3226903350809344,
            "precision": 0.7254901960784313,
            "recall": 0.8496868475991649
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8094973130626801,
            "auditor_fn_violation": 0.00902882893292507,
            "auditor_fp_violation": 0.023197615283134774,
            "ave_precision_score": 0.8095344781164052,
            "fpr": 0.16794731064763996,
            "logloss": 0.8804197886505541,
            "mae": 0.3077216432792769,
            "precision": 0.7267857142857143,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8072383069224525,
            "auditor_fn_violation": 0.014018606013991144,
            "auditor_fp_violation": 0.005064624610023907,
            "ave_precision_score": 0.8076799643483761,
            "fpr": 0.05592105263157895,
            "logloss": 0.5809525950853722,
            "mae": 0.406921612813644,
            "precision": 0.8338762214983714,
            "recall": 0.534446764091858
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8059609559195294,
            "auditor_fn_violation": 0.013308683343925137,
            "auditor_fp_violation": 0.0015810833945961195,
            "ave_precision_score": 0.8064297077316889,
            "fpr": 0.059275521405049394,
            "logloss": 0.5822811917109936,
            "mae": 0.40951014841312766,
            "precision": 0.8269230769230769,
            "recall": 0.5431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6466380365365691,
            "auditor_fn_violation": 0.0051940262974764775,
            "auditor_fp_violation": 0.0012965439001661199,
            "ave_precision_score": 0.6481655913177169,
            "fpr": 0.18530701754385964,
            "logloss": 0.6853364892384309,
            "mae": 0.4902313748668683,
            "precision": 0.6301969365426696,
            "recall": 0.6012526096033403
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6252524439924915,
            "auditor_fn_violation": 0.009987867583338155,
            "auditor_fp_violation": 0.008003605272963477,
            "ave_precision_score": 0.6269127254462514,
            "fpr": 0.20087815587266739,
            "logloss": 0.7047781727790934,
            "mae": 0.49457198780532985,
            "precision": 0.5942350332594235,
            "recall": 0.5642105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.8069312834122822,
            "auditor_fn_violation": 0.004708731641211589,
            "auditor_fp_violation": 0.01596876139540539,
            "ave_precision_score": 0.8073782855139062,
            "fpr": 0.3125,
            "logloss": 0.6473792703660348,
            "mae": 0.38033268348264854,
            "precision": 0.6074380165289256,
            "recall": 0.9206680584551148
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.8173965255707096,
            "auditor_fn_violation": 0.008076723092033047,
            "auditor_fp_violation": 0.018721235863402456,
            "ave_precision_score": 0.8176789386920836,
            "fpr": 0.3205268935236004,
            "logloss": 0.651944955264339,
            "mae": 0.3830264927379779,
            "precision": 0.6,
            "recall": 0.9221052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6786717727978766,
            "auditor_fn_violation": 0.0028087572794198443,
            "auditor_fp_violation": 0.00398839188039383,
            "ave_precision_score": 0.5237272281600469,
            "fpr": 0.43530701754385964,
            "logloss": 11.795383532938942,
            "mae": 0.45126489706995393,
            "precision": 0.5405092592592593,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7165622551871347,
            "auditor_fn_violation": 0.003928592061933098,
            "auditor_fp_violation": 0.003816755455744787,
            "ave_precision_score": 0.5522473777123185,
            "fpr": 0.424807903402854,
            "logloss": 11.628840799934295,
            "mae": 0.43988739808431576,
            "precision": 0.5447058823529412,
            "recall": 0.9747368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6907609076369575,
            "auditor_fn_violation": 0.0016825074167673881,
            "auditor_fp_violation": 0.005583748632551355,
            "ave_precision_score": 0.5179376843237475,
            "fpr": 0.4506578947368421,
            "logloss": 12.896342842578832,
            "mae": 0.4723712772768187,
            "precision": 0.5308219178082192,
            "recall": 0.9707724425887265
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.720828470560058,
            "auditor_fn_violation": 0.0024796348720318912,
            "auditor_fp_violation": 0.005156144573459956,
            "ave_precision_score": 0.5410767489266385,
            "fpr": 0.43907793633369924,
            "logloss": 12.720029186738499,
            "mae": 0.45690824842217465,
            "precision": 0.5391705069124424,
            "recall": 0.9852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 8653,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6833670794786315,
            "auditor_fn_violation": 0.002538640442442223,
            "auditor_fp_violation": 0.0007571613791985996,
            "ave_precision_score": 0.522108690843199,
            "fpr": 0.43201754385964913,
            "logloss": 12.128876582458004,
            "mae": 0.44916502784523166,
            "precision": 0.54292343387471,
            "recall": 0.9770354906054279
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.722256983577107,
            "auditor_fn_violation": 0.004587208966433647,
            "auditor_fp_violation": 0.003187343276367331,
            "ave_precision_score": 0.5525098846651191,
            "fpr": 0.42371020856201974,
            "logloss": 11.882696657519656,
            "mae": 0.4380364590818404,
            "precision": 0.5458823529411765,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6886940313206997,
            "auditor_fn_violation": 0.0012979342929348426,
            "auditor_fp_violation": 0.003907357886633444,
            "ave_precision_score": 0.5195497620909042,
            "fpr": 0.4375,
            "logloss": 12.625783219555107,
            "mae": 0.4626703471447782,
            "precision": 0.536046511627907,
            "recall": 0.9624217118997912
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7229804667412385,
            "auditor_fn_violation": 0.0027037957132127794,
            "auditor_fp_violation": 0.005820803834882532,
            "ave_precision_score": 0.544169304276988,
            "fpr": 0.42151481888035125,
            "logloss": 12.496446423894767,
            "mae": 0.44264545072019346,
            "precision": 0.5487661574618097,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8072181850190008,
            "auditor_fn_violation": 0.009671556239241116,
            "auditor_fp_violation": 0.009488574206879787,
            "ave_precision_score": 0.8076604127506495,
            "fpr": 0.06469298245614036,
            "logloss": 0.574307365849685,
            "mae": 0.405677970666275,
            "precision": 0.8264705882352941,
            "recall": 0.5866388308977035
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8056218983366543,
            "auditor_fn_violation": 0.02311167600670172,
            "auditor_fp_violation": 0.007150122357727672,
            "ave_precision_score": 0.8060853357516607,
            "fpr": 0.07464324917672886,
            "logloss": 0.5765693587013822,
            "mae": 0.40870105405261437,
            "precision": 0.8011695906432749,
            "recall": 0.5768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5252586482759094,
            "auditor_fn_violation": 0.009831795040838004,
            "auditor_fp_violation": 0.00438343259997569,
            "ave_precision_score": 0.5219098427297229,
            "fpr": 0.03179824561403509,
            "logloss": 0.695795232489195,
            "mae": 0.500645593854419,
            "precision": 0.5245901639344263,
            "recall": 0.06680584551148225
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.5187695275621861,
            "auditor_fn_violation": 0.010521693916459652,
            "auditor_fp_violation": 0.004702967804308201,
            "ave_precision_score": 0.5193326005429096,
            "fpr": 0.026344676180021953,
            "logloss": 0.6939895187336208,
            "mae": 0.49974468330782146,
            "precision": 0.6,
            "recall": 0.07578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7669049972835724,
            "auditor_fn_violation": 0.0002243343222356537,
            "auditor_fp_violation": 0.016910781572869824,
            "ave_precision_score": 0.7665365492260547,
            "fpr": 0.16557017543859648,
            "logloss": 1.0047279192410417,
            "mae": 0.3235676399919229,
            "precision": 0.7293906810035843,
            "recall": 0.8496868475991649
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8086238475557417,
            "auditor_fn_violation": 0.00902882893292507,
            "auditor_fp_violation": 0.02365582734972156,
            "ave_precision_score": 0.8086752115325537,
            "fpr": 0.1668496158068057,
            "logloss": 0.8839769418428564,
            "mae": 0.30875778324292763,
            "precision": 0.7280858676207513,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7394913758043322,
            "auditor_fn_violation": 0.006210398124748195,
            "auditor_fp_violation": 0.014317693772537585,
            "ave_precision_score": 0.7388838405490752,
            "fpr": 0.16666666666666666,
            "logloss": 1.4919295115442142,
            "mae": 0.28427094045741674,
            "precision": 0.7185185185185186,
            "recall": 0.8100208768267223
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7681446163607092,
            "auditor_fn_violation": 0.014868565486163273,
            "auditor_fp_violation": 0.02272177967552544,
            "ave_precision_score": 0.7677286456931787,
            "fpr": 0.16575192096597147,
            "logloss": 1.4074671078515597,
            "mae": 0.2748512082195543,
            "precision": 0.7161654135338346,
            "recall": 0.8021052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7117824091961076,
            "auditor_fn_violation": 0.008703256052448455,
            "auditor_fp_violation": 0.0189822130383696,
            "ave_precision_score": 0.7065384655248657,
            "fpr": 0.14583333333333334,
            "logloss": 1.658953088315997,
            "mae": 0.318906165923028,
            "precision": 0.72,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7336416015620023,
            "auditor_fn_violation": 0.017884337627823682,
            "auditor_fp_violation": 0.024317968962426616,
            "ave_precision_score": 0.7269494041886185,
            "fpr": 0.150384193194292,
            "logloss": 1.6556906029732095,
            "mae": 0.305637231385484,
            "precision": 0.7181069958847737,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6848794263106105,
            "auditor_fn_violation": 0.0028087572794198443,
            "auditor_fp_violation": 0.005163384789919387,
            "ave_precision_score": 0.5207333461304341,
            "fpr": 0.43859649122807015,
            "logloss": 12.318777542988922,
            "mae": 0.45518299841232074,
            "precision": 0.538638985005767,
            "recall": 0.9749478079331941
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.721207889707068,
            "auditor_fn_violation": 0.0026414004275232537,
            "auditor_fp_violation": 0.002255813250888732,
            "ave_precision_score": 0.5508055014854721,
            "fpr": 0.433589462129528,
            "logloss": 12.011907129441688,
            "mae": 0.4465536989263207,
            "precision": 0.5417633410672854,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7152865198089065,
            "auditor_fn_violation": 0.007581584441270191,
            "auditor_fp_violation": 0.01727036992018151,
            "ave_precision_score": 0.7077907348846542,
            "fpr": 0.15899122807017543,
            "logloss": 1.8038027698382924,
            "mae": 0.3139676631828253,
            "precision": 0.7123015873015873,
            "recall": 0.7494780793319415
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7426646016657653,
            "auditor_fn_violation": 0.01866081229418222,
            "auditor_fp_violation": 0.025586863916051517,
            "ave_precision_score": 0.7321447234010211,
            "fpr": 0.16794731064763996,
            "logloss": 1.7748365319779253,
            "mae": 0.30447305200800184,
            "precision": 0.7023346303501945,
            "recall": 0.76
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.7070479892319526,
            "auditor_fn_violation": 0.0026576749807713552,
            "auditor_fp_violation": 0.0011243466634253071,
            "ave_precision_score": 0.535442533787496,
            "fpr": 0.0021929824561403508,
            "logloss": 0.6914440298642999,
            "mae": 0.49538365189443556,
            "precision": 0.875,
            "recall": 0.029227557411273485
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.6893210735188896,
            "auditor_fn_violation": 0.0031128314749552513,
            "auditor_fp_violation": 0.001158118410054482,
            "ave_precision_score": 0.528925547847496,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6932428895205384,
            "mae": 0.4966695327659339,
            "precision": 0.8461538461538461,
            "recall": 0.023157894736842106
        }
    }
]