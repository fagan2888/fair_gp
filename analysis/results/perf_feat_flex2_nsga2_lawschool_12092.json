[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.026817504361276,
            "mae": 0.5219298245614035,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.122431522247318,
            "mae": 0.5246981339187706,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 12092,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5591379859719288,
            "auditor_fn_violation": 0.006744803184431682,
            "auditor_fp_violation": 0.006206743924030259,
            "ave_precision_score": 0.5453236308803271,
            "fpr": 0.05263157894736842,
            "logloss": 0.6928873926107465,
            "mae": 0.499644372481526,
            "precision": 0.5826086956521739,
            "recall": 0.1407563025210084
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5275582299037838,
            "auditor_fn_violation": 0.005054448419824655,
            "auditor_fp_violation": 0.00597267677830367,
            "ave_precision_score": 0.5261900759779258,
            "fpr": 0.059275521405049394,
            "logloss": 0.6940692312420162,
            "mae": 0.5002259253866717,
            "precision": 0.47572815533980584,
            "recall": 0.10251046025104603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 12092,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.6573692287478171,
            "auditor_fn_violation": 0.11794191360754827,
            "auditor_fp_violation": 0.08012936584580718,
            "ave_precision_score": 0.5189698217179611,
            "fpr": 0.28289473684210525,
            "logloss": 0.6940270549192875,
            "mae": 0.4996162920928838,
            "precision": 0.5168539325842697,
            "recall": 0.5798319327731093
        },
        "train": {
            "accuracy": 0.5005488474204172,
            "auc_prc": 0.6606702843648969,
            "auditor_fn_violation": 0.1195499910439124,
            "auditor_fp_violation": 0.07884136154721737,
            "ave_precision_score": 0.5229273732533573,
            "fpr": 0.278814489571899,
            "logloss": 0.6936259623224189,
            "mae": 0.4994189983272657,
            "precision": 0.5216572504708098,
            "recall": 0.5794979079497908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6488731177418623,
            "auditor_fn_violation": 0.01079444935869086,
            "auditor_fp_violation": 0.0015290519877675848,
            "ave_precision_score": 0.6494706859986057,
            "fpr": 0.01425438596491228,
            "logloss": 0.6635922858159952,
            "mae": 0.47205217483273726,
            "precision": 0.9161290322580645,
            "recall": 0.29831932773109243
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6629463683799943,
            "auditor_fn_violation": 0.0026156368696866367,
            "auditor_fp_violation": 0.0012878267416715893,
            "ave_precision_score": 0.6634311686735652,
            "fpr": 0.010976948408342482,
            "logloss": 0.6460090029380101,
            "mae": 0.463283210109539,
            "precision": 0.9386503067484663,
            "recall": 0.3200836820083682
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.742667182823975,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7290084075864173,
            "fpr": 0.4780701754385965,
            "logloss": 0.6807560525337563,
            "mae": 0.483825177803897,
            "precision": 0.5219298245614035,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7651588532068241,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7524478905093213,
            "fpr": 0.47530186608122943,
            "logloss": 0.673517624041657,
            "mae": 0.47975278797055443,
            "precision": 0.5246981339187706,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5536009024884343,
            "auditor_fn_violation": 0.02083794043933363,
            "auditor_fp_violation": 0.025614135683244818,
            "ave_precision_score": 0.5547579005197025,
            "fpr": 0.3782894736842105,
            "logloss": 0.6911697293971297,
            "mae": 0.49778196356144916,
            "precision": 0.5147679324894515,
            "recall": 0.7689075630252101
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5644812025263256,
            "auditor_fn_violation": 0.018807783988352495,
            "auditor_fp_violation": 0.02503656870226106,
            "ave_precision_score": 0.5657553944627106,
            "fpr": 0.3380900109769484,
            "logloss": 0.6878324674442358,
            "mae": 0.49614059398386273,
            "precision": 0.5443786982248521,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6105205932042314,
            "auditor_fn_violation": 0.00974172563762347,
            "auditor_fp_violation": 0.020964107516497674,
            "ave_precision_score": 0.59287442837577,
            "fpr": 0.23684210526315788,
            "logloss": 0.6832943943154043,
            "mae": 0.48963531057693455,
            "precision": 0.6190476190476191,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.5960595945364142,
            "auditor_fn_violation": 0.013071295050268916,
            "auditor_fp_violation": 0.009004646823656468,
            "ave_precision_score": 0.5914217553231137,
            "fpr": 0.23929747530186607,
            "logloss": 0.6845256875321324,
            "mae": 0.48962196131961666,
            "precision": 0.6317567567567568,
            "recall": 0.7824267782426778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5587634091372742,
            "auditor_fn_violation": 0.001746093174111762,
            "auditor_fp_violation": 0.01336411556413971,
            "ave_precision_score": 0.5536814603182254,
            "fpr": 0.06359649122807018,
            "logloss": 3.1851402692972415,
            "mae": 0.5020251943618377,
            "precision": 0.6081081081081081,
            "recall": 0.18907563025210083
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5320261947595197,
            "auditor_fn_violation": 0.00936025977246947,
            "auditor_fp_violation": 0.007392328304555819,
            "ave_precision_score": 0.5290097263411702,
            "fpr": 0.07903402854006586,
            "logloss": 2.8495548199529415,
            "mae": 0.5112357067130993,
            "precision": 0.5135135135135135,
            "recall": 0.1589958158995816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 12092,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5457444649476019,
            "auditor_fn_violation": 0.029361086539879105,
            "auditor_fp_violation": 0.030382363592467414,
            "ave_precision_score": 0.5408988552847795,
            "fpr": 0.12609649122807018,
            "logloss": 0.6933143249459764,
            "mae": 0.4998151840347993,
            "precision": 0.5381526104417671,
            "recall": 0.2815126050420168
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5380253935371508,
            "auditor_fn_violation": 0.03351873200170855,
            "auditor_fp_violation": 0.027054501943148034,
            "ave_precision_score": 0.5384617501683572,
            "fpr": 0.12294182217343579,
            "logloss": 0.6930718947835555,
            "mae": 0.4996793018541535,
            "precision": 0.5428571428571428,
            "recall": 0.27824267782426776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 12092,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5591379859719288,
            "auditor_fn_violation": 0.006744803184431682,
            "auditor_fp_violation": 0.006206743924030259,
            "ave_precision_score": 0.5453236308803271,
            "fpr": 0.05263157894736842,
            "logloss": 0.6928874321890408,
            "mae": 0.4996443766316301,
            "precision": 0.5826086956521739,
            "recall": 0.1407563025210084
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5275582299037838,
            "auditor_fn_violation": 0.005054448419824655,
            "auditor_fp_violation": 0.00597267677830367,
            "ave_precision_score": 0.5261900759779258,
            "fpr": 0.059275521405049394,
            "logloss": 0.6940693017540706,
            "mae": 0.500225944098997,
            "precision": 0.47572815533980584,
            "recall": 0.10251046025104603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 12092,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.5457444649476019,
            "auditor_fn_violation": 0.029361086539879105,
            "auditor_fp_violation": 0.030382363592467414,
            "ave_precision_score": 0.5408988552847795,
            "fpr": 0.12609649122807018,
            "logloss": 0.6933143224045694,
            "mae": 0.4998151830544597,
            "precision": 0.5381526104417671,
            "recall": 0.2815126050420168
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.5380253935371508,
            "auditor_fn_violation": 0.03351873200170855,
            "auditor_fp_violation": 0.027054501943148034,
            "ave_precision_score": 0.5384617501683572,
            "fpr": 0.12294182217343579,
            "logloss": 0.6930718924202061,
            "mae": 0.49967930097087937,
            "precision": 0.5428571428571428,
            "recall": 0.27824267782426776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5740797164751035,
            "auditor_fn_violation": 0.06304363850803481,
            "auditor_fp_violation": 0.07369125221310156,
            "ave_precision_score": 0.5630186396886492,
            "fpr": 0.32346491228070173,
            "logloss": 0.6895950811967211,
            "mae": 0.4977412236233552,
            "precision": 0.5482388973966309,
            "recall": 0.7521008403361344
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5423597751926404,
            "auditor_fn_violation": 0.06754267920212742,
            "auditor_fp_violation": 0.06603914689083641,
            "ave_precision_score": 0.5394129497640842,
            "fpr": 0.32711306256860595,
            "logloss": 0.6919097239864266,
            "mae": 0.4989142111706027,
            "precision": 0.5498489425981873,
            "recall": 0.7615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 12092,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7425918261522112,
            "auditor_fn_violation": 0.0020639834881320948,
            "auditor_fp_violation": 0.007745855464348964,
            "ave_precision_score": 0.7287874430312968,
            "fpr": 0.4473684210526316,
            "logloss": 0.6784425606035841,
            "mae": 0.4910611872022089,
            "precision": 0.5342465753424658,
            "recall": 0.9831932773109243
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7683372887605778,
            "auditor_fn_violation": 0.0011344377643768173,
            "auditor_fp_violation": 0.005265386107188779,
            "ave_precision_score": 0.7550855701112085,
            "fpr": 0.43578485181119647,
            "logloss": 0.673656402587088,
            "mae": 0.4884059081420417,
            "precision": 0.5420991926182238,
            "recall": 0.9832635983263598
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.758740461080196,
            "auditor_fn_violation": 0.0006634232640424595,
            "auditor_fp_violation": 0.006126267503621442,
            "ave_precision_score": 0.7451165812760352,
            "fpr": 0.45723684210526316,
            "logloss": 0.6683876561633213,
            "mae": 0.4714518298247927,
            "precision": 0.5304054054054054,
            "recall": 0.9894957983193278
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7788702490979562,
            "auditor_fn_violation": 7.807871252795903e-05,
            "auditor_fp_violation": 0.00729852990014273,
            "ave_precision_score": 0.7658920338015381,
            "fpr": 0.446761800219539,
            "logloss": 0.6568182186253099,
            "mae": 0.4651834718089727,
            "precision": 0.5369738339021616,
            "recall": 0.9874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6523753789706698,
            "auditor_fn_violation": 0.04600656051894444,
            "auditor_fp_violation": 0.019807258973120877,
            "ave_precision_score": 0.644948313698025,
            "fpr": 0.03508771929824561,
            "logloss": 5.042663406888018,
            "mae": 0.45067890734609745,
            "precision": 0.7575757575757576,
            "recall": 0.21008403361344538
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6515307469500727,
            "auditor_fn_violation": 0.04590569010099711,
            "auditor_fp_violation": 0.021031123324621072,
            "ave_precision_score": 0.6436354351985386,
            "fpr": 0.04610318331503842,
            "logloss": 4.627503111021444,
            "mae": 0.45852187505122355,
            "precision": 0.7123287671232876,
            "recall": 0.2175732217573222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 12092,
        "test": {
            "accuracy": 0.4824561403508772,
            "auc_prc": 0.5152167398972105,
            "auditor_fn_violation": 0.10850656051894442,
            "auditor_fp_violation": 0.05479438274585547,
            "ave_precision_score": 0.5075430039269487,
            "fpr": 0.3157894736842105,
            "logloss": 0.6950747447763,
            "mae": 0.5005999526106998,
            "precision": 0.503448275862069,
            "recall": 0.6134453781512605
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.5018951461052481,
            "auditor_fn_violation": 0.10646491739731502,
            "auditor_fp_violation": 0.07093440956439515,
            "ave_precision_score": 0.5033240008294105,
            "fpr": 0.2996706915477497,
            "logloss": 0.694115763767331,
            "mae": 0.5001211562873765,
            "precision": 0.5227272727272727,
            "recall": 0.6255230125523012
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6538099893624418,
            "auditor_fn_violation": 0.05559855521155831,
            "auditor_fp_violation": 0.02297601802671817,
            "ave_precision_score": 0.6459870871954386,
            "fpr": 0.04824561403508772,
            "logloss": 4.701781573714232,
            "mae": 0.4379606216412131,
            "precision": 0.7317073170731707,
            "recall": 0.25210084033613445
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6550899959746962,
            "auditor_fn_violation": 0.05280417399611443,
            "auditor_fp_violation": 0.02431660257109032,
            "ave_precision_score": 0.6465970669367817,
            "fpr": 0.05598243688254665,
            "logloss": 4.303353761974506,
            "mae": 0.4400130583973185,
            "precision": 0.7085714285714285,
            "recall": 0.2594142259414226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.5972969074677765,
            "auditor_fn_violation": 0.0508624502432552,
            "auditor_fp_violation": 0.02197760743602125,
            "ave_precision_score": 0.5867073228865642,
            "fpr": 0.13925438596491227,
            "logloss": 0.6847649115819288,
            "mae": 0.4940751159008135,
            "precision": 0.649171270718232,
            "recall": 0.49369747899159666
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.5997074879525532,
            "auditor_fn_violation": 0.05928241070321365,
            "auditor_fp_violation": 0.030649262414979353,
            "ave_precision_score": 0.5998614561343911,
            "fpr": 0.14489571899012074,
            "logloss": 0.6834123412953731,
            "mae": 0.4931532250212262,
            "precision": 0.6708229426433915,
            "recall": 0.5627615062761506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6174305851424509,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002092386930629353,
            "ave_precision_score": 0.533083491473756,
            "fpr": 0.47368421052631576,
            "logloss": 8.631942872741627,
            "mae": 0.47112712175013466,
            "precision": 0.5242290748898678,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.6038279656290344,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0008923523879299288,
            "ave_precision_score": 0.5194657330796157,
            "fpr": 0.47310647639956094,
            "logloss": 8.942590938840082,
            "mae": 0.4699712937573047,
            "precision": 0.5258525852585259,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6801133377647279,
            "auditor_fn_violation": 0.023560740085507886,
            "auditor_fp_violation": 0.025669463222275875,
            "ave_precision_score": 0.6708872680723919,
            "fpr": 0.07785087719298246,
            "logloss": 3.785601321099665,
            "mae": 0.3784671947905257,
            "precision": 0.73992673992674,
            "recall": 0.42436974789915966
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6922722789054718,
            "auditor_fn_violation": 0.014412411759572686,
            "auditor_fp_violation": 0.025972017654380772,
            "ave_precision_score": 0.6825808476175669,
            "fpr": 0.07244785949506037,
            "logloss": 3.3916662233423676,
            "mae": 0.36726551922867223,
            "precision": 0.7555555555555555,
            "recall": 0.42677824267782427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8043482435660833,
            "auditor_fn_violation": 0.011644460415745253,
            "auditor_fp_violation": 0.0039106510542411075,
            "ave_precision_score": 0.6815090075501576,
            "fpr": 0.01644736842105263,
            "logloss": 0.6030313889386414,
            "mae": 0.4224243797361851,
            "precision": 0.9127906976744186,
            "recall": 0.32983193277310924
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8158922166321735,
            "auditor_fn_violation": 0.012807205287306712,
            "auditor_fp_violation": 0.002803811764347987,
            "ave_precision_score": 0.6937183238712129,
            "fpr": 0.014270032930845226,
            "logloss": 0.588480921344916,
            "mae": 0.41446383647481644,
            "precision": 0.9277777777777778,
            "recall": 0.3493723849372385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6522707835572708,
            "auditor_fn_violation": 0.05153969482529854,
            "auditor_fp_violation": 0.02408256880733945,
            "ave_precision_score": 0.6444035923571201,
            "fpr": 0.043859649122807015,
            "logloss": 4.878873421231608,
            "mae": 0.44216399967141085,
            "precision": 0.7315436241610739,
            "recall": 0.22899159663865545
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6528139229941067,
            "auditor_fn_violation": 0.05028269086800565,
            "auditor_fp_violation": 0.022607950555565415,
            "ave_precision_score": 0.6443209223569644,
            "fpr": 0.052689352360043906,
            "logloss": 4.470617411133899,
            "mae": 0.44596219425413,
            "precision": 0.7073170731707317,
            "recall": 0.24267782426778242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6634192114675728,
            "auditor_fn_violation": 0.025200869821612862,
            "auditor_fp_violation": 0.023567016739095444,
            "ave_precision_score": 0.6541910641530173,
            "fpr": 0.07346491228070176,
            "logloss": 3.7564694846616224,
            "mae": 0.3920436883461087,
            "precision": 0.7462121212121212,
            "recall": 0.41386554621848737
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.674867653989493,
            "auditor_fn_violation": 0.015613446072870407,
            "auditor_fp_violation": 0.025898499986056995,
            "ave_precision_score": 0.6651995250854077,
            "fpr": 0.07244785949506037,
            "logloss": 3.370065940840379,
            "mae": 0.3865190961846211,
            "precision": 0.7411764705882353,
            "recall": 0.39539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6606970047886067,
            "auditor_fn_violation": 0.013480392156862746,
            "auditor_fp_violation": 0.04370372605826493,
            "ave_precision_score": 0.6519774472663655,
            "fpr": 0.30043859649122806,
            "logloss": 1.8113208417996274,
            "mae": 0.3769801254996932,
            "precision": 0.6051873198847262,
            "recall": 0.8823529411764706
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.6566599947446237,
            "auditor_fn_violation": 0.014152914862053289,
            "auditor_fp_violation": 0.04528688368744344,
            "ave_precision_score": 0.6496898792317909,
            "fpr": 0.283205268935236,
            "logloss": 1.8570540834720572,
            "mae": 0.35551222969249346,
            "precision": 0.625544267053701,
            "recall": 0.9016736401673641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7129171082533815,
            "auditor_fn_violation": 0.0031627782692024197,
            "auditor_fp_violation": 0.039139204088202165,
            "ave_precision_score": 0.68687981975801,
            "fpr": 0.2598684210526316,
            "logloss": 2.6265465732615243,
            "mae": 0.3441597007061295,
            "precision": 0.6441441441441441,
            "recall": 0.9012605042016807
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7038367257598324,
            "auditor_fn_violation": 0.00569056028365537,
            "auditor_fp_violation": 0.04433622418325674,
            "ave_precision_score": 0.6771182497120565,
            "fpr": 0.24259055982436883,
            "logloss": 2.7241065824772943,
            "mae": 0.3284003002617993,
            "precision": 0.6578947368421053,
            "recall": 0.8891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7833174620496447,
            "auditor_fn_violation": 0.028789805395842548,
            "auditor_fp_violation": 0.0422727547078706,
            "ave_precision_score": 0.7786379648551123,
            "fpr": 0.1962719298245614,
            "logloss": 1.3954569651059368,
            "mae": 0.30524856667216194,
            "precision": 0.6837455830388692,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7938035275711949,
            "auditor_fn_violation": 0.02480147339123406,
            "auditor_fp_violation": 0.026075956426838517,
            "ave_precision_score": 0.7866811360763768,
            "fpr": 0.16465422612513722,
            "logloss": 1.2946305588355433,
            "mae": 0.28431985751692707,
            "precision": 0.7169811320754716,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6632116344899277,
            "auditor_fn_violation": 0.02666592952970664,
            "auditor_fp_violation": 0.02382102044101079,
            "ave_precision_score": 0.654001843585795,
            "fpr": 0.07017543859649122,
            "logloss": 3.7940436767423473,
            "mae": 0.3990760269556344,
            "precision": 0.7419354838709677,
            "recall": 0.3865546218487395
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6743017391420378,
            "auditor_fn_violation": 0.015353949175351012,
            "auditor_fp_violation": 0.026271158511698183,
            "ave_precision_score": 0.6651487156899774,
            "fpr": 0.07135016465422613,
            "logloss": 3.4101263773870176,
            "mae": 0.39439401693293147,
            "precision": 0.7302904564315352,
            "recall": 0.3682008368200837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.719147228059342,
            "auditor_fn_violation": 0.007643188854489168,
            "auditor_fp_violation": 0.030925579430226953,
            "ave_precision_score": 0.7005153460840781,
            "fpr": 0.20942982456140352,
            "logloss": 1.9694839461599043,
            "mae": 0.33698764032749495,
            "precision": 0.6684027777777778,
            "recall": 0.8088235294117647
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.708740888123224,
            "auditor_fn_violation": 0.010421211689761125,
            "auditor_fp_violation": 0.03979333929924988,
            "ave_precision_score": 0.6890634870376179,
            "fpr": 0.19758507135016465,
            "logloss": 2.1069012268294043,
            "mae": 0.3225939630658052,
            "precision": 0.674502712477396,
            "recall": 0.7803347280334728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7234378504318653,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005054925156929112,
            "ave_precision_score": 0.6479861123610993,
            "fpr": 0.4769736842105263,
            "logloss": 8.291700894048764,
            "mae": 0.4745289605568376,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.73826149394864,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017847047758598363,
            "ave_precision_score": 0.6707874482931,
            "fpr": 0.47091108671789245,
            "logloss": 7.876298076595815,
            "mae": 0.47025812939872597,
            "precision": 0.5270121278941565,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5923138442305778,
            "auditor_fn_violation": 0.0006242628630399529,
            "auditor_fp_violation": 0.0025350072428778655,
            "ave_precision_score": 0.5064886365260239,
            "fpr": 0.4649122807017544,
            "logloss": 8.632226912588669,
            "mae": 0.45990801676765714,
            "precision": 0.5283648498331479,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.5743577321771076,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003353926730770692,
            "ave_precision_score": 0.4914983677191563,
            "fpr": 0.4610318331503842,
            "logloss": 8.95899996193485,
            "mae": 0.454110630192798,
            "precision": 0.532293986636971,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7850694897552735,
            "auditor_fn_violation": 0.0006173522040395106,
            "auditor_fp_violation": 0.005593111218413008,
            "ave_precision_score": 0.775466589882013,
            "fpr": 0.46271929824561403,
            "logloss": 3.080906398602137,
            "mae": 0.4554086213680548,
            "precision": 0.5295429208472687,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7959108391228467,
            "auditor_fn_violation": 0.000544254554974303,
            "auditor_fp_violation": 0.00375954145255704,
            "ave_precision_score": 0.7838152566255998,
            "fpr": 0.45773874862788144,
            "logloss": 3.062597337680578,
            "mae": 0.45028023581308313,
            "precision": 0.5335570469798657,
            "recall": 0.997907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5953580289543934,
            "auditor_fn_violation": 0.0006242628630399529,
            "auditor_fp_violation": 0.003782391759214554,
            "ave_precision_score": 0.5079577848396439,
            "fpr": 0.4649122807017544,
            "logloss": 8.739057320788302,
            "mae": 0.4617783027909657,
            "precision": 0.5283648498331479,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.5795256179575625,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0020610298050767802,
            "ave_precision_score": 0.49430952783923965,
            "fpr": 0.4632272228320527,
            "logloss": 9.039281971555729,
            "mae": 0.45638776205808645,
            "precision": 0.5311111111111111,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6620793358709006,
            "auditor_fn_violation": 0.020989974937343357,
            "auditor_fp_violation": 0.021600374215354903,
            "ave_precision_score": 0.6528736897742082,
            "fpr": 0.047149122807017545,
            "logloss": 4.086198174858896,
            "mae": 0.43511277102537177,
            "precision": 0.7378048780487805,
            "recall": 0.2542016806722689
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6726364404393069,
            "auditor_fn_violation": 0.020268315199169638,
            "auditor_fp_violation": 0.02602271949460406,
            "ave_precision_score": 0.6634821057409839,
            "fpr": 0.0570801317233809,
            "logloss": 3.7253126698686496,
            "mae": 0.4340384534457027,
            "precision": 0.717391304347826,
            "recall": 0.27615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.6174270620194392,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018408981168517662,
            "ave_precision_score": 0.5329774270178491,
            "fpr": 0.47478070175438597,
            "logloss": 8.631682593734368,
            "mae": 0.4718475478799327,
            "precision": 0.5236523652365237,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6037402001080254,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006413782788246325,
            "ave_precision_score": 0.5192656132444244,
            "fpr": 0.47420417124039516,
            "logloss": 8.94277301858639,
            "mae": 0.4703429361271675,
            "precision": 0.5252747252747253,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.585379204802658,
            "auditor_fn_violation": 0.0043698400412796705,
            "auditor_fp_violation": 0.010321100917431198,
            "ave_precision_score": 0.4999989570322619,
            "fpr": 0.40350877192982454,
            "logloss": 8.254377760467124,
            "mae": 0.43375622593042573,
            "precision": 0.5528554070473876,
            "recall": 0.9558823529411765
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5630532299751079,
            "auditor_fn_violation": 0.0071327200327012015,
            "auditor_fp_violation": 0.013699637228333209,
            "ave_precision_score": 0.48251115116624865,
            "fpr": 0.3951701427003293,
            "logloss": 8.620880142272114,
            "mae": 0.42932545745088596,
            "precision": 0.5599022004889975,
            "recall": 0.9581589958158996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7073173538013338,
            "auditor_fn_violation": 0.014551544301931299,
            "auditor_fp_violation": 0.023320557701593442,
            "ave_precision_score": 0.681494657776806,
            "fpr": 0.24232456140350878,
            "logloss": 2.538086550987277,
            "mae": 0.3392804973480834,
            "precision": 0.6503164556962026,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7026489670460723,
            "auditor_fn_violation": 0.011969007343991844,
            "auditor_fp_violation": 0.04562912110895065,
            "ave_precision_score": 0.6757708315453345,
            "fpr": 0.2261251372118551,
            "logloss": 2.6136026474038614,
            "mae": 0.32155063555317426,
            "precision": 0.6688102893890675,
            "recall": 0.8702928870292888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8043482435660833,
            "auditor_fn_violation": 0.011644460415745253,
            "auditor_fp_violation": 0.0039106510542411075,
            "ave_precision_score": 0.6815090075501576,
            "fpr": 0.01644736842105263,
            "logloss": 0.6019687033897492,
            "mae": 0.4222869201841062,
            "precision": 0.9127906976744186,
            "recall": 0.32983193277310924
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.8158922166321735,
            "auditor_fn_violation": 0.012807205287306712,
            "auditor_fp_violation": 0.002803811764347987,
            "ave_precision_score": 0.6937183238712129,
            "fpr": 0.014270032930845226,
            "logloss": 0.5883063069736982,
            "mae": 0.41477275495013605,
            "precision": 0.9277777777777778,
            "recall": 0.3493723849372385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.7420287772435761,
            "auditor_fn_violation": 0.006578947368421052,
            "auditor_fp_violation": 0.030726903267342676,
            "ave_precision_score": 0.7214834794646008,
            "fpr": 0.38706140350877194,
            "logloss": 2.6925558853523546,
            "mae": 0.390730099224093,
            "precision": 0.5668711656441717,
            "recall": 0.9705882352941176
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7360901463261509,
            "auditor_fn_violation": 0.003281602358895692,
            "auditor_fp_violation": 0.02845133764129969,
            "ave_precision_score": 0.711258149246246,
            "fpr": 0.3589462129527991,
            "logloss": 2.8084600081759494,
            "mae": 0.3686761870632452,
            "precision": 0.5891959798994975,
            "recall": 0.9811715481171548
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6427064280991396,
            "auditor_fn_violation": 0.05192208462332304,
            "auditor_fp_violation": 0.021738693062932562,
            "ave_precision_score": 0.6348760520656276,
            "fpr": 0.047149122807017545,
            "logloss": 4.894775104719192,
            "mae": 0.4485930499337226,
            "precision": 0.7225806451612903,
            "recall": 0.23529411764705882
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6449843654030075,
            "auditor_fn_violation": 0.048271015804049994,
            "auditor_fp_violation": 0.02340396944707108,
            "ave_precision_score": 0.6364984851103764,
            "fpr": 0.050493962678375415,
            "logloss": 4.4861357084600995,
            "mae": 0.45326746224300635,
            "precision": 0.7032258064516129,
            "recall": 0.2280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8087346905024251,
            "auditor_fn_violation": 0.0073921015774730935,
            "auditor_fp_violation": 0.003457971189441494,
            "ave_precision_score": 0.6924020728908914,
            "fpr": 0.020833333333333332,
            "logloss": 0.595167732690123,
            "mae": 0.4177778193629102,
            "precision": 0.9030612244897959,
            "recall": 0.37184873949579833
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8186306643967136,
            "auditor_fn_violation": 0.01435270450881603,
            "auditor_fp_violation": 0.0034806813313289216,
            "ave_precision_score": 0.7053746443784252,
            "fpr": 0.020856201975850714,
            "logloss": 0.5806382284796853,
            "mae": 0.40860410065734687,
            "precision": 0.909952606635071,
            "recall": 0.401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7125962134820782,
            "auditor_fn_violation": 0.0007670831490490936,
            "auditor_fp_violation": 0.03793457267020763,
            "ave_precision_score": 0.686015851100904,
            "fpr": 0.2631578947368421,
            "logloss": 2.6911917006597488,
            "mae": 0.3457610113589413,
            "precision": 0.6412556053811659,
            "recall": 0.9012605042016807
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7017997224862628,
            "auditor_fn_violation": 0.0073945133629420064,
            "auditor_fp_violation": 0.04385202160912431,
            "ave_precision_score": 0.6743348308492008,
            "fpr": 0.24588364434687157,
            "logloss": 2.813816418370876,
            "mae": 0.3316783105199596,
            "precision": 0.6548536209553159,
            "recall": 0.8891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6656132810641417,
            "auditor_fn_violation": 0.019736842105263164,
            "auditor_fp_violation": 0.018801303718010625,
            "ave_precision_score": 0.6566382407817808,
            "fpr": 0.043859649122807015,
            "logloss": 4.09464674504433,
            "mae": 0.4363802391676213,
            "precision": 0.7484276729559748,
            "recall": 0.25
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6753890507929692,
            "auditor_fn_violation": 0.022674976691207903,
            "auditor_fp_violation": 0.02688972096242233,
            "ave_precision_score": 0.6662345102691885,
            "fpr": 0.05378704720087816,
            "logloss": 3.7764845561305167,
            "mae": 0.43454076474680614,
            "precision": 0.7231638418079096,
            "recall": 0.26778242677824265
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6621013057242606,
            "auditor_fn_violation": 0.020989974937343357,
            "auditor_fp_violation": 0.021600374215354903,
            "ave_precision_score": 0.6528956334679896,
            "fpr": 0.047149122807017545,
            "logloss": 4.086293861422709,
            "mae": 0.4351256179839973,
            "precision": 0.7378048780487805,
            "recall": 0.2542016806722689
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6726327901324269,
            "auditor_fn_violation": 0.020268315199169638,
            "auditor_fp_violation": 0.02602271949460406,
            "ave_precision_score": 0.6634784581577963,
            "fpr": 0.0570801317233809,
            "logloss": 3.72542501484263,
            "mae": 0.43405238059181794,
            "precision": 0.717391304347826,
            "recall": 0.27615062761506276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7211506702034265,
            "auditor_fn_violation": 0.011533889871738172,
            "auditor_fp_violation": 0.020023539352969584,
            "ave_precision_score": 0.6878400537233753,
            "fpr": 0.3300438596491228,
            "logloss": 9.375489673203143,
            "mae": 0.4746167386227722,
            "precision": 0.5340557275541795,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7603848860262776,
            "auditor_fn_violation": 0.014481304741215003,
            "auditor_fp_violation": 0.019099383212113682,
            "ave_precision_score": 0.7320233343670954,
            "fpr": 0.33699231613611413,
            "logloss": 8.376992164404163,
            "mae": 0.45661390213876024,
            "precision": 0.5465288035450517,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6432942276504118,
            "auditor_fn_violation": 0.05692079463364295,
            "auditor_fp_violation": 0.02367264204088202,
            "ave_precision_score": 0.6354936888535668,
            "fpr": 0.049342105263157895,
            "logloss": 4.674218207334018,
            "mae": 0.43654915514792925,
            "precision": 0.7368421052631579,
            "recall": 0.2647058823529412
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6451735891368109,
            "auditor_fn_violation": 0.05388120094245599,
            "auditor_fp_violation": 0.023492697667461843,
            "ave_precision_score": 0.6367514704253394,
            "fpr": 0.06147091108671789,
            "logloss": 4.254807967892842,
            "mae": 0.4384333749787632,
            "precision": 0.7005347593582888,
            "recall": 0.27405857740585776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8087346905024251,
            "auditor_fn_violation": 0.0073921015774730935,
            "auditor_fp_violation": 0.003457971189441494,
            "ave_precision_score": 0.6924020728908914,
            "fpr": 0.020833333333333332,
            "logloss": 0.5952059119041017,
            "mae": 0.41778286059566755,
            "precision": 0.9030612244897959,
            "recall": 0.37184873949579833
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8186306643967136,
            "auditor_fn_violation": 0.01435270450881603,
            "auditor_fp_violation": 0.0034806813313289216,
            "ave_precision_score": 0.7053746443784252,
            "fpr": 0.020856201975850714,
            "logloss": 0.5806430036498205,
            "mae": 0.40859286899297087,
            "precision": 0.909952606635071,
            "recall": 0.401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.706696517535623,
            "auditor_fn_violation": 0.015097486362966244,
            "auditor_fp_violation": 0.02377072267825528,
            "ave_precision_score": 0.6815515180494077,
            "fpr": 0.2412280701754386,
            "logloss": 2.5085431870493506,
            "mae": 0.3388371537995113,
            "precision": 0.6513470681458003,
            "recall": 0.8634453781512605
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7032074941670614,
            "auditor_fn_violation": 0.012625787102315265,
            "auditor_fp_violation": 0.04559109472878319,
            "ave_precision_score": 0.6768628869372013,
            "fpr": 0.2239297475301866,
            "logloss": 2.5775700588469177,
            "mae": 0.32044616658629926,
            "precision": 0.6714975845410628,
            "recall": 0.8723849372384938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8083043792945048,
            "auditor_fn_violation": 0.01855742296918768,
            "auditor_fp_violation": 0.022148619829389992,
            "ave_precision_score": 0.8037468729957199,
            "fpr": 0.13706140350877194,
            "logloss": 1.0616433640646366,
            "mae": 0.27643776210118026,
            "precision": 0.7484909456740443,
            "recall": 0.7815126050420168
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8144067269256243,
            "auditor_fn_violation": 0.014715540878798877,
            "auditor_fp_violation": 0.01613079046704001,
            "ave_precision_score": 0.8082259327542825,
            "fpr": 0.1207464324917673,
            "logloss": 1.0634798082981993,
            "mae": 0.260375415774686,
            "precision": 0.7717842323651453,
            "recall": 0.7782426778242678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7105829802857849,
            "auditor_fn_violation": 0.00020962332301341922,
            "auditor_fp_violation": 0.03747686302913249,
            "ave_precision_score": 0.6836099467950816,
            "fpr": 0.26096491228070173,
            "logloss": 2.701752726832548,
            "mae": 0.34473975138478286,
            "precision": 0.6421052631578947,
            "recall": 0.8970588235294118
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7004505097300834,
            "auditor_fn_violation": 0.006563204717791384,
            "auditor_fp_violation": 0.04375315302068889,
            "ave_precision_score": 0.6727589375061469,
            "fpr": 0.24259055982436883,
            "logloss": 2.8122457099813194,
            "mae": 0.33110977048789786,
            "precision": 0.656298600311042,
            "recall": 0.8828451882845189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 12092,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7119093460504211,
            "auditor_fn_violation": 0.0037663091552410464,
            "auditor_fp_violation": 0.03730082085948818,
            "ave_precision_score": 0.6853879027918248,
            "fpr": 0.2719298245614035,
            "logloss": 2.6759563333929504,
            "mae": 0.3457019387273308,
            "precision": 0.6358296622613803,
            "recall": 0.9096638655462185
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7027902427175996,
            "auditor_fn_violation": 0.006554018986905742,
            "auditor_fp_violation": 0.04260982652365368,
            "ave_precision_score": 0.6756648771807918,
            "fpr": 0.24478594950603733,
            "logloss": 2.773119971065798,
            "mae": 0.3308956949856409,
            "precision": 0.6563944530046225,
            "recall": 0.891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 12092,
        "test": {
            "accuracy": 0.35635964912280704,
            "auc_prc": 0.4763798230485,
            "auditor_fn_violation": 0.023671310629514972,
            "auditor_fp_violation": 0.022525853050056336,
            "ave_precision_score": 0.4758624202131783,
            "fpr": 0.3059210526315789,
            "logloss": 0.7336600494726409,
            "mae": 0.5155127779825738,
            "precision": 0.37583892617449666,
            "recall": 0.35294117647058826
        },
        "train": {
            "accuracy": 0.3677277716794731,
            "auc_prc": 0.47506624624016724,
            "auditor_fn_violation": 0.01586835010494697,
            "auditor_fp_violation": 0.026192570659352085,
            "ave_precision_score": 0.47821300362591107,
            "fpr": 0.2996706915477497,
            "logloss": 0.7298516381129762,
            "mae": 0.5135810642812961,
            "precision": 0.390625,
            "recall": 0.36610878661087864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.645278926317996,
            "auditor_fn_violation": 0.0686919504643963,
            "auditor_fp_violation": 0.026285610816030907,
            "ave_precision_score": 0.6348369956509411,
            "fpr": 0.08442982456140351,
            "logloss": 4.252975422992074,
            "mae": 0.4096471732483264,
            "precision": 0.6956521739130435,
            "recall": 0.3697478991596639
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6500129231974627,
            "auditor_fn_violation": 0.06396024415672694,
            "auditor_fp_violation": 0.032000466456930055,
            "ave_precision_score": 0.6391186363416774,
            "fpr": 0.0867178924259056,
            "logloss": 3.7575281455789327,
            "mae": 0.40115374767793166,
            "precision": 0.7158273381294964,
            "recall": 0.41631799163179917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6603914077429838,
            "auditor_fn_violation": 0.03426765443019313,
            "auditor_fp_violation": 0.03882987284725575,
            "ave_precision_score": 0.6502025712288085,
            "fpr": 0.21820175438596492,
            "logloss": 1.8064428042660856,
            "mae": 0.3447930690013699,
            "precision": 0.6563039723661486,
            "recall": 0.7983193277310925
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6607563872341133,
            "auditor_fn_violation": 0.026994566640181142,
            "auditor_fp_violation": 0.039722356722937266,
            "ave_precision_score": 0.6506504008520309,
            "fpr": 0.1964873765093304,
            "logloss": 1.9411263949366675,
            "mae": 0.3235097001787517,
            "precision": 0.6837455830388692,
            "recall": 0.8096234309623431
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7819258835980214,
            "auditor_fn_violation": 0.021128188117352217,
            "auditor_fp_violation": 0.007298205375824887,
            "ave_precision_score": 0.774895965464532,
            "fpr": 0.06359649122807018,
            "logloss": 3.495643878529564,
            "mae": 0.3482133630450387,
            "precision": 0.7851851851851852,
            "recall": 0.44537815126050423
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8091663193038946,
            "auditor_fn_violation": 0.013029959261283522,
            "auditor_fp_violation": 0.005815501073611467,
            "ave_precision_score": 0.8015789874126433,
            "fpr": 0.038419319429198684,
            "logloss": 3.024879108600416,
            "mae": 0.3283583505556108,
            "precision": 0.8622047244094488,
            "recall": 0.4581589958158996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.779638958986303,
            "auditor_fn_violation": 0.016435850656051906,
            "auditor_fp_violation": 0.007947046515370997,
            "ave_precision_score": 0.7717197442378959,
            "fpr": 0.07675438596491228,
            "logloss": 3.3792150210282292,
            "mae": 0.3313676577532495,
            "precision": 0.7763578274760383,
            "recall": 0.5105042016806722
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8075709289912458,
            "auditor_fn_violation": 0.016887966233253268,
            "auditor_fp_violation": 0.006811792233999135,
            "ave_precision_score": 0.799863817838061,
            "fpr": 0.05598243688254665,
            "logloss": 2.8555871039799547,
            "mae": 0.3072178097629241,
            "precision": 0.8288590604026845,
            "recall": 0.5167364016736402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 12092,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7832955655652977,
            "auditor_fn_violation": 0.028789805395842548,
            "auditor_fp_violation": 0.0422727547078706,
            "ave_precision_score": 0.7786265275683486,
            "fpr": 0.1962719298245614,
            "logloss": 1.392217639554752,
            "mae": 0.3048650974301592,
            "precision": 0.6837455830388692,
            "recall": 0.8130252100840336
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7938590436953817,
            "auditor_fn_violation": 0.02480147339123406,
            "auditor_fp_violation": 0.026075956426838517,
            "ave_precision_score": 0.7867391707227289,
            "fpr": 0.16465422612513722,
            "logloss": 1.292365422833523,
            "mae": 0.28398966153352473,
            "precision": 0.7169811320754716,
            "recall": 0.7949790794979079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7132920606211353,
            "auditor_fn_violation": 0.0031627782692024197,
            "auditor_fp_violation": 0.039139204088202165,
            "ave_precision_score": 0.6871390426470327,
            "fpr": 0.2598684210526316,
            "logloss": 2.630159662304692,
            "mae": 0.34430279828148347,
            "precision": 0.6441441441441441,
            "recall": 0.9012605042016807
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7036999949703485,
            "auditor_fn_violation": 0.005961539344781818,
            "auditor_fp_violation": 0.043821600504990336,
            "ave_precision_score": 0.6769543708570809,
            "fpr": 0.24368825466520308,
            "logloss": 2.727365368270198,
            "mae": 0.32855847022429907,
            "precision": 0.6563467492260062,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.56419065366467,
            "auditor_fn_violation": 0.07659774436090226,
            "auditor_fp_violation": 0.04467698776758411,
            "ave_precision_score": 0.5650851448480183,
            "fpr": 0.26644736842105265,
            "logloss": 0.6897812122888742,
            "mae": 0.4965607690902656,
            "precision": 0.5573770491803278,
            "recall": 0.6428571428571429
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.564662986557629,
            "auditor_fn_violation": 0.07304493200262713,
            "auditor_fp_violation": 0.06286774678486956,
            "ave_precision_score": 0.5692629489417574,
            "fpr": 0.24478594950603733,
            "logloss": 0.6881783364489888,
            "mae": 0.49587957592094245,
            "precision": 0.5686653771760155,
            "recall": 0.6150627615062761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.674762696996088,
            "auditor_fn_violation": 0.005878667256376236,
            "auditor_fp_violation": 0.01513208192499598,
            "ave_precision_score": 0.648366289710063,
            "fpr": 0.3607456140350877,
            "logloss": 2.973649051752586,
            "mae": 0.4037770016781762,
            "precision": 0.5710560625814863,
            "recall": 0.9201680672268907
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.670756750420126,
            "auditor_fn_violation": 0.008519765396433182,
            "auditor_fp_violation": 0.014848033909390752,
            "ave_precision_score": 0.6437743690403137,
            "fpr": 0.3600439077936334,
            "logloss": 3.0085224718817427,
            "mae": 0.40343224315029497,
            "precision": 0.574025974025974,
            "recall": 0.9246861924686193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7204991397675393,
            "auditor_fn_violation": 0.009078302373581015,
            "auditor_fp_violation": 0.020285087719298243,
            "ave_precision_score": 0.6985901952900104,
            "fpr": 0.32346491228070173,
            "logloss": 8.398891543844968,
            "mae": 0.46924133257045747,
            "precision": 0.5376175548589341,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7573704466819455,
            "auditor_fn_violation": 0.009408484859619072,
            "auditor_fp_violation": 0.016391904944189968,
            "ave_precision_score": 0.7372942920366603,
            "fpr": 0.33040614709110866,
            "logloss": 7.465770754032571,
            "mae": 0.4513260653695864,
            "precision": 0.5507462686567164,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6804721953449312,
            "auditor_fn_violation": 0.023058565531475773,
            "auditor_fp_violation": 0.024927571221632062,
            "ave_precision_score": 0.6712988535558957,
            "fpr": 0.07894736842105263,
            "logloss": 3.7795717576975645,
            "mae": 0.3775834016126426,
            "precision": 0.7381818181818182,
            "recall": 0.4264705882352941
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.692402011782909,
            "auditor_fn_violation": 0.014063353985918278,
            "auditor_fp_violation": 0.025972017654380772,
            "ave_precision_score": 0.6827238855256227,
            "fpr": 0.07244785949506037,
            "logloss": 3.385507743817602,
            "mae": 0.3660324445851248,
            "precision": 0.7564575645756457,
            "recall": 0.42887029288702927
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.6666478775234146,
            "auditor_fn_violation": 0.023510061919504652,
            "auditor_fp_violation": 0.023815990664735234,
            "ave_precision_score": 0.6574727868074133,
            "fpr": 0.07346491228070176,
            "logloss": 3.741655215546953,
            "mae": 0.39296309870252644,
            "precision": 0.73828125,
            "recall": 0.39705882352941174
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.677704878878737,
            "auditor_fn_violation": 0.014380261701472953,
            "auditor_fp_violation": 0.02623313213153072,
            "ave_precision_score": 0.6680353055784678,
            "fpr": 0.07244785949506037,
            "logloss": 3.352974518038275,
            "mae": 0.3869240000249721,
            "precision": 0.7441860465116279,
            "recall": 0.401673640167364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6281939151754434,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005054925156929112,
            "ave_precision_score": 0.525458566784944,
            "fpr": 0.4769736842105263,
            "logloss": 9.798971807466504,
            "mae": 0.4751254971090116,
            "precision": 0.5225027442371021,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.6127329412220848,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011560019570910443,
            "ave_precision_score": 0.5106008837810478,
            "fpr": 0.47310647639956094,
            "logloss": 10.074967197075148,
            "mae": 0.4712790974735821,
            "precision": 0.5258525852585259,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.7793660313039479,
            "auditor_fn_violation": 0.01857585139318885,
            "auditor_fp_violation": 0.008047642040882022,
            "ave_precision_score": 0.7714129856588763,
            "fpr": 0.07456140350877193,
            "logloss": 3.4195946181495254,
            "mae": 0.336532253488675,
            "precision": 0.7755775577557755,
            "recall": 0.49369747899159666
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8076508066572234,
            "auditor_fn_violation": 0.01585457150861851,
            "auditor_fp_violation": 0.007508942537069384,
            "ave_precision_score": 0.7999564019716069,
            "fpr": 0.050493962678375415,
            "logloss": 2.903351580225188,
            "mae": 0.3131103710525641,
            "precision": 0.8380281690140845,
            "recall": 0.497907949790795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7881491943738385,
            "auditor_fn_violation": 0.028983303847854937,
            "auditor_fp_violation": 0.027995734749718334,
            "ave_precision_score": 0.7835773647480391,
            "fpr": 0.14692982456140352,
            "logloss": 1.2732087173421975,
            "mae": 0.29880472226376065,
            "precision": 0.722567287784679,
            "recall": 0.7331932773109243
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7981765148805794,
            "auditor_fn_violation": 0.02637223337267888,
            "auditor_fp_violation": 0.01870390885837202,
            "ave_precision_score": 0.7913058907030874,
            "fpr": 0.1163556531284303,
            "logloss": 1.215155620439382,
            "mae": 0.27629853112874136,
            "precision": 0.7705627705627706,
            "recall": 0.7447698744769874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7064071436491239,
            "auditor_fn_violation": 0.01371074745687749,
            "auditor_fp_violation": 0.02377072267825528,
            "ave_precision_score": 0.6808468785780906,
            "fpr": 0.2412280701754386,
            "logloss": 2.528294126017624,
            "mae": 0.33842784163927614,
            "precision": 0.6507936507936508,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7033514552532438,
            "auditor_fn_violation": 0.011969007343991844,
            "auditor_fp_violation": 0.04559109472878319,
            "ave_precision_score": 0.6770136181887367,
            "fpr": 0.2239297475301866,
            "logloss": 2.578289910877475,
            "mae": 0.32012983225685576,
            "precision": 0.6709677419354839,
            "recall": 0.8702928870292888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6568448803453408,
            "auditor_fn_violation": 0.016972578505086246,
            "auditor_fp_violation": 0.05369286174150974,
            "ave_precision_score": 0.6481629984898749,
            "fpr": 0.2708333333333333,
            "logloss": 1.8036635877782545,
            "mae": 0.3734942623026048,
            "precision": 0.6251896813353566,
            "recall": 0.865546218487395
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6548021931537727,
            "auditor_fn_violation": 0.017209466814250746,
            "auditor_fp_violation": 0.0482580115245283,
            "ave_precision_score": 0.6473052974303694,
            "fpr": 0.2601536772777168,
            "logloss": 1.849479877791962,
            "mae": 0.35069890338421467,
            "precision": 0.6414523449319214,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.725158323910726,
            "auditor_fn_violation": 0.009702565236620966,
            "auditor_fp_violation": 0.020692499597617917,
            "ave_precision_score": 0.6928432692866682,
            "fpr": 0.32785087719298245,
            "logloss": 9.367033007947777,
            "mae": 0.4735701886926569,
            "precision": 0.5349922239502333,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.7635998351002378,
            "auditor_fn_violation": 0.014481304741215003,
            "auditor_fp_violation": 0.019099383212113682,
            "ave_precision_score": 0.7369184742706172,
            "fpr": 0.33699231613611413,
            "logloss": 8.35133790197606,
            "mae": 0.45475062919120096,
            "precision": 0.5465288035450517,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.719087573846712,
            "auditor_fn_violation": 0.009702565236620966,
            "auditor_fp_violation": 0.020285087719298243,
            "ave_precision_score": 0.6964927137341905,
            "fpr": 0.32346491228070173,
            "logloss": 8.435093634450583,
            "mae": 0.46963639822944225,
            "precision": 0.5383411580594679,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7574120208948605,
            "auditor_fn_violation": 0.009408484859619072,
            "auditor_fp_violation": 0.016391904944189968,
            "ave_precision_score": 0.7373679282221038,
            "fpr": 0.33040614709110866,
            "logloss": 7.482782199298311,
            "mae": 0.45193638499272853,
            "precision": 0.5507462686567164,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5814798549313598,
            "auditor_fn_violation": 0.003740970072239421,
            "auditor_fp_violation": 0.013955114276516984,
            "ave_precision_score": 0.5008265427289753,
            "fpr": 0.37609649122807015,
            "logloss": 7.9084109816428505,
            "mae": 0.4204572287769559,
            "precision": 0.5663716814159292,
            "recall": 0.9411764705882353
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.5606366792220756,
            "auditor_fn_violation": 0.010425804555203947,
            "auditor_fp_violation": 0.012348433186382497,
            "ave_precision_score": 0.4845740232518355,
            "fpr": 0.3677277716794731,
            "logloss": 8.286475743147768,
            "mae": 0.4193377908941309,
            "precision": 0.5705128205128205,
            "recall": 0.9309623430962343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7796495921680185,
            "auditor_fn_violation": 0.01965391419725786,
            "auditor_fp_violation": 0.011357234830194754,
            "ave_precision_score": 0.7717057945633348,
            "fpr": 0.08881578947368421,
            "logloss": 3.334426365357411,
            "mae": 0.32152527445093215,
            "precision": 0.7624633431085044,
            "recall": 0.5462184873949579
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8073770285892545,
            "auditor_fn_violation": 0.026013989868138843,
            "auditor_fp_violation": 0.011060606444710911,
            "ave_precision_score": 0.798771301384092,
            "fpr": 0.06366630076838639,
            "logloss": 2.80497541393649,
            "mae": 0.29476613597130624,
            "precision": 0.8226299694189603,
            "recall": 0.5627615062761506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7129685828895809,
            "auditor_fn_violation": 0.000435371517027867,
            "auditor_fp_violation": 0.03392081120231773,
            "ave_precision_score": 0.6869498313074547,
            "fpr": 0.2598684210526316,
            "logloss": 2.6238648705960226,
            "mae": 0.3415290596384265,
            "precision": 0.6398176291793313,
            "recall": 0.884453781512605
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7035061918752963,
            "auditor_fn_violation": 0.006443790216278034,
            "auditor_fp_violation": 0.04365428443225348,
            "ave_precision_score": 0.6763400894867355,
            "fpr": 0.23929747530186607,
            "logloss": 2.743932127045127,
            "mae": 0.3261746800949681,
            "precision": 0.6599063962558502,
            "recall": 0.8849372384937239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7842641990703446,
            "auditor_fn_violation": 0.029577620521892976,
            "auditor_fp_violation": 0.036154031868662485,
            "ave_precision_score": 0.7797345535925865,
            "fpr": 0.15789473684210525,
            "logloss": 1.3237863866554864,
            "mae": 0.30360322325161,
            "precision": 0.7090909090909091,
            "recall": 0.7373949579831933
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7933493648625052,
            "auditor_fn_violation": 0.028654887497760982,
            "auditor_fp_violation": 0.022103467245343674,
            "ave_precision_score": 0.7864437749305893,
            "fpr": 0.11964873765093303,
            "logloss": 1.2657923090260133,
            "mae": 0.2809587809704382,
            "precision": 0.7645788336933045,
            "recall": 0.7405857740585774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7248453316307274,
            "auditor_fn_violation": 0.0026099255491670355,
            "auditor_fp_violation": 0.025780118300337995,
            "ave_precision_score": 0.696390901255336,
            "fpr": 0.3673245614035088,
            "logloss": 3.0576718934650686,
            "mae": 0.38834272162600775,
            "precision": 0.5694087403598972,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7167258189322252,
            "auditor_fn_violation": 0.004156543225753117,
            "auditor_fp_violation": 0.03149344805469715,
            "ave_precision_score": 0.6854136230073341,
            "fpr": 0.3446761800219539,
            "logloss": 3.1702317633976254,
            "mae": 0.3726572935129735,
            "precision": 0.5879265091863517,
            "recall": 0.9372384937238494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.5840071947562118,
            "auditor_fn_violation": 0.003740970072239421,
            "auditor_fp_violation": 0.01397271849348141,
            "ave_precision_score": 0.5016842481841688,
            "fpr": 0.3782894736842105,
            "logloss": 7.954265291878095,
            "mae": 0.4210680261265288,
            "precision": 0.5649432534678437,
            "recall": 0.9411764705882353
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.5614112592327543,
            "auditor_fn_violation": 0.011681953253815524,
            "auditor_fp_violation": 0.013245855758334776,
            "ave_precision_score": 0.48436741957357854,
            "fpr": 0.36882546652030734,
            "logloss": 8.329392293565563,
            "mae": 0.42060761594411744,
            "precision": 0.5675675675675675,
            "recall": 0.9225941422594143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7363438363409294,
            "auditor_fn_violation": 0.009702565236620966,
            "auditor_fp_violation": 0.020083896668276206,
            "ave_precision_score": 0.7133895187030331,
            "fpr": 0.3267543859649123,
            "logloss": 8.963388905051515,
            "mae": 0.4697895678815748,
            "precision": 0.5358255451713395,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.776022297318144,
            "auditor_fn_violation": 0.0135673245180936,
            "auditor_fp_violation": 0.01651612445273702,
            "ave_precision_score": 0.757293611287459,
            "fpr": 0.33150384193194293,
            "logloss": 8.026964307157153,
            "mae": 0.45130983890568904,
            "precision": 0.5499254843517138,
            "recall": 0.7719665271966527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7236522523879054,
            "auditor_fn_violation": 0.009702565236620966,
            "auditor_fp_violation": 0.020194551746338336,
            "ave_precision_score": 0.6930866054946594,
            "fpr": 0.3267543859649123,
            "logloss": 9.091266132459962,
            "mae": 0.4725494531553229,
            "precision": 0.5358255451713395,
            "recall": 0.7226890756302521
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7619621392447811,
            "auditor_fn_violation": 0.014481304741215003,
            "auditor_fp_violation": 0.01488859538156939,
            "ave_precision_score": 0.7363965744900983,
            "fpr": 0.3336992316136114,
            "logloss": 8.086522201400463,
            "mae": 0.45350078666664,
            "precision": 0.5489614243323442,
            "recall": 0.7740585774058577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7439808913711576,
            "auditor_fn_violation": 0.002607621996166888,
            "auditor_fp_violation": 0.0222416706904877,
            "ave_precision_score": 0.7221140867670289,
            "fpr": 0.40350877192982454,
            "logloss": 2.839869034542006,
            "mae": 0.400344785747022,
            "precision": 0.5587529976019184,
            "recall": 0.9789915966386554
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.7409400782961397,
            "auditor_fn_violation": 0.002677640553164714,
            "auditor_fp_violation": 0.02462081361243009,
            "ave_precision_score": 0.7157467186908337,
            "fpr": 0.38748627881448955,
            "logloss": 2.8968832847668353,
            "mae": 0.38093364749213504,
            "precision": 0.5721212121212121,
            "recall": 0.9874476987447699
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7209950833954657,
            "auditor_fn_violation": 0.0037893446852425195,
            "auditor_fp_violation": 0.02736198293899889,
            "ave_precision_score": 0.6939900622714854,
            "fpr": 0.2675438596491228,
            "logloss": 2.6856216424478343,
            "mae": 0.34269489470094333,
            "precision": 0.6363636363636364,
            "recall": 0.8970588235294118
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7097641913552892,
            "auditor_fn_violation": 0.011688842551979755,
            "auditor_fp_violation": 0.04096708690041905,
            "ave_precision_score": 0.6817693960705957,
            "fpr": 0.2502744237102086,
            "logloss": 2.8028630313192977,
            "mae": 0.32960058754996346,
            "precision": 0.6513761467889908,
            "recall": 0.891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.6610264654758845,
            "auditor_fn_violation": 0.013088788146837687,
            "auditor_fp_violation": 0.04482536616771286,
            "ave_precision_score": 0.6527339537412058,
            "fpr": 0.2982456140350877,
            "logloss": 1.8036693685768428,
            "mae": 0.37608999417218575,
            "precision": 0.6063675832127352,
            "recall": 0.8802521008403361
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6573360202858347,
            "auditor_fn_violation": 0.012515558331687557,
            "auditor_fp_violation": 0.04528688368744344,
            "ave_precision_score": 0.6503734198861315,
            "fpr": 0.283205268935236,
            "logloss": 1.8514522062794732,
            "mae": 0.35516600551811567,
            "precision": 0.625,
            "recall": 0.899581589958159
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5328947368421053,
            "auc_prc": 0.7217258605153872,
            "auditor_fn_violation": 0.009078302373581015,
            "auditor_fp_violation": 0.019548225494929992,
            "ave_precision_score": 0.6995684178165112,
            "fpr": 0.32127192982456143,
            "logloss": 8.422843872984535,
            "mae": 0.46842396440270395,
            "precision": 0.539308176100629,
            "recall": 0.7205882352941176
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7587582038774582,
            "auditor_fn_violation": 0.010237497072048279,
            "auditor_fp_violation": 0.014062155385929745,
            "ave_precision_score": 0.7386298504380098,
            "fpr": 0.32930845225027444,
            "logloss": 7.48749721890964,
            "mae": 0.4505152686803193,
            "precision": 0.5508982035928144,
            "recall": 0.7698744769874477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7227265151045581,
            "auditor_fn_violation": 0.002692853457172344,
            "auditor_fp_violation": 0.03687831965234187,
            "ave_precision_score": 0.6966003577687129,
            "fpr": 0.26096491228070173,
            "logloss": 2.628308604887598,
            "mae": 0.3421130462092389,
            "precision": 0.6421052631578947,
            "recall": 0.8970588235294118
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7123803110763205,
            "auditor_fn_violation": 0.0059799108065531036,
            "auditor_fp_violation": 0.04385202160912431,
            "ave_precision_score": 0.6845592695769885,
            "fpr": 0.24588364434687157,
            "logloss": 2.7646184690025466,
            "mae": 0.32745514547307797,
            "precision": 0.654320987654321,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.792426172626267,
            "auditor_fn_violation": 0.023106940144478852,
            "auditor_fp_violation": 0.026157351521004346,
            "ave_precision_score": 0.7879290829410244,
            "fpr": 0.14144736842105263,
            "logloss": 1.1934022873979775,
            "mae": 0.29368677312281455,
            "precision": 0.7323651452282157,
            "recall": 0.7415966386554622
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8049244847841809,
            "auditor_fn_violation": 0.021177702556848196,
            "auditor_fp_violation": 0.012863056864648904,
            "ave_precision_score": 0.7987985686904762,
            "fpr": 0.1141602634467618,
            "logloss": 1.118595637723602,
            "mae": 0.2722540299874263,
            "precision": 0.775377969762419,
            "recall": 0.7510460251046025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 12092,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7326483655817873,
            "auditor_fn_violation": 0.011517765000737139,
            "auditor_fp_violation": 0.03039996780943184,
            "ave_precision_score": 0.7106348918050451,
            "fpr": 0.22587719298245615,
            "logloss": 2.206547570566718,
            "mae": 0.31832982893042916,
            "precision": 0.6655844155844156,
            "recall": 0.8613445378151261
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7275670393334884,
            "auditor_fn_violation": 0.010209939879391358,
            "auditor_fp_violation": 0.039116469732268934,
            "ave_precision_score": 0.7024729896120522,
            "fpr": 0.20197585071350166,
            "logloss": 2.35773778351546,
            "mae": 0.29890076603746235,
            "precision": 0.6902356902356902,
            "recall": 0.8577405857740585
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 12092,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.607790120515861,
            "auditor_fn_violation": 0.010628593542680233,
            "auditor_fp_violation": 0.02070758892644456,
            "ave_precision_score": 0.5917072939504265,
            "fpr": 0.23135964912280702,
            "logloss": 0.6837346694573305,
            "mae": 0.49167333811260105,
            "precision": 0.6205035971223022,
            "recall": 0.7247899159663865
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.5963543541423943,
            "auditor_fn_violation": 0.012329547281253298,
            "auditor_fp_violation": 0.009073094307957911,
            "ave_precision_score": 0.5913313126117472,
            "fpr": 0.23710208562019758,
            "logloss": 0.6844205450478141,
            "mae": 0.49149588133186983,
            "precision": 0.6320272572402045,
            "recall": 0.7761506276150628
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6608295543526947,
            "auditor_fn_violation": 0.00927640793159369,
            "auditor_fp_violation": 0.04263238371157252,
            "ave_precision_score": 0.6525453515831111,
            "fpr": 0.2982456140350877,
            "logloss": 1.8082101389867158,
            "mae": 0.37422432456821153,
            "precision": 0.6075036075036075,
            "recall": 0.884453781512605
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.6589439265979314,
            "auditor_fn_violation": 0.014171286323824573,
            "auditor_fp_violation": 0.04468099669677511,
            "ave_precision_score": 0.6519335887175257,
            "fpr": 0.2854006586169045,
            "logloss": 1.8515994123701676,
            "mae": 0.35325704653886414,
            "precision": 0.6226415094339622,
            "recall": 0.897489539748954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.5919219630560713,
            "auditor_fn_violation": 0.0006242628630399529,
            "auditor_fp_violation": 0.004753138580395964,
            "ave_precision_score": 0.5059950726448035,
            "fpr": 0.46710526315789475,
            "logloss": 8.698533540951436,
            "mae": 0.46103941749683336,
            "precision": 0.5271920088790233,
            "recall": 0.9978991596638656
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.575968102705086,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0020610298050767802,
            "ave_precision_score": 0.4923413575015091,
            "fpr": 0.4632272228320527,
            "logloss": 9.001605279399188,
            "mae": 0.4554135830260575,
            "precision": 0.5311111111111111,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.712095960145794,
            "auditor_fn_violation": 0.0023081601061477235,
            "auditor_fp_violation": 0.038573354257202645,
            "ave_precision_score": 0.6855889203434506,
            "fpr": 0.26096491228070173,
            "logloss": 2.656664665510753,
            "mae": 0.344255611833823,
            "precision": 0.6437125748502994,
            "recall": 0.9033613445378151
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7033693977389679,
            "auditor_fn_violation": 0.005961539344781818,
            "auditor_fp_violation": 0.04433622418325674,
            "ave_precision_score": 0.6766109342123892,
            "fpr": 0.24259055982436883,
            "logloss": 2.7360657249602367,
            "mae": 0.32901847491214115,
            "precision": 0.6573643410852713,
            "recall": 0.8870292887029289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6262889847717079,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003767302430387909,
            "ave_precision_score": 0.5223312747128157,
            "fpr": 0.47039473684210525,
            "logloss": 9.882206148738273,
            "mae": 0.4720077642419359,
            "precision": 0.5259668508287293,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.6099109538021852,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0007453170512823973,
            "ave_precision_score": 0.5063342968480962,
            "fpr": 0.4698133918770582,
            "logloss": 10.219139816092111,
            "mae": 0.46893109386719345,
            "precision": 0.5275938189845475,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7778992037152692,
            "auditor_fn_violation": 0.020372622733303855,
            "auditor_fp_violation": 0.006709721551585387,
            "ave_precision_score": 0.7708922351819371,
            "fpr": 0.04824561403508772,
            "logloss": 3.7005519851185635,
            "mae": 0.3658987191786506,
            "precision": 0.8061674008810573,
            "recall": 0.38445378151260506
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.8035080048268791,
            "auditor_fn_violation": 0.011822035649821589,
            "auditor_fp_violation": 0.003967418997472515,
            "ave_precision_score": 0.795996888332987,
            "fpr": 0.030735455543358946,
            "logloss": 3.2773275431027757,
            "mae": 0.3529308744365251,
            "precision": 0.8691588785046729,
            "recall": 0.3891213389121339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6428725591207717,
            "auditor_fn_violation": 0.05192208462332304,
            "auditor_fp_violation": 0.021738693062932562,
            "ave_precision_score": 0.635041848053873,
            "fpr": 0.047149122807017545,
            "logloss": 4.891056017093574,
            "mae": 0.44834534414152616,
            "precision": 0.7225806451612903,
            "recall": 0.23529411764705882
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.6450688843888749,
            "auditor_fn_violation": 0.048271015804049994,
            "auditor_fp_violation": 0.02340396944707108,
            "ave_precision_score": 0.6365827191322344,
            "fpr": 0.050493962678375415,
            "logloss": 4.482686192098493,
            "mae": 0.45300586187774516,
            "precision": 0.7032258064516129,
            "recall": 0.2280334728033473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7226147910550667,
            "auditor_fn_violation": 0.0026099255491670355,
            "auditor_fp_violation": 0.028976541123450838,
            "ave_precision_score": 0.6925752459858073,
            "fpr": 0.3673245614035088,
            "logloss": 3.1565084375960186,
            "mae": 0.39027117839801784,
            "precision": 0.5694087403598972,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.715789440560656,
            "auditor_fn_violation": 0.005607888705684593,
            "auditor_fp_violation": 0.029260031992861184,
            "ave_precision_score": 0.6825869682256169,
            "fpr": 0.35016465422612514,
            "logloss": 3.2689968228278254,
            "mae": 0.3755899833971997,
            "precision": 0.5830065359477125,
            "recall": 0.9330543933054394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6827166774747386,
            "auditor_fn_violation": 0.008477075040542533,
            "auditor_fp_violation": 0.02642895943988411,
            "ave_precision_score": 0.6735292009332495,
            "fpr": 0.27960526315789475,
            "logloss": 1.823732677974704,
            "mae": 0.3584114826080622,
            "precision": 0.6233382570162481,
            "recall": 0.8865546218487395
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6734733651367565,
            "auditor_fn_violation": 0.007821649849124371,
            "auditor_fp_violation": 0.03794525722311092,
            "ave_precision_score": 0.6659901522753809,
            "fpr": 0.2535675082327113,
            "logloss": 1.9068083586354352,
            "mae": 0.33702939322972764,
            "precision": 0.648936170212766,
            "recall": 0.893305439330544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7248187471638292,
            "auditor_fn_violation": 0.0026099255491670355,
            "auditor_fp_violation": 0.024696201512956702,
            "ave_precision_score": 0.6963757312566037,
            "fpr": 0.3684210526315789,
            "logloss": 3.057307441431419,
            "mae": 0.3884650528763701,
            "precision": 0.5686777920410783,
            "recall": 0.930672268907563
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7166949428904349,
            "auditor_fn_violation": 0.004156543225753117,
            "auditor_fp_violation": 0.03149344805469715,
            "ave_precision_score": 0.6853857683991013,
            "fpr": 0.3446761800219539,
            "logloss": 3.1703536439818336,
            "mae": 0.37279711499063567,
            "precision": 0.5879265091863517,
            "recall": 0.9372384937238494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6778075737607827,
            "auditor_fn_violation": 0.005878667256376236,
            "auditor_fp_violation": 0.016173245614035086,
            "ave_precision_score": 0.6512974486226841,
            "fpr": 0.35855263157894735,
            "logloss": 2.928225053315235,
            "mae": 0.401620270627175,
            "precision": 0.5725490196078431,
            "recall": 0.9201680672268907
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6729514953825109,
            "auditor_fn_violation": 0.008983644806158115,
            "auditor_fp_violation": 0.014624945812408266,
            "ave_precision_score": 0.6461453131571524,
            "fpr": 0.3534577387486279,
            "logloss": 2.9613030685684065,
            "mae": 0.4005371347213119,
            "precision": 0.5774278215223098,
            "recall": 0.9205020920502092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 12092,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.7779658149130367,
            "auditor_fn_violation": 0.019914215686274522,
            "auditor_fp_violation": 0.00897563576372123,
            "ave_precision_score": 0.7709606569549775,
            "fpr": 0.0537280701754386,
            "logloss": 3.668241230414993,
            "mae": 0.36373552899593786,
            "precision": 0.7941176470588235,
            "recall": 0.39705882352941174
        },
        "train": {
            "accuracy": 0.6520307354555434,
            "auc_prc": 0.8033148324660329,
            "auditor_fn_violation": 0.01109177004441302,
            "auditor_fp_violation": 0.003967418997472515,
            "ave_precision_score": 0.7958246817089988,
            "fpr": 0.030735455543358946,
            "logloss": 3.2408187596980675,
            "mae": 0.3499571185042885,
            "precision": 0.8709677419354839,
            "recall": 0.39539748953974896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6734461464943446,
            "auditor_fn_violation": 0.01204297508477075,
            "auditor_fp_violation": 0.04776275551263481,
            "ave_precision_score": 0.6705032786028924,
            "fpr": 0.2916666666666667,
            "logloss": 1.3866171906257485,
            "mae": 0.3717154434365384,
            "precision": 0.6144927536231884,
            "recall": 0.8907563025210085
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6685664920420791,
            "auditor_fn_violation": 0.01638734389998576,
            "auditor_fp_violation": 0.04037641046181772,
            "ave_precision_score": 0.6640524143163021,
            "fpr": 0.27661909989023054,
            "logloss": 1.6842056802740537,
            "mae": 0.3498189610385149,
            "precision": 0.6347826086956522,
            "recall": 0.9163179916317992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 12092,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.675692640542016,
            "auditor_fn_violation": 0.016124871001031993,
            "auditor_fp_violation": 0.04844177530983423,
            "ave_precision_score": 0.6622198374532261,
            "fpr": 0.2774122807017544,
            "logloss": 2.0041979488792,
            "mae": 0.3665747257358529,
            "precision": 0.6229508196721312,
            "recall": 0.8781512605042017
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6660521144350529,
            "auditor_fn_violation": 0.013861267906434145,
            "auditor_fp_violation": 0.04061977929488952,
            "ave_precision_score": 0.6527150451554061,
            "fpr": 0.2645444566410538,
            "logloss": 2.155237089227377,
            "mae": 0.34544991791510543,
            "precision": 0.6397608370702541,
            "recall": 0.895397489539749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 12092,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.58969285227253,
            "auditor_fn_violation": 0.0026583001621701316,
            "auditor_fp_violation": 0.006377756317399023,
            "ave_precision_score": 0.5045447225681561,
            "fpr": 0.4407894736842105,
            "logloss": 8.3686864776259,
            "mae": 0.44370996326362827,
            "precision": 0.5373993095512083,
            "recall": 0.9810924369747899
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.5648337701662072,
            "auditor_fn_violation": 0.0015087562979667385,
            "auditor_fp_violation": 0.00538707052372466,
            "ave_precision_score": 0.48634239823271475,
            "fpr": 0.43029637760702527,
            "logloss": 8.698049977022373,
            "mae": 0.43757498301511977,
            "precision": 0.5468208092485549,
            "recall": 0.9895397489539749
        }
    }
]