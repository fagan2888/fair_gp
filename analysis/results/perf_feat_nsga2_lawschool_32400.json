[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 32400,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6022493103771447,
            "auditor_fn_violation": 0.0249746266492678,
            "auditor_fp_violation": 0.03706550254140023,
            "ave_precision_score": 0.6041961197706496,
            "fpr": 0.39144736842105265,
            "logloss": 0.7331573693441655,
            "mae": 0.48594694068930566,
            "precision": 0.5498108448928121,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5871299763081925,
            "auditor_fn_violation": 0.037994254618492665,
            "auditor_fp_violation": 0.034192820926394724,
            "ave_precision_score": 0.5874247691058542,
            "fpr": 0.4083424807903403,
            "logloss": 0.6839769909086851,
            "mae": 0.48299112945229844,
            "precision": 0.5308953341740227,
            "recall": 0.8957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8215251752396809,
            "auditor_fn_violation": 0.011943598666086705,
            "auditor_fp_violation": 0.013480693556320714,
            "ave_precision_score": 0.8228898680703067,
            "fpr": 0.1162280701754386,
            "logloss": 0.793676141015133,
            "mae": 0.27088256786854487,
            "precision": 0.774468085106383,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8240291679256655,
            "auditor_fn_violation": 0.02153350304785483,
            "auditor_fp_violation": 0.018222729999427506,
            "ave_precision_score": 0.8242743306993165,
            "fpr": 0.1163556531284303,
            "logloss": 0.8815658353469317,
            "mae": 0.2850054549005045,
            "precision": 0.7596371882086168,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8215251675608508,
            "auditor_fn_violation": 0.011943598666086705,
            "auditor_fp_violation": 0.013480693556320714,
            "ave_precision_score": 0.8228911350772666,
            "fpr": 0.1162280701754386,
            "logloss": 0.793674478403444,
            "mae": 0.27088246773183355,
            "precision": 0.774468085106383,
            "recall": 0.7520661157024794
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8240291679256655,
            "auditor_fn_violation": 0.02153350304785483,
            "auditor_fp_violation": 0.018222729999427506,
            "ave_precision_score": 0.8242743306993165,
            "fpr": 0.1163556531284303,
            "logloss": 0.8815637328320682,
            "mae": 0.28500504721692954,
            "precision": 0.7596371882086168,
            "recall": 0.7127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7544596044068186,
            "auditor_fn_violation": 0.003160341452805568,
            "auditor_fp_violation": 0.006701918347270044,
            "ave_precision_score": 0.5627027719610336,
            "fpr": 0.42543859649122806,
            "logloss": 13.262098508838454,
            "mae": 0.4338177604186696,
            "precision": 0.552479815455594,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7266451846239214,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.007357791268721185,
            "ave_precision_score": 0.5325768324044384,
            "fpr": 0.433589462129528,
            "logloss": 13.748448549622834,
            "mae": 0.44056196767697775,
            "precision": 0.5412311265969802,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.853693260740467,
            "auditor_fn_violation": 0.010176526025808322,
            "auditor_fp_violation": 0.004665211510083619,
            "ave_precision_score": 0.8574951421313612,
            "fpr": 0.11513157894736842,
            "logloss": 0.7903747541946036,
            "mae": 0.23795312459160908,
            "precision": 0.7887323943661971,
            "recall": 0.8099173553719008
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8576785889912392,
            "auditor_fn_violation": 0.010404745778545901,
            "auditor_fp_violation": 0.012378313930768063,
            "ave_precision_score": 0.8578556985685794,
            "fpr": 0.11964873765093303,
            "logloss": 0.8514628295186775,
            "mae": 0.25902904294587653,
            "precision": 0.7650862068965517,
            "recall": 0.7553191489361702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6383238451741134,
            "auditor_fn_violation": 0.0028409090909090914,
            "auditor_fp_violation": 0.003671196097720953,
            "ave_precision_score": 0.6391466293597399,
            "fpr": 0.4550438596491228,
            "logloss": 1.0748593813185787,
            "mae": 0.46560045941169637,
            "precision": 0.5352743561030235,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6162353063764627,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0037162321935726426,
            "ave_precision_score": 0.6143631620753989,
            "fpr": 0.4665203073545554,
            "logloss": 0.9744456490924445,
            "mae": 0.4684293137717698,
            "precision": 0.5251396648044693,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 32400,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6245134542176612,
            "auditor_fn_violation": 0.10685805422647529,
            "auditor_fp_violation": 0.10836817511067388,
            "ave_precision_score": 0.5725866967607838,
            "fpr": 0.2631578947368421,
            "logloss": 0.738921623612536,
            "mae": 0.4760322339440647,
            "precision": 0.5620437956204379,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6364243823917047,
            "auditor_fn_violation": 0.09926431090454725,
            "auditor_fp_violation": 0.11444402129677339,
            "ave_precision_score": 0.5727487863715172,
            "fpr": 0.2711306256860593,
            "logloss": 0.7256370907466148,
            "mae": 0.4699520152041731,
            "precision": 0.5581395348837209,
            "recall": 0.6638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.9248843411591685,
            "mae": 0.528138506273155,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.8233018261204488,
            "mae": 0.5133295126942028,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6614750826081119,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.01941404328578455,
            "ave_precision_score": 0.5689703614518757,
            "fpr": 0.08114035087719298,
            "logloss": 0.776195964985622,
            "mae": 0.46509300242995094,
            "precision": 0.6542056074766355,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6614958030556171,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.5610969759187316,
            "fpr": 0.07793633369923161,
            "logloss": 0.7598785532925163,
            "mae": 0.4610446835822057,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7711044964594489,
            "auditor_fn_violation": 0.0023107872988255766,
            "auditor_fp_violation": 0.007552467617642237,
            "ave_precision_score": 0.5570032559743642,
            "fpr": 0.42214912280701755,
            "logloss": 14.19279508804072,
            "mae": 0.4307310885058964,
            "precision": 0.5549132947976878,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7711841843563082,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009162391630636894,
            "ave_precision_score": 0.5483002021136272,
            "fpr": 0.424807903402854,
            "logloss": 14.54867373874569,
            "mae": 0.43454845754817817,
            "precision": 0.5463071512309496,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6001674096141734,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.018950340219708147,
            "ave_precision_score": 0.5715963914315514,
            "fpr": 0.08223684210526316,
            "logloss": 0.7686237601474583,
            "mae": 0.4680698936184247,
            "precision": 0.6511627906976745,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6042233069871461,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.5713845958448882,
            "fpr": 0.07793633369923161,
            "logloss": 0.7570765951813987,
            "mae": 0.46534660579606024,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 32400,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6022493103771447,
            "auditor_fn_violation": 0.0249746266492678,
            "auditor_fp_violation": 0.03706550254140023,
            "ave_precision_score": 0.6041961197706496,
            "fpr": 0.39144736842105265,
            "logloss": 0.7331574608486655,
            "mae": 0.48594694044733816,
            "precision": 0.5498108448928121,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5871299763081925,
            "auditor_fn_violation": 0.037994254618492665,
            "auditor_fp_violation": 0.034192820926394724,
            "ave_precision_score": 0.5874247691058542,
            "fpr": 0.4083424807903403,
            "logloss": 0.6839770168410533,
            "mae": 0.48299113086703593,
            "precision": 0.5308953341740227,
            "recall": 0.8957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7677087226713443,
            "auditor_fn_violation": 0.006139444686095404,
            "auditor_fp_violation": 0.009507193802262668,
            "ave_precision_score": 0.5467234726962331,
            "fpr": 0.4309210526315789,
            "logloss": 15.048856275214572,
            "mae": 0.4422244101926417,
            "precision": 0.5467128027681661,
            "recall": 0.9793388429752066
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.009625364964866294,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.429198682766191,
            "logloss": 14.976236094059239,
            "mae": 0.43382990548952505,
            "precision": 0.543757292882147,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 32400,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5971818517844855,
            "auditor_fn_violation": 0.0071113346382485265,
            "auditor_fp_violation": 0.015530209870470567,
            "ave_precision_score": 0.5983369155390352,
            "fpr": 0.19078947368421054,
            "logloss": 3.5449545755379006,
            "mae": 0.5226573462442254,
            "precision": 0.5070821529745042,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6492608509334395,
            "auditor_fn_violation": 0.006684260924399192,
            "auditor_fp_violation": 0.021916560257472913,
            "ave_precision_score": 0.6497716188200151,
            "fpr": 0.16465422612513722,
            "logloss": 3.172524121516666,
            "mae": 0.46792223313600606,
            "precision": 0.5626822157434402,
            "recall": 0.4106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.792634149893782,
            "mae": 0.5277617759511337,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.7009358007909228,
            "mae": 0.5129219515642371,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6621283091227783,
            "auditor_fn_violation": 0.013239451935624192,
            "auditor_fp_violation": 0.006281767502869325,
            "ave_precision_score": 0.5596710687815193,
            "fpr": 0.03070175438596491,
            "logloss": 0.7333040938124025,
            "mae": 0.47651040547511037,
            "precision": 0.7227722772277227,
            "recall": 0.15082644628099173
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6937401708946507,
            "auditor_fn_violation": 0.019333442324310435,
            "auditor_fp_violation": 0.00804976216611782,
            "ave_precision_score": 0.5640164324633917,
            "fpr": 0.025246981339187707,
            "logloss": 0.7084011297378923,
            "mae": 0.4680595445057171,
            "precision": 0.7850467289719626,
            "recall": 0.17872340425531916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6059488840551727,
            "auditor_fn_violation": 0.021893576917500362,
            "auditor_fp_violation": 0.026899901623216937,
            "ave_precision_score": 0.6080814678923263,
            "fpr": 0.3991228070175439,
            "logloss": 0.7317021112367347,
            "mae": 0.484613165773878,
            "precision": 0.5495049504950495,
            "recall": 0.9173553719008265
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5913757546638493,
            "auditor_fn_violation": 0.025728098652404423,
            "auditor_fp_violation": 0.020179165702138898,
            "ave_precision_score": 0.5917343478961001,
            "fpr": 0.4039517014270033,
            "logloss": 0.681658215915174,
            "mae": 0.4805412837670259,
            "precision": 0.5382685069008782,
            "recall": 0.9127659574468086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6798234678502937,
            "auditor_fn_violation": 0.0035160214586052,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5657180828851515,
            "fpr": 0.023026315789473683,
            "logloss": 0.686193111032006,
            "mae": 0.4793167047246402,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6495291276846671,
            "auditor_fn_violation": 0.008711493098535639,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5421360752469209,
            "fpr": 0.021953896816684963,
            "logloss": 0.6847113526366524,
            "mae": 0.48470419846319956,
            "precision": 0.726027397260274,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.6001674096141734,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.018950340219708147,
            "ave_precision_score": 0.5715963914315514,
            "fpr": 0.08223684210526316,
            "logloss": 0.7686266108557963,
            "mae": 0.46807691833952014,
            "precision": 0.6511627906976745,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6042233069871461,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.5713845958448882,
            "fpr": 0.07793633369923161,
            "logloss": 0.757091800715706,
            "mae": 0.4653561324633568,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7876112708209857,
            "auditor_fn_violation": 0.04536845730027548,
            "auditor_fp_violation": 0.02752500409903263,
            "ave_precision_score": 0.7882237567660324,
            "fpr": 0.09649122807017543,
            "logloss": 0.7955814252209968,
            "mae": 0.36402087131518146,
            "precision": 0.7766497461928934,
            "recall": 0.6322314049586777
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.791300237375295,
            "auditor_fn_violation": 0.04936824158628582,
            "auditor_fp_violation": 0.03488230271984388,
            "ave_precision_score": 0.7915629738364957,
            "fpr": 0.10757409440175632,
            "logloss": 0.7470397575813118,
            "mae": 0.36325870852799835,
            "precision": 0.7447916666666666,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6392736138393897,
            "auditor_fn_violation": 0.0028409090909090914,
            "auditor_fp_violation": 0.003671196097720953,
            "ave_precision_score": 0.6400718159501034,
            "fpr": 0.4550438596491228,
            "logloss": 2.1565372506033085,
            "mae": 0.46221088666786203,
            "precision": 0.5352743561030235,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6162289249667082,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0037162321935726426,
            "ave_precision_score": 0.6143603219758516,
            "fpr": 0.4665203073545554,
            "logloss": 2.1032323806932376,
            "mae": 0.46681274656460753,
            "precision": 0.5251396648044693,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7877879492255432,
            "auditor_fn_violation": 0.04536845730027548,
            "auditor_fp_violation": 0.026612969339235938,
            "ave_precision_score": 0.7883998448836267,
            "fpr": 0.09758771929824561,
            "logloss": 0.794561106180885,
            "mae": 0.36403036879179734,
            "precision": 0.7746835443037975,
            "recall": 0.6322314049586777
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7916064040726987,
            "auditor_fn_violation": 0.04859284863488802,
            "auditor_fp_violation": 0.03546973125144679,
            "ave_precision_score": 0.791868169550955,
            "fpr": 0.10647639956092206,
            "logloss": 0.7454802521417785,
            "mae": 0.36320743482662166,
            "precision": 0.7473958333333334,
            "recall": 0.6106382978723405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7711086677609317,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.01024758157074931,
            "ave_precision_score": 0.5570074274012601,
            "fpr": 0.42105263157894735,
            "logloss": 14.177319798595407,
            "mae": 0.43223909840290026,
            "precision": 0.5545243619489559,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7712039370373729,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009249510268798345,
            "ave_precision_score": 0.5483199525098689,
            "fpr": 0.42371020856201974,
            "logloss": 14.54487111054125,
            "mae": 0.43506039614849507,
            "precision": 0.5469483568075117,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7677087226713443,
            "auditor_fn_violation": 0.006139444686095404,
            "auditor_fp_violation": 0.009507193802262668,
            "ave_precision_score": 0.5467234726962331,
            "fpr": 0.4309210526315789,
            "logloss": 15.04885652144774,
            "mae": 0.4422246056981334,
            "precision": 0.5467128027681661,
            "recall": 0.9793388429752066
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.009625364964866294,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.429198682766191,
            "logloss": 14.976236063227423,
            "mae": 0.43382987529872563,
            "precision": 0.543757292882147,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8390409776703507,
            "auditor_fn_violation": 0.00950367913585617,
            "auditor_fp_violation": 0.010542199540908351,
            "ave_precision_score": 0.8398827099917562,
            "fpr": 0.15899122807017543,
            "logloss": 0.968844596711274,
            "mae": 0.25250486487073476,
            "precision": 0.7392086330935251,
            "recall": 0.8491735537190083
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.845135836781229,
            "auditor_fn_violation": 0.012177406170446322,
            "auditor_fp_violation": 0.019840647565282976,
            "ave_precision_score": 0.8453267956873742,
            "fpr": 0.1668496158068057,
            "logloss": 1.0229190750103594,
            "mae": 0.2721571145609485,
            "precision": 0.7126654064272212,
            "recall": 0.8021276595744681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5819362214161445,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.018950340219708147,
            "ave_precision_score": 0.5566245907676293,
            "fpr": 0.08223684210526316,
            "logloss": 0.7739164243247515,
            "mae": 0.4695751549381959,
            "precision": 0.6511627906976745,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5800006337409254,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.5503487987816047,
            "fpr": 0.07793633369923161,
            "logloss": 0.7620477850632866,
            "mae": 0.4662758204861085,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6687978572779322,
            "auditor_fn_violation": 0.0035160214586052,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5670365485860253,
            "fpr": 0.023026315789473683,
            "logloss": 0.6863990300722439,
            "mae": 0.4793173832347811,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6335585378038762,
            "auditor_fn_violation": 0.008711493098535639,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5455552418317708,
            "fpr": 0.021953896816684963,
            "logloss": 0.6847194726814427,
            "mae": 0.48470202017635466,
            "precision": 0.726027397260274,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5208333333333334,
            "auc_prc": 0.6813112919247122,
            "auditor_fn_violation": 0.004331593446425986,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5673385198881329,
            "fpr": 0.023026315789473683,
            "logloss": 0.6811804803875235,
            "mae": 0.48278978097726377,
            "precision": 0.7640449438202247,
            "recall": 0.14049586776859505
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6520342678750488,
            "auditor_fn_violation": 0.008769881121984268,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5437510774837989,
            "fpr": 0.021953896816684963,
            "logloss": 0.6868048523567158,
            "mae": 0.48695963565525974,
            "precision": 0.7333333333333333,
            "recall": 0.11702127659574468
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7711099234393513,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.01024758157074931,
            "ave_precision_score": 0.5570086829625488,
            "fpr": 0.42105263157894735,
            "logloss": 14.176115762217165,
            "mae": 0.4320846575786147,
            "precision": 0.5545243619489559,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7712039370373729,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009249510268798345,
            "ave_precision_score": 0.5483199525098689,
            "fpr": 0.42371020856201974,
            "logloss": 14.54442394075208,
            "mae": 0.4348397789202001,
            "precision": 0.5469483568075117,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 32400,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5971263210302771,
            "auditor_fn_violation": 0.0071113346382485265,
            "auditor_fp_violation": 0.015530209870470567,
            "ave_precision_score": 0.5982687975556803,
            "fpr": 0.19078947368421054,
            "logloss": 3.475584429376481,
            "mae": 0.522518361778501,
            "precision": 0.5070821529745042,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6492001700025598,
            "auditor_fn_violation": 0.006684260924399192,
            "auditor_fp_violation": 0.021916560257472913,
            "ave_precision_score": 0.6497220889989832,
            "fpr": 0.16465422612513722,
            "logloss": 3.1094933114885372,
            "mae": 0.4678524286784483,
            "precision": 0.5626822157434402,
            "recall": 0.4106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6014574735398913,
            "auditor_fn_violation": 0.03291739161954473,
            "auditor_fp_violation": 0.03819786030496804,
            "ave_precision_score": 0.6035133501112712,
            "fpr": 0.38377192982456143,
            "logloss": 0.7327174621795791,
            "mae": 0.48594637540577124,
            "precision": 0.5512820512820513,
            "recall": 0.8884297520661157
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5865392868699657,
            "auditor_fn_violation": 0.042518158675292524,
            "auditor_fp_violation": 0.04788040353353196,
            "ave_precision_score": 0.586838041335063,
            "fpr": 0.3918770581778266,
            "logloss": 0.6833157795493155,
            "mae": 0.48296712468681646,
            "precision": 0.5375647668393783,
            "recall": 0.8829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6582886995943413,
            "auditor_fn_violation": 0.007897455415398016,
            "auditor_fp_violation": 0.0035431013280865717,
            "ave_precision_score": 0.5628525382274127,
            "fpr": 0.025219298245614034,
            "logloss": 0.6929180932293852,
            "mae": 0.4797428479471324,
            "precision": 0.7386363636363636,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6484146440970195,
            "auditor_fn_violation": 0.004554265828993184,
            "auditor_fp_violation": 0.0017996221540207743,
            "ave_precision_score": 0.5503545483389144,
            "fpr": 0.018660812294182216,
            "logloss": 0.6817351408777647,
            "mae": 0.48217323576357984,
            "precision": 0.7605633802816901,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6582886995943413,
            "auditor_fn_violation": 0.007897455415398016,
            "auditor_fp_violation": 0.0035431013280865717,
            "ave_precision_score": 0.5628525382274127,
            "fpr": 0.025219298245614034,
            "logloss": 0.6929180892528624,
            "mae": 0.4797428479482094,
            "precision": 0.7386363636363636,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6484146440970195,
            "auditor_fn_violation": 0.004554265828993184,
            "auditor_fp_violation": 0.0017996221540207743,
            "ave_precision_score": 0.5503545483389144,
            "fpr": 0.018660812294182216,
            "logloss": 0.6817351408786632,
            "mae": 0.48217323576447835,
            "precision": 0.7605633802816901,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.608068458657796,
            "mae": 0.5270903332631502,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 2.52245996972416,
            "mae": 0.5122592663048404,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.5819362214161445,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.018950340219708147,
            "ave_precision_score": 0.5566245907676293,
            "fpr": 0.08223684210526316,
            "logloss": 0.7739164243247515,
            "mae": 0.4695751549381959,
            "precision": 0.6511627906976745,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5800006337409254,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.5503487987816047,
            "fpr": 0.07793633369923161,
            "logloss": 0.7620477850632866,
            "mae": 0.4662758204861085,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7677100571453292,
            "auditor_fn_violation": 0.004519628099173554,
            "auditor_fp_violation": 0.008823167732415175,
            "ave_precision_score": 0.54672480702389,
            "fpr": 0.4331140350877193,
            "logloss": 15.059740435465743,
            "mae": 0.44078446963323603,
            "precision": 0.5470183486238532,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.0052769003686363005,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.43249176728869376,
            "logloss": 14.982529948841108,
            "mae": 0.4383536336483306,
            "precision": 0.541860465116279,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8537154531992506,
            "auditor_fn_violation": 0.012709330143540677,
            "auditor_fp_violation": 0.00880267256927365,
            "ave_precision_score": 0.8558029222939828,
            "fpr": 0.11074561403508772,
            "logloss": 0.7770893348138604,
            "mae": 0.24151635484562603,
            "precision": 0.7921810699588477,
            "recall": 0.7954545454545454
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8555700003688571,
            "auditor_fn_violation": 0.007861363477123575,
            "auditor_fp_violation": 0.010981926616237425,
            "ave_precision_score": 0.8557582940079034,
            "fpr": 0.11306256860592755,
            "logloss": 0.8868846808010096,
            "mae": 0.25547282335725996,
            "precision": 0.7716186252771619,
            "recall": 0.7404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6014574735398913,
            "auditor_fn_violation": 0.03291739161954473,
            "auditor_fp_violation": 0.03819786030496804,
            "ave_precision_score": 0.6035133501112712,
            "fpr": 0.38377192982456143,
            "logloss": 0.7327174749047797,
            "mae": 0.48594637569830446,
            "precision": 0.5512820512820513,
            "recall": 0.8884297520661157
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5865392868699657,
            "auditor_fn_violation": 0.042518158675292524,
            "auditor_fp_violation": 0.04788040353353196,
            "ave_precision_score": 0.586838041335063,
            "fpr": 0.3918770581778266,
            "logloss": 0.6833157827182029,
            "mae": 0.48296712556695376,
            "precision": 0.5375647668393783,
            "recall": 0.8829787234042553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8098622299541403,
            "auditor_fn_violation": 0.011336450630709006,
            "auditor_fp_violation": 0.02184272011805214,
            "ave_precision_score": 0.811252219487549,
            "fpr": 0.16885964912280702,
            "logloss": 0.9010766217776265,
            "mae": 0.27467232974630496,
            "precision": 0.7220216606498195,
            "recall": 0.8264462809917356
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8195597224303705,
            "auditor_fn_violation": 0.018674825419809894,
            "auditor_fp_violation": 0.02619532994317376,
            "ave_precision_score": 0.8198081591659967,
            "fpr": 0.17453347969264543,
            "logloss": 0.9624962231847154,
            "mae": 0.2914385149227024,
            "precision": 0.7005649717514124,
            "recall": 0.7914893617021277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6648301279598494,
            "auditor_fn_violation": 0.0006048825576337538,
            "auditor_fp_violation": 0.00252602885718972,
            "ave_precision_score": 0.5707792486060383,
            "fpr": 0.4616228070175439,
            "logloss": 0.8847985243082083,
            "mae": 0.4627938141695044,
            "precision": 0.5342920353982301,
            "recall": 0.9979338842975206
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6669849427032238,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00270067778300491,
            "ave_precision_score": 0.5643994317733687,
            "fpr": 0.47859495060373214,
            "logloss": 0.8790977716668631,
            "mae": 0.4673537633756971,
            "precision": 0.5187637969094923,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7711044964594489,
            "auditor_fn_violation": 0.0023107872988255766,
            "auditor_fp_violation": 0.007552467617642237,
            "ave_precision_score": 0.5570032559743642,
            "fpr": 0.42214912280701755,
            "logloss": 14.192844073483341,
            "mae": 0.430741616694991,
            "precision": 0.5549132947976878,
            "recall": 0.9917355371900827
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7711841843563082,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009162391630636894,
            "ave_precision_score": 0.5483002021136272,
            "fpr": 0.424807903402854,
            "logloss": 14.548696471606192,
            "mae": 0.43456413445252157,
            "precision": 0.5463071512309496,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5443617117775239,
            "auditor_fn_violation": 0.005987657677250979,
            "auditor_fp_violation": 0.0004355222167568459,
            "ave_precision_score": 0.5677389224223093,
            "fpr": 0.05921052631578947,
            "logloss": 0.6878966208964826,
            "mae": 0.48453116142436076,
            "precision": 0.6804733727810651,
            "recall": 0.23760330578512398
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5566199325326988,
            "auditor_fn_violation": 0.00039703855945069156,
            "auditor_fp_violation": 0.0013416270276863029,
            "ave_precision_score": 0.5515059020833928,
            "fpr": 0.06366630076838639,
            "logloss": 0.6899280450687605,
            "mae": 0.48449291715768505,
            "precision": 0.6666666666666666,
            "recall": 0.24680851063829787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 32400,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6245134542176612,
            "auditor_fn_violation": 0.10685805422647529,
            "auditor_fp_violation": 0.10836817511067388,
            "ave_precision_score": 0.5725866967607838,
            "fpr": 0.2631578947368421,
            "logloss": 0.738921623612536,
            "mae": 0.4760322339440647,
            "precision": 0.5620437956204379,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6364243823917047,
            "auditor_fn_violation": 0.09926431090454725,
            "auditor_fp_violation": 0.11444402129677339,
            "ave_precision_score": 0.5727487863715172,
            "fpr": 0.2711306256860593,
            "logloss": 0.7256370907466148,
            "mae": 0.4699520152041731,
            "precision": 0.5581395348837209,
            "recall": 0.6638297872340425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6433345573406651,
            "auditor_fn_violation": 0.0028409090909090914,
            "auditor_fp_violation": 0.003671196097720953,
            "ave_precision_score": 0.6443385808502811,
            "fpr": 0.4550438596491228,
            "logloss": 0.9943005866518524,
            "mae": 0.46379546518572,
            "precision": 0.5352743561030235,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6278367552427551,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0037162321935726426,
            "ave_precision_score": 0.6259980709946541,
            "fpr": 0.4665203073545554,
            "logloss": 0.9504071583475981,
            "mae": 0.4668671391803983,
            "precision": 0.5251396648044693,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7677113315528353,
            "auditor_fn_violation": 0.004519628099173554,
            "auditor_fp_violation": 0.008823167732415175,
            "ave_precision_score": 0.5467260813201228,
            "fpr": 0.4331140350877193,
            "logloss": 15.063336515476642,
            "mae": 0.4412944821628467,
            "precision": 0.5470183486238532,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.00784067743453035,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.44017563117453345,
            "logloss": 14.993522937944366,
            "mae": 0.44211888567832397,
            "precision": 0.5374855824682814,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.592424982218744,
            "auditor_fn_violation": 0.04063134333768305,
            "auditor_fp_violation": 0.05133013608788326,
            "ave_precision_score": 0.5991044555973956,
            "fpr": 0.35964912280701755,
            "logloss": 0.7124610609550828,
            "mae": 0.4866898009009642,
            "precision": 0.5585464333781965,
            "recall": 0.8574380165289256
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5853709866567931,
            "auditor_fn_violation": 0.04857883550926034,
            "auditor_fp_violation": 0.05647776856809318,
            "ave_precision_score": 0.5855126675518867,
            "fpr": 0.3743139407244786,
            "logloss": 0.681460193430324,
            "mae": 0.4835722934315134,
            "precision": 0.5435073627844712,
            "recall": 0.8638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7711113246580332,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.01024758157074931,
            "ave_precision_score": 0.5570100839921827,
            "fpr": 0.42105263157894735,
            "logloss": 14.177315816608813,
            "mae": 0.43245240830685616,
            "precision": 0.5545243619489559,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7712039370373729,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009249510268798345,
            "ave_precision_score": 0.5483199525098689,
            "fpr": 0.42371020856201974,
            "logloss": 14.545096849646033,
            "mae": 0.4353061783527209,
            "precision": 0.5469483568075117,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.595873805397625,
            "auditor_fn_violation": 0.020996447730897493,
            "auditor_fp_violation": 0.024640309886866708,
            "ave_precision_score": 0.5992995046446908,
            "fpr": 0.4057017543859649,
            "logloss": 0.7760490248400046,
            "mae": 0.48315431616808835,
            "precision": 0.5454545454545454,
            "recall": 0.9173553719008265
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5656406755601187,
            "auditor_fn_violation": 0.027998225004087166,
            "auditor_fp_violation": 0.03235337310921441,
            "ave_precision_score": 0.5672930760338782,
            "fpr": 0.4138309549945115,
            "logloss": 0.6847905958637178,
            "mae": 0.4810995609558554,
            "precision": 0.5351418002466092,
            "recall": 0.9234042553191489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7935766706283085,
            "auditor_fn_violation": 0.04062228142670726,
            "auditor_fp_violation": 0.025367888178389905,
            "ave_precision_score": 0.7939702042393715,
            "fpr": 0.09429824561403509,
            "logloss": 0.7985919500345835,
            "mae": 0.36370769306705897,
            "precision": 0.7811704834605598,
            "recall": 0.6342975206611571
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7891093793208421,
            "auditor_fn_violation": 0.04922343928813322,
            "auditor_fp_violation": 0.033757227735587474,
            "ave_precision_score": 0.7893815437420003,
            "fpr": 0.10098792535675083,
            "logloss": 0.7490813150130224,
            "mae": 0.3631166547174981,
            "precision": 0.7566137566137566,
            "recall": 0.6085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8415236909365285,
            "auditor_fn_violation": 0.02222207119037263,
            "auditor_fp_violation": 0.018945216428922784,
            "ave_precision_score": 0.8420124336552828,
            "fpr": 0.19188596491228072,
            "logloss": 0.7269956565164746,
            "mae": 0.3408752151278525,
            "precision": 0.7043918918918919,
            "recall": 0.8615702479338843
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8422137198279891,
            "auditor_fn_violation": 0.026209215965621133,
            "auditor_fp_violation": 0.027681324999813326,
            "ave_precision_score": 0.8423444506567112,
            "fpr": 0.19319429198682767,
            "logloss": 0.6609201476539865,
            "mae": 0.34429581223735506,
            "precision": 0.6879432624113475,
            "recall": 0.825531914893617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6582886995943413,
            "auditor_fn_violation": 0.007897455415398016,
            "auditor_fp_violation": 0.0035431013280865717,
            "ave_precision_score": 0.5628525382274127,
            "fpr": 0.025219298245614034,
            "logloss": 0.6929181010941065,
            "mae": 0.47974284794500227,
            "precision": 0.7386363636363636,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6484146440970195,
            "auditor_fn_violation": 0.004554265828993184,
            "auditor_fp_violation": 0.0017996221540207743,
            "ave_precision_score": 0.5503545483389144,
            "fpr": 0.018660812294182216,
            "logloss": 0.6817351408759876,
            "mae": 0.48217323576180277,
            "precision": 0.7605633802816901,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8527123168305338,
            "auditor_fn_violation": 0.010466507177033494,
            "auditor_fp_violation": 0.004078537465158225,
            "ave_precision_score": 0.8548016179052924,
            "fpr": 0.11842105263157894,
            "logloss": 0.8143403749691176,
            "mae": 0.2392676123057556,
            "precision": 0.7857142857142857,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.85514251527479,
            "auditor_fn_violation": 0.010885863091762621,
            "auditor_fp_violation": 0.01721464290070218,
            "ave_precision_score": 0.85531227616652,
            "fpr": 0.13062568605927552,
            "logloss": 0.8769056547331391,
            "mae": 0.2605001391472322,
            "precision": 0.7510460251046025,
            "recall": 0.7638297872340426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7710976724239567,
            "auditor_fn_violation": 0.0029904306220095694,
            "auditor_fp_violation": 0.006896622397114299,
            "ave_precision_score": 0.556996432853574,
            "fpr": 0.4276315789473684,
            "logloss": 14.197857649747371,
            "mae": 0.4380971047896565,
            "precision": 0.5512082853855006,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7712088870334949,
            "auditor_fn_violation": 0.0018217063315972626,
            "auditor_fp_violation": 0.007561897792413714,
            "ave_precision_score": 0.5483249022734623,
            "fpr": 0.43029637760702527,
            "logloss": 14.5587296103544,
            "mae": 0.44266722463766517,
            "precision": 0.5436554132712457,
            "recall": 0.9936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 32400,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.329789227123655,
            "mae": 0.5307017543859649,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.81912722898795,
            "mae": 0.5159165751920965,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.794153619318086,
            "auditor_fn_violation": 0.042588716108452954,
            "auditor_fp_violation": 0.02406900721429743,
            "ave_precision_score": 0.7945275401135814,
            "fpr": 0.07346491228070176,
            "logloss": 0.8464738394816671,
            "mae": 0.37583651794582756,
            "precision": 0.7957317073170732,
            "recall": 0.5392561983471075
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7892123686725337,
            "auditor_fn_violation": 0.047588574631571574,
            "auditor_fp_violation": 0.024378284061520695,
            "ave_precision_score": 0.7894837574897153,
            "fpr": 0.07464324917672886,
            "logloss": 0.7940490559253919,
            "mae": 0.37189136425603575,
            "precision": 0.7920489296636085,
            "recall": 0.551063829787234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6582886995943413,
            "auditor_fn_violation": 0.007897455415398016,
            "auditor_fp_violation": 0.0035431013280865717,
            "ave_precision_score": 0.5628525382274127,
            "fpr": 0.025219298245614034,
            "logloss": 0.6929180964106141,
            "mae": 0.47974284794627076,
            "precision": 0.7386363636363636,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6484146440970195,
            "auditor_fn_violation": 0.004554265828993184,
            "auditor_fp_violation": 0.0017996221540207743,
            "ave_precision_score": 0.5503545483389144,
            "fpr": 0.018660812294182216,
            "logloss": 0.6817351408770459,
            "mae": 0.48217323576286103,
            "precision": 0.7605633802816901,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6794949655067171,
            "auditor_fn_violation": 0.0035160214586052,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5664925597999022,
            "fpr": 0.023026315789473683,
            "logloss": 0.6817783967528184,
            "mae": 0.4831752692790408,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6474088186905234,
            "auditor_fn_violation": 0.008711493098535639,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5420086231460715,
            "fpr": 0.021953896816684963,
            "logloss": 0.6880019952058565,
            "mae": 0.4877314623506611,
            "precision": 0.726027397260274,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6573367941364185,
            "auditor_fn_violation": 0.0118167319124257,
            "auditor_fp_violation": 0.005075114772913595,
            "ave_precision_score": 0.5589000500014227,
            "fpr": 0.03399122807017544,
            "logloss": 0.7406172167812853,
            "mae": 0.4765426647244838,
            "precision": 0.7102803738317757,
            "recall": 0.15702479338842976
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.674538806319346,
            "auditor_fn_violation": 0.013744540719807562,
            "auditor_fp_violation": 0.0027504598619542955,
            "ave_precision_score": 0.5574576051732199,
            "fpr": 0.031833150384193196,
            "logloss": 0.7272145331083765,
            "mae": 0.4706770752839801,
            "precision": 0.7456140350877193,
            "recall": 0.18085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6360720185327253,
            "auditor_fn_violation": 0.003024412788168769,
            "auditor_fp_violation": 0.00634837678307921,
            "ave_precision_score": 0.6156391514076484,
            "fpr": 0.43640350877192985,
            "logloss": 3.669930041286056,
            "mae": 0.42678334897286013,
            "precision": 0.5461801596351197,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6666507201332379,
            "auditor_fn_violation": 0.004577621038372609,
            "auditor_fp_violation": 0.010123185754360303,
            "ave_precision_score": 0.647340293404459,
            "fpr": 0.43907793633369924,
            "logloss": 3.330914377938313,
            "mae": 0.4310329953325109,
            "precision": 0.5348837209302325,
            "recall": 0.9787234042553191
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7711155352517729,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.01024758157074931,
            "ave_precision_score": 0.5570142940179389,
            "fpr": 0.42105263157894735,
            "logloss": 14.177956217456392,
            "mae": 0.4326406554502778,
            "precision": 0.5545243619489559,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7712039370373729,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009249510268798345,
            "ave_precision_score": 0.5483199525098689,
            "fpr": 0.42371020856201974,
            "logloss": 14.545536123101845,
            "mae": 0.43563587391293074,
            "precision": 0.5469483568075117,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.667521103535752,
            "auditor_fn_violation": 0.007897455415398016,
            "auditor_fp_violation": 0.0035431013280865717,
            "ave_precision_score": 0.5617275541058053,
            "fpr": 0.025219298245614034,
            "logloss": 0.6927256135557678,
            "mae": 0.4797398902576373,
            "precision": 0.7386363636363636,
            "recall": 0.13429752066115702
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.6673090726029183,
            "auditor_fn_violation": 0.004554265828993184,
            "auditor_fp_violation": 0.0017996221540207743,
            "ave_precision_score": 0.5465450256373617,
            "fpr": 0.018660812294182216,
            "logloss": 0.6817311433449089,
            "mae": 0.48217511493045206,
            "precision": 0.7605633802816901,
            "recall": 0.1148936170212766
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6320915343079083,
            "auditor_fn_violation": 0.005405429897056692,
            "auditor_fp_violation": 0.008244179373667835,
            "ave_precision_score": 0.634855372416564,
            "fpr": 0.4407894736842105,
            "logloss": 0.8986522695193241,
            "mae": 0.462634620012644,
            "precision": 0.5395189003436426,
            "recall": 0.9731404958677686
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6309391349456865,
            "auditor_fn_violation": 0.005691664525772473,
            "auditor_fp_violation": 0.007596745247678279,
            "ave_precision_score": 0.6308739577250433,
            "fpr": 0.45334796926454446,
            "logloss": 0.7651940553411878,
            "mae": 0.45782950347167384,
            "precision": 0.5274599542334096,
            "recall": 0.9808510638297873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.767714062448898,
            "auditor_fn_violation": 0.004519628099173554,
            "auditor_fp_violation": 0.008648958845712415,
            "ave_precision_score": 0.5467288118951192,
            "fpr": 0.4342105263157895,
            "logloss": 15.067532811757186,
            "mae": 0.4420279194385793,
            "precision": 0.5463917525773195,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.007273161734507199,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.44127332601536773,
            "logloss": 15.006053613842179,
            "mae": 0.44302375770943403,
            "precision": 0.5368663594470046,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 32400,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6022493103771447,
            "auditor_fn_violation": 0.0249746266492678,
            "auditor_fp_violation": 0.03706550254140023,
            "ave_precision_score": 0.6041961197706496,
            "fpr": 0.39144736842105265,
            "logloss": 0.7331574220513106,
            "mae": 0.48594694368863073,
            "precision": 0.5498108448928121,
            "recall": 0.9008264462809917
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.5871299763081925,
            "auditor_fn_violation": 0.037994254618492665,
            "auditor_fp_violation": 0.034192820926394724,
            "ave_precision_score": 0.5874247691058542,
            "fpr": 0.4083424807903403,
            "logloss": 0.6839770047175296,
            "mae": 0.48299113078044126,
            "precision": 0.5308953341740227,
            "recall": 0.8957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7709894553974086,
            "auditor_fn_violation": 0.005038422502537335,
            "auditor_fp_violation": 0.0064149860632890686,
            "ave_precision_score": 0.5568882281530951,
            "fpr": 0.41885964912280704,
            "logloss": 14.165243743179007,
            "mae": 0.43635730210511964,
            "precision": 0.5526932084309133,
            "recall": 0.9752066115702479
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.771195524347191,
            "auditor_fn_violation": 0.0027559147067753465,
            "auditor_fp_violation": 0.008064696789802647,
            "ave_precision_score": 0.5483115407647168,
            "fpr": 0.424807903402854,
            "logloss": 14.545774061118676,
            "mae": 0.4378380039839726,
            "precision": 0.545774647887324,
            "recall": 0.9893617021276596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.854206837938487,
            "auditor_fn_violation": 0.006909707119037263,
            "auditor_fp_violation": 0.007455115592720127,
            "ave_precision_score": 0.8558816788098695,
            "fpr": 0.1206140350877193,
            "logloss": 0.7560593398517472,
            "mae": 0.24115392980895933,
            "precision": 0.78,
            "recall": 0.8057851239669421
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8534799457267088,
            "auditor_fn_violation": 0.010271621085083024,
            "auditor_fp_violation": 0.013777190349246177,
            "ave_precision_score": 0.8536806506885755,
            "fpr": 0.12184412733260154,
            "logloss": 0.8716647160921701,
            "mae": 0.25645266247609916,
            "precision": 0.7628205128205128,
            "recall": 0.7595744680851064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7183062916621903,
            "auditor_fn_violation": 0.0050837320574162745,
            "auditor_fp_violation": 0.014613051319888538,
            "ave_precision_score": 0.7186919329771801,
            "fpr": 0.2412280701754386,
            "logloss": 0.7571501518530467,
            "mae": 0.4838275474455471,
            "precision": 0.6,
            "recall": 0.6818181818181818
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6933726227945349,
            "auditor_fn_violation": 0.001609173926244248,
            "auditor_fp_violation": 0.030063397477542077,
            "ave_precision_score": 0.6938243678230986,
            "fpr": 0.23380900109769484,
            "logloss": 0.6675546276387225,
            "mae": 0.47602484381323784,
            "precision": 0.585603112840467,
            "recall": 0.6404255319148936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8201044580844081,
            "auditor_fn_violation": 0.01925429534580252,
            "auditor_fp_violation": 0.01917322511887195,
            "ave_precision_score": 0.8207044809150202,
            "fpr": 0.15679824561403508,
            "logloss": 0.6367467160137461,
            "mae": 0.3105241793898147,
            "precision": 0.7281368821292775,
            "recall": 0.7913223140495868
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8117686685540002,
            "auditor_fn_violation": 0.02259850059555784,
            "auditor_fp_violation": 0.022379533591702323,
            "ave_precision_score": 0.8120206832180816,
            "fpr": 0.14818880351262348,
            "logloss": 0.6719086283613329,
            "mae": 0.32056113235084044,
            "precision": 0.725050916496945,
            "recall": 0.7574468085106383
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7417327244529178,
            "auditor_fn_violation": 0.07476076555023924,
            "auditor_fp_violation": 0.08874405640268898,
            "ave_precision_score": 0.7422927435089246,
            "fpr": 0.2675438596491228,
            "logloss": 0.6992061887574824,
            "mae": 0.4646617919707559,
            "precision": 0.6064516129032258,
            "recall": 0.7768595041322314
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7040002639718228,
            "auditor_fn_violation": 0.07552140504939628,
            "auditor_fp_violation": 0.08864445888124736,
            "ave_precision_score": 0.7046145377994106,
            "fpr": 0.283205268935236,
            "logloss": 0.6635455659156506,
            "mae": 0.46419560923376296,
            "precision": 0.5865384615384616,
            "recall": 0.7787234042553192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6253550502754875,
            "auditor_fn_violation": 0.003806002609830361,
            "auditor_fp_violation": 0.0018958025905886227,
            "ave_precision_score": 0.6261739045393918,
            "fpr": 0.4605263157894737,
            "logloss": 0.7879466416929081,
            "mae": 0.4783384021157572,
            "precision": 0.53125,
            "recall": 0.9834710743801653
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6083182510893798,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0043285517646502415,
            "ave_precision_score": 0.6090444459885576,
            "fpr": 0.4654226125137212,
            "logloss": 0.720833898953576,
            "mae": 0.4767787893245449,
            "precision": 0.5257270693512305,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6798234678502937,
            "auditor_fn_violation": 0.0035160214586052,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5657180828851515,
            "fpr": 0.023026315789473683,
            "logloss": 0.686193109089142,
            "mae": 0.4793167047255497,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6495291276846671,
            "auditor_fn_violation": 0.008711493098535639,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5421360752469209,
            "fpr": 0.021953896816684963,
            "logloss": 0.6847113526374111,
            "mae": 0.4847041984639583,
            "precision": 0.726027397260274,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.65711320646774,
            "auditor_fn_violation": 0.0118167319124257,
            "auditor_fp_violation": 0.005075114772913595,
            "ave_precision_score": 0.5595610688445902,
            "fpr": 0.03399122807017544,
            "logloss": 0.7401405949208181,
            "mae": 0.476600391300101,
            "precision": 0.7102803738317757,
            "recall": 0.15702479338842976
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.672197430823509,
            "auditor_fn_violation": 0.013744540719807562,
            "auditor_fp_violation": 0.0027504598619542955,
            "ave_precision_score": 0.5573573841061081,
            "fpr": 0.031833150384193196,
            "logloss": 0.7262736469335342,
            "mae": 0.4704770363384754,
            "precision": 0.7456140350877193,
            "recall": 0.18085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.65711320646774,
            "auditor_fn_violation": 0.0118167319124257,
            "auditor_fp_violation": 0.005075114772913595,
            "ave_precision_score": 0.5595610688445902,
            "fpr": 0.03399122807017544,
            "logloss": 0.7401623887559167,
            "mae": 0.4766014545437014,
            "precision": 0.7102803738317757,
            "recall": 0.15702479338842976
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.672197430823509,
            "auditor_fn_violation": 0.013744540719807562,
            "auditor_fp_violation": 0.0027504598619542955,
            "ave_precision_score": 0.5573573841061081,
            "fpr": 0.031833150384193196,
            "logloss": 0.726315946220193,
            "mae": 0.47049121897254637,
            "precision": 0.7456140350877193,
            "recall": 0.18085106382978725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6687978572779322,
            "auditor_fn_violation": 0.0035160214586052,
            "auditor_fp_violation": 0.0034073208722741432,
            "ave_precision_score": 0.5670365485860253,
            "fpr": 0.023026315789473683,
            "logloss": 0.6863990286114662,
            "mae": 0.47931738323535555,
            "precision": 0.7613636363636364,
            "recall": 0.1384297520661157
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6335585378038762,
            "auditor_fn_violation": 0.008711493098535639,
            "auditor_fp_violation": 0.005463583164696541,
            "ave_precision_score": 0.5455552418317708,
            "fpr": 0.021953896816684963,
            "logloss": 0.6847194726819221,
            "mae": 0.4847020201768339,
            "precision": 0.726027397260274,
            "recall": 0.1127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7711169495827322,
            "auditor_fn_violation": 0.003982709873858199,
            "auditor_fp_violation": 0.006125491883915403,
            "ave_precision_score": 0.557015708150509,
            "fpr": 0.42214912280701755,
            "logloss": 14.18581756418895,
            "mae": 0.43532034260498587,
            "precision": 0.5538818076477404,
            "recall": 0.987603305785124
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7712039370373729,
            "auditor_fn_violation": 0.0014153256883947965,
            "auditor_fp_violation": 0.009052871056948216,
            "ave_precision_score": 0.5483199525098689,
            "fpr": 0.42590559824368823,
            "logloss": 14.550810068896357,
            "mae": 0.43889590632886055,
            "precision": 0.5456674473067916,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 32400,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.5971629649278127,
            "auditor_fn_violation": 0.0071113346382485265,
            "auditor_fp_violation": 0.015530209870470567,
            "ave_precision_score": 0.5982918981820935,
            "fpr": 0.19078947368421054,
            "logloss": 3.4979465145597097,
            "mae": 0.5225423369484783,
            "precision": 0.5070821529745042,
            "recall": 0.36983471074380164
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6492474610859604,
            "auditor_fn_violation": 0.006684260924399192,
            "auditor_fp_violation": 0.021916560257472913,
            "ave_precision_score": 0.6497565263408953,
            "fpr": 0.16465422612513722,
            "logloss": 3.1295929868500227,
            "mae": 0.4678325822609429,
            "precision": 0.5626822157434402,
            "recall": 0.4106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6621283091227783,
            "auditor_fn_violation": 0.013239451935624192,
            "auditor_fp_violation": 0.006281767502869325,
            "ave_precision_score": 0.5596710687815193,
            "fpr": 0.03070175438596491,
            "logloss": 0.7333040938124025,
            "mae": 0.47651040547511037,
            "precision": 0.7227722772277227,
            "recall": 0.15082644628099173
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6937401708946507,
            "auditor_fn_violation": 0.019333442324310435,
            "auditor_fp_violation": 0.00804976216611782,
            "ave_precision_score": 0.5640164324633917,
            "fpr": 0.025246981339187707,
            "logloss": 0.7084011297378923,
            "mae": 0.4680595445057171,
            "precision": 0.7850467289719626,
            "recall": 0.17872340425531916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7223542605490175,
            "auditor_fn_violation": 0.053959148905321164,
            "auditor_fp_violation": 0.03831826938842433,
            "ave_precision_score": 0.5659438361894442,
            "fpr": 0.3475877192982456,
            "logloss": 0.6892133669745241,
            "mae": 0.49701263216373165,
            "precision": 0.5509915014164306,
            "recall": 0.8037190082644629
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7141740985238009,
            "auditor_fn_violation": 0.05025573954270501,
            "auditor_fp_violation": 0.03227372178289538,
            "ave_precision_score": 0.5473519306443557,
            "fpr": 0.3732162458836443,
            "logloss": 0.6897754119767893,
            "mae": 0.4972905021336678,
            "precision": 0.5355191256830601,
            "recall": 0.8340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7710976724239567,
            "auditor_fn_violation": 0.0029904306220095694,
            "auditor_fp_violation": 0.006896622397114299,
            "ave_precision_score": 0.556996432853574,
            "fpr": 0.4276315789473684,
            "logloss": 14.19786394051797,
            "mae": 0.43809911533128143,
            "precision": 0.5512082853855006,
            "recall": 0.9896694214876033
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.7712088870334949,
            "auditor_fn_violation": 0.0018217063315972626,
            "auditor_fp_violation": 0.007561897792413714,
            "ave_precision_score": 0.5483249022734623,
            "fpr": 0.43029637760702527,
            "logloss": 14.558734537472734,
            "mae": 0.44266983097915985,
            "precision": 0.5436554132712457,
            "recall": 0.9936170212765958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 32400,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7558414326364814,
            "auditor_fn_violation": 0.09080487893286937,
            "auditor_fp_violation": 0.07246833497294639,
            "ave_precision_score": 0.7573393979609719,
            "fpr": 0.2050438596491228,
            "logloss": 0.6389755888370903,
            "mae": 0.4594979478115739,
            "precision": 0.649155722326454,
            "recall": 0.7148760330578512
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6769543034849479,
            "auditor_fn_violation": 0.0881635798864937,
            "auditor_fp_violation": 0.07324686186219823,
            "ave_precision_score": 0.6785611345411697,
            "fpr": 0.22502744237102085,
            "logloss": 0.6561361630852576,
            "mae": 0.46647719131899196,
            "precision": 0.6146616541353384,
            "recall": 0.6957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.600161849798673,
            "auditor_fn_violation": 0.020063070900391493,
            "auditor_fp_violation": 0.018950340219708147,
            "ave_precision_score": 0.5716059094295128,
            "fpr": 0.08223684210526316,
            "logloss": 0.7685610883355856,
            "mae": 0.4680179717313302,
            "precision": 0.6511627906976745,
            "recall": 0.2892561983471074
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6040343636857974,
            "auditor_fn_violation": 0.015743746642688673,
            "auditor_fp_violation": 0.016868657452003857,
            "ave_precision_score": 0.571023933444996,
            "fpr": 0.07793633369923161,
            "logloss": 0.7567626751109614,
            "mae": 0.46529088009856273,
            "precision": 0.6619047619047619,
            "recall": 0.2957446808510638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6028588287632585,
            "auditor_fn_violation": 0.05808231839930404,
            "auditor_fp_violation": 0.04789207247089688,
            "ave_precision_score": 0.5602587136549759,
            "fpr": 0.3574561403508772,
            "logloss": 0.6887124008083554,
            "mae": 0.4972312007295458,
            "precision": 0.5497237569060773,
            "recall": 0.8223140495867769
        },
        "train": {
            "accuracy": 0.544456641053787,
            "auc_prc": 0.5825374827769193,
            "auditor_fn_violation": 0.039984118457621974,
            "auditor_fp_violation": 0.046879783746649056,
            "ave_precision_score": 0.5376407805382748,
            "fpr": 0.36223929747530187,
            "logloss": 0.6895151642152757,
            "mae": 0.497597944756109,
            "precision": 0.5384615384615384,
            "recall": 0.8191489361702128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 32400,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8374838770241565,
            "auditor_fn_violation": 0.010994363491373064,
            "auditor_fp_violation": 0.004757439744220363,
            "ave_precision_score": 0.8380038537295497,
            "fpr": 0.13486842105263158,
            "logloss": 0.7660668224041839,
            "mae": 0.25949913629681304,
            "precision": 0.754,
            "recall": 0.7789256198347108
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8341148942233514,
            "auditor_fn_violation": 0.007753929513978098,
            "auditor_fp_violation": 0.016674507344101197,
            "ave_precision_score": 0.8343611952839263,
            "fpr": 0.12733260153677278,
            "logloss": 0.869290439193409,
            "mae": 0.27010740836354225,
            "precision": 0.7521367521367521,
            "recall": 0.7489361702127659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 32400,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7249456998076024,
            "auditor_fn_violation": 0.09178129984051037,
            "auditor_fp_violation": 0.1016560091818331,
            "ave_precision_score": 0.5619259432125676,
            "fpr": 0.2916666666666667,
            "logloss": 0.6887219325552133,
            "mae": 0.4974315516454609,
            "precision": 0.5730337078651685,
            "recall": 0.737603305785124
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7133649856727304,
            "auditor_fn_violation": 0.09004834528341547,
            "auditor_fp_violation": 0.10419140213714465,
            "ave_precision_score": 0.5408444454239744,
            "fpr": 0.31613611416026344,
            "logloss": 0.6900887022858321,
            "mae": 0.49810786501112936,
            "precision": 0.5492957746478874,
            "recall": 0.7468085106382979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7677113315528353,
            "auditor_fn_violation": 0.004519628099173554,
            "auditor_fp_violation": 0.008823167732415175,
            "ave_precision_score": 0.5467260813201228,
            "fpr": 0.4331140350877193,
            "logloss": 15.06251155475754,
            "mae": 0.4412613748200033,
            "precision": 0.5470183486238532,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.008311118080602179,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.43907793633369924,
            "logloss": 14.992788472366293,
            "mae": 0.44195719336034484,
            "precision": 0.5381062355658198,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5996590519776337,
            "auditor_fn_violation": 0.06315925402348847,
            "auditor_fp_violation": 0.06331212083948189,
            "ave_precision_score": 0.6045003678983017,
            "fpr": 0.32127192982456143,
            "logloss": 0.7021018786552207,
            "mae": 0.4880009608301375,
            "precision": 0.5716374269005848,
            "recall": 0.8078512396694215
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5867766492117727,
            "auditor_fn_violation": 0.061592358175491045,
            "auditor_fp_violation": 0.07041177246602996,
            "ave_precision_score": 0.5872899268286533,
            "fpr": 0.33150384193194293,
            "logloss": 0.676981867718215,
            "mae": 0.4841685650493739,
            "precision": 0.5578330893118595,
            "recall": 0.8106382978723404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6621283091227783,
            "auditor_fn_violation": 0.013239451935624192,
            "auditor_fp_violation": 0.006281767502869325,
            "ave_precision_score": 0.5596710687815193,
            "fpr": 0.03070175438596491,
            "logloss": 0.7333040938124025,
            "mae": 0.47651040547511037,
            "precision": 0.7227722772277227,
            "recall": 0.15082644628099173
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6937401708946507,
            "auditor_fn_violation": 0.019333442324310435,
            "auditor_fp_violation": 0.00804976216611782,
            "ave_precision_score": 0.5640164324633917,
            "fpr": 0.025246981339187707,
            "logloss": 0.7084011297378923,
            "mae": 0.4680595445057171,
            "precision": 0.7850467289719626,
            "recall": 0.17872340425531916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7402503098435809,
            "auditor_fn_violation": 0.04090773162244454,
            "auditor_fp_violation": 0.01801524840137729,
            "ave_precision_score": 0.740860389923314,
            "fpr": 0.13596491228070176,
            "logloss": 0.745753391428059,
            "mae": 0.38990548727830404,
            "precision": 0.7026378896882494,
            "recall": 0.6053719008264463
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7422357737395042,
            "auditor_fn_violation": 0.038008267744120326,
            "auditor_fp_violation": 0.017535737309925813,
            "ave_precision_score": 0.7428219829698648,
            "fpr": 0.12733260153677278,
            "logloss": 0.6955307401900733,
            "mae": 0.37733216441282574,
            "precision": 0.7128712871287128,
            "recall": 0.6127659574468085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.767711361886256,
            "auditor_fn_violation": 0.004519628099173554,
            "auditor_fp_violation": 0.008823167732415175,
            "ave_precision_score": 0.5467261116371238,
            "fpr": 0.4331140350877193,
            "logloss": 15.056670568018527,
            "mae": 0.44089905366980564,
            "precision": 0.5470183486238532,
            "recall": 0.9855371900826446
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7697763094444445,
            "auditor_fn_violation": 0.0016675619496928792,
            "auditor_fp_violation": 0.008886101092467732,
            "ave_precision_score": 0.5435203506039338,
            "fpr": 0.4313940724478595,
            "logloss": 14.981352563902183,
            "mae": 0.4376800390559161,
            "precision": 0.5424912689173458,
            "recall": 0.9914893617021276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 32400,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7218233036457868,
            "auditor_fn_violation": 0.0910586124401914,
            "auditor_fp_violation": 0.09983193966223972,
            "ave_precision_score": 0.5655613116531311,
            "fpr": 0.2949561403508772,
            "logloss": 0.6892528325146795,
            "mae": 0.49775172662185996,
            "precision": 0.5709728867623605,
            "recall": 0.7396694214876033
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7132555503869463,
            "auditor_fn_violation": 0.08853492771562697,
            "auditor_fp_violation": 0.10136875826071373,
            "ave_precision_score": 0.5466052286403493,
            "fpr": 0.3238199780461032,
            "logloss": 0.6902343228906237,
            "mae": 0.4982280226426381,
            "precision": 0.5447530864197531,
            "recall": 0.7510638297872341
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 32400,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.6240161679063726,
            "auditor_fn_violation": 0.0298454037987531,
            "auditor_fp_violation": 0.036245696015740285,
            "ave_precision_score": 0.5251202547462556,
            "fpr": 0.21052631578947367,
            "logloss": 1.1683746151110808,
            "mae": 0.4929996157032356,
            "precision": 0.5175879396984925,
            "recall": 0.4256198347107438
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6191299839921098,
            "auditor_fn_violation": 0.024835929654109357,
            "auditor_fp_violation": 0.042175377285930835,
            "ave_precision_score": 0.5194598284655589,
            "fpr": 0.19099890230515917,
            "logloss": 1.120047655012452,
            "mae": 0.49070122393111887,
            "precision": 0.5245901639344263,
            "recall": 0.4085106382978723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 32400,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6289904641430955,
            "auditor_fn_violation": 0.008996212121212122,
            "auditor_fp_violation": 0.02382562715199214,
            "ave_precision_score": 0.6256120724424896,
            "fpr": 0.34210526315789475,
            "logloss": 2.9471867181158773,
            "mae": 0.388618345578148,
            "precision": 0.5910878112712975,
            "recall": 0.9318181818181818
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6647199979446305,
            "auditor_fn_violation": 0.006604853212509052,
            "auditor_fp_violation": 0.030115668660438934,
            "ave_precision_score": 0.6620129631634926,
            "fpr": 0.3216245883644347,
            "logloss": 2.66831423713213,
            "mae": 0.3794020025394898,
            "precision": 0.5997267759562842,
            "recall": 0.9340425531914893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 32400,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6573367941364185,
            "auditor_fn_violation": 0.0118167319124257,
            "auditor_fp_violation": 0.005075114772913595,
            "ave_precision_score": 0.5589000500014227,
            "fpr": 0.03399122807017544,
            "logloss": 0.7406172167812853,
            "mae": 0.4765426647244838,
            "precision": 0.7102803738317757,
            "recall": 0.15702479338842976
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.674538806319346,
            "auditor_fn_violation": 0.013744540719807562,
            "auditor_fp_violation": 0.0027504598619542955,
            "ave_precision_score": 0.5574576051732199,
            "fpr": 0.031833150384193196,
            "logloss": 0.7272145331083765,
            "mae": 0.4706770752839801,
            "precision": 0.7456140350877193,
            "recall": 0.18085106382978725
        }
    }
]