[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7909138094058614,
            "auditor_fn_violation": 0.009032346491228074,
            "auditor_fp_violation": 0.01342186484730345,
            "ave_precision_score": 0.7702384109575293,
            "fpr": 0.16666666666666666,
            "logloss": 2.841408165112341,
            "mae": 0.2940789462871377,
            "precision": 0.7275985663082437,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.773418577868667,
            "auditor_fn_violation": 0.010504522780641668,
            "auditor_fp_violation": 0.010233429706084044,
            "ave_precision_score": 0.7520847302760086,
            "fpr": 0.1712403951701427,
            "logloss": 3.1314664799548986,
            "mae": 0.30509766395507754,
            "precision": 0.7073170731707317,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7987429303192513,
            "auditor_fn_violation": 0.015035635964912284,
            "auditor_fp_violation": 0.03042001705653021,
            "ave_precision_score": 0.7864300848031347,
            "fpr": 0.18311403508771928,
            "logloss": 2.3450120636626433,
            "mae": 0.3029800813937902,
            "precision": 0.7085514834205934,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7766325030855286,
            "auditor_fn_violation": 0.013686448331920694,
            "auditor_fp_violation": 0.030007008166146293,
            "ave_precision_score": 0.7665113903301792,
            "fpr": 0.18880351262349068,
            "logloss": 2.595406468828765,
            "mae": 0.31592929108698403,
            "precision": 0.6906474820143885,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8831394792937457,
            "auditor_fn_violation": 0.007853618421052633,
            "auditor_fp_violation": 0.011838044184535414,
            "ave_precision_score": 0.8833430531874642,
            "fpr": 0.09429824561403509,
            "logloss": 0.45258639914717064,
            "mae": 0.27841090466270607,
            "precision": 0.8146551724137931,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8726788621676942,
            "auditor_fn_violation": 0.011831482999624839,
            "auditor_fp_violation": 0.008733832864029017,
            "ave_precision_score": 0.8731835652027125,
            "fpr": 0.10428100987925357,
            "logloss": 0.4601721439460405,
            "mae": 0.27659705711189253,
            "precision": 0.798728813559322,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8824726926650357,
            "auditor_fn_violation": 0.009438961988304097,
            "auditor_fp_violation": 0.014338145711500976,
            "ave_precision_score": 0.8826875107583549,
            "fpr": 0.09100877192982457,
            "logloss": 0.4563359279103761,
            "mae": 0.27697954547240217,
            "precision": 0.8179824561403509,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.872355442678164,
            "auditor_fn_violation": 0.013459498765672262,
            "auditor_fp_violation": 0.011150268646368944,
            "ave_precision_score": 0.87277443337868,
            "fpr": 0.09769484083424808,
            "logloss": 0.4627016794438043,
            "mae": 0.2755604528651535,
            "precision": 0.8061002178649237,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7491727796958617,
            "auditor_fn_violation": 0.005756578947368424,
            "auditor_fp_violation": 0.007330246913580249,
            "ave_precision_score": 0.717146474774106,
            "fpr": 0.16557017543859648,
            "logloss": 2.3705401140236755,
            "mae": 0.2945731308995515,
            "precision": 0.7284172661870504,
            "recall": 0.84375
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7307793418759585,
            "auditor_fn_violation": 0.007649126707332324,
            "auditor_fp_violation": 0.011029698046002708,
            "ave_precision_score": 0.6998273820615001,
            "fpr": 0.18331503841931943,
            "logloss": 2.40383006513038,
            "mae": 0.3041457275067851,
            "precision": 0.7017857142857142,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7825200063019704,
            "auditor_fn_violation": 0.01308479532163743,
            "auditor_fp_violation": 0.010421743014944774,
            "ave_precision_score": 0.7639486237271437,
            "fpr": 0.1425438596491228,
            "logloss": 2.7098066741179947,
            "mae": 0.2836935721065464,
            "precision": 0.7389558232931727,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7640227727990313,
            "auditor_fn_violation": 0.002714131547379197,
            "auditor_fp_violation": 0.01745259440301226,
            "ave_precision_score": 0.7460976112392238,
            "fpr": 0.14818880351262348,
            "logloss": 3.007837237841509,
            "mae": 0.30144222499541207,
            "precision": 0.7181628392484343,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7933896912121705,
            "auditor_fn_violation": 0.00723684210526316,
            "auditor_fp_violation": 0.014117324561403506,
            "ave_precision_score": 0.7743862580031481,
            "fpr": 0.17763157894736842,
            "logloss": 2.1759080832005573,
            "mae": 0.2950965559270892,
            "precision": 0.7197231833910035,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7680499468741562,
            "auditor_fn_violation": 0.0010606418504263435,
            "auditor_fp_violation": 0.017216476977295052,
            "ave_precision_score": 0.7476408318333212,
            "fpr": 0.20197585071350166,
            "logloss": 2.37939227831764,
            "mae": 0.31697330909357735,
            "precision": 0.68,
            "recall": 0.8248945147679325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7959113289311156,
            "auditor_fn_violation": 0.007789656432748541,
            "auditor_fp_violation": 0.015493014944769332,
            "ave_precision_score": 0.7769506666274089,
            "fpr": 0.16885964912280702,
            "logloss": 2.1586978520640616,
            "mae": 0.2861058081572791,
            "precision": 0.7283950617283951,
            "recall": 0.8604166666666667
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7722735562840132,
            "auditor_fn_violation": 0.005356472925843071,
            "auditor_fp_violation": 0.010828747045392315,
            "ave_precision_score": 0.7520096086390589,
            "fpr": 0.18990120746432493,
            "logloss": 2.3476925186612423,
            "mae": 0.3108634005341759,
            "precision": 0.6899641577060932,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8171463365463963,
            "auditor_fn_violation": 0.012280701754385967,
            "auditor_fp_violation": 0.01591435185185186,
            "ave_precision_score": 0.800197856553902,
            "fpr": 0.14692982456140352,
            "logloss": 1.438675010833858,
            "mae": 0.2735793343713579,
            "precision": 0.7545787545787546,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.786474231166067,
            "auditor_fn_violation": 0.014821196163162844,
            "auditor_fp_violation": 0.017229036414833202,
            "ave_precision_score": 0.7629907433465566,
            "fpr": 0.16465422612513722,
            "logloss": 1.836907349794429,
            "mae": 0.2809927154343629,
            "precision": 0.7277676950998185,
            "recall": 0.8459915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6845011275207646,
            "auditor_fn_violation": 0.01257995248538012,
            "auditor_fp_violation": 0.010802469135802477,
            "ave_precision_score": 0.6859413272075676,
            "fpr": 0.15679824561403508,
            "logloss": 0.9093563816109027,
            "mae": 0.36232722644841453,
            "precision": 0.7116935483870968,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.747532554253918,
            "auditor_fn_violation": 0.0034690862269403143,
            "auditor_fp_violation": 0.004435993338474332,
            "ave_precision_score": 0.7485845302343891,
            "fpr": 0.14270032930845225,
            "logloss": 0.6746880478851811,
            "mae": 0.3466278946055321,
            "precision": 0.7257383966244726,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7941857001012135,
            "auditor_fn_violation": 0.008922697368421054,
            "auditor_fp_violation": 0.019660696881091618,
            "ave_precision_score": 0.7751193214586086,
            "fpr": 0.18530701754385964,
            "logloss": 2.018039390438201,
            "mae": 0.2918968842875334,
            "precision": 0.71160409556314,
            "recall": 0.86875
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7715843356497071,
            "auditor_fn_violation": 0.0031101353823637023,
            "auditor_fp_violation": 0.00952507742893242,
            "ave_precision_score": 0.7503966461650196,
            "fpr": 0.18990120746432493,
            "logloss": 2.2334511179143886,
            "mae": 0.3097448771698748,
            "precision": 0.6954225352112676,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7491126827615157,
            "auditor_fn_violation": 0.013123629385964921,
            "auditor_fp_violation": 0.015343262670565303,
            "ave_precision_score": 0.7504773793516978,
            "fpr": 0.12390350877192982,
            "logloss": 1.4331371568152995,
            "mae": 0.3171768624550167,
            "precision": 0.7626050420168067,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8100759728637105,
            "auditor_fn_violation": 0.010944527041735569,
            "auditor_fp_violation": 0.011941513211272356,
            "ave_precision_score": 0.8108408078154961,
            "fpr": 0.12843029637760703,
            "logloss": 1.3524933386197233,
            "mae": 0.3117182893772429,
            "precision": 0.7494646680942184,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5611808231852169,
            "auditor_fn_violation": 0.004385964912280713,
            "auditor_fp_violation": 0.011188271604938273,
            "ave_precision_score": 0.5630515370427487,
            "fpr": 0.09429824561403509,
            "logloss": 6.266331902447074,
            "mae": 0.4913773704020643,
            "precision": 0.6573705179282868,
            "recall": 0.34375
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6312213657417083,
            "auditor_fn_violation": 0.008267448484764267,
            "auditor_fp_violation": 0.008992557277314893,
            "ave_precision_score": 0.6318429019764789,
            "fpr": 0.07793633369923161,
            "logloss": 5.831684567867645,
            "mae": 0.4645127122219652,
            "precision": 0.6978723404255319,
            "recall": 0.3459915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8241946989691294,
            "auditor_fn_violation": 0.00878563596491228,
            "auditor_fp_violation": 0.017361111111111115,
            "ave_precision_score": 0.7957913512147496,
            "fpr": 0.14912280701754385,
            "logloss": 1.8013454659698203,
            "mae": 0.2691024702181223,
            "precision": 0.7472118959107806,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7821907231478824,
            "auditor_fn_violation": 0.008869559578892768,
            "auditor_fp_violation": 0.02151180461534211,
            "ave_precision_score": 0.7422303428085435,
            "fpr": 0.15806805708013172,
            "logloss": 2.504624548332117,
            "mae": 0.28760280732730453,
            "precision": 0.7293233082706767,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7984876238576264,
            "auditor_fn_violation": 0.00651041666666667,
            "auditor_fp_violation": 0.013355872319688109,
            "ave_precision_score": 0.7655161149376883,
            "fpr": 0.1118421052631579,
            "logloss": 3.8546709200089766,
            "mae": 0.28361733981108966,
            "precision": 0.7718120805369127,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7626669724586653,
            "auditor_fn_violation": 0.0049396267837541145,
            "auditor_fp_violation": 0.010763437970193945,
            "ave_precision_score": 0.7217150271398782,
            "fpr": 0.1207464324917673,
            "logloss": 4.8681440819431785,
            "mae": 0.3045121179689501,
            "precision": 0.7471264367816092,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 6933,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7823755185479198,
            "auditor_fn_violation": 0.012129934210526317,
            "auditor_fp_violation": 0.01413762995451592,
            "ave_precision_score": 0.7638355323123633,
            "fpr": 0.1425438596491228,
            "logloss": 2.700124655852703,
            "mae": 0.2835929670249332,
            "precision": 0.7373737373737373,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.762816540824921,
            "auditor_fn_violation": 0.004884047298142263,
            "auditor_fp_violation": 0.01879143044457897,
            "ave_precision_score": 0.7450706624422284,
            "fpr": 0.14818880351262348,
            "logloss": 2.9937921724732415,
            "mae": 0.30204095760926214,
            "precision": 0.7163865546218487,
            "recall": 0.7194092827004219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.800210190101198,
            "auditor_fn_violation": 0.039912280701754385,
            "auditor_fp_violation": 0.021686159844054587,
            "ave_precision_score": 0.7873944557988827,
            "fpr": 0.14035087719298245,
            "logloss": 2.729331316470104,
            "mae": 0.3009730250473124,
            "precision": 0.75,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7700375072796003,
            "auditor_fn_violation": 0.027801321865432802,
            "auditor_fp_violation": 0.03235311109827259,
            "ave_precision_score": 0.7526870317880608,
            "fpr": 0.17672886937431395,
            "logloss": 2.7087845129723696,
            "mae": 0.3084660655493144,
            "precision": 0.7018518518518518,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7955956588659524,
            "auditor_fn_violation": 0.00884046052631579,
            "auditor_fp_violation": 0.020650584795321638,
            "ave_precision_score": 0.7764831306812837,
            "fpr": 0.18201754385964913,
            "logloss": 1.9939569428336632,
            "mae": 0.289533368989789,
            "precision": 0.7142857142857143,
            "recall": 0.8645833333333334
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.772853121188479,
            "auditor_fn_violation": 0.004376884491934027,
            "auditor_fp_violation": 0.00952507742893242,
            "ave_precision_score": 0.7516190749571354,
            "fpr": 0.18990120746432493,
            "logloss": 2.206204065685868,
            "mae": 0.3069701987292735,
            "precision": 0.6948853615520282,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7816259092328713,
            "auditor_fn_violation": 0.008568622076023396,
            "auditor_fp_violation": 0.011056286549707599,
            "ave_precision_score": 0.727219605137082,
            "fpr": 0.17105263157894737,
            "logloss": 4.010610128940074,
            "mae": 0.30751466263976623,
            "precision": 0.7039848197343453,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7497210527615747,
            "auditor_fn_violation": 0.003969301597447048,
            "auditor_fp_violation": 0.0014317758793490182,
            "ave_precision_score": 0.6839395056046532,
            "fpr": 0.1877058177826564,
            "logloss": 4.886609132885185,
            "mae": 0.3380076666549045,
            "precision": 0.6767485822306238,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7976205558284583,
            "auditor_fn_violation": 0.010535453216374276,
            "auditor_fp_violation": 0.007665285899935023,
            "ave_precision_score": 0.7646326950987187,
            "fpr": 0.12938596491228072,
            "logloss": 3.8257283371644846,
            "mae": 0.2807635678780627,
            "precision": 0.7596741344195519,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7687462778331251,
            "auditor_fn_violation": 0.007211438258138922,
            "auditor_fp_violation": 0.006023506243296402,
            "ave_precision_score": 0.7277754459093518,
            "fpr": 0.14928649835345773,
            "logloss": 4.719296206472244,
            "mae": 0.3023228613413742,
            "precision": 0.7207392197125256,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8212731964325412,
            "auditor_fn_violation": 0.011330409356725146,
            "auditor_fp_violation": 0.010561342592592594,
            "ave_precision_score": 0.7906926779238117,
            "fpr": 0.13706140350877194,
            "logloss": 2.842736934004238,
            "mae": 0.2582523618988233,
            "precision": 0.758220502901354,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7753781897851383,
            "auditor_fn_violation": 0.007697758757242704,
            "auditor_fp_violation": 0.014272544818352863,
            "ave_precision_score": 0.7326023334283135,
            "fpr": 0.150384193194292,
            "logloss": 3.93794686395397,
            "mae": 0.2832263305932958,
            "precision": 0.730844793713163,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7919743262681342,
            "auditor_fn_violation": 0.011229897660818717,
            "auditor_fp_violation": 0.015046296296296304,
            "ave_precision_score": 0.7731507587099398,
            "fpr": 0.16447368421052633,
            "logloss": 2.0948794534155244,
            "mae": 0.2782348948672897,
            "precision": 0.7307001795332136,
            "recall": 0.8479166666666667
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7677729002219429,
            "auditor_fn_violation": 0.005210576776111938,
            "auditor_fp_violation": 0.01227810613729475,
            "ave_precision_score": 0.7475822297868189,
            "fpr": 0.1800219538968167,
            "logloss": 2.311934403506256,
            "mae": 0.30493189388777875,
            "precision": 0.7007299270072993,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7879081762385309,
            "auditor_fn_violation": 0.006601790935672514,
            "auditor_fp_violation": 0.018800255847953216,
            "ave_precision_score": 0.7671398385446513,
            "fpr": 0.1875,
            "logloss": 2.787061848630735,
            "mae": 0.304247053276436,
            "precision": 0.7051724137931035,
            "recall": 0.8520833333333333
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7662218993765018,
            "auditor_fn_violation": 0.00229728540529024,
            "auditor_fp_violation": 0.015073836933286788,
            "ave_precision_score": 0.7463456984768615,
            "fpr": 0.18441273326015367,
            "logloss": 3.0632149355692277,
            "mae": 0.31705465001899763,
            "precision": 0.6983842010771992,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7328746153909356,
            "auditor_fn_violation": 0.005493877923976611,
            "auditor_fp_violation": 0.011962414717348933,
            "ave_precision_score": 0.6640605255595357,
            "fpr": 0.19407894736842105,
            "logloss": 5.971382586111458,
            "mae": 0.33519747597625876,
            "precision": 0.6734317343173432,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6926227270305385,
            "auditor_fn_violation": 0.007097963475014711,
            "auditor_fp_violation": 0.015026111070641817,
            "ave_precision_score": 0.6147809722423525,
            "fpr": 0.2074643249176729,
            "logloss": 7.634036120410303,
            "mae": 0.36986629099438306,
            "precision": 0.6486988847583643,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8715654042137568,
            "auditor_fn_violation": 0.010713633040935673,
            "auditor_fp_violation": 0.010117162118258612,
            "ave_precision_score": 0.8719330056479513,
            "fpr": 0.09429824561403509,
            "logloss": 0.47137992784877575,
            "mae": 0.2833578688981728,
            "precision": 0.8114035087719298,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.865754069468207,
            "auditor_fn_violation": 0.008415660446395905,
            "auditor_fp_violation": 0.00734978284732497,
            "ave_precision_score": 0.8662866837959478,
            "fpr": 0.10428100987925357,
            "logloss": 0.471859495030842,
            "mae": 0.2787046928371356,
            "precision": 0.7974413646055437,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7893712616083154,
            "auditor_fn_violation": 0.007049524853801169,
            "auditor_fp_violation": 0.01908706952566602,
            "ave_precision_score": 0.7708194218658504,
            "fpr": 0.19298245614035087,
            "logloss": 2.2756384700300147,
            "mae": 0.3023509689451376,
            "precision": 0.7011884550084889,
            "recall": 0.8604166666666667
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7726879133994068,
            "auditor_fn_violation": 0.007741759183352094,
            "auditor_fp_violation": 0.011971655861363907,
            "ave_precision_score": 0.7553970058522532,
            "fpr": 0.2074643249176729,
            "logloss": 2.3816393263538966,
            "mae": 0.3196888451772384,
            "precision": 0.6741379310344827,
            "recall": 0.8248945147679325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7891507408655082,
            "auditor_fn_violation": 0.00849780701754386,
            "auditor_fp_violation": 0.017399183723196886,
            "ave_precision_score": 0.7567001260532866,
            "fpr": 0.14364035087719298,
            "logloss": 4.175751448015476,
            "mae": 0.28510358380131845,
            "precision": 0.7331975560081466,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7610209045509131,
            "auditor_fn_violation": 0.009156720254554043,
            "auditor_fp_violation": 0.012695079463561307,
            "ave_precision_score": 0.722114261980253,
            "fpr": 0.14818880351262348,
            "logloss": 5.110497509451009,
            "mae": 0.30823504218010106,
            "precision": 0.7169811320754716,
            "recall": 0.7215189873417721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8047666083022431,
            "auditor_fn_violation": 0.006389345760233918,
            "auditor_fp_violation": 0.01183296783625731,
            "ave_precision_score": 0.7694754484104778,
            "fpr": 0.10855263157894737,
            "logloss": 3.806957528047417,
            "mae": 0.272984402173328,
            "precision": 0.7838427947598253,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7642613818490516,
            "auditor_fn_violation": 0.007185964327233494,
            "auditor_fp_violation": 0.013983677754975426,
            "ave_precision_score": 0.7198892647916386,
            "fpr": 0.1251372118551043,
            "logloss": 4.967306551942567,
            "mae": 0.30070491888543105,
            "precision": 0.7472283813747228,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8008177949686592,
            "auditor_fn_violation": 0.01716008771929825,
            "auditor_fp_violation": 0.015625000000000007,
            "ave_precision_score": 0.7674749582509576,
            "fpr": 0.12171052631578948,
            "logloss": 3.908887954899125,
            "mae": 0.27013362519893486,
            "precision": 0.7701863354037267,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7659684726915922,
            "auditor_fn_violation": 0.009300300592384687,
            "auditor_fp_violation": 0.01596555699849539,
            "ave_precision_score": 0.7247557556133482,
            "fpr": 0.1350164654226125,
            "logloss": 4.876320987669758,
            "mae": 0.2985662310485675,
            "precision": 0.7377398720682303,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8077741184413698,
            "auditor_fn_violation": 0.003974780701754385,
            "auditor_fp_violation": 0.007142422027290457,
            "ave_precision_score": 0.7857185209718949,
            "fpr": 0.15679824561403508,
            "logloss": 1.6581697497640338,
            "mae": 0.2808615756979347,
            "precision": 0.7395264116575592,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7710194326635819,
            "auditor_fn_violation": 0.010205783045477914,
            "auditor_fp_violation": 0.015887688485758854,
            "ave_precision_score": 0.7434035021217588,
            "fpr": 0.17672886937431395,
            "logloss": 2.080719656981168,
            "mae": 0.2964546336290456,
            "precision": 0.7114695340501792,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7508214507986604,
            "auditor_fn_violation": 0.019476425438596488,
            "auditor_fp_violation": 0.017300194931773878,
            "ave_precision_score": 0.6214186127570582,
            "fpr": 0.16337719298245615,
            "logloss": 12.172885300744166,
            "mae": 0.35459410153296694,
            "precision": 0.6725274725274726,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.734605846723241,
            "auditor_fn_violation": 0.012338645805833062,
            "auditor_fp_violation": 0.007837089023805161,
            "ave_precision_score": 0.5988078357008519,
            "fpr": 0.18660812294182216,
            "logloss": 12.853750292440068,
            "mae": 0.37282791845786717,
            "precision": 0.6413502109704642,
            "recall": 0.6413502109704642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7572349032257903,
            "auditor_fn_violation": 0.02033991228070176,
            "auditor_fp_violation": 0.009716130604288498,
            "ave_precision_score": 0.7268822562297262,
            "fpr": 0.38048245614035087,
            "logloss": 4.131501045652363,
            "mae": 0.4376372969186596,
            "precision": 0.5403973509933775,
            "recall": 0.85
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7168638424303304,
            "auditor_fn_violation": 0.023862125822692176,
            "auditor_fp_violation": 0.016568410000326557,
            "ave_precision_score": 0.6814053558487334,
            "fpr": 0.38748627881448955,
            "logloss": 4.518506023847839,
            "mae": 0.44115350540478865,
            "precision": 0.5349143610013175,
            "recall": 0.8565400843881856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7961535755456578,
            "auditor_fn_violation": 0.008315058479532164,
            "auditor_fp_violation": 0.017543859649122806,
            "ave_precision_score": 0.7772285237051217,
            "fpr": 0.17763157894736842,
            "logloss": 2.1576419050823565,
            "mae": 0.2908363771834372,
            "precision": 0.7177700348432056,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7707993809578597,
            "auditor_fn_violation": 0.0022046529292704745,
            "auditor_fp_violation": 0.011268327359227552,
            "ave_precision_score": 0.7505384614749807,
            "fpr": 0.19758507135016465,
            "logloss": 2.354942734561805,
            "mae": 0.31439231515692284,
            "precision": 0.6830985915492958,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7830501383256142,
            "auditor_fn_violation": 0.01127330043859649,
            "auditor_fp_violation": 0.016196089181286552,
            "ave_precision_score": 0.764419044569275,
            "fpr": 0.14364035087719298,
            "logloss": 2.7064235853218124,
            "mae": 0.28392605884294037,
            "precision": 0.738,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7636501063326651,
            "auditor_fn_violation": 0.001090747405132769,
            "auditor_fp_violation": 0.01745259440301226,
            "ave_precision_score": 0.7457098437466871,
            "fpr": 0.14818880351262348,
            "logloss": 3.00523155331839,
            "mae": 0.3016056112303536,
            "precision": 0.71875,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6448054651379652,
            "auditor_fn_violation": 0.006099232456140363,
            "auditor_fp_violation": 0.0074317738791423,
            "ave_precision_score": 0.6368839139959801,
            "fpr": 0.02412280701754386,
            "logloss": 10.231406967456383,
            "mae": 0.45478537230399035,
            "precision": 0.8333333333333334,
            "recall": 0.22916666666666666
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6253911470070798,
            "auditor_fn_violation": 0.013491920132279182,
            "auditor_fp_violation": 0.0011630039160326255,
            "ave_precision_score": 0.6168821241631882,
            "fpr": 0.029637760702524697,
            "logloss": 10.81184572934349,
            "mae": 0.4644936559934995,
            "precision": 0.7786885245901639,
            "recall": 0.20042194092827004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8241561634102679,
            "auditor_fn_violation": 0.010238486842105262,
            "auditor_fp_violation": 0.012731481481481479,
            "ave_precision_score": 0.7935708426061667,
            "fpr": 0.10964912280701754,
            "logloss": 2.882340957258306,
            "mae": 0.2575281907624043,
            "precision": 0.791231732776618,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7759508098426384,
            "auditor_fn_violation": 0.007614389528824909,
            "auditor_fp_violation": 0.01465686360702023,
            "ave_precision_score": 0.7325012336042717,
            "fpr": 0.13721185510428102,
            "logloss": 4.024055013844958,
            "mae": 0.2838448227882352,
            "precision": 0.742798353909465,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8216616161288416,
            "auditor_fn_violation": 0.009649122807017551,
            "auditor_fp_violation": 0.013975186809616638,
            "ave_precision_score": 0.7910805388170852,
            "fpr": 0.13048245614035087,
            "logloss": 2.8429155415566534,
            "mae": 0.2599476404400176,
            "precision": 0.7634194831013916,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7746447298443018,
            "auditor_fn_violation": 0.005717739582320166,
            "auditor_fp_violation": 0.013697322579105622,
            "ave_precision_score": 0.7318695496639225,
            "fpr": 0.145993413830955,
            "logloss": 3.94396229840497,
            "mae": 0.28521471179508856,
            "precision": 0.734,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8146767534836571,
            "auditor_fn_violation": 0.004111842105263158,
            "auditor_fp_violation": 0.021076998050682264,
            "ave_precision_score": 0.7976297086684783,
            "fpr": 0.21052631578947367,
            "logloss": 1.5212971895708776,
            "mae": 0.2925558290107323,
            "precision": 0.6962025316455697,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7807077297027654,
            "auditor_fn_violation": 0.012359488112937517,
            "auditor_fp_violation": 0.02056733491247328,
            "ave_precision_score": 0.7572169658586979,
            "fpr": 0.21953896816684962,
            "logloss": 1.920531981581088,
            "mae": 0.30760690092907056,
            "precision": 0.6820349761526232,
            "recall": 0.9050632911392406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7017624082529292,
            "auditor_fn_violation": 0.007611476608187138,
            "auditor_fp_violation": 0.004743847465886943,
            "ave_precision_score": 0.69814007629125,
            "fpr": 0.13048245614035087,
            "logloss": 1.8315225739476206,
            "mae": 0.3374184995666343,
            "precision": 0.7494736842105263,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7183348635343105,
            "auditor_fn_violation": 0.014934670946287063,
            "auditor_fp_violation": 0.00017834401304172467,
            "ave_precision_score": 0.7148334678814553,
            "fpr": 0.13062568605927552,
            "logloss": 1.552887697121127,
            "mae": 0.3278545554089076,
            "precision": 0.7478813559322034,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7832211546082406,
            "auditor_fn_violation": 0.01127330043859649,
            "auditor_fp_violation": 0.009685672514619888,
            "ave_precision_score": 0.7645518119336524,
            "fpr": 0.14473684210526316,
            "logloss": 2.7225902038398826,
            "mae": 0.2840835341220144,
            "precision": 0.7365269461077845,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7630837746007266,
            "auditor_fn_violation": 0.0024454973669218736,
            "auditor_fp_violation": 0.01769373560374472,
            "ave_precision_score": 0.7444589029223057,
            "fpr": 0.14818880351262348,
            "logloss": 3.0374194651991124,
            "mae": 0.3019070473046039,
            "precision": 0.7199170124481328,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.65871540278291,
            "auditor_fn_violation": 0.014464546783625734,
            "auditor_fp_violation": 0.036580165692007796,
            "ave_precision_score": 0.6436025686582927,
            "fpr": 0.1513157894736842,
            "logloss": 3.4098744659228286,
            "mae": 0.3284840591417091,
            "precision": 0.7063829787234043,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6436944528386367,
            "auditor_fn_violation": 0.019890508413344637,
            "auditor_fp_violation": 0.03910506471878163,
            "ave_precision_score": 0.6295870153332059,
            "fpr": 0.15697036223929747,
            "logloss": 3.6584644350094346,
            "mae": 0.3514692031960984,
            "precision": 0.6864035087719298,
            "recall": 0.6603375527426161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8278399231381879,
            "auditor_fn_violation": 0.003360288742690061,
            "auditor_fp_violation": 0.006398737004548415,
            "ave_precision_score": 0.8116127761446701,
            "fpr": 0.15899122807017543,
            "logloss": 1.3737910806883185,
            "mae": 0.26951058677186984,
            "precision": 0.7438162544169611,
            "recall": 0.8770833333333333
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.788739523023611,
            "auditor_fn_violation": 0.0066417485306173515,
            "auditor_fp_violation": 0.01609868703639976,
            "ave_precision_score": 0.767295317724515,
            "fpr": 0.1734357848518112,
            "logloss": 1.7736007740045263,
            "mae": 0.28345765067752426,
            "precision": 0.7208480565371025,
            "recall": 0.8607594936708861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8206227651791412,
            "auditor_fn_violation": 0.01127330043859649,
            "auditor_fp_violation": 0.0134294793697206,
            "ave_precision_score": 0.7900724502459451,
            "fpr": 0.11951754385964912,
            "logloss": 2.840078629777851,
            "mae": 0.2555840170720535,
            "precision": 0.780241935483871,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7727494631567808,
            "auditor_fn_violation": 0.007311018169860178,
            "auditor_fp_violation": 0.014938195007874775,
            "ave_precision_score": 0.7301567022731674,
            "fpr": 0.145993413830955,
            "logloss": 3.9254140550769883,
            "mae": 0.28517616446268274,
            "precision": 0.734,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8253486243189072,
            "auditor_fn_violation": 0.006743421052631581,
            "auditor_fp_violation": 0.015487938596491228,
            "ave_precision_score": 0.8102674631115698,
            "fpr": 0.17214912280701755,
            "logloss": 1.4295198349737148,
            "mae": 0.27459115545074253,
            "precision": 0.7311643835616438,
            "recall": 0.8895833333333333
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7830011844179663,
            "auditor_fn_violation": 0.005801108810737959,
            "auditor_fp_violation": 0.02075321458803789,
            "ave_precision_score": 0.7620599723558145,
            "fpr": 0.18990120746432493,
            "logloss": 1.8335036539933145,
            "mae": 0.2934087718584741,
            "precision": 0.7037671232876712,
            "recall": 0.8670886075949367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8228551058380006,
            "auditor_fn_violation": 0.015058479532163747,
            "auditor_fp_violation": 0.009990253411306046,
            "ave_precision_score": 0.7922733548949679,
            "fpr": 0.13157894736842105,
            "logloss": 2.8431346403141267,
            "mae": 0.2550256496908478,
            "precision": 0.7665369649805448,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.776346998634275,
            "auditor_fn_violation": 0.011880115049535225,
            "auditor_fp_violation": 0.0168422057386582,
            "ave_precision_score": 0.7335159013955335,
            "fpr": 0.150384193194292,
            "logloss": 3.9336458812904294,
            "mae": 0.2817954096522574,
            "precision": 0.7297830374753451,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8740050089337371,
            "auditor_fn_violation": 0.008516081871345033,
            "auditor_fp_violation": 0.014619883040935677,
            "ave_precision_score": 0.8742150850116508,
            "fpr": 0.09868421052631579,
            "logloss": 0.4739549103891727,
            "mae": 0.2963951805292725,
            "precision": 0.8068669527896996,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8745443369585022,
            "auditor_fn_violation": 0.010379468938014983,
            "auditor_fp_violation": 0.009926979430153202,
            "ave_precision_score": 0.8749102761634593,
            "fpr": 0.10428100987925357,
            "logloss": 0.4565702287647893,
            "mae": 0.2881646618090747,
            "precision": 0.7965738758029979,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7912599904801983,
            "auditor_fn_violation": 0.007773665935672516,
            "auditor_fp_violation": 0.014987918291098114,
            "ave_precision_score": 0.7717947281854234,
            "fpr": 0.17214912280701755,
            "logloss": 2.217650870926421,
            "mae": 0.2848648937080043,
            "precision": 0.7216312056737588,
            "recall": 0.8479166666666667
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7698995295061732,
            "auditor_fn_violation": 0.0036659302384823103,
            "auditor_fp_violation": 0.010828747045392315,
            "ave_precision_score": 0.7496352944447816,
            "fpr": 0.18990120746432493,
            "logloss": 2.389530500356105,
            "mae": 0.30830354928590725,
            "precision": 0.6888489208633094,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7246172495535501,
            "auditor_fn_violation": 0.007684576023391817,
            "auditor_fp_violation": 0.002827525990903185,
            "ave_precision_score": 0.7264961464126749,
            "fpr": 0.11074561403508772,
            "logloss": 0.6585044375029511,
            "mae": 0.3595106077987829,
            "precision": 0.7566265060240964,
            "recall": 0.6541666666666667
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7541541212115841,
            "auditor_fn_violation": 0.00408509219247176,
            "auditor_fp_violation": 0.00592051885548358,
            "ave_precision_score": 0.7552683743267733,
            "fpr": 0.11855104281009879,
            "logloss": 0.6186778787116419,
            "mae": 0.34457819371110565,
            "precision": 0.75,
            "recall": 0.6835443037974683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7943589333569345,
            "auditor_fn_violation": 0.006907894736842106,
            "auditor_fp_violation": 0.012147701429499681,
            "ave_precision_score": 0.775367736217583,
            "fpr": 0.18201754385964913,
            "logloss": 2.1904231157055247,
            "mae": 0.2934967560008009,
            "precision": 0.7152658662092625,
            "recall": 0.86875
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.769804688821482,
            "auditor_fn_violation": 0.007378176714974506,
            "auditor_fp_violation": 0.01371992956667429,
            "ave_precision_score": 0.7495593107512424,
            "fpr": 0.19758507135016465,
            "logloss": 2.3868719617464618,
            "mae": 0.3164632138498794,
            "precision": 0.6858638743455497,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6588134276428885,
            "auditor_fn_violation": 0.018028143274853806,
            "auditor_fp_violation": 0.040981359649122806,
            "ave_precision_score": 0.6602350046209724,
            "fpr": 0.1875,
            "logloss": 1.9432575318774614,
            "mae": 0.3834735234758179,
            "precision": 0.6698841698841699,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.6645775708542959,
            "auditor_fn_violation": 0.019772402006419443,
            "auditor_fp_violation": 0.04399822158364461,
            "ave_precision_score": 0.6646024228005529,
            "fpr": 0.1690450054884742,
            "logloss": 2.150235906957098,
            "mae": 0.3775769386718583,
            "precision": 0.673728813559322,
            "recall": 0.6708860759493671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8141992411175449,
            "auditor_fn_violation": 0.021728801169590643,
            "auditor_fp_violation": 0.014873700454840806,
            "ave_precision_score": 0.7992826249047863,
            "fpr": 0.13596491228070176,
            "logloss": 1.4350514326324884,
            "mae": 0.26375851691257696,
            "precision": 0.7554240631163708,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7744798280166698,
            "auditor_fn_violation": 0.012315487686828127,
            "auditor_fp_violation": 0.023282685308221154,
            "ave_precision_score": 0.7544892687002381,
            "fpr": 0.15148188803512624,
            "logloss": 1.848211500229605,
            "mae": 0.28464020160151704,
            "precision": 0.7299412915851272,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7504701404436919,
            "auditor_fn_violation": 0.026916575292397656,
            "auditor_fp_violation": 0.031310916179337234,
            "ave_precision_score": 0.6257027511961722,
            "fpr": 0.14144736842105263,
            "logloss": 12.119076239042943,
            "mae": 0.3509698841238819,
            "precision": 0.6913875598086124,
            "recall": 0.6020833333333333
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7205778615975063,
            "auditor_fn_violation": 0.009059456154733298,
            "auditor_fp_violation": 0.021865980753917918,
            "ave_precision_score": 0.5929605377533849,
            "fpr": 0.16794731064763996,
            "logloss": 13.237413177707252,
            "mae": 0.3843640229049208,
            "precision": 0.6441860465116279,
            "recall": 0.5843881856540084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7934829579849619,
            "auditor_fn_violation": 0.007830774853801173,
            "auditor_fp_violation": 0.015452404158544522,
            "ave_precision_score": 0.7810511963166097,
            "fpr": 0.15679824561403508,
            "logloss": 1.888794743278769,
            "mae": 0.28196021058678455,
            "precision": 0.7395264116575592,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7789891162451291,
            "auditor_fn_violation": 0.00359877169336798,
            "auditor_fp_violation": 0.009532613091455316,
            "ave_precision_score": 0.7695443431963837,
            "fpr": 0.17672886937431395,
            "logloss": 1.9282206503244295,
            "mae": 0.3029916434797457,
            "precision": 0.7045871559633028,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8113746746808018,
            "auditor_fn_violation": 0.014688413742690061,
            "auditor_fp_violation": 0.01620370370370371,
            "ave_precision_score": 0.7964062108508829,
            "fpr": 0.14912280701754385,
            "logloss": 1.3255233685446695,
            "mae": 0.29059099217719403,
            "precision": 0.7509157509157509,
            "recall": 0.8541666666666666
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7819663031805464,
            "auditor_fn_violation": 0.018257861023496233,
            "auditor_fp_violation": 0.01616399611159814,
            "ave_precision_score": 0.7619640711611357,
            "fpr": 0.16575192096597147,
            "logloss": 1.6602714848705256,
            "mae": 0.2943071869061902,
            "precision": 0.7239488117001828,
            "recall": 0.8354430379746836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7884633763441423,
            "auditor_fn_violation": 0.013377192982456142,
            "auditor_fp_violation": 0.012609649122807017,
            "ave_precision_score": 0.7897476643065428,
            "fpr": 0.11842105263157894,
            "logloss": 1.7950899278671177,
            "mae": 0.312610970789632,
            "precision": 0.7652173913043478,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8421937969784896,
            "auditor_fn_violation": 0.0006808486987452937,
            "auditor_fp_violation": 0.017229036414833195,
            "ave_precision_score": 0.8423827084523691,
            "fpr": 0.10428100987925357,
            "logloss": 1.8545486878423014,
            "mae": 0.3035963872390361,
            "precision": 0.7845804988662132,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7955122783930108,
            "auditor_fn_violation": 0.007383040935672513,
            "auditor_fp_violation": 0.01541179337231969,
            "ave_precision_score": 0.7765388396484946,
            "fpr": 0.18421052631578946,
            "logloss": 2.2059841936112963,
            "mae": 0.29139391108891,
            "precision": 0.7123287671232876,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7724928406312573,
            "auditor_fn_violation": 0.007378176714974506,
            "auditor_fp_violation": 0.01429012803090627,
            "ave_precision_score": 0.7520969069874647,
            "fpr": 0.1964873765093304,
            "logloss": 2.3999529013332297,
            "mae": 0.3144778070566953,
            "precision": 0.6870629370629371,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 6933,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7953302939241691,
            "auditor_fn_violation": 0.008299067982456143,
            "auditor_fp_violation": 0.01622654727095517,
            "ave_precision_score": 0.7762827024070664,
            "fpr": 0.17653508771929824,
            "logloss": 2.0830177809278245,
            "mae": 0.28673029146535967,
            "precision": 0.7195121951219512,
            "recall": 0.8604166666666667
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7718974625550238,
            "auditor_fn_violation": 0.004349094749128095,
            "auditor_fp_violation": 0.012097250236745398,
            "ave_precision_score": 0.751473456708892,
            "fpr": 0.19319429198682767,
            "logloss": 2.292565128062143,
            "mae": 0.30901770099490156,
            "precision": 0.6906854130052724,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.787680426489237,
            "auditor_fn_violation": 0.005215186403508773,
            "auditor_fp_violation": 0.019432261208577,
            "ave_precision_score": 0.7744793019986314,
            "fpr": 0.14473684210526316,
            "logloss": 1.6864134712237335,
            "mae": 0.29255604912107436,
            "precision": 0.7504725897920604,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.775148425745545,
            "auditor_fn_violation": 0.002885501628015769,
            "auditor_fp_violation": 0.006975511608688116,
            "ave_precision_score": 0.7627538214847918,
            "fpr": 0.15367727771679474,
            "logloss": 1.7600487491275685,
            "mae": 0.30282200297799466,
            "precision": 0.726027397260274,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5367272318768126,
            "auditor_fn_violation": 0.007670869883040962,
            "auditor_fp_violation": 0.009827810266406755,
            "ave_precision_score": 0.516901206478313,
            "fpr": 0.12280701754385964,
            "logloss": 8.05490246569109,
            "mae": 0.5013483339563914,
            "precision": 0.5836431226765799,
            "recall": 0.32708333333333334
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.531177184446148,
            "auditor_fn_violation": 0.0070261733060993856,
            "auditor_fp_violation": 0.011833502048444272,
            "ave_precision_score": 0.510189659367916,
            "fpr": 0.12733260153677278,
            "logloss": 7.964000268956502,
            "mae": 0.500163662267155,
            "precision": 0.5703703703703704,
            "recall": 0.32489451476793246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.7952893348293185,
            "auditor_fn_violation": 0.007789656432748541,
            "auditor_fp_violation": 0.01953125,
            "ave_precision_score": 0.7763848176324957,
            "fpr": 0.16337719298245615,
            "logloss": 2.1587509870594745,
            "mae": 0.2849207334922037,
            "precision": 0.7348754448398577,
            "recall": 0.8604166666666667
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.771888017577405,
            "auditor_fn_violation": 0.006695012204328721,
            "auditor_fp_violation": 0.012418771837722019,
            "ave_precision_score": 0.751675861278351,
            "fpr": 0.18880351262349068,
            "logloss": 2.349428377099479,
            "mae": 0.30821492209016393,
            "precision": 0.69009009009009,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.808154400782706,
            "auditor_fn_violation": 0.03566337719298246,
            "auditor_fp_violation": 0.022830876380766738,
            "ave_precision_score": 0.7934921378779666,
            "fpr": 0.12390350877192982,
            "logloss": 2.7796765964845442,
            "mae": 0.28204202500104614,
            "precision": 0.7693877551020408,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7792607255651625,
            "auditor_fn_violation": 0.03134682988508942,
            "auditor_fp_violation": 0.02797489117247374,
            "ave_precision_score": 0.7590815245139464,
            "fpr": 0.14489571899012074,
            "logloss": 2.816337500431437,
            "mae": 0.28813075954674766,
            "precision": 0.7380952380952381,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8038163963262484,
            "auditor_fn_violation": 0.006332236842105265,
            "auditor_fp_violation": 0.007716049382716048,
            "ave_precision_score": 0.7694905456059398,
            "fpr": 0.11403508771929824,
            "logloss": 3.7383264097034035,
            "mae": 0.27607231281544514,
            "precision": 0.7744034707158352,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7648459500302445,
            "auditor_fn_violation": 0.008288290791868725,
            "auditor_fp_violation": 0.013461205153388415,
            "ave_precision_score": 0.7223585664876533,
            "fpr": 0.12843029637760703,
            "logloss": 4.791912759999495,
            "mae": 0.30041062109272865,
            "precision": 0.7445414847161572,
            "recall": 0.7194092827004219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7937450436470881,
            "auditor_fn_violation": 0.013071089181286556,
            "auditor_fp_violation": 0.019104836744639378,
            "ave_precision_score": 0.7805790094529046,
            "fpr": 0.13706140350877194,
            "logloss": 2.374033480029738,
            "mae": 0.27784800564951867,
            "precision": 0.7534516765285996,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7702501694085018,
            "auditor_fn_violation": 0.009680093744065732,
            "auditor_fp_violation": 0.019032571645311438,
            "ave_precision_score": 0.7586638446550916,
            "fpr": 0.14050493962678376,
            "logloss": 2.656740959658925,
            "mae": 0.2978476625726713,
            "precision": 0.7349896480331263,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7984072634359357,
            "auditor_fn_violation": 0.008392726608187136,
            "auditor_fp_violation": 0.014916849415204677,
            "ave_precision_score": 0.7796696424438158,
            "fpr": 0.14144736842105263,
            "logloss": 1.7118619316202777,
            "mae": 0.27377177126427693,
            "precision": 0.7460629921259843,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7692848718586345,
            "auditor_fn_violation": 0.010916737298929636,
            "auditor_fp_violation": 0.02078838101314471,
            "ave_precision_score": 0.7491223109561195,
            "fpr": 0.15367727771679474,
            "logloss": 1.9520076868606826,
            "mae": 0.29148829255487124,
            "precision": 0.7222222222222222,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7927556746384448,
            "auditor_fn_violation": 0.00597587719298246,
            "auditor_fp_violation": 0.016376299545159196,
            "ave_precision_score": 0.7737878773862801,
            "fpr": 0.17982456140350878,
            "logloss": 2.197897195959394,
            "mae": 0.2953749987670098,
            "precision": 0.7152777777777778,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7679707701893261,
            "auditor_fn_violation": 0.0017785435395795423,
            "auditor_fp_violation": 0.01397865397996017,
            "ave_precision_score": 0.747619415782714,
            "fpr": 0.19758507135016465,
            "logloss": 2.3997514685618584,
            "mae": 0.31783535836153015,
            "precision": 0.6842105263157895,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.81823592719804,
            "auditor_fn_violation": 0.01030701754385965,
            "auditor_fp_violation": 0.009868421052631584,
            "ave_precision_score": 0.8189304250147225,
            "fpr": 0.11842105263157894,
            "logloss": 0.5567371144583461,
            "mae": 0.2911944162775686,
            "precision": 0.7804878048780488,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8555461657419886,
            "auditor_fn_violation": 0.014735511122844559,
            "auditor_fp_violation": 0.021476638190235292,
            "ave_precision_score": 0.8558353011881925,
            "fpr": 0.12294182217343579,
            "logloss": 0.5073141464690237,
            "mae": 0.2790266339958244,
            "precision": 0.7700205338809035,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8419502999407764,
            "auditor_fn_violation": 0.02135873538011696,
            "auditor_fp_violation": 0.013609689733593246,
            "ave_precision_score": 0.8424112503969708,
            "fpr": 0.1162280701754386,
            "logloss": 0.5134485312078076,
            "mae": 0.3381669020296581,
            "precision": 0.7749469214437368,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8582909505534766,
            "auditor_fn_violation": 0.02043935583376176,
            "auditor_fp_violation": 0.008929760089624149,
            "ave_precision_score": 0.8585860627490292,
            "fpr": 0.11745334796926454,
            "logloss": 0.48081007962210187,
            "mae": 0.3201052648522385,
            "precision": 0.7793814432989691,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 6933,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7965398280643607,
            "auditor_fn_violation": 0.010190515350877194,
            "auditor_fp_violation": 0.018746954191033137,
            "ave_precision_score": 0.7960729578464811,
            "fpr": 0.14144736842105263,
            "logloss": 1.806189904413471,
            "mae": 0.283358507321872,
            "precision": 0.7470588235294118,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.807594239745292,
            "auditor_fn_violation": 0.0056343703539023715,
            "auditor_fp_violation": 0.010070157018088105,
            "ave_precision_score": 0.8079335130290899,
            "fpr": 0.14270032930845225,
            "logloss": 2.052010889454558,
            "mae": 0.2991984675847919,
            "precision": 0.7297297297297297,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7893306254303138,
            "auditor_fn_violation": 0.010005482456140352,
            "auditor_fp_violation": 0.010434433885640032,
            "ave_precision_score": 0.7906028994120656,
            "fpr": 0.10416666666666667,
            "logloss": 1.7935941831282654,
            "mae": 0.3154492716482644,
            "precision": 0.7865168539325843,
            "recall": 0.7291666666666666
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8363222567646542,
            "auditor_fn_violation": 0.00827902754426675,
            "auditor_fp_violation": 0.014739755894772012,
            "ave_precision_score": 0.8365286205353137,
            "fpr": 0.09440175631174534,
            "logloss": 1.8602666923747146,
            "mae": 0.30736256334020806,
            "precision": 0.7985948477751756,
            "recall": 0.7194092827004219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7882019243779144,
            "auditor_fn_violation": 0.00622715643274854,
            "auditor_fp_violation": 0.005754040773229367,
            "ave_precision_score": 0.7718417373979003,
            "fpr": 0.16557017543859648,
            "logloss": 2.519982258166765,
            "mae": 0.31768283182642776,
            "precision": 0.7249544626593807,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7686915513331727,
            "auditor_fn_violation": 0.00708175279171125,
            "auditor_fp_violation": 0.009758682967142007,
            "ave_precision_score": 0.7510415828751784,
            "fpr": 0.1690450054884742,
            "logloss": 2.80715755794419,
            "mae": 0.3244033359429698,
            "precision": 0.7142857142857143,
            "recall": 0.8122362869198312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8241239300057817,
            "auditor_fn_violation": 0.010238486842105262,
            "auditor_fp_violation": 0.012731481481481479,
            "ave_precision_score": 0.7935386428127714,
            "fpr": 0.10964912280701754,
            "logloss": 2.8817546106039207,
            "mae": 0.2575184841430864,
            "precision": 0.791231732776618,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7759713907842861,
            "auditor_fn_violation": 0.006877961344467761,
            "auditor_fp_violation": 0.01465686360702023,
            "ave_precision_score": 0.7325209547179166,
            "fpr": 0.13721185510428102,
            "logloss": 4.023217660976408,
            "mae": 0.28372410880791843,
            "precision": 0.7443762781186094,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7868777199992575,
            "auditor_fn_violation": 0.011517726608187132,
            "auditor_fp_violation": 0.013711216699155298,
            "ave_precision_score": 0.7549036859476986,
            "fpr": 0.1425438596491228,
            "logloss": 4.075479156770989,
            "mae": 0.28229462001420896,
            "precision": 0.738430583501006,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7586633206922933,
            "auditor_fn_violation": 0.004779835762620023,
            "auditor_fp_violation": 0.012953803876847182,
            "ave_precision_score": 0.7210694379396564,
            "fpr": 0.14818880351262348,
            "logloss": 4.931510012215074,
            "mae": 0.3068335637387435,
            "precision": 0.7181628392484343,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.805668494425572,
            "auditor_fn_violation": 0.017786001461988308,
            "auditor_fp_violation": 0.01933581059129305,
            "ave_precision_score": 0.77225623782438,
            "fpr": 0.1206140350877193,
            "logloss": 3.850804574464836,
            "mae": 0.26960613174221626,
            "precision": 0.7713097713097713,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7668551658033365,
            "auditor_fn_violation": 0.0075032305576011905,
            "auditor_fp_violation": 0.018060471179858692,
            "ave_precision_score": 0.7247714673226341,
            "fpr": 0.13611416026344675,
            "logloss": 4.8973851943733075,
            "mae": 0.2987808525795317,
            "precision": 0.7339055793991416,
            "recall": 0.7215189873417721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.786385845611639,
            "auditor_fn_violation": 0.014528508771929828,
            "auditor_fp_violation": 0.017262122319688114,
            "ave_precision_score": 0.787686347450951,
            "fpr": 0.13267543859649122,
            "logloss": 1.800699904678403,
            "mae": 0.31393978210179374,
            "precision": 0.7484407484407485,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8404101106999272,
            "auditor_fn_violation": 0.011058001824859783,
            "auditor_fp_violation": 0.014081641367772988,
            "ave_precision_score": 0.840605533034481,
            "fpr": 0.1141602634467618,
            "logloss": 1.8595461408734508,
            "mae": 0.306786445252399,
            "precision": 0.775377969762419,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7927624758884305,
            "auditor_fn_violation": 0.009923245614035089,
            "auditor_fp_violation": 0.011251725958414562,
            "ave_precision_score": 0.7734670061568285,
            "fpr": 0.14364035087719298,
            "logloss": 1.7060143927958642,
            "mae": 0.2727829034653173,
            "precision": 0.746615087040619,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.770267283276834,
            "auditor_fn_violation": 0.011039475329655834,
            "auditor_fp_violation": 0.019391771558902506,
            "ave_precision_score": 0.7488421492487591,
            "fpr": 0.15697036223929747,
            "logloss": 1.9553655692438068,
            "mae": 0.28757815041951545,
            "precision": 0.720703125,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8862291064630766,
            "auditor_fn_violation": 0.011972313596491233,
            "auditor_fp_violation": 0.010660331384015597,
            "ave_precision_score": 0.8864218718999877,
            "fpr": 0.06578947368421052,
            "logloss": 0.46044157641100614,
            "mae": 0.29334099655470547,
            "precision": 0.8511166253101737,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8727807185032973,
            "auditor_fn_violation": 0.01351507825128412,
            "auditor_fp_violation": 0.00977877806720304,
            "ave_precision_score": 0.8734665887500837,
            "fpr": 0.0801317233809001,
            "logloss": 0.4626584312490594,
            "mae": 0.29107716497014413,
            "precision": 0.8270142180094787,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6684411742191715,
            "auditor_fn_violation": 0.01685855263157895,
            "auditor_fp_violation": 0.024417235217673826,
            "ave_precision_score": 0.6590942218861802,
            "fpr": 0.16228070175438597,
            "logloss": 2.917049483268524,
            "mae": 0.3162246224807026,
            "precision": 0.7069306930693069,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6595421053265522,
            "auditor_fn_violation": 0.013552131241692028,
            "auditor_fp_violation": 0.03414408689121267,
            "ave_precision_score": 0.6504335869221006,
            "fpr": 0.17672886937431395,
            "logloss": 3.170808344216477,
            "mae": 0.3409757317481212,
            "precision": 0.6747474747474748,
            "recall": 0.7046413502109705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8726068461073191,
            "auditor_fn_violation": 0.012175621345029235,
            "auditor_fp_violation": 0.011096897335932427,
            "ave_precision_score": 0.8729673176287471,
            "fpr": 0.09100877192982457,
            "logloss": 0.47207568076393713,
            "mae": 0.2912637510499304,
            "precision": 0.8167770419426048,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.869916942953219,
            "auditor_fn_violation": 0.011157581736581025,
            "auditor_fp_violation": 0.008791606276704503,
            "ave_precision_score": 0.8704388858912695,
            "fpr": 0.10318331503841932,
            "logloss": 0.4638394055797929,
            "mae": 0.28467878104894473,
            "precision": 0.7995735607675906,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8675575267545237,
            "auditor_fn_violation": 0.01453764619883041,
            "auditor_fp_violation": 0.013454861111111114,
            "ave_precision_score": 0.8679755768880515,
            "fpr": 0.09539473684210527,
            "logloss": 0.48100898515848,
            "mae": 0.2857532815037861,
            "precision": 0.8062360801781737,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8647670041940037,
            "auditor_fn_violation": 0.01840607298512786,
            "auditor_fp_violation": 0.012340903324985495,
            "ave_precision_score": 0.865176574796653,
            "fpr": 0.10208562019758508,
            "logloss": 0.4786882781581087,
            "mae": 0.2784743558866039,
            "precision": 0.8008565310492506,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8791835571877245,
            "auditor_fn_violation": 0.005007309941520469,
            "auditor_fp_violation": 0.018777412280701757,
            "ave_precision_score": 0.8793673333975409,
            "fpr": 0.14802631578947367,
            "logloss": 0.49401857670814103,
            "mae": 0.26958132938894425,
            "precision": 0.7563176895306859,
            "recall": 0.8729166666666667
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8539844373434424,
            "auditor_fn_violation": 0.007614389528824914,
            "auditor_fp_violation": 0.019344045696257545,
            "ave_precision_score": 0.8546890294842612,
            "fpr": 0.16136114160263446,
            "logloss": 0.5522844672472955,
            "mae": 0.2855608360021468,
            "precision": 0.7351351351351352,
            "recall": 0.8607594936708861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8203114147986889,
            "auditor_fn_violation": 0.023341557017543865,
            "auditor_fp_violation": 0.016335688758934375,
            "ave_precision_score": 0.820923551732589,
            "fpr": 0.1074561403508772,
            "logloss": 0.5375966650866187,
            "mae": 0.3018199800287237,
            "precision": 0.7954070981210856,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8651903917220897,
            "auditor_fn_violation": 0.012598016738688421,
            "auditor_fp_violation": 0.004677134539206794,
            "ave_precision_score": 0.8654814944653408,
            "fpr": 0.1251372118551043,
            "logloss": 0.4767265532965676,
            "mae": 0.28579803594537195,
            "precision": 0.7673469387755102,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7807017543859649,
            "auc_prc": 0.8233941428718335,
            "auditor_fn_violation": 0.007915296052631582,
            "auditor_fp_violation": 0.007741431124106566,
            "ave_precision_score": 0.792811060457322,
            "fpr": 0.10416666666666667,
            "logloss": 2.8623977084190844,
            "mae": 0.2599493146943377,
            "precision": 0.7978723404255319,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7748893208923372,
            "auditor_fn_violation": 0.006461115202378802,
            "auditor_fp_violation": 0.012782995526328353,
            "ave_precision_score": 0.7314375931016797,
            "fpr": 0.13062568605927552,
            "logloss": 3.9951661570836765,
            "mae": 0.28611625087246456,
            "precision": 0.7515657620041754,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 6933,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8827681089034238,
            "auditor_fn_violation": 0.007942708333333333,
            "auditor_fp_violation": 0.011127355425601036,
            "ave_precision_score": 0.8829849422235387,
            "fpr": 0.09758771929824561,
            "logloss": 0.45346531482704727,
            "mae": 0.2717659998191888,
            "precision": 0.8106382978723404,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8745904169567218,
            "auditor_fn_violation": 0.009703251863070673,
            "auditor_fp_violation": 0.004486231088626926,
            "ave_precision_score": 0.8750926290427252,
            "fpr": 0.10428100987925357,
            "logloss": 0.4604106924689474,
            "mae": 0.2704815653424442,
            "precision": 0.8,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7935287257636219,
            "auditor_fn_violation": 0.007490405701754385,
            "auditor_fp_violation": 0.016614887914230027,
            "ave_precision_score": 0.774649623643528,
            "fpr": 0.19407894736842105,
            "logloss": 2.0781532101478457,
            "mae": 0.29997467767030367,
            "precision": 0.7030201342281879,
            "recall": 0.8729166666666667
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7753447506593821,
            "auditor_fn_violation": 0.003404243493726469,
            "auditor_fp_violation": 0.007535662522889575,
            "ave_precision_score": 0.7550233575546178,
            "fpr": 0.2030735455543359,
            "logloss": 2.2464735506096303,
            "mae": 0.31866407355085524,
            "precision": 0.6815834767641996,
            "recall": 0.8354430379746836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7508214507986604,
            "auditor_fn_violation": 0.019476425438596488,
            "auditor_fp_violation": 0.017300194931773878,
            "ave_precision_score": 0.6214186127570582,
            "fpr": 0.16337719298245615,
            "logloss": 12.169445512107915,
            "mae": 0.3542227253793706,
            "precision": 0.6725274725274726,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.734605846723241,
            "auditor_fn_violation": 0.012338645805833062,
            "auditor_fp_violation": 0.010494666006877557,
            "ave_precision_score": 0.5988078357008519,
            "fpr": 0.18551042810098792,
            "logloss": 12.852981258903492,
            "mae": 0.37239292480151703,
            "precision": 0.642706131078224,
            "recall": 0.6413502109704642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8058390916367915,
            "auditor_fn_violation": 0.01798245614035088,
            "auditor_fp_violation": 0.01869619070825211,
            "ave_precision_score": 0.7724269124103694,
            "fpr": 0.11732456140350878,
            "logloss": 3.8512822210585806,
            "mae": 0.2681980636105123,
            "precision": 0.7747368421052632,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7680280655208267,
            "auditor_fn_violation": 0.009360511701797532,
            "auditor_fp_violation": 0.019346557583765172,
            "ave_precision_score": 0.7258864775032026,
            "fpr": 0.12952799121844127,
            "logloss": 4.895415757547738,
            "mae": 0.2973338913711956,
            "precision": 0.7412280701754386,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7876468412205435,
            "auditor_fn_violation": 0.006601790935672514,
            "auditor_fp_violation": 0.01861243096166342,
            "ave_precision_score": 0.767753503352155,
            "fpr": 0.18530701754385964,
            "logloss": 2.761831228609992,
            "mae": 0.3036201371793863,
            "precision": 0.7076124567474048,
            "recall": 0.8520833333333333
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7661014501818448,
            "auditor_fn_violation": 0.004279620392113275,
            "auditor_fp_violation": 0.013752584104273484,
            "ave_precision_score": 0.7462606379653804,
            "fpr": 0.18660812294182216,
            "logloss": 3.0536910321128192,
            "mae": 0.3163474558530619,
            "precision": 0.6953405017921147,
            "recall": 0.8185654008438819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.796713120125478,
            "auditor_fn_violation": 0.008168859649122819,
            "auditor_fp_violation": 0.0159067373294347,
            "ave_precision_score": 0.7638785859901901,
            "fpr": 0.11293859649122807,
            "logloss": 3.8654731908158104,
            "mae": 0.28701878474479686,
            "precision": 0.7680180180180181,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7612533513775788,
            "auditor_fn_violation": 0.005094786181087229,
            "auditor_fp_violation": 0.011944025098779981,
            "ave_precision_score": 0.7205503515338308,
            "fpr": 0.11964873765093303,
            "logloss": 4.880071135480316,
            "mae": 0.30682856867416736,
            "precision": 0.7488479262672811,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.7943247459625028,
            "auditor_fn_violation": 0.007264254385964916,
            "auditor_fp_violation": 0.01626461988304094,
            "ave_precision_score": 0.7754978060756863,
            "fpr": 0.16885964912280702,
            "logloss": 2.1317713500986244,
            "mae": 0.28142258388687996,
            "precision": 0.7288732394366197,
            "recall": 0.8625
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7701025693262944,
            "auditor_fn_violation": 0.008059025413719799,
            "auditor_fp_violation": 0.011622503497803359,
            "ave_precision_score": 0.7498818370585161,
            "fpr": 0.19099890230515917,
            "logloss": 2.3296788755513154,
            "mae": 0.30829165953887816,
            "precision": 0.6892857142857143,
            "recall": 0.8143459915611815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7033078581274821,
            "auditor_fn_violation": 0.004191794590643274,
            "auditor_fp_violation": 0.011015675763482792,
            "ave_precision_score": 0.6217225972914353,
            "fpr": 0.3399122807017544,
            "logloss": 5.740950504283735,
            "mae": 0.3601705942553625,
            "precision": 0.5947712418300654,
            "recall": 0.9479166666666666
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.6898349945725977,
            "auditor_fn_violation": 0.003165714867975564,
            "auditor_fp_violation": 0.0247646989377228,
            "ave_precision_score": 0.6054172121995514,
            "fpr": 0.3391877058177827,
            "logloss": 6.034080251606947,
            "mae": 0.3637242909431373,
            "precision": 0.5987012987012987,
            "recall": 0.9725738396624473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7994590147515295,
            "auditor_fn_violation": 0.005859374999999999,
            "auditor_fp_violation": 0.013076673164392464,
            "ave_precision_score": 0.7660522411691814,
            "fpr": 0.11403508771929824,
            "logloss": 3.8933926979609503,
            "mae": 0.2836973278384579,
            "precision": 0.7683741648106904,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7632364774933778,
            "auditor_fn_violation": 0.005784898127434501,
            "auditor_fp_violation": 0.010896568008098328,
            "ave_precision_score": 0.7219241331275085,
            "fpr": 0.12184412733260154,
            "logloss": 4.907810141661027,
            "mae": 0.30482420275113037,
            "precision": 0.7454128440366973,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.814255377740586,
            "auditor_fn_violation": 0.00831048976608187,
            "auditor_fp_violation": 0.015091983430799222,
            "ave_precision_score": 0.7981984179781934,
            "fpr": 0.16885964912280702,
            "logloss": 1.4473875378351364,
            "mae": 0.2841214051542537,
            "precision": 0.7349397590361446,
            "recall": 0.8895833333333333
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7821495949600183,
            "auditor_fn_violation": 0.012435909905653825,
            "auditor_fp_violation": 0.010635331707304827,
            "ave_precision_score": 0.7601556861488925,
            "fpr": 0.19319429198682767,
            "logloss": 1.8141079249672631,
            "mae": 0.29777704495084284,
            "precision": 0.696551724137931,
            "recall": 0.8523206751054853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7501131079411035,
            "auditor_fn_violation": 0.03130482456140351,
            "auditor_fp_violation": 0.0264782326185835,
            "ave_precision_score": 0.7514642415851546,
            "fpr": 0.16228070175438597,
            "logloss": 1.921850495426205,
            "mae": 0.35045069280917024,
            "precision": 0.7045908183632734,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8169192659835087,
            "auditor_fn_violation": 0.021245258375133743,
            "auditor_fp_violation": 0.026294438429869362,
            "ave_precision_score": 0.8172026246318165,
            "fpr": 0.14489571899012074,
            "logloss": 1.93649329401957,
            "mae": 0.3347181273751007,
            "precision": 0.7306122448979592,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7849366087842496,
            "auditor_fn_violation": 0.045355902777777776,
            "auditor_fp_violation": 0.015282346491228073,
            "ave_precision_score": 0.7822841749752387,
            "fpr": 0.0800438596491228,
            "logloss": 2.285562748824784,
            "mae": 0.34433313230985857,
            "precision": 0.7983425414364641,
            "recall": 0.6020833333333333
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7675253641681832,
            "auditor_fn_violation": 0.049424057580347104,
            "auditor_fp_violation": 0.027256491345291595,
            "ave_precision_score": 0.7657357323552743,
            "fpr": 0.09549945115257959,
            "logloss": 1.9590493014831705,
            "mae": 0.3439960940307403,
            "precision": 0.7740259740259741,
            "recall": 0.6286919831223629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7816611456287647,
            "auditor_fn_violation": 0.007616045321637426,
            "auditor_fp_violation": 0.016647884178037687,
            "ave_precision_score": 0.7631328108765288,
            "fpr": 0.15679824561403508,
            "logloss": 2.7304154494798425,
            "mae": 0.2836642286332218,
            "precision": 0.723404255319149,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7622546965548248,
            "auditor_fn_violation": 0.007600494657421953,
            "auditor_fp_violation": 0.018592991331476214,
            "ave_precision_score": 0.7443627805032086,
            "fpr": 0.15367727771679474,
            "logloss": 3.0327786490450976,
            "mae": 0.30463978072635955,
            "precision": 0.7142857142857143,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8062845217636556,
            "auditor_fn_violation": 0.014032803362573098,
            "auditor_fp_violation": 0.01611232943469786,
            "ave_precision_score": 0.7728718557328175,
            "fpr": 0.11513157894736842,
            "logloss": 3.8339723453739913,
            "mae": 0.26783574456788894,
            "precision": 0.777542372881356,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7678188741032367,
            "auditor_fn_violation": 0.011393794550431439,
            "auditor_fp_violation": 0.018967262570113063,
            "ave_precision_score": 0.7264113855642792,
            "fpr": 0.13062568605927552,
            "logloss": 4.861085480265846,
            "mae": 0.29753859936768634,
            "precision": 0.7396061269146609,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6348604747323272,
            "auditor_fn_violation": 0.014409722222222225,
            "auditor_fp_violation": 0.009061281676413258,
            "ave_precision_score": 0.6362070308836988,
            "fpr": 0.125,
            "logloss": 1.20582275922203,
            "mae": 0.3868686322754289,
            "precision": 0.7233009708737864,
            "recall": 0.6208333333333333
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6880999966194703,
            "auditor_fn_violation": 0.011018633022551376,
            "auditor_fp_violation": 0.008784070614181613,
            "ave_precision_score": 0.6892048336680023,
            "fpr": 0.1163556531284303,
            "logloss": 0.925255039278102,
            "mae": 0.36226716840184015,
            "precision": 0.7427184466019418,
            "recall": 0.6455696202531646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8040266213253946,
            "auditor_fn_violation": 0.007325932017543857,
            "auditor_fp_violation": 0.010152696556205328,
            "ave_precision_score": 0.7687365233552468,
            "fpr": 0.10416666666666667,
            "logloss": 3.8133729351635175,
            "mae": 0.2744596100473498,
            "precision": 0.7869955156950673,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7625365746548498,
            "auditor_fn_violation": 0.008302185663271688,
            "auditor_fp_violation": 0.013182385640041499,
            "ave_precision_score": 0.7182813502217235,
            "fpr": 0.12403951701427003,
            "logloss": 4.954285924853652,
            "mae": 0.30291052270375174,
            "precision": 0.7466367713004485,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7833749756422757,
            "auditor_fn_violation": 0.012301260964912287,
            "auditor_fp_violation": 0.016317921539961013,
            "ave_precision_score": 0.7846438578900696,
            "fpr": 0.11513157894736842,
            "logloss": 1.8052881742171243,
            "mae": 0.35410611061869485,
            "precision": 0.7666666666666667,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8364385059425448,
            "auditor_fn_violation": 0.016166682877349972,
            "auditor_fp_violation": 0.006342515956765392,
            "ave_precision_score": 0.8367137910472743,
            "fpr": 0.10757409440175632,
            "logloss": 1.8507497737314031,
            "mae": 0.3368074406920697,
            "precision": 0.7787810383747178,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7887547850048382,
            "auditor_fn_violation": 0.014400584795321636,
            "auditor_fp_violation": 0.015746832358674464,
            "ave_precision_score": 0.7910801335758385,
            "fpr": 0.125,
            "logloss": 0.8956078473394598,
            "mae": 0.3009680994318937,
            "precision": 0.7521739130434782,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7567598148475341,
            "auditor_fn_violation": 0.017632591810362794,
            "auditor_fp_violation": 0.013403431740712925,
            "ave_precision_score": 0.7574128007990772,
            "fpr": 0.13391877058177826,
            "logloss": 1.028033763580759,
            "mae": 0.31885802565184107,
            "precision": 0.7336244541484717,
            "recall": 0.7088607594936709
        }
    }
]