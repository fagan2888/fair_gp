[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7971905392067993,
            "auditor_fn_violation": 0.005248321649790439,
            "auditor_fp_violation": 0.004992906525996084,
            "ave_precision_score": 0.7696989350824505,
            "fpr": 0.04824561403508772,
            "logloss": 0.6095930869648416,
            "mae": 0.3610952278566465,
            "precision": 0.8528428093645485,
            "recall": 0.5391120507399577
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7944108847372137,
            "auditor_fn_violation": 0.006524552078887974,
            "auditor_fp_violation": 0.004743062823883796,
            "ave_precision_score": 0.7705010550530887,
            "fpr": 0.04171240395170143,
            "logloss": 0.6184875749189503,
            "mae": 0.36705328781734314,
            "precision": 0.8703071672354948,
            "recall": 0.5301455301455301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5663120129329793,
            "auditor_fn_violation": 0.010607915136678922,
            "auditor_fp_violation": 0.009064160971905856,
            "ave_precision_score": 0.567761793341751,
            "fpr": 0.17543859649122806,
            "logloss": 0.7218612251539223,
            "mae": 0.48537633961639487,
            "precision": 0.5389048991354467,
            "recall": 0.3953488372093023
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5891619142279535,
            "auditor_fn_violation": 0.00414887571857934,
            "auditor_fp_violation": 0.009869042452709776,
            "ave_precision_score": 0.5905740312047638,
            "fpr": 0.15806805708013172,
            "logloss": 0.7126605843053948,
            "mae": 0.4807495457579256,
            "precision": 0.5897435897435898,
            "recall": 0.4303534303534304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5435442817640956,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5341063804406704,
            "fpr": 0.05701754385964912,
            "logloss": 0.6944579909806959,
            "mae": 0.49969654468198615,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5448816845173157,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.005064712940035231,
            "ave_precision_score": 0.5395466175068009,
            "fpr": 0.05378704720087816,
            "logloss": 0.6950663212138666,
            "mae": 0.4998968308535941,
            "precision": 0.5545454545454546,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.768361385721224,
            "auditor_fn_violation": 0.0001367716330996565,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6657574885228335,
            "fpr": 0.017543859649122806,
            "logloss": 0.809707838430909,
            "mae": 0.43178033916729064,
            "precision": 0.9106145251396648,
            "recall": 0.34460887949260044
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7915119066313755,
            "auditor_fn_violation": 0.009384035728711911,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.6840688637518721,
            "fpr": 0.013172338090010977,
            "logloss": 0.723862392017172,
            "mae": 0.42912364768779315,
            "precision": 0.9329608938547486,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7424393911277839,
            "auditor_fn_violation": 0.0082874337005304,
            "auditor_fp_violation": 0.03716330975502539,
            "ave_precision_score": 0.7442354246897793,
            "fpr": 0.23026315789473684,
            "logloss": 0.8911022268130446,
            "mae": 0.3229312801324675,
            "precision": 0.6574225122349103,
            "recall": 0.8520084566596194
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7600376535492881,
            "auditor_fn_violation": 0.012823175282011729,
            "auditor_fp_violation": 0.026063870523064362,
            "ave_precision_score": 0.7609129099263554,
            "fpr": 0.2239297475301866,
            "logloss": 0.8660831758311717,
            "mae": 0.31276147260340154,
            "precision": 0.6736,
            "recall": 0.8752598752598753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7697408915714954,
            "auditor_fn_violation": 0.008472886762360458,
            "auditor_fp_violation": 0.005205211205690764,
            "ave_precision_score": 0.6600810423719853,
            "fpr": 0.01644736842105263,
            "logloss": 1.7959330674078964,
            "mae": 0.4324598572252367,
            "precision": 0.9137931034482759,
            "recall": 0.3361522198731501
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7891247986343444,
            "auditor_fn_violation": 0.005472499435177823,
            "auditor_fp_violation": 0.0022209174686646416,
            "ave_precision_score": 0.6730875443129011,
            "fpr": 0.010976948408342482,
            "logloss": 1.6399913841187443,
            "mae": 0.4280021646371916,
            "precision": 0.9428571428571428,
            "recall": 0.34303534303534305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.651854302457668,
            "auditor_fn_violation": 0.012511127183709801,
            "auditor_fp_violation": 0.04087239739439716,
            "ave_precision_score": 0.653617960980204,
            "fpr": 0.2138157894736842,
            "logloss": 1.0905600236933424,
            "mae": 0.34555432074943093,
            "precision": 0.6578947368421053,
            "recall": 0.7928118393234672
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6863864607485048,
            "auditor_fn_violation": 0.01442749851092332,
            "auditor_fp_violation": 0.026684195747070687,
            "ave_precision_score": 0.6876539131163747,
            "fpr": 0.21844127332601537,
            "logloss": 1.0082347627859791,
            "mae": 0.3362451455501241,
            "precision": 0.6644182124789207,
            "recall": 0.8191268191268192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.768433070556571,
            "auditor_fn_violation": 0.00427932940172843,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6598289228634691,
            "fpr": 0.017543859649122806,
            "logloss": 1.830290772630406,
            "mae": 0.43184849113008833,
            "precision": 0.9096045197740112,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7851864571689287,
            "auditor_fn_violation": 0.004002820687782273,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.6715019840502802,
            "fpr": 0.013172338090010977,
            "logloss": 1.6885499525686474,
            "mae": 0.42802729110907006,
            "precision": 0.9329608938547486,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5435389597965752,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5341010992291862,
            "fpr": 0.05701754385964912,
            "logloss": 0.6943649787826043,
            "mae": 0.499734594012823,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5428943281838593,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.002476195338626095,
            "ave_precision_score": 0.5377033250794846,
            "fpr": 0.054884742041712405,
            "logloss": 0.6955727391304446,
            "mae": 0.500328676662644,
            "precision": 0.5495495495495496,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7863029927915,
            "auditor_fn_violation": 0.009316698193687188,
            "auditor_fp_violation": 0.0032395196419294247,
            "ave_precision_score": 0.7318593543920325,
            "fpr": 0.09210526315789473,
            "logloss": 0.7396706800061668,
            "mae": 0.40950839531670613,
            "precision": 0.7717391304347826,
            "recall": 0.6004228329809725
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.802205070018218,
            "auditor_fn_violation": 0.01250367990214314,
            "auditor_fp_violation": 0.005319990809996679,
            "ave_precision_score": 0.7440477539947394,
            "fpr": 0.0867178924259056,
            "logloss": 0.6646742236600192,
            "mae": 0.40792414908387703,
            "precision": 0.7787114845938375,
            "recall": 0.577962577962578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.5663120129329793,
            "auditor_fn_violation": 0.010607915136678922,
            "auditor_fp_violation": 0.009064160971905856,
            "ave_precision_score": 0.567761793341751,
            "fpr": 0.17543859649122806,
            "logloss": 0.7218612432164705,
            "mae": 0.4853763410244842,
            "precision": 0.5389048991354467,
            "recall": 0.3953488372093023
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.5891619142279535,
            "auditor_fn_violation": 0.00414887571857934,
            "auditor_fp_violation": 0.009869042452709776,
            "ave_precision_score": 0.5905740312047638,
            "fpr": 0.15806805708013172,
            "logloss": 0.7126605998256011,
            "mae": 0.4807495453599922,
            "precision": 0.5897435897435898,
            "recall": 0.4303534303534304
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7632981382184996,
            "auditor_fn_violation": 0.005456956344349258,
            "auditor_fp_violation": 0.006186808136514408,
            "ave_precision_score": 0.760143559239431,
            "fpr": 0.027412280701754384,
            "logloss": 0.5991292968444081,
            "mae": 0.4049156416093179,
            "precision": 0.8931623931623932,
            "recall": 0.4418604651162791
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7907162440908985,
            "auditor_fn_violation": 0.005657350333530358,
            "auditor_fp_violation": 0.0042988793301508696,
            "ave_precision_score": 0.7869220510039303,
            "fpr": 0.019758507135016465,
            "logloss": 0.5803856936421606,
            "mae": 0.39981793322724124,
            "precision": 0.918918918918919,
            "recall": 0.42411642411642414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5433832546516111,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5340208953325324,
            "fpr": 0.05701754385964912,
            "logloss": 0.6938690264295395,
            "mae": 0.4995933030977061,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5453359225120727,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.005064712940035231,
            "ave_precision_score": 0.5394269318253585,
            "fpr": 0.05378704720087816,
            "logloss": 0.6942684125566151,
            "mae": 0.4996438601292449,
            "precision": 0.5545454545454546,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7589185093904893,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016260040762498484,
            "ave_precision_score": 0.5198684814329588,
            "fpr": 0.4780701754385965,
            "logloss": 16.48439017337178,
            "mae": 0.47808710923060027,
            "precision": 0.5203520352035204,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.764390509281971,
            "auditor_fn_violation": 0.0005454242556328177,
            "auditor_fp_violation": 0.0009751614632527716,
            "ave_precision_score": 0.5317034632761296,
            "fpr": 0.4632272228320527,
            "logloss": 15.978789951189528,
            "mae": 0.4644607575135443,
            "precision": 0.532150776053215,
            "recall": 0.997920997920998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7698213174520998,
            "auditor_fn_violation": 0.003975650012981728,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6618622862243799,
            "fpr": 0.017543859649122806,
            "logloss": 1.7417523997506432,
            "mae": 0.43024201576878246,
            "precision": 0.9090909090909091,
            "recall": 0.3382663847780127
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.786334128993502,
            "auditor_fn_violation": 0.005260263218550813,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.6732821872710676,
            "fpr": 0.013172338090010977,
            "logloss": 1.599898346601865,
            "mae": 0.42652397051030233,
            "precision": 0.9325842696629213,
            "recall": 0.34511434511434513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7059291178884383,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.5493926742360856,
            "fpr": 0.2982456140350877,
            "logloss": 0.6888374733329822,
            "mae": 0.49360613949727594,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7184785740032478,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.09105506343655069,
            "ave_precision_score": 0.5679495591407105,
            "fpr": 0.2843029637760702,
            "logloss": 0.684537338990692,
            "mae": 0.49144399004173595,
            "precision": 0.5683333333333334,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7209481278119984,
            "auditor_fn_violation": 0.012958532695374805,
            "auditor_fp_violation": 0.034940354873516384,
            "ave_precision_score": 0.7227782904189796,
            "fpr": 0.22697368421052633,
            "logloss": 0.866285885870954,
            "mae": 0.3388195505520208,
            "precision": 0.6515151515151515,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7462902265813365,
            "auditor_fn_violation": 0.012232108829254825,
            "auditor_fp_violation": 0.022515508130600163,
            "ave_precision_score": 0.7470774482640723,
            "fpr": 0.22063666300768386,
            "logloss": 0.831965598266801,
            "mae": 0.32580283022326323,
            "precision": 0.6715686274509803,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8380733689597467,
            "auditor_fn_violation": 0.009223971662772154,
            "auditor_fp_violation": 0.01972185589257883,
            "ave_precision_score": 0.8378459125745635,
            "fpr": 0.09320175438596491,
            "logloss": 0.5393444129054661,
            "mae": 0.3113823941290448,
            "precision": 0.7946859903381642,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8556217056753781,
            "auditor_fn_violation": 0.012519654671136572,
            "auditor_fp_violation": 0.014487019120312465,
            "ave_precision_score": 0.8548557088670959,
            "fpr": 0.0801317233809001,
            "logloss": 0.5221680826289017,
            "mae": 0.30395274778340386,
            "precision": 0.8165829145728644,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6194739381387975,
            "auditor_fn_violation": 0.008516931864545092,
            "auditor_fp_violation": 0.019219817767653764,
            "ave_precision_score": 0.5959795698675949,
            "fpr": 0.15021929824561403,
            "logloss": 0.7967602276777024,
            "mae": 0.4550676344354686,
            "precision": 0.6162464985994398,
            "recall": 0.46511627906976744
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6084394453626072,
            "auditor_fn_violation": 0.00565278611381795,
            "auditor_fp_violation": 0.017124039517014272,
            "ave_precision_score": 0.5944766551984795,
            "fpr": 0.15806805708013172,
            "logloss": 0.8124785928686942,
            "mae": 0.46370890159180345,
            "precision": 0.5966386554621849,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7332400268477127,
            "auditor_fn_violation": 0.012119357590593825,
            "auditor_fp_violation": 0.036916037245733925,
            "ave_precision_score": 0.7350551629789361,
            "fpr": 0.2225877192982456,
            "logloss": 0.8590893061886264,
            "mae": 0.32561366563791844,
            "precision": 0.6661184210526315,
            "recall": 0.8562367864693446
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7513325254309721,
            "auditor_fn_violation": 0.013964230210113854,
            "auditor_fp_violation": 0.02774615168611034,
            "ave_precision_score": 0.7521840118328739,
            "fpr": 0.22722283205268934,
            "logloss": 0.8286058535199093,
            "mae": 0.31797321284146435,
            "precision": 0.670906200317965,
            "recall": 0.8773388773388774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 6654,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8421048476695696,
            "auditor_fn_violation": 0.008076480842698715,
            "auditor_fp_violation": 0.02079586780162251,
            "ave_precision_score": 0.8428181181121409,
            "fpr": 0.09210526315789473,
            "logloss": 0.5368798171178347,
            "mae": 0.3098183732228088,
            "precision": 0.7966101694915254,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8576548282499965,
            "auditor_fn_violation": 0.010324264989468061,
            "auditor_fp_violation": 0.01208485436397519,
            "ave_precision_score": 0.8578932432535509,
            "fpr": 0.07903402854006586,
            "logloss": 0.5215565871620634,
            "mae": 0.3029187728799614,
            "precision": 0.818639798488665,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8380200944917292,
            "auditor_fn_violation": 0.009223971662772154,
            "auditor_fp_violation": 0.01972185589257883,
            "ave_precision_score": 0.8377927319365792,
            "fpr": 0.09320175438596491,
            "logloss": 0.5393853839865003,
            "mae": 0.3113325628551058,
            "precision": 0.7946859903381642,
            "recall": 0.6955602536997886
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8557448164376216,
            "auditor_fn_violation": 0.012519654671136572,
            "auditor_fp_violation": 0.014487019120312465,
            "ave_precision_score": 0.8549755390254032,
            "fpr": 0.0801317233809001,
            "logloss": 0.5221651107902847,
            "mae": 0.303896949090816,
            "precision": 0.8165829145728644,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6194739381387975,
            "auditor_fn_violation": 0.008516931864545092,
            "auditor_fp_violation": 0.019219817767653764,
            "ave_precision_score": 0.5959795698675949,
            "fpr": 0.15021929824561403,
            "logloss": 0.796760229707878,
            "mae": 0.4550676347785874,
            "precision": 0.6162464985994398,
            "recall": 0.46511627906976744
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6084394453626072,
            "auditor_fn_violation": 0.00565278611381795,
            "auditor_fp_violation": 0.017124039517014272,
            "ave_precision_score": 0.5944766551984795,
            "fpr": 0.15806805708013172,
            "logloss": 0.8124785949789443,
            "mae": 0.4637089019843697,
            "precision": 0.5966386554621849,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5374439324721986,
            "auditor_fn_violation": 0.015156151478060917,
            "auditor_fp_violation": 0.021700035966910447,
            "ave_precision_score": 0.5313151595892818,
            "fpr": 0.08662280701754387,
            "logloss": 0.6934069733541178,
            "mae": 0.49951957506045963,
            "precision": 0.487012987012987,
            "recall": 0.15856236786469344
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5403212151695119,
            "auditor_fn_violation": 0.025438678567108873,
            "auditor_fp_violation": 0.022232149694942947,
            "ave_precision_score": 0.5355950062832747,
            "fpr": 0.0889132821075741,
            "logloss": 0.6943571191111412,
            "mae": 0.4999819107754432,
            "precision": 0.547486033519553,
            "recall": 0.20374220374220375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7698132257086283,
            "auditor_fn_violation": 0.003975650012981728,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6618461027374372,
            "fpr": 0.017543859649122806,
            "logloss": 1.7424779850801688,
            "mae": 0.4301026011510313,
            "precision": 0.9090909090909091,
            "recall": 0.3382663847780127
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.786334128993502,
            "auditor_fn_violation": 0.005260263218550813,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.6732821872710676,
            "fpr": 0.013172338090010977,
            "logloss": 1.5999251624670408,
            "mae": 0.4264006652008382,
            "precision": 0.9325842696629213,
            "recall": 0.34511434511434513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7059291178884383,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.5493926742360856,
            "fpr": 0.2982456140350877,
            "logloss": 0.6888362911010374,
            "mae": 0.4936056414847834,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7184785740032478,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.09105506343655069,
            "ave_precision_score": 0.5679495591407105,
            "fpr": 0.2843029637760702,
            "logloss": 0.6845360574361808,
            "mae": 0.49144346740517997,
            "precision": 0.5683333333333334,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6737383413333343,
            "auditor_fn_violation": 0.008516931864545092,
            "auditor_fp_violation": 0.019219817767653764,
            "ave_precision_score": 0.5907915439486804,
            "fpr": 0.15021929824561403,
            "logloss": 0.8045024713811599,
            "mae": 0.4580294760434251,
            "precision": 0.6162464985994398,
            "recall": 0.46511627906976744
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6692286473326816,
            "auditor_fn_violation": 0.00565278611381795,
            "auditor_fp_violation": 0.017124039517014272,
            "ave_precision_score": 0.5919740443683031,
            "fpr": 0.15806805708013172,
            "logloss": 0.8195042521283288,
            "mae": 0.46493031841863264,
            "precision": 0.5966386554621849,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7698213174520998,
            "auditor_fn_violation": 0.003975650012981728,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6618622862243799,
            "fpr": 0.017543859649122806,
            "logloss": 1.7408579260640922,
            "mae": 0.4302506682381123,
            "precision": 0.9090909090909091,
            "recall": 0.3382663847780127
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.786334128993502,
            "auditor_fn_violation": 0.005260263218550813,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.6732821872710676,
            "fpr": 0.013172338090010977,
            "logloss": 1.5988290383190138,
            "mae": 0.4265408979364245,
            "precision": 0.9325842696629213,
            "recall": 0.34511434511434513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 6654,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5429508885076895,
            "auditor_fn_violation": 0.0033914728682170607,
            "auditor_fp_violation": 0.013525056947608203,
            "ave_precision_score": 0.5336386690064917,
            "fpr": 0.1074561403508772,
            "logloss": 0.6950079840299421,
            "mae": 0.4999383135061515,
            "precision": 0.48148148148148145,
            "recall": 0.19238900634249473
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5449531120259943,
            "auditor_fn_violation": 0.011682120353909604,
            "auditor_fp_violation": 0.015699589002629362,
            "ave_precision_score": 0.539015012492964,
            "fpr": 0.10757409440175632,
            "logloss": 0.693319496753497,
            "mae": 0.49922954790809415,
            "precision": 0.5504587155963303,
            "recall": 0.2494802494802495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7740802087427455,
            "auditor_fn_violation": 0.006198768591669453,
            "auditor_fp_violation": 0.001163929185149664,
            "ave_precision_score": 0.7483610541587307,
            "fpr": 0.03179824561403509,
            "logloss": 0.7221677936714195,
            "mae": 0.3839660210763676,
            "precision": 0.8776371308016878,
            "recall": 0.4397463002114165
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.7881415904641783,
            "auditor_fn_violation": 0.0046920178643559615,
            "auditor_fp_violation": 0.0026599954049983405,
            "ave_precision_score": 0.7604075933330109,
            "fpr": 0.02854006586169045,
            "logloss": 0.7280011044944171,
            "mae": 0.3889869382149007,
            "precision": 0.8834080717488789,
            "recall": 0.4095634095634096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5433832546516111,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5340208953325324,
            "fpr": 0.05701754385964912,
            "logloss": 0.6938690641547322,
            "mae": 0.4995933070844203,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5453359225120727,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.005064712940035231,
            "ave_precision_score": 0.5394269318253585,
            "fpr": 0.05378704720087816,
            "logloss": 0.6942684612564278,
            "mae": 0.49964386957537066,
            "precision": 0.5545454545454546,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6492212267693933,
            "auditor_fn_violation": 0.007401895330291901,
            "auditor_fp_violation": 0.014766414898293567,
            "ave_precision_score": 0.6239542110671064,
            "fpr": 0.22697368421052633,
            "logloss": 3.1979740720515637,
            "mae": 0.3237820581310749,
            "precision": 0.654424040066778,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6709779735942736,
            "auditor_fn_violation": 0.0034140363448815743,
            "auditor_fp_violation": 0.017583539682944897,
            "ave_precision_score": 0.6397882309026248,
            "fpr": 0.2217343578485181,
            "logloss": 3.2753774832050477,
            "mae": 0.31475009172440627,
            "precision": 0.6677631578947368,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6737383413333343,
            "auditor_fn_violation": 0.008516931864545092,
            "auditor_fp_violation": 0.019219817767653764,
            "ave_precision_score": 0.5907915439486804,
            "fpr": 0.15021929824561403,
            "logloss": 0.8045123729086281,
            "mae": 0.45802894103945346,
            "precision": 0.6162464985994398,
            "recall": 0.46511627906976744
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6692286473326816,
            "auditor_fn_violation": 0.00565278611381795,
            "auditor_fp_violation": 0.017124039517014272,
            "ave_precision_score": 0.5919740443683031,
            "fpr": 0.15806805708013172,
            "logloss": 0.8195121315851103,
            "mae": 0.4649292086828684,
            "precision": 0.5966386554621849,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6538618629493222,
            "auditor_fn_violation": 0.004005786135529099,
            "auditor_fp_violation": 0.016177616592734693,
            "ave_precision_score": 0.6293041041329439,
            "fpr": 0.21162280701754385,
            "logloss": 3.115532134321771,
            "mae": 0.3205494720859799,
            "precision": 0.6655112651646448,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.671317053420276,
            "auditor_fn_violation": 0.0039001257442530793,
            "auditor_fp_violation": 0.021994741275878794,
            "ave_precision_score": 0.6412324505896165,
            "fpr": 0.2074643249176729,
            "logloss": 3.1969199474352155,
            "mae": 0.3127235187926326,
            "precision": 0.6763698630136986,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7388689245378711,
            "auditor_fn_violation": 0.013855661881977677,
            "auditor_fp_violation": 0.03046697038724374,
            "ave_precision_score": 0.740649510357587,
            "fpr": 0.14912280701754385,
            "logloss": 0.7378421477121199,
            "mae": 0.3279206010670191,
            "precision": 0.7166666666666667,
            "recall": 0.7272727272727273
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7633493034961809,
            "auditor_fn_violation": 0.008831765143510483,
            "auditor_fp_violation": 0.03249942562479259,
            "ave_precision_score": 0.7640811768923854,
            "fpr": 0.150384193194292,
            "logloss": 0.6978208232518788,
            "mae": 0.3175568415059232,
            "precision": 0.726,
            "recall": 0.7546777546777547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7556787076303282,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6694191634250525,
            "fpr": 0.48135964912280704,
            "logloss": 9.149982528291549,
            "mae": 0.48134661642344373,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7743531238455942,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6909810813438505,
            "fpr": 0.47200878155872666,
            "logloss": 8.915896546242765,
            "mae": 0.4720029036640205,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7216111377327725,
            "auditor_fn_violation": 0.012112403100775198,
            "auditor_fp_violation": 0.035974403548735163,
            "ave_precision_score": 0.7234295104169879,
            "fpr": 0.22697368421052633,
            "logloss": 0.8612680023501619,
            "mae": 0.3382539040650412,
            "precision": 0.6503378378378378,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7453495722685536,
            "auditor_fn_violation": 0.012232108829254825,
            "auditor_fp_violation": 0.023628519643632093,
            "ave_precision_score": 0.7461900134956656,
            "fpr": 0.21734357848518113,
            "logloss": 0.8290006859715205,
            "mae": 0.32549349588223997,
            "precision": 0.6748768472906403,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5374439324721986,
            "auditor_fn_violation": 0.015156151478060917,
            "auditor_fp_violation": 0.021700035966910447,
            "ave_precision_score": 0.5313151595892818,
            "fpr": 0.08662280701754387,
            "logloss": 0.6934069679744297,
            "mae": 0.4995195755179514,
            "precision": 0.487012987012987,
            "recall": 0.15856236786469344
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5403212151695119,
            "auditor_fn_violation": 0.025438678567108873,
            "auditor_fp_violation": 0.022232149694942947,
            "ave_precision_score": 0.5355950062832747,
            "fpr": 0.0889132821075741,
            "logloss": 0.6943571089653946,
            "mae": 0.49998190884532573,
            "precision": 0.547486033519553,
            "recall": 0.20374220374220375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7059291178884383,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.5493926742360856,
            "fpr": 0.2982456140350877,
            "logloss": 0.6891187466544558,
            "mae": 0.4935851866346702,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.7178906346554597,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.09144053302019248,
            "ave_precision_score": 0.5670600894374598,
            "fpr": 0.2854006586169045,
            "logloss": 0.6854797451432132,
            "mae": 0.49183146529611194,
            "precision": 0.56738768718802,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 6654,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0.5433832546516111,
            "auditor_fn_violation": 0.0033914728682170607,
            "auditor_fp_violation": 0.013525056947608203,
            "ave_precision_score": 0.5340208953325324,
            "fpr": 0.1074561403508772,
            "logloss": 0.6935538418668098,
            "mae": 0.49952528727028456,
            "precision": 0.48148148148148145,
            "recall": 0.19238900634249473
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.5433569801596705,
            "auditor_fn_violation": 0.011682120353909604,
            "auditor_fp_violation": 0.015699589002629362,
            "ave_precision_score": 0.5375961397938651,
            "fpr": 0.10757409440175632,
            "logloss": 0.694624066397718,
            "mae": 0.5000431357701969,
            "precision": 0.5504587155963303,
            "recall": 0.2494802494802495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.842167528578855,
            "auditor_fn_violation": 0.009263380438411045,
            "auditor_fp_violation": 0.020166446868880635,
            "ave_precision_score": 0.8428806334773822,
            "fpr": 0.09210526315789473,
            "logloss": 0.5370845351112986,
            "mae": 0.30958275498644644,
            "precision": 0.7975903614457831,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8574495699274207,
            "auditor_fn_violation": 0.01125536581079941,
            "auditor_fp_violation": 0.01208485436397519,
            "ave_precision_score": 0.8576893832167027,
            "fpr": 0.07903402854006586,
            "logloss": 0.5215451698697178,
            "mae": 0.3026537831261106,
            "precision": 0.8181818181818182,
            "recall": 0.6735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.7572163222994528,
            "auditor_fn_violation": 0.007598939208486332,
            "auditor_fp_violation": 0.009653618670822846,
            "ave_precision_score": 0.7538872732395491,
            "fpr": 0.42653508771929827,
            "logloss": 0.806684887374204,
            "mae": 0.43970712847981863,
            "precision": 0.5149625935162094,
            "recall": 0.8731501057082452
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.7968277666389043,
            "auditor_fn_violation": 0.010159953079821357,
            "auditor_fp_violation": 0.011806601485717208,
            "ave_precision_score": 0.7942849071455524,
            "fpr": 0.411635565312843,
            "logloss": 0.7193400179513832,
            "mae": 0.43219555221378414,
            "precision": 0.5306633291614519,
            "recall": 0.8814968814968815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8390912182208436,
            "auditor_fn_violation": 0.011481862690553023,
            "auditor_fp_violation": 0.018612876153938376,
            "ave_precision_score": 0.8398081456710448,
            "fpr": 0.09429824561403509,
            "logloss": 0.5328780845031528,
            "mae": 0.3180074621356509,
            "precision": 0.7897310513447433,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8572825567573087,
            "auditor_fn_violation": 0.009037155030568863,
            "auditor_fp_violation": 0.011686620886835324,
            "ave_precision_score": 0.8575203122677079,
            "fpr": 0.07793633369923161,
            "logloss": 0.5210412458155268,
            "mae": 0.3113441565406277,
            "precision": 0.8202531645569621,
            "recall": 0.6735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.6797543279823118,
            "auditor_fn_violation": 0.008968973702755845,
            "auditor_fp_violation": 0.020863305758702,
            "ave_precision_score": 0.527527174414335,
            "fpr": 0.2916666666666667,
            "logloss": 0.9906883993581213,
            "mae": 0.4833244592147438,
            "precision": 0.5325131810193322,
            "recall": 0.6405919661733616
        },
        "train": {
            "accuracy": 0.5038419319429198,
            "auc_prc": 0.6738887177128866,
            "auditor_fn_violation": 0.006385343377659518,
            "auditor_fp_violation": 0.022732494320067395,
            "ave_precision_score": 0.5263713600792425,
            "fpr": 0.29747530186608123,
            "logloss": 1.0039864002194556,
            "mae": 0.4877365081684519,
            "precision": 0.5253940455341506,
            "recall": 0.6237006237006237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7427088442632247,
            "auditor_fn_violation": 0.008672248803827755,
            "auditor_fp_violation": 0.037328158094553025,
            "ave_precision_score": 0.7444599340406243,
            "fpr": 0.23464912280701755,
            "logloss": 0.9052951043833716,
            "mae": 0.32684145846526425,
            "precision": 0.654281098546042,
            "recall": 0.8562367864693446
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7581686514109572,
            "auditor_fn_violation": 0.008966409625026532,
            "auditor_fp_violation": 0.027784443366604558,
            "ave_precision_score": 0.7589941673468087,
            "fpr": 0.2327113062568606,
            "logloss": 0.8827207251659087,
            "mae": 0.31842453894275674,
            "precision": 0.6645569620253164,
            "recall": 0.8731808731808732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5433832546516111,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5340208953325324,
            "fpr": 0.05701754385964912,
            "logloss": 0.6943024993131216,
            "mae": 0.4997728398363841,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5433569801596705,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.002476195338626095,
            "ave_precision_score": 0.5375961397938651,
            "fpr": 0.054884742041712405,
            "logloss": 0.6955204697789683,
            "mae": 0.5003694819632005,
            "precision": 0.5495495495495496,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7698213174520998,
            "auditor_fn_violation": 0.00427932940172843,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6618622862243799,
            "fpr": 0.017543859649122806,
            "logloss": 1.7414643776839127,
            "mae": 0.4315674840528319,
            "precision": 0.9096045197740112,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.78633042681437,
            "auditor_fn_violation": 0.005260263218550813,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.673278485210259,
            "fpr": 0.013172338090010977,
            "logloss": 1.5990019110486446,
            "mae": 0.4278480034558141,
            "precision": 0.9325842696629213,
            "recall": 0.34511434511434513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7770761233760488,
            "auditor_fn_violation": 0.006198768591669453,
            "auditor_fp_violation": 0.001163929185149664,
            "ave_precision_score": 0.7509812009052785,
            "fpr": 0.03179824561403509,
            "logloss": 0.7803054392179489,
            "mae": 0.3903422977166708,
            "precision": 0.8776371308016878,
            "recall": 0.4397463002114165
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7921484266103249,
            "auditor_fn_violation": 0.0046920178643559615,
            "auditor_fp_violation": 0.0024251397646338044,
            "ave_precision_score": 0.7634742353599709,
            "fpr": 0.027442371020856202,
            "logloss": 0.7803111079669698,
            "mae": 0.3925836312029466,
            "precision": 0.8873873873873874,
            "recall": 0.4095634095634096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7691883374327579,
            "auditor_fn_violation": 0.003975650012981728,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6615090828921202,
            "fpr": 0.017543859649122806,
            "logloss": 1.7792615253034765,
            "mae": 0.43077698497768024,
            "precision": 0.9090909090909091,
            "recall": 0.3382663847780127
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7854026968191932,
            "auditor_fn_violation": 0.00656334794644345,
            "auditor_fp_violation": 0.0029433538406555544,
            "ave_precision_score": 0.6740957323001077,
            "fpr": 0.014270032930845226,
            "logloss": 1.6014893435703765,
            "mae": 0.426022177887687,
            "precision": 0.9277777777777778,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5435442817640956,
            "auditor_fn_violation": 0.005176458588331294,
            "auditor_fp_violation": 0.006181812732286299,
            "ave_precision_score": 0.5341063804406704,
            "fpr": 0.05701754385964912,
            "logloss": 0.6944579746136934,
            "mae": 0.4996965438977145,
            "precision": 0.514018691588785,
            "recall": 0.11627906976744186
        },
        "train": {
            "accuracy": 0.48518111964873767,
            "auc_prc": 0.5448816845173157,
            "auditor_fn_violation": 0.008795251385811227,
            "auditor_fp_violation": 0.005064712940035231,
            "ave_precision_score": 0.5395466175068009,
            "fpr": 0.05378704720087816,
            "logloss": 0.6950662998456921,
            "mae": 0.4998968275494947,
            "precision": 0.5545454545454546,
            "recall": 0.12681912681912683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6538576328830771,
            "auditor_fn_violation": 0.0018869849041207695,
            "auditor_fp_violation": 0.015670583063581513,
            "ave_precision_score": 0.6292571191922987,
            "fpr": 0.21271929824561403,
            "logloss": 3.1122449111430988,
            "mae": 0.319839350669427,
            "precision": 0.6649395509499136,
            "recall": 0.813953488372093
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6714714940396981,
            "auditor_fn_violation": 0.0039115362935341035,
            "auditor_fp_violation": 0.02157098001174278,
            "ave_precision_score": 0.6413596942750681,
            "fpr": 0.20856201975850713,
            "logloss": 3.1930601675399837,
            "mae": 0.3126449160987041,
            "precision": 0.676320272572402,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8142297418936189,
            "auditor_fn_violation": 0.006502447980416162,
            "auditor_fp_violation": 0.004915477760460377,
            "ave_precision_score": 0.8145900297298047,
            "fpr": 0.046052631578947366,
            "logloss": 0.5831833492028659,
            "mae": 0.3531270988649084,
            "precision": 0.8627450980392157,
            "recall": 0.5581395348837209
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8269247475318993,
            "auditor_fn_violation": 0.0018462268736692627,
            "auditor_fp_violation": 0.00636152451943941,
            "ave_precision_score": 0.8271843336050955,
            "fpr": 0.04171240395170143,
            "logloss": 0.5822151038276396,
            "mae": 0.350617637739207,
            "precision": 0.8745874587458746,
            "recall": 0.5509355509355509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8391086205371758,
            "auditor_fn_violation": 0.011481862690553023,
            "auditor_fp_violation": 0.018612876153938376,
            "ave_precision_score": 0.8398254689030953,
            "fpr": 0.09429824561403509,
            "logloss": 0.5328551829532768,
            "mae": 0.317951699237088,
            "precision": 0.7897310513447433,
            "recall": 0.6828752642706131
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8573701618422144,
            "auditor_fn_violation": 0.009037155030568863,
            "auditor_fp_violation": 0.011686620886835324,
            "ave_precision_score": 0.8576077033314091,
            "fpr": 0.07793633369923161,
            "logloss": 0.5209841539887657,
            "mae": 0.3112818568857524,
            "precision": 0.8202531645569621,
            "recall": 0.6735966735966736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7707639072971818,
            "auditor_fn_violation": 0.005276139609064951,
            "auditor_fp_violation": 0.026877772449346606,
            "ave_precision_score": 0.7718870424369564,
            "fpr": 0.1787280701754386,
            "logloss": 0.7656622802689754,
            "mae": 0.29788474464395287,
            "precision": 0.7014652014652014,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7948156252858356,
            "auditor_fn_violation": 0.012065514809751916,
            "auditor_fp_violation": 0.02850432695989585,
            "ave_precision_score": 0.7957291964025067,
            "fpr": 0.18221734357848518,
            "logloss": 0.7243518315397544,
            "mae": 0.29314957017604776,
            "precision": 0.7051509769094139,
            "recall": 0.8253638253638254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6492246741555905,
            "auditor_fn_violation": 0.007401895330291901,
            "auditor_fp_violation": 0.014766414898293567,
            "ave_precision_score": 0.6239576561531759,
            "fpr": 0.22697368421052633,
            "logloss": 3.1979726875616263,
            "mae": 0.32378198383660256,
            "precision": 0.654424040066778,
            "recall": 0.828752642706131
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6709779735942736,
            "auditor_fn_violation": 0.0034140363448815743,
            "auditor_fp_violation": 0.017583539682944897,
            "ave_precision_score": 0.6397882309026248,
            "fpr": 0.2217343578485181,
            "logloss": 3.275376993146489,
            "mae": 0.3147500390731864,
            "precision": 0.6677631578947368,
            "recall": 0.8440748440748441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7204328980794658,
            "auditor_fn_violation": 0.014667019027484147,
            "auditor_fp_violation": 0.014014606561963005,
            "ave_precision_score": 0.6900317860869174,
            "fpr": 0.3048245614035088,
            "logloss": 0.9439129875500479,
            "mae": 0.4514333745757159,
            "precision": 0.5669781931464174,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7421085672817791,
            "auditor_fn_violation": 0.010269494352919168,
            "auditor_fp_violation": 0.00963418681234526,
            "ave_precision_score": 0.7097083162226481,
            "fpr": 0.3205268935236004,
            "logloss": 0.8787878699557814,
            "mae": 0.4542259466138497,
            "precision": 0.5521472392638037,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8139916312355804,
            "auditor_fn_violation": 0.007591984718667709,
            "auditor_fp_violation": 0.004915477760460377,
            "ave_precision_score": 0.8143630204501067,
            "fpr": 0.046052631578947366,
            "logloss": 0.5789202206555963,
            "mae": 0.35435755105419575,
            "precision": 0.865814696485623,
            "recall": 0.572938689217759
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8271164763542528,
            "auditor_fn_violation": 0.0003605733572802722,
            "auditor_fp_violation": 0.006407474536032472,
            "ave_precision_score": 0.8273789865280009,
            "fpr": 0.043907793633369926,
            "logloss": 0.5752838172145617,
            "mae": 0.3511951644398869,
            "precision": 0.868421052631579,
            "recall": 0.5488565488565489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7691964291762294,
            "auditor_fn_violation": 0.003975650012981728,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.661525266379063,
            "fpr": 0.017543859649122806,
            "logloss": 1.7783759147786053,
            "mae": 0.430429245054511,
            "precision": 0.9090909090909091,
            "recall": 0.3382663847780127
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.785398986078349,
            "auditor_fn_violation": 0.00656334794644345,
            "auditor_fp_violation": 0.0029433538406555544,
            "ave_precision_score": 0.6740920216828107,
            "fpr": 0.014270032930845226,
            "logloss": 1.6015755051195204,
            "mae": 0.4258944681965992,
            "precision": 0.9277777777777778,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7698213174520998,
            "auditor_fn_violation": 0.00427932940172843,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.6618622862243799,
            "fpr": 0.017543859649122806,
            "logloss": 1.7398958714017214,
            "mae": 0.43085307015262164,
            "precision": 0.9096045197740112,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7863257810081602,
            "auditor_fn_violation": 0.005260263218550813,
            "auditor_fp_violation": 0.002654889847599112,
            "ave_precision_score": 0.673282148278914,
            "fpr": 0.013172338090010977,
            "logloss": 1.5973815770510096,
            "mae": 0.42707759321832306,
            "precision": 0.9325842696629213,
            "recall": 0.34511434511434513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7365897775940318,
            "auditor_fn_violation": 0.009314380030414304,
            "auditor_fp_violation": 0.0033669024497462335,
            "ave_precision_score": 0.7339731483535906,
            "fpr": 0.02412280701754386,
            "logloss": 0.6905054172739877,
            "mae": 0.4157596391866867,
            "precision": 0.8883248730964467,
            "recall": 0.3699788583509514
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.7596278527573317,
            "auditor_fn_violation": 0.006720813526521537,
            "auditor_fp_violation": 0.00032165011615143074,
            "ave_precision_score": 0.7559111253718342,
            "fpr": 0.019758507135016465,
            "logloss": 0.6332522042930815,
            "mae": 0.41343096767861376,
            "precision": 0.9081632653061225,
            "recall": 0.3700623700623701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.805247767800077,
            "auditor_fn_violation": 0.009219335336226401,
            "auditor_fp_violation": 0.02224203732566039,
            "ave_precision_score": 0.8061543826163301,
            "fpr": 0.1425438596491228,
            "logloss": 0.7421371430284032,
            "mae": 0.2876692600255718,
            "precision": 0.7352342158859471,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.826915876169062,
            "auditor_fn_violation": 0.007921203310884981,
            "auditor_fp_violation": 0.030434227656804435,
            "ave_precision_score": 0.8273310608687261,
            "fpr": 0.13391877058177826,
            "logloss": 0.6742350786137415,
            "mae": 0.27320724269241786,
            "precision": 0.7569721115537849,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7691964291762294,
            "auditor_fn_violation": 0.00427932940172843,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.661525266379063,
            "fpr": 0.017543859649122806,
            "logloss": 1.77582291478854,
            "mae": 0.4313607130744212,
            "precision": 0.9096045197740112,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7853943488338515,
            "auditor_fn_violation": 0.00656334794644345,
            "auditor_fp_violation": 0.0029433538406555544,
            "ave_precision_score": 0.674095693307954,
            "fpr": 0.014270032930845226,
            "logloss": 1.5981314950709316,
            "mae": 0.4265678860652362,
            "precision": 0.9277777777777778,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.46726404651494136,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.47496437080972115,
            "fpr": 0.2982456140350877,
            "logloss": 0.6883658659982733,
            "mae": 0.49377640320412947,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.4870858737115396,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.09144053302019248,
            "ave_precision_score": 0.49570108798137763,
            "fpr": 0.2854006586169045,
            "logloss": 0.6849600901202177,
            "mae": 0.49212770990037763,
            "precision": 0.56738768718802,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6910808445099096,
            "auditor_fn_violation": 0.005890452876377,
            "auditor_fp_violation": 0.008776925228789517,
            "ave_precision_score": 0.6910048563827244,
            "fpr": 0.19846491228070176,
            "logloss": 0.7400445483350503,
            "mae": 0.4376230181530863,
            "precision": 0.6298568507157464,
            "recall": 0.6511627906976745
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7180732427338344,
            "auditor_fn_violation": 0.01747867938866842,
            "auditor_fp_violation": 0.012789421285068795,
            "ave_precision_score": 0.7182052512792727,
            "fpr": 0.18221734357848518,
            "logloss": 0.6831639494708539,
            "mae": 0.42811817706498173,
            "precision": 0.6605316973415133,
            "recall": 0.6715176715176715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7741858926847573,
            "auditor_fn_violation": 0.0012981714328103534,
            "auditor_fp_violation": 0.004380969508052591,
            "ave_precision_score": 0.7604434983381584,
            "fpr": 0.03508771929824561,
            "logloss": 1.1509898059809844,
            "mae": 0.39426603947386185,
            "precision": 0.8666666666666667,
            "recall": 0.4397463002114165
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.813962685846339,
            "auditor_fn_violation": 0.000636708649880998,
            "auditor_fp_violation": 0.00286166492226789,
            "ave_precision_score": 0.8066878240757356,
            "fpr": 0.025246981339187707,
            "logloss": 0.8048561546652898,
            "mae": 0.38204378486865503,
            "precision": 0.902542372881356,
            "recall": 0.44282744282744285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7059291178884383,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.5493926742360856,
            "fpr": 0.2982456140350877,
            "logloss": 0.6891212053122725,
            "mae": 0.4935862251410359,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.7184785740032478,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.09105506343655069,
            "ave_precision_score": 0.5679495591407105,
            "fpr": 0.2843029637760702,
            "logloss": 0.684620362843254,
            "mae": 0.4912835739626581,
            "precision": 0.5683333333333334,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7134888641431169,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005719737841186102,
            "ave_precision_score": 0.7151235207254891,
            "fpr": 0.48026315789473684,
            "logloss": 4.433159284399782,
            "mae": 0.4782998640613075,
            "precision": 0.5192096597145993,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7323012886679989,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7308362909204152,
            "fpr": 0.47200878155872666,
            "logloss": 4.285668859845042,
            "mae": 0.46989832286907995,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7505438843413498,
            "auditor_fn_violation": 0.002392344497607671,
            "auditor_fp_violation": 0.00716840506733805,
            "ave_precision_score": 0.7472012479103458,
            "fpr": 0.019736842105263157,
            "logloss": 0.73665423887367,
            "mae": 0.41852190954303387,
            "precision": 0.9052631578947369,
            "recall": 0.36363636363636365
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7896259727882917,
            "auditor_fn_violation": 0.006011077361242028,
            "auditor_fp_violation": 0.0013121282516018685,
            "ave_precision_score": 0.7871516393116833,
            "fpr": 0.015367727771679473,
            "logloss": 0.6566943214347498,
            "mae": 0.4148019873264521,
            "precision": 0.9267015706806283,
            "recall": 0.367983367983368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6649162057509261,
            "auditor_fn_violation": 0.007629075331033719,
            "auditor_fp_violation": 0.010477860368461015,
            "ave_precision_score": 0.6660895248297037,
            "fpr": 0.21162280701754385,
            "logloss": 0.6868364001433341,
            "mae": 0.43807228723974395,
            "precision": 0.6237816764132553,
            "recall": 0.6765327695560254
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.6978640738524646,
            "auditor_fn_violation": 0.010066386575716988,
            "auditor_fp_violation": 0.017011717254231232,
            "ave_precision_score": 0.6981725305973047,
            "fpr": 0.1942919868276619,
            "logloss": 0.6597205587367632,
            "mae": 0.42691878293989516,
            "precision": 0.654296875,
            "recall": 0.6964656964656964
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7483128119628857,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7165660860479094,
            "fpr": 0.48135964912280704,
            "logloss": 6.740718239199259,
            "mae": 0.48125163119351655,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7600433457869183,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7264662957203835,
            "fpr": 0.47200878155872666,
            "logloss": 6.712304182860919,
            "mae": 0.4719581679245774,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.750175251218703,
            "auditor_fn_violation": 0.0021651644968658664,
            "auditor_fp_violation": 0.00716840506733805,
            "ave_precision_score": 0.7468253231896703,
            "fpr": 0.019736842105263157,
            "logloss": 0.7394554470714879,
            "mae": 0.418884984944093,
            "precision": 0.9057591623036649,
            "recall": 0.3657505285412262
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7894002027033634,
            "auditor_fn_violation": 0.006011077361242028,
            "auditor_fp_violation": 0.0013121282516018685,
            "ave_precision_score": 0.7869262240448627,
            "fpr": 0.015367727771679473,
            "logloss": 0.6580431094094181,
            "mae": 0.4149972250373629,
            "precision": 0.9267015706806283,
            "recall": 0.367983367983368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8422016713385481,
            "auditor_fn_violation": 0.009263380438411045,
            "auditor_fp_violation": 0.020166446868880635,
            "ave_precision_score": 0.8429139874116562,
            "fpr": 0.09210526315789473,
            "logloss": 0.5368761374231198,
            "mae": 0.3097549152193926,
            "precision": 0.7975903614457831,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8575011903984897,
            "auditor_fn_violation": 0.011421959830302308,
            "auditor_fp_violation": 0.01156664028795344,
            "ave_precision_score": 0.8577364364598603,
            "fpr": 0.0801317233809001,
            "logloss": 0.5218763381565616,
            "mae": 0.3028524400229064,
            "precision": 0.8165829145728644,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6511585718403917,
            "auditor_fn_violation": 0.005373502466525725,
            "auditor_fp_violation": 0.015563181872677138,
            "ave_precision_score": 0.6259921026352959,
            "fpr": 0.21162280701754385,
            "logloss": 3.21416255960245,
            "mae": 0.32350750102852527,
            "precision": 0.6649305555555556,
            "recall": 0.8097251585623678
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6701405148964685,
            "auditor_fn_violation": 0.0016317085471860462,
            "auditor_fp_violation": 0.022244913588441027,
            "ave_precision_score": 0.6392883387939869,
            "fpr": 0.20965971459934138,
            "logloss": 3.293955183472592,
            "mae": 0.3152510882813921,
            "precision": 0.6712564543889845,
            "recall": 0.8108108108108109
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8201877812976199,
            "auditor_fn_violation": 0.00986378472608583,
            "auditor_fp_violation": 0.01677456739799385,
            "ave_precision_score": 0.8205733825517294,
            "fpr": 0.07675438596491228,
            "logloss": 3.315187251821731,
            "mae": 0.32282289149206395,
            "precision": 0.7988505747126436,
            "recall": 0.587737843551797
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.845329427872401,
            "auditor_fn_violation": 0.009162671072660099,
            "auditor_fp_violation": 0.013453143746968578,
            "ave_precision_score": 0.8456027758038644,
            "fpr": 0.059275521405049394,
            "logloss": 2.8355337573031267,
            "mae": 0.30522276240051577,
            "precision": 0.8434782608695652,
            "recall": 0.604989604989605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6507728416491771,
            "auditor_fn_violation": 0.006279904306220098,
            "auditor_fp_violation": 0.017603804499860133,
            "ave_precision_score": 0.6262290484404358,
            "fpr": 0.22039473684210525,
            "logloss": 3.1439180600894185,
            "mae": 0.32094940300320723,
            "precision": 0.6581632653061225,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6717659475008051,
            "auditor_fn_violation": 0.0026997359598896404,
            "auditor_fp_violation": 0.01775712863451868,
            "ave_precision_score": 0.6413830209139544,
            "fpr": 0.21844127332601537,
            "logloss": 3.2202121564449406,
            "mae": 0.31206059553959425,
            "precision": 0.6694352159468439,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7691964291762294,
            "auditor_fn_violation": 0.00427932940172843,
            "auditor_fp_violation": 0.0055648803101146956,
            "ave_precision_score": 0.661525266379063,
            "fpr": 0.017543859649122806,
            "logloss": 1.7784857405095822,
            "mae": 0.43207250820506127,
            "precision": 0.9096045197740112,
            "recall": 0.3403805496828753
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.785587381921962,
            "auditor_fn_violation": 0.00656334794644345,
            "auditor_fp_violation": 0.0029433538406555544,
            "ave_precision_score": 0.6744439521832039,
            "fpr": 0.014270032930845226,
            "logloss": 1.6004537029866859,
            "mae": 0.4270367040781679,
            "precision": 0.9277777777777778,
            "recall": 0.3471933471933472
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8390219079763668,
            "auditor_fn_violation": 0.0132251214717555,
            "auditor_fp_violation": 0.017921012668345126,
            "ave_precision_score": 0.8397431846694959,
            "fpr": 0.10087719298245613,
            "logloss": 0.5340077389304603,
            "mae": 0.3192712001572976,
            "precision": 0.7835294117647059,
            "recall": 0.7040169133192389
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8562288706293154,
            "auditor_fn_violation": 0.010714505774878997,
            "auditor_fp_violation": 0.011750440354325683,
            "ave_precision_score": 0.8564802979312767,
            "fpr": 0.0867178924259056,
            "logloss": 0.5211429813651907,
            "mae": 0.3127032505595212,
            "precision": 0.8096385542168675,
            "recall": 0.6985446985446986
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 6654,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.913203108325387,
            "mae": 0.518640350877193,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.236170632219583,
            "mae": 0.5279912184412733,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 6654,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7059291178884383,
            "auditor_fn_violation": 0.08789084232780683,
            "auditor_fp_violation": 0.09162070894776805,
            "ave_precision_score": 0.5493926742360856,
            "fpr": 0.2982456140350877,
            "logloss": 0.6889266559311595,
            "mae": 0.49357018064250024,
            "precision": 0.5511551155115512,
            "recall": 0.7061310782241015
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7190684337765832,
            "auditor_fn_violation": 0.08347957853995176,
            "auditor_fp_violation": 0.0906695938529089,
            "ave_precision_score": 0.5688419142229516,
            "fpr": 0.283205268935236,
            "logloss": 0.6836497553120185,
            "mae": 0.4907752993536048,
            "precision": 0.5692821368948247,
            "recall": 0.7089397089397089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8421842407700905,
            "auditor_fn_violation": 0.009263380438411045,
            "auditor_fp_violation": 0.020166446868880635,
            "ave_precision_score": 0.8428966760023404,
            "fpr": 0.09210526315789473,
            "logloss": 0.5369587052194935,
            "mae": 0.30966096536972226,
            "precision": 0.7975903614457831,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8574391449413982,
            "auditor_fn_violation": 0.011421959830302308,
            "auditor_fp_violation": 0.01156664028795344,
            "ave_precision_score": 0.8576748584157285,
            "fpr": 0.0801317233809001,
            "logloss": 0.5218729887549204,
            "mae": 0.3027471969693615,
            "precision": 0.8165829145728644,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7553008746079031,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7250270115598576,
            "fpr": 0.48135964912280704,
            "logloss": 6.6484364311087205,
            "mae": 0.48125029218040016,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7668898727635894,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7347787579599271,
            "fpr": 0.47200878155872666,
            "logloss": 6.638505358280667,
            "mae": 0.47195524638099545,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7609084443168445,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7261702335520218,
            "fpr": 0.48135964912280704,
            "logloss": 6.659147230174254,
            "mae": 0.4810352384913386,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7810472287798516,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7474384676140197,
            "fpr": 0.47200878155872666,
            "logloss": 6.517435465098661,
            "mae": 0.4718235956196204,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7850573308207052,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.642685039355122,
            "fpr": 0.48135964912280704,
            "logloss": 11.39628750923272,
            "mae": 0.4813550764269996,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8057818714913929,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6653343943900969,
            "fpr": 0.47200878155872666,
            "logloss": 11.143114025867051,
            "mae": 0.4720065046743818,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6538618629493222,
            "auditor_fn_violation": 0.004005786135529099,
            "auditor_fp_violation": 0.016177616592734693,
            "ave_precision_score": 0.6293041041329439,
            "fpr": 0.21162280701754385,
            "logloss": 3.1155305883845616,
            "mae": 0.3205493774591161,
            "precision": 0.6655112651646448,
            "recall": 0.8118393234672304
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.671317053420276,
            "auditor_fn_violation": 0.0039001257442530793,
            "auditor_fp_violation": 0.021994741275878794,
            "ave_precision_score": 0.6412324505896165,
            "fpr": 0.2074643249176729,
            "logloss": 3.196918870068102,
            "mae": 0.31272340202970317,
            "precision": 0.6763698630136986,
            "recall": 0.8212058212058212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6553138143864219,
            "auditor_fn_violation": 0.0005285412262156504,
            "auditor_fp_violation": 0.01972685129680694,
            "ave_precision_score": 0.6307323120809554,
            "fpr": 0.21710526315789475,
            "logloss": 3.1051647816859402,
            "mae": 0.31794652907028964,
            "precision": 0.6632653061224489,
            "recall": 0.8245243128964059
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6745254520183045,
            "auditor_fn_violation": 0.0035030386292735395,
            "auditor_fp_violation": 0.02353151405304675,
            "ave_precision_score": 0.6449627038430565,
            "fpr": 0.21514818880351264,
            "logloss": 3.159849638418378,
            "mae": 0.3093989560439327,
            "precision": 0.6738768718801996,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7789863057165827,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6447007093468549,
            "fpr": 0.48135964912280704,
            "logloss": 11.096583652177932,
            "mae": 0.48135462880396007,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8063605156321179,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6762118100767672,
            "fpr": 0.47200878155872666,
            "logloss": 10.726455679772728,
            "mae": 0.4720063638739476,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6505768237151907,
            "auditor_fn_violation": 0.006279904306220098,
            "auditor_fp_violation": 0.01819326219877713,
            "ave_precision_score": 0.6260198161660747,
            "fpr": 0.22149122807017543,
            "logloss": 3.149199459595868,
            "mae": 0.32078541248113784,
            "precision": 0.6570458404074703,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6720207797826562,
            "auditor_fn_violation": 0.0026997359598896404,
            "auditor_fp_violation": 0.022732494320067388,
            "ave_precision_score": 0.6416504390476693,
            "fpr": 0.21405049396267836,
            "logloss": 3.2232531990030444,
            "mae": 0.3114492861686211,
            "precision": 0.6739130434782609,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6497878749453216,
            "auditor_fn_violation": 0.0035908349096843584,
            "auditor_fp_violation": 0.01338268792710707,
            "ave_precision_score": 0.6245644337333439,
            "fpr": 0.22478070175438597,
            "logloss": 3.1970763507253723,
            "mae": 0.3233335439561123,
            "precision": 0.6583333333333333,
            "recall": 0.8350951374207188
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6710289888855832,
            "auditor_fn_violation": 0.0022227749999429516,
            "auditor_fp_violation": 0.017409950731371096,
            "ave_precision_score": 0.6398700617571729,
            "fpr": 0.22502744237102085,
            "logloss": 3.277887956253256,
            "mae": 0.3146762997803931,
            "precision": 0.6639344262295082,
            "recall": 0.841995841995842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7332861529176435,
            "auditor_fn_violation": 0.010610233299951784,
            "auditor_fp_violation": 0.03742556847700116,
            "ave_precision_score": 0.7351030878171354,
            "fpr": 0.22149122807017543,
            "logloss": 0.8505523756159931,
            "mae": 0.3253243127092231,
            "precision": 0.6666666666666666,
            "recall": 0.854122621564482
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7495734695167251,
            "auditor_fn_violation": 0.011686684573622009,
            "auditor_fp_violation": 0.024940647895233963,
            "ave_precision_score": 0.7504667298123487,
            "fpr": 0.21953896816684962,
            "logloss": 0.8203144513501542,
            "mae": 0.31662944394056475,
            "precision": 0.6768982229402262,
            "recall": 0.8711018711018711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.771030508279033,
            "auditor_fn_violation": 0.018434034345907065,
            "auditor_fp_violation": 0.0041511809135595275,
            "ave_precision_score": 0.7716924957475482,
            "fpr": 0.03618421052631579,
            "logloss": 1.3723067513574159,
            "mae": 0.37236339106109706,
            "precision": 0.8382352941176471,
            "recall": 0.36152219873150104
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7974287079997602,
            "auditor_fn_violation": 0.024010077797125,
            "auditor_fp_violation": 0.008526280856712531,
            "ave_precision_score": 0.7978052996241443,
            "fpr": 0.04171240395170143,
            "logloss": 1.287150115092788,
            "mae": 0.36707265267616657,
            "precision": 0.8354978354978355,
            "recall": 0.40124740124740127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7774594504341774,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6489355625302926,
            "fpr": 0.48135964912280704,
            "logloss": 10.848482661941977,
            "mae": 0.4813519901220213,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8030447207507367,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6795980006236075,
            "fpr": 0.47200878155872666,
            "logloss": 10.451353632664084,
            "mae": 0.47200539089845645,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 6654,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5395540619396001,
            "auditor_fn_violation": 0.015156151478060917,
            "auditor_fp_violation": 0.021700035966910447,
            "ave_precision_score": 0.5336134601529331,
            "fpr": 0.08662280701754387,
            "logloss": 0.693853918734638,
            "mae": 0.49965557727243815,
            "precision": 0.487012987012987,
            "recall": 0.15856236786469344
        },
        "train": {
            "accuracy": 0.49066959385290887,
            "auc_prc": 0.5438938613464875,
            "auditor_fn_violation": 0.025438678567108873,
            "auditor_fp_violation": 0.022232149694942947,
            "ave_precision_score": 0.5389908514711431,
            "fpr": 0.0889132821075741,
            "logloss": 0.6948953119618851,
            "mae": 0.5001672742199296,
            "precision": 0.547486033519553,
            "recall": 0.20374220374220375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6519129450807883,
            "auditor_fn_violation": 0.000598086124401915,
            "auditor_fp_violation": 0.01819326219877713,
            "ave_precision_score": 0.6266612333106916,
            "fpr": 0.22149122807017543,
            "logloss": 3.193498539826939,
            "mae": 0.3210778862237694,
            "precision": 0.6570458404074703,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6738282550366048,
            "auditor_fn_violation": 0.002293520405485281,
            "auditor_fp_violation": 0.022834605468051977,
            "ave_precision_score": 0.642652392611502,
            "fpr": 0.21405049396267836,
            "logloss": 3.268917264656682,
            "mae": 0.31148802366570955,
            "precision": 0.6733668341708543,
            "recall": 0.8357588357588358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6505829119580132,
            "auditor_fn_violation": 0.006279904306220098,
            "auditor_fp_violation": 0.01819326219877713,
            "ave_precision_score": 0.6260419895773921,
            "fpr": 0.22149122807017543,
            "logloss": 3.1496716327290173,
            "mae": 0.32084531486272877,
            "precision": 0.6570458404074703,
            "recall": 0.8181818181818182
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6719860191286524,
            "auditor_fn_violation": 0.0026997359598896404,
            "auditor_fp_violation": 0.022732494320067388,
            "ave_precision_score": 0.6416023161797937,
            "fpr": 0.21405049396267836,
            "logloss": 3.2235276640360624,
            "mae": 0.31145126803393003,
            "precision": 0.6739130434782609,
            "recall": 0.8378378378378378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7507767791424202,
            "auditor_fn_violation": 0.002392344497607671,
            "auditor_fp_violation": 0.00716840506733805,
            "ave_precision_score": 0.747464792162432,
            "fpr": 0.019736842105263157,
            "logloss": 0.7368354309518331,
            "mae": 0.4178486166444233,
            "precision": 0.9052631578947369,
            "recall": 0.36363636363636365
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7897433555210343,
            "auditor_fn_violation": 0.006734506185658776,
            "auditor_fp_violation": 0.0011819365379215272,
            "ave_precision_score": 0.7872301726903919,
            "fpr": 0.014270032930845226,
            "logloss": 0.6587399091432062,
            "mae": 0.41465941723573213,
            "precision": 0.9308510638297872,
            "recall": 0.36382536382536385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8420818095440287,
            "auditor_fn_violation": 0.009263380438411045,
            "auditor_fp_violation": 0.020166446868880635,
            "ave_precision_score": 0.8427945544055059,
            "fpr": 0.09210526315789473,
            "logloss": 0.5370619684719613,
            "mae": 0.30954630786257903,
            "precision": 0.7975903614457831,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8574147787978268,
            "auditor_fn_violation": 0.011421959830302308,
            "auditor_fp_violation": 0.01156664028795344,
            "ave_precision_score": 0.857650469850479,
            "fpr": 0.0801317233809001,
            "logloss": 0.521870904230938,
            "mae": 0.3026186958436867,
            "precision": 0.8165829145728644,
            "recall": 0.6756756756756757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 6654,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8142297418936189,
            "auditor_fn_violation": 0.006502447980416162,
            "auditor_fp_violation": 0.004915477760460377,
            "ave_precision_score": 0.8145900297298047,
            "fpr": 0.046052631578947366,
            "logloss": 0.583183348645698,
            "mae": 0.35312708958538186,
            "precision": 0.8627450980392157,
            "recall": 0.5581395348837209
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8269247475318993,
            "auditor_fn_violation": 0.0018462268736692627,
            "auditor_fp_violation": 0.00636152451943941,
            "ave_precision_score": 0.8271843336050955,
            "fpr": 0.04171240395170143,
            "logloss": 0.5822150992675674,
            "mae": 0.3506176281550697,
            "precision": 0.8745874587458746,
            "recall": 0.5509355509355509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 6654,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7933923846119765,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.666355884709201,
            "fpr": 0.48135964912280704,
            "logloss": 10.58253323574991,
            "mae": 0.48133125162699764,
            "precision": 0.518640350877193,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.8124831333481125,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6872383157962899,
            "fpr": 0.47200878155872666,
            "logloss": 10.374247827396015,
            "mae": 0.4719992932320688,
            "precision": 0.5279912184412733,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 6654,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7507767791424202,
            "auditor_fn_violation": 0.002392344497607671,
            "auditor_fp_violation": 0.00716840506733805,
            "ave_precision_score": 0.747464792162432,
            "fpr": 0.019736842105263157,
            "logloss": 0.7368354154611783,
            "mae": 0.4178486193073856,
            "precision": 0.9052631578947369,
            "recall": 0.36363636363636365
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7897433555210343,
            "auditor_fn_violation": 0.006734506185658776,
            "auditor_fp_violation": 0.0011819365379215272,
            "ave_precision_score": 0.7872301726903919,
            "fpr": 0.014270032930845226,
            "logloss": 0.6587399081800223,
            "mae": 0.41465941983309723,
            "precision": 0.9308510638297872,
            "recall": 0.36382536382536385
        }
    }
]