[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7480430866967078,
            "auditor_fn_violation": 0.02028508771929826,
            "auditor_fp_violation": 0.004733694769330737,
            "ave_precision_score": 0.7485385922642767,
            "fpr": 0.06030701754385965,
            "logloss": 1.2566980132919172,
            "mae": 0.38687515246976695,
            "precision": 0.7962962962962963,
            "recall": 0.4479166666666667
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7897900073864862,
            "auditor_fn_violation": 0.017512169591537112,
            "auditor_fp_violation": 0.0076361380231947705,
            "ave_precision_score": 0.7912275826806162,
            "fpr": 0.04171240395170143,
            "logloss": 1.0157424561941353,
            "mae": 0.3571312259820212,
            "precision": 0.8560606060606061,
            "recall": 0.4767932489451477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5825724678443509,
            "auditor_fn_violation": 0.04432565789473685,
            "auditor_fp_violation": 0.03972750162443145,
            "ave_precision_score": 0.5640121085390867,
            "fpr": 0.14692982456140352,
            "logloss": 5.3177920196103,
            "mae": 0.44123524629859195,
            "precision": 0.6298342541436464,
            "recall": 0.475
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5878141689148537,
            "auditor_fn_violation": 0.038961219413914325,
            "auditor_fp_violation": 0.04298593091806977,
            "ave_precision_score": 0.5698290803013257,
            "fpr": 0.14489571899012074,
            "logloss": 4.76849665180026,
            "mae": 0.43514062097342154,
            "precision": 0.6333333333333333,
            "recall": 0.4810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8389470989683602,
            "auditor_fn_violation": 0.00562865497076023,
            "auditor_fp_violation": 0.011437012670565306,
            "ave_precision_score": 0.8391768214196749,
            "fpr": 0.08442982456140351,
            "logloss": 0.5528312106294168,
            "mae": 0.3244182456279911,
            "precision": 0.8040712468193384,
            "recall": 0.6583333333333333
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8629317980017204,
            "auditor_fn_violation": 0.013241812447025807,
            "auditor_fp_violation": 0.011908858673673162,
            "ave_precision_score": 0.8632196372121892,
            "fpr": 0.06695938529088913,
            "logloss": 0.5009826692948103,
            "mae": 0.3015689013324449,
            "precision": 0.8455696202531645,
            "recall": 0.7046413502109705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7480740252437538,
            "auditor_fn_violation": 0.01893046418128656,
            "auditor_fp_violation": 0.00682261208576998,
            "ave_precision_score": 0.7486906736980405,
            "fpr": 0.06140350877192982,
            "logloss": 0.9409670386749718,
            "mae": 0.3822314430137186,
            "precision": 0.7992831541218638,
            "recall": 0.46458333333333335
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.798450035780947,
            "auditor_fn_violation": 0.009462407425419305,
            "auditor_fp_violation": 0.009793849392248817,
            "ave_precision_score": 0.7998465207287042,
            "fpr": 0.04500548847420417,
            "logloss": 0.8608979269459154,
            "mae": 0.35087125370068883,
            "precision": 0.844106463878327,
            "recall": 0.46835443037974683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7163145102491486,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.09795321637426901,
            "ave_precision_score": 0.5631047083459821,
            "fpr": 0.29714912280701755,
            "logloss": 13.946627735549878,
            "mae": 0.4277778416022064,
            "precision": 0.5725552050473186,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7104516701629422,
            "auditor_fn_violation": 0.09463796912559573,
            "auditor_fp_violation": 0.1002368709919695,
            "ave_precision_score": 0.5618687015189847,
            "fpr": 0.2810098792535675,
            "logloss": 13.88676309895879,
            "mae": 0.4261707291863951,
            "precision": 0.5733333333333334,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7133188275118421,
            "auditor_fn_violation": 0.08706597222222223,
            "auditor_fp_violation": 0.09868421052631579,
            "ave_precision_score": 0.5605785388295201,
            "fpr": 0.2993421052631579,
            "logloss": 13.908175398054356,
            "mae": 0.4294711126845264,
            "precision": 0.5700787401574803,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7050102256123392,
            "auditor_fn_violation": 0.09463796912559573,
            "auditor_fp_violation": 0.10266335432433994,
            "ave_precision_score": 0.5575606810244391,
            "fpr": 0.287596048298573,
            "logloss": 13.903063685191855,
            "mae": 0.43256354446226947,
            "precision": 0.5676567656765676,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8364037510388227,
            "auditor_fn_violation": 0.02339181286549707,
            "auditor_fp_violation": 0.013843201754385966,
            "ave_precision_score": 0.8366159771772819,
            "fpr": 0.07675438596491228,
            "logloss": 1.1140788839089237,
            "mae": 0.28880345838002786,
            "precision": 0.8097826086956522,
            "recall": 0.6208333333333333
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8350041645750157,
            "auditor_fn_violation": 0.010736103970691089,
            "auditor_fp_violation": 0.012740293438698647,
            "ave_precision_score": 0.8352531449200936,
            "fpr": 0.06366630076838639,
            "logloss": 1.1019965199181514,
            "mae": 0.28516863780131085,
            "precision": 0.8313953488372093,
            "recall": 0.6033755274261603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8479241280367458,
            "auditor_fn_violation": 0.014281798245614031,
            "auditor_fp_violation": 0.01613263482781027,
            "ave_precision_score": 0.8480984413424566,
            "fpr": 0.13706140350877194,
            "logloss": 0.8580536787826885,
            "mae": 0.26620077839109163,
            "precision": 0.7534516765285996,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8418175427597678,
            "auditor_fn_violation": 0.01326960218983174,
            "auditor_fp_violation": 0.014425769956318274,
            "ave_precision_score": 0.8422893762802013,
            "fpr": 0.10757409440175632,
            "logloss": 0.7313601922829133,
            "mae": 0.2610521654016486,
            "precision": 0.7883369330453563,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8687469333499136,
            "auditor_fn_violation": 0.01377467105263158,
            "auditor_fp_violation": 0.02253391000649773,
            "ave_precision_score": 0.8689200426528847,
            "fpr": 0.1600877192982456,
            "logloss": 0.5320803321019905,
            "mae": 0.27877756893836275,
            "precision": 0.7392857142857143,
            "recall": 0.8625
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8607131703036689,
            "auditor_fn_violation": 0.010532312523447596,
            "auditor_fp_violation": 0.019720828822402028,
            "ave_precision_score": 0.8620086385911507,
            "fpr": 0.12843029637760703,
            "logloss": 0.4897461275251575,
            "mae": 0.26921902464762115,
            "precision": 0.7719298245614035,
            "recall": 0.8354430379746836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.8305900264813046,
            "auditor_fn_violation": 0.005619517543859651,
            "auditor_fp_violation": 0.02727014294996753,
            "ave_precision_score": 0.830812830070181,
            "fpr": 0.2675438596491228,
            "logloss": 1.1745152945935193,
            "mae": 0.30864330484324126,
            "precision": 0.6453488372093024,
            "recall": 0.925
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.81276765604408,
            "auditor_fn_violation": 0.009490197168225212,
            "auditor_fp_violation": 0.026008083253999562,
            "ave_precision_score": 0.8134497459015535,
            "fpr": 0.2349066959385291,
            "logloss": 1.0965447564982707,
            "mae": 0.29721344384161386,
            "precision": 0.6635220125786163,
            "recall": 0.890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7967027986005291,
            "auditor_fn_violation": 0.028143274853801175,
            "auditor_fp_violation": 0.022356237816764143,
            "ave_precision_score": 0.7932804977714228,
            "fpr": 0.15899122807017543,
            "logloss": 1.392755040505118,
            "mae": 0.29179375057608725,
            "precision": 0.7238095238095238,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7778615757759905,
            "auditor_fn_violation": 0.03278263326339582,
            "auditor_fp_violation": 0.030057245916298887,
            "ave_precision_score": 0.7745158481471432,
            "fpr": 0.13062568605927552,
            "logloss": 1.5410668671892076,
            "mae": 0.2947872393383174,
            "precision": 0.746268656716418,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7721171657636994,
            "auditor_fn_violation": 0.013637609649122823,
            "auditor_fp_violation": 0.01784336419753087,
            "ave_precision_score": 0.7627391299976269,
            "fpr": 0.12938596491228072,
            "logloss": 1.9742624883893363,
            "mae": 0.31367456228618973,
            "precision": 0.7342342342342343,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7426516623289825,
            "auditor_fn_violation": 0.024985294594431873,
            "auditor_fp_violation": 0.013702346354120877,
            "ave_precision_score": 0.7310449841759503,
            "fpr": 0.1163556531284303,
            "logloss": 2.304673470167178,
            "mae": 0.3200019240273059,
            "precision": 0.7420924574209246,
            "recall": 0.6434599156118144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.705468941836896,
            "auditor_fn_violation": 0.01010827850877193,
            "auditor_fp_violation": 0.022899407082521122,
            "ave_precision_score": 0.7057498697993985,
            "fpr": 0.17653508771929824,
            "logloss": 5.088725871044776,
            "mae": 0.402444075261211,
            "precision": 0.6390134529147982,
            "recall": 0.59375
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7357039230278677,
            "auditor_fn_violation": 0.013297391932637672,
            "auditor_fp_violation": 0.009140758640265055,
            "ave_precision_score": 0.7350100370753951,
            "fpr": 0.16575192096597147,
            "logloss": 4.748104000764868,
            "mae": 0.37638466376332286,
            "precision": 0.6536697247706422,
            "recall": 0.6012658227848101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6649844601531119,
            "auditor_fn_violation": 0.044216008771929834,
            "auditor_fp_violation": 0.056101262995451616,
            "ave_precision_score": 0.5719362836629498,
            "fpr": 0.25109649122807015,
            "logloss": 8.459319248884057,
            "mae": 0.3889474497286995,
            "precision": 0.6282467532467533,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6356106957322754,
            "auditor_fn_violation": 0.05032954003344032,
            "auditor_fp_violation": 0.06574614362470392,
            "ave_precision_score": 0.5468444579541041,
            "fpr": 0.24698133918770582,
            "logloss": 9.2503262029016,
            "mae": 0.4040327473665239,
            "precision": 0.6147260273972602,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8155152482739924,
            "auditor_fn_violation": 0.009196820175438597,
            "auditor_fp_violation": 0.013980263157894739,
            "ave_precision_score": 0.8169795609027459,
            "fpr": 0.09868421052631579,
            "logloss": 0.569738826691268,
            "mae": 0.3174346042056609,
            "precision": 0.7877358490566038,
            "recall": 0.6958333333333333
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8271894076534255,
            "auditor_fn_violation": 0.011963484277953013,
            "auditor_fp_violation": 0.009439673253673012,
            "ave_precision_score": 0.8288406161146735,
            "fpr": 0.07683863885839737,
            "logloss": 0.560361848660662,
            "mae": 0.29846987609943715,
            "precision": 0.8275862068965517,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7491106993187936,
            "auditor_fn_violation": 0.01837993421052632,
            "auditor_fp_violation": 0.008680555555555556,
            "ave_precision_score": 0.7500007379027879,
            "fpr": 0.08662280701754387,
            "logloss": 1.9210346696311469,
            "mae": 0.3702473081076821,
            "precision": 0.7690058479532164,
            "recall": 0.5479166666666667
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7907703909063942,
            "auditor_fn_violation": 0.018243966152093272,
            "auditor_fp_violation": 0.007588412160549802,
            "ave_precision_score": 0.7911233547158079,
            "fpr": 0.06256860592755215,
            "logloss": 1.6515637397910305,
            "mae": 0.3426688191783871,
            "precision": 0.8207547169811321,
            "recall": 0.5506329113924051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8690469555342422,
            "auditor_fn_violation": 0.01399168494152047,
            "auditor_fp_violation": 0.023018701267056536,
            "ave_precision_score": 0.8692194319656414,
            "fpr": 0.1611842105263158,
            "logloss": 0.5318700314070224,
            "mae": 0.27898967768880956,
            "precision": 0.7384341637010676,
            "recall": 0.8645833333333334
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.860791656481122,
            "auditor_fn_violation": 0.010083045014751723,
            "auditor_fp_violation": 0.019017500320265664,
            "ave_precision_score": 0.8620840181224018,
            "fpr": 0.12733260153677278,
            "logloss": 0.4898106041063746,
            "mae": 0.2695117360160084,
            "precision": 0.7738791423001949,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8530593902236142,
            "auditor_fn_violation": 0.005710891812865498,
            "auditor_fp_violation": 0.019777452891487985,
            "ave_precision_score": 0.8532937702801203,
            "fpr": 0.14035087719298245,
            "logloss": 0.5637129835092785,
            "mae": 0.2820446167417741,
            "precision": 0.7490196078431373,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8572328776736577,
            "auditor_fn_violation": 0.013825397045950339,
            "auditor_fp_violation": 0.0178092824290957,
            "ave_precision_score": 0.8584831372069651,
            "fpr": 0.10976948408342481,
            "logloss": 0.517243068574582,
            "mae": 0.27020009562237757,
            "precision": 0.7858672376873662,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8462205564625932,
            "auditor_fn_violation": 0.009713084795321639,
            "auditor_fp_violation": 0.020559210526315794,
            "ave_precision_score": 0.8464437583822314,
            "fpr": 0.16776315789473684,
            "logloss": 0.7021465938989162,
            "mae": 0.27271236817248384,
            "precision": 0.7223230490018149,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8373658417194647,
            "auditor_fn_violation": 0.010666629613676261,
            "auditor_fp_violation": 0.01635741144968564,
            "ave_precision_score": 0.8379423425871566,
            "fpr": 0.14270032930845225,
            "logloss": 0.6623332202550896,
            "mae": 0.267249422856164,
            "precision": 0.7445972495088409,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8543651410999815,
            "auditor_fn_violation": 0.014119608918128662,
            "auditor_fp_violation": 0.0224729938271605,
            "ave_precision_score": 0.8545717689338734,
            "fpr": 0.13267543859649122,
            "logloss": 0.6963738428652929,
            "mae": 0.26493042035816095,
            "precision": 0.7570281124497992,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.838104222516872,
            "auditor_fn_violation": 0.013899503026766158,
            "auditor_fp_violation": 0.01582740318557574,
            "ave_precision_score": 0.8386152781790777,
            "fpr": 0.10976948408342481,
            "logloss": 0.719243715584657,
            "mae": 0.2647036400815171,
            "precision": 0.7816593886462883,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.6231964780642323,
            "auditor_fn_violation": 0.002784630847953223,
            "auditor_fp_violation": 0.012759401397011046,
            "ave_precision_score": 0.5661499884085874,
            "fpr": 0.17653508771929824,
            "logloss": 8.548230071045625,
            "mae": 0.4923217589258447,
            "precision": 0.5373563218390804,
            "recall": 0.38958333333333334
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.635343351818804,
            "auditor_fn_violation": 0.006428693835771901,
            "auditor_fp_violation": 0.009449720803703527,
            "ave_precision_score": 0.577611131789883,
            "fpr": 0.1756311745334797,
            "logloss": 7.963195945248557,
            "mae": 0.4776849823156004,
            "precision": 0.550561797752809,
            "recall": 0.41350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8450902866965355,
            "auditor_fn_violation": 0.027809758771929823,
            "auditor_fp_violation": 0.025003553443794676,
            "ave_precision_score": 0.8453268089541353,
            "fpr": 0.1524122807017544,
            "logloss": 0.5814256372316556,
            "mae": 0.3119370144394404,
            "precision": 0.7311411992263056,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8620039837449474,
            "auditor_fn_violation": 0.02564298517417222,
            "auditor_fp_violation": 0.024495926974406387,
            "ave_precision_score": 0.8623537528703966,
            "fpr": 0.1207464324917673,
            "logloss": 0.511402655326965,
            "mae": 0.29205717948710336,
            "precision": 0.7731958762886598,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8395111344891507,
            "auditor_fn_violation": 0.0075886330409356715,
            "auditor_fp_violation": 0.016927083333333336,
            "ave_precision_score": 0.8397337382831969,
            "fpr": 0.10197368421052631,
            "logloss": 0.553171209864636,
            "mae": 0.31924269824013574,
            "precision": 0.786697247706422,
            "recall": 0.7145833333333333
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8623055502230587,
            "auditor_fn_violation": 0.008600925398435436,
            "auditor_fp_violation": 0.01656589811281892,
            "ave_precision_score": 0.8628597410193238,
            "fpr": 0.0801317233809001,
            "logloss": 0.49290456521668113,
            "mae": 0.296036473898121,
            "precision": 0.8253588516746412,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6651977972960756,
            "auditor_fn_violation": 0.04529650950292398,
            "auditor_fp_violation": 0.05398696393762183,
            "ave_precision_score": 0.5724944311470292,
            "fpr": 0.23903508771929824,
            "logloss": 8.427125943073717,
            "mae": 0.3878534526937935,
            "precision": 0.6336134453781512,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.6351523887772179,
            "auditor_fn_violation": 0.050160485764704256,
            "auditor_fp_violation": 0.06565822756193687,
            "ave_precision_score": 0.5463863454693673,
            "fpr": 0.23929747530186607,
            "logloss": 9.256143488200674,
            "mae": 0.40338164829300427,
            "precision": 0.6155202821869489,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.856522786713437,
            "auditor_fn_violation": 0.01904011330409357,
            "auditor_fp_violation": 0.03169925682261209,
            "ave_precision_score": 0.8567385787037162,
            "fpr": 0.17653508771929824,
            "logloss": 0.7140202926310916,
            "mae": 0.2645367515689813,
            "precision": 0.7195121951219512,
            "recall": 0.8604166666666667
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8481981750032643,
            "auditor_fn_violation": 0.017729855910183553,
            "auditor_fp_violation": 0.024234690673612874,
            "ave_precision_score": 0.8485189526695109,
            "fpr": 0.15477497255762898,
            "logloss": 0.6965376410410488,
            "mae": 0.2628581250183734,
            "precision": 0.7344632768361582,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6269728168487627,
            "auditor_fn_violation": 0.028013066520467846,
            "auditor_fp_violation": 0.023178606237816767,
            "ave_precision_score": 0.6280822486588048,
            "fpr": 0.09210526315789473,
            "logloss": 6.058037910936342,
            "mae": 0.45342399105728587,
            "precision": 0.6806083650190115,
            "recall": 0.3729166666666667
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6560295600547674,
            "auditor_fn_violation": 0.03001755385420575,
            "auditor_fp_violation": 0.024104072523216124,
            "ave_precision_score": 0.6568240136418366,
            "fpr": 0.0889132821075741,
            "logloss": 5.400496546341828,
            "mae": 0.43963150433691095,
            "precision": 0.7011070110701108,
            "recall": 0.4008438818565401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6176621308404783,
            "auditor_fn_violation": 0.04314007675438597,
            "auditor_fp_violation": 0.05893640350877193,
            "ave_precision_score": 0.5826906810025656,
            "fpr": 0.26535087719298245,
            "logloss": 4.532304224316642,
            "mae": 0.3708428132130178,
            "precision": 0.6248062015503876,
            "recall": 0.8395833333333333
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.612895875191496,
            "auditor_fn_violation": 0.04959079603718268,
            "auditor_fp_violation": 0.05716051212362506,
            "ave_precision_score": 0.5793066625150949,
            "fpr": 0.2414928649835346,
            "logloss": 4.723737842997211,
            "mae": 0.358401609503758,
            "precision": 0.6339434276206323,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7361049407869296,
            "auditor_fn_violation": 0.018832236842105263,
            "auditor_fp_violation": 0.005675357374918782,
            "ave_precision_score": 0.7374651418829817,
            "fpr": 0.09978070175438597,
            "logloss": 1.5662397907002847,
            "mae": 0.30888489078225173,
            "precision": 0.7707808564231738,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7448480608106457,
            "auditor_fn_violation": 0.01683132089279181,
            "auditor_fp_violation": 0.0004144614387589286,
            "ave_precision_score": 0.7442293967624267,
            "fpr": 0.08232711306256861,
            "logloss": 1.4060861293278877,
            "mae": 0.3016200887815085,
            "precision": 0.7972972972972973,
            "recall": 0.6223628691983122
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8589023059066934,
            "auditor_fn_violation": 0.018537554824561406,
            "auditor_fp_violation": 0.022691276803118915,
            "ave_precision_score": 0.859096956157572,
            "fpr": 0.14473684210526316,
            "logloss": 0.6639065973309094,
            "mae": 0.26220872262950445,
            "precision": 0.7485714285714286,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8434098671914227,
            "auditor_fn_violation": 0.015013408550903868,
            "auditor_fp_violation": 0.017924829254446675,
            "ave_precision_score": 0.8439022306573113,
            "fpr": 0.1207464324917673,
            "logloss": 0.6731637760985261,
            "mae": 0.262234656294493,
            "precision": 0.7703549060542797,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8439016669247181,
            "auditor_fn_violation": 0.011613669590643281,
            "auditor_fp_violation": 0.013036062378167646,
            "ave_precision_score": 0.8441299362825485,
            "fpr": 0.1118421052631579,
            "logloss": 0.6363361378570489,
            "mae": 0.275795766691794,
            "precision": 0.7811158798283262,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8379903200538212,
            "auditor_fn_violation": 0.006519010499891157,
            "auditor_fp_violation": 0.005606532917029847,
            "ave_precision_score": 0.8385556594839592,
            "fpr": 0.09659714599341383,
            "logloss": 0.6409772927810315,
            "mae": 0.2696722783937089,
            "precision": 0.7986270022883295,
            "recall": 0.7362869198312236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7349488044891896,
            "auditor_fn_violation": 0.020467836257309944,
            "auditor_fp_violation": 0.0065332602339181305,
            "ave_precision_score": 0.7361714916501885,
            "fpr": 0.09868421052631579,
            "logloss": 1.5580236706482855,
            "mae": 0.3070838193863623,
            "precision": 0.7738693467336684,
            "recall": 0.6416666666666667
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7432362554565113,
            "auditor_fn_violation": 0.010893579179924699,
            "auditor_fp_violation": 0.0066665494452496435,
            "ave_precision_score": 0.7425894549935447,
            "fpr": 0.0845225027442371,
            "logloss": 1.4218421644554975,
            "mae": 0.2990695794379564,
            "precision": 0.7957559681697612,
            "recall": 0.6329113924050633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8389036190862356,
            "auditor_fn_violation": 0.0385530884502924,
            "auditor_fp_violation": 0.025391894087069534,
            "ave_precision_score": 0.8392117298313582,
            "fpr": 0.1206140350877193,
            "logloss": 0.604637998898252,
            "mae": 0.31145540132834476,
            "precision": 0.7592997811816192,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8546867271798476,
            "auditor_fn_violation": 0.03493633833085542,
            "auditor_fp_violation": 0.028062807235240777,
            "ave_precision_score": 0.8550193229052014,
            "fpr": 0.09989023051591657,
            "logloss": 0.5382121186898282,
            "mae": 0.2938697928862808,
            "precision": 0.7908045977011494,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7339892795874184,
            "auditor_fn_violation": 0.016922514619883044,
            "auditor_fp_violation": 0.006051007147498374,
            "ave_precision_score": 0.7353908334212157,
            "fpr": 0.10087719298245613,
            "logloss": 1.5608508798982477,
            "mae": 0.30641178302916006,
            "precision": 0.7733990147783252,
            "recall": 0.6541666666666667
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.742514894733159,
            "auditor_fn_violation": 0.007929339947292124,
            "auditor_fp_violation": 0.0073874611599394156,
            "ave_precision_score": 0.7418629024968751,
            "fpr": 0.0889132821075741,
            "logloss": 1.4220593813747844,
            "mae": 0.2980402902044712,
            "precision": 0.7885117493472585,
            "recall": 0.6371308016877637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8668714124739887,
            "auditor_fn_violation": 0.01331323099415205,
            "auditor_fp_violation": 0.015371182586094868,
            "ave_precision_score": 0.8670612573582328,
            "fpr": 0.14912280701754385,
            "logloss": 0.7546955168423408,
            "mae": 0.28351937724009824,
            "precision": 0.7481481481481481,
            "recall": 0.8416666666666667
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.863478423411768,
            "auditor_fn_violation": 0.012783281690727955,
            "auditor_fp_violation": 0.014473495818963246,
            "ave_precision_score": 0.8640738063550469,
            "fpr": 0.13062568605927552,
            "logloss": 0.5922812783046328,
            "mae": 0.27290390016414984,
            "precision": 0.7715930902111324,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8422659045605433,
            "auditor_fn_violation": 0.01411732456140351,
            "auditor_fp_violation": 0.024716739766081876,
            "ave_precision_score": 0.8424939758660118,
            "fpr": 0.16776315789473684,
            "logloss": 0.7877691942768871,
            "mae": 0.269350526940082,
            "precision": 0.7213114754098361,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8292505113478481,
            "auditor_fn_violation": 0.018762708017803966,
            "auditor_fp_violation": 0.018876834619838384,
            "ave_precision_score": 0.8301612815440278,
            "fpr": 0.14050493962678376,
            "logloss": 0.7736196002795498,
            "mae": 0.26911563917731,
            "precision": 0.7429718875502008,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8440333799858383,
            "auditor_fn_violation": 0.00879934210526316,
            "auditor_fp_violation": 0.006556103801169591,
            "ave_precision_score": 0.8442518032592028,
            "fpr": 0.049342105263157895,
            "logloss": 0.6208047480838397,
            "mae": 0.33228148825525605,
            "precision": 0.8557692307692307,
            "recall": 0.55625
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8639972994809304,
            "auditor_fn_violation": 0.007656074143033818,
            "auditor_fp_violation": 0.0035945110234183284,
            "ave_precision_score": 0.8643966259579886,
            "fpr": 0.036223929747530186,
            "logloss": 0.5716785894956553,
            "mae": 0.3125038869708621,
            "precision": 0.8942307692307693,
            "recall": 0.5886075949367089
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8002347167445626,
            "auditor_fn_violation": 0.007990679824561406,
            "auditor_fp_violation": 0.013569078947368423,
            "ave_precision_score": 0.7917660138468146,
            "fpr": 0.1337719298245614,
            "logloss": 1.4234710083970477,
            "mae": 0.27138689675224753,
            "precision": 0.7579365079365079,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7932873105254614,
            "auditor_fn_violation": 0.012208960339405394,
            "auditor_fp_violation": 0.01117287563393761,
            "ave_precision_score": 0.7839544398563052,
            "fpr": 0.11525795828759605,
            "logloss": 1.4988372298901913,
            "mae": 0.2675150996801171,
            "precision": 0.7761194029850746,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8368549620722386,
            "auditor_fn_violation": 0.036211622807017556,
            "auditor_fp_violation": 0.022254710851202078,
            "ave_precision_score": 0.8373844642612823,
            "fpr": 0.1074561403508772,
            "logloss": 0.6097603912666462,
            "mae": 0.3106392431498319,
            "precision": 0.7772727272727272,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8568210737185443,
            "auditor_fn_violation": 0.03286600249181361,
            "auditor_fp_violation": 0.025892536428648583,
            "ave_precision_score": 0.857111625071731,
            "fpr": 0.09440175631174534,
            "logloss": 0.5339640781473489,
            "mae": 0.29304794191766703,
            "precision": 0.7981220657276995,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8418685092825369,
            "auditor_fn_violation": 0.00933845029239766,
            "auditor_fp_violation": 0.02124705571799871,
            "ave_precision_score": 0.8420966160953807,
            "fpr": 0.1699561403508772,
            "logloss": 0.7379951474382094,
            "mae": 0.2734741710567801,
            "precision": 0.7197106690777577,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8320847176139055,
            "auditor_fn_violation": 0.009383669820802477,
            "auditor_fp_violation": 0.012069619474161472,
            "ave_precision_score": 0.8326874354627959,
            "fpr": 0.1394072447859495,
            "logloss": 0.6996548952773728,
            "mae": 0.2686380649285674,
            "precision": 0.7475149105367793,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7410271422543451,
            "auditor_fn_violation": 0.03199698464912281,
            "auditor_fp_violation": 0.02105669265756985,
            "ave_precision_score": 0.7426472538993487,
            "fpr": 0.0800438596491228,
            "logloss": 0.9438221106686191,
            "mae": 0.3733907290352483,
            "precision": 0.7645161290322581,
            "recall": 0.49375
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7901066693352137,
            "auditor_fn_violation": 0.023600439077936335,
            "auditor_fp_violation": 0.0110372337085256,
            "ave_precision_score": 0.7906354587115486,
            "fpr": 0.052689352360043906,
            "logloss": 0.8403418577684216,
            "mae": 0.3453424935030166,
            "precision": 0.8339100346020761,
            "recall": 0.5084388185654009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8618523005070428,
            "auditor_fn_violation": 0.018640350877192985,
            "auditor_fp_violation": 0.019889132553606245,
            "ave_precision_score": 0.8620446390869823,
            "fpr": 0.12171052631578948,
            "logloss": 0.6431062959897793,
            "mae": 0.26316559962152336,
            "precision": 0.7701863354037267,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8466054556992942,
            "auditor_fn_violation": 0.015298253414664653,
            "auditor_fp_violation": 0.01618911498667444,
            "ave_precision_score": 0.8470949463497155,
            "fpr": 0.09879253567508232,
            "logloss": 0.6609681196421253,
            "mae": 0.2621205117908351,
            "precision": 0.7982062780269058,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6645744178009166,
            "auditor_fn_violation": 0.04686357821637428,
            "auditor_fp_violation": 0.05554794103313842,
            "ave_precision_score": 0.5715670248782269,
            "fpr": 0.23135964912280702,
            "logloss": 8.465953185058966,
            "mae": 0.39018737380913654,
            "precision": 0.6336805555555556,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6335119475136174,
            "auditor_fn_violation": 0.05104975753449402,
            "auditor_fp_violation": 0.06757479773025846,
            "ave_precision_score": 0.5447463645636637,
            "fpr": 0.2327113062568606,
            "logloss": 9.276550746434632,
            "mae": 0.408226025089712,
            "precision": 0.6159420289855072,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8278444624379233,
            "auditor_fn_violation": 0.007200292397660817,
            "auditor_fp_violation": 0.004913905133203381,
            "ave_precision_score": 0.827231557856601,
            "fpr": 0.06030701754385965,
            "logloss": 0.6559981283537195,
            "mae": 0.32988657657270987,
            "precision": 0.8377581120943953,
            "recall": 0.5916666666666667
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8678321214616079,
            "auditor_fn_violation": 0.009728725793976116,
            "auditor_fp_violation": 0.010688081344965048,
            "ave_precision_score": 0.8680324208013467,
            "fpr": 0.050493962678375415,
            "logloss": 0.5622444850015724,
            "mae": 0.30309382827444414,
            "precision": 0.8696883852691218,
            "recall": 0.6476793248945147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.844867931937463,
            "auditor_fn_violation": 0.009105445906432749,
            "auditor_fp_violation": 0.01488892949967512,
            "ave_precision_score": 0.8450971004714901,
            "fpr": 0.10416666666666667,
            "logloss": 0.6474385436830419,
            "mae": 0.2814135974453847,
            "precision": 0.7902869757174393,
            "recall": 0.7458333333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8411984218541384,
            "auditor_fn_violation": 0.01404539917649729,
            "auditor_fp_violation": 0.008804165714242656,
            "ave_precision_score": 0.8416980306991948,
            "fpr": 0.09220636663007684,
            "logloss": 0.6342755597524778,
            "mae": 0.2736058037218586,
            "precision": 0.8023529411764706,
            "recall": 0.7194092827004219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7289753575295919,
            "auditor_fn_violation": 0.033931834795321636,
            "auditor_fp_violation": 0.05216709307992203,
            "ave_precision_score": 0.721407835711876,
            "fpr": 0.2532894736842105,
            "logloss": 2.5304748180517667,
            "mae": 0.3560025491589435,
            "precision": 0.6304,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7176051885294683,
            "auditor_fn_violation": 0.03677509297984781,
            "auditor_fp_violation": 0.0523929496341436,
            "ave_precision_score": 0.7109380667205976,
            "fpr": 0.21185510428100987,
            "logloss": 2.698351737202389,
            "mae": 0.343925309166732,
            "precision": 0.6596119929453262,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7133299988846517,
            "auditor_fn_violation": 0.08706597222222223,
            "auditor_fp_violation": 0.09868421052631579,
            "ave_precision_score": 0.5605897080310602,
            "fpr": 0.2993421052631579,
            "logloss": 13.889874037547449,
            "mae": 0.4291002275053767,
            "precision": 0.5700787401574803,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7056111664634658,
            "auditor_fn_violation": 0.09463796912559573,
            "auditor_fp_violation": 0.10266335432433994,
            "ave_precision_score": 0.5589624324756306,
            "fpr": 0.287596048298573,
            "logloss": 13.83702751419361,
            "mae": 0.43231032111907763,
            "precision": 0.5676567656765676,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.843683391093486,
            "auditor_fn_violation": 0.012490862573099419,
            "auditor_fp_violation": 0.029285453216374272,
            "ave_precision_score": 0.843915152876773,
            "fpr": 0.16776315789473684,
            "logloss": 0.8386988751617096,
            "mae": 0.2684059426733905,
            "precision": 0.720292504570384,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8307786324098455,
            "auditor_fn_violation": 0.015585414090325933,
            "auditor_fp_violation": 0.022021717779390975,
            "ave_precision_score": 0.8314130119954326,
            "fpr": 0.13721185510428102,
            "logloss": 0.754105750426181,
            "mae": 0.2672042325024771,
            "precision": 0.7504990019960079,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8453907591876264,
            "auditor_fn_violation": 0.015497076023391815,
            "auditor_fp_violation": 0.011939571150097467,
            "ave_precision_score": 0.8455924514697668,
            "fpr": 0.11513157894736842,
            "logloss": 0.7887522888386209,
            "mae": 0.27952161245414037,
            "precision": 0.7661469933184856,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.828501895774854,
            "auditor_fn_violation": 0.019188817407494892,
            "auditor_fp_violation": 0.01565659483505691,
            "ave_precision_score": 0.8289927228524101,
            "fpr": 0.09330406147091108,
            "logloss": 0.8389665260110203,
            "mae": 0.27982509626348206,
            "precision": 0.7906403940886699,
            "recall": 0.6772151898734177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8598252473091041,
            "auditor_fn_violation": 0.018407346491228067,
            "auditor_fp_violation": 0.01812256335282651,
            "ave_precision_score": 0.8600217543061692,
            "fpr": 0.12938596491228072,
            "logloss": 0.657221972739803,
            "mae": 0.26157822504125217,
            "precision": 0.7620967741935484,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8435582707688902,
            "auditor_fn_violation": 0.01609489270843465,
            "auditor_fp_violation": 0.014465960156440359,
            "ave_precision_score": 0.8440365308277042,
            "fpr": 0.10537870472008781,
            "logloss": 0.6791602078175003,
            "mae": 0.2625675042631176,
            "precision": 0.788546255506608,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8408028526140605,
            "auditor_fn_violation": 0.005733735380116971,
            "auditor_fp_violation": 0.008436890838206632,
            "ave_precision_score": 0.8410362354835923,
            "fpr": 0.09539473684210527,
            "logloss": 0.5538897748647151,
            "mae": 0.3193194491089487,
            "precision": 0.7918660287081339,
            "recall": 0.6895833333333333
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8639141030762341,
            "auditor_fn_violation": 0.013755922688935511,
            "auditor_fp_violation": 0.013350682103052703,
            "ave_precision_score": 0.8642054692602731,
            "fpr": 0.07683863885839737,
            "logloss": 0.4965144863030288,
            "mae": 0.29846827063899134,
            "precision": 0.8284313725490197,
            "recall": 0.7130801687763713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7191875833177457,
            "auditor_fn_violation": 0.01446683114035088,
            "auditor_fp_violation": 0.0070053606237816795,
            "ave_precision_score": 0.7203497117929964,
            "fpr": 0.09649122807017543,
            "logloss": 1.5393581528657632,
            "mae": 0.32348898855686875,
            "precision": 0.7714285714285715,
            "recall": 0.61875
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.715314720299367,
            "auditor_fn_violation": 0.013478025260876214,
            "auditor_fp_violation": 0.007430163247569124,
            "ave_precision_score": 0.7145947889276564,
            "fpr": 0.08562019758507135,
            "logloss": 1.448302441572765,
            "mae": 0.32219040983610964,
            "precision": 0.7880434782608695,
            "recall": 0.6118143459915611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8141912160613696,
            "auditor_fn_violation": 0.009587445175438594,
            "auditor_fp_violation": 0.013112207602339184,
            "ave_precision_score": 0.8125543210672833,
            "fpr": 0.13815789473684212,
            "logloss": 0.9445749177901097,
            "mae": 0.27265034726947013,
            "precision": 0.7524557956777996,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8089897626033837,
            "auditor_fn_violation": 0.009724094170175127,
            "auditor_fp_violation": 0.011007091058434046,
            "ave_precision_score": 0.8067128800856852,
            "fpr": 0.1163556531284303,
            "logloss": 0.9935933398090462,
            "mae": 0.26755912019961164,
            "precision": 0.7749469214437368,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 28699,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8248099043780489,
            "auditor_fn_violation": 0.00912828947368422,
            "auditor_fp_violation": 0.016127558479532164,
            "ave_precision_score": 0.8251196401022489,
            "fpr": 0.1074561403508772,
            "logloss": 0.6583929832260644,
            "mae": 0.31666998058911455,
            "precision": 0.7841409691629956,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8508922448162453,
            "auditor_fn_violation": 0.00981904245809538,
            "auditor_fp_violation": 0.009040283139959865,
            "ave_precision_score": 0.8514401965856031,
            "fpr": 0.09330406147091108,
            "logloss": 0.49955960413484246,
            "mae": 0.2945086026060087,
            "precision": 0.8106904231625836,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8606175806266747,
            "auditor_fn_violation": 0.016365131578947374,
            "auditor_fp_violation": 0.018206323099415205,
            "ave_precision_score": 0.8608518772777467,
            "fpr": 0.1524122807017544,
            "logloss": 0.5636580824116958,
            "mae": 0.2765269800686762,
            "precision": 0.741635687732342,
            "recall": 0.83125
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8691535083176138,
            "auditor_fn_violation": 0.013070442366389236,
            "auditor_fp_violation": 0.019642960309665496,
            "ave_precision_score": 0.869373116685649,
            "fpr": 0.12623490669593854,
            "logloss": 0.5133468199492488,
            "mae": 0.2678563991662696,
            "precision": 0.7648261758691206,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.624648968173994,
            "auditor_fn_violation": 0.02639117324561404,
            "auditor_fp_violation": 0.05206302794022093,
            "ave_precision_score": 0.6114336326200779,
            "fpr": 0.21929824561403508,
            "logloss": 4.358104061787825,
            "mae": 0.3547603580759811,
            "precision": 0.6447602131438721,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.5978058159744546,
            "auditor_fn_violation": 0.026983840264558356,
            "auditor_fp_violation": 0.05200109518295333,
            "ave_precision_score": 0.5786195107216956,
            "fpr": 0.21405049396267836,
            "logloss": 4.772170417557203,
            "mae": 0.35609456235783277,
            "precision": 0.6473779385171791,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8453092115329615,
            "auditor_fn_violation": 0.013212719298245617,
            "auditor_fp_violation": 0.027851384827810275,
            "ave_precision_score": 0.845535333008319,
            "fpr": 0.1699561403508772,
            "logloss": 0.8350756067800104,
            "mae": 0.2685124522567882,
            "precision": 0.7176684881602914,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8329756780472948,
            "auditor_fn_violation": 0.015997628608613895,
            "auditor_fp_violation": 0.02032116993672556,
            "ave_precision_score": 0.8336954177205986,
            "fpr": 0.13830954994511527,
            "logloss": 0.7482980652828796,
            "mae": 0.26698007981612415,
            "precision": 0.7495029821073559,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8269278988187028,
            "auditor_fn_violation": 0.009662828947368422,
            "auditor_fp_violation": 0.009147579597141006,
            "ave_precision_score": 0.8257439871282183,
            "fpr": 0.12938596491228072,
            "logloss": 0.847355031759605,
            "mae": 0.2747584325536656,
            "precision": 0.7658730158730159,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8082406496354713,
            "auditor_fn_violation": 0.02196779168808793,
            "auditor_fp_violation": 0.01767112861617606,
            "ave_precision_score": 0.8094444019241768,
            "fpr": 0.10976948408342481,
            "logloss": 0.8759220106985757,
            "mae": 0.2759806152727542,
            "precision": 0.7816593886462883,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8427074108454666,
            "auditor_fn_violation": 0.02557337353801171,
            "auditor_fp_violation": 0.014132553606237814,
            "ave_precision_score": 0.8429325732686417,
            "fpr": 0.10526315789473684,
            "logloss": 0.561924196852002,
            "mae": 0.3116173595786804,
            "precision": 0.7803203661327232,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8645946791120004,
            "auditor_fn_violation": 0.02482318776139727,
            "auditor_fp_violation": 0.01772136636632865,
            "ave_precision_score": 0.8648543126421151,
            "fpr": 0.07793633369923161,
            "logloss": 0.5024565788319684,
            "mae": 0.29440838351214976,
            "precision": 0.8242574257425742,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7159578260661588,
            "auditor_fn_violation": 0.086328125,
            "auditor_fp_violation": 0.09795321637426901,
            "ave_precision_score": 0.5632861098279355,
            "fpr": 0.29714912280701755,
            "logloss": 13.908482859746215,
            "mae": 0.42756233421414114,
            "precision": 0.5725552050473186,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7090304350079976,
            "auditor_fn_violation": 0.09463796912559573,
            "auditor_fp_violation": 0.10133456583280374,
            "ave_precision_score": 0.5608292217939786,
            "fpr": 0.2810098792535675,
            "logloss": 13.870739309305913,
            "mae": 0.42613418861107066,
            "precision": 0.5733333333333334,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8482858543696583,
            "auditor_fn_violation": 0.017288011695906432,
            "auditor_fp_violation": 0.009944566276803119,
            "ave_precision_score": 0.848494256509671,
            "fpr": 0.08223684210526316,
            "logloss": 0.554397739225009,
            "mae": 0.30854512937252077,
            "precision": 0.8138957816377171,
            "recall": 0.6833333333333333
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8702136594166769,
            "auditor_fn_violation": 0.013723501322328597,
            "auditor_fp_violation": 0.013265277927793284,
            "ave_precision_score": 0.8704118016972908,
            "fpr": 0.06695938529088913,
            "logloss": 0.4958972121825288,
            "mae": 0.29082242242012296,
            "precision": 0.8419689119170984,
            "recall": 0.6856540084388185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 28699,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8514379447813654,
            "auditor_fn_violation": 0.018743146929824567,
            "auditor_fp_violation": 0.020579515919428214,
            "ave_precision_score": 0.851635415495523,
            "fpr": 0.1524122807017544,
            "logloss": 0.7165472064465955,
            "mae": 0.27160804732928806,
            "precision": 0.7347328244274809,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8367672875706014,
            "auditor_fn_violation": 0.01961492679718583,
            "auditor_fp_violation": 0.019836375647752993,
            "ave_precision_score": 0.8373321049758268,
            "fpr": 0.12184412733260154,
            "logloss": 0.7294185732179724,
            "mae": 0.27044500892003714,
            "precision": 0.7653276955602537,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8220311822313445,
            "auditor_fn_violation": 0.015419407894736843,
            "auditor_fp_violation": 0.01690677794022092,
            "ave_precision_score": 0.8202657067233856,
            "fpr": 0.14583333333333334,
            "logloss": 0.9006556723857052,
            "mae": 0.27032247271856985,
            "precision": 0.7481060606060606,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8110154849952051,
            "auditor_fn_violation": 0.022421690820584792,
            "auditor_fp_violation": 0.023079222420103143,
            "ave_precision_score": 0.8122052054361318,
            "fpr": 0.12184412733260154,
            "logloss": 0.8806183661192772,
            "mae": 0.27143287143657435,
            "precision": 0.7663157894736842,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.7146955714386904,
            "auditor_fn_violation": 0.08706597222222223,
            "auditor_fp_violation": 0.09868421052631579,
            "ave_precision_score": 0.5615677204196132,
            "fpr": 0.2993421052631579,
            "logloss": 13.926785095035775,
            "mae": 0.4295092078636573,
            "precision": 0.5700787401574803,
            "recall": 0.7541666666666667
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7051131661948473,
            "auditor_fn_violation": 0.09463796912559573,
            "auditor_fp_violation": 0.10266335432433994,
            "ave_precision_score": 0.5575519672551434,
            "fpr": 0.287596048298573,
            "logloss": 13.93024760623195,
            "mae": 0.4326682917931525,
            "precision": 0.5676567656765676,
            "recall": 0.7257383966244726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.859186009825934,
            "auditor_fn_violation": 0.027515076754385966,
            "auditor_fp_violation": 0.019097222222222227,
            "ave_precision_score": 0.8594064622582821,
            "fpr": 0.13815789473684212,
            "logloss": 0.5418578621042881,
            "mae": 0.30278240839650983,
            "precision": 0.7534246575342466,
            "recall": 0.8020833333333334
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8735250469650603,
            "auditor_fn_violation": 0.01660437132654338,
            "auditor_fp_violation": 0.02275267704411126,
            "ave_precision_score": 0.8742078130514996,
            "fpr": 0.10647639956092206,
            "logloss": 0.4655668588668069,
            "mae": 0.2825862320435317,
            "precision": 0.7983367983367984,
            "recall": 0.810126582278481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8416453736167728,
            "auditor_fn_violation": 0.007903874269005852,
            "auditor_fp_violation": 0.008436890838206628,
            "ave_precision_score": 0.8418818957370351,
            "fpr": 0.0712719298245614,
            "logloss": 0.581193513016319,
            "mae": 0.31634088906241487,
            "precision": 0.8194444444444444,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8627829970992071,
            "auditor_fn_violation": 0.014436771387680809,
            "auditor_fp_violation": 0.008296764437701424,
            "ave_precision_score": 0.8633258135959919,
            "fpr": 0.05598243688254665,
            "logloss": 0.5254780958989738,
            "mae": 0.29554463319394036,
            "precision": 0.8591160220994475,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.6659296525068797,
            "auditor_fn_violation": 0.0475717288011696,
            "auditor_fp_violation": 0.05548702485380117,
            "ave_precision_score": 0.5732259905994915,
            "fpr": 0.24013157894736842,
            "logloss": 8.424607921623487,
            "mae": 0.38740851093296025,
            "precision": 0.6337792642140468,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6363365141763162,
            "auditor_fn_violation": 0.053648098486848504,
            "auditor_fp_violation": 0.07100101229066558,
            "ave_precision_score": 0.5475700789792418,
            "fpr": 0.24039517014270034,
            "logloss": 9.2460350884442,
            "mae": 0.40109677710130803,
            "precision": 0.6137566137566137,
            "recall": 0.7341772151898734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8166450800391889,
            "auditor_fn_violation": 0.005436769005847958,
            "auditor_fp_violation": 0.027178768680961665,
            "ave_precision_score": 0.8170165756399377,
            "fpr": 0.15899122807017543,
            "logloss": 0.8172054356232091,
            "mae": 0.2778174609956121,
            "precision": 0.7238095238095238,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8126633227793207,
            "auditor_fn_violation": 0.013109811168697636,
            "auditor_fp_violation": 0.016151436674059994,
            "ave_precision_score": 0.814099748188412,
            "fpr": 0.12952799121844127,
            "logloss": 0.7240241302551854,
            "mae": 0.27670270174092976,
            "precision": 0.7536534446764092,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8421940180251655,
            "auditor_fn_violation": 0.004495614035087721,
            "auditor_fp_violation": 0.009106968810916181,
            "ave_precision_score": 0.8424163011855621,
            "fpr": 0.08662280701754387,
            "logloss": 0.5536116157715276,
            "mae": 0.32151342950620393,
            "precision": 0.8039702233250621,
            "recall": 0.675
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8652828674469524,
            "auditor_fn_violation": 0.01235254067723603,
            "auditor_fp_violation": 0.011162828083907091,
            "ave_precision_score": 0.8656721081286305,
            "fpr": 0.07135016465422613,
            "logloss": 0.495416071275318,
            "mae": 0.2991546833041481,
            "precision": 0.8370927318295739,
            "recall": 0.7046413502109705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8362655123321217,
            "auditor_fn_violation": 0.009409265350877194,
            "auditor_fp_violation": 0.01967592592592593,
            "ave_precision_score": 0.8365933497966974,
            "fpr": 0.17105263157894737,
            "logloss": 0.6168251370897118,
            "mae": 0.2834884658413897,
            "precision": 0.7158469945355191,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8445115705226264,
            "auditor_fn_violation": 0.009115035640345149,
            "auditor_fp_violation": 0.022421107893104114,
            "ave_precision_score": 0.8451322493092381,
            "fpr": 0.13611416026344675,
            "logloss": 0.5792912733760639,
            "mae": 0.2715190576582387,
            "precision": 0.752,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8346081010321003,
            "auditor_fn_violation": 0.04098135964912281,
            "auditor_fp_violation": 0.027046783625731,
            "ave_precision_score": 0.8348860199941641,
            "fpr": 0.10526315789473684,
            "logloss": 0.8803500292075229,
            "mae": 0.31750954483906324,
            "precision": 0.7746478873239436,
            "recall": 0.6875
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.837585670895253,
            "auditor_fn_violation": 0.03816921174394531,
            "auditor_fp_violation": 0.023491171971354436,
            "ave_precision_score": 0.8379997850263681,
            "fpr": 0.0801317233809001,
            "logloss": 0.6822134288184957,
            "mae": 0.30638275687367605,
            "precision": 0.8147208121827412,
            "recall": 0.6772151898734177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7538407663763265,
            "auditor_fn_violation": 0.042386239035087724,
            "auditor_fp_violation": 0.04462110136452242,
            "ave_precision_score": 0.7477849109341201,
            "fpr": 0.18859649122807018,
            "logloss": 1.8524105100915322,
            "mae": 0.3302803670863124,
            "precision": 0.6797020484171322,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7223225900658798,
            "auditor_fn_violation": 0.04348863167938048,
            "auditor_fp_violation": 0.039574787682708425,
            "ave_precision_score": 0.7156232067053707,
            "fpr": 0.15148188803512624,
            "logloss": 2.126989878056306,
            "mae": 0.32902742082786957,
            "precision": 0.7057569296375267,
            "recall": 0.6983122362869199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6619890396434805,
            "auditor_fn_violation": 0.03910818713450293,
            "auditor_fp_violation": 0.05468750000000001,
            "ave_precision_score": 0.5692906692235122,
            "fpr": 0.37390350877192985,
            "logloss": 9.49713536282705,
            "mae": 0.4339769148970382,
            "precision": 0.5548302872062664,
            "recall": 0.8854166666666666
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6336183396061524,
            "auditor_fn_violation": 0.05299967115471014,
            "auditor_fp_violation": 0.06400791746942407,
            "ave_precision_score": 0.5448611159738368,
            "fpr": 0.3578485181119649,
            "logloss": 10.159373378087645,
            "mae": 0.43726786275104945,
            "precision": 0.5515818431911967,
            "recall": 0.8459915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8562728328508377,
            "auditor_fn_violation": 0.026206140350877195,
            "auditor_fp_violation": 0.025204069200779736,
            "ave_precision_score": 0.8565343982781102,
            "fpr": 0.1337719298245614,
            "logloss": 0.7926890893550202,
            "mae": 0.27961744169867114,
            "precision": 0.7584158415841584,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8609741963192828,
            "auditor_fn_violation": 0.01840607298512786,
            "auditor_fp_violation": 0.025407742139676014,
            "ave_precision_score": 0.8614149191806892,
            "fpr": 0.1163556531284303,
            "logloss": 0.6172838544889927,
            "mae": 0.26749218281918963,
            "precision": 0.7791666666666667,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8341476698614415,
            "auditor_fn_violation": 0.0046966374269005896,
            "auditor_fp_violation": 0.009312560916179338,
            "ave_precision_score": 0.8343922937982525,
            "fpr": 0.09539473684210527,
            "logloss": 0.5539851980097261,
            "mae": 0.3253920465310027,
            "precision": 0.7923627684964201,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8583973073509314,
            "auditor_fn_violation": 0.008827874964683865,
            "auditor_fp_violation": 0.010976948408342482,
            "ave_precision_score": 0.8587635175603341,
            "fpr": 0.07574094401756312,
            "logloss": 0.5025221209563445,
            "mae": 0.3042260794545106,
            "precision": 0.8287841191066998,
            "recall": 0.7046413502109705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8454285428073445,
            "auditor_fn_violation": 0.008634868421052636,
            "auditor_fp_violation": 0.009365862573099418,
            "ave_precision_score": 0.8456460267749395,
            "fpr": 0.07675438596491228,
            "logloss": 0.5764991144955708,
            "mae": 0.3167484263226869,
            "precision": 0.8108108108108109,
            "recall": 0.625
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.861361082530155,
            "auditor_fn_violation": 0.003987828092651,
            "auditor_fp_violation": 0.004242578000386831,
            "ave_precision_score": 0.861801171393404,
            "fpr": 0.05817782656421515,
            "logloss": 0.5328070338082785,
            "mae": 0.3003477439343491,
            "precision": 0.855191256830601,
            "recall": 0.6603375527426161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6642859881998324,
            "auditor_fn_violation": 0.04920047514619884,
            "auditor_fp_violation": 0.061538032001299564,
            "ave_precision_score": 0.5712380016582723,
            "fpr": 0.2642543859649123,
            "logloss": 8.485317081917295,
            "mae": 0.39182001005929923,
            "precision": 0.6204724409448819,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6342440101955663,
            "auditor_fn_violation": 0.05399315446002214,
            "auditor_fp_violation": 0.07200827918122515,
            "ave_precision_score": 0.5454781322054041,
            "fpr": 0.2623490669593853,
            "logloss": 9.269590448310483,
            "mae": 0.4065367817761693,
            "precision": 0.6016666666666667,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7604395666070722,
            "auditor_fn_violation": 0.02495888157894736,
            "auditor_fp_violation": 0.014985380116959065,
            "ave_precision_score": 0.7609029486302658,
            "fpr": 0.09210526315789473,
            "logloss": 1.105502604185117,
            "mae": 0.3639852521176963,
            "precision": 0.7579250720461095,
            "recall": 0.5479166666666667
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7914135907825661,
            "auditor_fn_violation": 0.021942317757182497,
            "auditor_fp_violation": 0.01595048567344961,
            "ave_precision_score": 0.7919514858538991,
            "fpr": 0.06805708013172337,
            "logloss": 0.9128448538770404,
            "mae": 0.33493560389605714,
            "precision": 0.8092307692307692,
            "recall": 0.5548523206751055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.867365074540902,
            "auditor_fn_violation": 0.01331323099415205,
            "auditor_fp_violation": 0.016122482131254067,
            "ave_precision_score": 0.8675552712148094,
            "fpr": 0.14912280701754385,
            "logloss": 0.7491780835394335,
            "mae": 0.2841521982995083,
            "precision": 0.7481481481481481,
            "recall": 0.8416666666666667
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.865237507568309,
            "auditor_fn_violation": 0.010497575344940184,
            "auditor_fp_violation": 0.012041988711577543,
            "ave_precision_score": 0.8658217261417718,
            "fpr": 0.11745334796926454,
            "logloss": 0.5859759316664171,
            "mae": 0.2732296204112642,
            "precision": 0.7885375494071146,
            "recall": 0.8417721518987342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.861038043577394,
            "auditor_fn_violation": 0.018667763157894736,
            "auditor_fp_violation": 0.01726973684210527,
            "ave_precision_score": 0.861258518171793,
            "fpr": 0.14802631578947367,
            "logloss": 0.5474558513350748,
            "mae": 0.28014116197424765,
            "precision": 0.7462406015037594,
            "recall": 0.8270833333333333
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.875430427091326,
            "auditor_fn_violation": 0.01230622443922615,
            "auditor_fp_violation": 0.018758775906979785,
            "ave_precision_score": 0.8756577433578376,
            "fpr": 0.11855104281009879,
            "logloss": 0.4822198993768298,
            "mae": 0.26667224903317804,
            "precision": 0.7795918367346939,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7542604092659779,
            "auditor_fn_violation": 0.017338267543859656,
            "auditor_fp_violation": 0.014081790123456792,
            "ave_precision_score": 0.75473975195722,
            "fpr": 0.08662280701754387,
            "logloss": 1.164436560584309,
            "mae": 0.37351689115232795,
            "precision": 0.7569230769230769,
            "recall": 0.5125
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7901599993056363,
            "auditor_fn_violation": 0.016437632869707803,
            "auditor_fp_violation": 0.008573072063540707,
            "ave_precision_score": 0.7916143793453831,
            "fpr": 0.06147091108671789,
            "logloss": 0.9240988808341581,
            "mae": 0.3399371664735643,
            "precision": 0.8205128205128205,
            "recall": 0.540084388185654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7207196746638358,
            "auditor_fn_violation": 0.021171418128654973,
            "auditor_fp_violation": 0.03245309454191034,
            "ave_precision_score": 0.7217967069839974,
            "fpr": 0.22039473684210525,
            "logloss": 1.035006290970965,
            "mae": 0.38744389810917607,
            "precision": 0.6332116788321168,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7637579325635002,
            "auditor_fn_violation": 0.02829458980023807,
            "auditor_fp_violation": 0.03649018982333895,
            "ave_precision_score": 0.7645981150444484,
            "fpr": 0.19319429198682767,
            "logloss": 0.903786409591662,
            "mae": 0.35727532443038607,
            "precision": 0.6691729323308271,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 28699,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8348727918362552,
            "auditor_fn_violation": 0.012609649122807019,
            "auditor_fp_violation": 0.02055921052631579,
            "ave_precision_score": 0.8351562957749418,
            "fpr": 0.11842105263157894,
            "logloss": 0.8051417408902557,
            "mae": 0.3013685359937622,
            "precision": 0.7692307692307693,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8352046598342449,
            "auditor_fn_violation": 0.00927251084957876,
            "auditor_fp_violation": 0.0016076080048831112,
            "ave_precision_score": 0.8355663960352602,
            "fpr": 0.11086717892425905,
            "logloss": 0.6445634593823487,
            "mae": 0.2908541044713668,
            "precision": 0.7799564270152506,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8656292505435224,
            "auditor_fn_violation": 0.01439144736842106,
            "auditor_fp_violation": 0.013838125406107868,
            "ave_precision_score": 0.8658214344613318,
            "fpr": 0.10964912280701754,
            "logloss": 0.5486646635970548,
            "mae": 0.3061149255597245,
            "precision": 0.7894736842105263,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8727994802684149,
            "auditor_fn_violation": 0.007751022430954073,
            "auditor_fp_violation": 0.015053741833225743,
            "ave_precision_score": 0.8733509190783204,
            "fpr": 0.09769484083424808,
            "logloss": 0.45544954656450004,
            "mae": 0.2972573637021818,
            "precision": 0.8065217391304348,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8376503258144825,
            "auditor_fn_violation": 0.0015350877192982489,
            "auditor_fp_violation": 0.00995979532163743,
            "ave_precision_score": 0.8378942763136489,
            "fpr": 0.13815789473684212,
            "logloss": 0.6760136064953597,
            "mae": 0.27341111417746305,
            "precision": 0.7504950495049505,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8315372372261378,
            "auditor_fn_violation": 0.005794161375036478,
            "auditor_fp_violation": 0.014350413331089386,
            "ave_precision_score": 0.8320177379478372,
            "fpr": 0.1141602634467618,
            "logloss": 0.6763285233971249,
            "mae": 0.26929175106108155,
            "precision": 0.7748917748917749,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 28699,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8270389666432674,
            "auditor_fn_violation": 0.007072368421052635,
            "auditor_fp_violation": 0.0213409681611436,
            "ave_precision_score": 0.8273304091141809,
            "fpr": 0.17653508771929824,
            "logloss": 0.9021350112552736,
            "mae": 0.2756096182637536,
            "precision": 0.7109515260323159,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8042724407776848,
            "auditor_fn_violation": 0.014666036765829735,
            "auditor_fp_violation": 0.021227961326979936,
            "ave_precision_score": 0.805722355549627,
            "fpr": 0.15916575192096596,
            "logloss": 0.9118439835213625,
            "mae": 0.27643619224450705,
            "precision": 0.7211538461538461,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8257426188974778,
            "auditor_fn_violation": 0.014300073099415212,
            "auditor_fp_violation": 0.011916727582846003,
            "ave_precision_score": 0.826045367874211,
            "fpr": 0.09978070175438597,
            "logloss": 0.6507881835696006,
            "mae": 0.3165943448127145,
            "precision": 0.7936507936507936,
            "recall": 0.7291666666666666
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8498578521049869,
            "auditor_fn_violation": 0.009467039049220272,
            "auditor_fp_violation": 0.007362342284863117,
            "ave_precision_score": 0.8504742670369362,
            "fpr": 0.09330406147091108,
            "logloss": 0.4973733872237305,
            "mae": 0.29451875846387837,
            "precision": 0.8085585585585585,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.562627603935451,
            "auditor_fn_violation": 0.0329952485380117,
            "auditor_fp_violation": 0.05274325860948668,
            "ave_precision_score": 0.529974371195902,
            "fpr": 0.16885964912280702,
            "logloss": 10.917587746527177,
            "mae": 0.4576676225145715,
            "precision": 0.6130653266331658,
            "recall": 0.5083333333333333
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.5839299938501625,
            "auditor_fn_violation": 0.040612393298966695,
            "auditor_fp_violation": 0.047567613731986626,
            "ave_precision_score": 0.5373265750288575,
            "fpr": 0.17453347969264543,
            "logloss": 10.307096961059543,
            "mae": 0.4315678683384582,
            "precision": 0.6232227488151659,
            "recall": 0.5548523206751055
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8530018038480405,
            "auditor_fn_violation": 0.007869608918128655,
            "auditor_fp_violation": 0.015289961013645229,
            "ave_precision_score": 0.853220758120113,
            "fpr": 0.1206140350877193,
            "logloss": 0.5451009834621753,
            "mae": 0.28616859896651714,
            "precision": 0.7713097713097713,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.855423592514402,
            "auditor_fn_violation": 0.009087245897539219,
            "auditor_fp_violation": 0.0139987490800212,
            "ave_precision_score": 0.8566910297701216,
            "fpr": 0.09440175631174534,
            "logloss": 0.5174713343776636,
            "mae": 0.27110940861094573,
            "precision": 0.8063063063063063,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8306567716189592,
            "auditor_fn_violation": 0.008867872807017549,
            "auditor_fp_violation": 0.019706384015594543,
            "ave_precision_score": 0.8309135057610306,
            "fpr": 0.18859649122807018,
            "logloss": 0.9073030990619727,
            "mae": 0.27778843956713456,
            "precision": 0.7003484320557491,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8200871987183838,
            "auditor_fn_violation": 0.011602217621475919,
            "auditor_fp_violation": 0.023013913344904765,
            "ave_precision_score": 0.8207048266815684,
            "fpr": 0.16355653128430298,
            "logloss": 0.8014679334055895,
            "mae": 0.27367127115852935,
            "precision": 0.71939736346516,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.672228182766051,
            "auditor_fn_violation": 0.011798702485380133,
            "auditor_fp_violation": 0.0051474171539961045,
            "ave_precision_score": 0.6733763375482054,
            "fpr": 0.09210526315789473,
            "logloss": 1.0822794903598714,
            "mae": 0.42400288177038437,
            "precision": 0.7263843648208469,
            "recall": 0.46458333333333335
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.723655538309945,
            "auditor_fn_violation": 0.0077811279856604965,
            "auditor_fp_violation": 0.006656501895219131,
            "ave_precision_score": 0.7248378992870692,
            "fpr": 0.06805708013172337,
            "logloss": 0.8976845288363379,
            "mae": 0.3949279836070732,
            "precision": 0.7816901408450704,
            "recall": 0.46835443037974683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7826068324491924,
            "auditor_fn_violation": 0.03908991228070176,
            "auditor_fp_violation": 0.0317094095191683,
            "ave_precision_score": 0.7693439131687376,
            "fpr": 0.1699561403508772,
            "logloss": 2.356671375900722,
            "mae": 0.30467718955284506,
            "precision": 0.7013487475915221,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7462713481008567,
            "auditor_fn_violation": 0.038863955314093576,
            "auditor_fp_violation": 0.03958232334523131,
            "ave_precision_score": 0.7318012963382855,
            "fpr": 0.1437980241492865,
            "logloss": 2.7851112256638704,
            "mae": 0.3152691742011694,
            "precision": 0.7145969498910676,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8591832814963206,
            "auditor_fn_violation": 0.01779513888888889,
            "auditor_fp_violation": 0.022691276803118915,
            "ave_precision_score": 0.8593771996788883,
            "fpr": 0.14473684210526316,
            "logloss": 0.661851714064901,
            "mae": 0.2620567119617855,
            "precision": 0.7490494296577946,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8436006211828919,
            "auditor_fn_violation": 0.015013408550903868,
            "auditor_fp_violation": 0.018540241693815983,
            "ave_precision_score": 0.8441142477574592,
            "fpr": 0.11964873765093303,
            "logloss": 0.6726667030190192,
            "mae": 0.2622521644192142,
            "precision": 0.7719665271966527,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8440754911992798,
            "auditor_fn_violation": 0.008950109649122812,
            "auditor_fp_violation": 0.01661234974009098,
            "ave_precision_score": 0.8442409599716582,
            "fpr": 0.13925438596491227,
            "logloss": 0.8859888965837633,
            "mae": 0.2693813432815739,
            "precision": 0.75,
            "recall": 0.79375
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8368628876859812,
            "auditor_fn_violation": 0.0145201406160986,
            "auditor_fp_violation": 0.015164264883561459,
            "ave_precision_score": 0.8373765686228012,
            "fpr": 0.11525795828759605,
            "logloss": 0.7595022229000588,
            "mae": 0.2635511728020413,
            "precision": 0.7756410256410257,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8159020869634465,
            "auditor_fn_violation": 0.03470851608187134,
            "auditor_fp_violation": 0.02250852826510721,
            "ave_precision_score": 0.8161864715626255,
            "fpr": 0.15460526315789475,
            "logloss": 0.5515052473406581,
            "mae": 0.35937763336972384,
            "precision": 0.7262135922330097,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8352272619574779,
            "auditor_fn_violation": 0.030408926065389266,
            "auditor_fp_violation": 0.024556212274589498,
            "ave_precision_score": 0.8355095349517514,
            "fpr": 0.14489571899012074,
            "logloss": 0.5162001002899048,
            "mae": 0.34572405684289537,
            "precision": 0.7396449704142012,
            "recall": 0.7911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7950244054692548,
            "auditor_fn_violation": 0.01884594298245614,
            "auditor_fp_violation": 0.0199119761208577,
            "ave_precision_score": 0.7808789553149929,
            "fpr": 0.15460526315789475,
            "logloss": 2.2700590159870453,
            "mae": 0.28765589156535554,
            "precision": 0.7262135922330097,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7761591124162088,
            "auditor_fn_violation": 0.022755167734255965,
            "auditor_fp_violation": 0.025121386963806214,
            "ave_precision_score": 0.7611964032874801,
            "fpr": 0.132821075740944,
            "logloss": 2.4250378308571814,
            "mae": 0.289845901967972,
            "precision": 0.7441860465116279,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8392409472399598,
            "auditor_fn_violation": 0.008127741228070175,
            "auditor_fp_violation": 0.008177997076023395,
            "ave_precision_score": 0.8394834665585251,
            "fpr": 0.13048245614035087,
            "logloss": 0.6307209666752281,
            "mae": 0.276064275347995,
            "precision": 0.7605633802816901,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8404483811009387,
            "auditor_fn_violation": 0.007380492526875001,
            "auditor_fp_violation": 0.014179604980570554,
            "ave_precision_score": 0.8410195002964558,
            "fpr": 0.11086717892425905,
            "logloss": 0.6178461412515233,
            "mae": 0.2667845936005604,
            "precision": 0.7841880341880342,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8398978486000884,
            "auditor_fn_violation": 0.024077119883040937,
            "auditor_fp_violation": 0.022866410818713455,
            "ave_precision_score": 0.8402554472224186,
            "fpr": 0.14364035087719298,
            "logloss": 0.5799531503459721,
            "mae": 0.29378677601095243,
            "precision": 0.7523629489603024,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8349431907726963,
            "auditor_fn_violation": 0.01729911489669163,
            "auditor_fp_violation": 0.019220963208383676,
            "ave_precision_score": 0.8359977660881435,
            "fpr": 0.12403951701427003,
            "logloss": 0.532333195759084,
            "mae": 0.28807769650535414,
            "precision": 0.7753479125248509,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 28699,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6647120172189896,
            "auditor_fn_violation": 0.04605263157894737,
            "auditor_fp_violation": 0.06125121832358676,
            "ave_precision_score": 0.5716639266717971,
            "fpr": 0.25,
            "logloss": 8.46945906340526,
            "mae": 0.38704767116005795,
            "precision": 0.6274509803921569,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.635439413372008,
            "auditor_fn_violation": 0.05232808570356682,
            "auditor_fp_violation": 0.06936074974818329,
            "ave_precision_score": 0.5466732579878661,
            "fpr": 0.24039517014270034,
            "logloss": 9.258473523128416,
            "mae": 0.3996579250546726,
            "precision": 0.6191304347826087,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 28699,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8441713688828554,
            "auditor_fn_violation": 0.010215643274853808,
            "auditor_fp_violation": 0.0023985745614035093,
            "ave_precision_score": 0.8443853345395652,
            "fpr": 0.005482456140350877,
            "logloss": 1.2907267423594277,
            "mae": 0.4098413730030108,
            "precision": 0.9541284403669725,
            "recall": 0.21666666666666667
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8511787754967725,
            "auditor_fn_violation": 0.010483680473537227,
            "auditor_fp_violation": 0.0008414823150560025,
            "ave_precision_score": 0.8524300021519932,
            "fpr": 0.0043907793633369925,
            "logloss": 1.1299119670194606,
            "mae": 0.4051184252315775,
            "precision": 0.9587628865979382,
            "recall": 0.1962025316455696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 28699,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7650871875837169,
            "auditor_fn_violation": 0.012536549707602342,
            "auditor_fp_violation": 0.025584795321637422,
            "ave_precision_score": 0.7659310632264572,
            "fpr": 0.14144736842105263,
            "logloss": 0.9478230424254834,
            "mae": 0.28315537904355365,
            "precision": 0.7445544554455445,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7951150134823045,
            "auditor_fn_violation": 0.010532312523447593,
            "auditor_fp_violation": 0.015036158620672337,
            "ave_precision_score": 0.7955906777181087,
            "fpr": 0.11525795828759605,
            "logloss": 0.8130674093538935,
            "mae": 0.28105733545843364,
            "precision": 0.7751605995717344,
            "recall": 0.7637130801687764
        }
    }
]