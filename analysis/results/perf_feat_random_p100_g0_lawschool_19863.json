[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8163276784098829,
            "auditor_fn_violation": 0.020525546321945216,
            "auditor_fp_violation": 0.025474184364419825,
            "ave_precision_score": 0.8166295932127305,
            "fpr": 0.1524122807017544,
            "logloss": 0.8200493110964461,
            "mae": 0.27369878706670225,
            "precision": 0.7191919191919192,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8328004755350202,
            "auditor_fn_violation": 0.009376694483752798,
            "auditor_fp_violation": 0.022857568114224052,
            "ave_precision_score": 0.8333179084844015,
            "fpr": 0.11855104281009879,
            "logloss": 0.8225651661665299,
            "mae": 0.2768186446049833,
            "precision": 0.7763975155279503,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6623372037052753,
            "auditor_fn_violation": 0.0015485534010464777,
            "auditor_fp_violation": 0.012176823638042478,
            "ave_precision_score": 0.6624668150463922,
            "fpr": 0.29276315789473684,
            "logloss": 0.6473107901719987,
            "mae": 0.44196774557298213,
            "precision": 0.6158273381294964,
            "recall": 0.9385964912280702
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6733813383327766,
            "auditor_fn_violation": 0.005673627550817984,
            "auditor_fp_violation": 0.02021300064054349,
            "ave_precision_score": 0.6736323115491266,
            "fpr": 0.2623490669593853,
            "logloss": 0.6322095635552242,
            "mae": 0.4324030297451564,
            "precision": 0.6585714285714286,
            "recall": 0.9257028112449799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.7839810837627658,
            "auditor_fn_violation": 0.00707910126192675,
            "auditor_fp_violation": 0.0043859649122807015,
            "ave_precision_score": 0.7506176146090826,
            "fpr": 0.09429824561403509,
            "logloss": 0.581957582978519,
            "mae": 0.36942974053192557,
            "precision": 0.7995337995337995,
            "recall": 0.7521929824561403
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7739092549580121,
            "auditor_fn_violation": 0.011805730055237423,
            "auditor_fp_violation": 0.01343280805224284,
            "ave_precision_score": 0.7519454146106711,
            "fpr": 0.09110867178924259,
            "logloss": 0.66325554749366,
            "mae": 0.4068762508479615,
            "precision": 0.8028503562945368,
            "recall": 0.678714859437751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6422276248553715,
            "auditor_fn_violation": 0.0017697753154816982,
            "auditor_fp_violation": 0.0022891658971991385,
            "ave_precision_score": 0.6431092757223769,
            "fpr": 0.017543859649122806,
            "logloss": 0.7792982341841234,
            "mae": 0.4607781022174382,
            "precision": 0.7142857142857143,
            "recall": 0.08771929824561403
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.6518850493001479,
            "auditor_fn_violation": 0.0019176596616983944,
            "auditor_fp_violation": 0.001934919719436641,
            "ave_precision_score": 0.6528047681834676,
            "fpr": 0.015367727771679473,
            "logloss": 0.8516289088240697,
            "mae": 0.4907370094643368,
            "precision": 0.65,
            "recall": 0.05220883534136546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6150034290816366,
            "auditor_fn_violation": 0.007867805478608825,
            "auditor_fp_violation": 0.010719644506001848,
            "ave_precision_score": 0.601380728700242,
            "fpr": 0.1074561403508772,
            "logloss": 3.303568407445927,
            "mae": 0.4501173418583088,
            "precision": 0.6733333333333333,
            "recall": 0.44298245614035087
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.64064884557871,
            "auditor_fn_violation": 0.0221412543698394,
            "auditor_fp_violation": 0.0017116597518093345,
            "ave_precision_score": 0.6242064336476935,
            "fpr": 0.0867178924259056,
            "logloss": 3.762561029184382,
            "mae": 0.4883454014787567,
            "precision": 0.7074074074074074,
            "recall": 0.38353413654618473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8205355009763196,
            "auditor_fn_violation": 0.01215277777777778,
            "auditor_fp_violation": 0.03486890196983689,
            "ave_precision_score": 0.8209357734931773,
            "fpr": 0.26864035087719296,
            "logloss": 0.6584009597599594,
            "mae": 0.33451102713221,
            "precision": 0.6343283582089553,
            "recall": 0.9320175438596491
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8368228899464742,
            "auditor_fn_violation": 0.010057794294631875,
            "auditor_fp_violation": 0.03217069819239163,
            "ave_precision_score": 0.8371734881584026,
            "fpr": 0.23600439077936333,
            "logloss": 0.6001914878765675,
            "mae": 0.31368617466512894,
            "precision": 0.6810089020771514,
            "recall": 0.9216867469879518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7314206147103864,
            "auditor_fn_violation": 0.011715143120960296,
            "auditor_fp_violation": 0.015350877192982462,
            "ave_precision_score": 0.7287527044829314,
            "fpr": 0.18640350877192982,
            "logloss": 0.6089982967363425,
            "mae": 0.4260859644988127,
            "precision": 0.6640316205533597,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7715407244913357,
            "auditor_fn_violation": 0.0029404114812708604,
            "auditor_fp_violation": 0.0245187285876415,
            "ave_precision_score": 0.7690840686437217,
            "fpr": 0.16245883644346873,
            "logloss": 0.6041482393541117,
            "mae": 0.4247301472954117,
            "precision": 0.7092337917485265,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7334613390058837,
            "auditor_fn_violation": 0.015899122807017548,
            "auditor_fp_violation": 0.02595029239766082,
            "ave_precision_score": 0.6453841402593619,
            "fpr": 0.3333333333333333,
            "logloss": 0.6691506416621551,
            "mae": 0.4468118805748305,
            "precision": 0.5663338088445078,
            "recall": 0.8706140350877193
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7705563223852855,
            "auditor_fn_violation": 0.015414016108341158,
            "auditor_fp_violation": 0.035628569833857385,
            "ave_precision_score": 0.6931818083198651,
            "fpr": 0.29198682766191,
            "logloss": 0.6268035392592928,
            "mae": 0.43080491570915985,
            "precision": 0.6205420827389444,
            "recall": 0.8734939759036144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8569349345189261,
            "auditor_fn_violation": 0.002731609726069566,
            "auditor_fp_violation": 0.0043859649122807015,
            "ave_precision_score": 0.8465389550179839,
            "fpr": 0.09429824561403509,
            "logloss": 2.1132462217667514,
            "mae": 0.22383521366637488,
            "precision": 0.8,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8408306647612289,
            "auditor_fn_violation": 0.012358985888669951,
            "auditor_fp_violation": 0.018203660931897736,
            "ave_precision_score": 0.8292942457807978,
            "fpr": 0.08781558726673985,
            "logloss": 2.8813260445127225,
            "mae": 0.2684397035143497,
            "precision": 0.8099762470308789,
            "recall": 0.6847389558232931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7423539645109356,
            "auditor_fn_violation": 0.010416666666666666,
            "auditor_fp_violation": 0.05312451908279471,
            "ave_precision_score": 0.7277007293665911,
            "fpr": 0.32785087719298245,
            "logloss": 1.3967106570766656,
            "mae": 0.4110890866910986,
            "precision": 0.5904109589041096,
            "recall": 0.9451754385964912
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7753992318899715,
            "auditor_fn_violation": 0.017428660856378314,
            "auditor_fp_violation": 0.04042068556757202,
            "ave_precision_score": 0.7600068739650518,
            "fpr": 0.3018660812294182,
            "logloss": 1.4219133171266756,
            "mae": 0.3968359457543625,
            "precision": 0.626358695652174,
            "recall": 0.9257028112449799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6977157973512388,
            "auditor_fn_violation": 0.018539358264081266,
            "auditor_fp_violation": 0.012465373961218837,
            "ave_precision_score": 0.6725115200863913,
            "fpr": 0.08771929824561403,
            "logloss": 0.6922323678293306,
            "mae": 0.41734401607608196,
            "precision": 0.7122302158273381,
            "recall": 0.4342105263157895
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7367852693704002,
            "auditor_fn_violation": 0.029304925519862107,
            "auditor_fp_violation": 0.007994833126463485,
            "ave_precision_score": 0.710708953981207,
            "fpr": 0.07354555433589462,
            "logloss": 0.7381969160569453,
            "mae": 0.4335179081560817,
            "precision": 0.7572463768115942,
            "recall": 0.41967871485943775
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7202818325880331,
            "auditor_fn_violation": 0.0004833217913204103,
            "auditor_fp_violation": 0.011484302862419207,
            "ave_precision_score": 0.7103759758410881,
            "fpr": 0.07236842105263158,
            "logloss": 0.6873352494542864,
            "mae": 0.39621993817752554,
            "precision": 0.7411764705882353,
            "recall": 0.4144736842105263
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7324926634083633,
            "auditor_fn_violation": 0.008398026794334322,
            "auditor_fp_violation": 0.009685230024213074,
            "ave_precision_score": 0.7224618706318595,
            "fpr": 0.06366630076838639,
            "logloss": 0.7734320497248927,
            "mae": 0.42489012401514203,
            "precision": 0.7716535433070866,
            "recall": 0.39357429718875503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8017594332061476,
            "auditor_fn_violation": 0.0015437442289935367,
            "auditor_fp_violation": 0.009529374422899355,
            "ave_precision_score": 0.7988947161159552,
            "fpr": 0.10635964912280702,
            "logloss": 0.5252332914442978,
            "mae": 0.33290887687747417,
            "precision": 0.7863436123348018,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7978331327971107,
            "auditor_fn_violation": 0.014076062758167687,
            "auditor_fp_violation": 0.014448109333595572,
            "ave_precision_score": 0.7941304803241855,
            "fpr": 0.10208562019758508,
            "logloss": 0.5353594811344065,
            "mae": 0.33573332911461556,
            "precision": 0.7951541850220264,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8295001346856314,
            "auditor_fn_violation": 0.014138965835641743,
            "auditor_fp_violation": 0.020717913204062792,
            "ave_precision_score": 0.8211939324030608,
            "fpr": 0.08881578947368421,
            "logloss": 0.5171200980566355,
            "mae": 0.32517338389267314,
            "precision": 0.7980049875311721,
            "recall": 0.7017543859649122
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.843776929608301,
            "auditor_fn_violation": 0.015804160660203945,
            "auditor_fp_violation": 0.023391797322475105,
            "ave_precision_score": 0.8368463554408804,
            "fpr": 0.10098792535675083,
            "logloss": 0.5359974739575667,
            "mae": 0.3370889498996339,
            "precision": 0.7865429234338747,
            "recall": 0.6807228915662651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6537434983075383,
            "auditor_fn_violation": 0.007915897199138225,
            "auditor_fp_violation": 0.009034029701446603,
            "ave_precision_score": 0.6548421564390672,
            "fpr": 0.0668859649122807,
            "logloss": 10.479439630927596,
            "mae": 0.43512070812630294,
            "precision": 0.7038834951456311,
            "recall": 0.31798245614035087
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6604288354516685,
            "auditor_fn_violation": 0.005451002693540346,
            "auditor_fp_violation": 0.011083262678641199,
            "ave_precision_score": 0.6621984452502181,
            "fpr": 0.06037321624588365,
            "logloss": 11.91631833162828,
            "mae": 0.4862671171157931,
            "precision": 0.7164948453608248,
            "recall": 0.2791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7080374644489928,
            "auditor_fn_violation": 0.021432075253924286,
            "auditor_fp_violation": 0.04228704986149583,
            "ave_precision_score": 0.7040452748880582,
            "fpr": 0.22149122807017543,
            "logloss": 0.608422938652124,
            "mae": 0.4004346791801876,
            "precision": 0.6373429084380611,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7137891687137716,
            "auditor_fn_violation": 0.03504908767892647,
            "auditor_fp_violation": 0.041034650478547104,
            "ave_precision_score": 0.7135897354360841,
            "fpr": 0.19099890230515917,
            "logloss": 0.613235883823423,
            "mae": 0.40370369898860725,
            "precision": 0.6771799628942486,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7798540158694791,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.7309795511610511,
            "fpr": 0.4956140350877193,
            "logloss": 8.04658662438649,
            "mae": 0.4967101388860751,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7972645113216167,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.752743303370183,
            "fpr": 0.4445664105378705,
            "logloss": 7.378266260546196,
            "mae": 0.44456620630202776,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5964848385339132,
            "auditor_fn_violation": 0.005944136657433072,
            "auditor_fp_violation": 0.00922639658356418,
            "ave_precision_score": 0.5705226145467688,
            "fpr": 0.10855263157894737,
            "logloss": 0.6661212005097821,
            "mae": 0.4551940317625147,
            "precision": 0.611764705882353,
            "recall": 0.34210526315789475
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6353745347926405,
            "auditor_fn_violation": 0.009295138842967931,
            "auditor_fp_violation": 0.009796860008026733,
            "ave_precision_score": 0.6152907282001666,
            "fpr": 0.09330406147091108,
            "logloss": 0.6930193466951116,
            "mae": 0.4651775118679168,
            "precision": 0.6367521367521367,
            "recall": 0.2991967871485944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.483920396753206,
            "auditor_fn_violation": 0.002635426285010773,
            "auditor_fp_violation": 0.002539242843951988,
            "ave_precision_score": 0.49320060772055896,
            "fpr": 0.49122807017543857,
            "logloss": 0.9317243668494498,
            "mae": 0.4940147455128139,
            "precision": 0.5022222222222222,
            "recall": 0.9912280701754386
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5582021804320805,
            "auditor_fn_violation": 0.0005664810724787184,
            "auditor_fp_violation": 0.0028253017331883916,
            "ave_precision_score": 0.5679802935979787,
            "fpr": 0.4434687156970362,
            "logloss": 0.8480484966654187,
            "mae": 0.4622464963162377,
            "precision": 0.5516093229744728,
            "recall": 0.9979919678714859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7657534051315606,
            "auditor_fn_violation": 0.009471664358264098,
            "auditor_fp_violation": 0.004176765927977842,
            "ave_precision_score": 0.6964907349349125,
            "fpr": 0.06907894736842106,
            "logloss": 0.5998772655452064,
            "mae": 0.41028901132379186,
            "precision": 0.7797202797202797,
            "recall": 0.48903508771929827
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7515138348599449,
            "auditor_fn_violation": 0.005572234051463834,
            "auditor_fp_violation": 0.006097123401631393,
            "ave_precision_score": 0.6904771243745291,
            "fpr": 0.07354555433589462,
            "logloss": 0.6287371030458889,
            "mae": 0.42194784055622425,
            "precision": 0.7589928057553957,
            "recall": 0.42369477911646586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7811706992961902,
            "auditor_fn_violation": 0.0005121768236380431,
            "auditor_fp_violation": 0.0017216835949522946,
            "ave_precision_score": 0.7599615666375312,
            "fpr": 0.0668859649122807,
            "logloss": 0.5836881949457788,
            "mae": 0.38117057806509247,
            "precision": 0.8117283950617284,
            "recall": 0.5767543859649122
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8040748079000183,
            "auditor_fn_violation": 0.012480217246593402,
            "auditor_fp_violation": 0.011989591832937758,
            "ave_precision_score": 0.7884743100707056,
            "fpr": 0.05817782656421515,
            "logloss": 0.5528320082620771,
            "mae": 0.375429735540463,
            "precision": 0.8290322580645161,
            "recall": 0.5160642570281124
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6611842105263158,
            "auc_prc": 0.6747907632712625,
            "auditor_fn_violation": 0.03624192059095107,
            "auditor_fp_violation": 0.008440096952908586,
            "ave_precision_score": 0.6660349372290413,
            "fpr": 0.0668859649122807,
            "logloss": 2.3482339505861614,
            "mae": 0.39909405333014353,
            "precision": 0.7732342007434945,
            "recall": 0.45614035087719296
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.694332493489607,
            "auditor_fn_violation": 0.04507161466943515,
            "auditor_fp_violation": 0.008422748064415817,
            "ave_precision_score": 0.6868631313732935,
            "fpr": 0.06256860592755215,
            "logloss": 2.5462720327610273,
            "mae": 0.43068991121976014,
            "precision": 0.7816091954022989,
            "recall": 0.40963855421686746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6512127667748939,
            "auditor_fn_violation": 0.009204755309325947,
            "auditor_fp_violation": 0.02977358417974764,
            "ave_precision_score": 0.6521485204314289,
            "fpr": 0.36622807017543857,
            "logloss": 0.7503161133348418,
            "mae": 0.4330528914650673,
            "precision": 0.562254259501966,
            "recall": 0.9407894736842105
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6748178473741453,
            "auditor_fn_violation": 0.010051181675108777,
            "auditor_fp_violation": 0.03835818872377693,
            "ave_precision_score": 0.6757158977466267,
            "fpr": 0.3029637760702525,
            "logloss": 0.6923755174112369,
            "mae": 0.41025747419728537,
            "precision": 0.6310160427807486,
            "recall": 0.9477911646586346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8126647357200318,
            "auditor_fn_violation": 0.015139273622653123,
            "auditor_fp_violation": 0.014756944444444451,
            "ave_precision_score": 0.8129882122289481,
            "fpr": 0.21162280701754385,
            "logloss": 0.7052961999004433,
            "mae": 0.3883627944482415,
            "precision": 0.6717687074829932,
            "recall": 0.8662280701754386
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.8159586179753018,
            "auditor_fn_violation": 0.0218304612522538,
            "auditor_fp_violation": 0.009547021472824742,
            "ave_precision_score": 0.8163028746855385,
            "fpr": 0.18990120746432493,
            "logloss": 0.8714249364827545,
            "mae": 0.3975202580053393,
            "precision": 0.6986062717770035,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7411880205963876,
            "auditor_fn_violation": 0.005511311172668517,
            "auditor_fp_violation": 0.014408279470606343,
            "ave_precision_score": 0.75012954558889,
            "fpr": 0.11403508771929824,
            "logloss": 0.6099195641799832,
            "mae": 0.36031157833426014,
            "precision": 0.7552941176470588,
            "recall": 0.7039473684210527
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7678033684306363,
            "auditor_fn_violation": 0.010408263129356068,
            "auditor_fp_violation": 0.016332529774640326,
            "ave_precision_score": 0.7701145129743852,
            "fpr": 0.10976948408342481,
            "logloss": 0.6054385500689153,
            "mae": 0.36701066296703044,
            "precision": 0.7727272727272727,
            "recall": 0.6827309236947792
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 19863,
        "test": {
            "accuracy": 0.3333333333333333,
            "auc_prc": 0.483362566293001,
            "auditor_fn_violation": 0.0022843567251462126,
            "auditor_fp_violation": 0.013561865189289013,
            "ave_precision_score": 0.44762966560875156,
            "fpr": 0.21710526315789475,
            "logloss": 9.827739312471406,
            "mae": 0.664038635090097,
            "precision": 0.1885245901639344,
            "recall": 0.10087719298245613
        },
        "train": {
            "accuracy": 0.35016465422612514,
            "auc_prc": 0.5516328032005144,
            "auditor_fn_violation": 0.006564126979928508,
            "auditor_fp_violation": 0.017531223172258362,
            "ave_precision_score": 0.50566608803628,
            "fpr": 0.18660812294182216,
            "logloss": 8.949918831680833,
            "mae": 0.6472105681051887,
            "precision": 0.3089430894308943,
            "recall": 0.15261044176706828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0.47091868763369304,
            "auditor_fn_violation": 0.004842836257309941,
            "auditor_fp_violation": 0.004395583256386592,
            "ave_precision_score": 0.5025161718007904,
            "fpr": 0.4682017543859649,
            "logloss": 0.8568755207998288,
            "mae": 0.5030574195675159,
            "precision": 0.49467455621301776,
            "recall": 0.9166666666666666
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5859087545303203,
            "auditor_fn_violation": 0.004933014164231018,
            "auditor_fp_violation": 0.0032346116738384612,
            "ave_precision_score": 0.5718306057533402,
            "fpr": 0.4105378704720088,
            "logloss": 0.7846851758996845,
            "mae": 0.4710795995334632,
            "precision": 0.5547619047619048,
            "recall": 0.9357429718875502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6124101471377044,
            "auditor_fn_violation": 0.06739573714989228,
            "auditor_fp_violation": 0.09235053093259465,
            "ave_precision_score": 0.6155517567447397,
            "fpr": 0.33114035087719296,
            "logloss": 1.441390409411781,
            "mae": 0.4638968748417423,
            "precision": 0.5424242424242425,
            "recall": 0.7850877192982456
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5917644784432337,
            "auditor_fn_violation": 0.0676911818514453,
            "auditor_fp_violation": 0.07467780131457596,
            "ave_precision_score": 0.5934965481918477,
            "fpr": 0.3194291986827662,
            "logloss": 1.805248867653445,
            "mae": 0.4825199150355563,
            "precision": 0.5794797687861272,
            "recall": 0.8052208835341366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7573096624052285,
            "auditor_fn_violation": 0.029980378578024013,
            "auditor_fp_violation": 0.04529759156663589,
            "ave_precision_score": 0.7579176513131716,
            "fpr": 0.25219298245614036,
            "logloss": 1.3597791149598084,
            "mae": 0.322990033885921,
            "precision": 0.6308186195826645,
            "recall": 0.8618421052631579
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7857579719308823,
            "auditor_fn_violation": 0.028328462036951323,
            "auditor_fp_violation": 0.04494967348229734,
            "ave_precision_score": 0.7862546446868546,
            "fpr": 0.2305159165751921,
            "logloss": 1.276288938880182,
            "mae": 0.3156636538010194,
            "precision": 0.6728971962616822,
            "recall": 0.8674698795180723
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7125589270796038,
            "auditor_fn_violation": 0.01754866882117575,
            "auditor_fp_violation": 0.018048822714681452,
            "ave_precision_score": 0.5745290806381032,
            "fpr": 0.18201754385964913,
            "logloss": 0.6652607694616411,
            "mae": 0.4748204917107758,
            "precision": 0.6235827664399093,
            "recall": 0.6030701754385965
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7326173374531113,
            "auditor_fn_violation": 0.03666917946208544,
            "auditor_fp_violation": 0.013493938757664598,
            "ave_precision_score": 0.6075583555938855,
            "fpr": 0.1756311745334797,
            "logloss": 0.6688835592253489,
            "mae": 0.47650931512223377,
            "precision": 0.6491228070175439,
            "recall": 0.5943775100401606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8160552932391787,
            "auditor_fn_violation": 0.008117882425361649,
            "auditor_fp_violation": 0.009132617728531857,
            "ave_precision_score": 0.805799141207915,
            "fpr": 0.07346491228070176,
            "logloss": 0.5482494690369454,
            "mae": 0.33976383995991855,
            "precision": 0.8227513227513228,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8310985843904297,
            "auditor_fn_violation": 0.012057009597115136,
            "auditor_fp_violation": 0.012149063238385832,
            "ave_precision_score": 0.8199405829337346,
            "fpr": 0.0845225027442371,
            "logloss": 0.5555177364697125,
            "mae": 0.3482035133925304,
            "precision": 0.8089330024813896,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.685519267630091,
            "auditor_fn_violation": 0.03344298245614036,
            "auditor_fp_violation": 0.008021698984302864,
            "ave_precision_score": 0.6926114664359225,
            "fpr": 0.1425438596491228,
            "logloss": 0.6118445125206393,
            "mae": 0.4305748821873414,
            "precision": 0.6867469879518072,
            "recall": 0.625
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7010419187413188,
            "auditor_fn_violation": 0.028619417295967634,
            "auditor_fp_violation": 0.018931913683443952,
            "ave_precision_score": 0.7031966248154458,
            "fpr": 0.15806805708013172,
            "logloss": 0.6411495172072925,
            "mae": 0.4469534075122764,
            "precision": 0.6778523489932886,
            "recall": 0.608433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.7579744816586922,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6313131313131313,
            "fpr": 0.5,
            "logloss": 0.672835458869234,
            "mae": 0.4282434781392415,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.7775762116133456,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6614025186654805,
            "fpr": 0.45334796926454446,
            "logloss": 0.6535115960637821,
            "mae": 0.4220060994674817,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.7494945999461018,
            "auditor_fn_violation": 0.001644736842105263,
            "auditor_fp_violation": 0.0036189019698368925,
            "ave_precision_score": 0.5044325391424581,
            "fpr": 0.4857456140350877,
            "logloss": 0.6991126935455426,
            "mae": 0.49719363071939404,
            "precision": 0.5044742729306487,
            "recall": 0.9890350877192983
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7766335298033913,
            "auditor_fn_violation": 0.0014327342300045408,
            "auditor_fp_violation": 0.0068067711558753375,
            "ave_precision_score": 0.556850901701619,
            "fpr": 0.4313940724478595,
            "logloss": 0.6813305882076023,
            "mae": 0.4880911087623412,
            "precision": 0.5569334836527621,
            "recall": 0.9919678714859438
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8519620491085056,
            "auditor_fn_violation": 0.009320175438596492,
            "auditor_fp_violation": 0.022321772083718078,
            "ave_precision_score": 0.8435568089693689,
            "fpr": 0.18311403508771928,
            "logloss": 0.49570979224576056,
            "mae": 0.31549154002252117,
            "precision": 0.7049469964664311,
            "recall": 0.875
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8486068764522638,
            "auditor_fn_violation": 0.01069921838837237,
            "auditor_fp_violation": 0.025398479174363376,
            "ave_precision_score": 0.8421691661958233,
            "fpr": 0.15697036223929747,
            "logloss": 0.5071326819039625,
            "mae": 0.31957853594477953,
            "precision": 0.7409420289855072,
            "recall": 0.821285140562249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6426236499569745,
            "auditor_fn_violation": 0.010084833795013851,
            "auditor_fp_violation": 0.026034452908587264,
            "ave_precision_score": 0.6434649032487265,
            "fpr": 0.3782894736842105,
            "logloss": 2.161216892302849,
            "mae": 0.421610810400868,
            "precision": 0.5448548812664907,
            "recall": 0.9057017543859649
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6714139949358682,
            "auditor_fn_violation": 0.0034914631081956827,
            "auditor_fp_violation": 0.01524546636083594,
            "ave_precision_score": 0.6721029573629801,
            "fpr": 0.3424807903402854,
            "logloss": 1.9524424493327148,
            "mae": 0.384727136787481,
            "precision": 0.59375,
            "recall": 0.9156626506024096
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8487026994533394,
            "auditor_fn_violation": 0.018457602339181287,
            "auditor_fp_violation": 0.013501750538627275,
            "ave_precision_score": 0.8489635368799915,
            "fpr": 0.12390350877192982,
            "logloss": 0.49707389093614496,
            "mae": 0.32973160284515407,
            "precision": 0.7505518763796909,
            "recall": 0.7456140350877193
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8428143312502012,
            "auditor_fn_violation": 0.011774871164129631,
            "auditor_fp_violation": 0.019250856494340093,
            "ave_precision_score": 0.8431154966512614,
            "fpr": 0.10867178924259056,
            "logloss": 0.5334947323934621,
            "mae": 0.3422011180117638,
            "precision": 0.7861771058315334,
            "recall": 0.7309236947791165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8531807506634244,
            "auditor_fn_violation": 0.005482456140350884,
            "auditor_fp_violation": 0.0008776738996614347,
            "ave_precision_score": 0.8123289311212287,
            "fpr": 0.0581140350877193,
            "logloss": 0.5066805721728737,
            "mae": 0.3391672183623926,
            "precision": 0.8547945205479452,
            "recall": 0.6842105263157895
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8428081952642754,
            "auditor_fn_violation": 0.012233346117731081,
            "auditor_fp_violation": 0.01254508389524855,
            "ave_precision_score": 0.8080492451919281,
            "fpr": 0.06476399560922064,
            "logloss": 0.5292679282409437,
            "mae": 0.35515364983032394,
            "precision": 0.8387978142076503,
            "recall": 0.6164658634538153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8339524582085894,
            "auditor_fn_violation": 0.008197233764235149,
            "auditor_fp_violation": 0.0043859649122807015,
            "ave_precision_score": 0.7306014582689089,
            "fpr": 0.09429824561403509,
            "logloss": 0.6024598670461385,
            "mae": 0.3272646926261746,
            "precision": 0.8013856812933026,
            "recall": 0.7609649122807017
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8307628099540574,
            "auditor_fn_violation": 0.012127544205361517,
            "auditor_fp_violation": 0.014323190065994583,
            "ave_precision_score": 0.7351578140062364,
            "fpr": 0.09001097694840834,
            "logloss": 0.6172293861291971,
            "mae": 0.33696814347569687,
            "precision": 0.8093023255813954,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7472078625882722,
            "auditor_fn_violation": 0.01575484764542937,
            "auditor_fp_violation": 0.02370921822099107,
            "ave_precision_score": 0.6897656908224856,
            "fpr": 0.16885964912280702,
            "logloss": 4.966639459249661,
            "mae": 0.3219026101302608,
            "precision": 0.6818181818181818,
            "recall": 0.7236842105263158
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7923389577585742,
            "auditor_fn_violation": 0.006193820286635015,
            "auditor_fp_violation": 0.01816910879405066,
            "ave_precision_score": 0.7474268727571539,
            "fpr": 0.1525795828759605,
            "logloss": 4.719225592973293,
            "mae": 0.3194870787008013,
            "precision": 0.7225548902195609,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6546496300927525,
            "auditor_fn_violation": 0.01626461988304094,
            "auditor_fp_violation": 0.012559152816251157,
            "ave_precision_score": 0.6556226343934581,
            "fpr": 0.20723684210526316,
            "logloss": 0.6854384136396957,
            "mae": 0.4096898616356939,
            "precision": 0.6493506493506493,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7003228190784949,
            "auditor_fn_violation": 0.004011655844012717,
            "auditor_fp_violation": 0.016420239047636766,
            "ave_precision_score": 0.701113162074871,
            "fpr": 0.19538968166849616,
            "logloss": 0.6562791009287535,
            "mae": 0.4016843458063058,
            "precision": 0.6827094474153298,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.7161536682973341,
            "auditor_fn_violation": 0.01620210064635273,
            "auditor_fp_violation": 0.02112188365650972,
            "ave_precision_score": 0.6841548104328884,
            "fpr": 0.3157894736842105,
            "logloss": 0.6204187649184744,
            "mae": 0.42969143897164286,
            "precision": 0.504302925989673,
            "recall": 0.6425438596491229
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7506025041026241,
            "auditor_fn_violation": 0.01011069525081666,
            "auditor_fp_violation": 0.01929072434570212,
            "ave_precision_score": 0.7093192925505113,
            "fpr": 0.2711306256860593,
            "logloss": 0.625804007270261,
            "mae": 0.42852856145208673,
            "precision": 0.5711805555555556,
            "recall": 0.6606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8096096639574477,
            "auditor_fn_violation": 0.02942251461988304,
            "auditor_fp_violation": 0.02889350569405971,
            "ave_precision_score": 0.8104403298757485,
            "fpr": 0.10964912280701754,
            "logloss": 0.9826803826339622,
            "mae": 0.29179684875802203,
            "precision": 0.7635933806146572,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7981585158340685,
            "auditor_fn_violation": 0.031165275812360314,
            "auditor_fp_violation": 0.02126551191650078,
            "ave_precision_score": 0.797258722621476,
            "fpr": 0.11086717892425905,
            "logloss": 1.2641647489506354,
            "mae": 0.33351084801806374,
            "precision": 0.7672811059907834,
            "recall": 0.6686746987951807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7513747559353134,
            "auditor_fn_violation": 0.027960526315789477,
            "auditor_fp_violation": 0.021742266851338874,
            "ave_precision_score": 0.7518261461525868,
            "fpr": 0.17763157894736842,
            "logloss": 0.7204320045134501,
            "mae": 0.39958161462033004,
            "precision": 0.6531049250535332,
            "recall": 0.668859649122807
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7882338828509673,
            "auditor_fn_violation": 0.013789515912166785,
            "auditor_fp_violation": 0.028385910169757316,
            "ave_precision_score": 0.7887375833697833,
            "fpr": 0.1525795828759605,
            "logloss": 0.6599574915991046,
            "mae": 0.3747386809736981,
            "precision": 0.7151639344262295,
            "recall": 0.7008032128514057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6142702112814121,
            "auditor_fn_violation": 0.03581149969221299,
            "auditor_fp_violation": 0.033414127423822715,
            "ave_precision_score": 0.6144593839616302,
            "fpr": 0.2236842105263158,
            "logloss": 0.8231319413924825,
            "mae": 0.43108854324486157,
            "precision": 0.6084452975047985,
            "recall": 0.6951754385964912
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6479640547787007,
            "auditor_fn_violation": 0.04051551981802072,
            "auditor_fp_violation": 0.02793407452098778,
            "ave_precision_score": 0.6486891025589987,
            "fpr": 0.20417124039517015,
            "logloss": 0.859394795634512,
            "mae": 0.44038593003369086,
            "precision": 0.6287425149700598,
            "recall": 0.6325301204819277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8177762612805637,
            "auditor_fn_violation": 0.009697695444752234,
            "auditor_fp_violation": 0.010676361957525391,
            "ave_precision_score": 0.8181284954362436,
            "fpr": 0.19078947368421054,
            "logloss": 0.8884594501008021,
            "mae": 0.3404905104639617,
            "precision": 0.678373382624769,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7978837659307729,
            "auditor_fn_violation": 0.011492732731144126,
            "auditor_fp_violation": 0.030432459873007602,
            "ave_precision_score": 0.7981859161109474,
            "fpr": 0.16794731064763996,
            "logloss": 1.0085796668258495,
            "mae": 0.35307379652579296,
            "precision": 0.7085714285714285,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5911192929230736,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5926012179991749,
            "fpr": 0.4956140350877193,
            "logloss": 0.9821384809703755,
            "mae": 0.48889362625675603,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.645449166574402,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.6473011104915775,
            "fpr": 0.4445664105378705,
            "logloss": 0.8922259116508463,
            "mae": 0.45433044453835447,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7552164399880908,
            "auditor_fn_violation": 0.022622345337026784,
            "auditor_fp_violation": 0.024952389196675907,
            "ave_precision_score": 0.7626481705816044,
            "fpr": 0.13048245614035087,
            "logloss": 1.3560338206573281,
            "mae": 0.37240514339693065,
            "precision": 0.7276887871853547,
            "recall": 0.6973684210526315
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7339597036068686,
            "auditor_fn_violation": 0.039907158821895716,
            "auditor_fp_violation": 0.021727978992300192,
            "ave_precision_score": 0.7421571856695667,
            "fpr": 0.15477497255762898,
            "logloss": 1.5969117546039366,
            "mae": 0.40741493417958946,
            "precision": 0.6948051948051948,
            "recall": 0.6445783132530121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.7935206286514167,
            "auditor_fn_violation": 0.008098645737149893,
            "auditor_fp_violation": 0.006278374115112354,
            "ave_precision_score": 0.793836432143514,
            "fpr": 0.4616228070175439,
            "logloss": 0.626644089866896,
            "mae": 0.4255702731550851,
            "precision": 0.5005931198102017,
            "recall": 0.9254385964912281
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.7911211108615881,
            "auditor_fn_violation": 0.0018471250534520109,
            "auditor_fp_violation": 0.006636668323397384,
            "ave_precision_score": 0.7914576871318938,
            "fpr": 0.41822173435784854,
            "logloss": 0.6137652472252612,
            "mae": 0.4214059057861207,
            "precision": 0.5475059382422803,
            "recall": 0.9257028112449799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.5630453861793533,
            "auditor_fn_violation": 0.004905355493998153,
            "auditor_fp_violation": 0.007713911972914744,
            "ave_precision_score": 0.5638652928620507,
            "fpr": 0.4649122807017544,
            "logloss": 0.6920295934114812,
            "mae": 0.498893883994274,
            "precision": 0.5126436781609195,
            "recall": 0.9780701754385965
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5843976992738947,
            "auditor_fn_violation": 0.005043224489615984,
            "auditor_fp_violation": 0.0032505588143832594,
            "ave_precision_score": 0.5867294347161451,
            "fpr": 0.424807903402854,
            "logloss": 0.6900517451085647,
            "mae": 0.49796648374242397,
            "precision": 0.5526011560693641,
            "recall": 0.9598393574297188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 19863,
        "test": {
            "accuracy": 0.3519736842105263,
            "auc_prc": 0.47609375469495663,
            "auditor_fn_violation": 0.022131809787626983,
            "auditor_fp_violation": 0.01187144121268084,
            "ave_precision_score": 0.45835744525453576,
            "fpr": 0.3366228070175439,
            "logloss": 0.726602906509522,
            "mae": 0.5124800324832138,
            "precision": 0.35908141962421714,
            "recall": 0.37719298245614036
        },
        "train": {
            "accuracy": 0.3512623490669594,
            "auc_prc": 0.5143662698039311,
            "auditor_fn_violation": 0.010758731964080273,
            "auditor_fp_violation": 0.017531223172258362,
            "ave_precision_score": 0.4970650392450188,
            "fpr": 0.31394072447859495,
            "logloss": 0.7224706883292689,
            "mae": 0.5105606892302583,
            "precision": 0.40292275574112735,
            "recall": 0.38755020080321284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5688327471994539,
            "auditor_fn_violation": 0.019455505540166205,
            "auditor_fp_violation": 0.011438615727916289,
            "ave_precision_score": 0.5417323370473354,
            "fpr": 0.4418859649122807,
            "logloss": 2.6130724409528514,
            "mae": 0.48589928059332205,
            "precision": 0.5097323600973236,
            "recall": 0.918859649122807
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5980809509915366,
            "auditor_fn_violation": 0.011422198122897744,
            "auditor_fp_violation": 0.014562397174166696,
            "ave_precision_score": 0.583741094102699,
            "fpr": 0.38638858397365533,
            "logloss": 1.8851199296147227,
            "mae": 0.4789408745344332,
            "precision": 0.5616438356164384,
            "recall": 0.9056224899598394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5015935281169956,
            "auditor_fn_violation": 0.006759291320406279,
            "auditor_fp_violation": 0.0039627577716220405,
            "ave_precision_score": 0.4744079457538703,
            "fpr": 0.4780701754385965,
            "logloss": 0.7009946421277211,
            "mae": 0.49981510381034594,
            "precision": 0.4982738780207135,
            "recall": 0.9495614035087719
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5851922695635616,
            "auditor_fn_violation": 0.005567825638448417,
            "auditor_fp_violation": 0.005049927839189036,
            "ave_precision_score": 0.5490958482164281,
            "fpr": 0.429198682766191,
            "logloss": 0.6889362920807032,
            "mae": 0.4938389532652435,
            "precision": 0.543757292882147,
            "recall": 0.9357429718875502
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.726551469318178,
            "auditor_fn_violation": 0.030018851954447527,
            "auditor_fp_violation": 0.03420764081255771,
            "ave_precision_score": 0.7278052234447047,
            "fpr": 0.16447368421052633,
            "logloss": 1.1965401097603698,
            "mae": 0.31330213168941407,
            "precision": 0.6919917864476386,
            "recall": 0.7390350877192983
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7669667584226014,
            "auditor_fn_violation": 0.03078835649954373,
            "auditor_fp_violation": 0.03299197593044921,
            "ave_precision_score": 0.7675089459051946,
            "fpr": 0.1602634467618002,
            "logloss": 1.1564588756701042,
            "mae": 0.32893771707468455,
            "precision": 0.708,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6903655355644369,
            "auditor_fn_violation": 0.007790858725761773,
            "auditor_fp_violation": 0.003174053554939977,
            "ave_precision_score": 0.5900431453467312,
            "fpr": 0.4298245614035088,
            "logloss": 0.6799603568002545,
            "mae": 0.47297468142616644,
            "precision": 0.5172413793103449,
            "recall": 0.9210526315789473
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7242542227843887,
            "auditor_fn_violation": 0.005607501355587002,
            "auditor_fp_violation": 0.00487716714995362,
            "ave_precision_score": 0.641388523056524,
            "fpr": 0.38309549945115257,
            "logloss": 0.6646843423916081,
            "mae": 0.4676943534063063,
            "precision": 0.5576679340937896,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.4390376883708421,
            "auditor_fn_violation": 0.0012744305940289322,
            "auditor_fp_violation": 0.0015293167128347166,
            "ave_precision_score": 0.48198407017077094,
            "fpr": 0.4967105263157895,
            "logloss": 1.953225748818,
            "mae": 0.500971932160227,
            "precision": 0.5005512679162073,
            "recall": 0.9956140350877193
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.4665557930629557,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006644641893669852,
            "ave_precision_score": 0.5109731264588488,
            "fpr": 0.4522502744237102,
            "logloss": 1.9659455886774087,
            "mae": 0.4623847918505203,
            "precision": 0.5472527472527473,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8045920694322101,
            "auditor_fn_violation": 0.007521545090797164,
            "auditor_fp_violation": 0.012792397660818718,
            "ave_precision_score": 0.7977821252931435,
            "fpr": 0.08333333333333333,
            "logloss": 0.5518247270280795,
            "mae": 0.34007435573342565,
            "precision": 0.8036175710594315,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8046411681930384,
            "auditor_fn_violation": 0.009180520104567566,
            "auditor_fp_violation": 0.011981618262665356,
            "ave_precision_score": 0.8008727676117757,
            "fpr": 0.07793633369923161,
            "logloss": 0.5885129097402709,
            "mae": 0.3562330131640844,
            "precision": 0.8197969543147208,
            "recall": 0.6485943775100401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8570304475713455,
            "auditor_fn_violation": 0.006723222530009232,
            "auditor_fp_violation": 0.006141312711603575,
            "ave_precision_score": 0.8528522486038765,
            "fpr": 0.14692982456140352,
            "logloss": 0.47182020873424685,
            "mae": 0.3145587693311666,
            "precision": 0.73828125,
            "recall": 0.8289473684210527
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8523808090952931,
            "auditor_fn_violation": 0.01492468226363192,
            "auditor_fp_violation": 0.0162767147827335,
            "ave_precision_score": 0.8485489679367996,
            "fpr": 0.13391877058177826,
            "logloss": 0.5041881843077907,
            "mae": 0.3304343236330181,
            "precision": 0.7631067961165049,
            "recall": 0.7891566265060241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.269388197455342,
            "mae": 0.5,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.45334796926454446,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.880692255395743,
            "mae": 0.5466520307354555,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7939976522486104,
            "auditor_fn_violation": 0.004955851800554017,
            "auditor_fp_violation": 0.005092913204062788,
            "ave_precision_score": 0.7147995247802084,
            "fpr": 0.3848684210526316,
            "logloss": 0.7514467787734964,
            "mae": 0.4079933400805059,
            "precision": 0.5534351145038168,
            "recall": 0.9539473684210527
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7988298226451954,
            "auditor_fn_violation": 0.009650016090707507,
            "auditor_fp_violation": 0.015939166974535075,
            "ave_precision_score": 0.7362871475736024,
            "fpr": 0.3336992316136114,
            "logloss": 0.6983600095995615,
            "mae": 0.3852328907219953,
            "precision": 0.6082474226804123,
            "recall": 0.9477911646586346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8409340687168267,
            "auditor_fn_violation": 0.008197233764235149,
            "auditor_fp_violation": 0.0043859649122807015,
            "ave_precision_score": 0.7293439285280174,
            "fpr": 0.09429824561403509,
            "logloss": 0.523119143587281,
            "mae": 0.3584685312878144,
            "precision": 0.8013856812933026,
            "recall": 0.7609649122807017
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.836375866214712,
            "auditor_fn_violation": 0.012127544205361517,
            "auditor_fp_violation": 0.014323190065994583,
            "ave_precision_score": 0.7301907909892449,
            "fpr": 0.09001097694840834,
            "logloss": 0.5605579732441087,
            "mae": 0.37608615689298586,
            "precision": 0.8093023255813954,
            "recall": 0.6987951807228916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.8081152838291961,
            "auditor_fn_violation": 0.0022218374884579897,
            "auditor_fp_violation": 0.008714219759926147,
            "ave_precision_score": 0.7056486381409325,
            "fpr": 0.2894736842105263,
            "logloss": 0.5780657487394911,
            "mae": 0.375455982456475,
            "precision": 0.6173913043478261,
            "recall": 0.9342105263157895
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8220157818848253,
            "auditor_fn_violation": 0.0033525980982106254,
            "auditor_fp_violation": 0.015027522106723588,
            "ave_precision_score": 0.7310742200543882,
            "fpr": 0.2601536772777168,
            "logloss": 0.5636769276365511,
            "mae": 0.3693545475529526,
            "precision": 0.6594827586206896,
            "recall": 0.9216867469879518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 19863,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7088389902936051,
            "auditor_fn_violation": 0.014600646352723916,
            "auditor_fp_violation": 0.020280278547245314,
            "ave_precision_score": 0.7091510584422266,
            "fpr": 0.1787280701754386,
            "logloss": 2.011122559118172,
            "mae": 0.32888123378365747,
            "precision": 0.6680244399185336,
            "recall": 0.7192982456140351
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7707428800992268,
            "auditor_fn_violation": 0.006771322391652229,
            "auditor_fp_violation": 0.024848302825567527,
            "ave_precision_score": 0.7705097804508976,
            "fpr": 0.15587266739846323,
            "logloss": 2.1676211268471275,
            "mae": 0.3275247031982653,
            "precision": 0.7107942973523421,
            "recall": 0.7008032128514057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.745896600404265,
            "auditor_fn_violation": 0.010936057248384123,
            "auditor_fp_violation": 0.0045182171437365545,
            "ave_precision_score": 0.5451978583730316,
            "fpr": 0.3607456140350877,
            "logloss": 0.7102783474151949,
            "mae": 0.4760626158694485,
            "precision": 0.5499316005471956,
            "recall": 0.881578947368421
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.3402849138665892,
            "auditor_fn_violation": 0.02444685437689286,
            "auditor_fp_violation": 0.020744571992037063,
            "ave_precision_score": 0.5989410480400607,
            "fpr": 0.30735455543358947,
            "logloss": 0.6655808240808124,
            "mae": 0.46093701880829985,
            "precision": 0.6061884669479606,
            "recall": 0.8654618473895582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8451400211942545,
            "auditor_fn_violation": 0.01754385964912281,
            "auditor_fp_violation": 0.030846029547553094,
            "ave_precision_score": 0.8299800615061431,
            "fpr": 0.14473684210526316,
            "logloss": 0.4882954147740524,
            "mae": 0.3210972736491577,
            "precision": 0.7391304347826086,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.844525923079111,
            "auditor_fn_violation": 0.022253668901732068,
            "auditor_fp_violation": 0.027054323934265895,
            "ave_precision_score": 0.8252714477898567,
            "fpr": 0.12184412733260154,
            "logloss": 0.5063988997629815,
            "mae": 0.32846598045820724,
            "precision": 0.7762096774193549,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8616854629732864,
            "auditor_fn_violation": 0.012503847337642352,
            "auditor_fp_violation": 0.015194579101261929,
            "ave_precision_score": 0.8493554497489665,
            "fpr": 0.11732456140350878,
            "logloss": 0.47363232128687416,
            "mae": 0.32361411608820945,
            "precision": 0.7742616033755274,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8568122849689099,
            "auditor_fn_violation": 0.0068374485868832185,
            "auditor_fp_violation": 0.010530428473087881,
            "ave_precision_score": 0.8456916082061059,
            "fpr": 0.11745334796926454,
            "logloss": 0.49901014179924136,
            "mae": 0.33535299241608246,
            "precision": 0.7775467775467776,
            "recall": 0.751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4440789473684211,
            "auc_prc": 0.4924762147486837,
            "auditor_fn_violation": 0.005936922899353658,
            "auditor_fp_violation": 0.01067636195752539,
            "ave_precision_score": 0.47348501305868324,
            "fpr": 0.28289473684210525,
            "logloss": 0.7413144187914663,
            "mae": 0.5149513520627168,
            "precision": 0.44516129032258067,
            "recall": 0.45394736842105265
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.546976866641277,
            "auditor_fn_violation": 0.006714013022452064,
            "auditor_fp_violation": 0.0146288435931034,
            "ave_precision_score": 0.5328799532384014,
            "fpr": 0.22722283205268934,
            "logloss": 0.7429519532867565,
            "mae": 0.5141895349606724,
            "precision": 0.5219399538106235,
            "recall": 0.4538152610441767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502786562602758,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016501769860151,
            "fpr": 0.4956140350877193,
            "logloss": 0.712475255693418,
            "mae": 0.4981663657217394,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4445664105378705,
            "logloss": 0.6818646169295747,
            "mae": 0.48974695340793034,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8606820139944368,
            "auditor_fn_violation": 0.015331640504770698,
            "auditor_fp_violation": 0.019349703755001554,
            "ave_precision_score": 0.8484708601568238,
            "fpr": 0.20942982456140352,
            "logloss": 0.4873654909630163,
            "mae": 0.30829434125370136,
            "precision": 0.6735042735042736,
            "recall": 0.8640350877192983
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8548414577380001,
            "auditor_fn_violation": 0.008153359871979692,
            "auditor_fp_violation": 0.02436988860922331,
            "ave_precision_score": 0.8445057548191576,
            "fpr": 0.18660812294182216,
            "logloss": 0.5131624330251107,
            "mae": 0.3222092494880338,
            "precision": 0.7133220910623946,
            "recall": 0.8493975903614458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5903141570789167,
            "auditor_fn_violation": 0.010070406278855037,
            "auditor_fp_violation": 0.0273088835026162,
            "ave_precision_score": 0.5924316821883069,
            "fpr": 0.40021929824561403,
            "logloss": 0.6988504229732687,
            "mae": 0.47601992135873605,
            "precision": 0.5314505776636713,
            "recall": 0.9078947368421053
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6319586212533705,
            "auditor_fn_violation": 0.006830835967360111,
            "auditor_fp_violation": 0.020728624851492267,
            "ave_precision_score": 0.6330593801696922,
            "fpr": 0.35236004390779363,
            "logloss": 0.670996905112008,
            "mae": 0.466055842237363,
            "precision": 0.58203125,
            "recall": 0.8975903614457831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8313378563264966,
            "auditor_fn_violation": 0.013465681748230226,
            "auditor_fp_violation": 0.017890120036934447,
            "ave_precision_score": 0.8270115833730244,
            "fpr": 0.09210526315789473,
            "logloss": 0.5038768466016236,
            "mae": 0.30479262483698366,
            "precision": 0.7961165048543689,
            "recall": 0.7192982456140351
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8034150951496194,
            "auditor_fn_violation": 0.018462433708489285,
            "auditor_fp_violation": 0.024423045744372655,
            "ave_precision_score": 0.838445431495187,
            "fpr": 0.09330406147091108,
            "logloss": 0.536717012882463,
            "mae": 0.31781290109963467,
            "precision": 0.802784222737819,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.5431708299088094,
            "auditor_fn_violation": 0.014215912588488764,
            "auditor_fp_violation": 0.03546523930440137,
            "ave_precision_score": 0.5272579786632093,
            "fpr": 0.38048245614035087,
            "logloss": 2.874798739247415,
            "mae": 0.42907446975565716,
            "precision": 0.5499351491569391,
            "recall": 0.9298245614035088
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6446307618456801,
            "auditor_fn_violation": 0.024175736976445848,
            "auditor_fp_violation": 0.02453733358494378,
            "ave_precision_score": 0.629357087582725,
            "fpr": 0.33150384193194293,
            "logloss": 2.152395207126707,
            "mae": 0.3965445371915676,
            "precision": 0.5967957276368492,
            "recall": 0.8975903614457831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 19863,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7992542700117229,
            "auditor_fn_violation": 0.024634983841181908,
            "auditor_fp_violation": 0.04019506001846722,
            "ave_precision_score": 0.7813369545759505,
            "fpr": 0.2324561403508772,
            "logloss": 0.5680494460920145,
            "mae": 0.3895919906759733,
            "precision": 0.6472545757071547,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7931473537563994,
            "auditor_fn_violation": 0.02875166968642958,
            "auditor_fp_violation": 0.03590498693663404,
            "ave_precision_score": 0.7763932836569644,
            "fpr": 0.21405049396267836,
            "logloss": 0.5778691924259178,
            "mae": 0.39042052904677577,
            "precision": 0.6755407653910149,
            "recall": 0.8152610441767069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8597873862784644,
            "auditor_fn_violation": 0.012811634349030472,
            "auditor_fp_violation": 0.021352723915050786,
            "ave_precision_score": 0.8599929115034571,
            "fpr": 0.20065789473684212,
            "logloss": 0.5872081200845555,
            "mae": 0.29491418556578086,
            "precision": 0.6839378238341969,
            "recall": 0.868421052631579
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.849358378377561,
            "auditor_fn_violation": 0.006877124304021795,
            "auditor_fp_violation": 0.028234412334581644,
            "ave_precision_score": 0.8500505861518766,
            "fpr": 0.1734357848518112,
            "logloss": 0.5743665198789667,
            "mae": 0.28915640111191,
            "precision": 0.726643598615917,
            "recall": 0.8433734939759037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.6093187856678307,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5325763354704154,
            "fpr": 0.5,
            "logloss": 0.7080960525074143,
            "mae": 0.49685415011226086,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6527953513813769,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5868468881427098,
            "fpr": 0.45334796926454446,
            "logloss": 0.6881256577953256,
            "mae": 0.4872104886727066,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8548067586495118,
            "auditor_fn_violation": 0.006477954755309326,
            "auditor_fp_violation": 0.013193963527239162,
            "ave_precision_score": 0.8301576139392983,
            "fpr": 0.24451754385964913,
            "logloss": 0.5576441506467498,
            "mae": 0.35999069637373876,
            "precision": 0.6499215070643642,
            "recall": 0.9078947368421053
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8530152599581173,
            "auditor_fn_violation": 0.0036986585199194166,
            "auditor_fp_violation": 0.02477388283635842,
            "ave_precision_score": 0.8292576468115918,
            "fpr": 0.21734357848518113,
            "logloss": 0.5479706025797376,
            "mae": 0.3537397393803434,
            "precision": 0.6896551724137931,
            "recall": 0.8835341365461847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8539013961416968,
            "auditor_fn_violation": 0.0035323368728839635,
            "auditor_fp_violation": 0.004828408741151131,
            "ave_precision_score": 0.8057732776040701,
            "fpr": 0.22149122807017543,
            "logloss": 0.5369232522100174,
            "mae": 0.3425247115328124,
            "precision": 0.6693944353518821,
            "recall": 0.8969298245614035
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8359394300122793,
            "auditor_fn_violation": 0.0005532558334325284,
            "auditor_fp_violation": 0.016675393296353695,
            "ave_precision_score": 0.7861735469041691,
            "fpr": 0.18221734357848518,
            "logloss": 0.5495812791236889,
            "mae": 0.3439621097693459,
            "precision": 0.7228714524207012,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.8039323483285608,
            "auditor_fn_violation": 0.027989381348107106,
            "auditor_fp_violation": 0.05326638965835643,
            "ave_precision_score": 0.8042604209502785,
            "fpr": 0.34649122807017546,
            "logloss": 1.562611948339073,
            "mae": 0.39006609412310167,
            "precision": 0.56353591160221,
            "recall": 0.8947368421052632
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.8029014335929389,
            "auditor_fn_violation": 0.03567949074012847,
            "auditor_fp_violation": 0.03454416427681047,
            "ave_precision_score": 0.8034527636403443,
            "fpr": 0.3106476399560922,
            "logloss": 1.8472103338513608,
            "mae": 0.3822581208573209,
            "precision": 0.6069444444444444,
            "recall": 0.8775100401606426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.4594361561938131,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.3922245088375893,
            "fpr": 0.5,
            "logloss": 0.6943027589534928,
            "mae": 0.5000032893659776,
            "precision": 0.5,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.5260785397683607,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.44771618086215104,
            "fpr": 0.45334796926454446,
            "logloss": 0.6898217654577518,
            "mae": 0.49776441591631304,
            "precision": 0.5466520307354555,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8002832014072321,
            "auditor_fn_violation": 0.002457486919052018,
            "auditor_fp_violation": 0.006179786088027086,
            "ave_precision_score": 0.7436253817775523,
            "fpr": 0.09320175438596491,
            "logloss": 0.5258923434358408,
            "mae": 0.3657929710063495,
            "precision": 0.802784222737819,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8084648394316974,
            "auditor_fn_violation": 0.012167219922500106,
            "auditor_fp_violation": 0.013679988730687348,
            "ave_precision_score": 0.7515500584469874,
            "fpr": 0.0889132821075741,
            "logloss": 0.5655725373048779,
            "mae": 0.3846253208349879,
            "precision": 0.8094117647058824,
            "recall": 0.6907630522088354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.5560831807288648,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5408009339558186,
            "fpr": 0.4956140350877193,
            "logloss": 5.322801063332671,
            "mae": 0.49671057989839656,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5785374076526253,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5711772920679374,
            "fpr": 0.4445664105378705,
            "logloss": 4.7624680927021315,
            "mae": 0.4445687058724615,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.8245196498974864,
            "auditor_fn_violation": 0.006194213604185904,
            "auditor_fp_violation": 0.014355378578024009,
            "ave_precision_score": 0.8250910113899791,
            "fpr": 0.3969298245614035,
            "logloss": 0.7084082915766916,
            "mae": 0.3439832165942247,
            "precision": 0.5480649188514357,
            "recall": 0.9627192982456141
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.81149177356646,
            "auditor_fn_violation": 0.0027773001997011093,
            "auditor_fp_violation": 0.010623453459599256,
            "ave_precision_score": 0.8121534218304218,
            "fpr": 0.3380900109769484,
            "logloss": 0.720770268027747,
            "mae": 0.3326663591065365,
            "precision": 0.6030927835051546,
            "recall": 0.9397590361445783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6629113748607784,
            "auditor_fn_violation": 0.06394275161588181,
            "auditor_fp_violation": 0.08327802785472453,
            "ave_precision_score": 0.6990940233077079,
            "fpr": 0.30153508771929827,
            "logloss": 0.6365803082099898,
            "mae": 0.4028157996699998,
            "precision": 0.5669291338582677,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7362765760009191,
            "auditor_fn_violation": 0.06030268163763726,
            "auditor_fp_violation": 0.08167593815698898,
            "ave_precision_score": 0.69241165388553,
            "fpr": 0.29198682766191,
            "logloss": 0.6448004275929575,
            "mae": 0.40579939443049656,
            "precision": 0.6047548291233283,
            "recall": 0.8172690763052208
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7645159383776456,
            "auditor_fn_violation": 0.011513157894736843,
            "auditor_fp_violation": 0.016331948291782087,
            "ave_precision_score": 0.745540439201707,
            "fpr": 0.17214912280701755,
            "logloss": 1.7257902310892548,
            "mae": 0.28889236284298375,
            "precision": 0.7037735849056603,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8165737048575512,
            "auditor_fn_violation": 0.0058984566146033125,
            "auditor_fp_violation": 0.024617069287667815,
            "ave_precision_score": 0.8027855152586258,
            "fpr": 0.1394072447859495,
            "logloss": 1.4293229921855923,
            "mae": 0.2816039050232034,
            "precision": 0.7543520309477756,
            "recall": 0.7831325301204819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 19863,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7850792722705038,
            "auditor_fn_violation": 0.003347183748845809,
            "auditor_fp_violation": 0.011743998153277938,
            "ave_precision_score": 0.7757480604585989,
            "fpr": 0.10855263157894737,
            "logloss": 0.5664368949621759,
            "mae": 0.35520623653131744,
            "precision": 0.7765237020316027,
            "recall": 0.7543859649122807
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7963024968786578,
            "auditor_fn_violation": 0.011757237512068032,
            "auditor_fp_violation": 0.016098638379983155,
            "ave_precision_score": 0.792200882451246,
            "fpr": 0.10098792535675083,
            "logloss": 0.5667788303613842,
            "mae": 0.3675623339878281,
            "precision": 0.7923250564334086,
            "recall": 0.7048192771084337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7593729894872534,
            "auditor_fn_violation": 0.008502616189596805,
            "auditor_fp_violation": 0.013157894736842105,
            "ave_precision_score": 0.7604667963751388,
            "fpr": 0.11403508771929824,
            "logloss": 0.5483223423848779,
            "mae": 0.3658931344827196,
            "precision": 0.7688888888888888,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8063402973283365,
            "auditor_fn_violation": 0.009764634829107874,
            "auditor_fp_violation": 0.016255451928673757,
            "ave_precision_score": 0.8069254488066301,
            "fpr": 0.10098792535675083,
            "logloss": 0.546382140531798,
            "mae": 0.3702898391090031,
            "precision": 0.7941834451901566,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5776743846756816,
            "auditor_fn_violation": 0.035818713450292416,
            "auditor_fp_violation": 0.027181440443213297,
            "ave_precision_score": 0.5784884865915136,
            "fpr": 0.3190789473684211,
            "logloss": 0.8860676840915168,
            "mae": 0.47789070436632947,
            "precision": 0.5109243697478991,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.613624374083607,
            "auditor_fn_violation": 0.03289116950788886,
            "auditor_fp_violation": 0.022368522470849965,
            "ave_precision_score": 0.6145869530515783,
            "fpr": 0.2678375411635565,
            "logloss": 0.8329057737993443,
            "mae": 0.4513655079530734,
            "precision": 0.5821917808219178,
            "recall": 0.6827309236947792
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8150720207860223,
            "auditor_fn_violation": 0.010132925515543243,
            "auditor_fp_violation": 0.003539550630963375,
            "ave_precision_score": 0.7785656966083754,
            "fpr": 0.09429824561403509,
            "logloss": 0.5365297182654393,
            "mae": 0.37180249644606783,
            "precision": 0.7828282828282829,
            "recall": 0.6798245614035088
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8150502255369461,
            "auditor_fn_violation": 0.012440541529454814,
            "auditor_fp_violation": 0.01190188255994132,
            "ave_precision_score": 0.7820323703037766,
            "fpr": 0.09001097694840834,
            "logloss": 0.5593236409152793,
            "mae": 0.3798548280865641,
            "precision": 0.7955112219451371,
            "recall": 0.6405622489959839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7927631578947368,
            "auc_prc": 0.8567477859190026,
            "auditor_fn_violation": 0.007675438596491229,
            "auditor_fp_violation": 0.00018755771006463532,
            "ave_precision_score": 0.8509052786139905,
            "fpr": 0.10197368421052631,
            "logloss": 0.47388601421989185,
            "mae": 0.2955782713303179,
            "precision": 0.7947019867549668,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8483214257987088,
            "auditor_fn_violation": 0.008966712073320728,
            "auditor_fp_violation": 0.004826667871561732,
            "ave_precision_score": 0.8436841520936409,
            "fpr": 0.09330406147091108,
            "logloss": 0.5070330152340426,
            "mae": 0.30922095414606854,
            "precision": 0.8089887640449438,
            "recall": 0.7228915662650602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.5920481614918236,
            "auditor_fn_violation": 0.0053021121883656515,
            "auditor_fp_violation": 0.011707929362880893,
            "ave_precision_score": 0.5926034691548664,
            "fpr": 0.4769736842105263,
            "logloss": 1.297483311253624,
            "mae": 0.4679165148541838,
            "precision": 0.5079185520361991,
            "recall": 0.9846491228070176
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6134691257480431,
            "auditor_fn_violation": 0.0043907793633369925,
            "auditor_fp_violation": 0.014554423603894303,
            "ave_precision_score": 0.6140947430952945,
            "fpr": 0.4281009879253567,
            "logloss": 1.191411815778474,
            "mae": 0.44125295327475417,
            "precision": 0.5578231292517006,
            "recall": 0.9879518072289156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502780504684308,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016501769860151,
            "fpr": 0.4956140350877193,
            "logloss": 17.126557359953416,
            "mae": 0.49671232410381844,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4445664105378705,
            "logloss": 15.355139960799724,
            "mae": 0.4445710496930457,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.7218343180114359,
            "auditor_fn_violation": 0.008981128808864269,
            "auditor_fp_violation": 0.003871383502616194,
            "ave_precision_score": 0.7518070795240052,
            "fpr": 0.11293859649122807,
            "logloss": 0.5241916228310468,
            "mae": 0.3517848759268721,
            "precision": 0.778969957081545,
            "recall": 0.7960526315789473
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.747685541193651,
            "auditor_fn_violation": 0.007216572106207489,
            "auditor_fp_violation": 0.010006830691866694,
            "ave_precision_score": 0.7509505337404145,
            "fpr": 0.11306256860592755,
            "logloss": 0.5770211750733316,
            "mae": 0.37532383033394423,
            "precision": 0.775599128540305,
            "recall": 0.714859437751004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7916311158806201,
            "auditor_fn_violation": 0.009442809325946445,
            "auditor_fp_violation": 0.0022218374884579893,
            "ave_precision_score": 0.6989005020088472,
            "fpr": 0.13486842105263158,
            "logloss": 0.6139694023384793,
            "mae": 0.4148131222382449,
            "precision": 0.7217194570135747,
            "recall": 0.6995614035087719
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8009983441876385,
            "auditor_fn_violation": 0.004739043991553484,
            "auditor_fp_violation": 0.006487828344979184,
            "ave_precision_score": 0.7161370398024043,
            "fpr": 0.12403951701427003,
            "logloss": 0.6077509776022145,
            "mae": 0.41201353565463644,
            "precision": 0.7472035794183445,
            "recall": 0.6706827309236948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 19863,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.7217970716171904,
            "auditor_fn_violation": 0.02159318251769775,
            "auditor_fp_violation": 0.033500692520775636,
            "ave_precision_score": 0.7227464201092045,
            "fpr": 0.28728070175438597,
            "logloss": 0.7505673500692641,
            "mae": 0.3989398906946601,
            "precision": 0.5760517799352751,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7545043603397453,
            "auditor_fn_violation": 0.024116223400737973,
            "auditor_fp_violation": 0.022232971776219097,
            "ave_precision_score": 0.7554742176321366,
            "fpr": 0.21514818880351264,
            "logloss": 0.6520430532168486,
            "mae": 0.3717069005136581,
            "precision": 0.666098807495741,
            "recall": 0.785140562248996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 19863,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6152779967915866,
            "auditor_fn_violation": 0.0022362650046168246,
            "auditor_fp_violation": 0.003520313942751617,
            "ave_precision_score": 0.6067372302148043,
            "fpr": 0.013157894736842105,
            "logloss": 0.9291024479385156,
            "mae": 0.4788240934150261,
            "precision": 0.3333333333333333,
            "recall": 0.013157894736842105
        },
        "train": {
            "accuracy": 0.4434687156970362,
            "auc_prc": 0.6310736373605801,
            "auditor_fn_violation": 0.0017148726629900477,
            "auditor_fp_violation": 0.004885140720226025,
            "ave_precision_score": 0.6243298796206164,
            "fpr": 0.018660812294182216,
            "logloss": 1.037811761742609,
            "mae": 0.5105327785334066,
            "precision": 0.32,
            "recall": 0.01606425702811245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6657326608210168,
            "auditor_fn_violation": 0.04235918744228995,
            "auditor_fp_violation": 0.03699936518928901,
            "ave_precision_score": 0.6507570557183417,
            "fpr": 0.24013157894736842,
            "logloss": 0.780958657426575,
            "mae": 0.467115273682057,
            "precision": 0.5680473372781065,
            "recall": 0.631578947368421
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.6430165354498782,
            "auditor_fn_violation": 0.04216867469879519,
            "auditor_fp_violation": 0.02664501399361583,
            "ave_precision_score": 0.6320894279755296,
            "fpr": 0.21953896816684962,
            "logloss": 0.742819035617727,
            "mae": 0.48199859290752606,
            "precision": 0.5824634655532359,
            "recall": 0.5602409638554217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8150193201252657,
            "auditor_fn_violation": 0.026830370883348727,
            "auditor_fp_violation": 0.033635349338257924,
            "ave_precision_score": 0.8093256797401005,
            "fpr": 0.13925438596491227,
            "logloss": 0.5146585184000191,
            "mae": 0.3512308873775366,
            "precision": 0.741869918699187,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8196686717451729,
            "auditor_fn_violation": 0.03488597639735671,
            "auditor_fp_violation": 0.0316338111273831,
            "ave_precision_score": 0.8081632146117058,
            "fpr": 0.14818880351262348,
            "logloss": 0.565834172352976,
            "mae": 0.37841087225599684,
            "precision": 0.733201581027668,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 19863,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7601063822302467,
            "auditor_fn_violation": 0.0176640889504463,
            "auditor_fp_violation": 0.020285087719298253,
            "ave_precision_score": 0.7050430112349533,
            "fpr": 0.13815789473684212,
            "logloss": 3.8960207169080134,
            "mae": 0.29200819626911934,
            "precision": 0.7242888402625821,
            "recall": 0.7258771929824561
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8028801727869727,
            "auditor_fn_violation": 0.0042100344297056535,
            "auditor_fp_violation": 0.016476054039543594,
            "ave_precision_score": 0.7597923154712244,
            "fpr": 0.1119648737650933,
            "logloss": 3.4264308960556042,
            "mae": 0.29234211515062924,
            "precision": 0.7743362831858407,
            "recall": 0.7028112449799196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.7502798598598962,
            "auditor_fn_violation": 0.0006011465066174208,
            "auditor_fp_violation": 0.0022218374884579936,
            "ave_precision_score": 0.5016537957689461,
            "fpr": 0.4956140350877193,
            "logloss": 17.156170093128274,
            "mae": 0.4967105263157895,
            "precision": 0.5016538037486218,
            "recall": 0.9978070175438597
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7757475083056478,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003877813009145692,
            "ave_precision_score": 0.5514950166112956,
            "fpr": 0.4445664105378705,
            "logloss": 15.35513532041499,
            "mae": 0.4445664105378705,
            "precision": 0.5514950166112956,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 19863,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.8466825724715833,
            "auditor_fn_violation": 0.0043859649122807015,
            "auditor_fp_violation": 0.011606936749769167,
            "ave_precision_score": 0.8467684773362338,
            "fpr": 0.4769736842105263,
            "logloss": 4.264753741097822,
            "mae": 0.48325605694794344,
            "precision": 0.5084745762711864,
            "recall": 0.9868421052631579
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.8394883257088375,
            "auditor_fn_violation": 0.0021755518230992025,
            "auditor_fp_violation": 0.011287917648966233,
            "ave_precision_score": 0.8394826980578657,
            "fpr": 0.43249176728869376,
            "logloss": 3.831542133193285,
            "mae": 0.43589959740598244,
            "precision": 0.5568053993250843,
            "recall": 0.9939759036144579
        }
    }
]