[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6483137398826693,
            "auditor_fn_violation": 0.03701829359724097,
            "auditor_fp_violation": 0.023782005689900427,
            "ave_precision_score": 0.648969148476751,
            "fpr": 0.19078947368421054,
            "logloss": 1.7068784255667564,
            "mae": 0.412480872574472,
            "precision": 0.6200873362445415,
            "recall": 0.6068376068376068
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6489712082213119,
            "auditor_fn_violation": 0.04360287839980486,
            "auditor_fp_violation": 0.02218376703041261,
            "ave_precision_score": 0.6477981032379074,
            "fpr": 0.1800219538968167,
            "logloss": 1.843494349222036,
            "mae": 0.4243161548409305,
            "precision": 0.6395604395604395,
            "recall": 0.5987654320987654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6765807115538421,
            "auditor_fn_violation": 0.029408457040036005,
            "auditor_fp_violation": 0.024663643907064964,
            "ave_precision_score": 0.6771566630808923,
            "fpr": 0.11513157894736842,
            "logloss": 1.3671292747165062,
            "mae": 0.39546973261595314,
            "precision": 0.6827794561933535,
            "recall": 0.4829059829059829
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6729467163185638,
            "auditor_fn_violation": 0.018443983683647067,
            "auditor_fp_violation": 0.01858074514108608,
            "ave_precision_score": 0.67366106717144,
            "fpr": 0.11306256860592755,
            "logloss": 1.5109179933937777,
            "mae": 0.4068751856032504,
            "precision": 0.6906906906906907,
            "recall": 0.4732510288065844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.704801424130653,
            "auditor_fn_violation": 0.01754385964912282,
            "auditor_fp_violation": 0.010952564406511777,
            "ave_precision_score": 0.7052648635709635,
            "fpr": 0.0668859649122807,
            "logloss": 1.8048054207367883,
            "mae": 0.4055845561664602,
            "precision": 0.7370689655172413,
            "recall": 0.36538461538461536
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7219676948503451,
            "auditor_fn_violation": 0.00982504641487445,
            "auditor_fp_violation": 0.007792341964228064,
            "ave_precision_score": 0.7225238731321619,
            "fpr": 0.06476399560922064,
            "logloss": 1.804161000587988,
            "mae": 0.408398489618778,
            "precision": 0.757201646090535,
            "recall": 0.3786008230452675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.6546730532695313,
            "auditor_fn_violation": 0.0033691333033438508,
            "auditor_fp_violation": 0.013083807491702232,
            "ave_precision_score": 0.6551733099121778,
            "fpr": 0.12609649122807018,
            "logloss": 1.5358917239857344,
            "mae": 0.42748300728176614,
            "precision": 0.6627565982404692,
            "recall": 0.4829059829059829
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6400986858231584,
            "auditor_fn_violation": 0.008646040845089516,
            "auditor_fp_violation": 0.027047200878155875,
            "ave_precision_score": 0.6407543068037608,
            "fpr": 0.13062568605927552,
            "logloss": 1.67721384209432,
            "mae": 0.4469063276440737,
            "precision": 0.66,
            "recall": 0.47530864197530864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7369310110246969,
            "auditor_fn_violation": 0.02674220272904484,
            "auditor_fp_violation": 0.025130393551446185,
            "ave_precision_score": 0.7373233853726144,
            "fpr": 0.1611842105263158,
            "logloss": 1.9013615109829198,
            "mae": 0.3466639881835129,
            "precision": 0.6969072164948453,
            "recall": 0.7222222222222222
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.760279705467062,
            "auditor_fn_violation": 0.015042484855876746,
            "auditor_fp_violation": 0.02054626460902693,
            "ave_precision_score": 0.7608394682048932,
            "fpr": 0.15477497255762898,
            "logloss": 1.947306259823454,
            "mae": 0.3365810343659587,
            "precision": 0.717434869739479,
            "recall": 0.7366255144032922
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8176401368832933,
            "auditor_fn_violation": 0.010871195081721399,
            "auditor_fp_violation": 0.009646159317211949,
            "ave_precision_score": 0.8182028689297246,
            "fpr": 0.17763157894736842,
            "logloss": 0.8727746768600196,
            "mae": 0.30260682993735954,
            "precision": 0.7086330935251799,
            "recall": 0.8418803418803419
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8354263171903442,
            "auditor_fn_violation": 0.010380669729370792,
            "auditor_fp_violation": 0.016181313359591915,
            "ave_precision_score": 0.8357257958981072,
            "fpr": 0.1712403951701427,
            "logloss": 0.8465782921306663,
            "mae": 0.287976437661302,
            "precision": 0.7319587628865979,
            "recall": 0.8765432098765432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6748335233644744,
            "auditor_fn_violation": 0.0125534188034188,
            "auditor_fp_violation": 0.006144302196933775,
            "ave_precision_score": 0.6752927327282693,
            "fpr": 0.04824561403508772,
            "logloss": 3.915916198561122,
            "mae": 0.4281699342355236,
            "precision": 0.7894736842105263,
            "recall": 0.3525641025641026
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.687820559568862,
            "auditor_fn_violation": 0.016329904730929247,
            "auditor_fp_violation": 0.003644346871569705,
            "ave_precision_score": 0.6883004637911312,
            "fpr": 0.04500548847420417,
            "logloss": 4.242553593718249,
            "mae": 0.4396993029654674,
            "precision": 0.8038277511961722,
            "recall": 0.345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7642061583059128,
            "auditor_fn_violation": 0.020104682111261058,
            "auditor_fp_violation": 0.028116109530583223,
            "ave_precision_score": 0.7647413436662535,
            "fpr": 0.18969298245614036,
            "logloss": 0.7807359960059845,
            "mae": 0.32690422179677026,
            "precision": 0.6954225352112676,
            "recall": 0.844017094017094
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7606735061883227,
            "auditor_fn_violation": 0.009423010032840498,
            "auditor_fp_violation": 0.02581261703364112,
            "ave_precision_score": 0.7614667009199767,
            "fpr": 0.17892425905598244,
            "logloss": 0.7831635923287981,
            "mae": 0.31628601851152716,
            "precision": 0.7135325131810193,
            "recall": 0.8353909465020576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7830598469960648,
            "auditor_fn_violation": 0.011379610886189835,
            "auditor_fp_violation": 0.020010964912280705,
            "ave_precision_score": 0.7799089388935088,
            "fpr": 0.20285087719298245,
            "logloss": 1.6179345821768936,
            "mae": 0.31897816471265333,
            "precision": 0.6843003412969283,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7749884276919841,
            "auditor_fn_violation": 0.00935073382932878,
            "auditor_fp_violation": 0.02336411183573319,
            "ave_precision_score": 0.7699626161896364,
            "fpr": 0.19099890230515917,
            "logloss": 1.735828402659046,
            "mae": 0.30555442369131025,
            "precision": 0.7085427135678392,
            "recall": 0.8703703703703703
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.5801735684267184,
            "auditor_fn_violation": 0.00876724396461239,
            "auditor_fp_violation": 0.013809862494073025,
            "ave_precision_score": 0.5803446953076067,
            "fpr": 0.19956140350877194,
            "logloss": 1.929123137014729,
            "mae": 0.4478697833503303,
            "precision": 0.5900900900900901,
            "recall": 0.5598290598290598
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5983499511297908,
            "auditor_fn_violation": 0.016095007069516148,
            "auditor_fp_violation": 0.018694388842254803,
            "ave_precision_score": 0.5984488983441778,
            "fpr": 0.1964873765093304,
            "logloss": 2.0166024473594852,
            "mae": 0.45058431298856777,
            "precision": 0.597752808988764,
            "recall": 0.5473251028806584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 9271,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8156005070902776,
            "auditor_fn_violation": 0.00932486129854551,
            "auditor_fp_violation": 0.008974434961277065,
            "ave_precision_score": 0.8158197086887828,
            "fpr": 0.16885964912280702,
            "logloss": 1.091453453832522,
            "mae": 0.29955034367058514,
            "precision": 0.7158671586715867,
            "recall": 0.8290598290598291
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8177015313096418,
            "auditor_fn_violation": 0.011857814638641568,
            "auditor_fp_violation": 0.01715245044230645,
            "ave_precision_score": 0.8180077648792439,
            "fpr": 0.1778265642151482,
            "logloss": 1.0835649725460175,
            "mae": 0.2944007029423503,
            "precision": 0.7157894736842105,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.6574570098500684,
            "auditor_fn_violation": 0.02032726045883941,
            "auditor_fp_violation": 0.028884147305199937,
            "ave_precision_score": 0.657690337531227,
            "fpr": 0.15350877192982457,
            "logloss": 2.325940268984263,
            "mae": 0.41205290456006244,
            "precision": 0.6344647519582245,
            "recall": 0.5192307692307693
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6563172925361951,
            "auditor_fn_violation": 0.02030057866135438,
            "auditor_fp_violation": 0.019779169626138054,
            "ave_precision_score": 0.6559735831887947,
            "fpr": 0.14050493962678376,
            "logloss": 2.3113114748555046,
            "mae": 0.4233798911701219,
            "precision": 0.654054054054054,
            "recall": 0.49794238683127573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.8037318997819599,
            "auditor_fn_violation": 0.0033644474433948144,
            "auditor_fp_violation": 0.020285087719298257,
            "ave_precision_score": 0.8040260535167291,
            "fpr": 0.3125,
            "logloss": 1.1894901938175513,
            "mae": 0.37243659117896305,
            "precision": 0.6047156726768377,
            "recall": 0.9316239316239316
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8183161676648524,
            "auditor_fn_violation": 0.004018105188979686,
            "auditor_fp_violation": 0.018361206172919232,
            "ave_precision_score": 0.8187663129698666,
            "fpr": 0.2843029637760702,
            "logloss": 1.1696696676906937,
            "mae": 0.35335995902386047,
            "precision": 0.6442307692307693,
            "recall": 0.9650205761316872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8145079022723121,
            "auditor_fn_violation": 0.012192607587344428,
            "auditor_fp_violation": 0.009730124861703812,
            "ave_precision_score": 0.8148092126957811,
            "fpr": 0.05701754385964912,
            "logloss": 0.6959724062431484,
            "mae": 0.34532948185739787,
            "precision": 0.8169014084507042,
            "recall": 0.49572649572649574
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.8233444668340388,
            "auditor_fn_violation": 0.009346216566609302,
            "auditor_fp_violation": 0.003182023632724222,
            "ave_precision_score": 0.8236527181564142,
            "fpr": 0.04610318331503842,
            "logloss": 0.682566015239347,
            "mae": 0.3580681851678754,
            "precision": 0.8432835820895522,
            "recall": 0.46502057613168724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8057701564192326,
            "auditor_fn_violation": 0.026156470235417603,
            "auditor_fp_violation": 0.018978682629998425,
            "ave_precision_score": 0.8061251477636399,
            "fpr": 0.11951754385964912,
            "logloss": 0.570827303860868,
            "mae": 0.3326212647585443,
            "precision": 0.745920745920746,
            "recall": 0.6837606837606838
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8300479180213842,
            "auditor_fn_violation": 0.020571614424523314,
            "auditor_fp_violation": 0.018066765674436627,
            "ave_precision_score": 0.8303776870176851,
            "fpr": 0.10098792535675083,
            "logloss": 0.5320357459803471,
            "mae": 0.32480070984495024,
            "precision": 0.7855477855477856,
            "recall": 0.6934156378600823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6520146189971697,
            "auditor_fn_violation": 0.014024778827410418,
            "auditor_fp_violation": 0.033121937727200894,
            "ave_precision_score": 0.6525889431061631,
            "fpr": 0.1337719298245614,
            "logloss": 2.3341276072153074,
            "mae": 0.42135895961806835,
            "precision": 0.640117994100295,
            "recall": 0.4636752136752137
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6493272126890677,
            "auditor_fn_violation": 0.011388019315815385,
            "auditor_fp_violation": 0.024446309808226253,
            "ave_precision_score": 0.6498544835661155,
            "fpr": 0.12623490669593854,
            "logloss": 2.321381952984009,
            "mae": 0.4360326324619744,
            "precision": 0.6607669616519174,
            "recall": 0.4609053497942387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.6549083089404057,
            "auditor_fn_violation": 0.03415991902834009,
            "auditor_fp_violation": 0.03857969811917181,
            "ave_precision_score": 0.6553810276927228,
            "fpr": 0.18201754385964913,
            "logloss": 1.448221765789085,
            "mae": 0.4305415590953354,
            "precision": 0.6084905660377359,
            "recall": 0.5512820512820513
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6500245979887398,
            "auditor_fn_violation": 0.039973257804700665,
            "auditor_fp_violation": 0.02837734874410797,
            "ave_precision_score": 0.6497483353538525,
            "fpr": 0.16245883644346873,
            "logloss": 1.6131243412477512,
            "mae": 0.433770027990224,
            "precision": 0.6416464891041163,
            "recall": 0.5452674897119342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7554737439356205,
            "auditor_fn_violation": 0.012211351027140499,
            "auditor_fp_violation": 0.004022937411095304,
            "ave_precision_score": 0.7572629667592456,
            "fpr": 0.19407894736842105,
            "logloss": 1.4789047273184233,
            "mae": 0.32518650698240664,
            "precision": 0.6816546762589928,
            "recall": 0.8098290598290598
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7929474601934765,
            "auditor_fn_violation": 0.008546661065260894,
            "auditor_fp_violation": 0.0035513656615225727,
            "ave_precision_score": 0.7957929786773557,
            "fpr": 0.17014270032930845,
            "logloss": 1.320337601147998,
            "mae": 0.3037328744873519,
            "precision": 0.7266313932980599,
            "recall": 0.8477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8088833029686225,
            "auditor_fn_violation": 0.015566426750637278,
            "auditor_fp_violation": 0.010979729729729729,
            "ave_precision_score": 0.8093228951971372,
            "fpr": 0.1074561403508772,
            "logloss": 0.5369295158956837,
            "mae": 0.3321557731210385,
            "precision": 0.7777777777777778,
            "recall": 0.7329059829059829
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8468203196308542,
            "auditor_fn_violation": 0.011821676536885707,
            "auditor_fp_violation": 0.012575708658875192,
            "ave_precision_score": 0.8472443898850893,
            "fpr": 0.09110867178924259,
            "logloss": 0.5040092566474622,
            "mae": 0.3193244174742329,
            "precision": 0.8159645232815964,
            "recall": 0.757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6613281190590243,
            "auditor_fn_violation": 0.029713037936722156,
            "auditor_fp_violation": 0.033013276434329074,
            "ave_precision_score": 0.6625081380533613,
            "fpr": 0.2807017543859649,
            "logloss": 5.063846465968871,
            "mae": 0.4397183760588301,
            "precision": 0.5661016949152542,
            "recall": 0.7136752136752137
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6830100909731405,
            "auditor_fn_violation": 0.02759144069059912,
            "auditor_fp_violation": 0.02801058952669982,
            "ave_precision_score": 0.6832949836099582,
            "fpr": 0.29088913282107576,
            "logloss": 4.935926401966702,
            "mae": 0.43807263539750413,
            "precision": 0.573268921095008,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7842425782666507,
            "auditor_fn_violation": 0.020744301994301998,
            "auditor_fp_violation": 0.03777955587166114,
            "ave_precision_score": 0.783973915470388,
            "fpr": 0.20833333333333334,
            "logloss": 1.2215105073341879,
            "mae": 0.3157752178308887,
            "precision": 0.6859504132231405,
            "recall": 0.8867521367521367
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7790656247595045,
            "auditor_fn_violation": 0.018886675430156343,
            "auditor_fp_violation": 0.03258733131013108,
            "ave_precision_score": 0.7788990552271838,
            "fpr": 0.21295279912184412,
            "logloss": 1.1890042092622193,
            "mae": 0.31753869925786127,
            "precision": 0.6905901116427432,
            "recall": 0.8909465020576132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8173286409713809,
            "auditor_fn_violation": 0.008087794272004801,
            "auditor_fp_violation": 0.0194108582266477,
            "ave_precision_score": 0.8168986862223375,
            "fpr": 0.16447368421052633,
            "logloss": 1.215849880879165,
            "mae": 0.2952509015285933,
            "precision": 0.7242647058823529,
            "recall": 0.8418803418803419
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8289285630995467,
            "auditor_fn_violation": 0.011263794591029625,
            "auditor_fp_violation": 0.02174210628268871,
            "ave_precision_score": 0.8281702568880601,
            "fpr": 0.1668496158068057,
            "logloss": 1.212805779309622,
            "mae": 0.28253138427516294,
            "precision": 0.7365684575389948,
            "recall": 0.8744855967078189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.660895867358308,
            "auditor_fn_violation": 0.0352938971360024,
            "auditor_fp_violation": 0.03953295400663822,
            "ave_precision_score": 0.661413119696551,
            "fpr": 0.18201754385964913,
            "logloss": 1.3649145759425438,
            "mae": 0.42365099059740735,
            "precision": 0.6148491879350348,
            "recall": 0.5662393162393162
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.655122589998595,
            "auditor_fn_violation": 0.035614099280400054,
            "auditor_fp_violation": 0.027946019241944873,
            "ave_precision_score": 0.6552221911560135,
            "fpr": 0.16245883644346873,
            "logloss": 1.5215696542119312,
            "mae": 0.4285641702326163,
            "precision": 0.645933014354067,
            "recall": 0.5555555555555556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 9271,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6168093951274021,
            "auditor_fn_violation": 0.01297514619883041,
            "auditor_fp_violation": 0.0007606290501027387,
            "ave_precision_score": 0.6187021847190375,
            "fpr": 0.2807017543859649,
            "logloss": 1.8786659538799333,
            "mae": 0.370743286150524,
            "precision": 0.6224188790560472,
            "recall": 0.9017094017094017
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6375427045333982,
            "auditor_fn_violation": 0.010780447480044994,
            "auditor_fp_violation": 0.02537612190869763,
            "ave_precision_score": 0.643412621845949,
            "fpr": 0.2579582875960483,
            "logloss": 1.632312289707587,
            "mae": 0.3527971052490052,
            "precision": 0.6513353115727003,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.855761099683436,
            "auditor_fn_violation": 0.012768968361073626,
            "auditor_fp_violation": 0.01054755413308045,
            "ave_precision_score": 0.8561750251879559,
            "fpr": 0.15679824561403508,
            "logloss": 0.5081603472839185,
            "mae": 0.29776366091544715,
            "precision": 0.7371323529411765,
            "recall": 0.8568376068376068
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8704598371946546,
            "auditor_fn_violation": 0.010543291187272163,
            "auditor_fp_violation": 0.016439594498611744,
            "ave_precision_score": 0.8707326614125781,
            "fpr": 0.14270032930845225,
            "logloss": 0.47067409152778794,
            "mae": 0.2827152129422166,
            "precision": 0.7623400365630713,
            "recall": 0.8580246913580247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8307005157692566,
            "auditor_fn_violation": 0.0180405608037187,
            "auditor_fp_violation": 0.012678797218270903,
            "ave_precision_score": 0.8309791439996134,
            "fpr": 0.06359649122807018,
            "logloss": 0.5964468001277009,
            "mae": 0.3297094240831364,
            "precision": 0.8209876543209876,
            "recall": 0.5683760683760684
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8419961677173795,
            "auditor_fn_violation": 0.010100599440762878,
            "auditor_fp_violation": 0.00846903854846,
            "ave_precision_score": 0.8423744496271607,
            "fpr": 0.05378704720087816,
            "logloss": 0.5770111458225221,
            "mae": 0.3303784953568818,
            "precision": 0.8541666666666666,
            "recall": 0.5905349794238683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.715445022920883,
            "auditor_fn_violation": 0.016447368421052638,
            "auditor_fp_violation": 0.007747056266793112,
            "ave_precision_score": 0.7158161883200602,
            "fpr": 0.0668859649122807,
            "logloss": 2.566379860265607,
            "mae": 0.4096707404125552,
            "precision": 0.7489711934156379,
            "recall": 0.3888888888888889
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7205514031658523,
            "auditor_fn_violation": 0.005210662546923075,
            "auditor_fp_violation": 0.010984696842513077,
            "ave_precision_score": 0.7219206730998353,
            "fpr": 0.06256860592755215,
            "logloss": 2.6156365505952563,
            "mae": 0.4150992875135395,
            "precision": 0.7738095238095238,
            "recall": 0.4012345679012346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7866687060776472,
            "auditor_fn_violation": 0.010215174688858897,
            "auditor_fp_violation": 0.029052078394183677,
            "ave_precision_score": 0.7889504947031039,
            "fpr": 0.20175438596491227,
            "logloss": 1.1810300731569443,
            "mae": 0.3067051966781747,
            "precision": 0.6897133220910624,
            "recall": 0.8739316239316239
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7971014627552216,
            "auditor_fn_violation": 0.013831858447055423,
            "auditor_fp_violation": 0.019900561761477368,
            "ave_precision_score": 0.7971117161263219,
            "fpr": 0.21075740944017562,
            "logloss": 1.1661591552315271,
            "mae": 0.3093924047472032,
            "precision": 0.6942675159235668,
            "recall": 0.897119341563786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6511383391165653,
            "auditor_fn_violation": 0.01678475033738192,
            "auditor_fp_violation": 0.03947862336020231,
            "ave_precision_score": 0.6515499948487333,
            "fpr": 0.17324561403508773,
            "logloss": 2.3312594289097808,
            "mae": 0.42824208670006214,
            "precision": 0.6059850374064838,
            "recall": 0.5192307692307693
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6496909098498665,
            "auditor_fn_violation": 0.029838778893541675,
            "auditor_fp_violation": 0.021997804610318333,
            "ave_precision_score": 0.6501990428793119,
            "fpr": 0.16794731064763996,
            "logloss": 2.221932501414276,
            "mae": 0.4407155217580026,
            "precision": 0.6212871287128713,
            "recall": 0.5164609053497943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8392817805958797,
            "auditor_fn_violation": 0.016306792622582094,
            "auditor_fp_violation": 0.005877588114430218,
            "ave_precision_score": 0.839528282160922,
            "fpr": 0.10416666666666667,
            "logloss": 0.516119946838042,
            "mae": 0.3170727724663856,
            "precision": 0.7855530474040632,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8649487252969654,
            "auditor_fn_violation": 0.007864554394619036,
            "auditor_fp_violation": 0.010274423710208563,
            "ave_precision_score": 0.8652402901015311,
            "fpr": 0.0889132821075741,
            "logloss": 0.4891241147243818,
            "mae": 0.3044177807384998,
            "precision": 0.8171557562076749,
            "recall": 0.7448559670781894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7789969881016889,
            "auditor_fn_violation": 0.03508771929824561,
            "auditor_fp_violation": 0.029842342342342343,
            "ave_precision_score": 0.7781294948444557,
            "fpr": 0.14473684210526316,
            "logloss": 1.2837193930540762,
            "mae": 0.3021020114034288,
            "precision": 0.7338709677419355,
            "recall": 0.7777777777777778
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7728005933197404,
            "auditor_fn_violation": 0.03417760973560462,
            "auditor_fp_violation": 0.026362755859753343,
            "ave_precision_score": 0.7710772099492285,
            "fpr": 0.1437980241492865,
            "logloss": 1.2857730652807253,
            "mae": 0.3033139206360183,
            "precision": 0.7342799188640974,
            "recall": 0.7448559670781894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7062167146910676,
            "auditor_fn_violation": 0.012698680461838368,
            "auditor_fp_violation": 0.004252607871028926,
            "ave_precision_score": 0.7066696371246081,
            "fpr": 0.025219298245614034,
            "logloss": 2.9098139267116654,
            "mae": 0.4180978470463618,
            "precision": 0.8506493506493507,
            "recall": 0.2799145299145299
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.707737950452584,
            "auditor_fn_violation": 0.010204496483310987,
            "auditor_fp_violation": 0.0035281203590107834,
            "ave_precision_score": 0.7083355085947414,
            "fpr": 0.024149286498353458,
            "logloss": 2.9812442904301473,
            "mae": 0.43947377767776413,
            "precision": 0.8461538461538461,
            "recall": 0.24897119341563786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6768930325550592,
            "auditor_fn_violation": 0.018816070625281157,
            "auditor_fp_violation": 0.011083451872925558,
            "ave_precision_score": 0.6774735040878443,
            "fpr": 0.10307017543859649,
            "logloss": 1.4035127000836212,
            "mae": 0.4263740121553855,
            "precision": 0.6996805111821086,
            "recall": 0.46794871794871795
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.679717493707952,
            "auditor_fn_violation": 0.019047038256697988,
            "auditor_fp_violation": 0.01540646994253245,
            "ave_precision_score": 0.6803722973017655,
            "fpr": 0.09549945115257959,
            "logloss": 1.5226185166441037,
            "mae": 0.4319711507739108,
            "precision": 0.7211538461538461,
            "recall": 0.46296296296296297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6801047656969995,
            "auditor_fn_violation": 0.018396686159844067,
            "auditor_fp_violation": 0.010784633317528056,
            "ave_precision_score": 0.6807889638995184,
            "fpr": 0.09978070175438597,
            "logloss": 1.4555624612315845,
            "mae": 0.436018076750001,
            "precision": 0.6956521739130435,
            "recall": 0.4444444444444444
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.6756894580731566,
            "auditor_fn_violation": 0.009947012508300474,
            "auditor_fp_violation": 0.008267579260024539,
            "ave_precision_score": 0.6762444779580007,
            "fpr": 0.10098792535675083,
            "logloss": 1.6308661167330032,
            "mae": 0.44596935081337086,
            "precision": 0.7088607594936709,
            "recall": 0.4609053497942387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6704432301407424,
            "auditor_fn_violation": 0.01882309941520469,
            "auditor_fp_violation": 0.011145191243875455,
            "ave_precision_score": 0.6712406471129236,
            "fpr": 0.08442982456140351,
            "logloss": 1.5345539466475995,
            "mae": 0.41870771829470554,
            "precision": 0.7317073170731707,
            "recall": 0.44871794871794873
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6757789033225859,
            "auditor_fn_violation": 0.016135662433991508,
            "auditor_fp_violation": 0.008203008975269582,
            "ave_precision_score": 0.6764112739838866,
            "fpr": 0.09110867178924259,
            "logloss": 1.7065725255522028,
            "mae": 0.42415590985692864,
            "precision": 0.7242524916943521,
            "recall": 0.448559670781893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 9271,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.7180610724832103,
            "auditor_fn_violation": 0.01343201754385965,
            "auditor_fp_violation": 0.022833688952110017,
            "ave_precision_score": 0.7207454770378204,
            "fpr": 0.3519736842105263,
            "logloss": 1.8691443065897528,
            "mae": 0.380985077186651,
            "precision": 0.5787401574803149,
            "recall": 0.9423076923076923
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.739802309135739,
            "auditor_fn_violation": 0.002909117191346732,
            "auditor_fp_violation": 0.017731000193710874,
            "ave_precision_score": 0.7436821161040676,
            "fpr": 0.32821075740944017,
            "logloss": 1.6826541113998836,
            "mae": 0.3582889555394241,
            "precision": 0.611183355006502,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.736461956048314,
            "auditor_fn_violation": 0.008247113510271407,
            "auditor_fp_violation": 0.00773470839260314,
            "ave_precision_score": 0.7379045802840569,
            "fpr": 0.2719298245614035,
            "logloss": 1.6109205845660293,
            "mae": 0.3479004048358388,
            "precision": 0.6363636363636364,
            "recall": 0.9273504273504274
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7716285262924771,
            "auditor_fn_violation": 0.005610440297597267,
            "auditor_fp_violation": 0.010292503389939945,
            "ave_precision_score": 0.7742642716060184,
            "fpr": 0.2513721185510428,
            "logloss": 1.4498739665597642,
            "mae": 0.3285911637373702,
            "precision": 0.6661807580174927,
            "recall": 0.9403292181069959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6634127353383669,
            "auditor_fn_violation": 0.016840980656770137,
            "auditor_fp_violation": 0.012456535482851274,
            "ave_precision_score": 0.6639684037193466,
            "fpr": 0.07017543859649122,
            "logloss": 2.3972959083815155,
            "mae": 0.42704810113766134,
            "precision": 0.7241379310344828,
            "recall": 0.358974358974359
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6780051803343938,
            "auditor_fn_violation": 0.014294877875802381,
            "auditor_fp_violation": 0.003887131142248338,
            "ave_precision_score": 0.6786385302787048,
            "fpr": 0.06476399560922064,
            "logloss": 2.369745567420526,
            "mae": 0.4375328851716741,
            "precision": 0.7412280701754386,
            "recall": 0.3477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6543505826680727,
            "auditor_fn_violation": 0.03179824561403509,
            "auditor_fp_violation": 0.03562114746325273,
            "ave_precision_score": 0.6548744756522646,
            "fpr": 0.17763157894736842,
            "logloss": 1.4103753678023476,
            "mae": 0.43072162829068933,
            "precision": 0.6086956521739131,
            "recall": 0.5384615384615384
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.648218237855857,
            "auditor_fn_violation": 0.03825218070857783,
            "auditor_fp_violation": 0.031084135081035708,
            "ave_precision_score": 0.6483163825108089,
            "fpr": 0.15916575192096596,
            "logloss": 1.5833770776335687,
            "mae": 0.43520820553876405,
            "precision": 0.6410891089108911,
            "recall": 0.5329218106995884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8164518808004134,
            "auditor_fn_violation": 0.013553849902534115,
            "auditor_fp_violation": 0.01562993914967599,
            "ave_precision_score": 0.816850572383715,
            "fpr": 0.14364035087719298,
            "logloss": 0.5494861391204704,
            "mae": 0.3300313493203711,
            "precision": 0.733739837398374,
            "recall": 0.7713675213675214
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8478516983149753,
            "auditor_fn_violation": 0.010956620726104817,
            "auditor_fp_violation": 0.01202298702137277,
            "ave_precision_score": 0.8480927985109858,
            "fpr": 0.1207464324917673,
            "logloss": 0.5073711241971985,
            "mae": 0.3154637353249665,
            "precision": 0.7759674134419552,
            "recall": 0.7839506172839507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7839463346101809,
            "auditor_fn_violation": 0.01567420152946469,
            "auditor_fp_violation": 0.03757705073494548,
            "ave_precision_score": 0.7834230611540969,
            "fpr": 0.21052631578947367,
            "logloss": 1.225945298028374,
            "mae": 0.3168699353029073,
            "precision": 0.6852459016393443,
            "recall": 0.8931623931623932
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.78090948081453,
            "auditor_fn_violation": 0.018886675430156343,
            "auditor_fp_violation": 0.031259766255569185,
            "ave_precision_score": 0.7801528205995338,
            "fpr": 0.21514818880351264,
            "logloss": 1.193780116810474,
            "mae": 0.3185184421360239,
            "precision": 0.6883942766295708,
            "recall": 0.8909465020576132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.829353174035361,
            "auditor_fn_violation": 0.009235829959514167,
            "auditor_fp_violation": 0.0058479532163742695,
            "ave_precision_score": 0.8296468041651319,
            "fpr": 0.08114035087719298,
            "logloss": 0.5609309682150472,
            "mae": 0.3237152637422632,
            "precision": 0.8052631578947368,
            "recall": 0.6538461538461539
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.842816132781061,
            "auditor_fn_violation": 0.01277481897069652,
            "auditor_fp_violation": 0.008489701039581585,
            "ave_precision_score": 0.8440738204311377,
            "fpr": 0.06476399560922064,
            "logloss": 0.548258837185779,
            "mae": 0.32446430691719286,
            "precision": 0.8443271767810027,
            "recall": 0.6584362139917695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 9271,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5336227248657357,
            "auditor_fn_violation": 0.025191183085919933,
            "auditor_fp_violation": 0.036362019914651496,
            "ave_precision_score": 0.5346152191088677,
            "fpr": 0.1337719298245614,
            "logloss": 6.786535275650408,
            "mae": 0.47798336523642093,
            "precision": 0.5878378378378378,
            "recall": 0.3717948717948718
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.570938343182597,
            "auditor_fn_violation": 0.029881692889376758,
            "auditor_fp_violation": 0.032912765545296055,
            "ave_precision_score": 0.5719036422249366,
            "fpr": 0.11964873765093303,
            "logloss": 7.2137918350696735,
            "mae": 0.4789772291577624,
            "precision": 0.6305084745762712,
            "recall": 0.38271604938271603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5625502444130699,
            "auditor_fn_violation": 0.029640407107512385,
            "auditor_fp_violation": 0.039831772562035725,
            "ave_precision_score": 0.5645468440543313,
            "fpr": 0.13267543859649122,
            "logloss": 3.839829993166452,
            "mae": 0.4486508724540425,
            "precision": 0.6194968553459119,
            "recall": 0.42094017094017094
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.5921536884737587,
            "auditor_fn_violation": 0.032621412728742895,
            "auditor_fp_violation": 0.024296506747594756,
            "ave_precision_score": 0.5932680826783442,
            "fpr": 0.10867178924259056,
            "logloss": 4.083411452777438,
            "mae": 0.4474380931002188,
            "precision": 0.6655405405405406,
            "recall": 0.4053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8039326826612978,
            "auditor_fn_violation": 0.00732868496026391,
            "auditor_fp_violation": 0.027041844476055007,
            "ave_precision_score": 0.8042927516015218,
            "fpr": 0.18640350877192982,
            "logloss": 1.0128100174245729,
            "mae": 0.3027999457576937,
            "precision": 0.7048611111111112,
            "recall": 0.8675213675213675
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8108188925516625,
            "auditor_fn_violation": 0.009269423100378095,
            "auditor_fp_violation": 0.01625363207851746,
            "ave_precision_score": 0.8112900556455411,
            "fpr": 0.19538968166849616,
            "logloss": 1.0029942460363717,
            "mae": 0.30143441946098004,
            "precision": 0.7086743044189853,
            "recall": 0.8909465020576132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6180059328111376,
            "auditor_fn_violation": 0.0068858711950817286,
            "auditor_fp_violation": 0.009740003161055796,
            "ave_precision_score": 0.6197112451927844,
            "fpr": 0.10307017543859649,
            "logloss": 1.6357422645352881,
            "mae": 0.43236642568451894,
            "precision": 0.6791808873720137,
            "recall": 0.4252136752136752
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6178066123717706,
            "auditor_fn_violation": 0.0048221779530475874,
            "auditor_fp_violation": 0.01089688125524634,
            "ave_precision_score": 0.6187013417473857,
            "fpr": 0.10318331503841932,
            "logloss": 1.7415128101601907,
            "mae": 0.4426584084251988,
            "precision": 0.6918032786885245,
            "recall": 0.43415637860082307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 9271,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6652359671939154,
            "auditor_fn_violation": 0.016313821412505633,
            "auditor_fp_violation": 0.02155444918602814,
            "ave_precision_score": 0.6658815017871555,
            "fpr": 0.16557017543859648,
            "logloss": 1.684368468926225,
            "mae": 0.4489034357977808,
            "precision": 0.6108247422680413,
            "recall": 0.5064102564102564
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.664612530289638,
            "auditor_fn_violation": 0.013956083171841185,
            "auditor_fp_violation": 0.012511138374120233,
            "ave_precision_score": 0.6651871580556533,
            "fpr": 0.1394072447859495,
            "logloss": 1.898846026760787,
            "mae": 0.4569123621479468,
            "precision": 0.660427807486631,
            "recall": 0.5082304526748971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6861745838600612,
            "auditor_fn_violation": 0.016147473384315502,
            "auditor_fp_violation": 0.011416844476055003,
            "ave_precision_score": 0.6866098926347388,
            "fpr": 0.06030701754385965,
            "logloss": 3.8362981989393856,
            "mae": 0.4166616946055084,
            "precision": 0.7764227642276422,
            "recall": 0.4081196581196581
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6950836299602863,
            "auditor_fn_violation": 0.02463715087205757,
            "auditor_fp_violation": 0.004277135662168274,
            "ave_precision_score": 0.6955093313560914,
            "fpr": 0.0570801317233809,
            "logloss": 4.131054294961297,
            "mae": 0.42246369317213955,
            "precision": 0.792,
            "recall": 0.4074074074074074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8522355214119397,
            "auditor_fn_violation": 0.015182186234817815,
            "auditor_fp_violation": 0.013888888888888899,
            "ave_precision_score": 0.8524594159607157,
            "fpr": 0.14912280701754385,
            "logloss": 0.5048883109526537,
            "mae": 0.33216559974754456,
            "precision": 0.7322834645669292,
            "recall": 0.7948717948717948
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8519733824442066,
            "auditor_fn_violation": 0.011056000505933427,
            "auditor_fp_violation": 0.014179634532188293,
            "ave_precision_score": 0.8523459728877957,
            "fpr": 0.1207464324917673,
            "logloss": 0.49728085873902345,
            "mae": 0.3272329724049267,
            "precision": 0.7777777777777778,
            "recall": 0.7921810699588477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6378967580853915,
            "auditor_fn_violation": 0.030926675663517776,
            "auditor_fp_violation": 0.0526982574679943,
            "ave_precision_score": 0.6384327215970361,
            "fpr": 0.18092105263157895,
            "logloss": 1.2160318805433463,
            "mae": 0.4394862850687922,
            "precision": 0.5985401459854015,
            "recall": 0.5256410256410257
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6346606068873719,
            "auditor_fn_violation": 0.03957122142266673,
            "auditor_fp_violation": 0.04034609672628657,
            "ave_precision_score": 0.6352524338254156,
            "fpr": 0.16575192096597147,
            "logloss": 1.3142450513102024,
            "mae": 0.4533125126625391,
            "precision": 0.6196473551637279,
            "recall": 0.5061728395061729
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7057783801122894,
            "auditor_fn_violation": 0.030750955915429614,
            "auditor_fp_violation": 0.03284781492018335,
            "ave_precision_score": 0.7066274677355566,
            "fpr": 0.13706140350877194,
            "logloss": 0.9189340542522819,
            "mae": 0.38645610816295456,
            "precision": 0.6710526315789473,
            "recall": 0.5448717948717948
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7054988554380778,
            "auditor_fn_violation": 0.027695337733147227,
            "auditor_fp_violation": 0.01771292051397947,
            "ave_precision_score": 0.706070575260628,
            "fpr": 0.1251372118551043,
            "logloss": 1.0121016921528971,
            "mae": 0.39746818979255405,
            "precision": 0.6902173913043478,
            "recall": 0.522633744855967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6563790197362155,
            "auditor_fn_violation": 0.0032637014544909366,
            "auditor_fp_violation": 0.012350343764817449,
            "ave_precision_score": 0.6570105643857107,
            "fpr": 0.12390350877192982,
            "logloss": 1.59321096175692,
            "mae": 0.42396347048804334,
            "precision": 0.6636904761904762,
            "recall": 0.47649572649572647
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6436927094307813,
            "auditor_fn_violation": 0.012210161130761217,
            "auditor_fp_violation": 0.02937947956350488,
            "ave_precision_score": 0.6442625496901632,
            "fpr": 0.12184412733260154,
            "logloss": 1.7335491738059443,
            "mae": 0.44265276550477944,
            "precision": 0.6735294117647059,
            "recall": 0.4711934156378601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8530296561305378,
            "auditor_fn_violation": 0.016777721547458394,
            "auditor_fp_violation": 0.012663979769242929,
            "ave_precision_score": 0.8533634815072899,
            "fpr": 0.13596491228070176,
            "logloss": 0.5038971432322099,
            "mae": 0.2963991184135426,
            "precision": 0.7554240631163708,
            "recall": 0.8183760683760684
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8725774696916223,
            "auditor_fn_violation": 0.021156599946696303,
            "auditor_fp_violation": 0.023315038419319437,
            "ave_precision_score": 0.8728601234398528,
            "fpr": 0.132821075740944,
            "logloss": 0.4628848510823705,
            "mae": 0.2854191919735814,
            "precision": 0.7716981132075472,
            "recall": 0.8415637860082305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6150433084783099,
            "auditor_fn_violation": 0.021325348627980217,
            "auditor_fp_violation": 0.030049786628734,
            "ave_precision_score": 0.6158729547502693,
            "fpr": 0.11842105263157894,
            "logloss": 1.5042162923272788,
            "mae": 0.45028874123340085,
            "precision": 0.660377358490566,
            "recall": 0.44871794871794873
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6291685612310032,
            "auditor_fn_violation": 0.02665636730766625,
            "auditor_fp_violation": 0.017529540905275393,
            "ave_precision_score": 0.6298425418060175,
            "fpr": 0.10867178924259056,
            "logloss": 1.6097483392820882,
            "mae": 0.4530982965438997,
            "precision": 0.6837060702875399,
            "recall": 0.4403292181069959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6078151535061267,
            "auditor_fn_violation": 0.017796896086369775,
            "auditor_fp_violation": 0.014565552394499767,
            "ave_precision_score": 0.6086838490789499,
            "fpr": 0.09539473684210527,
            "logloss": 5.021189394742856,
            "mae": 0.44111333388706675,
            "precision": 0.6813186813186813,
            "recall": 0.3974358974358974
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6121402236064215,
            "auditor_fn_violation": 0.01088660315395285,
            "auditor_fp_violation": 0.013660489442758446,
            "ave_precision_score": 0.6134516309862282,
            "fpr": 0.09440175631174534,
            "logloss": 5.381290081429398,
            "mae": 0.4524523613459766,
            "precision": 0.6950354609929078,
            "recall": 0.40329218106995884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6126071024489592,
            "auditor_fn_violation": 0.02345741490478334,
            "auditor_fp_violation": 0.03808084400189663,
            "ave_precision_score": 0.6131538398002891,
            "fpr": 0.17982456140350878,
            "logloss": 4.311522816221288,
            "mae": 0.46531014647556335,
            "precision": 0.583756345177665,
            "recall": 0.49145299145299143
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6297859361356736,
            "auditor_fn_violation": 0.026728643511177978,
            "auditor_fp_violation": 0.029782398140375796,
            "ave_precision_score": 0.6303389561477706,
            "fpr": 0.15587266739846323,
            "logloss": 4.651115514432967,
            "mae": 0.46147478375475354,
            "precision": 0.6263157894736842,
            "recall": 0.4897119341563786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.744589339436869,
            "auditor_fn_violation": 0.012155120707752291,
            "auditor_fp_violation": 0.022660818713450305,
            "ave_precision_score": 0.745742231460216,
            "fpr": 0.32456140350877194,
            "logloss": 1.7938279996778963,
            "mae": 0.3649043014718285,
            "precision": 0.5956284153005464,
            "recall": 0.9316239316239316
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7676881068381226,
            "auditor_fn_violation": 0.006613272621322384,
            "auditor_fp_violation": 0.023606896106411833,
            "ave_precision_score": 0.7680185912082685,
            "fpr": 0.29088913282107576,
            "logloss": 1.6203831237172979,
            "mae": 0.3408344420231265,
            "precision": 0.6379781420765027,
            "recall": 0.9609053497942387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 9271,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8320826605096381,
            "auditor_fn_violation": 0.021744733093417304,
            "auditor_fp_violation": 0.025357594436541807,
            "ave_precision_score": 0.8323595321446053,
            "fpr": 0.1524122807017544,
            "logloss": 0.5354656307120942,
            "mae": 0.3220445922664734,
            "precision": 0.7316602316602316,
            "recall": 0.8098290598290598
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8370554584051694,
            "auditor_fn_violation": 0.024386442791126287,
            "auditor_fp_violation": 0.02938464518628528,
            "ave_precision_score": 0.8375220519016351,
            "fpr": 0.14489571899012074,
            "logloss": 0.5201284791547861,
            "mae": 0.3192050527501647,
            "precision": 0.7436893203883496,
            "recall": 0.7880658436213992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7784743374664981,
            "auditor_fn_violation": 0.011049257759784076,
            "auditor_fp_violation": 0.02158902323376008,
            "ave_precision_score": 0.7750710221802856,
            "fpr": 0.2138157894736842,
            "logloss": 1.572393439773327,
            "mae": 0.3137961040320398,
            "precision": 0.6813725490196079,
            "recall": 0.8910256410256411
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7813390995605689,
            "auditor_fn_violation": 0.011668089604423303,
            "auditor_fp_violation": 0.02676567443662427,
            "ave_precision_score": 0.7787481070492661,
            "fpr": 0.21075740944017562,
            "logloss": 1.597707157167339,
            "mae": 0.298347552894266,
            "precision": 0.6966824644549763,
            "recall": 0.9074074074074074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6653555706014884,
            "auditor_fn_violation": 0.013832658569500686,
            "auditor_fp_violation": 0.010399379642800698,
            "ave_precision_score": 0.6666156615977055,
            "fpr": 0.11293859649122807,
            "logloss": 1.449211595483396,
            "mae": 0.4249686803978676,
            "precision": 0.6869300911854104,
            "recall": 0.4829059829059829
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6706099652549854,
            "auditor_fn_violation": 0.0069181878548874535,
            "auditor_fp_violation": 0.015659585458771875,
            "ave_precision_score": 0.6712055625304825,
            "fpr": 0.10647639956092206,
            "logloss": 1.6077750952654832,
            "mae": 0.43082548120491043,
            "precision": 0.7113095238095238,
            "recall": 0.49176954732510286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6288202655048107,
            "auditor_fn_violation": 0.016606687659319254,
            "auditor_fp_violation": 0.037722755650387234,
            "ave_precision_score": 0.6295223703772206,
            "fpr": 0.1524122807017544,
            "logloss": 5.406851603210399,
            "mae": 0.45537075265856414,
            "precision": 0.6160220994475138,
            "recall": 0.47649572649572647
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6553593974992757,
            "auditor_fn_violation": 0.023781129586715636,
            "auditor_fp_violation": 0.023077419771421193,
            "ave_precision_score": 0.656160639502577,
            "fpr": 0.13172338090010977,
            "logloss": 5.840040207226204,
            "mae": 0.46087286521084087,
            "precision": 0.660056657223796,
            "recall": 0.4794238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8079679297154259,
            "auditor_fn_violation": 0.0082189983505773,
            "auditor_fp_violation": 0.010416666666666671,
            "ave_precision_score": 0.8080344767878848,
            "fpr": 0.20285087719298245,
            "logloss": 1.2902725667134844,
            "mae": 0.31049364343546093,
            "precision": 0.6793760831889082,
            "recall": 0.8376068376068376
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7992932631064655,
            "auditor_fn_violation": 0.005127093186612645,
            "auditor_fp_violation": 0.01747013624330084,
            "ave_precision_score": 0.8029674851563406,
            "fpr": 0.18990120746432493,
            "logloss": 1.2966127235116531,
            "mae": 0.3023646502659128,
            "precision": 0.7077702702702703,
            "recall": 0.8621399176954733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.669849722546837,
            "auditor_fn_violation": 0.019315114709851568,
            "auditor_fp_violation": 0.01481497945313735,
            "ave_precision_score": 0.6703064937091703,
            "fpr": 0.08442982456140351,
            "logloss": 3.6846152143031254,
            "mae": 0.4362178153399953,
            "precision": 0.72,
            "recall": 0.4230769230769231
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6893606836024961,
            "auditor_fn_violation": 0.00952916570674835,
            "auditor_fp_violation": 0.008933944598695683,
            "ave_precision_score": 0.6897729067573616,
            "fpr": 0.07903402854006586,
            "logloss": 3.9702813993876225,
            "mae": 0.44218385617063133,
            "precision": 0.7437722419928826,
            "recall": 0.43004115226337447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7039533058321831,
            "auditor_fn_violation": 0.01678475033738193,
            "auditor_fp_violation": 0.005112019914651496,
            "ave_precision_score": 0.7044163520910349,
            "fpr": 0.03399122807017544,
            "logloss": 2.8206544915149436,
            "mae": 0.41523977341475027,
            "precision": 0.8315217391304348,
            "recall": 0.3269230769230769
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.7054734502826352,
            "auditor_fn_violation": 0.00016939735198061165,
            "auditor_fp_violation": 0.00844062762316782,
            "ave_precision_score": 0.7060270740996787,
            "fpr": 0.03951701427003293,
            "logloss": 2.8750901104398197,
            "mae": 0.4356658798525349,
            "precision": 0.7966101694915254,
            "recall": 0.29012345679012347
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.666927260903196,
            "auditor_fn_violation": 0.01901521967311441,
            "auditor_fp_violation": 0.015454599336178286,
            "ave_precision_score": 0.6673608014848815,
            "fpr": 0.09868421052631579,
            "logloss": 1.2475611038962187,
            "mae": 0.42340198421497954,
            "precision": 0.7039473684210527,
            "recall": 0.45726495726495725
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6698675717623656,
            "auditor_fn_violation": 0.016546733341464406,
            "auditor_fp_violation": 0.013216245883644348,
            "ave_precision_score": 0.6704257483113303,
            "fpr": 0.09989023051591657,
            "logloss": 1.3883712073824797,
            "mae": 0.43047618231640966,
            "precision": 0.707395498392283,
            "recall": 0.45267489711934156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6550656460825552,
            "auditor_fn_violation": 0.006593004948268117,
            "auditor_fp_violation": 0.008238501659554295,
            "ave_precision_score": 0.6566228565892699,
            "fpr": 0.10087719298245613,
            "logloss": 2.1055475319986248,
            "mae": 0.42437648355449054,
            "precision": 0.6902356902356902,
            "recall": 0.43803418803418803
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6584020891796194,
            "auditor_fn_violation": 0.011293156798706253,
            "auditor_fp_violation": 0.008820300897526959,
            "ave_precision_score": 0.6592238941916415,
            "fpr": 0.09879253567508232,
            "logloss": 2.1922879416695737,
            "mae": 0.43005676616344485,
            "precision": 0.7133757961783439,
            "recall": 0.4609053497942387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5976164942176032,
            "auditor_fn_violation": 0.016934697855750504,
            "auditor_fp_violation": 0.006816026552868659,
            "ave_precision_score": 0.5979874865540233,
            "fpr": 0.13596491228070176,
            "logloss": 3.096810693311548,
            "mae": 0.4534855917363789,
            "precision": 0.6160990712074303,
            "recall": 0.4252136752136752
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6271129528193877,
            "auditor_fn_violation": 0.016998459613412672,
            "auditor_fp_violation": 0.010597275133983343,
            "ave_precision_score": 0.6284716714313722,
            "fpr": 0.11306256860592755,
            "logloss": 2.9107404446197633,
            "mae": 0.4490140289546403,
            "precision": 0.6791277258566978,
            "recall": 0.448559670781893
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6739423302183358,
            "auditor_fn_violation": 0.014155982905982918,
            "auditor_fp_violation": 0.013543148411569474,
            "ave_precision_score": 0.6747280634940527,
            "fpr": 0.1074561403508772,
            "logloss": 1.3056411733004092,
            "mae": 0.4218339181664628,
            "precision": 0.69375,
            "recall": 0.47435897435897434
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.6718751346974552,
            "auditor_fn_violation": 0.010001219660934266,
            "auditor_fp_violation": 0.015328985600826501,
            "ave_precision_score": 0.6724672474214524,
            "fpr": 0.10757409440175632,
            "logloss": 1.4584010010806783,
            "mae": 0.431283922375882,
            "precision": 0.7065868263473054,
            "recall": 0.48559670781893005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.6486843407223125,
            "auditor_fn_violation": 0.016892525116209322,
            "auditor_fp_violation": 0.00804093567251462,
            "ave_precision_score": 0.6492131405406012,
            "fpr": 0.08114035087719298,
            "logloss": 5.442510393968256,
            "mae": 0.4434554779274278,
            "precision": 0.7196969696969697,
            "recall": 0.405982905982906
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6875850057433306,
            "auditor_fn_violation": 0.012442800160814557,
            "auditor_fp_violation": 0.00995673790921418,
            "ave_precision_score": 0.6880104916275891,
            "fpr": 0.05817782656421515,
            "logloss": 5.821560364973612,
            "mae": 0.4404695156475639,
            "precision": 0.788,
            "recall": 0.4053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.531672302513373,
            "auditor_fn_violation": 0.0255754236017394,
            "auditor_fp_violation": 0.03553224276908488,
            "ave_precision_score": 0.5327874234179866,
            "fpr": 0.13157894736842105,
            "logloss": 6.737578553038936,
            "mae": 0.47519475438528735,
            "precision": 0.5932203389830508,
            "recall": 0.37393162393162394
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5706129364571846,
            "auditor_fn_violation": 0.02941415619791031,
            "auditor_fp_violation": 0.03252017821398593,
            "ave_precision_score": 0.5715871859403299,
            "fpr": 0.11855104281009879,
            "logloss": 7.154954944588019,
            "mae": 0.47545714390745586,
            "precision": 0.6313993174061433,
            "recall": 0.38065843621399176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8278172010078394,
            "auditor_fn_violation": 0.008800044984255517,
            "auditor_fp_violation": 0.013335704125177815,
            "ave_precision_score": 0.8280565320216444,
            "fpr": 0.1513157894736842,
            "logloss": 0.9885789725407965,
            "mae": 0.29178098360589183,
            "precision": 0.7341040462427746,
            "recall": 0.8141025641025641
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8406575114951018,
            "auditor_fn_violation": 0.007123723308623907,
            "auditor_fp_violation": 0.016005682185058434,
            "ave_precision_score": 0.8409194513753137,
            "fpr": 0.141602634467618,
            "logloss": 0.9777943241516595,
            "mae": 0.2837907686222827,
            "precision": 0.7533460803059273,
            "recall": 0.8106995884773662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8500730638900938,
            "auditor_fn_violation": 0.010093342330184437,
            "auditor_fp_violation": 0.013513513513513525,
            "ave_precision_score": 0.8503159809343162,
            "fpr": 0.15460526315789475,
            "logloss": 0.509374871095623,
            "mae": 0.3225681338364283,
            "precision": 0.7314285714285714,
            "recall": 0.8205128205128205
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8512792461294064,
            "auditor_fn_violation": 0.009231026367262496,
            "auditor_fp_violation": 0.011010524956415071,
            "ave_precision_score": 0.8515877389115879,
            "fpr": 0.14050493962678376,
            "logloss": 0.5060709697103455,
            "mae": 0.3207453212943071,
            "precision": 0.7533718689788054,
            "recall": 0.8045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6415763156337625,
            "auditor_fn_violation": 0.02293962738041686,
            "auditor_fp_violation": 0.01998626916390075,
            "ave_precision_score": 0.6425501251767438,
            "fpr": 0.09978070175438597,
            "logloss": 1.5505481641589092,
            "mae": 0.4302240480415767,
            "precision": 0.6702898550724637,
            "recall": 0.3952991452991453
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6475051494497019,
            "auditor_fn_violation": 0.02592682937846984,
            "auditor_fp_violation": 0.01295279912184413,
            "ave_precision_score": 0.6481678905264238,
            "fpr": 0.09330406147091108,
            "logloss": 1.6918756328256195,
            "mae": 0.4401491673129481,
            "precision": 0.6730769230769231,
            "recall": 0.360082304526749
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7797677786233472,
            "auditor_fn_violation": 0.021742390163442794,
            "auditor_fp_violation": 0.03976262446657185,
            "ave_precision_score": 0.7792299581872131,
            "fpr": 0.21820175438596492,
            "logloss": 1.2397966874984367,
            "mae": 0.32043593325662395,
            "precision": 0.6774716369529984,
            "recall": 0.8931623931623932
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.775322503546918,
            "auditor_fn_violation": 0.018294914013904137,
            "auditor_fp_violation": 0.03355846839284561,
            "ave_precision_score": 0.7737967283841648,
            "fpr": 0.2217343578485181,
            "logloss": 1.210285101209973,
            "mae": 0.3220170529775984,
            "precision": 0.6813880126182965,
            "recall": 0.8888888888888888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8286711544708123,
            "auditor_fn_violation": 0.021479982006297797,
            "auditor_fp_violation": 0.019487415046625572,
            "ave_precision_score": 0.8289711959565411,
            "fpr": 0.12609649122807018,
            "logloss": 0.5301772109933203,
            "mae": 0.3191447744244023,
            "precision": 0.7558386411889597,
            "recall": 0.7606837606837606
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.843591505394791,
            "auditor_fn_violation": 0.010294841737700622,
            "auditor_fp_violation": 0.020112352295473625,
            "ave_precision_score": 0.8439709778391549,
            "fpr": 0.12733260153677278,
            "logloss": 0.5006235452586123,
            "mae": 0.3121699498921355,
            "precision": 0.7647058823529411,
            "recall": 0.7757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.6061329797148447,
            "auditor_fn_violation": 0.011702935222672066,
            "auditor_fp_violation": 0.001459518729255593,
            "ave_precision_score": 0.6090899533414432,
            "fpr": 0.2730263157894737,
            "logloss": 1.9114105535324832,
            "mae": 0.37422354548164694,
            "precision": 0.6238670694864048,
            "recall": 0.8824786324786325
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6277037716887749,
            "auditor_fn_violation": 0.012187574817163793,
            "auditor_fp_violation": 0.022646090269258085,
            "ave_precision_score": 0.6342994940514955,
            "fpr": 0.25466520307354557,
            "logloss": 1.6794865248399253,
            "mae": 0.35829278916881124,
            "precision": 0.6500754147812972,
            "recall": 0.8868312757201646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5430221593438647,
            "auditor_fn_violation": 0.025790973159394232,
            "auditor_fp_violation": 0.030672119487908957,
            "ave_precision_score": 0.5438844146426975,
            "fpr": 0.11293859649122807,
            "logloss": 7.347976774680228,
            "mae": 0.46869064613544853,
            "precision": 0.6185185185185185,
            "recall": 0.35683760683760685
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.5838244368450933,
            "auditor_fn_violation": 0.03213806561775829,
            "auditor_fp_violation": 0.028302447213792218,
            "ave_precision_score": 0.5847400364242221,
            "fpr": 0.09769484083424808,
            "logloss": 7.8880695720790035,
            "mae": 0.4690472154000638,
            "precision": 0.6798561151079137,
            "recall": 0.3888888888888889
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6624590707497297,
            "auditor_fn_violation": 0.017337681811366027,
            "auditor_fp_violation": 0.012545440177019123,
            "ave_precision_score": 0.6634593146930663,
            "fpr": 0.10964912280701754,
            "logloss": 1.4927618089920713,
            "mae": 0.42717446032314393,
            "precision": 0.691358024691358,
            "recall": 0.47863247863247865
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.6691049499027417,
            "auditor_fn_violation": 0.00805202079747758,
            "auditor_fp_violation": 0.013567508232711306,
            "ave_precision_score": 0.6696716485138174,
            "fpr": 0.1119648737650933,
            "logloss": 1.6543180799149113,
            "mae": 0.4327949783362655,
            "precision": 0.7008797653958945,
            "recall": 0.49176954732510286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8614310047706468,
            "auditor_fn_violation": 0.015575798470535314,
            "auditor_fp_violation": 0.022018729255571363,
            "ave_precision_score": 0.861627495811508,
            "fpr": 0.12390350877192982,
            "logloss": 0.5016017648759227,
            "mae": 0.29044980722542196,
            "precision": 0.7670103092783506,
            "recall": 0.7948717948717948
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8631949342987866,
            "auditor_fn_violation": 0.015286417042728795,
            "auditor_fp_violation": 0.013985923677923425,
            "ave_precision_score": 0.8637629851953176,
            "fpr": 0.1207464324917673,
            "logloss": 0.48507140353148825,
            "mae": 0.2872457880799993,
            "precision": 0.78,
            "recall": 0.8024691358024691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7337085534734136,
            "auditor_fn_violation": 0.008293972109761587,
            "auditor_fp_violation": 0.011251382961909284,
            "ave_precision_score": 0.7342740132912329,
            "fpr": 0.2576754385964912,
            "logloss": 1.4392604858309137,
            "mae": 0.3455666142685355,
            "precision": 0.6439393939393939,
            "recall": 0.9081196581196581
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7657179163366995,
            "auditor_fn_violation": 0.006674255668035398,
            "auditor_fp_violation": 0.0033783172983792883,
            "ave_precision_score": 0.7673924160271666,
            "fpr": 0.23819978046103182,
            "logloss": 1.2817547948944406,
            "mae": 0.32881531264309893,
            "precision": 0.6761194029850747,
            "recall": 0.9320987654320988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6471506651183041,
            "auditor_fn_violation": 0.0055621157594841954,
            "auditor_fp_violation": 0.012073751382961911,
            "ave_precision_score": 0.6467433693457763,
            "fpr": 0.12390350877192982,
            "logloss": 2.003105207345139,
            "mae": 0.4282163446434166,
            "precision": 0.6512345679012346,
            "recall": 0.45085470085470086
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6363572367040121,
            "auditor_fn_violation": 0.01222597155027939,
            "auditor_fp_violation": 0.02523148447084652,
            "ave_precision_score": 0.6357099853497203,
            "fpr": 0.11086717892425905,
            "logloss": 2.2201982739428403,
            "mae": 0.44611110790146,
            "precision": 0.6823899371069182,
            "recall": 0.44650205761316875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7967948791129493,
            "auditor_fn_violation": 0.018338112910481333,
            "auditor_fp_violation": 0.03233661292871819,
            "ave_precision_score": 0.7973546684593946,
            "fpr": 0.22478070175438597,
            "logloss": 0.687063000644765,
            "mae": 0.3083852556362552,
            "precision": 0.6682847896440129,
            "recall": 0.8824786324786325
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8020866484633411,
            "auditor_fn_violation": 0.009269423100378095,
            "auditor_fp_violation": 0.03184864725253439,
            "ave_precision_score": 0.80352901540602,
            "fpr": 0.18880351262349068,
            "logloss": 0.6418534340117492,
            "mae": 0.2933904178191128,
            "precision": 0.7194127243066885,
            "recall": 0.9074074074074074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6376302006592732,
            "auditor_fn_violation": 0.026449336482231234,
            "auditor_fp_violation": 0.030909198672356572,
            "ave_precision_score": 0.6388139723683349,
            "fpr": 0.13815789473684212,
            "logloss": 1.444517334789924,
            "mae": 0.434968802040839,
            "precision": 0.6238805970149254,
            "recall": 0.4465811965811966
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6458950437838401,
            "auditor_fn_violation": 0.026385331544497306,
            "auditor_fp_violation": 0.013926519015948866,
            "ave_precision_score": 0.6465662637490316,
            "fpr": 0.11086717892425905,
            "logloss": 1.5666924944670158,
            "mae": 0.43921186043789384,
            "precision": 0.6688524590163935,
            "recall": 0.41975308641975306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.670100574048808,
            "auditor_fn_violation": 0.019568151147098513,
            "auditor_fp_violation": 0.02461919155998104,
            "ave_precision_score": 0.6695417715056724,
            "fpr": 0.11293859649122807,
            "logloss": 3.8042735415294096,
            "mae": 0.412115378663803,
            "precision": 0.677115987460815,
            "recall": 0.46153846153846156
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6864952181916719,
            "auditor_fn_violation": 0.027202956096723643,
            "auditor_fp_violation": 0.02076322076580358,
            "ave_precision_score": 0.6845223443412555,
            "fpr": 0.11086717892425905,
            "logloss": 4.16409677738895,
            "mae": 0.4216045297586991,
            "precision": 0.680379746835443,
            "recall": 0.44238683127572015
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7059173947611882,
            "auditor_fn_violation": 0.017075273654221026,
            "auditor_fp_violation": 0.004805792634740006,
            "ave_precision_score": 0.7063730712915827,
            "fpr": 0.03399122807017544,
            "logloss": 2.6398245817287638,
            "mae": 0.412590400542302,
            "precision": 0.8268156424581006,
            "recall": 0.3162393162393162
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7095628212918136,
            "auditor_fn_violation": 0.0006188649925691013,
            "auditor_fp_violation": 0.008657583779944472,
            "ave_precision_score": 0.7101585797277673,
            "fpr": 0.04061470911086718,
            "logloss": 2.7027766303342142,
            "mae": 0.4290208706672789,
            "precision": 0.7944444444444444,
            "recall": 0.294238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 9271,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6727421468887113,
            "auditor_fn_violation": 0.014331702654071084,
            "auditor_fp_violation": 0.013202347083926034,
            "ave_precision_score": 0.673359186695657,
            "fpr": 0.08881578947368421,
            "logloss": 4.506157527692289,
            "mae": 0.4354445623931144,
            "precision": 0.7127659574468085,
            "recall": 0.42948717948717946
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6912508779605064,
            "auditor_fn_violation": 0.013041337471145997,
            "auditor_fp_violation": 0.008386388583973657,
            "ave_precision_score": 0.6916715150511183,
            "fpr": 0.07464324917672886,
            "logloss": 4.843753431160863,
            "mae": 0.43954779753510864,
            "precision": 0.7588652482269503,
            "recall": 0.4403292181069959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8173863070321703,
            "auditor_fn_violation": 0.009889507422402159,
            "auditor_fp_violation": 0.030701754385964918,
            "ave_precision_score": 0.816027681301869,
            "fpr": 0.24342105263157895,
            "logloss": 1.4581476617025528,
            "mae": 0.32024992570707883,
            "precision": 0.6525821596244131,
            "recall": 0.8910256410256411
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8082674379013259,
            "auditor_fn_violation": 0.009102284379757243,
            "auditor_fp_violation": 0.02680441660747724,
            "ave_precision_score": 0.805964324543206,
            "fpr": 0.22941822173435786,
            "logloss": 1.5171940220605624,
            "mae": 0.31505798570490745,
            "precision": 0.6759689922480621,
            "recall": 0.897119341563786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7920165125203845,
            "auditor_fn_violation": 0.016843323586744643,
            "auditor_fp_violation": 0.029111348190295563,
            "ave_precision_score": 0.7934396042186729,
            "fpr": 0.1787280701754386,
            "logloss": 0.9489527006058956,
            "mae": 0.30266835884979454,
            "precision": 0.7140350877192982,
            "recall": 0.8696581196581197
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7907814103019314,
            "auditor_fn_violation": 0.01676807921471905,
            "auditor_fp_violation": 0.025789371731129336,
            "ave_precision_score": 0.7913679435855264,
            "fpr": 0.1756311745334797,
            "logloss": 0.9254546624897961,
            "mae": 0.2926817587561472,
            "precision": 0.7231833910034602,
            "recall": 0.8600823045267489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8413698898659363,
            "auditor_fn_violation": 0.017543859649122806,
            "auditor_fp_violation": 0.020211000474158376,
            "ave_precision_score": 0.8415960166011791,
            "fpr": 0.125,
            "logloss": 0.5300748770389745,
            "mae": 0.3080389104435566,
            "precision": 0.7548387096774194,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8508547016876479,
            "auditor_fn_violation": 0.020246371508720575,
            "auditor_fp_violation": 0.01565700264738168,
            "ave_precision_score": 0.8510997897079535,
            "fpr": 0.10098792535675083,
            "logloss": 0.5160907100347927,
            "mae": 0.30611881963462945,
            "precision": 0.7918552036199095,
            "recall": 0.720164609053498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.659842134224941,
            "auditor_fn_violation": 0.012412843004948269,
            "auditor_fp_violation": 0.003941441441441457,
            "ave_precision_score": 0.6561208159319899,
            "fpr": 0.2675438596491228,
            "logloss": 1.5374220804511503,
            "mae": 0.3624094898420337,
            "precision": 0.6286149162861492,
            "recall": 0.8824786324786325
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6710496852213979,
            "auditor_fn_violation": 0.011817159274166227,
            "auditor_fp_violation": 0.023043843223348626,
            "ave_precision_score": 0.6690806847307842,
            "fpr": 0.24368825466520308,
            "logloss": 1.4050251499322846,
            "mae": 0.3472862760439253,
            "precision": 0.6595092024539877,
            "recall": 0.8847736625514403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.7006191150833561,
            "auditor_fn_violation": 0.0165387426900585,
            "auditor_fp_violation": 0.007097558084400189,
            "ave_precision_score": 0.7010874198528512,
            "fpr": 0.02850877192982456,
            "logloss": 2.962642180993964,
            "mae": 0.4174183711323959,
            "precision": 0.8461538461538461,
            "recall": 0.3055555555555556
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7027948343996595,
            "auditor_fn_violation": 0.0012603162987356148,
            "auditor_fp_violation": 0.005643442887583135,
            "ave_precision_score": 0.7033786058047098,
            "fpr": 0.03293084522502744,
            "logloss": 3.026991281514764,
            "mae": 0.43671924286651365,
            "precision": 0.8148148148148148,
            "recall": 0.2716049382716049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.64971835005834,
            "auditor_fn_violation": 0.03761808367071525,
            "auditor_fp_violation": 0.039229196301564725,
            "ave_precision_score": 0.6502526544723543,
            "fpr": 0.1787280701754386,
            "logloss": 1.503290141749103,
            "mae": 0.4265941344961274,
            "precision": 0.6235565819861432,
            "recall": 0.5769230769230769
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6427447554894583,
            "auditor_fn_violation": 0.03688796736729411,
            "auditor_fp_violation": 0.032719054691031195,
            "ave_precision_score": 0.6423667041302751,
            "fpr": 0.16245883644346873,
            "logloss": 1.6961121479117178,
            "mae": 0.43121789071217603,
            "precision": 0.6442307692307693,
            "recall": 0.551440329218107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8116334365857968,
            "auditor_fn_violation": 0.007984705353126407,
            "auditor_fp_violation": 0.01310850324008219,
            "ave_precision_score": 0.813171144358899,
            "fpr": 0.1787280701754386,
            "logloss": 0.790034781937349,
            "mae": 0.2921053841531383,
            "precision": 0.7145359019264448,
            "recall": 0.8717948717948718
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8301396931893448,
            "auditor_fn_violation": 0.01050263582279682,
            "auditor_fp_violation": 0.014784012397494675,
            "ave_precision_score": 0.8304767438793104,
            "fpr": 0.16355653128430298,
            "logloss": 0.7572062053258477,
            "mae": 0.2779329897126369,
            "precision": 0.7444253859348199,
            "recall": 0.8930041152263375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6775014639438242,
            "auditor_fn_violation": 0.01642393912130756,
            "auditor_fp_violation": 0.011942863916548129,
            "ave_precision_score": 0.6779808231551414,
            "fpr": 0.08552631578947369,
            "logloss": 4.003358103019703,
            "mae": 0.4302025545111232,
            "precision": 0.7214285714285714,
            "recall": 0.43162393162393164
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.6920317919696022,
            "auditor_fn_violation": 0.01569297068748221,
            "auditor_fp_violation": 0.006206495770646355,
            "ave_precision_score": 0.6924600813422533,
            "fpr": 0.07025246981339188,
            "logloss": 4.301997661649586,
            "mae": 0.43535020708376343,
            "precision": 0.7664233576642335,
            "recall": 0.43209876543209874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.8233223643824064,
            "auditor_fn_violation": 0.0022351551956815117,
            "auditor_fp_violation": 0.008576833412359744,
            "ave_precision_score": 0.819745582428544,
            "fpr": 0.4418859649122807,
            "logloss": 3.3325222598316864,
            "mae": 0.45224424764379173,
            "precision": 0.5324825986078886,
            "recall": 0.9807692307692307
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8380590093951296,
            "auditor_fn_violation": 0.001748180672439729,
            "auditor_fp_violation": 0.006526764383030929,
            "ave_precision_score": 0.8340366658480558,
            "fpr": 0.41602634467618005,
            "logloss": 3.211397177294323,
            "mae": 0.42653674983422546,
            "precision": 0.5587892898719441,
            "recall": 0.9876543209876543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6333130096915522,
            "auditor_fn_violation": 0.0038142899985005455,
            "auditor_fp_violation": 0.012031768610715985,
            "ave_precision_score": 0.6339967115874674,
            "fpr": 0.09210526315789473,
            "logloss": 4.464775172087803,
            "mae": 0.44795004445163145,
            "precision": 0.6911764705882353,
            "recall": 0.4017094017094017
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6612362858497293,
            "auditor_fn_violation": 0.013935755489603538,
            "auditor_fp_violation": 0.02053593336346613,
            "ave_precision_score": 0.6618753454809696,
            "fpr": 0.0801317233809001,
            "logloss": 4.780813712559884,
            "mae": 0.445048464057381,
            "precision": 0.7383512544802867,
            "recall": 0.42386831275720166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7846510469532757,
            "auditor_fn_violation": 0.019026934322986955,
            "auditor_fp_violation": 0.0338282361308677,
            "ave_precision_score": 0.7813954995548539,
            "fpr": 0.20942982456140352,
            "logloss": 1.49031567492795,
            "mae": 0.30417207843742,
            "precision": 0.6848184818481848,
            "recall": 0.8867521367521367
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7816036471500308,
            "auditor_fn_violation": 0.02355752508210125,
            "auditor_fp_violation": 0.031161619422741666,
            "ave_precision_score": 0.7784755173778684,
            "fpr": 0.2030735455543359,
            "logloss": 1.4412409633592038,
            "mae": 0.30711631731229344,
            "precision": 0.6962233169129721,
            "recall": 0.8724279835390947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8483487338346131,
            "auditor_fn_violation": 0.01577026165841956,
            "auditor_fp_violation": 0.016499229492650543,
            "ave_precision_score": 0.8485947986922853,
            "fpr": 0.10855263157894737,
            "logloss": 0.513119848393227,
            "mae": 0.3243523555554515,
            "precision": 0.7760180995475113,
            "recall": 0.7329059829059829
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8581440039323518,
            "auditor_fn_violation": 0.012117557245011812,
            "auditor_fp_violation": 0.00964680054239039,
            "ave_precision_score": 0.8584282597968598,
            "fpr": 0.08562019758507135,
            "logloss": 0.5025369455017065,
            "mae": 0.3223942769169971,
            "precision": 0.8198614318706697,
            "recall": 0.7304526748971193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6821954127041163,
            "auditor_fn_violation": 0.014872919478182643,
            "auditor_fp_violation": 0.023268334123597287,
            "ave_precision_score": 0.6827104967376455,
            "fpr": 0.1524122807017544,
            "logloss": 1.1489375432450804,
            "mae": 0.4191429978435648,
            "precision": 0.633245382585752,
            "recall": 0.5128205128205128
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6789163594609594,
            "auditor_fn_violation": 0.01664159585857354,
            "auditor_fp_violation": 0.01674694905404533,
            "ave_precision_score": 0.6794644445629432,
            "fpr": 0.1437980241492865,
            "logloss": 1.2895368805310359,
            "mae": 0.4272608880124971,
            "precision": 0.6543535620052771,
            "recall": 0.5102880658436214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.771868080721561,
            "auditor_fn_violation": 0.01126012145748988,
            "auditor_fp_violation": 0.03496424055634583,
            "ave_precision_score": 0.7726006534883357,
            "fpr": 0.26206140350877194,
            "logloss": 1.2018834921838084,
            "mae": 0.33817993926130474,
            "precision": 0.6367781155015197,
            "recall": 0.8952991452991453
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7757081395374283,
            "auditor_fn_violation": 0.02207586291011099,
            "auditor_fp_violation": 0.02435074578678893,
            "ave_precision_score": 0.7759918713534595,
            "fpr": 0.23819978046103182,
            "logloss": 1.1840119809491996,
            "mae": 0.3253927914252961,
            "precision": 0.6656394453004623,
            "recall": 0.8888888888888888
        }
    }
]