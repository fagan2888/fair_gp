[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5131928827599406,
            "auditor_fn_violation": 0.013306451612903222,
            "auditor_fp_violation": 0.005634542171984773,
            "ave_precision_score": 0.5151999983814174,
            "fpr": 0.09429824561403509,
            "logloss": 10.72364928244773,
            "mae": 0.48216233422119614,
            "precision": 0.5845410628019324,
            "recall": 0.26021505376344084
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5942888250253919,
            "auditor_fn_violation": 0.012413604232747249,
            "auditor_fp_violation": 0.013354420172613816,
            "ave_precision_score": 0.5867093138420335,
            "fpr": 0.07244785949506037,
            "logloss": 10.413477234896277,
            "mae": 0.46206671626795454,
            "precision": 0.6930232558139535,
            "recall": 0.3047034764826176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6730455253613639,
            "auditor_fn_violation": 0.0033248443689869837,
            "auditor_fp_violation": 0.02412280701754386,
            "ave_precision_score": 0.6698619317322564,
            "fpr": 0.3267543859649123,
            "logloss": 3.0290658444275858,
            "mae": 0.36514148124987483,
            "precision": 0.5917808219178082,
            "recall": 0.9290322580645162
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7475424773749488,
            "auditor_fn_violation": 0.0038183618083007286,
            "auditor_fp_violation": 0.023488588655766023,
            "ave_precision_score": 0.7410421353691887,
            "fpr": 0.278814489571899,
            "logloss": 2.4411239430009957,
            "mae": 0.3136701329291686,
            "precision": 0.6452513966480447,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7726977953761975,
            "auditor_fn_violation": 0.016025278249386907,
            "auditor_fp_violation": 0.017070430550649555,
            "ave_precision_score": 0.7042669952182118,
            "fpr": 0.1425438596491228,
            "logloss": 6.431042490612791,
            "mae": 0.2836592973722614,
            "precision": 0.721627408993576,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7881220074088152,
            "auditor_fn_violation": 0.015347524799148783,
            "auditor_fp_violation": 0.020533656572382833,
            "ave_precision_score": 0.7266323404414856,
            "fpr": 0.13062568605927552,
            "logloss": 6.274419194984237,
            "mae": 0.28008579178187487,
            "precision": 0.75,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6855439076889364,
            "auditor_fn_violation": 0.008488964346349746,
            "auditor_fp_violation": 0.022913477766003394,
            "ave_precision_score": 0.6835997097047364,
            "fpr": 0.2949561403508772,
            "logloss": 2.438701333984985,
            "mae": 0.3507066327066529,
            "precision": 0.6090116279069767,
            "recall": 0.9010752688172043
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7678083170382171,
            "auditor_fn_violation": 0.0052864444788643244,
            "auditor_fp_violation": 0.01909520811982043,
            "ave_precision_score": 0.7637475753593096,
            "fpr": 0.2557628979143798,
            "logloss": 1.9230733991265432,
            "mae": 0.3017217530263213,
            "precision": 0.6593567251461988,
            "recall": 0.9222903885480572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6774735186610353,
            "auditor_fn_violation": 0.0062676853423882335,
            "auditor_fp_violation": 0.021446583460889363,
            "ave_precision_score": 0.6756500930687321,
            "fpr": 0.25548245614035087,
            "logloss": 1.9169945401787742,
            "mae": 0.3374986321892288,
            "precision": 0.6266025641025641,
            "recall": 0.8408602150537634
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7507653542893244,
            "auditor_fn_violation": 0.002363747786090928,
            "auditor_fp_violation": 0.018985958870258713,
            "ave_precision_score": 0.7469036107210723,
            "fpr": 0.21844127332601537,
            "logloss": 1.5087404447438224,
            "mae": 0.29957149479991585,
            "precision": 0.6774716369529984,
            "recall": 0.8548057259713702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6901357548114508,
            "auditor_fn_violation": 0.0017520279192605173,
            "auditor_fp_violation": 0.01872620589505082,
            "ave_precision_score": 0.6831379851828253,
            "fpr": 0.4133771929824561,
            "logloss": 4.908907146573928,
            "mae": 0.42264488118330934,
            "precision": 0.548502994011976,
            "recall": 0.9849462365591398
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7552825443983655,
            "auditor_fn_violation": 0.0009562740331194064,
            "auditor_fp_violation": 0.020856201975850724,
            "ave_precision_score": 0.7530511731835292,
            "fpr": 0.3885839736553238,
            "logloss": 4.264894082414485,
            "mae": 0.38957535092159495,
            "precision": 0.5790725326991677,
            "recall": 0.9959100204498977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8014115552111115,
            "auditor_fn_violation": 0.02012591963780419,
            "auditor_fp_violation": 0.018505435849130662,
            "ave_precision_score": 0.8017381350454759,
            "fpr": 0.15021929824561403,
            "logloss": 1.3184188472648661,
            "mae": 0.2911015654266407,
            "precision": 0.7181069958847737,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8286975646240026,
            "auditor_fn_violation": 0.010038632573028138,
            "auditor_fp_violation": 0.019116017500689315,
            "ave_precision_score": 0.8290781309440513,
            "fpr": 0.12623490669593854,
            "logloss": 1.1980477502627975,
            "mae": 0.2785204950472557,
            "precision": 0.7604166666666666,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5128911709718407,
            "auditor_fn_violation": 0.012577815506508211,
            "auditor_fp_violation": 0.005634542171984773,
            "ave_precision_score": 0.514378081615919,
            "fpr": 0.09429824561403509,
            "logloss": 10.775529898729355,
            "mae": 0.48282639986313786,
            "precision": 0.5784313725490197,
            "recall": 0.2537634408602151
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5940145275036235,
            "auditor_fn_violation": 0.0067186107538177945,
            "auditor_fp_violation": 0.014935933118649889,
            "ave_precision_score": 0.5860483701858519,
            "fpr": 0.06915477497255763,
            "logloss": 10.446111544939285,
            "mae": 0.46267584441661613,
            "precision": 0.6985645933014354,
            "recall": 0.2985685071574642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7057303074713116,
            "auditor_fn_violation": 0.009630258441803435,
            "auditor_fp_violation": 0.012632952627654147,
            "ave_precision_score": 0.704100511610185,
            "fpr": 0.08771929824561403,
            "logloss": 1.8014993041205984,
            "mae": 0.353337024615142,
            "precision": 0.7667638483965015,
            "recall": 0.5655913978494623
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7800700435040242,
            "auditor_fn_violation": 0.014546140222098023,
            "auditor_fp_violation": 0.013489681148261636,
            "ave_precision_score": 0.7761043181565027,
            "fpr": 0.054884742041712405,
            "logloss": 1.4778321746965266,
            "mae": 0.33087003120745956,
            "precision": 0.8470948012232415,
            "recall": 0.5664621676891616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7269132550392561,
            "auditor_fn_violation": 0.02255942275042445,
            "auditor_fp_violation": 0.010952647278150644,
            "ave_precision_score": 0.7278847324617791,
            "fpr": 0.12938596491228072,
            "logloss": 1.3309874029590505,
            "mae": 0.3164499460591345,
            "precision": 0.7268518518518519,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7752195837657913,
            "auditor_fn_violation": 0.01590871848055688,
            "auditor_fp_violation": 0.009390233117089183,
            "ave_precision_score": 0.7756000211395536,
            "fpr": 0.09769484083424808,
            "logloss": 1.4048708103733882,
            "mae": 0.2936175055605528,
            "precision": 0.7885985748218527,
            "recall": 0.6789366053169734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6145051450334569,
            "auditor_fn_violation": 0.04943171099792494,
            "auditor_fp_violation": 0.02944581812473017,
            "ave_precision_score": 0.606956736281846,
            "fpr": 0.11732456140350878,
            "logloss": 3.5343562023407853,
            "mae": 0.3830414451955026,
            "precision": 0.6786786786786787,
            "recall": 0.4860215053763441
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7042222919121929,
            "auditor_fn_violation": 0.035521315258407245,
            "auditor_fp_violation": 0.02800422430431639,
            "ave_precision_score": 0.6948232480509676,
            "fpr": 0.0889132821075741,
            "logloss": 2.9993500957662307,
            "mae": 0.35152100775691053,
            "precision": 0.7603550295857988,
            "recall": 0.5255623721881391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5124964148285533,
            "auditor_fn_violation": 0.012698075834748152,
            "auditor_fp_violation": 0.00915705090466659,
            "ave_precision_score": 0.5144679837515849,
            "fpr": 0.09649122807017543,
            "logloss": 10.709059557862235,
            "mae": 0.48316313620372714,
            "precision": 0.5769230769230769,
            "recall": 0.25806451612903225
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5929488199576971,
            "auditor_fn_violation": 0.008139553155143114,
            "auditor_fp_violation": 0.013593728052606117,
            "ave_precision_score": 0.5860652499938217,
            "fpr": 0.07244785949506037,
            "logloss": 10.39539260058254,
            "mae": 0.46273302546987033,
            "precision": 0.6915887850467289,
            "recall": 0.30265848670756645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6648308853764253,
            "auditor_fn_violation": 0.049044991511035654,
            "auditor_fp_violation": 0.025570077318576082,
            "ave_precision_score": 0.6630923450215975,
            "fpr": 0.11074561403508772,
            "logloss": 2.6280549894342147,
            "mae": 0.37511303472664514,
            "precision": 0.7055393586005831,
            "recall": 0.5204301075268817
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7514522377765375,
            "auditor_fn_violation": 0.057645814954240274,
            "auditor_fp_violation": 0.024656515157032793,
            "ave_precision_score": 0.7473422337740812,
            "fpr": 0.0801317233809001,
            "logloss": 2.126847706808561,
            "mae": 0.3493606121161222,
            "precision": 0.7820895522388059,
            "recall": 0.5357873210633947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.793295057668463,
            "auditor_fn_violation": 0.012839558573853996,
            "auditor_fp_violation": 0.019064719965461763,
            "ave_precision_score": 0.7939128702919105,
            "fpr": 0.18640350877192982,
            "logloss": 0.7132105923570486,
            "mae": 0.3015732338995772,
            "precision": 0.6880733944954128,
            "recall": 0.8064516129032258
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8252028687072881,
            "auditor_fn_violation": 0.008720949809081916,
            "auditor_fp_violation": 0.026422711358280313,
            "ave_precision_score": 0.8261431523614804,
            "fpr": 0.17014270032930845,
            "logloss": 0.6367201197906313,
            "mae": 0.2800473412125689,
            "precision": 0.7181818181818181,
            "recall": 0.8077709611451943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.5176688976708135,
            "auditor_fn_violation": 0.01524240709300134,
            "auditor_fp_violation": 0.006630460379135763,
            "ave_precision_score": 0.5215037504327913,
            "fpr": 0.07236842105263158,
            "logloss": 10.503989737985991,
            "mae": 0.4814474943258976,
            "precision": 0.6162790697674418,
            "recall": 0.22795698924731184
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.5990107347632907,
            "auditor_fn_violation": 0.015338545700246252,
            "auditor_fp_violation": 0.013250373268269338,
            "ave_precision_score": 0.5941089712470738,
            "fpr": 0.04939626783754116,
            "logloss": 10.252030975919435,
            "mae": 0.46100061440196094,
            "precision": 0.7486033519553073,
            "recall": 0.2740286298568507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6969421581571429,
            "auditor_fn_violation": 0.011224297302395783,
            "auditor_fp_violation": 0.0051267710663683835,
            "ave_precision_score": 0.6945593524471881,
            "fpr": 0.043859649122807015,
            "logloss": 2.026803913685572,
            "mae": 0.3972005850384895,
            "precision": 0.7938144329896907,
            "recall": 0.3311827956989247
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7786148156443948,
            "auditor_fn_violation": 0.015161208496921298,
            "auditor_fp_violation": 0.005777204363727168,
            "ave_precision_score": 0.7742853940871455,
            "fpr": 0.027442371020856202,
            "logloss": 1.7433626081701756,
            "mae": 0.38811841525971763,
            "precision": 0.8711340206185567,
            "recall": 0.3456032719836401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.65244836116788,
            "auditor_fn_violation": 0.01308243727598567,
            "auditor_fp_violation": 0.0064513913418893995,
            "ave_precision_score": 0.6501296131607759,
            "fpr": 0.09320175438596491,
            "logloss": 1.8935871544519556,
            "mae": 0.4054888301863475,
            "precision": 0.678030303030303,
            "recall": 0.3849462365591398
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7466205329858011,
            "auditor_fn_violation": 0.009502131413601985,
            "auditor_fp_violation": 0.01281337627002253,
            "ave_precision_score": 0.7423410677336735,
            "fpr": 0.059275521405049394,
            "logloss": 1.562705025988473,
            "mae": 0.3800723140703687,
            "precision": 0.7969924812030075,
            "recall": 0.4335378323108384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8152672365349934,
            "auditor_fn_violation": 0.018010752688172045,
            "auditor_fp_violation": 0.018385238824129676,
            "ave_precision_score": 0.8155666068662704,
            "fpr": 0.16228070175438597,
            "logloss": 0.846187339845833,
            "mae": 0.2813209697929347,
            "precision": 0.7103718199608611,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8470150955010706,
            "auditor_fn_violation": 0.009643552221316834,
            "auditor_fp_violation": 0.021381638842790335,
            "ave_precision_score": 0.8473405981700812,
            "fpr": 0.132821075740944,
            "logloss": 0.7068294746709991,
            "mae": 0.2608551484947774,
            "precision": 0.7603960396039604,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.72601978056314,
            "auditor_fn_violation": 0.010776268628560653,
            "auditor_fp_violation": 0.022025491581302254,
            "ave_precision_score": 0.727560855632061,
            "fpr": 0.19078947368421054,
            "logloss": 1.149612312612074,
            "mae": 0.3057710135891467,
            "precision": 0.6771799628942486,
            "recall": 0.7849462365591398
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7797864123208607,
            "auditor_fn_violation": 0.0017352108629138537,
            "auditor_fp_violation": 0.023384541751421548,
            "ave_precision_score": 0.7796337716417234,
            "fpr": 0.1602634467618002,
            "logloss": 0.9751030346423685,
            "mae": 0.2803197699134851,
            "precision": 0.7250470809792844,
            "recall": 0.787321063394683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7709917172415734,
            "auditor_fn_violation": 0.01591680814940577,
            "auditor_fp_violation": 0.015073688135327137,
            "ave_precision_score": 0.7723909406047741,
            "fpr": 0.14692982456140352,
            "logloss": 1.0528347179732298,
            "mae": 0.2996666643029149,
            "precision": 0.7172995780590717,
            "recall": 0.7311827956989247
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7955026565819252,
            "auditor_fn_violation": 0.0021841658080403482,
            "auditor_fp_violation": 0.009478672985781996,
            "ave_precision_score": 0.7952988790077633,
            "fpr": 0.12952799121844127,
            "logloss": 0.9488395183103151,
            "mae": 0.29037817118460924,
            "precision": 0.7489361702127659,
            "recall": 0.7198364008179959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6556936524858712,
            "auditor_fn_violation": 0.013205055649877383,
            "auditor_fp_violation": 0.005820970210761805,
            "ave_precision_score": 0.6533776463374422,
            "fpr": 0.049342105263157895,
            "logloss": 2.153562722452664,
            "mae": 0.4281827632016593,
            "precision": 0.7352941176470589,
            "recall": 0.26881720430107525
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7523529385738674,
            "auditor_fn_violation": 0.014442880584718924,
            "auditor_fp_violation": 0.004864192778104369,
            "ave_precision_score": 0.7480672258817942,
            "fpr": 0.03293084522502744,
            "logloss": 1.8388631169092582,
            "mae": 0.41364283553494113,
            "precision": 0.8265895953757225,
            "recall": 0.29243353783231085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7915280293992139,
            "auditor_fn_violation": 0.015067911714770803,
            "auditor_fp_violation": 0.015328800188390446,
            "ave_precision_score": 0.7918706073496842,
            "fpr": 0.1611842105263158,
            "logloss": 0.9766051169104228,
            "mae": 0.29490479375178863,
            "precision": 0.7083333333333334,
            "recall": 0.7677419354838709
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8237874946595978,
            "auditor_fn_violation": 0.0007003697143973144,
            "auditor_fp_violation": 0.027333121771294502,
            "ave_precision_score": 0.8241444875176496,
            "fpr": 0.14818880351262348,
            "logloss": 0.8689081608580064,
            "mae": 0.2815434966399393,
            "precision": 0.7337278106508875,
            "recall": 0.7607361963190185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7553523723305268,
            "auditor_fn_violation": 0.012344368986983588,
            "auditor_fp_violation": 0.020651811295576753,
            "ave_precision_score": 0.757215006842692,
            "fpr": 0.1699561403508772,
            "logloss": 1.0978327733119948,
            "mae": 0.30030845950552665,
            "precision": 0.6966731898238747,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8011653792370427,
            "auditor_fn_violation": 0.002480476071823812,
            "auditor_fp_violation": 0.01965446023067199,
            "ave_precision_score": 0.8018386435756824,
            "fpr": 0.14709110867178923,
            "logloss": 0.9083044458542521,
            "mae": 0.2840412191459582,
            "precision": 0.7387914230019493,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6042690865741491,
            "auditor_fn_violation": 0.008029145444255805,
            "auditor_fp_violation": 0.027880803799207193,
            "ave_precision_score": 0.6018011556272048,
            "fpr": 0.15021929824561403,
            "logloss": 2.021957449092123,
            "mae": 0.39340325589207165,
            "precision": 0.6505102040816326,
            "recall": 0.5483870967741935
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7021644151379032,
            "auditor_fn_violation": 0.022479174102482957,
            "auditor_fp_violation": 0.026159992924810506,
            "ave_precision_score": 0.695958861976989,
            "fpr": 0.11964873765093303,
            "logloss": 1.6724583536947433,
            "mae": 0.3550879892746196,
            "precision": 0.72264631043257,
            "recall": 0.5807770961145194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.6839684886262196,
            "auditor_fn_violation": 0.01755800792303339,
            "auditor_fp_violation": 0.008781741826602298,
            "ave_precision_score": 0.6816099663551953,
            "fpr": 0.09100877192982457,
            "logloss": 1.8941659779845736,
            "mae": 0.37386606511806025,
            "precision": 0.7331189710610932,
            "recall": 0.49032258064516127
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7726954358570509,
            "auditor_fn_violation": 0.013307024573548928,
            "auditor_fp_violation": 0.011434754787458187,
            "ave_precision_score": 0.7683761046328371,
            "fpr": 0.06147091108671789,
            "logloss": 1.545330080636974,
            "mae": 0.3495501748065649,
            "precision": 0.8108108108108109,
            "recall": 0.49079754601226994
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 29759,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7199770708876325,
            "auditor_fn_violation": 0.017489624599132256,
            "auditor_fp_violation": 0.003031908630636995,
            "ave_precision_score": 0.7175532046484538,
            "fpr": 0.04824561403508772,
            "logloss": 1.7857676515308698,
            "mae": 0.36764871276184874,
            "precision": 0.8320610687022901,
            "recall": 0.46881720430107526
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7857716426173638,
            "auditor_fn_violation": 0.016083810909156223,
            "auditor_fp_violation": 0.007504382975845511,
            "ave_precision_score": 0.7814332073662517,
            "fpr": 0.038419319429198684,
            "logloss": 1.516371490309775,
            "mae": 0.35919536869133656,
            "precision": 0.8611111111111112,
            "recall": 0.4437627811860941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8191993154846466,
            "auditor_fn_violation": 0.015643274853801174,
            "auditor_fp_violation": 0.009576513991914918,
            "ave_precision_score": 0.8195339906975488,
            "fpr": 0.14364035087719298,
            "logloss": 1.0654983650081205,
            "mae": 0.33265163225944616,
            "precision": 0.722457627118644,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.853575011077512,
            "auditor_fn_violation": 0.01937689543165896,
            "auditor_fp_violation": 0.011127816419641974,
            "ave_precision_score": 0.8541091687246694,
            "fpr": 0.10537870472008781,
            "logloss": 1.0588669886281579,
            "mae": 0.31025581441656974,
            "precision": 0.7917570498915402,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.6884189701875938,
            "auditor_fn_violation": 0.014183644595359365,
            "auditor_fp_violation": 0.016403214411868598,
            "ave_precision_score": 0.6860538760696573,
            "fpr": 0.09539473684210527,
            "logloss": 1.7959159295930907,
            "mae": 0.3635158805179928,
            "precision": 0.747093023255814,
            "recall": 0.5526881720430108
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7644634901057438,
            "auditor_fn_violation": 0.014674092381459065,
            "auditor_fp_violation": 0.018946941281129538,
            "ave_precision_score": 0.7601722738418799,
            "fpr": 0.06586169045005488,
            "logloss": 1.4945077023254514,
            "mae": 0.34144967586075065,
            "precision": 0.8198198198198198,
            "recall": 0.558282208588957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7499406675724434,
            "auditor_fn_violation": 0.013681380871533678,
            "auditor_fp_violation": 0.018375426822088786,
            "ave_precision_score": 0.7513547487910357,
            "fpr": 0.18969298245614036,
            "logloss": 1.107274662131145,
            "mae": 0.30620382468314034,
            "precision": 0.6778398510242085,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8032847449479056,
            "auditor_fn_violation": 0.002119067340996994,
            "auditor_fp_violation": 0.026118374163072715,
            "ave_precision_score": 0.8035231859483583,
            "fpr": 0.16355653128430298,
            "logloss": 0.8806665693101741,
            "mae": 0.27670387518397094,
            "precision": 0.7225325884543762,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7347084785167746,
            "auditor_fn_violation": 0.01036361063950198,
            "auditor_fp_violation": 0.02196661956905687,
            "ave_precision_score": 0.7364266741094339,
            "fpr": 0.19736842105263158,
            "logloss": 1.0673029436410826,
            "mae": 0.31052231532516766,
            "precision": 0.6756756756756757,
            "recall": 0.8064516129032258
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7835869447935554,
            "auditor_fn_violation": 0.0024445596762137,
            "auditor_fp_violation": 0.026245831620894708,
            "ave_precision_score": 0.7835744838032863,
            "fpr": 0.1778265642151482,
            "logloss": 0.9004609436930011,
            "mae": 0.28897263070414947,
            "precision": 0.7112299465240641,
            "recall": 0.8159509202453987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.79622944940149,
            "auditor_fn_violation": 0.01794708545557442,
            "auditor_fp_violation": 0.016248675379724478,
            "ave_precision_score": 0.7965879116701756,
            "fpr": 0.14364035087719298,
            "logloss": 1.037603343372699,
            "mae": 0.2874165182441686,
            "precision": 0.7270833333333333,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8202493958354417,
            "auditor_fn_violation": 0.004525465846874938,
            "auditor_fp_violation": 0.015274085557769445,
            "ave_precision_score": 0.8205552876120161,
            "fpr": 0.12952799121844127,
            "logloss": 0.9529224791763566,
            "mae": 0.2796795806669424,
            "precision": 0.756701030927835,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7708939859664826,
            "auditor_fn_violation": 0.01301641199773628,
            "auditor_fp_violation": 0.01651850543584914,
            "ave_precision_score": 0.7723037262745887,
            "fpr": 0.15570175438596492,
            "logloss": 1.0134084942565151,
            "mae": 0.30002814863350136,
            "precision": 0.7107942973523421,
            "recall": 0.7505376344086021
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7983932320557987,
            "auditor_fn_violation": 0.0007811816045200911,
            "auditor_fp_violation": 0.014881308493869042,
            "ave_precision_score": 0.7982815070909286,
            "fpr": 0.141602634467618,
            "logloss": 0.9013856150807288,
            "mae": 0.28730547550776825,
            "precision": 0.7393939393939394,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6671167764818253,
            "auditor_fn_violation": 0.015294284097340127,
            "auditor_fp_violation": 0.012672200635817737,
            "ave_precision_score": 0.6353930974882742,
            "fpr": 0.3223684210526316,
            "logloss": 3.827115591761095,
            "mae": 0.4193301706659515,
            "precision": 0.5739130434782609,
            "recall": 0.8516129032258064
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6731634776500853,
            "auditor_fn_violation": 0.0013827812309895689,
            "auditor_fp_violation": 0.008505834430161122,
            "ave_precision_score": 0.6478483169027442,
            "fpr": 0.32491767288693746,
            "logloss": 3.681219930203075,
            "mae": 0.42281514477353666,
            "precision": 0.5825105782792666,
            "recall": 0.8445807770961146
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 29759,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7279602872971238,
            "auditor_fn_violation": 0.014327485380116965,
            "auditor_fp_violation": 0.018723752894540605,
            "ave_precision_score": 0.7294844250016124,
            "fpr": 0.1699561403508772,
            "logloss": 1.0044767541275397,
            "mae": 0.31943865160425794,
            "precision": 0.6875,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7747472668509083,
            "auditor_fn_violation": 0.006027220138323019,
            "auditor_fp_violation": 0.01959723443328253,
            "ave_precision_score": 0.775131231642948,
            "fpr": 0.14270032930845225,
            "logloss": 0.853116605291436,
            "mae": 0.2929236764342858,
            "precision": 0.7394789579158316,
            "recall": 0.754601226993865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6556936524858712,
            "auditor_fn_violation": 0.013205055649877383,
            "auditor_fp_violation": 0.005820970210761805,
            "ave_precision_score": 0.6533776463374422,
            "fpr": 0.049342105263157895,
            "logloss": 2.1535431733039543,
            "mae": 0.42817690088443483,
            "precision": 0.7352941176470589,
            "recall": 0.26881720430107525
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7523432060003648,
            "auditor_fn_violation": 0.014442880584718924,
            "auditor_fp_violation": 0.004864192778104369,
            "ave_precision_score": 0.7480575037869536,
            "fpr": 0.03293084522502744,
            "logloss": 1.8388474727832282,
            "mae": 0.4136377605600474,
            "precision": 0.8265895953757225,
            "recall": 0.29243353783231085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6181996602551048,
            "auditor_fn_violation": 0.012188737973967183,
            "auditor_fp_violation": 0.009937105066917855,
            "ave_precision_score": 0.6158206774597415,
            "fpr": 0.07785087719298246,
            "logloss": 2.126715259071877,
            "mae": 0.43741342858075,
            "precision": 0.6757990867579908,
            "recall": 0.31827956989247314
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7129167414869344,
            "auditor_fn_violation": 0.0006913906154947908,
            "auditor_fp_violation": 0.013765405444774507,
            "ave_precision_score": 0.7081705431133746,
            "fpr": 0.050493962678375415,
            "logloss": 1.780732276971186,
            "mae": 0.41744835468202635,
            "precision": 0.786046511627907,
            "recall": 0.3456032719836401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6227573565887581,
            "auditor_fn_violation": 0.01499717034521789,
            "auditor_fp_violation": 0.03167068958750343,
            "ave_precision_score": 0.6066181192978003,
            "fpr": 0.30153508771929827,
            "logloss": 4.024952680508657,
            "mae": 0.37535337106092553,
            "precision": 0.5901639344262295,
            "recall": 0.8516129032258064
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6786996432027319,
            "auditor_fn_violation": 0.012528087743754478,
            "auditor_fp_violation": 0.02437818968791133,
            "ave_precision_score": 0.6577632769569014,
            "fpr": 0.2689352360043908,
            "logloss": 3.9556245744852805,
            "mae": 0.33904012940565104,
            "precision": 0.6354166666666666,
            "recall": 0.8732106339468303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.733278493536553,
            "auditor_fn_violation": 0.022035936615732884,
            "auditor_fp_violation": 0.0066746143883197944,
            "ave_precision_score": 0.7308399684479587,
            "fpr": 0.0537280701754386,
            "logloss": 1.777768037826191,
            "mae": 0.33940593115585554,
            "precision": 0.8377483443708609,
            "recall": 0.5440860215053763
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7953115486568132,
            "auditor_fn_violation": 0.021684523849609078,
            "auditor_fp_violation": 0.008500632084943893,
            "ave_precision_score": 0.7909560574299909,
            "fpr": 0.03951701427003293,
            "logloss": 1.4886423620027558,
            "mae": 0.33194957920315327,
            "precision": 0.8787878787878788,
            "recall": 0.5337423312883436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.644663969698767,
            "auditor_fn_violation": 0.006901999622712709,
            "auditor_fp_violation": 0.014602712037364107,
            "ave_precision_score": 0.6422147590124354,
            "fpr": 0.07346491228070176,
            "logloss": 2.1485716056371804,
            "mae": 0.4011691032747632,
            "precision": 0.7403100775193798,
            "recall": 0.410752688172043
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7326993939116782,
            "auditor_fn_violation": 0.0025590431872209597,
            "auditor_fp_violation": 0.017557915108130748,
            "ave_precision_score": 0.7272067997627871,
            "fpr": 0.0570801317233809,
            "logloss": 1.7977588697703197,
            "mae": 0.3775726563233132,
            "precision": 0.796875,
            "recall": 0.4171779141104294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.6157668393648512,
            "auditor_fn_violation": 0.011283248443689869,
            "auditor_fp_violation": 0.003451371717885318,
            "ave_precision_score": 0.6134833450755526,
            "fpr": 0.03070175438596491,
            "logloss": 2.899066998831264,
            "mae": 0.47799208607736626,
            "precision": 0.6626506024096386,
            "recall": 0.11827956989247312
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7154940064357664,
            "auditor_fn_violation": 0.006175375270214761,
            "auditor_fp_violation": 0.0034803689503228063,
            "ave_precision_score": 0.7112387847722771,
            "fpr": 0.015367727771679473,
            "logloss": 2.6079490718506557,
            "mae": 0.4741177725612316,
            "precision": 0.8333333333333334,
            "recall": 0.14314928425357873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6268346706127699,
            "auditor_fn_violation": 0.011200716845878138,
            "auditor_fp_violation": 0.019758919109855173,
            "ave_precision_score": 0.5615990905396089,
            "fpr": 0.20065789473684212,
            "logloss": 5.389293219604227,
            "mae": 0.39871158130538614,
            "precision": 0.6171548117154811,
            "recall": 0.6344086021505376
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6794030545542453,
            "auditor_fn_violation": 0.020472345497767584,
            "auditor_fp_violation": 0.007267676268461823,
            "ave_precision_score": 0.6242809095964647,
            "fpr": 0.16465422612513722,
            "logloss": 4.317975210471652,
            "mae": 0.3731383044656921,
            "precision": 0.6746203904555315,
            "recall": 0.6359918200408998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.6608965199630648,
            "auditor_fn_violation": 0.011353989813242807,
            "auditor_fp_violation": 0.005480003139840654,
            "ave_precision_score": 0.6585748672607074,
            "fpr": 0.03837719298245614,
            "logloss": 2.352590550191357,
            "mae": 0.4468179632697127,
            "precision": 0.7083333333333334,
            "recall": 0.1827956989247312
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.7565068159285031,
            "auditor_fn_violation": 0.011428148128194602,
            "auditor_fp_violation": 0.005654949251122407,
            "ave_precision_score": 0.7522155566642775,
            "fpr": 0.02305159165751921,
            "logloss": 2.0511502060807327,
            "mae": 0.43887158367567997,
            "precision": 0.8173913043478261,
            "recall": 0.19222903885480572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6628385166990591,
            "auditor_fn_violation": 0.007076495000943226,
            "auditor_fp_violation": 0.0025437615291023998,
            "ave_precision_score": 0.6605024547834855,
            "fpr": 0.04057017543859649,
            "logloss": 2.1733492333873268,
            "mae": 0.42980569950806524,
            "precision": 0.7533333333333333,
            "recall": 0.24301075268817204
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7552244433117479,
            "auditor_fn_violation": 0.01035739058406795,
            "auditor_fp_violation": 0.0060867439041519915,
            "ave_precision_score": 0.7509254797452629,
            "fpr": 0.026344676180021953,
            "logloss": 1.8725273132947242,
            "mae": 0.41995442479891903,
            "precision": 0.8410596026490066,
            "recall": 0.25971370143149286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7936595670279314,
            "auditor_fn_violation": 0.012167515563101309,
            "auditor_fp_violation": 0.019920817143529973,
            "ave_precision_score": 0.7940263254100564,
            "fpr": 0.17543859649122806,
            "logloss": 0.9605095919444149,
            "mae": 0.2964802288455029,
            "precision": 0.6958174904942965,
            "recall": 0.7870967741935484
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8295641713648281,
            "auditor_fn_violation": 0.0015646079837657923,
            "auditor_fp_violation": 0.026157391752201897,
            "ave_precision_score": 0.8299219226843926,
            "fpr": 0.15477497255762898,
            "logloss": 0.8227456188723069,
            "mae": 0.27587972689622525,
            "precision": 0.7304015296367112,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7361573222918225,
            "auditor_fn_violation": 0.0230121675155631,
            "auditor_fp_violation": 0.0054750971388202035,
            "ave_precision_score": 0.7139888945105091,
            "fpr": 0.09758771929824561,
            "logloss": 2.256702573616896,
            "mae": 0.315609956469359,
            "precision": 0.7694300518134715,
            "recall": 0.6387096774193548
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8024406846857075,
            "auditor_fn_violation": 0.018912227063453052,
            "auditor_fp_violation": 0.006586169045005493,
            "ave_precision_score": 0.7893979353105376,
            "fpr": 0.07244785949506037,
            "logloss": 1.6592548124434312,
            "mae": 0.2964811742538385,
            "precision": 0.8272251308900523,
            "recall": 0.6462167689161554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.5342211627843207,
            "auditor_fn_violation": 0.013829937747594796,
            "auditor_fp_violation": 0.005305840103614743,
            "ave_precision_score": 0.5354824641415901,
            "fpr": 0.10087719298245613,
            "logloss": 9.816829584168941,
            "mae": 0.4739137489018345,
            "precision": 0.5947136563876652,
            "recall": 0.2903225806451613
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.611793122061125,
            "auditor_fn_violation": 0.004417716660044586,
            "auditor_fp_violation": 0.01032145291097227,
            "ave_precision_score": 0.6074829349757169,
            "fpr": 0.07025246981339188,
            "logloss": 9.43535192882531,
            "mae": 0.4472971969274006,
            "precision": 0.7288135593220338,
            "recall": 0.35173824130879344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6665038325813828,
            "auditor_fn_violation": 0.0187959818902094,
            "auditor_fp_violation": 0.005460379135758861,
            "ave_precision_score": 0.6641673253726199,
            "fpr": 0.03837719298245614,
            "logloss": 2.2324411154228443,
            "mae": 0.4282439824654923,
            "precision": 0.7682119205298014,
            "recall": 0.24946236559139784
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7566896457813601,
            "auditor_fn_violation": 0.014707764002343545,
            "auditor_fp_violation": 0.0049266209207110565,
            "ave_precision_score": 0.7523826331773114,
            "fpr": 0.026344676180021953,
            "logloss": 2.0192883517289375,
            "mae": 0.41720500398949417,
            "precision": 0.8451612903225807,
            "recall": 0.26789366053169733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.69154723941374,
            "auditor_fn_violation": 0.015152801358234316,
            "auditor_fp_violation": 0.00691010243730131,
            "ave_precision_score": 0.6891799982278826,
            "fpr": 0.049342105263157895,
            "logloss": 2.026425679744359,
            "mae": 0.3926421709617708,
            "precision": 0.7916666666666666,
            "recall": 0.36774193548387096
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.7783955759358931,
            "auditor_fn_violation": 0.015803214068452153,
            "auditor_fp_violation": 0.005584717590689884,
            "ave_precision_score": 0.7740711577384483,
            "fpr": 0.031833150384193196,
            "logloss": 1.7177761348788239,
            "mae": 0.37718446231556924,
            "precision": 0.8657407407407407,
            "recall": 0.3824130879345603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.6642582871845596,
            "auditor_fn_violation": 0.004499151103565365,
            "auditor_fp_violation": 0.02437546607009696,
            "ave_precision_score": 0.6565383343399879,
            "fpr": 0.32346491228070173,
            "logloss": 3.328362702038405,
            "mae": 0.3629052033151069,
            "precision": 0.594222833562586,
            "recall": 0.9290322580645162
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7359395289757632,
            "auditor_fn_violation": 0.0038183618083007286,
            "auditor_fp_violation": 0.023691480119237752,
            "ave_precision_score": 0.725685512007347,
            "fpr": 0.27661909989023054,
            "logloss": 2.656004801032561,
            "mae": 0.31095415760104594,
            "precision": 0.6470588235294118,
            "recall": 0.9447852760736196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7112816135839058,
            "auditor_fn_violation": 0.007083569137898509,
            "auditor_fp_violation": 0.023114623807841753,
            "ave_precision_score": 0.7089558533445754,
            "fpr": 0.29605263157894735,
            "logloss": 2.389274998041031,
            "mae": 0.34807231705727704,
            "precision": 0.6075581395348837,
            "recall": 0.8989247311827957
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7768857632364448,
            "auditor_fn_violation": 0.005093393852459938,
            "auditor_fp_violation": 0.022791474396658018,
            "ave_precision_score": 0.7725779914916451,
            "fpr": 0.2535675082327113,
            "logloss": 1.889431061907449,
            "mae": 0.298576250285292,
            "precision": 0.6617862371888726,
            "recall": 0.9243353783231084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7135697260777658,
            "auditor_fn_violation": 0.008764855687606113,
            "auditor_fp_violation": 0.02388486596805214,
            "ave_precision_score": 0.7111595815421026,
            "fpr": 0.2916666666666667,
            "logloss": 2.262287208744836,
            "mae": 0.3465969262252178,
            "precision": 0.6088235294117647,
            "recall": 0.8903225806451613
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7801540753499184,
            "auditor_fn_violation": 0.004467101704008496,
            "auditor_fp_violation": 0.022307656291456198,
            "ave_precision_score": 0.775848923580382,
            "fpr": 0.24807903402854006,
            "logloss": 1.7768653155270413,
            "mae": 0.2966083946073122,
            "precision": 0.6661742983751846,
            "recall": 0.9222903885480572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6779136621890857,
            "auditor_fn_violation": 0.01549235993208829,
            "auditor_fp_violation": 0.01848581184504887,
            "ave_precision_score": 0.6784093627705843,
            "fpr": 0.1611842105263158,
            "logloss": 1.183187761358527,
            "mae": 0.32121208452166344,
            "precision": 0.6950207468879668,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7427796150816522,
            "auditor_fn_violation": 0.0037644872148855572,
            "auditor_fp_violation": 0.021441465812788406,
            "ave_precision_score": 0.7428573320505242,
            "fpr": 0.13721185510428102,
            "logloss": 0.9794029061967322,
            "mae": 0.2960667551272016,
            "precision": 0.7401247401247402,
            "recall": 0.7280163599182005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.520150512367694,
            "auditor_fn_violation": 0.014770797962648555,
            "auditor_fp_violation": 0.0035028847286000236,
            "ave_precision_score": 0.5218330506325972,
            "fpr": 0.08552631578947369,
            "logloss": 10.889818787038145,
            "mae": 0.48115437341826184,
            "precision": 0.6020408163265306,
            "recall": 0.2537634408602151
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5970798580183445,
            "auditor_fn_violation": 0.011859144875516018,
            "auditor_fp_violation": 0.008750344655370643,
            "ave_precision_score": 0.5886968520972825,
            "fpr": 0.06037321624588365,
            "logloss": 10.699753281459655,
            "mae": 0.4648964905127372,
            "precision": 0.7135416666666666,
            "recall": 0.28016359918200406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.5336336527505476,
            "auditor_fn_violation": 0.013023486134691576,
            "auditor_fp_violation": 0.013366399780211155,
            "ave_precision_score": 0.5348967663816153,
            "fpr": 0.16885964912280702,
            "logloss": 9.780738363161754,
            "mae": 0.4881497889476707,
            "precision": 0.5261538461538462,
            "recall": 0.36774193548387096
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6117852828387502,
            "auditor_fn_violation": 0.005216856462369716,
            "auditor_fp_violation": 0.018078149629853144,
            "ave_precision_score": 0.6073208696190557,
            "fpr": 0.14270032930845225,
            "logloss": 9.369551373444276,
            "mae": 0.45093039965955894,
            "precision": 0.608433734939759,
            "recall": 0.4130879345603272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6734816927895594,
            "auditor_fn_violation": 0.013212129786832673,
            "auditor_fp_violation": 0.006404784332195141,
            "ave_precision_score": 0.6711414403272925,
            "fpr": 0.04824561403508772,
            "logloss": 2.0549509453641104,
            "mae": 0.4188324512909443,
            "precision": 0.7300613496932515,
            "recall": 0.25591397849462366
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7587666956678054,
            "auditor_fn_violation": 0.0036230664071707237,
            "auditor_fp_violation": 0.006154374391975905,
            "ave_precision_score": 0.7544820267072287,
            "fpr": 0.030735455543358946,
            "logloss": 1.7447858549809605,
            "mae": 0.405492097615316,
            "precision": 0.84,
            "recall": 0.3006134969325153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6206456235075954,
            "auditor_fn_violation": 0.04160771552537257,
            "auditor_fp_violation": 0.02826592487931238,
            "ave_precision_score": 0.6129871835000673,
            "fpr": 0.12171052631578948,
            "logloss": 3.359575279097038,
            "mae": 0.3700854370786992,
            "precision": 0.6882022471910112,
            "recall": 0.5268817204301075
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7072849202309399,
            "auditor_fn_violation": 0.03146949687864075,
            "auditor_fp_violation": 0.029122728526019534,
            "ave_precision_score": 0.6982250378413317,
            "fpr": 0.09220636663007684,
            "logloss": 2.8496531625163333,
            "mae": 0.33512914837952934,
            "precision": 0.766016713091922,
            "recall": 0.5623721881390593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8028680828301755,
            "auditor_fn_violation": 0.014891058290888517,
            "auditor_fp_violation": 0.023565975901722987,
            "ave_precision_score": 0.8031991743886226,
            "fpr": 0.17543859649122806,
            "logloss": 0.9000279941146401,
            "mae": 0.2928595416352618,
            "precision": 0.6963946869070209,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8356578554850723,
            "auditor_fn_violation": 0.006592903369182393,
            "auditor_fp_violation": 0.02544467045744222,
            "ave_precision_score": 0.8360192175976142,
            "fpr": 0.15477497255762898,
            "logloss": 0.7689722111288473,
            "mae": 0.2731846924819596,
            "precision": 0.7334593572778828,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8413524713763287,
            "auditor_fn_violation": 0.011464817958875688,
            "auditor_fp_violation": 0.014350052984811018,
            "ave_precision_score": 0.8415642183069934,
            "fpr": 0.15460526315789475,
            "logloss": 0.8839177552236682,
            "mae": 0.2896710818082605,
            "precision": 0.717434869739479,
            "recall": 0.7698924731182796
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8567617927523513,
            "auditor_fn_violation": 0.010350656259891039,
            "auditor_fp_violation": 0.02264060638535852,
            "ave_precision_score": 0.8573001865202471,
            "fpr": 0.12733260153677278,
            "logloss": 0.7749474600528315,
            "mae": 0.26830185675674345,
            "precision": 0.7637474541751528,
            "recall": 0.7668711656441718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6882484504857228,
            "auditor_fn_violation": 0.01833616298811546,
            "auditor_fp_violation": 0.0155790062404333,
            "ave_precision_score": 0.6860065397633454,
            "fpr": 0.09100877192982457,
            "logloss": 2.7596008642028393,
            "mae": 0.3513170116414663,
            "precision": 0.7373417721518988,
            "recall": 0.5010752688172043
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7490766426313838,
            "auditor_fn_violation": 0.005317871325023182,
            "auditor_fp_violation": 0.017729592500299134,
            "ave_precision_score": 0.7458517892794754,
            "fpr": 0.06586169045005488,
            "logloss": 2.659381470883445,
            "mae": 0.335820065217057,
            "precision": 0.8064516129032258,
            "recall": 0.5112474437627812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 29759,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6277442541165867,
            "auditor_fn_violation": 0.005845595170722505,
            "auditor_fp_violation": 0.02501569920326544,
            "ave_precision_score": 0.6110464484958396,
            "fpr": 0.3081140350877193,
            "logloss": 3.2744407078458835,
            "mae": 0.3568473052421408,
            "precision": 0.5997150997150997,
            "recall": 0.9053763440860215
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6864155902464708,
            "auditor_fn_violation": 0.0038004036104956687,
            "auditor_fp_violation": 0.02363425432184829,
            "ave_precision_score": 0.666314210419259,
            "fpr": 0.2667398463227223,
            "logloss": 2.9206988944349614,
            "mae": 0.3081312012626195,
            "precision": 0.6513629842180775,
            "recall": 0.9284253578732107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7709974231972123,
            "auditor_fn_violation": 0.01495472552348614,
            "auditor_fp_violation": 0.014857824090427412,
            "ave_precision_score": 0.7724036596450092,
            "fpr": 0.13815789473684212,
            "logloss": 1.0401627239030877,
            "mae": 0.30061149304406,
            "precision": 0.7212389380530974,
            "recall": 0.7010752688172043
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7862074098852095,
            "auditor_fn_violation": 0.00012570738463541886,
            "auditor_fp_violation": 0.011814525988315533,
            "ave_precision_score": 0.7855755099745486,
            "fpr": 0.12184412733260154,
            "logloss": 0.986976872217269,
            "mae": 0.2909507359977634,
            "precision": 0.753880266075388,
            "recall": 0.6952965235173824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8323543355043302,
            "auditor_fn_violation": 0.013723825693265421,
            "auditor_fp_violation": 0.018201263785862877,
            "ave_precision_score": 0.8325792006811008,
            "fpr": 0.1787280701754386,
            "logloss": 0.8434444334295013,
            "mae": 0.2906035069691307,
            "precision": 0.6947565543071161,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8491893990256948,
            "auditor_fn_violation": 0.008411170896944643,
            "auditor_fp_violation": 0.023072401038388105,
            "ave_precision_score": 0.849601695613709,
            "fpr": 0.15148188803512624,
            "logloss": 0.735723237010603,
            "mae": 0.26467185351217587,
            "precision": 0.7401129943502824,
            "recall": 0.803680981595092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5688746284276622,
            "auditor_fn_violation": 0.019378419166195093,
            "auditor_fp_violation": 0.025283076258879867,
            "ave_precision_score": 0.5509894825106187,
            "fpr": 0.1162280701754386,
            "logloss": 4.133739109245083,
            "mae": 0.4675177628673279,
            "precision": 0.5984848484848485,
            "recall": 0.33978494623655914
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6304742307830388,
            "auditor_fn_violation": 0.01512304732658555,
            "auditor_fp_violation": 0.03388547557238803,
            "ave_precision_score": 0.6102352388421737,
            "fpr": 0.09549945115257959,
            "logloss": 3.889298488906842,
            "mae": 0.4561379670798938,
            "precision": 0.6561264822134387,
            "recall": 0.3394683026584867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8179827280456932,
            "auditor_fn_violation": 0.014431239388794575,
            "auditor_fp_violation": 0.020055732171592296,
            "ave_precision_score": 0.8182524295986122,
            "fpr": 0.16557017543859648,
            "logloss": 0.8888369308032953,
            "mae": 0.2888014301088228,
            "precision": 0.7056530214424951,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.841633063353694,
            "auditor_fn_violation": 0.009630083572963037,
            "auditor_fp_violation": 0.024378189687911313,
            "ave_precision_score": 0.8421362194335431,
            "fpr": 0.1350164654226125,
            "logloss": 0.7729189874419112,
            "mae": 0.2647488431312093,
            "precision": 0.754,
            "recall": 0.7709611451942741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7230477353564373,
            "auditor_fn_violation": 0.009479343520090553,
            "auditor_fp_violation": 0.004959967031673143,
            "ave_precision_score": 0.7213844199711903,
            "fpr": 0.05921052631578947,
            "logloss": 1.73929307875886,
            "mae": 0.36079792714575665,
            "precision": 0.8181818181818182,
            "recall": 0.5225806451612903
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7822935976551557,
            "auditor_fn_violation": 0.01034167716098852,
            "auditor_fp_violation": 0.008500632084943893,
            "ave_precision_score": 0.7783247051805613,
            "fpr": 0.042810098792535674,
            "logloss": 1.4824206429940137,
            "mae": 0.3499656383757593,
            "precision": 0.8612099644128114,
            "recall": 0.4948875255623722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6413919270858566,
            "auditor_fn_violation": 0.014947651386530853,
            "auditor_fp_violation": 0.0011038502296008487,
            "ave_precision_score": 0.6390867364756547,
            "fpr": 0.1118421052631579,
            "logloss": 1.9665510193424827,
            "mae": 0.3997443561747755,
            "precision": 0.6655737704918033,
            "recall": 0.43655913978494626
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7352947713046576,
            "auditor_fn_violation": 0.008889307913504355,
            "auditor_fp_violation": 0.00750958532106274,
            "ave_precision_score": 0.7310436515912242,
            "fpr": 0.0801317233809001,
            "logloss": 1.6042856070647975,
            "mae": 0.3718066448373156,
            "precision": 0.762214983713355,
            "recall": 0.4785276073619632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6260429571769527,
            "auditor_fn_violation": 0.011184210526315793,
            "auditor_fp_violation": 0.030574198359433268,
            "ave_precision_score": 0.6078415413987299,
            "fpr": 0.3048245614035088,
            "logloss": 3.9450596792450643,
            "mae": 0.3708645317309753,
            "precision": 0.591776798825257,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.677156746061826,
            "auditor_fn_violation": 0.011158775161118706,
            "auditor_fp_violation": 0.025299004791359946,
            "ave_precision_score": 0.6562077871788506,
            "fpr": 0.2678375411635565,
            "logloss": 3.7896875284632885,
            "mae": 0.33608474912301645,
            "precision": 0.6390532544378699,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.5874503178773677,
            "auditor_fn_violation": 0.008842671194114316,
            "auditor_fp_violation": 0.015193885160328116,
            "ave_precision_score": 0.5849873076343743,
            "fpr": 0.07785087719298246,
            "logloss": 2.508440718875748,
            "mae": 0.45385242033332046,
            "precision": 0.6553398058252428,
            "recall": 0.2903225806451613
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6817775925657638,
            "auditor_fn_violation": 0.005757847171247138,
            "auditor_fp_violation": 0.02003943377674656,
            "ave_precision_score": 0.6756088284432332,
            "fpr": 0.0570801317233809,
            "logloss": 2.187608170714535,
            "mae": 0.4337484217951786,
            "precision": 0.74,
            "recall": 0.30265848670756645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6445771968363915,
            "auditor_fn_violation": 0.01665251839275609,
            "auditor_fp_violation": 0.010464500176616048,
            "ave_precision_score": 0.551289649879663,
            "fpr": 0.25,
            "logloss": 7.325726797723481,
            "mae": 0.3746285923131031,
            "precision": 0.6180904522613065,
            "recall": 0.7935483870967742
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6895038960300736,
            "auditor_fn_violation": 0.010635742650046359,
            "auditor_fp_violation": 0.011283886776158696,
            "ave_precision_score": 0.5985181343071061,
            "fpr": 0.20636663007683864,
            "logloss": 6.67361762825782,
            "mae": 0.33889708236824706,
            "precision": 0.6786324786324787,
            "recall": 0.8118609406952966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7835567464326942,
            "auditor_fn_violation": 0.01007121297868327,
            "auditor_fp_violation": 0.026617508536441774,
            "ave_precision_score": 0.7201507485209772,
            "fpr": 0.24561403508771928,
            "logloss": 3.8982391673451997,
            "mae": 0.33193705189047906,
            "precision": 0.65,
            "recall": 0.8946236559139785
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7965877904073743,
            "auditor_fn_violation": 0.01163691217767841,
            "auditor_fp_violation": 0.0254186587313561,
            "ave_precision_score": 0.7393267965265656,
            "fpr": 0.21953896816684962,
            "logloss": 3.6768414845538326,
            "mae": 0.311691515203462,
            "precision": 0.6923076923076923,
            "recall": 0.9202453987730062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.586931466966147,
            "auditor_fn_violation": 0.011125259385021687,
            "auditor_fp_violation": 0.01556674123788218,
            "ave_precision_score": 0.5844689436586632,
            "fpr": 0.07675438596491228,
            "logloss": 2.506583081766451,
            "mae": 0.4542173827918102,
            "precision": 0.6601941747572816,
            "recall": 0.2924731182795699
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6815662089694451,
            "auditor_fn_violation": 0.005757847171247138,
            "auditor_fp_violation": 0.02003943377674656,
            "ave_precision_score": 0.675397285512308,
            "fpr": 0.0570801317233809,
            "logloss": 2.1862626737138426,
            "mae": 0.4339761285348577,
            "precision": 0.74,
            "recall": 0.30265848670756645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6765013425950601,
            "auditor_fn_violation": 0.0336611016789285,
            "auditor_fp_violation": 0.04177705168962676,
            "ave_precision_score": 0.6655968393334859,
            "fpr": 0.17214912280701755,
            "logloss": 2.904370823062787,
            "mae": 0.34316481617206646,
            "precision": 0.6645299145299145,
            "recall": 0.6688172043010753
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7388137768338644,
            "auditor_fn_violation": 0.03166254750504513,
            "auditor_fp_violation": 0.03366177472804741,
            "ave_precision_score": 0.7282242944993638,
            "fpr": 0.12623490669593854,
            "logloss": 2.539429545237094,
            "mae": 0.29318699820212635,
            "precision": 0.7526881720430108,
            "recall": 0.7157464212678937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6098116062815085,
            "auditor_fn_violation": 0.009066685531031892,
            "auditor_fp_violation": 0.014286274971545193,
            "ave_precision_score": 0.6073409943590017,
            "fpr": 0.07456140350877193,
            "logloss": 2.324029512953517,
            "mae": 0.4343677047936098,
            "precision": 0.6777251184834123,
            "recall": 0.30752688172043013
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7029504978167922,
            "auditor_fn_violation": 0.004121406396261102,
            "auditor_fp_violation": 0.019664864921106435,
            "ave_precision_score": 0.6967451422469157,
            "fpr": 0.05817782656421515,
            "logloss": 2.0083454069654434,
            "mae": 0.4116423978335273,
            "precision": 0.7601809954751131,
            "recall": 0.34355828220858897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.613793465628103,
            "auditor_fn_violation": 0.04569892473118281,
            "auditor_fp_violation": 0.028874269005847955,
            "ave_precision_score": 0.6063112623679497,
            "fpr": 0.09758771929824561,
            "logloss": 3.641954184844227,
            "mae": 0.39384616421543034,
            "precision": 0.6941580756013745,
            "recall": 0.4344086021505376
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.7016360195524982,
            "auditor_fn_violation": 0.03962476345686331,
            "auditor_fp_violation": 0.02768948241867434,
            "ave_precision_score": 0.6934725584941854,
            "fpr": 0.0801317233809001,
            "logloss": 3.1015115849285193,
            "mae": 0.36873447633640843,
            "precision": 0.7558528428093646,
            "recall": 0.4621676891615542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7308827460301188,
            "auditor_fn_violation": 0.011146481795887571,
            "auditor_fp_violation": 0.02760852074257232,
            "ave_precision_score": 0.7190222424798858,
            "fpr": 0.1524122807017544,
            "logloss": 2.373568571713145,
            "mae": 0.2828925364623929,
            "precision": 0.7122153209109731,
            "recall": 0.7397849462365591
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7842947704550765,
            "auditor_fn_violation": 0.007656926589132144,
            "auditor_fp_violation": 0.0228955213010025,
            "ave_precision_score": 0.7733706288282938,
            "fpr": 0.1207464324917673,
            "logloss": 2.019659592498551,
            "mae": 0.25672927017187164,
            "precision": 0.7727272727272727,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.6324513047152118,
            "auditor_fn_violation": 0.014678834182229776,
            "auditor_fp_violation": 0.0063949723301542465,
            "ave_precision_score": 0.630055954777096,
            "fpr": 0.0625,
            "logloss": 2.1398200082314607,
            "mae": 0.4336729701363211,
            "precision": 0.6984126984126984,
            "recall": 0.2838709677419355
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7246604501886017,
            "auditor_fn_violation": 0.0015039990661737208,
            "auditor_fp_violation": 0.009639945687515932,
            "ave_precision_score": 0.7199070524377431,
            "fpr": 0.043907793633369926,
            "logloss": 1.7952859951910085,
            "mae": 0.41585631812409357,
            "precision": 0.7916666666666666,
            "recall": 0.310838445807771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6130345583182076,
            "auditor_fn_violation": 0.014556215808338052,
            "auditor_fp_violation": 0.029382040111464346,
            "ave_precision_score": 0.596973246094897,
            "fpr": 0.2883771929824561,
            "logloss": 3.7988093653208423,
            "mae": 0.37056313874452995,
            "precision": 0.5966257668711656,
            "recall": 0.8365591397849462
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6709597291876306,
            "auditor_fn_violation": 0.011657115150209105,
            "auditor_fp_violation": 0.023694081291846365,
            "ave_precision_score": 0.6526994902103611,
            "fpr": 0.2557628979143798,
            "logloss": 3.6459693903085695,
            "mae": 0.3334214937199545,
            "precision": 0.6426380368098159,
            "recall": 0.8568507157464212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7032140496562979,
            "auditor_fn_violation": 0.014855687606112063,
            "auditor_fp_violation": 0.009797284037835082,
            "ave_precision_score": 0.7015895131652473,
            "fpr": 0.08333333333333333,
            "logloss": 1.81918415099356,
            "mae": 0.35791829029620387,
            "precision": 0.7661538461538462,
            "recall": 0.535483870967742
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7784057827822728,
            "auditor_fn_violation": 0.00659290336918239,
            "auditor_fp_violation": 0.013489681148261636,
            "ave_precision_score": 0.77444297829613,
            "fpr": 0.054884742041712405,
            "logloss": 1.4967389428589575,
            "mae": 0.3363622684374446,
            "precision": 0.84375,
            "recall": 0.5521472392638037
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.737442200569462,
            "auditor_fn_violation": 0.012117996604414266,
            "auditor_fp_violation": 0.02323482083284274,
            "ave_precision_score": 0.7389415511113239,
            "fpr": 0.17543859649122806,
            "logloss": 1.0860272905246562,
            "mae": 0.30415955873526257,
            "precision": 0.6875,
            "recall": 0.7569892473118279
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7910886236052687,
            "auditor_fn_violation": 0.0008889307913504347,
            "auditor_fp_violation": 0.023527606244895197,
            "ave_precision_score": 0.7910496159043594,
            "fpr": 0.145993413830955,
            "logloss": 0.9283580755595597,
            "mae": 0.28228421950034593,
            "precision": 0.740234375,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.6443186454738152,
            "auditor_fn_violation": 0.017305697038294664,
            "auditor_fp_violation": 0.011497213391420392,
            "ave_precision_score": 0.551031172461824,
            "fpr": 0.25109649122807015,
            "logloss": 7.3531088969573455,
            "mae": 0.37477116722455334,
            "precision": 0.6164154103852596,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6896115695985354,
            "auditor_fn_violation": 0.010606560578613134,
            "auditor_fp_violation": 0.011700074393536614,
            "ave_precision_score": 0.5986239008363826,
            "fpr": 0.2074643249176729,
            "logloss": 6.690019908459749,
            "mae": 0.33818298612844644,
            "precision": 0.6785714285714286,
            "recall": 0.8159509202453987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6214208408220823,
            "auditor_fn_violation": 0.011403508771929836,
            "auditor_fp_violation": 0.005210173083716002,
            "ave_precision_score": 0.6191290859598669,
            "fpr": 0.041666666666666664,
            "logloss": 2.4840646521000496,
            "mae": 0.46042058254248847,
            "precision": 0.7099236641221374,
            "recall": 0.2
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7220713091937534,
            "auditor_fn_violation": 0.00661984066588998,
            "auditor_fp_violation": 0.006776054645434162,
            "ave_precision_score": 0.7178113639920178,
            "fpr": 0.025246981339187707,
            "logloss": 2.1126339064060424,
            "mae": 0.4467350221540039,
            "precision": 0.8203125,
            "recall": 0.2147239263803681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6229161797902734,
            "auditor_fn_violation": 0.04158413506885493,
            "auditor_fp_violation": 0.026222575454295693,
            "ave_precision_score": 0.6154288514966708,
            "fpr": 0.12938596491228072,
            "logloss": 3.1765303085259116,
            "mae": 0.3695035534819494,
            "precision": 0.6793478260869565,
            "recall": 0.5376344086021505
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7105432315806308,
            "auditor_fn_violation": 0.03148969985117145,
            "auditor_fp_violation": 0.028004224304316386,
            "ave_precision_score": 0.7022075464107508,
            "fpr": 0.09659714599341383,
            "logloss": 2.6336859045798455,
            "mae": 0.33245293909109047,
            "precision": 0.7595628415300546,
            "recall": 0.5685071574642127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7581099556433477,
            "auditor_fn_violation": 0.012874929258630452,
            "auditor_fp_violation": 0.02310481180580087,
            "ave_precision_score": 0.6776685774100589,
            "fpr": 0.16666666666666666,
            "logloss": 7.197688304342258,
            "mae": 0.3017383861394603,
            "precision": 0.6941649899396378,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7775407080719627,
            "auditor_fn_violation": 0.004339149544647452,
            "auditor_fp_violation": 0.018132774254633992,
            "ave_precision_score": 0.7017860696851206,
            "fpr": 0.15477497255762898,
            "logloss": 7.019467884790711,
            "mae": 0.2916962398609425,
            "precision": 0.7229862475442044,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.712074782428577,
            "auditor_fn_violation": 0.0075009432182607085,
            "auditor_fp_violation": 0.023114623807841753,
            "ave_precision_score": 0.7096765893205468,
            "fpr": 0.29605263157894735,
            "logloss": 2.4084345212935094,
            "mae": 0.34852349642715563,
            "precision": 0.6081277213352685,
            "recall": 0.9010752688172043
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7773812380253826,
            "auditor_fn_violation": 0.005225835561272251,
            "auditor_fp_violation": 0.022791474396658018,
            "ave_precision_score": 0.7730824783286346,
            "fpr": 0.2535675082327113,
            "logloss": 1.9067646703075174,
            "mae": 0.29927282823853946,
            "precision": 0.6622807017543859,
            "recall": 0.9263803680981595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5128831806649481,
            "auditor_fn_violation": 0.023040464063384267,
            "auditor_fp_violation": 0.013528297813885946,
            "ave_precision_score": 0.5143551228077928,
            "fpr": 0.1206140350877193,
            "logloss": 10.801681804338656,
            "mae": 0.4830718199186258,
            "precision": 0.5546558704453441,
            "recall": 0.2946236559139785
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.5879027074729997,
            "auditor_fn_violation": 0.01261338918332851,
            "auditor_fp_violation": 0.013697774956950598,
            "ave_precision_score": 0.5792346159624652,
            "fpr": 0.08781558726673985,
            "logloss": 10.470450686018792,
            "mae": 0.4591571473155195,
            "precision": 0.6694214876033058,
            "recall": 0.3312883435582822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 29759,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.6173272676476063,
            "auditor_fn_violation": 0.003921429918883229,
            "auditor_fp_violation": 0.008448133757211821,
            "ave_precision_score": 0.6192075184757703,
            "fpr": 0.013157894736842105,
            "logloss": 1.2939709101554182,
            "mae": 0.48671418981702247,
            "precision": 0.3684210526315789,
            "recall": 0.015053763440860216
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0.6602239741628715,
            "auditor_fn_violation": 0.001838470500292946,
            "auditor_fp_violation": 0.004728931802456548,
            "ave_precision_score": 0.6617956797174711,
            "fpr": 0.008781558726673985,
            "logloss": 1.3094373233165368,
            "mae": 0.50579147737886,
            "precision": 0.3333333333333333,
            "recall": 0.0081799591002045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5450673243878421,
            "auditor_fn_violation": 0.014855687606112066,
            "auditor_fp_violation": 0.017749911691981635,
            "ave_precision_score": 0.546540146848777,
            "fpr": 0.18201754385964913,
            "logloss": 9.817635995859613,
            "mae": 0.4838812471811387,
            "precision": 0.5297450424929179,
            "recall": 0.4021505376344086
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6363985366528182,
            "auditor_fn_violation": 0.00944825682018681,
            "auditor_fp_violation": 0.008084444467565986,
            "ave_precision_score": 0.6323618028158542,
            "fpr": 0.15367727771679474,
            "logloss": 9.358381980516995,
            "mae": 0.45347963025224786,
            "precision": 0.6011396011396012,
            "recall": 0.43149284253578735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.512834303096951,
            "auditor_fn_violation": 0.013794567062818333,
            "auditor_fp_violation": 0.006497998351583659,
            "ave_precision_score": 0.5146039477035144,
            "fpr": 0.09210526315789473,
            "logloss": 10.763724367335268,
            "mae": 0.48265423531645585,
            "precision": 0.5882352941176471,
            "recall": 0.25806451612903225
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5946912773106385,
            "auditor_fn_violation": 0.007100222457175331,
            "auditor_fp_violation": 0.012969446626539248,
            "ave_precision_score": 0.5865064830070468,
            "fpr": 0.06805708013172337,
            "logloss": 10.460860796590344,
            "mae": 0.46241086614659105,
            "precision": 0.7004830917874396,
            "recall": 0.2965235173824131
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6370614035087719,
            "auc_prc": 0.6715391591302845,
            "auditor_fn_violation": 0.012214676476136574,
            "auditor_fp_violation": 0.013702460850111859,
            "ave_precision_score": 0.6692034877420295,
            "fpr": 0.08552631578947369,
            "logloss": 1.8718635683743552,
            "mae": 0.38659837952393855,
            "precision": 0.7310344827586207,
            "recall": 0.4559139784946237
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7536605419726253,
            "auditor_fn_violation": 0.009829868523544314,
            "auditor_fp_violation": 0.018203005915066513,
            "ave_precision_score": 0.7493865855663226,
            "fpr": 0.06147091108671789,
            "logloss": 1.569324254429114,
            "mae": 0.3659404359297029,
            "precision": 0.8082191780821918,
            "recall": 0.48261758691206547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6623010171002712,
            "auditor_fn_violation": 0.019701471420486706,
            "auditor_fp_violation": 0.0049329840260606776,
            "ave_precision_score": 0.6599744856293502,
            "fpr": 0.04057017543859649,
            "logloss": 2.314186161328981,
            "mae": 0.4353707989645003,
            "precision": 0.7375886524822695,
            "recall": 0.22365591397849463
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7553964466827224,
            "auditor_fn_violation": 0.01200505523268212,
            "auditor_fp_violation": 0.0064769197954437875,
            "ave_precision_score": 0.7510917513949034,
            "fpr": 0.025246981339187707,
            "logloss": 2.0908540172974157,
            "mae": 0.4248165072458177,
            "precision": 0.8380281690140845,
            "recall": 0.24335378323108384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7586406437528703,
            "auditor_fn_violation": 0.0144100169779287,
            "auditor_fp_violation": 0.015215962164920131,
            "ave_precision_score": 0.7601899373859344,
            "fpr": 0.15570175438596492,
            "logloss": 1.0303512829796513,
            "mae": 0.2984032586514226,
            "precision": 0.7096114519427403,
            "recall": 0.7462365591397849
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8087484639234754,
            "auditor_fn_violation": 0.0003030445879603749,
            "auditor_fp_violation": 0.01850994428288273,
            "ave_precision_score": 0.8088854727931357,
            "fpr": 0.13172338090010977,
            "logloss": 0.8859634837807441,
            "mae": 0.28141791446853803,
            "precision": 0.7551020408163265,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.6473361291664895,
            "auditor_fn_violation": 0.01345029239766082,
            "auditor_fp_violation": 0.018983770948624367,
            "ave_precision_score": 0.5562044686299892,
            "fpr": 0.2817982456140351,
            "logloss": 7.062610818285042,
            "mae": 0.36030278205571165,
            "precision": 0.6106060606060606,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6910200422885749,
            "auditor_fn_violation": 0.006094563380091993,
            "auditor_fp_violation": 0.018889715483740084,
            "ave_precision_score": 0.6043814605894419,
            "fpr": 0.24807903402854006,
            "logloss": 6.27279166568858,
            "mae": 0.32160798387147554,
            "precision": 0.6549618320610687,
            "recall": 0.8773006134969326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6875703659990056,
            "auditor_fn_violation": 0.011297396717600454,
            "auditor_fp_violation": 0.03791357588602379,
            "ave_precision_score": 0.6892590332184824,
            "fpr": 0.2807017543859649,
            "logloss": 0.730151757004332,
            "mae": 0.37609649042031124,
            "precision": 0.6138763197586727,
            "recall": 0.875268817204301
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7672846314905265,
            "auditor_fn_violation": 0.00940111655094853,
            "auditor_fp_violation": 0.03386206501891052,
            "ave_precision_score": 0.7691276345438814,
            "fpr": 0.23929747530186607,
            "logloss": 0.5966510012642495,
            "mae": 0.33286834556331324,
            "precision": 0.667175572519084,
            "recall": 0.8936605316973415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6117830231688554,
            "auditor_fn_violation": 0.012082625919637812,
            "auditor_fp_violation": 0.00972860002354881,
            "ave_precision_score": 0.6093189970242527,
            "fpr": 0.06907894736842106,
            "logloss": 2.331870015585838,
            "mae": 0.4399989733814681,
            "precision": 0.6701570680628273,
            "recall": 0.2752688172043011
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7108437419498279,
            "auditor_fn_violation": 0.004841979083189115,
            "auditor_fp_violation": 0.014717434619526485,
            "ave_precision_score": 0.7050408576219511,
            "fpr": 0.05159165751920966,
            "logloss": 1.9790820233709483,
            "mae": 0.4162368172414155,
            "precision": 0.7684729064039408,
            "recall": 0.31901840490797545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6361842692935541,
            "auditor_fn_violation": 0.0197863610639502,
            "auditor_fp_violation": 0.018745829899132625,
            "ave_precision_score": 0.6338869259957989,
            "fpr": 0.15350877192982457,
            "logloss": 2.1212111156275038,
            "mae": 0.37694658828158956,
            "precision": 0.6534653465346535,
            "recall": 0.567741935483871
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7269771080947081,
            "auditor_fn_violation": 0.011434882452371497,
            "auditor_fp_violation": 0.006554954973702145,
            "ave_precision_score": 0.7227509870917783,
            "fpr": 0.10647639956092206,
            "logloss": 1.6555194077144564,
            "mae": 0.33119460454936644,
            "precision": 0.7550505050505051,
            "recall": 0.6114519427402862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7950114913762016,
            "auditor_fn_violation": 0.013794567062818338,
            "auditor_fp_violation": 0.022040209584363594,
            "ave_precision_score": 0.7953731669503488,
            "fpr": 0.18092105263157895,
            "logloss": 0.9544860578828903,
            "mae": 0.29702523652795576,
            "precision": 0.6898496240601504,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.830305218690948,
            "auditor_fn_violation": 0.004956462594196363,
            "auditor_fp_violation": 0.02671924503566208,
            "ave_precision_score": 0.8306622136233758,
            "fpr": 0.15806805708013172,
            "logloss": 0.8145222863755316,
            "mae": 0.2748692171838317,
            "precision": 0.7303370786516854,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7394479038874701,
            "auditor_fn_violation": 0.013947840030182984,
            "auditor_fp_violation": 0.02562894933082147,
            "ave_precision_score": 0.7410245159351241,
            "fpr": 0.17214912280701755,
            "logloss": 1.1903993916348015,
            "mae": 0.30584278197953574,
            "precision": 0.693359375,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7869155062082482,
            "auditor_fn_violation": 0.003227986055459406,
            "auditor_fp_violation": 0.026698435654793184,
            "ave_precision_score": 0.7873875100845268,
            "fpr": 0.15367727771679474,
            "logloss": 0.9977187016782296,
            "mae": 0.2904121607646697,
            "precision": 0.7302504816955684,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.532602156170591,
            "auditor_fn_violation": 0.013999717034521797,
            "auditor_fp_violation": 0.013209407747556813,
            "ave_precision_score": 0.5338664178147187,
            "fpr": 0.16447368421052633,
            "logloss": 9.824893286620805,
            "mae": 0.48818969006966195,
            "precision": 0.5297805642633229,
            "recall": 0.3634408602150538
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6113703248910208,
            "auditor_fn_violation": 0.0030843204730189376,
            "auditor_fp_violation": 0.017833639404643623,
            "ave_precision_score": 0.6069061170611287,
            "fpr": 0.14050493962678376,
            "logloss": 9.413304098720792,
            "mae": 0.45099117518371035,
            "precision": 0.6085626911314985,
            "recall": 0.4069529652351738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 29759,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6167521532914456,
            "auditor_fn_violation": 0.010127806074325603,
            "auditor_fp_violation": 0.016474351426665097,
            "ave_precision_score": 0.6143239313277521,
            "fpr": 0.0712719298245614,
            "logloss": 2.237186327484534,
            "mae": 0.43591853825736115,
            "precision": 0.6782178217821783,
            "recall": 0.2946236559139785
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.7099415580962886,
            "auditor_fn_violation": 2.693729670760009e-05,
            "auditor_fp_violation": 0.017896067547250302,
            "ave_precision_score": 0.7044803378426858,
            "fpr": 0.052689352360043906,
            "logloss": 1.891153734515108,
            "mae": 0.4149941564005225,
            "precision": 0.7681159420289855,
            "recall": 0.32515337423312884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6934450909135746,
            "auditor_fn_violation": 0.013558762497641949,
            "auditor_fp_violation": 0.0049329840260606776,
            "ave_precision_score": 0.6910751594534899,
            "fpr": 0.04057017543859649,
            "logloss": 2.2420499467226356,
            "mae": 0.40990936371800285,
            "precision": 0.7784431137724551,
            "recall": 0.27956989247311825
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7753446891281455,
            "auditor_fn_violation": 0.012108314870061207,
            "auditor_fp_violation": 0.00667981125891552,
            "ave_precision_score": 0.7710192482200291,
            "fpr": 0.027442371020856202,
            "logloss": 2.0225759678590993,
            "mae": 0.40189405218084223,
            "precision": 0.8554913294797688,
            "recall": 0.30265848670756645
        }
    }
]