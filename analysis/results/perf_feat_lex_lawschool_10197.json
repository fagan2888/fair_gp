[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.725955362224425,
            "auditor_fn_violation": 0.031058114035087726,
            "auditor_fp_violation": 0.017196129792072787,
            "ave_precision_score": 0.7214302143897029,
            "fpr": 0.13925438596491227,
            "logloss": 1.6031468765139913,
            "mae": 0.3081766590750673,
            "precision": 0.7315010570824524,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7265986631462249,
            "auditor_fn_violation": 0.020203143019911357,
            "auditor_fp_violation": 0.016131341573998953,
            "ave_precision_score": 0.7214477472076357,
            "fpr": 0.145993413830955,
            "logloss": 1.6850263468604358,
            "mae": 0.3013255162735897,
            "precision": 0.7234927234927235,
            "recall": 0.7341772151898734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7636483100178717,
            "auditor_fn_violation": 0.009836440058479532,
            "auditor_fp_violation": 0.004629629629629632,
            "ave_precision_score": 0.764828122576038,
            "fpr": 0.15460526315789475,
            "logloss": 0.6400777979550525,
            "mae": 0.36480922443514463,
            "precision": 0.7145748987854251,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7722345704516539,
            "auditor_fn_violation": 0.011764324454510514,
            "auditor_fp_violation": 0.006350051619288282,
            "ave_precision_score": 0.7728727593619538,
            "fpr": 0.1163556531284303,
            "logloss": 0.6894794767485487,
            "mae": 0.37391848359195645,
            "precision": 0.7376237623762376,
            "recall": 0.6286919831223629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6444848454005578,
            "auditor_fn_violation": 0.05276864035087718,
            "auditor_fp_violation": 0.018274853801169597,
            "ave_precision_score": 0.5835287668732249,
            "fpr": 0.15789473684210525,
            "logloss": 10.314115615957776,
            "mae": 0.4220238097912766,
            "precision": 0.6230366492146597,
            "recall": 0.49583333333333335
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6621307858708794,
            "auditor_fn_violation": 0.04196945907265629,
            "auditor_fp_violation": 0.022664760981344213,
            "ave_precision_score": 0.5924460863002076,
            "fpr": 0.16355653128430298,
            "logloss": 9.765216809973785,
            "mae": 0.40207756682496354,
            "precision": 0.6330049261083743,
            "recall": 0.5421940928270043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7393911260409967,
            "auditor_fn_violation": 0.022772752192982457,
            "auditor_fp_violation": 0.015480324074074077,
            "ave_precision_score": 0.7359362673027701,
            "fpr": 0.1524122807017544,
            "logloss": 1.857617435699987,
            "mae": 0.2950540448372857,
            "precision": 0.7163265306122449,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7468750233731896,
            "auditor_fn_violation": 0.01737785250130844,
            "auditor_fp_violation": 0.021155116589258675,
            "ave_precision_score": 0.7425462863559571,
            "fpr": 0.14709110867178923,
            "logloss": 1.8871760369277903,
            "mae": 0.27800814564313514,
            "precision": 0.7298387096774194,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6362304037730135,
            "auditor_fn_violation": 0.057223135964912276,
            "auditor_fp_violation": 0.024813190383365828,
            "ave_precision_score": 0.5954192480132137,
            "fpr": 0.20175438596491227,
            "logloss": 6.110276208769983,
            "mae": 0.4098245412183716,
            "precision": 0.6142557651991615,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6387913014964136,
            "auditor_fn_violation": 0.03546665925606859,
            "auditor_fp_violation": 0.03073796743086658,
            "ave_precision_score": 0.5933985759507427,
            "fpr": 0.2052689352360044,
            "logloss": 6.143234226942932,
            "mae": 0.3855739717462522,
            "precision": 0.6304347826086957,
            "recall": 0.6729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.746827367311249,
            "auditor_fn_violation": 0.015131578947368426,
            "auditor_fp_violation": 0.02320652615334633,
            "ave_precision_score": 0.7461390257109094,
            "fpr": 0.17653508771929824,
            "logloss": 1.0849969372927253,
            "mae": 0.31120229232998864,
            "precision": 0.7045871559633028,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7692420885270325,
            "auditor_fn_violation": 0.019174922536091932,
            "auditor_fp_violation": 0.02362430200925882,
            "ave_precision_score": 0.7677535166150274,
            "fpr": 0.1668496158068057,
            "logloss": 0.9843334488497352,
            "mae": 0.2948389999352116,
            "precision": 0.7153558052434457,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7971848631242446,
            "auditor_fn_violation": 0.008760508040935675,
            "auditor_fp_violation": 0.019290123456790126,
            "ave_precision_score": 0.7973465197526128,
            "fpr": 0.1787280701754386,
            "logloss": 0.9484852051186032,
            "mae": 0.28117824411368464,
            "precision": 0.7078853046594982,
            "recall": 0.8229166666666666
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8435966340183295,
            "auditor_fn_violation": 0.009080298461837739,
            "auditor_fp_violation": 0.021906170954039992,
            "ave_precision_score": 0.8432458547807855,
            "fpr": 0.1668496158068057,
            "logloss": 0.87250981438083,
            "mae": 0.2645963776367233,
            "precision": 0.7231329690346083,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7632081712492808,
            "auditor_fn_violation": 0.009320175438596494,
            "auditor_fp_violation": 0.0184779077322937,
            "ave_precision_score": 0.7430149671133677,
            "fpr": 0.14912280701754385,
            "logloss": 2.2532638825620537,
            "mae": 0.28129825031055516,
            "precision": 0.7306930693069307,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7755150500737864,
            "auditor_fn_violation": 0.015643309387838283,
            "auditor_fp_violation": 0.021536923490418414,
            "ave_precision_score": 0.7569743818595114,
            "fpr": 0.14489571899012074,
            "logloss": 2.0623249600606517,
            "mae": 0.26750261821557736,
            "precision": 0.7386138613861386,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7579635222147643,
            "auditor_fn_violation": 0.016876827485380115,
            "auditor_fp_violation": 0.018640350877192985,
            "ave_precision_score": 0.753039192042599,
            "fpr": 0.16666666666666666,
            "logloss": 1.4913430721611631,
            "mae": 0.2941069986194985,
            "precision": 0.7110266159695817,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7521477341426434,
            "auditor_fn_violation": 0.018855340493823734,
            "auditor_fp_violation": 0.023061639207549736,
            "ave_precision_score": 0.7464491124104478,
            "fpr": 0.16245883644346873,
            "logloss": 1.6651966553723208,
            "mae": 0.2840854865660972,
            "precision": 0.720226843100189,
            "recall": 0.8037974683544303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8439933047550221,
            "auditor_fn_violation": 0.005598958333333337,
            "auditor_fp_violation": 0.02174707602339182,
            "ave_precision_score": 0.8445287138374508,
            "fpr": 0.18421052631578946,
            "logloss": 0.6762780790397948,
            "mae": 0.2789774085104,
            "precision": 0.7098445595854922,
            "recall": 0.85625
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8625723561756931,
            "auditor_fn_violation": 0.00929103734478271,
            "auditor_fp_violation": 0.020371407686878153,
            "ave_precision_score": 0.8628250124608533,
            "fpr": 0.1734357848518112,
            "logloss": 0.6018163157727584,
            "mae": 0.2665235683126181,
            "precision": 0.7188612099644128,
            "recall": 0.8523206751054853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.6627135318402589,
            "auditor_fn_violation": 0.0366593567251462,
            "auditor_fp_violation": 0.01112735542560105,
            "ave_precision_score": 0.6443338152404375,
            "fpr": 0.16885964912280702,
            "logloss": 3.219504223780219,
            "mae": 0.3386206958599305,
            "precision": 0.6907630522088354,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6656112710842165,
            "auditor_fn_violation": 0.028572487228297378,
            "auditor_fp_violation": 0.020122730823622807,
            "ave_precision_score": 0.6391889001000557,
            "fpr": 0.1778265642151482,
            "logloss": 3.681931817449289,
            "mae": 0.3220703305120928,
            "precision": 0.6848249027237354,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.7090195783484394,
            "auditor_fn_violation": 0.001507675438596494,
            "auditor_fp_violation": 0.00038580246913580294,
            "ave_precision_score": 0.7064534728263308,
            "fpr": 0.015350877192982455,
            "logloss": 5.96179040505164,
            "mae": 0.5310147793465948,
            "precision": 0.4166666666666667,
            "recall": 0.020833333333333332
        },
        "train": {
            "accuracy": 0.47530186608122943,
            "auc_prc": 0.7484878048310748,
            "auditor_fn_violation": 0.0029758182921350534,
            "auditor_fp_violation": 0.0035970229109259576,
            "ave_precision_score": 0.7442891684851951,
            "fpr": 0.01646542261251372,
            "logloss": 6.047836633349475,
            "mae": 0.5252009337477777,
            "precision": 0.4230769230769231,
            "recall": 0.023206751054852322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8454868367041988,
            "auditor_fn_violation": 0.012838084795321645,
            "auditor_fp_violation": 0.01622400909681612,
            "ave_precision_score": 0.8458337773343809,
            "fpr": 0.12719298245614036,
            "logloss": 0.6056216566151084,
            "mae": 0.28239829835416586,
            "precision": 0.7542372881355932,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8677320155326671,
            "auditor_fn_violation": 0.010814841575307892,
            "auditor_fp_violation": 0.01656841000032655,
            "ave_precision_score": 0.8679477655558957,
            "fpr": 0.11525795828759605,
            "logloss": 0.5449289432600616,
            "mae": 0.2700057248873728,
            "precision": 0.7732181425485961,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7825668934844261,
            "auditor_fn_violation": 0.008379020467836258,
            "auditor_fp_violation": 0.023485725308641976,
            "ave_precision_score": 0.7781599987021228,
            "fpr": 0.14583333333333334,
            "logloss": 0.9772798706888219,
            "mae": 0.2794638038147624,
            "precision": 0.744721689059501,
            "recall": 0.8083333333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7723898620711118,
            "auditor_fn_violation": 0.013288128685035684,
            "auditor_fp_violation": 0.0044962786386574475,
            "ave_precision_score": 0.7678392777841783,
            "fpr": 0.14050493962678376,
            "logloss": 1.0689781598588985,
            "mae": 0.2816614672327828,
            "precision": 0.7445109780439122,
            "recall": 0.7869198312236287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8513338565473716,
            "auditor_fn_violation": 0.0189327485380117,
            "auditor_fp_violation": 0.022381619558154646,
            "ave_precision_score": 0.8516525179435765,
            "fpr": 0.1074561403508772,
            "logloss": 0.6007266325506272,
            "mae": 0.2743289773232089,
            "precision": 0.7850877192982456,
            "recall": 0.7458333333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8609568028435168,
            "auditor_fn_violation": 0.03623782461893316,
            "auditor_fp_violation": 0.01850507526870917,
            "ave_precision_score": 0.8613020662868875,
            "fpr": 0.09110867178924259,
            "logloss": 0.5800466086046171,
            "mae": 0.2718770345405408,
            "precision": 0.8033175355450237,
            "recall": 0.7151898734177216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.725808494778098,
            "auditor_fn_violation": 0.01813322368421053,
            "auditor_fp_violation": 0.016569200779727095,
            "ave_precision_score": 0.7214904636335184,
            "fpr": 0.21052631578947367,
            "logloss": 1.3295638929619644,
            "mae": 0.3113458281248936,
            "precision": 0.6789297658862876,
            "recall": 0.8458333333333333
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7130760441924214,
            "auditor_fn_violation": 0.014932355134386566,
            "auditor_fp_violation": 0.02288831896952327,
            "ave_precision_score": 0.708354179792776,
            "fpr": 0.2074643249176729,
            "logloss": 1.3881876017351293,
            "mae": 0.3037314083055405,
            "precision": 0.6823529411764706,
            "recall": 0.8565400843881856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7253244975989344,
            "auditor_fn_violation": 0.026053088450292403,
            "auditor_fp_violation": 0.01106136289798571,
            "ave_precision_score": 0.7217912384813988,
            "fpr": 0.1425438596491228,
            "logloss": 1.2437252434028985,
            "mae": 0.3058536136526924,
            "precision": 0.7319587628865979,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7122640885373077,
            "auditor_fn_violation": 0.020631568221502784,
            "auditor_fp_violation": 0.009924467542645575,
            "ave_precision_score": 0.7077307057523415,
            "fpr": 0.16136114160263446,
            "logloss": 1.2873564011150818,
            "mae": 0.3050882032553291,
            "precision": 0.706,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8033991832073388,
            "auditor_fn_violation": 0.012097953216374272,
            "auditor_fp_violation": 0.015533625730994153,
            "ave_precision_score": 0.8036294934278143,
            "fpr": 0.14912280701754385,
            "logloss": 0.7960530736683085,
            "mae": 0.28371001282791614,
            "precision": 0.734375,
            "recall": 0.7833333333333333
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8142582339814732,
            "auditor_fn_violation": 0.011078844131964229,
            "auditor_fp_violation": 0.01480757685747802,
            "ave_precision_score": 0.812944252021042,
            "fpr": 0.13721185510428102,
            "logloss": 0.8080533829973596,
            "mae": 0.272770162290228,
            "precision": 0.7474747474747475,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.62969422670333,
            "auditor_fn_violation": 0.06106085526315789,
            "auditor_fp_violation": 0.025102542235217677,
            "ave_precision_score": 0.5933315837638522,
            "fpr": 0.18969298245614036,
            "logloss": 5.999419018839261,
            "mae": 0.4065505229207246,
            "precision": 0.6222707423580786,
            "recall": 0.59375
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.634079073553673,
            "auditor_fn_violation": 0.038294265586572,
            "auditor_fp_violation": 0.03471428535544464,
            "ave_precision_score": 0.5905429746802682,
            "fpr": 0.19099890230515917,
            "logloss": 6.102762618026792,
            "mae": 0.38605650286329735,
            "precision": 0.634453781512605,
            "recall": 0.6371308016877637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 10197,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.7776238538412643,
            "auditor_fn_violation": 0.002339181286549708,
            "auditor_fp_violation": 0.01803118908382068,
            "ave_precision_score": 0.5794593654385163,
            "fpr": 0.3815789473684211,
            "logloss": 12.582253034293384,
            "mae": 0.40266545774750084,
            "precision": 0.5740514075887393,
            "recall": 0.9770833333333333
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.774972188668835,
            "auditor_fn_violation": 0.004173093044690539,
            "auditor_fp_violation": 0.027068099782219367,
            "ave_precision_score": 0.5864136648268661,
            "fpr": 0.3578485181119649,
            "logloss": 11.727568121012814,
            "mae": 0.39414568375550724,
            "precision": 0.5820512820512821,
            "recall": 0.9578059071729957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7962254425277094,
            "auditor_fn_violation": 0.015085891812865496,
            "auditor_fp_violation": 0.016036184210526317,
            "ave_precision_score": 0.7964645064564208,
            "fpr": 0.14802631578947367,
            "logloss": 0.8147639431763932,
            "mae": 0.2869898130488684,
            "precision": 0.7294589178356713,
            "recall": 0.7583333333333333
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8146660836366599,
            "auditor_fn_violation": 0.014432139763879819,
            "auditor_fp_violation": 0.015106491470885983,
            "ave_precision_score": 0.8133506565693461,
            "fpr": 0.1437980241492865,
            "logloss": 0.8155280357145398,
            "mae": 0.275036306861373,
            "precision": 0.7358870967741935,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7251149396622303,
            "auditor_fn_violation": 0.016509046052631583,
            "auditor_fp_violation": 0.012404057017543864,
            "ave_precision_score": 0.7208205849651577,
            "fpr": 0.20723684210526316,
            "logloss": 1.3228851538160817,
            "mae": 0.3118640666548947,
            "precision": 0.6807432432432432,
            "recall": 0.8395833333333333
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7124171978037482,
            "auditor_fn_violation": 0.014825827786963832,
            "auditor_fp_violation": 0.02281296234429437,
            "ave_precision_score": 0.7075259956874896,
            "fpr": 0.20856201975850713,
            "logloss": 1.401174759406594,
            "mae": 0.30483520422045823,
            "precision": 0.6790540540540541,
            "recall": 0.8481012658227848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7646107238418092,
            "auditor_fn_violation": 0.011424067982456137,
            "auditor_fp_violation": 0.016599658869395715,
            "ave_precision_score": 0.7352895680920493,
            "fpr": 0.125,
            "logloss": 4.810859649469727,
            "mae": 0.32578889105609954,
            "precision": 0.7239709443099274,
            "recall": 0.6229166666666667
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7776937892160335,
            "auditor_fn_violation": 0.009064087778534282,
            "auditor_fp_violation": 0.013659644266491173,
            "ave_precision_score": 0.7545922511273101,
            "fpr": 0.12843029637760703,
            "logloss": 4.2240976481538635,
            "mae": 0.3118057873147977,
            "precision": 0.7247058823529412,
            "recall": 0.6497890295358649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7855831582632701,
            "auditor_fn_violation": 0.021210252192982455,
            "auditor_fp_violation": 0.027909762833008445,
            "ave_precision_score": 0.7858630722673716,
            "fpr": 0.14692982456140352,
            "logloss": 0.9702432726501775,
            "mae": 0.28215117251094446,
            "precision": 0.7303822937625755,
            "recall": 0.75625
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8023906275717595,
            "auditor_fn_violation": 0.03292621360122646,
            "auditor_fp_violation": 0.024526069624497937,
            "ave_precision_score": 0.8017316142349791,
            "fpr": 0.13391877058177826,
            "logloss": 0.9599980154350257,
            "mae": 0.2695023575272833,
            "precision": 0.7474120082815735,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7767696617828356,
            "auditor_fn_violation": 0.008004385964912287,
            "auditor_fp_violation": 0.024488304093567264,
            "ave_precision_score": 0.726038980750945,
            "fpr": 0.15789473684210525,
            "logloss": 5.409689141520665,
            "mae": 0.31686036096845216,
            "precision": 0.7,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7839379862959599,
            "auditor_fn_violation": 0.015015724362804355,
            "auditor_fp_violation": 0.02348614819633918,
            "ave_precision_score": 0.7346626045162272,
            "fpr": 0.16465422612513722,
            "logloss": 5.14698277293618,
            "mae": 0.3057570545046226,
            "precision": 0.6938775510204082,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 10197,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.8506371061050996,
            "auditor_fn_violation": 0.004751461988304094,
            "auditor_fp_violation": 0.02423448667966213,
            "ave_precision_score": 0.8508531180937076,
            "fpr": 0.36403508771929827,
            "logloss": 1.3346711151827122,
            "mae": 0.3757914693315366,
            "precision": 0.5860349127182045,
            "recall": 0.9791666666666666
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.8658086062462269,
            "auditor_fn_violation": 0.006646380154418338,
            "auditor_fp_violation": 0.027045492794650686,
            "ave_precision_score": 0.8660120935422897,
            "fpr": 0.36663007683863885,
            "logloss": 1.239130894636375,
            "mae": 0.373932064009951,
            "precision": 0.5809284818067754,
            "recall": 0.9767932489451476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7994911470211021,
            "auditor_fn_violation": 0.016403965643274863,
            "auditor_fp_violation": 0.021358735380116966,
            "ave_precision_score": 0.7998641320292388,
            "fpr": 0.14144736842105263,
            "logloss": 0.7853531585994211,
            "mae": 0.3156905342986105,
            "precision": 0.7301255230125523,
            "recall": 0.7270833333333333
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8043124237670314,
            "auditor_fn_violation": 0.01955008406397199,
            "auditor_fp_violation": 0.022526607168424567,
            "ave_precision_score": 0.8045797896349707,
            "fpr": 0.150384193194292,
            "logloss": 0.7542686875951496,
            "mae": 0.30681410266656906,
            "precision": 0.7192622950819673,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7919142890679022,
            "auditor_fn_violation": 0.011627375730994153,
            "auditor_fp_violation": 0.020853638726445748,
            "ave_precision_score": 0.7921474095598287,
            "fpr": 0.13267543859649122,
            "logloss": 0.7795469082505563,
            "mae": 0.2983069406306906,
            "precision": 0.7408993576017131,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7822457928779436,
            "auditor_fn_violation": 0.0078042861046654375,
            "auditor_fp_violation": 0.018394552218373453,
            "ave_precision_score": 0.7810140625472239,
            "fpr": 0.13830954994511527,
            "logloss": 0.8313104649655141,
            "mae": 0.2956607870504047,
            "precision": 0.7352941176470589,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6577245243224932,
            "auditor_fn_violation": 0.015851151315789486,
            "auditor_fp_violation": 0.005898716699155299,
            "ave_precision_score": 0.6573635760359747,
            "fpr": 0.07456140350877193,
            "logloss": 1.7442866273491628,
            "mae": 0.4364096607605519,
            "precision": 0.6746411483253588,
            "recall": 0.29375
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6890746797394136,
            "auditor_fn_violation": 0.010687471920780725,
            "auditor_fp_violation": 0.011115102221262123,
            "ave_precision_score": 0.6894864080165467,
            "fpr": 0.05598243688254665,
            "logloss": 1.789758899590168,
            "mae": 0.43478744377367246,
            "precision": 0.6927710843373494,
            "recall": 0.24261603375527427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6250148113381839,
            "auditor_fn_violation": 0.06140350877192983,
            "auditor_fp_violation": 0.025341130604288508,
            "ave_precision_score": 0.5700793042494745,
            "fpr": 0.21052631578947367,
            "logloss": 7.516823932007291,
            "mae": 0.4225200299116456,
            "precision": 0.6,
            "recall": 0.6
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.633806671114094,
            "auditor_fn_violation": 0.042532201364476385,
            "auditor_fp_violation": 0.025583574265210105,
            "ave_precision_score": 0.5692159025812927,
            "fpr": 0.22283205268935236,
            "logloss": 7.6458598648225005,
            "mae": 0.39406913668006244,
            "precision": 0.6118546845124283,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 10197,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6362410743123427,
            "auditor_fn_violation": 0.048793859649122806,
            "auditor_fp_violation": 0.015482862248213138,
            "ave_precision_score": 0.5809467618433263,
            "fpr": 0.19188596491228072,
            "logloss": 9.0492722831037,
            "mae": 0.39789154462515125,
            "precision": 0.6284501061571125,
            "recall": 0.6166666666666667
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6409392112549106,
            "auditor_fn_violation": 0.02970028762383804,
            "auditor_fp_violation": 0.03176784130899483,
            "ave_precision_score": 0.5754505687576124,
            "fpr": 0.20087815587266739,
            "logloss": 8.895864648923302,
            "mae": 0.3759480149949993,
            "precision": 0.6383399209486166,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.7765650383907676,
            "auditor_fn_violation": 0.003001644736842105,
            "auditor_fp_violation": 0.017399183723196886,
            "ave_precision_score": 0.5764760096287505,
            "fpr": 0.37390350877192985,
            "logloss": 12.672072458233508,
            "mae": 0.3941285794446645,
            "precision": 0.5774473358116481,
            "recall": 0.9708333333333333
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7732200373621231,
            "auditor_fn_violation": 0.006783013056547495,
            "auditor_fp_violation": 0.02705302845717358,
            "ave_precision_score": 0.5828497689416283,
            "fpr": 0.35236004390779363,
            "logloss": 11.819807267681965,
            "mae": 0.38454252469243994,
            "precision": 0.5841968911917098,
            "recall": 0.9514767932489452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.84579374635477,
            "auditor_fn_violation": 0.01789793494152047,
            "auditor_fp_violation": 0.026407163742690063,
            "ave_precision_score": 0.8462341107228384,
            "fpr": 0.13815789473684212,
            "logloss": 0.6127618178148442,
            "mae": 0.278695268248137,
            "precision": 0.7433808553971487,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8657068362406303,
            "auditor_fn_violation": 0.026066778751962654,
            "auditor_fp_violation": 0.020810988000713376,
            "ave_precision_score": 0.8660714480723488,
            "fpr": 0.12184412733260154,
            "logloss": 0.5529129456474964,
            "mae": 0.26494404301893926,
            "precision": 0.7682672233820459,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7871878585344938,
            "auditor_fn_violation": 0.010119700292397662,
            "auditor_fp_violation": 0.020627741228070182,
            "ave_precision_score": 0.7865874545142603,
            "fpr": 0.14144736842105263,
            "logloss": 0.8787383840157509,
            "mae": 0.2843512139881026,
            "precision": 0.7414829659318637,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7951458078205753,
            "auditor_fn_violation": 0.010041360400542827,
            "auditor_fp_violation": 0.013966094542422015,
            "ave_precision_score": 0.7931151567874803,
            "fpr": 0.1350164654226125,
            "logloss": 0.8960039280003415,
            "mae": 0.27843091644652895,
            "precision": 0.7479508196721312,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6085526315789473,
            "auc_prc": 0.7765284980457884,
            "auditor_fn_violation": 0.002339181286549708,
            "auditor_fp_violation": 0.01799057829759585,
            "ave_precision_score": 0.5764394742951044,
            "fpr": 0.3793859649122807,
            "logloss": 12.680680832079595,
            "mae": 0.40040269731074213,
            "precision": 0.5754601226993865,
            "recall": 0.9770833333333333
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7732487798839623,
            "auditor_fn_violation": 0.004636255424789378,
            "auditor_fp_violation": 0.02633714051749907,
            "ave_precision_score": 0.5828785055775321,
            "fpr": 0.3578485181119649,
            "logloss": 11.824298631790663,
            "mae": 0.3895339015789502,
            "precision": 0.5825864276568502,
            "recall": 0.959915611814346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7746359768198756,
            "auditor_fn_violation": 0.013007127192982457,
            "auditor_fp_violation": 0.025942677875243663,
            "ave_precision_score": 0.7740162196071843,
            "fpr": 0.13486842105263158,
            "logloss": 1.123335900588562,
            "mae": 0.28208133792889073,
            "precision": 0.7458677685950413,
            "recall": 0.7520833333333333
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7945720904756913,
            "auditor_fn_violation": 0.024862556563705673,
            "auditor_fp_violation": 0.024043787223033013,
            "ave_precision_score": 0.7925193354042864,
            "fpr": 0.12733260153677278,
            "logloss": 1.0798158869649235,
            "mae": 0.26717041386967955,
            "precision": 0.7542372881355932,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7639796765161326,
            "auditor_fn_violation": 0.028871984649122807,
            "auditor_fp_violation": 0.02141203703703704,
            "ave_precision_score": 0.758430537112743,
            "fpr": 0.13596491228070176,
            "logloss": 1.6013209167533884,
            "mae": 0.29188963697247,
            "precision": 0.7474541751527495,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7513389624091921,
            "auditor_fn_violation": 0.03822247541765668,
            "auditor_fp_violation": 0.02378506280974714,
            "ave_precision_score": 0.7453964427938563,
            "fpr": 0.13391877058177826,
            "logloss": 1.9029510396250566,
            "mae": 0.2911623188266225,
            "precision": 0.7463617463617463,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.623997598950169,
            "auditor_fn_violation": 0.057223135964912276,
            "auditor_fp_violation": 0.02920169346978558,
            "ave_precision_score": 0.6142792263462417,
            "fpr": 0.18530701754385964,
            "logloss": 2.9630737537165284,
            "mae": 0.41287464658902456,
            "precision": 0.6210762331838565,
            "recall": 0.5770833333333333
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6300669435141533,
            "auditor_fn_violation": 0.0475065653267379,
            "auditor_fp_violation": 0.031785424521548235,
            "ave_precision_score": 0.6188769969805039,
            "fpr": 0.1877058177826564,
            "logloss": 3.03864675672459,
            "mae": 0.39598269239753286,
            "precision": 0.6208425720620843,
            "recall": 0.5907172995780591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7712143177121742,
            "auditor_fn_violation": 0.014453125000000004,
            "auditor_fp_violation": 0.022051656920077975,
            "ave_precision_score": 0.7726408635246721,
            "fpr": 0.16557017543859648,
            "logloss": 0.7984791188310705,
            "mae": 0.31145449392253094,
            "precision": 0.710727969348659,
            "recall": 0.7729166666666667
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8081445998483772,
            "auditor_fn_violation": 0.018646917422779255,
            "auditor_fp_violation": 0.02509877997623754,
            "ave_precision_score": 0.807942329937855,
            "fpr": 0.14928649835345773,
            "logloss": 0.6532824240496939,
            "mae": 0.2936281524293184,
            "precision": 0.7306930693069307,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5956630669711245,
            "auditor_fn_violation": 0.05208333333333333,
            "auditor_fp_violation": 0.023432423651721903,
            "ave_precision_score": 0.5692222311166732,
            "fpr": 0.24561403508771928,
            "logloss": 5.187022884434411,
            "mae": 0.43691445476928537,
            "precision": 0.582089552238806,
            "recall": 0.65
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.5996987060511033,
            "auditor_fn_violation": 0.040260389890091564,
            "auditor_fp_violation": 0.021190283014365503,
            "ave_precision_score": 0.5665522451149664,
            "fpr": 0.24259055982436883,
            "logloss": 5.459521820023928,
            "mae": 0.41139411537079057,
            "precision": 0.5981818181818181,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8410476430687661,
            "auditor_fn_violation": 0.016118421052631584,
            "auditor_fp_violation": 0.020483065302144256,
            "ave_precision_score": 0.8411377484001243,
            "fpr": 0.1425438596491228,
            "logloss": 1.3955094177242888,
            "mae": 0.28469869370707923,
            "precision": 0.7389558232931727,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8512875858861605,
            "auditor_fn_violation": 0.015326043157470576,
            "auditor_fp_violation": 0.03283539349973751,
            "ave_precision_score": 0.8512812567142289,
            "fpr": 0.13062568605927552,
            "logloss": 1.2514598619842088,
            "mae": 0.27073642643976376,
            "precision": 0.7546391752577319,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8514779899161136,
            "auditor_fn_violation": 0.012015716374269007,
            "auditor_fp_violation": 0.02646807992202729,
            "ave_precision_score": 0.8517890088707478,
            "fpr": 0.19078947368421054,
            "logloss": 0.9551143587690406,
            "mae": 0.28625904277859665,
            "precision": 0.702054794520548,
            "recall": 0.8541666666666666
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8658496937279028,
            "auditor_fn_violation": 0.017285220025288667,
            "auditor_fp_violation": 0.030514409442687525,
            "ave_precision_score": 0.8660801425046418,
            "fpr": 0.1602634467618002,
            "logloss": 1.022590180056029,
            "mae": 0.2705484759484452,
            "precision": 0.7355072463768116,
            "recall": 0.8565400843881856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6769762070245628,
            "auditor_fn_violation": 0.007634320175438618,
            "auditor_fp_violation": 0.004934210526315793,
            "ave_precision_score": 0.6786145106134862,
            "fpr": 0.07894736842105263,
            "logloss": 1.7215086322243245,
            "mae": 0.3871664794126216,
            "precision": 0.7482517482517482,
            "recall": 0.44583333333333336
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6990807644253224,
            "auditor_fn_violation": 0.014485403437591204,
            "auditor_fp_violation": 0.005918006967975946,
            "ave_precision_score": 0.7005339584338877,
            "fpr": 0.05598243688254665,
            "logloss": 1.8458245779628306,
            "mae": 0.3863415487875052,
            "precision": 0.782051282051282,
            "recall": 0.3860759493670886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6287826533114382,
            "auditor_fn_violation": 0.06044407894736842,
            "auditor_fp_violation": 0.025031473359324246,
            "ave_precision_score": 0.5927359838739792,
            "fpr": 0.19188596491228072,
            "logloss": 5.9934128896179235,
            "mae": 0.40764054334839267,
            "precision": 0.6203904555314533,
            "recall": 0.5958333333333333
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.6340231842786457,
            "auditor_fn_violation": 0.035202656699412256,
            "auditor_fp_violation": 0.034578643430032634,
            "ave_precision_score": 0.5905288091971368,
            "fpr": 0.19538968166849616,
            "logloss": 6.095666384228778,
            "mae": 0.38621344856093576,
            "precision": 0.6329896907216495,
            "recall": 0.6476793248945147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6472607432300945,
            "auditor_fn_violation": 0.016109283625731004,
            "auditor_fp_violation": 0.0081932261208577,
            "ave_precision_score": 0.6469032556431055,
            "fpr": 0.0800438596491228,
            "logloss": 1.8366631437815493,
            "mae": 0.43623208328142793,
            "precision": 0.6741071428571429,
            "recall": 0.3145833333333333
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6808059181306155,
            "auditor_fn_violation": 0.010837999694312829,
            "auditor_fp_violation": 0.012458962037844096,
            "ave_precision_score": 0.6812243622596235,
            "fpr": 0.05817782656421515,
            "logloss": 1.8473374061056835,
            "mae": 0.43255755532424267,
            "precision": 0.6971428571428572,
            "recall": 0.25738396624472576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 10197,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.5355326601410535,
            "auditor_fn_violation": 0.05482456140350877,
            "auditor_fp_violation": 0.05974354288499026,
            "ave_precision_score": 0.5253698052322548,
            "fpr": 0.09320175438596491,
            "logloss": 5.650912715762389,
            "mae": 0.5352463952027686,
            "precision": 0.46875,
            "recall": 0.15625
        },
        "train": {
            "accuracy": 0.4544456641053787,
            "auc_prc": 0.5350556102997975,
            "auditor_fn_violation": 0.05764287401520099,
            "auditor_fp_violation": 0.074452345726149,
            "ave_precision_score": 0.5228118813380909,
            "fpr": 0.1141602634467618,
            "logloss": 6.023043816560181,
            "mae": 0.5447399458804881,
            "precision": 0.43783783783783786,
            "recall": 0.17088607594936708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7922369672923115,
            "auditor_fn_violation": 0.02182474415204679,
            "auditor_fp_violation": 0.02347303443794672,
            "ave_precision_score": 0.7915800714001329,
            "fpr": 0.12280701754385964,
            "logloss": 0.9221466560150253,
            "mae": 0.28383077764825215,
            "precision": 0.7591397849462366,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7930360297560958,
            "auditor_fn_violation": 0.03663614426581816,
            "auditor_fp_violation": 0.015832426960591,
            "ave_precision_score": 0.7910276261968927,
            "fpr": 0.09879253567508232,
            "logloss": 0.9397012935519777,
            "mae": 0.2783187494514164,
            "precision": 0.7906976744186046,
            "recall": 0.7172995780590717
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7489693381136208,
            "auditor_fn_violation": 0.04947916666666667,
            "auditor_fp_violation": 0.08890716374269006,
            "ave_precision_score": 0.750342449369755,
            "fpr": 0.2565789473684211,
            "logloss": 0.855266220143664,
            "mae": 0.36477548376301694,
            "precision": 0.629746835443038,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7604990660548362,
            "auditor_fn_violation": 0.0567605496811127,
            "auditor_fp_violation": 0.09594656712893772,
            "ave_precision_score": 0.7618802787660459,
            "fpr": 0.2261251372118551,
            "logloss": 0.7744324293266436,
            "mae": 0.3573168986106371,
            "precision": 0.6411149825783972,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7768804084511678,
            "auditor_fn_violation": 0.02010233918128655,
            "auditor_fp_violation": 0.011954800194931774,
            "ave_precision_score": 0.7762856501312898,
            "fpr": 0.1162280701754386,
            "logloss": 0.9694354082476042,
            "mae": 0.29318585004202463,
            "precision": 0.7644444444444445,
            "recall": 0.7166666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.788807520601086,
            "auditor_fn_violation": 0.03293084522502744,
            "auditor_fp_violation": 0.007957659624171394,
            "ave_precision_score": 0.7868089752879512,
            "fpr": 0.0845225027442371,
            "logloss": 0.9692851173617071,
            "mae": 0.2826659987030027,
            "precision": 0.8121951219512196,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7960441545374335,
            "auditor_fn_violation": 0.020010964912280705,
            "auditor_fp_violation": 0.02469389619883041,
            "ave_precision_score": 0.7953805354418156,
            "fpr": 0.12828947368421054,
            "logloss": 0.8944281726135576,
            "mae": 0.28039608542939165,
            "precision": 0.7547169811320755,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7976142412661014,
            "auditor_fn_violation": 0.03213883755505843,
            "auditor_fp_violation": 0.0172039175397569,
            "ave_precision_score": 0.7961958354601779,
            "fpr": 0.10976948408342481,
            "logloss": 0.904781991234543,
            "mae": 0.2759779846228277,
            "precision": 0.7752808988764045,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7506019071746604,
            "auditor_fn_violation": 0.01344800804093567,
            "auditor_fp_violation": 0.017467714424951274,
            "ave_precision_score": 0.7456885461640257,
            "fpr": 0.1513157894736842,
            "logloss": 1.7344927345280359,
            "mae": 0.2920357203038588,
            "precision": 0.7267326732673267,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7599455172096103,
            "auditor_fn_violation": 0.017456590105925242,
            "auditor_fp_violation": 0.017746485241404947,
            "ave_precision_score": 0.7545631773524875,
            "fpr": 0.14709110867178923,
            "logloss": 1.7882842256630798,
            "mae": 0.2745690447157451,
            "precision": 0.7330677290836654,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.8458703784319392,
            "auditor_fn_violation": 0.0058479532163742695,
            "auditor_fp_violation": 0.01759716130604288,
            "ave_precision_score": 0.8462343795778172,
            "fpr": 0.41776315789473684,
            "logloss": 1.0062044058137856,
            "mae": 0.39613136823958994,
            "precision": 0.5522914218566393,
            "recall": 0.9791666666666666
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.8626551538238951,
            "auditor_fn_violation": 0.007438387824387352,
            "auditor_fp_violation": 0.027346919295566284,
            "ave_precision_score": 0.8628670616698649,
            "fpr": 0.4226125137211855,
            "logloss": 0.9529916076005681,
            "mae": 0.39790128815906894,
            "precision": 0.5459905660377359,
            "recall": 0.9767932489451476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8439498922697042,
            "auditor_fn_violation": 0.01359649122807018,
            "auditor_fp_violation": 0.020988161955815467,
            "ave_precision_score": 0.844270436231041,
            "fpr": 0.1787280701754386,
            "logloss": 0.6575325382106408,
            "mae": 0.29828621172379044,
            "precision": 0.7020109689213894,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8576613789065056,
            "auditor_fn_violation": 0.01943429346894728,
            "auditor_fp_violation": 0.024387915811578294,
            "ave_precision_score": 0.8579028315839895,
            "fpr": 0.1668496158068057,
            "logloss": 0.6423376985555523,
            "mae": 0.28671432209508363,
            "precision": 0.7153558052434457,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7825904639070067,
            "auditor_fn_violation": 0.005523574561403513,
            "auditor_fp_violation": 0.02282326185834958,
            "ave_precision_score": 0.7781820579292199,
            "fpr": 0.14912280701754385,
            "logloss": 0.9798894438660175,
            "mae": 0.27891548011818185,
            "precision": 0.7429111531190926,
            "recall": 0.81875
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7722784262843516,
            "auditor_fn_violation": 0.014381191902068942,
            "auditor_fp_violation": 0.005116714853042024,
            "ave_precision_score": 0.7677277912875425,
            "fpr": 0.14270032930845225,
            "logloss": 1.0682946773247346,
            "mae": 0.2806052716207894,
            "precision": 0.7440944881889764,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 10197,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7768023795716077,
            "auditor_fn_violation": 0.008662280701754396,
            "auditor_fp_violation": 0.02378015350877193,
            "ave_precision_score": 0.7421535469716376,
            "fpr": 0.14802631578947367,
            "logloss": 4.192551793515851,
            "mae": 0.31405814379466523,
            "precision": 0.7133757961783439,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7882635188926119,
            "auditor_fn_violation": 0.014172768831024477,
            "auditor_fp_violation": 0.022501488293348273,
            "ave_precision_score": 0.7608883816403351,
            "fpr": 0.15477497255762898,
            "logloss": 3.8160036694962076,
            "mae": 0.30051520322675107,
            "precision": 0.7080745341614907,
            "recall": 0.7215189873417721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7702554592738973,
            "auditor_fn_violation": 0.014482821637426905,
            "auditor_fp_violation": 0.022554215399610136,
            "ave_precision_score": 0.7424873421555833,
            "fpr": 0.14144736842105263,
            "logloss": 4.00363851562718,
            "mae": 0.31208231509285056,
            "precision": 0.7164835164835165,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7861708810118664,
            "auditor_fn_violation": 0.016979532854423433,
            "auditor_fp_violation": 0.02095165370114065,
            "ave_precision_score": 0.7654024855482047,
            "fpr": 0.14709110867178923,
            "logloss": 3.5500715816814705,
            "mae": 0.29959594728974437,
            "precision": 0.7148936170212766,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 10197,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8428268485820174,
            "auditor_fn_violation": 0.010672514619883049,
            "auditor_fp_violation": 0.023079617446393766,
            "ave_precision_score": 0.8432211698862264,
            "fpr": 0.17214912280701755,
            "logloss": 1.0230077501234713,
            "mae": 0.2942766633426353,
            "precision": 0.7140255009107468,
            "recall": 0.8166666666666667
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8526825642820949,
            "auditor_fn_violation": 0.011796745821117423,
            "auditor_fp_violation": 0.03054455209277908,
            "ave_precision_score": 0.8529159547617723,
            "fpr": 0.1602634467618002,
            "logloss": 1.0010194199653977,
            "mae": 0.2801245381269118,
            "precision": 0.7276119402985075,
            "recall": 0.8227848101265823
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 10197,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.612981218457029,
            "auditor_fn_violation": 0.05893640350877194,
            "auditor_fp_violation": 0.02687164961013646,
            "ave_precision_score": 0.5583982730460813,
            "fpr": 0.20285087719298245,
            "logloss": 8.200363665249192,
            "mae": 0.45360154537571323,
            "precision": 0.5842696629213483,
            "recall": 0.5416666666666666
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.628694216626801,
            "auditor_fn_violation": 0.05011880115049536,
            "auditor_fp_violation": 0.034576131542525,
            "ave_precision_score": 0.5664169914176128,
            "fpr": 0.19758507135016465,
            "logloss": 7.9664336648817615,
            "mae": 0.4211637218135087,
            "precision": 0.6035242290748899,
            "recall": 0.5780590717299579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.772404531129711,
            "auditor_fn_violation": 0.014482821637426905,
            "auditor_fp_violation": 0.022554215399610136,
            "ave_precision_score": 0.7446877712210789,
            "fpr": 0.14144736842105263,
            "logloss": 3.752375249199971,
            "mae": 0.3123828531586837,
            "precision": 0.7164835164835165,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.785860341902872,
            "auditor_fn_violation": 0.016979532854423433,
            "auditor_fp_violation": 0.02027846784909585,
            "ave_precision_score": 0.7636670608318136,
            "fpr": 0.14709110867178923,
            "logloss": 3.4384014037116066,
            "mae": 0.29999065704746625,
            "precision": 0.7148936170212766,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7971372234167836,
            "auditor_fn_violation": 0.006058114035087722,
            "auditor_fp_violation": 0.0211480669265757,
            "ave_precision_score": 0.7972276466945225,
            "fpr": 0.17982456140350878,
            "logloss": 0.9372823971977956,
            "mae": 0.28151505950702277,
            "precision": 0.7071428571428572,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8444655985443422,
            "auditor_fn_violation": 0.00870513693395768,
            "auditor_fp_violation": 0.020833594988282047,
            "ave_precision_score": 0.8441131398870558,
            "fpr": 0.16794731064763996,
            "logloss": 0.8616159897840476,
            "mae": 0.26491003076755765,
            "precision": 0.7228260869565217,
            "recall": 0.8417721518987342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7246393639604973,
            "auditor_fn_violation": 0.02984512061403509,
            "auditor_fp_violation": 0.016680880441845368,
            "ave_precision_score": 0.7201332040926929,
            "fpr": 0.13925438596491227,
            "logloss": 1.608142958094573,
            "mae": 0.30939725140062335,
            "precision": 0.7309322033898306,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7256630520214327,
            "auditor_fn_violation": 0.02015219515810049,
            "auditor_fp_violation": 0.015463179496969414,
            "ave_precision_score": 0.7205128854144295,
            "fpr": 0.145993413830955,
            "logloss": 1.6902984630590125,
            "mae": 0.30200692445498606,
            "precision": 0.7246376811594203,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6919738812074105,
            "auditor_fn_violation": 0.06428179824561403,
            "auditor_fp_violation": 0.10280112897985705,
            "ave_precision_score": 0.692069749672522,
            "fpr": 0.24232456140350878,
            "logloss": 2.6337282478270776,
            "mae": 0.39751170328766955,
            "precision": 0.6102292768959435,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6842913864809246,
            "auditor_fn_violation": 0.06855034806652864,
            "auditor_fp_violation": 0.1134267922945339,
            "ave_precision_score": 0.6835219380612944,
            "fpr": 0.24698133918770582,
            "logloss": 2.7844353818651997,
            "mae": 0.41724955475455666,
            "precision": 0.5953237410071942,
            "recall": 0.6983122362869199
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8484371622330393,
            "auditor_fn_violation": 0.017836257309941525,
            "auditor_fp_violation": 0.01916829109811566,
            "ave_precision_score": 0.848959826222126,
            "fpr": 0.11951754385964912,
            "logloss": 0.6108287091655853,
            "mae": 0.28062138104819734,
            "precision": 0.7635574837310195,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.867748468368042,
            "auditor_fn_violation": 0.01898039433645042,
            "auditor_fp_violation": 0.02381018168482343,
            "ave_precision_score": 0.8679597791194443,
            "fpr": 0.10208562019758508,
            "logloss": 0.5600371445888346,
            "mae": 0.2667901154935184,
            "precision": 0.7919463087248322,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.5652374601668344,
            "auditor_fn_violation": 0.016447368421052634,
            "auditor_fp_violation": 0.024539067576348286,
            "ave_precision_score": 0.5460577611431701,
            "fpr": 0.25219298245614036,
            "logloss": 4.6307967231593015,
            "mae": 0.3875550324238153,
            "precision": 0.6254071661237784,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.6465422612513722,
            "auc_prc": 0.5477530830447296,
            "auditor_fn_violation": 0.02759521460628882,
            "auditor_fp_violation": 0.034076265928506655,
            "ave_precision_score": 0.5318700400587483,
            "fpr": 0.2305159165751921,
            "logloss": 5.171083201319939,
            "mae": 0.3922048301095243,
            "precision": 0.6328671328671329,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7608570047033447,
            "auditor_fn_violation": 0.009594298245614039,
            "auditor_fp_violation": 0.01949317738791424,
            "ave_precision_score": 0.7460624440834884,
            "fpr": 0.12280701754385964,
            "logloss": 3.6404476098454146,
            "mae": 0.32343673893447833,
            "precision": 0.7281553398058253,
            "recall": 0.625
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7765970562338371,
            "auditor_fn_violation": 0.011766640266411006,
            "auditor_fp_violation": 0.015370239659187105,
            "ave_precision_score": 0.7642721738858206,
            "fpr": 0.12294182217343579,
            "logloss": 3.280182725339039,
            "mae": 0.31047034043006483,
            "precision": 0.7288135593220338,
            "recall": 0.6350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8447621828623413,
            "auditor_fn_violation": 0.025575657894736845,
            "auditor_fp_violation": 0.01719359161793373,
            "ave_precision_score": 0.8450986548881045,
            "fpr": 0.09320175438596491,
            "logloss": 0.7214227052543054,
            "mae": 0.2897503502013901,
            "precision": 0.802784222737819,
            "recall": 0.7208333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.845961218856965,
            "auditor_fn_violation": 0.01921660715030084,
            "auditor_fp_violation": 0.01773894957888206,
            "ave_precision_score": 0.8462856218726196,
            "fpr": 0.08562019758507135,
            "logloss": 0.7747581890445401,
            "mae": 0.29188828050791726,
            "precision": 0.805,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7566938907064743,
            "auditor_fn_violation": 0.028531615497076026,
            "auditor_fp_violation": 0.016447368421052638,
            "ave_precision_score": 0.7587825050610608,
            "fpr": 0.12719298245614036,
            "logloss": 1.26491525732574,
            "mae": 0.3041749841045056,
            "precision": 0.7369614512471655,
            "recall": 0.6770833333333334
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7829240273903086,
            "auditor_fn_violation": 0.01378834405554244,
            "auditor_fp_violation": 0.015900247923297004,
            "ave_precision_score": 0.7836218968242608,
            "fpr": 0.12294182217343579,
            "logloss": 1.072075409649356,
            "mae": 0.28765038639639157,
            "precision": 0.7494407158836689,
            "recall": 0.7067510548523207
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6369547573577881,
            "auditor_fn_violation": 0.057223135964912276,
            "auditor_fp_violation": 0.024813190383365828,
            "ave_precision_score": 0.5959821875579013,
            "fpr": 0.20175438596491227,
            "logloss": 6.106619048483271,
            "mae": 0.40993283671929925,
            "precision": 0.6142557651991615,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6388495689428595,
            "auditor_fn_violation": 0.03594603231947088,
            "auditor_fp_violation": 0.03073796743086658,
            "ave_precision_score": 0.593461145486357,
            "fpr": 0.2052689352360044,
            "logloss": 6.1398339413601,
            "mae": 0.38542745973134773,
            "precision": 0.631163708086785,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8423668443877518,
            "auditor_fn_violation": 0.014322916666666666,
            "auditor_fp_violation": 0.015526011208577007,
            "ave_precision_score": 0.8435861768745875,
            "fpr": 0.12171052631578948,
            "logloss": 0.9551712649532557,
            "mae": 0.27909211095172354,
            "precision": 0.7638297872340426,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.869206976309793,
            "auditor_fn_violation": 0.014325612416457089,
            "auditor_fp_violation": 0.025380111377092087,
            "ave_precision_score": 0.869389699162765,
            "fpr": 0.10867178924259056,
            "logloss": 0.9174828075296654,
            "mae": 0.2612392266769538,
            "precision": 0.7852494577006508,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8094084575491005,
            "auditor_fn_violation": 0.01450566520467837,
            "auditor_fp_violation": 0.020848562378167648,
            "ave_precision_score": 0.8094866404217367,
            "fpr": 0.125,
            "logloss": 1.0139243175109183,
            "mae": 0.27688423309092314,
            "precision": 0.7644628099173554,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8432732704127577,
            "auditor_fn_violation": 0.023405910878294824,
            "auditor_fp_violation": 0.02489782897562716,
            "ave_precision_score": 0.8430023436611711,
            "fpr": 0.10976948408342481,
            "logloss": 1.0044674272690552,
            "mae": 0.2668813130940529,
            "precision": 0.7811816192560175,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7235278591734041,
            "auditor_fn_violation": 0.019257127192982455,
            "auditor_fp_violation": 0.020637893924626383,
            "ave_precision_score": 0.7192347836995662,
            "fpr": 0.21162280701754385,
            "logloss": 1.3360045299708647,
            "mae": 0.31251397972983125,
            "precision": 0.677257525083612,
            "recall": 0.84375
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7100935494326002,
            "auditor_fn_violation": 0.014932355134386566,
            "auditor_fp_violation": 0.023767479597193726,
            "ave_precision_score": 0.7052125132542844,
            "fpr": 0.20856201975850713,
            "logloss": 1.4163056400865799,
            "mae": 0.30503079530026245,
            "precision": 0.6812080536912751,
            "recall": 0.8565400843881856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7972473426102205,
            "auditor_fn_violation": 0.008479532163742693,
            "auditor_fp_violation": 0.017620004873294345,
            "ave_precision_score": 0.7973737942570098,
            "fpr": 0.17324561403508773,
            "logloss": 0.9150835929683893,
            "mae": 0.28211197819393474,
            "precision": 0.7137681159420289,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8441414370168909,
            "auditor_fn_violation": 0.01121316122219289,
            "auditor_fp_violation": 0.02133597248980802,
            "ave_precision_score": 0.8438101299472416,
            "fpr": 0.16575192096597147,
            "logloss": 0.8444447417075986,
            "mae": 0.26688118083267376,
            "precision": 0.7224264705882353,
            "recall": 0.8291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8496518148830653,
            "auditor_fn_violation": 0.017690058479532166,
            "auditor_fp_violation": 0.02585891812865498,
            "ave_precision_score": 0.8499122253815548,
            "fpr": 0.1875,
            "logloss": 0.6988247352868102,
            "mae": 0.2897308057720278,
            "precision": 0.7086882453151618,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8600024374140447,
            "auditor_fn_violation": 0.02176168442894395,
            "auditor_fp_violation": 0.027168575282524553,
            "ave_precision_score": 0.8604233275968104,
            "fpr": 0.17014270032930845,
            "logloss": 0.628624953511524,
            "mae": 0.27999825874678574,
            "precision": 0.725177304964539,
            "recall": 0.8628691983122363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7765827094868599,
            "auditor_fn_violation": 0.003001644736842105,
            "auditor_fp_violation": 0.01840176250812218,
            "ave_precision_score": 0.5764936785974216,
            "fpr": 0.3706140350877193,
            "logloss": 12.673488215704543,
            "mae": 0.3921636032484872,
            "precision": 0.5796019900497512,
            "recall": 0.9708333333333333
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7732178177913454,
            "auditor_fn_violation": 0.007503230557601191,
            "auditor_fp_violation": 0.02717359905753981,
            "ave_precision_score": 0.5828475500409791,
            "fpr": 0.35016465422612514,
            "logloss": 11.824823747577282,
            "mae": 0.38259366964594216,
            "precision": 0.5835509138381201,
            "recall": 0.9430379746835443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.73334135659643,
            "auditor_fn_violation": 0.02166255482456141,
            "auditor_fp_violation": 0.0209450129954516,
            "ave_precision_score": 0.7308378749935915,
            "fpr": 0.15899122807017543,
            "logloss": 1.8700474176401676,
            "mae": 0.3008748009702136,
            "precision": 0.7111553784860558,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7458990479751114,
            "auditor_fn_violation": 0.016910058497408613,
            "auditor_fp_violation": 0.019168213570723455,
            "ave_precision_score": 0.7418150852174776,
            "fpr": 0.15697036223929747,
            "logloss": 1.8665839034106972,
            "mae": 0.2786678701598773,
            "precision": 0.7223300970873786,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6830351938021513,
            "auditor_fn_violation": 0.006487573099415216,
            "auditor_fp_violation": 0.00791910331384016,
            "ave_precision_score": 0.6840288007025876,
            "fpr": 0.0756578947368421,
            "logloss": 1.3169939336356087,
            "mae": 0.40095059340505623,
            "precision": 0.73046875,
            "recall": 0.38958333333333334
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7107095489188889,
            "auditor_fn_violation": 0.02198168655949091,
            "auditor_fp_violation": 0.017319464365107874,
            "ave_precision_score": 0.7116920779146542,
            "fpr": 0.054884742041712405,
            "logloss": 1.3050752647222634,
            "mae": 0.40279678369225247,
            "precision": 0.7641509433962265,
            "recall": 0.34177215189873417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7662421303007094,
            "auditor_fn_violation": 0.011341831140350889,
            "auditor_fp_violation": 0.020787646198830417,
            "ave_precision_score": 0.738506048581498,
            "fpr": 0.12828947368421054,
            "logloss": 4.491164846281502,
            "mae": 0.32227989755669895,
            "precision": 0.7214285714285714,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.778816963877871,
            "auditor_fn_violation": 0.010055255271945795,
            "auditor_fp_violation": 0.015598821422381427,
            "ave_precision_score": 0.7560617355185799,
            "fpr": 0.12623490669593854,
            "logloss": 3.9991896671979763,
            "mae": 0.3090234264078734,
            "precision": 0.7300469483568075,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8305285090034373,
            "auditor_fn_violation": 0.011101973684210524,
            "auditor_fp_violation": 0.013569078947368425,
            "ave_precision_score": 0.8309552776144146,
            "fpr": 0.13815789473684212,
            "logloss": 0.759874487245418,
            "mae": 0.2791652570429479,
            "precision": 0.7439024390243902,
            "recall": 0.7625
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8609485777042628,
            "auditor_fn_violation": 0.017718276850681076,
            "auditor_fp_violation": 0.016874860276257394,
            "ave_precision_score": 0.8611195036476847,
            "fpr": 0.13062568605927552,
            "logloss": 0.6821855189662847,
            "mae": 0.2619986307473571,
            "precision": 0.7551440329218106,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6490790609097872,
            "auditor_fn_violation": 0.055788559941520495,
            "auditor_fp_violation": 0.04611862410656271,
            "ave_precision_score": 0.6504923009048635,
            "fpr": 0.11074561403508772,
            "logloss": 1.8140474200716479,
            "mae": 0.4053077733737905,
            "precision": 0.6833855799373041,
            "recall": 0.45416666666666666
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.64490931587419,
            "auditor_fn_violation": 0.05082512378014611,
            "auditor_fp_violation": 0.04728628233113208,
            "ave_precision_score": 0.6450784482080512,
            "fpr": 0.10318331503841932,
            "logloss": 2.2336751117115945,
            "mae": 0.4042500850195867,
            "precision": 0.6897689768976898,
            "recall": 0.4409282700421941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 10197,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.7490482182735265,
            "auditor_fn_violation": 0.0005825109649122896,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7501063037292603,
            "fpr": 0.0,
            "logloss": 6.694164303814783,
            "mae": 0.5247950577888943,
            "precision": 1.0,
            "recall": 0.00625
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.8168068765331107,
            "auditor_fn_violation": 0.0019105448179077204,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8177082459434171,
            "fpr": 0.0,
            "logloss": 6.8012030392762695,
            "mae": 0.5178907516021111,
            "precision": 1.0,
            "recall": 0.006329113924050633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7889601460080138,
            "auditor_fn_violation": 0.016502192982456143,
            "auditor_fp_violation": 0.02515838206627681,
            "ave_precision_score": 0.784544862821742,
            "fpr": 0.14473684210526316,
            "logloss": 0.9908752564199237,
            "mae": 0.2731170000742858,
            "precision": 0.7490494296577946,
            "recall": 0.8208333333333333
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7717642087877465,
            "auditor_fn_violation": 0.03229168114049105,
            "auditor_fp_violation": 0.026329604854976173,
            "ave_precision_score": 0.76735407666264,
            "fpr": 0.14050493962678376,
            "logloss": 1.0832127853128741,
            "mae": 0.275598699768595,
            "precision": 0.744,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7787674052790715,
            "auditor_fn_violation": 0.010738760964912287,
            "auditor_fp_violation": 0.025912219785575053,
            "ave_precision_score": 0.7395623871976866,
            "fpr": 0.15679824561403508,
            "logloss": 4.424154378239474,
            "mae": 0.31295087800534455,
            "precision": 0.7033195020746889,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7914837543988228,
            "auditor_fn_violation": 0.020355986605343965,
            "auditor_fp_violation": 0.02264717776879081,
            "ave_precision_score": 0.7612913535643862,
            "fpr": 0.16136114160263446,
            "logloss": 4.006108272641721,
            "mae": 0.30211620524633354,
            "precision": 0.6993865030674846,
            "recall": 0.7215189873417721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7739332008665063,
            "auditor_fn_violation": 0.012646198830409357,
            "auditor_fp_violation": 0.019168291098115665,
            "ave_precision_score": 0.7712349834636558,
            "fpr": 0.14035087719298245,
            "logloss": 1.3229981449952388,
            "mae": 0.28519292604173224,
            "precision": 0.7419354838709677,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7774918415604051,
            "auditor_fn_violation": 0.012644332976698303,
            "auditor_fp_violation": 0.021393745902483507,
            "ave_precision_score": 0.7732220577167852,
            "fpr": 0.12294182217343579,
            "logloss": 1.3298878463868722,
            "mae": 0.27375440391863703,
            "precision": 0.768595041322314,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7026118256724307,
            "auditor_fn_violation": 0.03991228070175439,
            "auditor_fp_violation": 0.042884990253411324,
            "ave_precision_score": 0.687577927209241,
            "fpr": 0.21052631578947367,
            "logloss": 3.0134921373702794,
            "mae": 0.3217442915467395,
            "precision": 0.6666666666666666,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6740157338242445,
            "auditor_fn_violation": 0.05186955494726897,
            "auditor_fp_violation": 0.04037607979764234,
            "ave_precision_score": 0.6551492254799278,
            "fpr": 0.20856201975850713,
            "logloss": 3.662335902703939,
            "mae": 0.3288219362721537,
            "precision": 0.6631205673758865,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7070389129497381,
            "auditor_fn_violation": 0.06476151315789473,
            "auditor_fp_violation": 0.10488243177387914,
            "ave_precision_score": 0.7066362076738474,
            "fpr": 0.24013157894736842,
            "logloss": 2.406841624138604,
            "mae": 0.39834561494001064,
            "precision": 0.6117021276595744,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6970986632510209,
            "auditor_fn_violation": 0.07334407870055162,
            "auditor_fp_violation": 0.1134267922945339,
            "ave_precision_score": 0.6969673380649577,
            "fpr": 0.24698133918770582,
            "logloss": 2.600494997414896,
            "mae": 0.4276956660034495,
            "precision": 0.5879120879120879,
            "recall": 0.6772151898734177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.6190844592669436,
            "auditor_fn_violation": 0.057360197368421066,
            "auditor_fp_violation": 0.02147295321637427,
            "ave_precision_score": 0.5862867238582244,
            "fpr": 0.19407894736842105,
            "logloss": 5.842610298520797,
            "mae": 0.41005130370042864,
            "precision": 0.6217948717948718,
            "recall": 0.60625
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6252003030207041,
            "auditor_fn_violation": 0.036918673317678445,
            "auditor_fp_violation": 0.03508855659408149,
            "ave_precision_score": 0.5853784897939047,
            "fpr": 0.19319429198682767,
            "logloss": 5.951802825697653,
            "mae": 0.3877750064390665,
            "precision": 0.6348547717842323,
            "recall": 0.6455696202531646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6473975774495215,
            "auditor_fn_violation": 0.016310307017543872,
            "auditor_fp_violation": 0.0081932261208577,
            "ave_precision_score": 0.647040320790615,
            "fpr": 0.0800438596491228,
            "logloss": 1.8336062974021863,
            "mae": 0.43571936543849565,
            "precision": 0.672645739910314,
            "recall": 0.3125
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6809287079217282,
            "auditor_fn_violation": 0.011268740707804752,
            "auditor_fp_violation": 0.012458962037844096,
            "ave_precision_score": 0.681347115536207,
            "fpr": 0.05817782656421515,
            "logloss": 1.8446479583852975,
            "mae": 0.4321498112739171,
            "precision": 0.6988636363636364,
            "recall": 0.25949367088607594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7765026164597952,
            "auditor_fn_violation": 0.011947185672514625,
            "auditor_fp_violation": 0.022950170565302148,
            "ave_precision_score": 0.772852503126692,
            "fpr": 0.14144736842105263,
            "logloss": 1.3121272879732993,
            "mae": 0.28283890534003736,
            "precision": 0.7435387673956262,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7749570176277861,
            "auditor_fn_violation": 0.013042652623583307,
            "auditor_fp_violation": 0.0166312071880173,
            "ave_precision_score": 0.7706955239021545,
            "fpr": 0.12733260153677278,
            "logloss": 1.3447674729696137,
            "mae": 0.2730954013949896,
            "precision": 0.7642276422764228,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 10197,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8058596960337452,
            "auditor_fn_violation": 0.015796326754385963,
            "auditor_fp_violation": 0.026726973684210533,
            "ave_precision_score": 0.8071178529995973,
            "fpr": 0.13486842105263158,
            "logloss": 0.7206317865476344,
            "mae": 0.2805972153019902,
            "precision": 0.7530120481927711,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8114642324651065,
            "auditor_fn_violation": 0.03127735552807459,
            "auditor_fp_violation": 0.02553333651505752,
            "ave_precision_score": 0.8127328949663203,
            "fpr": 0.1251372118551043,
            "logloss": 0.719943532200406,
            "mae": 0.27463622727754966,
            "precision": 0.7579617834394905,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8279624683294675,
            "auditor_fn_violation": 0.013432017543859658,
            "auditor_fp_violation": 0.01575698505523067,
            "ave_precision_score": 0.8284864349671313,
            "fpr": 0.14035087719298245,
            "logloss": 1.0812963462146619,
            "mae": 0.2804162695428859,
            "precision": 0.7429718875502008,
            "recall": 0.7708333333333334
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8610388474778827,
            "auditor_fn_violation": 0.015256568800455757,
            "auditor_fp_violation": 0.019615329547081565,
            "ave_precision_score": 0.8612114726844425,
            "fpr": 0.132821075740944,
            "logloss": 1.0520498384391144,
            "mae": 0.2607655989716109,
            "precision": 0.7545638945233266,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7844065837756002,
            "auditor_fn_violation": 0.007700566520467842,
            "auditor_fp_violation": 0.02296539961013646,
            "ave_precision_score": 0.7799958932148732,
            "fpr": 0.14473684210526316,
            "logloss": 0.9728426212560223,
            "mae": 0.27817560479809145,
            "precision": 0.7476099426386233,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.774832390101338,
            "auditor_fn_violation": 0.011861588554331264,
            "auditor_fp_violation": 0.006254599893998355,
            "ave_precision_score": 0.7702784006359403,
            "fpr": 0.13391877058177826,
            "logloss": 1.0623434084395926,
            "mae": 0.27946802517059915,
            "precision": 0.7540322580645161,
            "recall": 0.7890295358649789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.781367739262759,
            "auditor_fn_violation": 0.017543859649122803,
            "auditor_fp_violation": 0.024285250162443147,
            "ave_precision_score": 0.7807494164496418,
            "fpr": 0.14912280701754385,
            "logloss": 1.0364920645550417,
            "mae": 0.2769433484932642,
            "precision": 0.7338551859099804,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.796556546176787,
            "auditor_fn_violation": 0.02974891967374842,
            "auditor_fp_violation": 0.024274880873734955,
            "ave_precision_score": 0.7951109175075455,
            "fpr": 0.1394072447859495,
            "logloss": 1.0082972023591303,
            "mae": 0.26525862261824323,
            "precision": 0.7449799196787149,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7716946214524856,
            "auditor_fn_violation": 0.014482821637426905,
            "auditor_fp_violation": 0.022554215399610136,
            "ave_precision_score": 0.7470543825811636,
            "fpr": 0.14144736842105263,
            "logloss": 3.5877912325944536,
            "mae": 0.31164501127187266,
            "precision": 0.7164835164835165,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7864427465892476,
            "auditor_fn_violation": 0.016979532854423433,
            "auditor_fp_violation": 0.021137533376705257,
            "ave_precision_score": 0.767391366104011,
            "fpr": 0.14818880351262348,
            "logloss": 3.2795123323799142,
            "mae": 0.2993920119977565,
            "precision": 0.7133757961783439,
            "recall": 0.7088607594936709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.617753546569321,
            "auditor_fn_violation": 0.05489309210526316,
            "auditor_fp_violation": 0.024006051007147505,
            "ave_precision_score": 0.5858974223474842,
            "fpr": 0.18969298245614036,
            "logloss": 5.754477803309132,
            "mae": 0.40439497980925726,
            "precision": 0.6303418803418803,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.6229866135551214,
            "auditor_fn_violation": 0.03664077588961915,
            "auditor_fp_violation": 0.0347695468806125,
            "ave_precision_score": 0.5847430315730089,
            "fpr": 0.19758507135016465,
            "logloss": 5.87273904109684,
            "mae": 0.38535956109910097,
            "precision": 0.6326530612244898,
            "recall": 0.6540084388185654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6055957497483007,
            "auditor_fn_violation": 0.054550438596491224,
            "auditor_fp_violation": 0.015404178849902535,
            "ave_precision_score": 0.5807970272628935,
            "fpr": 0.17214912280701755,
            "logloss": 4.671147391165405,
            "mae": 0.4121855939653822,
            "precision": 0.6374133949191686,
            "recall": 0.575
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6056060160557633,
            "auditor_fn_violation": 0.042282093679223,
            "auditor_fp_violation": 0.032478705473654064,
            "ave_precision_score": 0.5735051294260523,
            "fpr": 0.17453347969264543,
            "logloss": 5.102036156291391,
            "mae": 0.39670665185023396,
            "precision": 0.647450110864745,
            "recall": 0.6160337552742616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7821691580501385,
            "auditor_fn_violation": 0.008468110380116963,
            "auditor_fp_violation": 0.024092348927875252,
            "ave_precision_score": 0.7777619473466899,
            "fpr": 0.14473684210526316,
            "logloss": 0.9782431342681575,
            "mae": 0.27934449529330824,
            "precision": 0.746641074856046,
            "recall": 0.8104166666666667
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7724046791764387,
            "auditor_fn_violation": 0.013672553460517727,
            "auditor_fp_violation": 0.006797167595646404,
            "ave_precision_score": 0.7678535395454424,
            "fpr": 0.1394072447859495,
            "logloss": 1.0681209503932692,
            "mae": 0.2814200000540209,
            "precision": 0.7454909819639278,
            "recall": 0.7848101265822784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8497309937265707,
            "auditor_fn_violation": 0.020518092105263157,
            "auditor_fp_violation": 0.02044753086419753,
            "ave_precision_score": 0.850180325738924,
            "fpr": 0.10307017543859649,
            "logloss": 0.6136035461984508,
            "mae": 0.27425910132925124,
            "precision": 0.7887640449438202,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8614369780848828,
            "auditor_fn_violation": 0.03029081965846406,
            "auditor_fp_violation": 0.021634887103215976,
            "ave_precision_score": 0.8616645510871048,
            "fpr": 0.0867178924259056,
            "logloss": 0.5823885827955861,
            "mae": 0.2710185866520779,
            "precision": 0.808252427184466,
            "recall": 0.7025316455696202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6543710777587003,
            "auditor_fn_violation": 0.00870339912280702,
            "auditor_fp_violation": 0.006868299220272905,
            "ave_precision_score": 0.6540127827846945,
            "fpr": 0.08552631578947369,
            "logloss": 1.5663555955123418,
            "mae": 0.40576072119169776,
            "precision": 0.7089552238805971,
            "recall": 0.3958333333333333
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6863894833634867,
            "auditor_fn_violation": 0.02491350442551656,
            "auditor_fp_violation": 0.013732489004212436,
            "ave_precision_score": 0.6868044669246447,
            "fpr": 0.059275521405049394,
            "logloss": 1.5744548631821942,
            "mae": 0.40289787616482137,
            "precision": 0.7534246575342466,
            "recall": 0.34810126582278483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.636248966445172,
            "auditor_fn_violation": 0.057223135964912276,
            "auditor_fp_violation": 0.026772660818713455,
            "ave_precision_score": 0.5954318140543182,
            "fpr": 0.20065789473684212,
            "logloss": 6.108576377264851,
            "mae": 0.4099263798678168,
            "precision": 0.615546218487395,
            "recall": 0.6104166666666667
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6388581407611051,
            "auditor_fn_violation": 0.03594603231947088,
            "auditor_fp_violation": 0.03073796743086658,
            "ave_precision_score": 0.5934726145122606,
            "fpr": 0.2052689352360044,
            "logloss": 6.140950658155478,
            "mae": 0.38547314768246643,
            "precision": 0.631163708086785,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8462509849500861,
            "auditor_fn_violation": 0.0002330043859649149,
            "auditor_fp_violation": 0.028031595191682912,
            "ave_precision_score": 0.8465445096657087,
            "fpr": 0.22916666666666666,
            "logloss": 0.7604347610269654,
            "mae": 0.2984992118027437,
            "precision": 0.6784615384615384,
            "recall": 0.91875
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8706827180841794,
            "auditor_fn_violation": 0.010492943721139195,
            "auditor_fp_violation": 0.024413034686654605,
            "ave_precision_score": 0.8708662643481944,
            "fpr": 0.21295279912184412,
            "logloss": 0.6721758788687187,
            "mae": 0.2875555486205667,
            "precision": 0.6925515055467512,
            "recall": 0.9219409282700421
        }
    }
]