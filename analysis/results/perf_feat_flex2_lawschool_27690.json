[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8523277231740835,
            "auditor_fn_violation": 0.005708679593721146,
            "auditor_fp_violation": 0.020527219077441896,
            "ave_precision_score": 0.8526055478412448,
            "fpr": 0.12828947368421054,
            "logloss": 0.6197441484396383,
            "mae": 0.26358344114348764,
            "precision": 0.7612244897959184,
            "recall": 0.7852631578947369
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8500218172414371,
            "auditor_fn_violation": 0.0168229182182969,
            "auditor_fp_violation": 0.016800829369435298,
            "ave_precision_score": 0.8503108898369154,
            "fpr": 0.1251372118551043,
            "logloss": 0.6531477069879875,
            "mae": 0.26353920192421393,
            "precision": 0.7668711656441718,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.829356822441897,
            "auditor_fn_violation": 0.003460295475530933,
            "auditor_fp_violation": 0.02111435625677467,
            "ave_precision_score": 0.8296728911161242,
            "fpr": 0.1425438596491228,
            "logloss": 0.7921241250809485,
            "mae": 0.2745045897873027,
            "precision": 0.7389558232931727,
            "recall": 0.7747368421052632
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8196356341364355,
            "auditor_fn_violation": 0.01384378817010374,
            "auditor_fp_violation": 0.020985790950115872,
            "ave_precision_score": 0.8200468039480306,
            "fpr": 0.1350164654226125,
            "logloss": 0.8432147095347955,
            "mae": 0.27640589835964174,
            "precision": 0.75,
            "recall": 0.7703549060542797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8719005635667536,
            "auditor_fn_violation": 0.004843028624192068,
            "auditor_fp_violation": 0.014904251475370351,
            "ave_precision_score": 0.8717111439785131,
            "fpr": 0.08991228070175439,
            "logloss": 0.8622778675334045,
            "mae": 0.2245514420485242,
            "precision": 0.8169642857142857,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8712740421060359,
            "auditor_fn_violation": 0.014959816118926874,
            "auditor_fp_violation": 0.01230332967435053,
            "ave_precision_score": 0.8714387221878623,
            "fpr": 0.09879253567508232,
            "logloss": 0.9400323798203332,
            "mae": 0.23008693443725423,
            "precision": 0.8064516129032258,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.836816204646053,
            "auditor_fn_violation": 0.0032686980609418345,
            "auditor_fp_violation": 0.0195762575775824,
            "ave_precision_score": 0.8371311566047596,
            "fpr": 0.13267543859649122,
            "logloss": 0.7131491393164069,
            "mae": 0.2699614275307846,
            "precision": 0.753061224489796,
            "recall": 0.7768421052631579
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8341679891025655,
            "auditor_fn_violation": 0.015830638748398723,
            "auditor_fp_violation": 0.019816949221449776,
            "ave_precision_score": 0.8345096387218217,
            "fpr": 0.12403951701427003,
            "logloss": 0.744341453407644,
            "mae": 0.27106737487074156,
            "precision": 0.7650727650727651,
            "recall": 0.7682672233820459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8489817936234357,
            "auditor_fn_violation": 0.005447830101569714,
            "auditor_fp_violation": 0.01724276365972139,
            "ave_precision_score": 0.8493476110881482,
            "fpr": 0.12938596491228072,
            "logloss": 0.6335204470319006,
            "mae": 0.26653564535026636,
            "precision": 0.7581967213114754,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8434945330282215,
            "auditor_fn_violation": 0.016816043302801075,
            "auditor_fp_violation": 0.01905720209781681,
            "ave_precision_score": 0.8437927047217468,
            "fpr": 0.12403951701427003,
            "logloss": 0.6752655209204816,
            "mae": 0.26937820214296826,
            "precision": 0.7684426229508197,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8359641338857083,
            "auditor_fn_violation": 0.008578024007386888,
            "auditor_fp_violation": 0.022687582801397092,
            "ave_precision_score": 0.8362973275142891,
            "fpr": 0.14912280701754385,
            "logloss": 0.7692231179507433,
            "mae": 0.26909696123083926,
            "precision": 0.7359223300970874,
            "recall": 0.7978947368421052
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8293395312003089,
            "auditor_fn_violation": 0.02075766152041048,
            "auditor_fp_violation": 0.025117392364922553,
            "ave_precision_score": 0.8297205688155285,
            "fpr": 0.145993413830955,
            "logloss": 0.8171307859143205,
            "mae": 0.26678612732846846,
            "precision": 0.7432432432432432,
            "recall": 0.8037578288100209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.842824163453707,
            "auditor_fn_violation": 0.006096491228070174,
            "auditor_fp_violation": 0.018557549480107592,
            "ave_precision_score": 0.8431631796038122,
            "fpr": 0.13157894736842105,
            "logloss": 0.6628350322811423,
            "mae": 0.2702197381643295,
            "precision": 0.7556008146639511,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8383170366772208,
            "auditor_fn_violation": 0.020462040154089776,
            "auditor_fp_violation": 0.020536040980607396,
            "ave_precision_score": 0.8386294021642003,
            "fpr": 0.12623490669593854,
            "logloss": 0.7039917511217206,
            "mae": 0.2716715040012323,
            "precision": 0.7619047619047619,
            "recall": 0.7682672233820459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8458774421105106,
            "auditor_fn_violation": 0.0051038781163434965,
            "auditor_fp_violation": 0.013800232847565139,
            "ave_precision_score": 0.8466526228745441,
            "fpr": 0.1118421052631579,
            "logloss": 0.6241192258591446,
            "mae": 0.26896103972466395,
            "precision": 0.7801724137931034,
            "recall": 0.7621052631578947
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.847140647936422,
            "auditor_fn_violation": 0.013280045099445659,
            "auditor_fp_violation": 0.01330700898483555,
            "ave_precision_score": 0.8473974445803955,
            "fpr": 0.11306256860592755,
            "logloss": 0.6558699419402046,
            "mae": 0.274524961921165,
            "precision": 0.7760869565217391,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 27690,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7757898149086523,
            "auditor_fn_violation": 0.007010618651892892,
            "auditor_fp_violation": 0.022414087277690804,
            "ave_precision_score": 0.7764707383794258,
            "fpr": 0.1611842105263158,
            "logloss": 0.7924366674566667,
            "mae": 0.28792056762737056,
            "precision": 0.7252336448598131,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7758872618396748,
            "auditor_fn_violation": 0.016327924302597115,
            "auditor_fp_violation": 0.01530674472496647,
            "ave_precision_score": 0.7763824690910183,
            "fpr": 0.16136114160263446,
            "logloss": 0.8511316602118751,
            "mae": 0.2871853279066162,
            "precision": 0.7252336448598131,
            "recall": 0.8100208768267223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8296405700401178,
            "auditor_fn_violation": 0.0074953831948291775,
            "auditor_fp_violation": 0.02140290657995102,
            "ave_precision_score": 0.8300216679610654,
            "fpr": 0.14035087719298245,
            "logloss": 0.7073695241343493,
            "mae": 0.27515921652873065,
            "precision": 0.744,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8250597061999908,
            "auditor_fn_violation": 0.019348303843765256,
            "auditor_fp_violation": 0.021745538073748835,
            "ave_precision_score": 0.825403432890974,
            "fpr": 0.12952799121844127,
            "logloss": 0.7395217537664591,
            "mae": 0.2762110186778129,
            "precision": 0.757700205338809,
            "recall": 0.7703549060542797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8338632783754301,
            "auditor_fn_violation": 0.003391043397968611,
            "auditor_fp_violation": 0.02143803444538119,
            "ave_precision_score": 0.8342393443815578,
            "fpr": 0.13925438596491227,
            "logloss": 0.7287509661164596,
            "mae": 0.2717882071386594,
            "precision": 0.7449799196787149,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8331562935646872,
            "auditor_fn_violation": 0.016398965096054027,
            "auditor_fp_violation": 0.02254339960157743,
            "ave_precision_score": 0.8335145696777394,
            "fpr": 0.12952799121844127,
            "logloss": 0.7627208271685688,
            "mae": 0.2701663250466319,
            "precision": 0.7601626016260162,
            "recall": 0.7807933194154488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8431217088503014,
            "auditor_fn_violation": 0.003725761772853186,
            "auditor_fp_violation": 0.024408848207475214,
            "ave_precision_score": 0.843397953371992,
            "fpr": 0.16666666666666666,
            "logloss": 0.7210016530104467,
            "mae": 0.27015026638605805,
            "precision": 0.7185185185185186,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8296726181210634,
            "auditor_fn_violation": 0.014618361982633967,
            "auditor_fp_violation": 0.018792942228727082,
            "ave_precision_score": 0.8300537527234957,
            "fpr": 0.16245883644346873,
            "logloss": 0.780746806084124,
            "mae": 0.26956467557706126,
            "precision": 0.725925925925926,
            "recall": 0.8183716075156576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8287499399200526,
            "auditor_fn_violation": 0.006830563250230843,
            "auditor_fp_violation": 0.03442028985507247,
            "ave_precision_score": 0.8295839178514048,
            "fpr": 0.14583333333333334,
            "logloss": 0.5108817674942634,
            "mae": 0.31390514391936003,
            "precision": 0.7476280834914611,
            "recall": 0.8294736842105264
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8348734435235546,
            "auditor_fn_violation": 0.00428994726939815,
            "auditor_fp_violation": 0.023132902386469895,
            "ave_precision_score": 0.8352598146532162,
            "fpr": 0.14270032930845225,
            "logloss": 0.5073177386239366,
            "mae": 0.3146411116448621,
            "precision": 0.752851711026616,
            "recall": 0.826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8292635679367959,
            "auditor_fn_violation": 0.0074953831948291775,
            "auditor_fp_violation": 0.02009062989280983,
            "ave_precision_score": 0.8296457118737937,
            "fpr": 0.14144736842105263,
            "logloss": 0.7091846410373971,
            "mae": 0.27520735329832796,
            "precision": 0.7425149700598802,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8247732344774191,
            "auditor_fn_violation": 0.019841006120966433,
            "auditor_fp_violation": 0.02124496889864618,
            "ave_precision_score": 0.8251175557418167,
            "fpr": 0.12843029637760703,
            "logloss": 0.7409453977951759,
            "mae": 0.276156187534569,
            "precision": 0.7597535934291582,
            "recall": 0.7724425887265136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8388994224683012,
            "auditor_fn_violation": 0.004536011080332411,
            "auditor_fp_violation": 0.0195762575775824,
            "ave_precision_score": 0.8392036496190568,
            "fpr": 0.13267543859649122,
            "logloss": 0.6922087959760517,
            "mae": 0.26988390086057823,
            "precision": 0.7545638945233266,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.836260275242314,
            "auditor_fn_violation": 0.016398965096054027,
            "auditor_fp_violation": 0.018637943651664848,
            "ave_precision_score": 0.8366023830611251,
            "fpr": 0.12843029637760703,
            "logloss": 0.7205200136193857,
            "mae": 0.2695393552679001,
            "precision": 0.7617107942973523,
            "recall": 0.7807933194154488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8727586721806342,
            "auditor_fn_violation": 0.010175438596491237,
            "auditor_fp_violation": 0.009148299811313182,
            "ave_precision_score": 0.8730838955580661,
            "fpr": 0.08991228070175439,
            "logloss": 0.5877664417584729,
            "mae": 0.23721923803426356,
            "precision": 0.8148984198645598,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8673133321826481,
            "auditor_fn_violation": 0.001984558939796364,
            "auditor_fp_violation": 9.909745090865021e-05,
            "ave_precision_score": 0.8675231506045669,
            "fpr": 0.09549945115257959,
            "logloss": 0.622851520761798,
            "mae": 0.2434707936820986,
            "precision": 0.8083700440528634,
            "recall": 0.7661795407098121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.841221951250531,
            "auditor_fn_violation": 0.00797322253000924,
            "auditor_fp_violation": 0.01603587056887069,
            "ave_precision_score": 0.841565787947294,
            "fpr": 0.11074561403508772,
            "logloss": 0.6302628470167309,
            "mae": 0.2719547479753256,
            "precision": 0.7794759825327511,
            "recall": 0.751578947368421
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8393490706680193,
            "auditor_fn_violation": 0.014350240278296579,
            "auditor_fp_violation": 0.012806439809732903,
            "ave_precision_score": 0.8397766244954914,
            "fpr": 0.1141602634467618,
            "logloss": 0.6604784333269995,
            "mae": 0.27408114341418066,
            "precision": 0.7734204793028322,
            "recall": 0.7411273486430062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8508923753693485,
            "auditor_fn_violation": 0.007590027700831028,
            "auditor_fp_violation": 0.012741378618170145,
            "ave_precision_score": 0.8514281779556445,
            "fpr": 0.09758771929824561,
            "logloss": 0.6219044369580762,
            "mae": 0.27629481580238435,
            "precision": 0.7939814814814815,
            "recall": 0.7221052631578947
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8564489808217258,
            "auditor_fn_violation": 0.013928578794552319,
            "auditor_fp_violation": 0.015543054030979386,
            "ave_precision_score": 0.85668369558878,
            "fpr": 0.09110867178924259,
            "logloss": 0.6517917609429656,
            "mae": 0.27679490474790763,
            "precision": 0.8069767441860465,
            "recall": 0.7244258872651357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7957676018796361,
            "auditor_fn_violation": 0.004272853185595571,
            "auditor_fp_violation": 0.027823778553936335,
            "ave_precision_score": 0.796608690514884,
            "fpr": 0.19078947368421054,
            "logloss": 1.191863084975547,
            "mae": 0.2998273785960019,
            "precision": 0.6892857142857143,
            "recall": 0.8126315789473684
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.805010172876288,
            "auditor_fn_violation": 0.013669623644209376,
            "auditor_fp_violation": 0.02288897019961784,
            "ave_precision_score": 0.8053380214097258,
            "fpr": 0.1800219538968167,
            "logloss": 1.15739603938403,
            "mae": 0.2871225083418649,
            "precision": 0.7071428571428572,
            "recall": 0.826722338204593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8629647247945771,
            "auditor_fn_violation": 0.00618882733148661,
            "auditor_fp_violation": 0.010987494479906866,
            "ave_precision_score": 0.8549807879835502,
            "fpr": 0.09978070175438597,
            "logloss": 2.005732824952152,
            "mae": 0.23312385770835048,
            "precision": 0.7941176470588235,
            "recall": 0.7389473684210527
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8518372723920481,
            "auditor_fn_violation": 0.004411404109824484,
            "auditor_fp_violation": 0.004314550554945724,
            "ave_precision_score": 0.8413174665885971,
            "fpr": 0.09549945115257959,
            "logloss": 2.189612706712212,
            "mae": 0.2390323850243186,
            "precision": 0.8018223234624146,
            "recall": 0.7348643006263048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8448810503739945,
            "auditor_fn_violation": 0.0058541089566020305,
            "auditor_fp_violation": 0.02455186880244089,
            "ave_precision_score": 0.8452356768903548,
            "fpr": 0.14583333333333334,
            "logloss": 0.6593737111725468,
            "mae": 0.268057947054776,
            "precision": 0.7392156862745098,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8435034950594447,
            "auditor_fn_violation": 0.018271233749418497,
            "auditor_fp_violation": 0.020683416676830504,
            "ave_precision_score": 0.8438262678881177,
            "fpr": 0.13611416026344675,
            "logloss": 0.6933387208302813,
            "mae": 0.2663579174032269,
            "precision": 0.7568627450980392,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8799046436164579,
            "auditor_fn_violation": 0.013504155124653748,
            "auditor_fp_violation": 0.01098498534666185,
            "ave_precision_score": 0.8801258245896676,
            "fpr": 0.08223684210526316,
            "logloss": 0.45763079476339913,
            "mae": 0.2944587006436849,
            "precision": 0.8231132075471698,
            "recall": 0.7347368421052631
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8651101385795585,
            "auditor_fn_violation": 0.012647552873829264,
            "auditor_fp_violation": 0.011769728015611661,
            "ave_precision_score": 0.8653642303215354,
            "fpr": 0.09220636663007684,
            "logloss": 0.4817410905829896,
            "mae": 0.30512765287748783,
            "precision": 0.8090909090909091,
            "recall": 0.7432150313152401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8881833118375602,
            "auditor_fn_violation": 0.009145891043397974,
            "auditor_fp_violation": 0.01071148982295556,
            "ave_precision_score": 0.886904987750701,
            "fpr": 0.08552631578947369,
            "logloss": 1.011747172541654,
            "mae": 0.20990009520891745,
            "precision": 0.8227272727272728,
            "recall": 0.7621052631578947
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.872769233257786,
            "auditor_fn_violation": 0.0037972449921969726,
            "auditor_fp_violation": 0.00672338090010977,
            "ave_precision_score": 0.8718195754845495,
            "fpr": 0.0889132821075741,
            "logloss": 1.1765686920278071,
            "mae": 0.21888589834659325,
            "precision": 0.8187919463087249,
            "recall": 0.7640918580375783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8447080633076245,
            "auditor_fn_violation": 0.0031879039704524477,
            "auditor_fp_violation": 0.016505078485687913,
            "ave_precision_score": 0.845045033786145,
            "fpr": 0.12609649122807018,
            "logloss": 0.647920313447692,
            "mae": 0.2691538481357463,
            "precision": 0.760914760914761,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8407509636960127,
            "auditor_fn_violation": 0.018422481890326765,
            "auditor_fp_violation": 0.01767237874537545,
            "ave_precision_score": 0.84106354191736,
            "fpr": 0.12403951701427003,
            "logloss": 0.6878222515439616,
            "mae": 0.27143475785426396,
            "precision": 0.7635983263598326,
            "recall": 0.7620041753653445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 27690,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8404976816168674,
            "auditor_fn_violation": 0.0147876269621422,
            "auditor_fp_violation": 0.022755329399012408,
            "ave_precision_score": 0.8408400136424895,
            "fpr": 0.14802631578947367,
            "logloss": 0.6176063723456308,
            "mae": 0.2758499712804074,
            "precision": 0.735812133072407,
            "recall": 0.791578947368421
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8393801419318003,
            "auditor_fn_violation": 0.02310200770448864,
            "auditor_fp_violation": 0.020185388462007566,
            "ave_precision_score": 0.8396304608143189,
            "fpr": 0.13172338090010977,
            "logloss": 0.6466105044808013,
            "mae": 0.276226808429202,
            "precision": 0.7560975609756098,
            "recall": 0.7766179540709812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8647779225154939,
            "auditor_fn_violation": 0.006546629732225308,
            "auditor_fp_violation": 0.023952185956883067,
            "ave_precision_score": 0.8650359269026213,
            "fpr": 0.13596491228070176,
            "logloss": 0.5346093827886308,
            "mae": 0.26217279095602697,
            "precision": 0.7582846003898636,
            "recall": 0.8189473684210526
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.858423172528293,
            "auditor_fn_violation": 0.017661657908788205,
            "auditor_fp_violation": 0.01587083790706184,
            "ave_precision_score": 0.8586841800952842,
            "fpr": 0.13830954994511527,
            "logloss": 0.5772075660991619,
            "mae": 0.26469352447619765,
            "precision": 0.7572254335260116,
            "recall": 0.8204592901878914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8803572993210684,
            "auditor_fn_violation": 0.015466297322253004,
            "auditor_fp_violation": 0.00718615761371392,
            "ave_precision_score": 0.880629194029344,
            "fpr": 0.051535087719298246,
            "logloss": 0.4780933580160406,
            "mae": 0.3037630214693899,
            "precision": 0.8739946380697051,
            "recall": 0.6863157894736842
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8699182688550109,
            "auditor_fn_violation": 0.012849217061706945,
            "auditor_fp_violation": 0.009061064357441966,
            "ave_precision_score": 0.8701349940460321,
            "fpr": 0.05817782656421515,
            "logloss": 0.49543638178235244,
            "mae": 0.31240230203329145,
            "precision": 0.8563685636856369,
            "recall": 0.6597077244258872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8451397792092017,
            "auditor_fn_violation": 0.007465373961218841,
            "auditor_fp_violation": 0.020419326347906382,
            "ave_precision_score": 0.8454363987872007,
            "fpr": 0.13815789473684212,
            "logloss": 0.6701672143556923,
            "mae": 0.2678375188370621,
            "precision": 0.7464788732394366,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8415649378124883,
            "auditor_fn_violation": 0.01586959660287509,
            "auditor_fp_violation": 0.01892507216327195,
            "ave_precision_score": 0.8418758039266334,
            "fpr": 0.12733260153677278,
            "logloss": 0.707712327281307,
            "mae": 0.2665431876413598,
            "precision": 0.7661290322580645,
            "recall": 0.7933194154488518
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8492962716736218,
            "auditor_fn_violation": 0.006322714681440448,
            "auditor_fp_violation": 0.012834216548235583,
            "ave_precision_score": 0.8496485934743732,
            "fpr": 0.09649122807017543,
            "logloss": 0.6240779634202255,
            "mae": 0.27223446624193026,
            "precision": 0.7924528301886793,
            "recall": 0.7073684210526315
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8485662539891149,
            "auditor_fn_violation": 0.018766227665118287,
            "auditor_fp_violation": 0.011388583973655327,
            "ave_precision_score": 0.8488402158037468,
            "fpr": 0.09879253567508232,
            "logloss": 0.661206779766751,
            "mae": 0.2755845397192733,
            "precision": 0.7906976744186046,
            "recall": 0.7098121085594989
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7872807017543859,
            "auc_prc": 0.8716773822434725,
            "auditor_fn_violation": 0.007876269621421976,
            "auditor_fp_violation": 0.011792926251555666,
            "ave_precision_score": 0.8718973322873693,
            "fpr": 0.0800438596491228,
            "logloss": 0.47245482711680287,
            "mae": 0.3077119036900337,
            "precision": 0.8290398126463701,
            "recall": 0.7452631578947368
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8664242099398201,
            "auditor_fn_violation": 0.007947402313179907,
            "auditor_fp_violation": 0.007223950075212425,
            "ave_precision_score": 0.8666517772012046,
            "fpr": 0.07793633369923161,
            "logloss": 0.4764033665815262,
            "mae": 0.31240588192941476,
            "precision": 0.8301435406698564,
            "recall": 0.7244258872651357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8368612896815669,
            "auditor_fn_violation": 0.005921052631578952,
            "auditor_fp_violation": 0.016650608213898598,
            "ave_precision_score": 0.837186717962184,
            "fpr": 0.12938596491228072,
            "logloss": 0.6732596184298495,
            "mae": 0.27175562337248693,
            "precision": 0.7581967213114754,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.832006504219702,
            "auditor_fn_violation": 0.01726520444852866,
            "auditor_fp_violation": 0.019941456275155513,
            "ave_precision_score": 0.8323305103462216,
            "fpr": 0.12733260153677278,
            "logloss": 0.7089626410056666,
            "mae": 0.27471679378836084,
            "precision": 0.7598343685300207,
            "recall": 0.7661795407098121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8518192834666416,
            "auditor_fn_violation": 0.008257156048014776,
            "auditor_fp_violation": 0.01973935123850817,
            "ave_precision_score": 0.8521044841575789,
            "fpr": 0.13157894736842105,
            "logloss": 0.6214830157208742,
            "mae": 0.26391965947994867,
            "precision": 0.7585513078470825,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8492388840173788,
            "auditor_fn_violation": 0.01604834440576668,
            "auditor_fp_violation": 0.018226308086352,
            "ave_precision_score": 0.8495319939041891,
            "fpr": 0.12843029637760703,
            "logloss": 0.6548707172643049,
            "mae": 0.26381598745058404,
            "precision": 0.7641129032258065,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8756911511208719,
            "auditor_fn_violation": 0.016389658356417362,
            "auditor_fp_violation": 0.013072584206511705,
            "ave_precision_score": 0.8759419779860065,
            "fpr": 0.07017543859649122,
            "logloss": 0.4678140866483855,
            "mae": 0.30143101395796085,
            "precision": 0.8431372549019608,
            "recall": 0.7242105263157895
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8644856880198633,
            "auditor_fn_violation": 0.011611732272457492,
            "auditor_fp_violation": 0.006743708582347444,
            "ave_precision_score": 0.8646965077937843,
            "fpr": 0.08122941822173436,
            "logloss": 0.4823518900855279,
            "mae": 0.308442390967277,
            "precision": 0.8242280285035629,
            "recall": 0.7244258872651357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.885732954139737,
            "auditor_fn_violation": 0.01258541089566021,
            "auditor_fp_violation": 0.00808191818218315,
            "ave_precision_score": 0.885915214895356,
            "fpr": 0.06140350877192982,
            "logloss": 0.46285650643686366,
            "mae": 0.29535554847659606,
            "precision": 0.8556701030927835,
            "recall": 0.6989473684210527
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8703727767829785,
            "auditor_fn_violation": 0.01696041652821351,
            "auditor_fp_violation": 0.009386307273244705,
            "ave_precision_score": 0.8706090376440895,
            "fpr": 0.06805708013172337,
            "logloss": 0.48496620007361685,
            "mae": 0.3058460599550636,
            "precision": 0.8402061855670103,
            "recall": 0.6805845511482255
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8002957010019982,
            "auditor_fn_violation": 0.0033979686057248448,
            "auditor_fp_violation": 0.013431390260548397,
            "ave_precision_score": 0.7767678932743048,
            "fpr": 0.1118421052631579,
            "logloss": 2.7502903113146844,
            "mae": 0.2765202473853528,
            "precision": 0.7748344370860927,
            "recall": 0.7389473684210527
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7789020468449785,
            "auditor_fn_violation": 0.012968382263634684,
            "auditor_fp_violation": 0.01590641135097776,
            "ave_precision_score": 0.7504767630500151,
            "fpr": 0.11745334796926454,
            "logloss": 3.133992888145695,
            "mae": 0.2851806252731538,
            "precision": 0.7668845315904139,
            "recall": 0.7348643006263048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 27690,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.826954593422873,
            "auditor_fn_violation": 0.0035272391505078485,
            "auditor_fp_violation": 0.024883074390782453,
            "ave_precision_score": 0.8274126141200618,
            "fpr": 0.15460526315789475,
            "logloss": 0.8048474269056235,
            "mae": 0.2773764803331721,
            "precision": 0.724609375,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.819278096475757,
            "auditor_fn_violation": 0.015104189344339316,
            "auditor_fp_violation": 0.02241126966703257,
            "ave_precision_score": 0.8196204428225005,
            "fpr": 0.14489571899012074,
            "logloss": 0.8596534596083245,
            "mae": 0.276574344013105,
            "precision": 0.7396449704142012,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8133458751317486,
            "auditor_fn_violation": 0.01014081255771007,
            "auditor_fp_violation": 0.02726926010678872,
            "ave_precision_score": 0.8149361947286015,
            "fpr": 0.14473684210526316,
            "logloss": 0.5938172236314198,
            "mae": 0.28022883284991523,
            "precision": 0.7431906614785992,
            "recall": 0.8042105263157895
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.812475841528476,
            "auditor_fn_violation": 0.009847170628527694,
            "auditor_fp_violation": 0.00907631011912022,
            "ave_precision_score": 0.8136354475694346,
            "fpr": 0.1437980241492865,
            "logloss": 0.6100224372286738,
            "mae": 0.2783991759345211,
            "precision": 0.7490421455938697,
            "recall": 0.8162839248434238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8487709493837605,
            "auditor_fn_violation": 0.008307940904893818,
            "auditor_fp_violation": 0.02437622947529006,
            "ave_precision_score": 0.8491188418566448,
            "fpr": 0.14802631578947367,
            "logloss": 0.6349767012331246,
            "mae": 0.266876230165009,
            "precision": 0.7383720930232558,
            "recall": 0.8021052631578948
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8476889310029376,
            "auditor_fn_violation": 0.016630420584413656,
            "auditor_fp_violation": 0.018630320770825715,
            "ave_precision_score": 0.8479923977248629,
            "fpr": 0.1394072447859495,
            "logloss": 0.6673528291315561,
            "mae": 0.265532022032365,
            "precision": 0.7543520309477756,
            "recall": 0.81419624217119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8349865080570774,
            "auditor_fn_violation": 0.0022506925207756248,
            "auditor_fp_violation": 0.019719278172548083,
            "ave_precision_score": 0.8353533489962179,
            "fpr": 0.14473684210526316,
            "logloss": 0.7209742361714625,
            "mae": 0.27364444672831884,
            "precision": 0.7396449704142012,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.829227251805637,
            "auditor_fn_violation": 0.015083564597851816,
            "auditor_fp_violation": 0.019994816441029396,
            "ave_precision_score": 0.8295658830032747,
            "fpr": 0.132821075740944,
            "logloss": 0.7620476244837306,
            "mae": 0.27498560585211734,
            "precision": 0.7550607287449392,
            "recall": 0.778705636743215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8323560340027496,
            "auditor_fn_violation": 0.005131578947368424,
            "auditor_fp_violation": 0.024702416797141608,
            "ave_precision_score": 0.8327540659452102,
            "fpr": 0.18640350877192982,
            "logloss": 0.8157007067655808,
            "mae": 0.27767456234074817,
            "precision": 0.7001763668430335,
            "recall": 0.8357894736842105
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8216535079437639,
            "auditor_fn_violation": 0.018947267106508483,
            "auditor_fp_violation": 0.02051825425864943,
            "ave_precision_score": 0.8220253576783181,
            "fpr": 0.17672886937431395,
            "logloss": 0.8708373487056887,
            "mae": 0.27534050129140697,
            "precision": 0.7119856887298748,
            "recall": 0.8308977035490606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 27690,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7578720590217223,
            "auditor_fn_violation": 0.002788550323176365,
            "auditor_fp_violation": 0.01971175077281305,
            "ave_precision_score": 0.7585301363849657,
            "fpr": 0.1611842105263158,
            "logloss": 0.7861890952209116,
            "mae": 0.33079193326304934,
            "precision": 0.6962809917355371,
            "recall": 0.7094736842105264
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7563029204424176,
            "auditor_fn_violation": 0.015216479630771213,
            "auditor_fp_violation": 0.026550493962678383,
            "ave_precision_score": 0.7569023157838707,
            "fpr": 0.14818880351262348,
            "logloss": 0.7935956839877908,
            "mae": 0.32746554186152843,
            "precision": 0.7127659574468085,
            "recall": 0.6993736951983298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8474644020478888,
            "auditor_fn_violation": 0.007338411819021242,
            "auditor_fp_violation": 0.024647215865751342,
            "ave_precision_score": 0.8478138867693839,
            "fpr": 0.1425438596491228,
            "logloss": 0.6451957281865286,
            "mae": 0.2666790422774564,
            "precision": 0.7430830039525692,
            "recall": 0.791578947368421
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.845723685643846,
            "auditor_fn_violation": 0.015429602011141947,
            "auditor_fp_violation": 0.02088161157864781,
            "ave_precision_score": 0.8460430286590489,
            "fpr": 0.13391877058177826,
            "logloss": 0.6790171443272448,
            "mae": 0.26559028630330933,
            "precision": 0.7603143418467584,
            "recall": 0.8079331941544885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8454097406709511,
            "auditor_fn_violation": 0.007511542012927063,
            "auditor_fp_violation": 0.013953289975510864,
            "ave_precision_score": 0.8457926754138356,
            "fpr": 0.09649122807017543,
            "logloss": 0.6422365961897646,
            "mae": 0.27270001162223284,
            "precision": 0.7914691943127962,
            "recall": 0.7031578947368421
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8449601481683542,
            "auditor_fn_violation": 0.017588325476832686,
            "auditor_fp_violation": 0.014178558360775705,
            "ave_precision_score": 0.8452495963475453,
            "fpr": 0.09879253567508232,
            "logloss": 0.6793100638211409,
            "mae": 0.27558825763277406,
            "precision": 0.7926267281105991,
            "recall": 0.7181628392484343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8317055820742327,
            "auditor_fn_violation": 0.0022299168975069305,
            "auditor_fp_violation": 0.01555160785258341,
            "ave_precision_score": 0.8320392358417384,
            "fpr": 0.12171052631578948,
            "logloss": 0.7346832920501642,
            "mae": 0.27356343038749814,
            "precision": 0.7653276955602537,
            "recall": 0.7621052631578947
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8291683312493101,
            "auditor_fn_violation": 0.01405461891197588,
            "auditor_fp_violation": 0.018660812294182223,
            "ave_precision_score": 0.829510629840293,
            "fpr": 0.11855104281009879,
            "logloss": 0.7687627932850047,
            "mae": 0.2753026406355774,
            "precision": 0.7692307692307693,
            "recall": 0.7515657620041754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7949561403508771,
            "auc_prc": 0.8723102053800181,
            "auditor_fn_violation": 0.006726685133887357,
            "auditor_fp_violation": 0.009981332048657114,
            "ave_precision_score": 0.8725928342830744,
            "fpr": 0.0712719298245614,
            "logloss": 0.4697343010700086,
            "mae": 0.307814055949086,
            "precision": 0.8444976076555024,
            "recall": 0.7431578947368421
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8664715489697036,
            "auditor_fn_violation": 0.01179277171384769,
            "auditor_fp_violation": 0.005956010895637684,
            "ave_precision_score": 0.8666891481034805,
            "fpr": 0.08122941822173436,
            "logloss": 0.48181568425172383,
            "mae": 0.312792102805759,
            "precision": 0.8242280285035629,
            "recall": 0.7244258872651357
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8317028486518727,
            "auditor_fn_violation": 0.004351338873499539,
            "auditor_fp_violation": 0.02612509534706331,
            "ave_precision_score": 0.8320240212794039,
            "fpr": 0.1425438596491228,
            "logloss": 0.7679035804998972,
            "mae": 0.27216020109861505,
            "precision": 0.74,
            "recall": 0.7789473684210526
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8254593841798692,
            "auditor_fn_violation": 0.01600021999729587,
            "auditor_fp_violation": 0.02103661015571005,
            "ave_precision_score": 0.8258009833263713,
            "fpr": 0.13062568605927552,
            "logloss": 0.8174782782288045,
            "mae": 0.27205053754098746,
            "precision": 0.7591093117408907,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8659057293086284,
            "auditor_fn_violation": 0.010203139427516163,
            "auditor_fp_violation": 0.0225646352723915,
            "ave_precision_score": 0.8662130245273129,
            "fpr": 0.12390350877192982,
            "logloss": 0.5553287513634425,
            "mae": 0.2557896757499307,
            "precision": 0.7730923694779116,
            "recall": 0.8105263157894737
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8505861889188508,
            "auditor_fn_violation": 0.02251305661034583,
            "auditor_fp_violation": 0.017639346261739235,
            "ave_precision_score": 0.85083167059776,
            "fpr": 0.12952799121844127,
            "logloss": 0.6291462275407549,
            "mae": 0.2689915050810331,
            "precision": 0.7625754527162978,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8381994131671604,
            "auditor_fn_violation": 0.00015697137580794057,
            "auditor_fp_violation": 0.021719057368822518,
            "ave_precision_score": 0.838564015105639,
            "fpr": 0.15679824561403508,
            "logloss": 0.7376334956671018,
            "mae": 0.2711796520925324,
            "precision": 0.72552783109405,
            "recall": 0.7957894736842105
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8300234342480363,
            "auditor_fn_violation": 0.015968137058315325,
            "auditor_fp_violation": 0.019407854616416642,
            "ave_precision_score": 0.8303830912808863,
            "fpr": 0.14270032930845225,
            "logloss": 0.7969463914423371,
            "mae": 0.26971311109948637,
            "precision": 0.7485493230174082,
            "recall": 0.8079331941544885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.843021561295353,
            "auditor_fn_violation": 0.008307940904893818,
            "auditor_fp_violation": 0.02636346300533944,
            "ave_precision_score": 0.8434903972359372,
            "fpr": 0.14364035087719298,
            "logloss": 0.6492952089057293,
            "mae": 0.26955409793156415,
            "precision": 0.744140625,
            "recall": 0.8021052631578948
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8422207759106788,
            "auditor_fn_violation": 0.02109453237970617,
            "auditor_fp_violation": 0.020635138431516046,
            "ave_precision_score": 0.8425014143278596,
            "fpr": 0.1350164654226125,
            "logloss": 0.6849693513101065,
            "mae": 0.27024597039208925,
            "precision": 0.7559523809523809,
            "recall": 0.7954070981210856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 27690,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8655341096076574,
            "auditor_fn_violation": 0.013301015697137587,
            "auditor_fp_violation": 0.024990967120317963,
            "ave_precision_score": 0.8658613343613407,
            "fpr": 0.13596491228070176,
            "logloss": 0.5578523103260433,
            "mae": 0.2561042975309381,
            "precision": 0.7578125,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8502325680874406,
            "auditor_fn_violation": 0.021486402562968493,
            "auditor_fp_violation": 0.023005854372484452,
            "ave_precision_score": 0.8504787996824343,
            "fpr": 0.13830954994511527,
            "logloss": 0.6310232530357506,
            "mae": 0.2690132196232029,
            "precision": 0.7519685039370079,
            "recall": 0.7974947807933194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8633145887376723,
            "auditor_fn_violation": 0.010664819944598338,
            "auditor_fp_violation": 0.020843369866313383,
            "ave_precision_score": 0.8635980675370829,
            "fpr": 0.13815789473684212,
            "logloss": 0.5371172834336404,
            "mae": 0.26778260401459975,
            "precision": 0.7529411764705882,
            "recall": 0.8084210526315789
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8575996947406747,
            "auditor_fn_violation": 0.015500642804598862,
            "auditor_fp_violation": 0.01576411757531406,
            "ave_precision_score": 0.8578927705727548,
            "fpr": 0.1350164654226125,
            "logloss": 0.5688679595585538,
            "mae": 0.2697488095701213,
            "precision": 0.7583497053045186,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8232413180983579,
            "auditor_fn_violation": 0.004018928901200376,
            "auditor_fp_violation": 0.011027640611827053,
            "ave_precision_score": 0.8236590808747126,
            "fpr": 0.12280701754385964,
            "logloss": 0.8720826143712228,
            "mae": 0.27557845422197574,
            "precision": 0.759656652360515,
            "recall": 0.7452631578947368
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8189289219163467,
            "auditor_fn_violation": 0.016683128269881692,
            "auditor_fp_violation": 0.021709964629832913,
            "ave_precision_score": 0.8192453502527242,
            "fpr": 0.12294182217343579,
            "logloss": 0.9226780436859247,
            "mae": 0.2787127948305166,
            "precision": 0.759656652360515,
            "recall": 0.7390396659707724
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8541111703346245,
            "auditor_fn_violation": 0.005923361034164357,
            "auditor_fp_violation": 0.017122325263960823,
            "ave_precision_score": 0.8543863036162233,
            "fpr": 0.11951754385964912,
            "logloss": 0.6050290656995139,
            "mae": 0.2633791401207799,
            "precision": 0.7733887733887734,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8512047252240726,
            "auditor_fn_violation": 0.017040623875664865,
            "auditor_fp_violation": 0.015825100622027084,
            "ave_precision_score": 0.8514900537313621,
            "fpr": 0.12184412733260154,
            "logloss": 0.6395785202031159,
            "mae": 0.26418397576501246,
            "precision": 0.7697095435684648,
            "recall": 0.7745302713987474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8373862371689157,
            "auditor_fn_violation": 0.004725300092336106,
            "auditor_fp_violation": 0.01758651491428801,
            "ave_precision_score": 0.8381074231895624,
            "fpr": 0.13157894736842105,
            "logloss": 0.7466663690245143,
            "mae": 0.27789492891386514,
            "precision": 0.7484276729559748,
            "recall": 0.751578947368421
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.837546508759023,
            "auditor_fn_violation": 0.014233366714867473,
            "auditor_fp_violation": 0.01648066837419198,
            "ave_precision_score": 0.8378297480591442,
            "fpr": 0.1207464324917673,
            "logloss": 0.7840113473739196,
            "mae": 0.2773929986983223,
            "precision": 0.7634408602150538,
            "recall": 0.7411273486430062
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8686340971080826,
            "auditor_fn_violation": 0.013702677746999079,
            "auditor_fp_violation": 0.02454183226946084,
            "ave_precision_score": 0.8689585035139359,
            "fpr": 0.13486842105263158,
            "logloss": 0.5383468224662971,
            "mae": 0.25715606323510487,
            "precision": 0.7592954990215264,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8542094955286286,
            "auditor_fn_violation": 0.02116786481166169,
            "auditor_fp_violation": 0.024106090173598407,
            "ave_precision_score": 0.8544449753647614,
            "fpr": 0.13062568605927552,
            "logloss": 0.6091285799022287,
            "mae": 0.270215702626681,
            "precision": 0.7634194831013916,
            "recall": 0.8016701461377871
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8208519201542939,
            "auditor_fn_violation": 0.010445521698984307,
            "auditor_fp_violation": 0.006892589024047534,
            "ave_precision_score": 0.8212430488878352,
            "fpr": 0.08991228070175439,
            "logloss": 0.8272883325123946,
            "mae": 0.28801552191327223,
            "precision": 0.7908163265306123,
            "recall": 0.6526315789473685
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8203229635009501,
            "auditor_fn_violation": 0.01033528962873165,
            "auditor_fp_violation": 0.011759564174492828,
            "ave_precision_score": 0.820653977237121,
            "fpr": 0.09330406147091108,
            "logloss": 0.8677828270601652,
            "mae": 0.2947498097564818,
            "precision": 0.7831632653061225,
            "recall": 0.6409185803757829
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8472084977576558,
            "auditor_fn_violation": 0.0058541089566020305,
            "auditor_fp_violation": 0.023841784094102536,
            "ave_precision_score": 0.8475580667495912,
            "fpr": 0.14364035087719298,
            "logloss": 0.6548023338538456,
            "mae": 0.26609314840245535,
            "precision": 0.7421259842519685,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8456197260815295,
            "auditor_fn_violation": 0.01666250352339419,
            "auditor_fp_violation": 0.01960350855795423,
            "ave_precision_score": 0.8459448180236089,
            "fpr": 0.132821075740944,
            "logloss": 0.6898753891767508,
            "mae": 0.26485501451644483,
            "precision": 0.7613412228796844,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 27690,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8460913798883851,
            "auditor_fn_violation": 0.004605263157894737,
            "auditor_fp_violation": 0.023904512425227828,
            "ave_precision_score": 0.8464247591335254,
            "fpr": 0.14802631578947367,
            "logloss": 0.6286662782030906,
            "mae": 0.27333905896549576,
            "precision": 0.7388781431334622,
            "recall": 0.8042105263157895
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8484580745938892,
            "auditor_fn_violation": 0.008566144707804634,
            "auditor_fp_violation": 0.01718705533195105,
            "ave_precision_score": 0.8488197117454851,
            "fpr": 0.14709110867178923,
            "logloss": 0.6388728398177999,
            "mae": 0.2700260972914354,
            "precision": 0.7403100775193798,
            "recall": 0.7974947807933194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.8833353706558202,
            "auditor_fn_violation": 0.013229455216989846,
            "auditor_fp_violation": 0.010435485166004259,
            "ave_precision_score": 0.8794091292017681,
            "fpr": 0.09649122807017543,
            "logloss": 1.218665594081144,
            "mae": 0.21267564314189163,
            "precision": 0.8065934065934066,
            "recall": 0.7726315789473684
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8728893597071302,
            "auditor_fn_violation": 0.006120966429787637,
            "auditor_fp_violation": 0.003384559092572266,
            "ave_precision_score": 0.8680771823705555,
            "fpr": 0.09989023051591657,
            "logloss": 1.4092883997808472,
            "mae": 0.21963715036181272,
            "precision": 0.8047210300429185,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8245731947217263,
            "auditor_fn_violation": 0.004845337026777472,
            "auditor_fp_violation": 0.02150076277650649,
            "ave_precision_score": 0.8249246869782568,
            "fpr": 0.14473684210526316,
            "logloss": 0.7560531884512708,
            "mae": 0.27581216603980496,
            "precision": 0.7365269461077845,
            "recall": 0.7768421052631579
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8197177173930179,
            "auditor_fn_violation": 0.02068891236545218,
            "auditor_fp_violation": 0.019834735943407743,
            "ave_precision_score": 0.8200327560793407,
            "fpr": 0.13391877058177826,
            "logloss": 0.7879058299652931,
            "mae": 0.27594318564198256,
            "precision": 0.7520325203252033,
            "recall": 0.7724425887265136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8292719550075316,
            "auditor_fn_violation": 0.005983379501385043,
            "auditor_fp_violation": 0.019154723192420408,
            "ave_precision_score": 0.8297521343323899,
            "fpr": 0.13267543859649122,
            "logloss": 0.8642843966598094,
            "mae": 0.2800762099881063,
            "precision": 0.7447257383966245,
            "recall": 0.7431578947368421
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8273946021847396,
            "auditor_fn_violation": 0.01765249135479377,
            "auditor_fp_violation": 0.022548481522136846,
            "ave_precision_score": 0.8276934414863213,
            "fpr": 0.1251372118551043,
            "logloss": 0.9100800903186547,
            "mae": 0.2810460890042099,
            "precision": 0.7548387096774194,
            "recall": 0.732776617954071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8469131105515068,
            "auditor_fn_violation": 0.008612650046168057,
            "auditor_fp_violation": 0.017042033000120443,
            "ave_precision_score": 0.8473471981842995,
            "fpr": 0.11403508771929824,
            "logloss": 0.5091484143997289,
            "mae": 0.29016218756141987,
            "precision": 0.7810526315789473,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8575380485595077,
            "auditor_fn_violation": 0.013176921367008203,
            "auditor_fp_violation": 0.011251372118551043,
            "ave_precision_score": 0.8578168111658357,
            "fpr": 0.11855104281009879,
            "logloss": 0.513983741465655,
            "mae": 0.29053979701344407,
            "precision": 0.7809330628803245,
            "recall": 0.8037578288100209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8531697810451371,
            "auditor_fn_violation": 0.004455216989843029,
            "auditor_fp_violation": 0.02235888634630054,
            "ave_precision_score": 0.8535243943818075,
            "fpr": 0.17105263157894737,
            "logloss": 0.6633259308985127,
            "mae": 0.26987912566712885,
            "precision": 0.717391304347826,
            "recall": 0.8336842105263158
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8443779057538794,
            "auditor_fn_violation": 0.01710249811512734,
            "auditor_fp_violation": 0.018846302394600972,
            "ave_precision_score": 0.8446568747051212,
            "fpr": 0.16575192096597147,
            "logloss": 0.7151018565171475,
            "mae": 0.26946179803283427,
            "precision": 0.7269439421338155,
            "recall": 0.8392484342379958
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 27690,
        "test": {
            "accuracy": 0.793859649122807,
            "auc_prc": 0.8782766139895362,
            "auditor_fn_violation": 0.009342105263157891,
            "auditor_fp_violation": 0.010703962423220525,
            "ave_precision_score": 0.8786860586263915,
            "fpr": 0.08114035087719298,
            "logloss": 0.4719442431263417,
            "mae": 0.26949123573491596,
            "precision": 0.8298850574712644,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8776649113056721,
            "auditor_fn_violation": 0.012844633784709734,
            "auditor_fp_violation": 0.012471033052811319,
            "ave_precision_score": 0.8778588535684423,
            "fpr": 0.0845225027442371,
            "logloss": 0.49294038921584277,
            "mae": 0.2730623293039248,
            "precision": 0.8225806451612904,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8306588944330568,
            "auditor_fn_violation": 0.0070891043397968605,
            "auditor_fp_violation": 0.020201031755590352,
            "ave_precision_score": 0.8310375183628029,
            "fpr": 0.13925438596491227,
            "logloss": 0.7055340921423335,
            "mae": 0.2741368207720487,
            "precision": 0.7449799196787149,
            "recall": 0.7810526315789473
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8265787259220949,
            "auditor_fn_violation": 0.018855601566564083,
            "auditor_fp_violation": 0.02144570476074318,
            "ave_precision_score": 0.8269265956034898,
            "fpr": 0.12952799121844127,
            "logloss": 0.7390723766791448,
            "mae": 0.27556307008697123,
            "precision": 0.757201646090535,
            "recall": 0.7682672233820459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8575025194478385,
            "auditor_fn_violation": 0.018529547553093263,
            "auditor_fp_violation": 0.018893773334939187,
            "ave_precision_score": 0.8580925033606035,
            "fpr": 0.10526315789473684,
            "logloss": 0.4694796770129791,
            "mae": 0.3018514405864009,
            "precision": 0.7953091684434968,
            "recall": 0.7852631578947369
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8491833552083703,
            "auditor_fn_violation": 0.009464466999259806,
            "auditor_fp_violation": 0.001372118551042813,
            "ave_precision_score": 0.8498906912652487,
            "fpr": 0.09879253567508232,
            "logloss": 0.48447292121923125,
            "mae": 0.30540204286226713,
            "precision": 0.8064516129032258,
            "recall": 0.7828810020876826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8377610955227279,
            "auditor_fn_violation": 0.00220914127423823,
            "auditor_fp_violation": 0.023377594443775348,
            "ave_precision_score": 0.8380751724270323,
            "fpr": 0.13925438596491227,
            "logloss": 0.6174903532768211,
            "mae": 0.2797897963571678,
            "precision": 0.7475149105367793,
            "recall": 0.791578947368421
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8356142999871857,
            "auditor_fn_violation": 0.011240486835682646,
            "auditor_fp_violation": 0.010733016221490426,
            "ave_precision_score": 0.8359859873707141,
            "fpr": 0.14050493962678376,
            "logloss": 0.6376261515042244,
            "mae": 0.28055034765974757,
            "precision": 0.7450199203187251,
            "recall": 0.7807933194154488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8663205132846837,
            "auditor_fn_violation": 0.0052216066481994465,
            "auditor_fp_violation": 0.028594082460154966,
            "ave_precision_score": 0.8665760656886595,
            "fpr": 0.12280701754385964,
            "logloss": 0.5250703154021081,
            "mae": 0.2724695559129048,
            "precision": 0.7695473251028807,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8619847452921718,
            "auditor_fn_violation": 0.00958363220118753,
            "auditor_fp_violation": 0.0112666178802293,
            "ave_precision_score": 0.8624120435185538,
            "fpr": 0.1163556531284303,
            "logloss": 0.5426200395105082,
            "mae": 0.2701371996443395,
            "precision": 0.7814432989690722,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8334381879519389,
            "auditor_fn_violation": 0.007179132040627886,
            "auditor_fp_violation": 0.017523786583162716,
            "ave_precision_score": 0.833770498282302,
            "fpr": 0.13157894736842105,
            "logloss": 0.7573451405521091,
            "mae": 0.2723900704935199,
            "precision": 0.7525773195876289,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8255402967437362,
            "auditor_fn_violation": 0.012874425085191672,
            "auditor_fp_violation": 0.021796357279343013,
            "ave_precision_score": 0.8258517092700374,
            "fpr": 0.132821075740944,
            "logloss": 0.8177386592268513,
            "mae": 0.2756971455188316,
            "precision": 0.7545638945233266,
            "recall": 0.7766179540709812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8104740666473759,
            "auditor_fn_violation": 0.005657894736842109,
            "auditor_fp_violation": 0.021026536593199252,
            "ave_precision_score": 0.8020680046069015,
            "fpr": 0.15789473684210525,
            "logloss": 1.330388539880293,
            "mae": 0.2665028862510874,
            "precision": 0.7348066298342542,
            "recall": 0.84
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8002895648541113,
            "auditor_fn_violation": 0.017512701406378554,
            "auditor_fp_violation": 0.014910354921331866,
            "ave_precision_score": 0.7933633636046838,
            "fpr": 0.15367727771679474,
            "logloss": 1.4610599629761805,
            "mae": 0.27202814323686914,
            "precision": 0.7368421052631579,
            "recall": 0.8183716075156576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8834480884038902,
            "auditor_fn_violation": 0.019095106186518933,
            "auditor_fp_violation": 0.015112509534706334,
            "ave_precision_score": 0.8836577072360023,
            "fpr": 0.125,
            "logloss": 0.45255055843651293,
            "mae": 0.2915620642203992,
            "precision": 0.7764705882352941,
            "recall": 0.8336842105263158
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8727251293454366,
            "auditor_fn_violation": 0.013976703203023135,
            "auditor_fp_violation": 0.013375614912387694,
            "ave_precision_score": 0.8729739457639176,
            "fpr": 0.12294182217343579,
            "logloss": 0.46877946993003866,
            "mae": 0.2979401903557289,
            "precision": 0.7790927021696252,
            "recall": 0.824634655532359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8298626376279236,
            "auditor_fn_violation": 0.006555863342566943,
            "auditor_fp_violation": 0.02156600024087679,
            "ave_precision_score": 0.830243404061507,
            "fpr": 0.1425438596491228,
            "logloss": 0.7067252274012653,
            "mae": 0.27505805746781126,
            "precision": 0.7420634920634921,
            "recall": 0.7873684210526316
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8254478889117147,
            "auditor_fn_violation": 0.02033370839816761,
            "auditor_fp_violation": 0.02091972598284344,
            "ave_precision_score": 0.8257905028626975,
            "fpr": 0.132821075740944,
            "logloss": 0.738142228694591,
            "mae": 0.2757987595810231,
            "precision": 0.7540650406504065,
            "recall": 0.7745302713987474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8280999952614113,
            "auditor_fn_violation": 0.006265004616805181,
            "auditor_fp_violation": 0.018793408005138713,
            "ave_precision_score": 0.8286099026639195,
            "fpr": 0.1337719298245614,
            "logloss": 0.881662424059742,
            "mae": 0.28041272939860074,
            "precision": 0.7431578947368421,
            "recall": 0.7431578947368421
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8258567175135727,
            "auditor_fn_violation": 0.015908554457351464,
            "auditor_fp_violation": 0.020612269788998657,
            "ave_precision_score": 0.8261738283871278,
            "fpr": 0.12294182217343579,
            "logloss": 0.9271685049746091,
            "mae": 0.2807669578111478,
            "precision": 0.7570498915401301,
            "recall": 0.7286012526096033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8586876121411084,
            "auditor_fn_violation": 0.01641043397968606,
            "auditor_fp_violation": 0.012450319161748769,
            "ave_precision_score": 0.8592690203418509,
            "fpr": 0.11513157894736842,
            "logloss": 0.46800402064339913,
            "mae": 0.3005819941813171,
            "precision": 0.7848360655737705,
            "recall": 0.8063157894736842
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8505986485350909,
            "auditor_fn_violation": 0.005071395997424207,
            "auditor_fp_violation": 0.0006174533479692701,
            "ave_precision_score": 0.8513152638766135,
            "fpr": 0.10867178924259056,
            "logloss": 0.4824227272528203,
            "mae": 0.3041813416226586,
            "precision": 0.7954545454545454,
            "recall": 0.8037578288100209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8742505754523965,
            "auditor_fn_violation": 0.008079409048938136,
            "auditor_fp_violation": 0.01591543217311012,
            "ave_precision_score": 0.8744832950796496,
            "fpr": 0.1337719298245614,
            "logloss": 0.5025385722768914,
            "mae": 0.26410478134613713,
            "precision": 0.7607843137254902,
            "recall": 0.8168421052631579
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8636192748276162,
            "auditor_fn_violation": 0.012021935563708697,
            "auditor_fp_violation": 0.014691832337276917,
            "ave_precision_score": 0.863866865116382,
            "fpr": 0.1394072447859495,
            "logloss": 0.5387933494309135,
            "mae": 0.26742157216786555,
            "precision": 0.7552986512524085,
            "recall": 0.8183716075156576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8884432003355657,
            "auditor_fn_violation": 0.01807710064635273,
            "auditor_fp_violation": 0.012083985707977042,
            "ave_precision_score": 0.8835624928096908,
            "fpr": 0.09210526315789473,
            "logloss": 1.2812644632738952,
            "mae": 0.20807797681322884,
            "precision": 0.8125,
            "recall": 0.7663157894736842
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8734275501954277,
            "auditor_fn_violation": 0.00813989994706315,
            "auditor_fp_violation": 0.003282920681383908,
            "ave_precision_score": 0.8685801313081947,
            "fpr": 0.10318331503841932,
            "logloss": 1.5037326170755236,
            "mae": 0.21967954232929401,
            "precision": 0.7978494623655914,
            "recall": 0.7745302713987474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8274821519426031,
            "auditor_fn_violation": 0.0013919667590027718,
            "auditor_fp_violation": 0.024238227146814416,
            "ave_precision_score": 0.8278839543849237,
            "fpr": 0.1513157894736842,
            "logloss": 0.8121600663748817,
            "mae": 0.27585020847429076,
            "precision": 0.727810650887574,
            "recall": 0.7768421052631579
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.821791830281116,
            "auditor_fn_violation": 0.013990453034014796,
            "auditor_fp_violation": 0.022251189169410913,
            "ave_precision_score": 0.8221505429577565,
            "fpr": 0.141602634467618,
            "logloss": 0.8621828651297059,
            "mae": 0.2746049840029725,
            "precision": 0.7450592885375494,
            "recall": 0.7870563674321504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8259530717150871,
            "auditor_fn_violation": 0.007536934441366578,
            "auditor_fp_violation": 0.02185204143080815,
            "ave_precision_score": 0.8263061229986659,
            "fpr": 0.13815789473684212,
            "logloss": 0.7412650249470973,
            "mae": 0.27838029208747445,
            "precision": 0.7433808553971487,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8206781021752043,
            "auditor_fn_violation": 0.016513547020984537,
            "auditor_fp_violation": 0.020251453429279993,
            "ave_precision_score": 0.8210324179395486,
            "fpr": 0.12952799121844127,
            "logloss": 0.7808104140552099,
            "mae": 0.27756680782682763,
            "precision": 0.757201646090535,
            "recall": 0.7682672233820459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8514241321951379,
            "auditor_fn_violation": 0.008257156048014776,
            "auditor_fp_violation": 0.019433236982616724,
            "ave_precision_score": 0.8517265355087513,
            "fpr": 0.1337719298245614,
            "logloss": 0.6213222404268997,
            "mae": 0.26396616960488173,
            "precision": 0.7555110220440882,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8492836267930068,
            "auditor_fn_violation": 0.01604834440576668,
            "auditor_fp_violation": 0.018226308086352,
            "ave_precision_score": 0.8495768033060035,
            "fpr": 0.12843029637760703,
            "logloss": 0.6545914859246542,
            "mae": 0.2638109950147624,
            "precision": 0.7641129032258065,
            "recall": 0.791231732776618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7748641238977414,
            "auditor_fn_violation": 0.0038550323176361955,
            "auditor_fp_violation": 0.029221365771407933,
            "ave_precision_score": 0.7766757418414109,
            "fpr": 0.14473684210526316,
            "logloss": 0.602433413018344,
            "mae": 0.30661559041120773,
            "precision": 0.7426900584795322,
            "recall": 0.8021052631578948
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7990326654649227,
            "auditor_fn_violation": 0.011474233962540879,
            "auditor_fp_violation": 0.018333028418099768,
            "ave_precision_score": 0.7999280632000981,
            "fpr": 0.141602634467618,
            "logloss": 0.5708005728201291,
            "mae": 0.29880899054909593,
            "precision": 0.7495145631067961,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8375469427177452,
            "auditor_fn_violation": 0.0026084949215143113,
            "auditor_fp_violation": 0.01406369183829138,
            "ave_precision_score": 0.8378835332067079,
            "fpr": 0.11732456140350878,
            "logloss": 0.7043877060381144,
            "mae": 0.2741745876210121,
            "precision": 0.7632743362831859,
            "recall": 0.7263157894736842
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8348000334990019,
            "auditor_fn_violation": 0.018133735439501895,
            "auditor_fp_violation": 0.01681353417083384,
            "ave_precision_score": 0.8351069196716273,
            "fpr": 0.11086717892425905,
            "logloss": 0.7461095499825549,
            "mae": 0.2758427535715078,
            "precision": 0.7760532150776053,
            "recall": 0.7306889352818372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8380430498983201,
            "auditor_fn_violation": 0.009766851338873509,
            "auditor_fp_violation": 0.018115942028985515,
            "ave_precision_score": 0.8383572668608217,
            "fpr": 0.12719298245614036,
            "logloss": 0.7263814632772786,
            "mae": 0.27092802617381645,
            "precision": 0.7542372881355932,
            "recall": 0.7494736842105263
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8338695838390219,
            "auditor_fn_violation": 0.016905417204246872,
            "auditor_fp_violation": 0.018272045371386766,
            "ave_precision_score": 0.8342265217106707,
            "fpr": 0.12184412733260154,
            "logloss": 0.7726961731428602,
            "mae": 0.2695906299307269,
            "precision": 0.7628205128205128,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8314597587014368,
            "auditor_fn_violation": 0.007617728531855957,
            "auditor_fp_violation": 0.01914468665944037,
            "ave_precision_score": 0.832185389661004,
            "fpr": 0.12719298245614036,
            "logloss": 0.8694581141912342,
            "mae": 0.28086505802881623,
            "precision": 0.7510729613733905,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8331518102136879,
            "auditor_fn_violation": 0.016614379114923375,
            "auditor_fp_violation": 0.019354494450542752,
            "ave_precision_score": 0.8334269185282333,
            "fpr": 0.11964873765093303,
            "logloss": 0.9106646941020571,
            "mae": 0.2804958643260446,
            "precision": 0.7604395604395604,
            "recall": 0.7223382045929019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8861982620042328,
            "auditor_fn_violation": 0.013515697137580801,
            "auditor_fp_violation": 0.013230659600947459,
            "ave_precision_score": 0.8812331892616208,
            "fpr": 0.09649122807017543,
            "logloss": 1.295649628272441,
            "mae": 0.21129933892093747,
            "precision": 0.8057395143487859,
            "recall": 0.7684210526315789
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8727431119930107,
            "auditor_fn_violation": 0.006769500124894298,
            "auditor_fp_violation": 0.007076574378989312,
            "ave_precision_score": 0.8670804347800243,
            "fpr": 0.09989023051591657,
            "logloss": 1.511150864016131,
            "mae": 0.21962773613500589,
            "precision": 0.8038793103448276,
            "recall": 0.778705636743215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 27690,
        "test": {
            "accuracy": 0.805921052631579,
            "auc_prc": 0.8849332650590185,
            "auditor_fn_violation": 0.019148199445983383,
            "auditor_fp_violation": 0.01131117266851339,
            "ave_precision_score": 0.8851377448074416,
            "fpr": 0.09100877192982457,
            "logloss": 0.4466196929947086,
            "mae": 0.2916009421981136,
            "precision": 0.8211206896551724,
            "recall": 0.8021052631578948
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8701911221294976,
            "auditor_fn_violation": 0.013784205569139882,
            "auditor_fp_violation": 0.0038012765784445272,
            "ave_precision_score": 0.8704312410172997,
            "fpr": 0.09659714599341383,
            "logloss": 0.46667447931246614,
            "mae": 0.29855218093150165,
            "precision": 0.8095238095238095,
            "recall": 0.7807933194154488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 27690,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7996496847064051,
            "auditor_fn_violation": 0.018781163434903048,
            "auditor_fp_violation": 0.041937653057127953,
            "ave_precision_score": 0.8010961327426713,
            "fpr": 0.13048245614035087,
            "logloss": 0.5358875328296813,
            "mae": 0.32218436130770306,
            "precision": 0.7576374745417516,
            "recall": 0.783157894736842
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8054830262672721,
            "auditor_fn_violation": 0.010912782530381401,
            "auditor_fp_violation": 0.027686303207708263,
            "ave_precision_score": 0.8060584823981979,
            "fpr": 0.13172338090010977,
            "logloss": 0.5357345881299757,
            "mae": 0.32253794030579774,
            "precision": 0.7585513078470825,
            "recall": 0.7870563674321504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7850877192982456,
            "auc_prc": 0.884715477003698,
            "auditor_fn_violation": 0.005586334256694369,
            "auditor_fp_violation": 0.01276646995062026,
            "ave_precision_score": 0.8825107197393776,
            "fpr": 0.07236842105263158,
            "logloss": 1.2556210530195415,
            "mae": 0.21264647829994943,
            "precision": 0.8394160583941606,
            "recall": 0.7263157894736842
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8717894349096814,
            "auditor_fn_violation": 0.007926777566692415,
            "auditor_fp_violation": 0.010908342480790345,
            "ave_precision_score": 0.8679814216561055,
            "fpr": 0.07574094401756312,
            "logloss": 1.4628288392478421,
            "mae": 0.22050219984389952,
            "precision": 0.8380281690140845,
            "recall": 0.7453027139874739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7905701754385965,
            "auc_prc": 0.8719855059264229,
            "auditor_fn_violation": 0.006756694367497692,
            "auditor_fp_violation": 0.017270364125416524,
            "ave_precision_score": 0.8717145762871774,
            "fpr": 0.09210526315789473,
            "logloss": 0.8489088831408916,
            "mae": 0.2253906404775713,
            "precision": 0.8141592920353983,
            "recall": 0.7747368421052632
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8682773829184556,
            "auditor_fn_violation": 0.015491476250604423,
            "auditor_fp_violation": 0.01298176606903281,
            "ave_precision_score": 0.8684521843764557,
            "fpr": 0.10208562019758508,
            "logloss": 0.9349849283475763,
            "mae": 0.2331193405778116,
            "precision": 0.8017057569296375,
            "recall": 0.7849686847599165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.856929020432678,
            "auditor_fn_violation": 0.00978993536472761,
            "auditor_fp_violation": 0.017418402986872215,
            "ave_precision_score": 0.8571947283101033,
            "fpr": 0.1337719298245614,
            "logloss": 0.6026543339659707,
            "mae": 0.26288777589379675,
            "precision": 0.7555110220440882,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8492814981225115,
            "auditor_fn_violation": 0.012911091301169426,
            "auditor_fp_violation": 0.01858458348579095,
            "ave_precision_score": 0.8495598664547267,
            "fpr": 0.12403951701427003,
            "logloss": 0.6442317992363814,
            "mae": 0.2657614582667488,
            "precision": 0.771255060728745,
            "recall": 0.7954070981210856
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8468580231258483,
            "auditor_fn_violation": 0.006149584487534628,
            "auditor_fp_violation": 0.023455377574370714,
            "ave_precision_score": 0.8472098936822796,
            "fpr": 0.14583333333333334,
            "logloss": 0.6464026001708149,
            "mae": 0.26704845436748936,
            "precision": 0.7392156862745098,
            "recall": 0.7936842105263158
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8463500200095974,
            "auditor_fn_violation": 0.015553350490066896,
            "auditor_fp_violation": 0.01840163434565192,
            "ave_precision_score": 0.8466534866801011,
            "fpr": 0.13391877058177826,
            "logloss": 0.6829229302150427,
            "mae": 0.266333207046992,
            "precision": 0.7598425196850394,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8481139085880507,
            "auditor_fn_violation": 0.008164819944598339,
            "auditor_fp_violation": 0.02133515998233571,
            "ave_precision_score": 0.8484321217675626,
            "fpr": 0.13925438596491227,
            "logloss": 0.6388122949844866,
            "mae": 0.2663858319914151,
            "precision": 0.7485148514851485,
            "recall": 0.7957894736842105
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8455302083689191,
            "auditor_fn_violation": 0.015564808682559947,
            "auditor_fp_violation": 0.01840163434565192,
            "ave_precision_score": 0.8458713475439205,
            "fpr": 0.13391877058177826,
            "logloss": 0.673127198465621,
            "mae": 0.2650566007875664,
            "precision": 0.7598425196850394,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8165233542899907,
            "auditor_fn_violation": 0.006620498614958455,
            "auditor_fp_violation": 0.0193429081857963,
            "ave_precision_score": 0.8168900149208322,
            "fpr": 0.13706140350877194,
            "logloss": 0.855736388045883,
            "mae": 0.2795747160552287,
            "precision": 0.7433264887063655,
            "recall": 0.7621052631578947
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.810244181694725,
            "auditor_fn_violation": 0.015253145846748969,
            "auditor_fp_violation": 0.021092511281863645,
            "ave_precision_score": 0.8106802403566884,
            "fpr": 0.132821075740944,
            "logloss": 0.9034110352002301,
            "mae": 0.27939413975674504,
            "precision": 0.7479166666666667,
            "recall": 0.7494780793319415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7861842105263158,
            "auc_prc": 0.8790351681479863,
            "auditor_fn_violation": 0.022045244690674055,
            "auditor_fp_violation": 0.010904693082821475,
            "ave_precision_score": 0.8793927049809531,
            "fpr": 0.08442982456140351,
            "logloss": 0.4606373445859627,
            "mae": 0.3071541163106367,
            "precision": 0.8225806451612904,
            "recall": 0.751578947368421
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.868488404433333,
            "auditor_fn_violation": 0.01642188148104013,
            "auditor_fp_violation": 0.0012603162987356174,
            "ave_precision_score": 0.8686796448618922,
            "fpr": 0.08781558726673985,
            "logloss": 0.4832657096604684,
            "mae": 0.31571470477652014,
            "precision": 0.814385150812065,
            "recall": 0.732776617954071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8457897174938835,
            "auditor_fn_violation": 0.005828716528162513,
            "auditor_fp_violation": 0.02136777871452086,
            "ave_precision_score": 0.8460993380994322,
            "fpr": 0.13815789473684212,
            "logloss": 0.6468069745420137,
            "mae": 0.2679806896573949,
            "precision": 0.7485029940119761,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8427276942350139,
            "auditor_fn_violation": 0.015713765184969607,
            "auditor_fp_violation": 0.01960350855795423,
            "ave_precision_score": 0.8430615762111779,
            "fpr": 0.132821075740944,
            "logloss": 0.6819692251943781,
            "mae": 0.2664523644160198,
            "precision": 0.7599206349206349,
            "recall": 0.7995824634655533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8372029785882347,
            "auditor_fn_violation": 0.002830101569713758,
            "auditor_fp_violation": 0.022574671805371566,
            "ave_precision_score": 0.8376311335775534,
            "fpr": 0.16228070175438597,
            "logloss": 0.7686763590428802,
            "mae": 0.2704569348472207,
            "precision": 0.7218045112781954,
            "recall": 0.8084210526315789
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8286265939354949,
            "auditor_fn_violation": 0.01878226913460855,
            "auditor_fp_violation": 0.023702077489124694,
            "ave_precision_score": 0.8289605813468679,
            "fpr": 0.14928649835345773,
            "logloss": 0.831211192759116,
            "mae": 0.2704021216735941,
            "precision": 0.7394636015325671,
            "recall": 0.8058455114822547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8444444278783032,
            "auditor_fn_violation": 0.009210526315789478,
            "auditor_fp_violation": 0.024845437392107275,
            "ave_precision_score": 0.8448578901881474,
            "fpr": 0.14692982456140352,
            "logloss": 0.6869672992370092,
            "mae": 0.2664366166234252,
            "precision": 0.7392996108949417,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8416728561065694,
            "auditor_fn_violation": 0.02174306607481283,
            "auditor_fp_violation": 0.02030735455543359,
            "ave_precision_score": 0.8419776434483641,
            "fpr": 0.13830954994511527,
            "logloss": 0.7492488054505957,
            "mae": 0.2683041926665076,
            "precision": 0.7534246575342466,
            "recall": 0.8037578288100209
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 27690,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8423666977065423,
            "auditor_fn_violation": 0.0075346260387811675,
            "auditor_fp_violation": 0.016108635432976037,
            "ave_precision_score": 0.8427498563082578,
            "fpr": 0.12171052631578948,
            "logloss": 0.675049786876139,
            "mae": 0.26746300338181966,
            "precision": 0.7663157894736842,
            "recall": 0.7663157894736842
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8404211482286547,
            "auditor_fn_violation": 0.014070660381466147,
            "auditor_fp_violation": 0.01640443956580071,
            "ave_precision_score": 0.840704420088843,
            "fpr": 0.1207464324917673,
            "logloss": 0.712733606653849,
            "mae": 0.2706660447751659,
            "precision": 0.7689075630252101,
            "recall": 0.7640918580375783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8195341634040623,
            "auditor_fn_violation": 0.0069113573407202245,
            "auditor_fp_violation": 0.010977457946926818,
            "ave_precision_score": 0.8198763373133798,
            "fpr": 0.11074561403508772,
            "logloss": 0.7932319366815691,
            "mae": 0.285938213311724,
            "precision": 0.7672811059907834,
            "recall": 0.7010526315789474
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8092150908005238,
            "auditor_fn_violation": 0.01678625200231914,
            "auditor_fp_violation": 0.01991604667235842,
            "ave_precision_score": 0.8100082383357842,
            "fpr": 0.10757409440175632,
            "logloss": 0.8437148077173395,
            "mae": 0.288949301082325,
            "precision": 0.7741935483870968,
            "recall": 0.7014613778705637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8285240922397858,
            "auditor_fn_violation": 0.007216066481994456,
            "auditor_fp_violation": 0.015707174113774144,
            "ave_precision_score": 0.8290019799978454,
            "fpr": 0.12938596491228072,
            "logloss": 0.8421908075301668,
            "mae": 0.2797805511445426,
            "precision": 0.75,
            "recall": 0.7452631578947368
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8264804993988139,
            "auditor_fn_violation": 0.01626146678613742,
            "auditor_fp_violation": 0.02087144773752897,
            "ave_precision_score": 0.826790725401132,
            "fpr": 0.1207464324917673,
            "logloss": 0.885952335888909,
            "mae": 0.28072337508797723,
            "precision": 0.7613882863340564,
            "recall": 0.732776617954071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 27690,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8619169497246457,
            "auditor_fn_violation": 0.011747460757156056,
            "auditor_fp_violation": 0.006676803564976518,
            "ave_precision_score": 0.8621437773952974,
            "fpr": 0.11293859649122807,
            "logloss": 0.4937249359872368,
            "mae": 0.30658074369443566,
            "precision": 0.7803837953091685,
            "recall": 0.7705263157894737
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8411236257950683,
            "auditor_fn_violation": 0.013247962160465115,
            "auditor_fp_violation": 0.005099707281375783,
            "ave_precision_score": 0.84145817813325,
            "fpr": 0.12184412733260154,
            "logloss": 0.533457485776457,
            "mae": 0.3221564981078249,
            "precision": 0.7692307692307693,
            "recall": 0.7724425887265136
        }
    }
]