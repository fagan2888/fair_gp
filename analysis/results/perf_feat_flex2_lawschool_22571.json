[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.743051376354934,
            "auditor_fn_violation": 0.0006383224796270594,
            "auditor_fp_violation": 0.005741531633379392,
            "ave_precision_score": 0.7441176824789169,
            "fpr": 0.01425438596491228,
            "logloss": 17.800601074664975,
            "mae": 0.5492861897015378,
            "precision": 0.1875,
            "recall": 0.006085192697768763
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.8008785422573808,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.001909989023051592,
            "ave_precision_score": 0.8017023414330312,
            "fpr": 0.009879253567508232,
            "logloss": 16.46601011557162,
            "mae": 0.5056742463755525,
            "precision": 0.47058823529411764,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8339858098886337,
            "auditor_fn_violation": 0.013856268460197146,
            "auditor_fp_violation": 0.025512393752878625,
            "ave_precision_score": 0.8343643294216365,
            "fpr": 0.24561403508771928,
            "logloss": 1.2938487473922529,
            "mae": 0.29615175001292915,
            "precision": 0.6691285081240768,
            "recall": 0.9188640973630832
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.8250636505172877,
            "auditor_fn_violation": 0.011450790649830584,
            "auditor_fp_violation": 0.025015245761678254,
            "ave_precision_score": 0.825334111234362,
            "fpr": 0.2689352360043908,
            "logloss": 1.3487471238501785,
            "mae": 0.31466312985435424,
            "precision": 0.6332335329341318,
            "recall": 0.9175704989154013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8144661694417421,
            "auditor_fn_violation": 0.010275435037899017,
            "auditor_fp_violation": 0.017242913369342215,
            "ave_precision_score": 0.8147423450376188,
            "fpr": 0.14144736842105263,
            "logloss": 1.0213475548626965,
            "mae": 0.29543605515539545,
            "precision": 0.7378048780487805,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8053581449293877,
            "auditor_fn_violation": 0.006533784475594744,
            "auditor_fp_violation": 0.020197585071350173,
            "ave_precision_score": 0.8059756203807149,
            "fpr": 0.14709110867178923,
            "logloss": 0.9490151063783913,
            "mae": 0.28152408458992284,
            "precision": 0.722567287784679,
            "recall": 0.7570498915401301
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8223104064617558,
            "auditor_fn_violation": 0.0241695135404434,
            "auditor_fp_violation": 0.022659946405392963,
            "ave_precision_score": 0.8235624663407434,
            "fpr": 0.1524122807017544,
            "logloss": 0.8871795114774375,
            "mae": 0.29775923988318864,
            "precision": 0.7274509803921568,
            "recall": 0.7525354969574036
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8123720914845083,
            "auditor_fn_violation": 0.015398682289967647,
            "auditor_fp_violation": 0.018155872667398466,
            "ave_precision_score": 0.8127787800787727,
            "fpr": 0.145993413830955,
            "logloss": 0.8750178377664034,
            "mae": 0.2817400158697575,
            "precision": 0.7307692307692307,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8010011897635566,
            "auditor_fn_violation": 0.02421622006334295,
            "auditor_fp_violation": 0.028160721014947872,
            "ave_precision_score": 0.8013533275675128,
            "fpr": 0.14692982456140352,
            "logloss": 1.0540379324722648,
            "mae": 0.29946536492189796,
            "precision": 0.7325349301397206,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7896094065053008,
            "auditor_fn_violation": 0.01615825854642345,
            "auditor_fp_violation": 0.023819978046103193,
            "ave_precision_score": 0.78999140472786,
            "fpr": 0.14818880351262348,
            "logloss": 0.9886314703696834,
            "mae": 0.28813113450854083,
            "precision": 0.7239263803680982,
            "recall": 0.7678958785249458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8556289213307238,
            "auditor_fn_violation": 0.011529838795772393,
            "auditor_fp_violation": 0.013348930201398485,
            "ave_precision_score": 0.8559704145916286,
            "fpr": 0.1118421052631579,
            "logloss": 0.5478582511561172,
            "mae": 0.27583236309440334,
            "precision": 0.7879417879417879,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8643909469610493,
            "auditor_fn_violation": 0.01767502994254365,
            "auditor_fp_violation": 0.02004146847176485,
            "ave_precision_score": 0.8645955683758062,
            "fpr": 0.11964873765093303,
            "logloss": 0.49347890250804355,
            "mae": 0.26581098396025915,
            "precision": 0.770042194092827,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.833546146427985,
            "auditor_fn_violation": 0.01886053877086225,
            "auditor_fp_violation": 0.015162458652598083,
            "ave_precision_score": 0.8343903306974605,
            "fpr": 0.09539473684210527,
            "logloss": 0.5653122651210157,
            "mae": 0.3090304492475856,
            "precision": 0.8009153318077803,
            "recall": 0.7099391480730223
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8658783891080526,
            "auditor_fn_violation": 0.022430120174964468,
            "auditor_fp_violation": 0.018294914013904137,
            "ave_precision_score": 0.8660733821684748,
            "fpr": 0.08562019758507135,
            "logloss": 0.4761266327344419,
            "mae": 0.2867991360026211,
            "precision": 0.8138424821002387,
            "recall": 0.7396963123644251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.8575930885431711,
            "auditor_fn_violation": 0.0057337817159531694,
            "auditor_fp_violation": 0.017020474814721773,
            "ave_precision_score": 0.8580012866461573,
            "fpr": 0.4024122807017544,
            "logloss": 2.07497230709022,
            "mae": 0.40332158487367104,
            "precision": 0.5677267373380448,
            "recall": 0.9776876267748479
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8651619144731306,
            "auditor_fn_violation": 0.00478366363391758,
            "auditor_fp_violation": 0.0057299670691547825,
            "ave_precision_score": 0.8653449987738683,
            "fpr": 0.4489571899012075,
            "logloss": 2.1705024722859796,
            "mae": 0.44437801509246755,
            "precision": 0.5244186046511627,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8246536282135428,
            "auditor_fn_violation": 0.010302124479555894,
            "auditor_fp_violation": 0.021267742745886192,
            "ave_precision_score": 0.8254304911186139,
            "fpr": 0.19846491228070176,
            "logloss": 1.3798348725392275,
            "mae": 0.2965298022506975,
            "precision": 0.6905982905982906,
            "recall": 0.8194726166328601
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8233406011019517,
            "auditor_fn_violation": 0.013922389879301191,
            "auditor_fp_violation": 0.028169288937675334,
            "ave_precision_score": 0.8236604728014812,
            "fpr": 0.19319429198682767,
            "logloss": 1.2574643610492615,
            "mae": 0.29170230613656656,
            "precision": 0.6834532374100719,
            "recall": 0.824295010845987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 22571,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.7445211229498284,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.0027216011388853994,
            "ave_precision_score": 0.745583534258704,
            "fpr": 0.005482456140350877,
            "logloss": 6.089977166603254,
            "mae": 0.5449358136677168,
            "precision": 0.2857142857142857,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7755580903350323,
            "auditor_fn_violation": 0.0013334254031826076,
            "auditor_fp_violation": 0.0005512867422856446,
            "ave_precision_score": 0.7763963948462416,
            "fpr": 0.0010976948408342481,
            "logloss": 5.53494821293741,
            "mae": 0.5031819791494998,
            "precision": 0.8571428571428571,
            "recall": 0.013015184381778741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8664303683519736,
            "auditor_fn_violation": 0.010913757517526068,
            "auditor_fp_violation": 0.03183226562827117,
            "ave_precision_score": 0.866690575956049,
            "fpr": 0.2532894736842105,
            "logloss": 0.7022745044988925,
            "mae": 0.3075922965659278,
            "precision": 0.6661849710982659,
            "recall": 0.9350912778904665
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8729538798587243,
            "auditor_fn_violation": 0.006648078081581824,
            "auditor_fp_violation": 0.027881448957189924,
            "ave_precision_score": 0.8731664620072632,
            "fpr": 0.2689352360043908,
            "logloss": 0.6941037877440738,
            "mae": 0.31156106557263596,
            "precision": 0.6433770014556041,
            "recall": 0.9587852494577006
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 22571,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7785269793462438,
            "auditor_fn_violation": 0.000676132521974307,
            "auditor_fp_violation": 0.007748712473307393,
            "ave_precision_score": 0.5652079581231956,
            "fpr": 0.43859649122807015,
            "logloss": 14.444667784944542,
            "mae": 0.4440210561158208,
            "precision": 0.5495495495495496,
            "recall": 0.9898580121703854
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.754235474368586,
            "auditor_fn_violation": 0.0026954242078619716,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.5212138832640311,
            "fpr": 0.4829857299670692,
            "logloss": 15.99363685126042,
            "mae": 0.49245367890560715,
            "precision": 0.5067264573991032,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.6134151669057032,
            "auditor_fn_violation": 0.001276644959254128,
            "auditor_fp_violation": 0.0005704894694971319,
            "ave_precision_score": 0.6130541445237692,
            "fpr": 0.0010964912280701754,
            "logloss": 13.318322433572133,
            "mae": 0.5392835943618189,
            "precision": 0.6666666666666666,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.5961356091728236,
            "auditor_fn_violation": 0.000723859504584843,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5962174079972943,
            "fpr": 0.0,
            "logloss": 12.48629938670321,
            "mae": 0.502914592729,
            "precision": 1.0,
            "recall": 0.006507592190889371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.7071842972160101,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.005027111334421974,
            "ave_precision_score": 0.7082971945558257,
            "fpr": 0.013157894736842105,
            "logloss": 6.7814993374264345,
            "mae": 0.5498803557337042,
            "precision": 0.14285714285714285,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.7557873319359029,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0022344188315648254,
            "ave_precision_score": 0.7567796734786691,
            "fpr": 0.008781558726673985,
            "logloss": 6.228226106401203,
            "mae": 0.5048870927290452,
            "precision": 0.5,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8424675268600522,
            "auditor_fn_violation": 0.0038277107576242843,
            "auditor_fp_violation": 0.014236067495708266,
            "ave_precision_score": 0.841521701869307,
            "fpr": 0.4067982456140351,
            "logloss": 4.321406007609923,
            "mae": 0.41734561686898086,
            "precision": 0.5655737704918032,
            "recall": 0.9797160243407708
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8482388579702408,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.8462899409347332,
            "fpr": 0.45115257958287597,
            "logloss": 4.657500202444468,
            "mae": 0.463517295867254,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8373330622003929,
            "auditor_fn_violation": 0.025074730436639273,
            "auditor_fp_violation": 0.022997529623581637,
            "ave_precision_score": 0.8379038930967868,
            "fpr": 0.11842105263157894,
            "logloss": 0.693851634678361,
            "mae": 0.29989523456127265,
            "precision": 0.7692307692307693,
            "recall": 0.7302231237322515
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8536569106175802,
            "auditor_fn_violation": 0.023751639994190075,
            "auditor_fp_violation": 0.022363702890596415,
            "ave_precision_score": 0.8538818524489343,
            "fpr": 0.1141602634467618,
            "logloss": 0.583246647216626,
            "mae": 0.2834378359878202,
            "precision": 0.7694013303769401,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.8451745500502666,
            "auditor_fn_violation": 0.0057337817159531694,
            "auditor_fp_violation": 0.016159506762132063,
            "ave_precision_score": 0.8457885315663709,
            "fpr": 0.40131578947368424,
            "logloss": 2.393442752752266,
            "mae": 0.4052132679740742,
            "precision": 0.5683962264150944,
            "recall": 0.9776876267748479
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.8558634789167445,
            "auditor_fn_violation": 0.00478366363391758,
            "auditor_fp_violation": 0.0057299670691547825,
            "ave_precision_score": 0.856079648329275,
            "fpr": 0.4489571899012075,
            "logloss": 2.512752599642525,
            "mae": 0.4472005001346199,
            "precision": 0.5244186046511627,
            "recall": 0.9783080260303688
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8546773165419593,
            "auditor_fn_violation": 0.01119844489519946,
            "auditor_fp_violation": 0.019797031361219283,
            "ave_precision_score": 0.8549556123639582,
            "fpr": 0.12280701754385964,
            "logloss": 0.570103403279539,
            "mae": 0.2771351295437183,
            "precision": 0.7790927021696252,
            "recall": 0.8012170385395537
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8745977651669046,
            "auditor_fn_violation": 0.014198599427103296,
            "auditor_fp_violation": 0.02291498963288206,
            "ave_precision_score": 0.8747784024631313,
            "fpr": 0.12733260153677278,
            "logloss": 0.48563112868996905,
            "mae": 0.25863693301943175,
            "precision": 0.7618069815195072,
            "recall": 0.8047722342733189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7160307867050101,
            "auditor_fn_violation": 0.011516494074943958,
            "auditor_fp_violation": 0.008868756018925608,
            "ave_precision_score": 0.7172309336303249,
            "fpr": 0.14692982456140352,
            "logloss": 0.8829519216037917,
            "mae": 0.30148050071459676,
            "precision": 0.7387914230019493,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7200589722166433,
            "auditor_fn_violation": 0.010365001392953325,
            "auditor_fp_violation": 0.014804244420051233,
            "ave_precision_score": 0.7212996378294374,
            "fpr": 0.15477497255762898,
            "logloss": 0.7921574438087887,
            "mae": 0.2945274522829601,
            "precision": 0.7207920792079208,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.8440100677161816,
            "auditor_fn_violation": 0.003972278566599053,
            "auditor_fp_violation": 0.016355776075032462,
            "ave_precision_score": 0.8439887008130272,
            "fpr": 0.40350877192982454,
            "logloss": 3.1588259405169747,
            "mae": 0.41357107006950217,
            "precision": 0.568075117370892,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.8531837573990455,
            "auditor_fn_violation": 0.0042479123558531425,
            "auditor_fp_violation": 0.0054884742041712425,
            "ave_precision_score": 0.853173954943173,
            "fpr": 0.4500548847420417,
            "logloss": 3.3792168447597333,
            "mae": 0.45927435105764636,
            "precision": 0.5232558139534884,
            "recall": 0.9761388286334056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.83499249426521,
            "auditor_fn_violation": 0.04924201985694459,
            "auditor_fp_violation": 0.03465592680986476,
            "ave_precision_score": 0.8352207299697598,
            "fpr": 0.125,
            "logloss": 0.7836733648277918,
            "mae": 0.3044560078157271,
            "precision": 0.7537796976241901,
            "recall": 0.7079107505070994
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8455615696257637,
            "auditor_fn_violation": 0.036616814018110774,
            "auditor_fp_violation": 0.035921453835833644,
            "ave_precision_score": 0.8458076021743244,
            "fpr": 0.11086717892425905,
            "logloss": 0.6239262148720669,
            "mae": 0.27748550778595354,
            "precision": 0.7672811059907834,
            "recall": 0.7223427331887202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7224641603668375,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.005121320604614161,
            "ave_precision_score": 0.7235613862630214,
            "fpr": 0.01206140350877193,
            "logloss": 8.489881607123465,
            "mae": 0.5478845675539142,
            "precision": 0.15384615384615385,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.7495218894478883,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0005317721673374803,
            "ave_precision_score": 0.7504116251261967,
            "fpr": 0.007683863885839737,
            "logloss": 7.766092647136212,
            "mae": 0.5046164647569371,
            "precision": 0.5333333333333333,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8561415816201983,
            "auditor_fn_violation": 0.0072817693320522394,
            "auditor_fp_violation": 0.023790457647699208,
            "ave_precision_score": 0.8564187106417596,
            "fpr": 0.22587719298245615,
            "logloss": 0.7198745122268371,
            "mae": 0.2927067373579791,
            "precision": 0.6888217522658611,
            "recall": 0.9249492900608519
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8597132282445928,
            "auditor_fn_violation": 0.0020739527253072253,
            "auditor_fp_violation": 0.025905598243688252,
            "ave_precision_score": 0.8599238679203552,
            "fpr": 0.2414928649835346,
            "logloss": 0.7188765536998996,
            "mae": 0.2984819418833798,
            "precision": 0.6636085626911316,
            "recall": 0.9414316702819957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8335692859896993,
            "auditor_fn_violation": 0.017921960072595285,
            "auditor_fp_violation": 0.012296926684252403,
            "ave_precision_score": 0.8339586150573485,
            "fpr": 0.11293859649122807,
            "logloss": 0.9103946902493647,
            "mae": 0.2820941916547201,
            "precision": 0.7760869565217391,
            "recall": 0.7241379310344828
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8282833266197711,
            "auditor_fn_violation": 0.011217441204273633,
            "auditor_fp_violation": 0.01775338455909258,
            "ave_precision_score": 0.828565825586951,
            "fpr": 0.1163556531284303,
            "logloss": 0.8141053386282935,
            "mae": 0.2658632896586139,
            "precision": 0.7660044150110376,
            "recall": 0.7527114967462039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8183445250581416,
            "auditor_fn_violation": 0.007043788477278388,
            "auditor_fp_violation": 0.022453209395804544,
            "ave_precision_score": 0.8197698858031949,
            "fpr": 0.21710526315789475,
            "logloss": 0.7779765098776259,
            "mae": 0.2878863629186143,
            "precision": 0.695852534562212,
            "recall": 0.9188640973630832
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8395224648582928,
            "auditor_fn_violation": 0.004319345859595068,
            "auditor_fp_violation": 0.027654592023417503,
            "ave_precision_score": 0.840070992439407,
            "fpr": 0.23380900109769484,
            "logloss": 0.7449696636749925,
            "mae": 0.29149839128312655,
            "precision": 0.6712962962962963,
            "recall": 0.9436008676789588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4199561403508772,
            "auc_prc": 0.5790304625457584,
            "auditor_fn_violation": 0.004239172983167865,
            "auditor_fp_violation": 0.004514194196708956,
            "ave_precision_score": 0.5763329896942455,
            "fpr": 0.0668859649122807,
            "logloss": 5.258387731445854,
            "mae": 0.5576169390181993,
            "precision": 0.29069767441860467,
            "recall": 0.05070993914807302
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.5493125825221878,
            "auditor_fn_violation": 0.0038812203699779358,
            "auditor_fp_violation": 0.015526283693133308,
            "ave_precision_score": 0.5493303566164985,
            "fpr": 0.07135016465422613,
            "logloss": 5.261534611863906,
            "mae": 0.5200887769355494,
            "precision": 0.2857142857142857,
            "recall": 0.05639913232104121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 22571,
        "test": {
            "accuracy": 0.41885964912280704,
            "auc_prc": 0.5787436647416246,
            "auditor_fn_violation": 0.004239172983167865,
            "auditor_fp_violation": 0.005524326927102965,
            "ave_precision_score": 0.5760460298967855,
            "fpr": 0.06798245614035088,
            "logloss": 5.263435975911879,
            "mae": 0.5575463892395373,
            "precision": 0.28735632183908044,
            "recall": 0.05070993914807302
        },
        "train": {
            "accuracy": 0.45115257958287597,
            "auc_prc": 0.5490997063889316,
            "auditor_fn_violation": 0.0038812203699779358,
            "auditor_fp_violation": 0.015526283693133308,
            "ave_precision_score": 0.5491172061842216,
            "fpr": 0.07135016465422613,
            "logloss": 5.266416822721343,
            "mae": 0.5199908235814324,
            "precision": 0.2857142857142857,
            "recall": 0.05639913232104121
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.8340147780025416,
            "auditor_fn_violation": 0.001483488132094943,
            "auditor_fp_violation": 0.009572708621195011,
            "ave_precision_score": 0.8317717338810589,
            "fpr": 0.43640350877192985,
            "logloss": 3.897774274683337,
            "mae": 0.44102759904736605,
            "precision": 0.5512965050732808,
            "recall": 0.9918864097363083
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.8413815356825215,
            "auditor_fn_violation": 0.0026954242078619716,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.8402636888493725,
            "fpr": 0.4829857299670692,
            "logloss": 4.23260411372648,
            "mae": 0.4903300518741086,
            "precision": 0.5067264573991032,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.6335931700380996,
            "auditor_fn_violation": 0.0013144550016013978,
            "auditor_fp_violation": 0.005741531633379392,
            "ave_precision_score": 0.6349673472699293,
            "fpr": 0.01425438596491228,
            "logloss": 11.388109179968005,
            "mae": 0.5506959949278658,
            "precision": 0.23529411764705882,
            "recall": 0.008113590263691683
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.6292912611714077,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0024393218685205514,
            "ave_precision_score": 0.6305695548075225,
            "fpr": 0.010976948408342482,
            "logloss": 10.520066844652932,
            "mae": 0.507972557963612,
            "precision": 0.4444444444444444,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8622688639654933,
            "auditor_fn_violation": 0.00972162912351874,
            "auditor_fp_violation": 0.024080936230791782,
            "ave_precision_score": 0.8625386603129116,
            "fpr": 0.23355263157894737,
            "logloss": 0.703244992168369,
            "mae": 0.29857921531003195,
            "precision": 0.6816143497757847,
            "recall": 0.9249492900608519
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8699947858253103,
            "auditor_fn_violation": 0.00444078281595634,
            "auditor_fp_violation": 0.024698133918770588,
            "ave_precision_score": 0.8702105985685413,
            "fpr": 0.24698133918770582,
            "logloss": 0.6866105696207749,
            "mae": 0.2996659982125515,
            "precision": 0.659606656580938,
            "recall": 0.9457700650759219
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8193423316808294,
            "auditor_fn_violation": 0.01006414362478204,
            "auditor_fp_violation": 0.017305719549470345,
            "ave_precision_score": 0.8200427059801517,
            "fpr": 0.21929824561403508,
            "logloss": 0.8819278815462692,
            "mae": 0.2855145093149575,
            "precision": 0.6908809891808346,
            "recall": 0.9066937119675457
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8317224264853283,
            "auditor_fn_violation": 0.003912174888266094,
            "auditor_fp_violation": 0.021822173435784856,
            "ave_precision_score": 0.8320562642315668,
            "fpr": 0.2349066959385291,
            "logloss": 0.8504555632306451,
            "mae": 0.29056451922680415,
            "precision": 0.6635220125786163,
            "recall": 0.9154013015184381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8203051388428295,
            "auditor_fn_violation": 0.01848688658766592,
            "auditor_fp_violation": 0.01517816019763012,
            "ave_precision_score": 0.8215597012421452,
            "fpr": 0.1074561403508772,
            "logloss": 1.0210158998131007,
            "mae": 0.2869466612633599,
            "precision": 0.7787810383747178,
            "recall": 0.6997971602434077
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8086188873983126,
            "auditor_fn_violation": 0.014546242478647341,
            "auditor_fp_violation": 0.02101719721917307,
            "ave_precision_score": 0.8089736454073225,
            "fpr": 0.1119648737650933,
            "logloss": 0.9550687564966082,
            "mae": 0.27540751660443086,
            "precision": 0.7582938388625592,
            "recall": 0.6941431670281996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6941678434795662,
            "auditor_fn_violation": 0.014176541760079715,
            "auditor_fp_violation": 0.011472595570070762,
            "ave_precision_score": 0.6922893650890984,
            "fpr": 0.15350877192982457,
            "logloss": 1.4894113221369174,
            "mae": 0.30735406276156735,
            "precision": 0.724950884086444,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6901400834315292,
            "auditor_fn_violation": 0.007993409068721416,
            "auditor_fp_violation": 0.01924137089889012,
            "ave_precision_score": 0.6889009808838658,
            "fpr": 0.15587266739846323,
            "logloss": 1.332598786490825,
            "mae": 0.2969687657278054,
            "precision": 0.7131313131313132,
            "recall": 0.7657266811279827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8483930384704867,
            "auditor_fn_violation": 0.014656951709903568,
            "auditor_fp_violation": 0.01637671146840849,
            "ave_precision_score": 0.8488958150710912,
            "fpr": 0.11293859649122807,
            "logloss": 0.6305919616269512,
            "mae": 0.27610977082952326,
            "precision": 0.783157894736842,
            "recall": 0.7545638945233266
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8552502732600507,
            "auditor_fn_violation": 0.014896266646982766,
            "auditor_fp_violation": 0.018982802780826934,
            "ave_precision_score": 0.8554561440086763,
            "fpr": 0.12184412733260154,
            "logloss": 0.5542897221946649,
            "mae": 0.26939205205661376,
            "precision": 0.7633262260127932,
            "recall": 0.7765726681127982
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8222987796941856,
            "auditor_fn_violation": 0.012786466673783855,
            "auditor_fp_violation": 0.021589624419042837,
            "ave_precision_score": 0.8228591366281859,
            "fpr": 0.19517543859649122,
            "logloss": 1.3901620101934966,
            "mae": 0.29619700455717285,
            "precision": 0.6983050847457627,
            "recall": 0.8356997971602435
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8240113494617047,
            "auditor_fn_violation": 0.012503244271628279,
            "auditor_fp_violation": 0.02454445664105379,
            "ave_precision_score": 0.8243205484568054,
            "fpr": 0.19978046103183314,
            "logloss": 1.2432644280311564,
            "mae": 0.2945761404139141,
            "precision": 0.675,
            "recall": 0.8199566160520607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4506578947368421,
            "auc_prc": 0.7441700277152377,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.004346711049700624,
            "ave_precision_score": 0.745230346635232,
            "fpr": 0.010964912280701754,
            "logloss": 15.049748366272269,
            "mae": 0.5486944380150967,
            "precision": 0.16666666666666666,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.803071099313179,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0027320404927430176,
            "ave_precision_score": 0.8038899193690136,
            "fpr": 0.005488474204171241,
            "logloss": 13.839778394874,
            "mae": 0.5038828183705414,
            "precision": 0.6153846153846154,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 22571,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8536633866696128,
            "auditor_fn_violation": 0.017101259741646207,
            "auditor_fp_violation": 0.015725097349579206,
            "ave_precision_score": 0.8539370587822268,
            "fpr": 0.09320175438596491,
            "logloss": 0.7271199598475527,
            "mae": 0.2816404464308883,
            "precision": 0.8119469026548672,
            "recall": 0.744421906693712
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.869615116043951,
            "auditor_fn_violation": 0.01821316233739949,
            "auditor_fp_violation": 0.021734357848518116,
            "ave_precision_score": 0.8698056898288233,
            "fpr": 0.09879253567508232,
            "logloss": 0.5875898365620459,
            "mae": 0.2628415866872932,
            "precision": 0.7935779816513762,
            "recall": 0.7505422993492408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 22571,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8548244416251465,
            "auditor_fn_violation": 0.010669104302337997,
            "auditor_fp_violation": 0.029126366034417796,
            "ave_precision_score": 0.8551126326533336,
            "fpr": 0.2138157894736842,
            "logloss": 0.7516895753403291,
            "mae": 0.28528536071478483,
            "precision": 0.6943573667711599,
            "recall": 0.8985801217038539
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8579496801783713,
            "auditor_fn_violation": 0.007138588140609711,
            "auditor_fp_violation": 0.02813757775338456,
            "ave_precision_score": 0.8581567524512352,
            "fpr": 0.22063666300768386,
            "logloss": 0.7207312516298618,
            "mae": 0.2897710462328872,
            "precision": 0.6778846153846154,
            "recall": 0.9175704989154013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.8621001511055327,
            "auditor_fn_violation": 0.0018348991139105371,
            "auditor_fp_violation": 0.006547544278356993,
            "ave_precision_score": 0.8624470107923324,
            "fpr": 0.43530701754385964,
            "logloss": 1.7536738336132793,
            "mae": 0.42132252335483045,
            "precision": 0.552423900789177,
            "recall": 0.9939148073022313
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.8682925406565468,
            "auditor_fn_violation": 0.0006429015336773254,
            "auditor_fp_violation": 0.006932552750335421,
            "ave_precision_score": 0.8684961695864647,
            "fpr": 0.47310647639956094,
            "logloss": 1.8543582306507391,
            "mae": 0.4512096451499329,
            "precision": 0.5162738496071829,
            "recall": 0.9978308026030369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8500742004633085,
            "auditor_fn_violation": 0.008709654460695349,
            "auditor_fp_violation": 0.02451272871917265,
            "ave_precision_score": 0.8503714454288692,
            "fpr": 0.22807017543859648,
            "logloss": 0.7913049578749112,
            "mae": 0.2938611709160335,
            "precision": 0.6848484848484848,
            "recall": 0.9168356997971603
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8554681586270172,
            "auditor_fn_violation": 0.006178998073676517,
            "auditor_fp_violation": 0.02515916575192097,
            "ave_precision_score": 0.8556867862911316,
            "fpr": 0.23929747530186607,
            "logloss": 0.7652475600446562,
            "mae": 0.2971741853513718,
            "precision": 0.6656441717791411,
            "recall": 0.9414316702819957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 22571,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8479761584407642,
            "auditor_fn_violation": 0.021091331269349846,
            "auditor_fp_violation": 0.021314847380982292,
            "ave_precision_score": 0.8485154241823419,
            "fpr": 0.12938596491228072,
            "logloss": 0.8529772896842072,
            "mae": 0.26693483718318906,
            "precision": 0.7616161616161616,
            "recall": 0.7647058823529411
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8495756391678504,
            "auditor_fn_violation": 0.023651633088951386,
            "auditor_fp_violation": 0.024171240395170143,
            "ave_precision_score": 0.8498288017268465,
            "fpr": 0.1350164654226125,
            "logloss": 0.7325886100447113,
            "mae": 0.2637974518261074,
            "precision": 0.7458677685950413,
            "recall": 0.7830802603036876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7096080185834139,
            "auditor_fn_violation": 0.011621027721433403,
            "auditor_fp_violation": 0.006887744420717672,
            "ave_precision_score": 0.7106630435173803,
            "fpr": 0.14364035087719298,
            "logloss": 0.9572363913170858,
            "mae": 0.3061587275833517,
            "precision": 0.7390438247011952,
            "recall": 0.7525354969574036
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7055617841266689,
            "auditor_fn_violation": 0.010191179867181311,
            "auditor_fp_violation": 0.00898158311989267,
            "ave_precision_score": 0.7067426500189974,
            "fpr": 0.15697036223929747,
            "logloss": 0.8745472212320188,
            "mae": 0.2991015874463735,
            "precision": 0.717948717948718,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8298570511343408,
            "auditor_fn_violation": 0.024580975765986973,
            "auditor_fp_violation": 0.03426862203240799,
            "ave_precision_score": 0.8307092454184395,
            "fpr": 0.13486842105263158,
            "logloss": 0.9395550871690229,
            "mae": 0.27710941356386365,
            "precision": 0.7535070140280561,
            "recall": 0.7626774847870182
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8345036032580373,
            "auditor_fn_violation": 0.022544413780951546,
            "auditor_fp_violation": 0.029857299670691544,
            "ave_precision_score": 0.8347863082505288,
            "fpr": 0.1350164654226125,
            "logloss": 0.8311087496111305,
            "mae": 0.2655228002231641,
            "precision": 0.7469135802469136,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8221910873889089,
            "auditor_fn_violation": 0.012321625564926518,
            "auditor_fp_violation": 0.021589624419042837,
            "ave_precision_score": 0.8227261453032734,
            "fpr": 0.19517543859649122,
            "logloss": 1.390494142397955,
            "mae": 0.2962207113328527,
            "precision": 0.6977928692699491,
            "recall": 0.8336713995943205
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8239624959331403,
            "auditor_fn_violation": 0.012503244271628279,
            "auditor_fp_violation": 0.02454445664105379,
            "ave_precision_score": 0.8242716549196121,
            "fpr": 0.19978046103183314,
            "logloss": 1.2439597594058953,
            "mae": 0.29453843516678135,
            "precision": 0.675,
            "recall": 0.8199566160520607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8317114371397143,
            "auditor_fn_violation": 0.009932920536635713,
            "auditor_fp_violation": 0.02677375120378512,
            "ave_precision_score": 0.832088268329853,
            "fpr": 0.1787280701754386,
            "logloss": 0.9847431469675202,
            "mae": 0.2776760059421439,
            "precision": 0.7135325131810193,
            "recall": 0.8235294117647058
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8241064361199765,
            "auditor_fn_violation": 0.013519981141555015,
            "auditor_fp_violation": 0.021661178192462504,
            "ave_precision_score": 0.8243960240274102,
            "fpr": 0.18441273326015367,
            "logloss": 0.9560562630676739,
            "mae": 0.27422272882783116,
            "precision": 0.7,
            "recall": 0.8503253796095445
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8443743151175934,
            "auditor_fn_violation": 0.003972278566599053,
            "auditor_fp_violation": 0.014236067495708266,
            "ave_precision_score": 0.8327801183036436,
            "fpr": 0.4067982456140351,
            "logloss": 5.020857823895133,
            "mae": 0.4169274460249288,
            "precision": 0.5660818713450292,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8430266799252669,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.8312947978541144,
            "fpr": 0.45115257958287597,
            "logloss": 5.361835988543603,
            "mae": 0.4631544689080725,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.822635201610361,
            "auditor_fn_violation": 0.012966620404967797,
            "auditor_fp_violation": 0.018535673910312783,
            "ave_precision_score": 0.823130940793663,
            "fpr": 0.20942982456140352,
            "logloss": 1.4009649520203593,
            "mae": 0.3005165436220393,
            "precision": 0.6879084967320261,
            "recall": 0.8539553752535497
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8251413727788213,
            "auditor_fn_violation": 0.006112326803517387,
            "auditor_fp_violation": 0.026403219904866465,
            "ave_precision_score": 0.825459349684314,
            "fpr": 0.21624588364434688,
            "logloss": 1.2683904233135033,
            "mae": 0.30084144029708537,
            "precision": 0.6649659863945578,
            "recall": 0.8481561822125814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.8051027789784588,
            "auditor_fn_violation": 0.0010408882246183387,
            "auditor_fp_violation": 0.0006646987396893187,
            "ave_precision_score": 0.8058331337703807,
            "fpr": 0.0010964912280701754,
            "logloss": 2.738196219487907,
            "mae": 0.5235620254373258,
            "precision": 0.75,
            "recall": 0.006085192697768763
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.8466498838468399,
            "auditor_fn_violation": 0.0014167644908815325,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8470488876169372,
            "fpr": 0.0,
            "logloss": 2.439147040251128,
            "mae": 0.48648908346769104,
            "precision": 1.0,
            "recall": 0.008676789587852495
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8509506528960439,
            "auditor_fn_violation": 0.011122824810504974,
            "auditor_fp_violation": 0.015455554159862672,
            "ave_precision_score": 0.851298753562763,
            "fpr": 0.10964912280701754,
            "logloss": 0.7598365581027379,
            "mae": 0.28275497505905794,
            "precision": 0.7907949790794979,
            "recall": 0.7667342799188641
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8641812107058318,
            "auditor_fn_violation": 0.009943543720875966,
            "auditor_fp_violation": 0.021270886693499205,
            "ave_precision_score": 0.8643786421878282,
            "fpr": 0.1207464324917673,
            "logloss": 0.6152207222437128,
            "mae": 0.26672690933930326,
            "precision": 0.7689075630252101,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8811488029113633,
            "auditor_fn_violation": 0.011498701113839369,
            "auditor_fp_violation": 0.011428107859146676,
            "ave_precision_score": 0.871686182724617,
            "fpr": 0.08771929824561403,
            "logloss": 2.1395398946915463,
            "mae": 0.2228395154814698,
            "precision": 0.821826280623608,
            "recall": 0.7484787018255578
        },
        "train": {
            "accuracy": 0.8057080131723381,
            "auc_prc": 0.868814385891081,
            "auditor_fn_violation": 0.008586307149779393,
            "auditor_fp_violation": 0.008674228564459086,
            "ave_precision_score": 0.8522225293291557,
            "fpr": 0.09001097694840834,
            "logloss": 2.035186678658176,
            "mae": 0.19944043174503306,
            "precision": 0.8169642857142857,
            "recall": 0.7939262472885033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 22571,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8206744585857972,
            "auditor_fn_violation": 0.012862086758478348,
            "auditor_fp_violation": 0.017138236402462002,
            "ave_precision_score": 0.8212209305532449,
            "fpr": 0.19298245614035087,
            "logloss": 1.389719061345725,
            "mae": 0.2965203348097729,
            "precision": 0.6949740034662045,
            "recall": 0.8133874239350912
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8209896381431044,
            "auditor_fn_violation": 0.012831838388841136,
            "auditor_fp_violation": 0.020524454201731927,
            "ave_precision_score": 0.8213018543019686,
            "fpr": 0.19319429198682767,
            "logloss": 1.2541076516133394,
            "mae": 0.29430014455136594,
            "precision": 0.6805807622504537,
            "recall": 0.8134490238611713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8358003879581375,
            "auditor_fn_violation": 0.017141293904131532,
            "auditor_fp_violation": 0.03061539588828874,
            "ave_precision_score": 0.8363581648932971,
            "fpr": 0.16337719298245615,
            "logloss": 0.9605533355099956,
            "mae": 0.2723890122896127,
            "precision": 0.7281021897810219,
            "recall": 0.8093306288032455
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8319628949811305,
            "auditor_fn_violation": 0.0158225210788364,
            "auditor_fp_violation": 0.02655933650445177,
            "ave_precision_score": 0.8322308978425126,
            "fpr": 0.17233809001097694,
            "logloss": 0.9143307953246496,
            "mae": 0.27084988593487985,
            "precision": 0.707635009310987,
            "recall": 0.824295010845987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.7430343313881083,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.005092534438722104,
            "ave_precision_score": 0.7441050292459525,
            "fpr": 0.01206140350877193,
            "logloss": 17.473275590930005,
            "mae": 0.5482755827376549,
            "precision": 0.15384615384615385,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.7996502695655432,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.00137089889010855,
            "ave_precision_score": 0.8004900007516867,
            "fpr": 0.008781558726673985,
            "logloss": 16.152506266623345,
            "mae": 0.5049894848913632,
            "precision": 0.5,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 22571,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.7893953739968618,
            "auditor_fn_violation": 0.0011209565495889913,
            "auditor_fp_violation": 0.004579617301009088,
            "ave_precision_score": 0.790734204662681,
            "fpr": 0.09649122807017543,
            "logloss": 0.5511889498140079,
            "mae": 0.3595968387988314,
            "precision": 0.8031319910514542,
            "recall": 0.7281947261663286
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8142686475445611,
            "auditor_fn_violation": 0.0031787909165156697,
            "auditor_fp_violation": 0.009313330894011467,
            "ave_precision_score": 0.814936328804459,
            "fpr": 0.09440175631174534,
            "logloss": 0.5176835085344417,
            "mae": 0.34759963075625255,
            "precision": 0.7971698113207547,
            "recall": 0.7331887201735358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 22571,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.8249227728726473,
            "auditor_fn_violation": 0.004879719582932991,
            "auditor_fp_violation": 0.002187748607796341,
            "ave_precision_score": 0.8257398651803576,
            "fpr": 0.0043859649122807015,
            "logloss": 1.6722596744389253,
            "mae": 0.4722634560789898,
            "precision": 0.9215686274509803,
            "recall": 0.09533468559837728
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.852423317130189,
            "auditor_fn_violation": 0.0036264408732983944,
            "auditor_fp_violation": 0.0009074277350896451,
            "ave_precision_score": 0.8528510184128705,
            "fpr": 0.0021953896816684962,
            "logloss": 1.4860763590863648,
            "mae": 0.4384036815711287,
            "precision": 0.9574468085106383,
            "recall": 0.09761388286334056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8307115459637661,
            "auditor_fn_violation": 0.01617380164406961,
            "auditor_fp_violation": 0.010491249005568817,
            "ave_precision_score": 0.8310915067235934,
            "fpr": 0.11074561403508772,
            "logloss": 0.9574139330700568,
            "mae": 0.29613186146609843,
            "precision": 0.7827956989247312,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8604478434635117,
            "auditor_fn_violation": 0.01118886780277686,
            "auditor_fp_violation": 0.015462861324551781,
            "ave_precision_score": 0.8606341579405298,
            "fpr": 0.11745334796926454,
            "logloss": 0.90983012169159,
            "mae": 0.2746686843332051,
            "precision": 0.7648351648351648,
            "recall": 0.754880694143167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.37593670099820453,
            "auditor_fn_violation": 0.0006027365574178844,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5405174405136725,
            "fpr": 0.0,
            "logloss": 18.5321346977104,
            "mae": 0.5395111664224636,
            "precision": 1.0,
            "recall": 0.002028397565922921
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.496757577326903,
            "auditor_fn_violation": 0.0001595348250236434,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5127545039308307,
            "fpr": 0.0,
            "logloss": 17.192256074073352,
            "mae": 0.5040610318900721,
            "precision": 1.0,
            "recall": 0.004338394793926247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.8221496830003815,
            "auditor_fn_violation": 0.009227874452866446,
            "auditor_fp_violation": 0.016609617719716967,
            "ave_precision_score": 0.8216094284491005,
            "fpr": 0.27850877192982454,
            "logloss": 1.4990063446922979,
            "mae": 0.31305211743484396,
            "precision": 0.6472222222222223,
            "recall": 0.9452332657200812
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.8119207569851701,
            "auditor_fn_violation": 0.004269342406975722,
            "auditor_fp_violation": 0.024356628857177723,
            "ave_precision_score": 0.8117744631416288,
            "fpr": 0.3040614709110867,
            "logloss": 1.595348560203548,
            "mae": 0.3376075149779826,
            "precision": 0.6109550561797753,
            "recall": 0.9436008676789588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.8615860094750355,
            "auditor_fn_violation": 0.004612825166364186,
            "auditor_fp_violation": 0.014424486036092626,
            "ave_precision_score": 0.8618672471535005,
            "fpr": 0.3684210526315789,
            "logloss": 1.01525804150592,
            "mae": 0.36275534831567485,
            "precision": 0.5902439024390244,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.8688753812387631,
            "auditor_fn_violation": 0.0005238456941074505,
            "auditor_fp_violation": 0.018251006220270784,
            "ave_precision_score": 0.8690458043469217,
            "fpr": 0.3885839736553238,
            "logloss": 1.0460309328603288,
            "mae": 0.3790345768475932,
            "precision": 0.5640394088669951,
            "recall": 0.9934924078091106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.832611156304182,
            "auditor_fn_violation": 0.01193462866090175,
            "auditor_fp_violation": 0.03005275719130763,
            "ave_precision_score": 0.8323548724131506,
            "fpr": 0.25877192982456143,
            "logloss": 1.5394955725237072,
            "mae": 0.3032142957790173,
            "precision": 0.6609195402298851,
            "recall": 0.9330628803245437
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8206867477529827,
            "auditor_fn_violation": 0.006121851270682977,
            "auditor_fp_violation": 0.029784120014635936,
            "ave_precision_score": 0.8209133613579329,
            "fpr": 0.29198682766191,
            "logloss": 1.5613698347278073,
            "mae": 0.3233291522957932,
            "precision": 0.6194563662374821,
            "recall": 0.9392624728850325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8507679470181594,
            "auditor_fn_violation": 0.007183908045977011,
            "auditor_fp_violation": 0.02763995310471885,
            "ave_precision_score": 0.85108053637173,
            "fpr": 0.23026315789473684,
            "logloss": 0.7803380495008928,
            "mae": 0.289555383659111,
            "precision": 0.6837349397590361,
            "recall": 0.920892494929006
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8533211861192016,
            "auditor_fn_violation": 0.00704572458574521,
            "auditor_fp_violation": 0.02857665568971826,
            "ave_precision_score": 0.8535509597617994,
            "fpr": 0.24039517014270034,
            "logloss": 0.7702197467226569,
            "mae": 0.29528807002285223,
            "precision": 0.663594470046083,
            "recall": 0.9370932754880694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8412739009982675,
            "auditor_fn_violation": 0.0038277107576242843,
            "auditor_fp_violation": 0.014236067495708266,
            "ave_precision_score": 0.8084922530158187,
            "fpr": 0.4067982456140351,
            "logloss": 6.266587359713369,
            "mae": 0.417287253570887,
            "precision": 0.5655737704918032,
            "recall": 0.9797160243407708
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8422835755129536,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.8069518205021372,
            "fpr": 0.45115257958287597,
            "logloss": 6.7539155749604305,
            "mae": 0.4636503704873867,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7792737522902542,
            "auditor_fn_violation": 0.028237429272979623,
            "auditor_fp_violation": 0.026501591089896588,
            "ave_precision_score": 0.7802044994885641,
            "fpr": 0.1337719298245614,
            "logloss": 1.477935302529041,
            "mae": 0.3081497905814471,
            "precision": 0.7376344086021506,
            "recall": 0.6957403651115619
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7723484550953055,
            "auditor_fn_violation": 0.025485093018327458,
            "auditor_fp_violation": 0.027727771679473115,
            "ave_precision_score": 0.7730723900999452,
            "fpr": 0.1394072447859495,
            "logloss": 1.4511747947934017,
            "mae": 0.2989293103844173,
            "precision": 0.7221006564551422,
            "recall": 0.7158351409978309
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8492844030445328,
            "auditor_fn_violation": 0.012021369346286611,
            "auditor_fp_violation": 0.032261441192480006,
            "ave_precision_score": 0.8497131818664659,
            "fpr": 0.21710526315789475,
            "logloss": 0.7910360621929435,
            "mae": 0.2882541774316658,
            "precision": 0.695852534562212,
            "recall": 0.9188640973630832
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8526145347170602,
            "auditor_fn_violation": 0.015186762895533265,
            "auditor_fp_violation": 0.03357482619831688,
            "ave_precision_score": 0.8529120451545692,
            "fpr": 0.24368825466520308,
            "logloss": 0.775698067660011,
            "mae": 0.2985564175288514,
            "precision": 0.6584615384615384,
            "recall": 0.928416485900217
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8327990104907087,
            "auditor_fn_violation": 0.00416800113874951,
            "auditor_fp_violation": 0.02129129506343424,
            "ave_precision_score": 0.8333335007374056,
            "fpr": 0.19407894736842105,
            "logloss": 0.9351842454783593,
            "mae": 0.297374657203104,
            "precision": 0.6958762886597938,
            "recall": 0.821501014198783
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8386882809863694,
            "auditor_fn_violation": 0.005064635415302489,
            "auditor_fp_violation": 0.03194291986827663,
            "ave_precision_score": 0.8388862532846827,
            "fpr": 0.2030735455543359,
            "logloss": 0.8872873087673182,
            "mae": 0.2863539847348276,
            "precision": 0.6799307958477508,
            "recall": 0.8524945770065075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8123314744749355,
            "auditor_fn_violation": 0.0038277107576242843,
            "auditor_fp_violation": 0.014236067495708266,
            "ave_precision_score": 0.7109051429821277,
            "fpr": 0.4067982456140351,
            "logloss": 9.095155665319341,
            "mae": 0.41774583543774546,
            "precision": 0.5655737704918032,
            "recall": 0.9797160243407708
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8040141326958016,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.696673051045125,
            "fpr": 0.45115257958287597,
            "logloss": 9.720254492377226,
            "mae": 0.46403242424826674,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4517543859649123,
            "auc_prc": 0.7120665087194081,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.004357178746388646,
            "ave_precision_score": 0.7132512519726016,
            "fpr": 0.009868421052631578,
            "logloss": 5.94063693255802,
            "mae": 0.546782386812299,
            "precision": 0.18181818181818182,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4961580680570801,
            "auc_prc": 0.7579781436042881,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0012440541529454812,
            "ave_precision_score": 0.7589550299246665,
            "fpr": 0.006586169045005488,
            "logloss": 5.449962590848616,
            "mae": 0.5042671182929889,
            "precision": 0.5714285714285714,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8502882024428999,
            "auditor_fn_violation": 0.006634550371872888,
            "auditor_fp_violation": 0.02755882845538668,
            "ave_precision_score": 0.850701399722446,
            "fpr": 0.23135964912280702,
            "logloss": 0.7712994666655323,
            "mae": 0.2939697731932954,
            "precision": 0.6831831831831832,
            "recall": 0.922920892494929
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8564835905197452,
            "auditor_fn_violation": 0.007702912820170917,
            "auditor_fp_violation": 0.02499085254299306,
            "ave_precision_score": 0.8567008288340235,
            "fpr": 0.24259055982436883,
            "logloss": 0.757096423747036,
            "mae": 0.2978785141448119,
            "precision": 0.663109756097561,
            "recall": 0.9436008676789588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.851107770141837,
            "auditor_fn_violation": 0.010528984733639373,
            "auditor_fp_violation": 0.026006992421387595,
            "ave_precision_score": 0.851389330519887,
            "fpr": 0.23026315789473684,
            "logloss": 1.0174505884748133,
            "mae": 0.29181291182925506,
            "precision": 0.6822995461422088,
            "recall": 0.9148073022312373
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8606336128952348,
            "auditor_fn_violation": 0.00883394329608473,
            "auditor_fp_violation": 0.026432491767288697,
            "ave_precision_score": 0.8608255392017707,
            "fpr": 0.24588364434687157,
            "logloss": 0.9326628583014933,
            "mae": 0.2960007024977998,
            "precision": 0.6569678407350689,
            "recall": 0.93058568329718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8333699670579625,
            "auditor_fn_violation": 0.009939592897049928,
            "auditor_fp_violation": 0.027485554578570538,
            "ave_precision_score": 0.8337392513309975,
            "fpr": 0.19736842105263158,
            "logloss": 1.0116891040724791,
            "mae": 0.28108379384128873,
            "precision": 0.7014925373134329,
            "recall": 0.8580121703853956
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8238788104138275,
            "auditor_fn_violation": 0.014484333442071003,
            "auditor_fp_violation": 0.024149286498353476,
            "ave_precision_score": 0.8241435979246067,
            "fpr": 0.21953896816684962,
            "logloss": 1.0135991898483334,
            "mae": 0.2847134569949369,
            "precision": 0.6683250414593698,
            "recall": 0.8741865509761388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 22571,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8574846627192191,
            "auditor_fn_violation": 0.008500587167716456,
            "auditor_fp_violation": 0.010868086086337563,
            "ave_precision_score": 0.8578187594854841,
            "fpr": 0.10635964912280702,
            "logloss": 0.5408031305398456,
            "mae": 0.2771108185674836,
            "precision": 0.7962184873949579,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8662237714936045,
            "auditor_fn_violation": 0.01799886182617371,
            "auditor_fp_violation": 0.01849005976338579,
            "ave_precision_score": 0.8664239975597543,
            "fpr": 0.1141602634467618,
            "logloss": 0.4872762485063068,
            "mae": 0.266937102449283,
            "precision": 0.7773019271948608,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 22571,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.635169602157257,
            "auditor_fn_violation": 0.0013144550016013978,
            "auditor_fp_violation": 0.006707176652849307,
            "ave_precision_score": 0.6365434587368024,
            "fpr": 0.015350877192982455,
            "logloss": 11.114283586735027,
            "mae": 0.5508530461132721,
            "precision": 0.2222222222222222,
            "recall": 0.008113590263691683
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.6341933867429664,
            "auditor_fn_violation": 0.001404858906924531,
            "auditor_fp_violation": 0.0024393218685205514,
            "ave_precision_score": 0.6354599217443819,
            "fpr": 0.010976948408342482,
            "logloss": 10.268184688281133,
            "mae": 0.5079535086005256,
            "precision": 0.4444444444444444,
            "recall": 0.01735357917570499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 22571,
        "test": {
            "accuracy": 0.45394736842105265,
            "auc_prc": 0.7353682238873687,
            "auditor_fn_violation": 0.00032472154015872004,
            "auditor_fp_violation": 0.0030487166603860487,
            "ave_precision_score": 0.7364832492410169,
            "fpr": 0.008771929824561403,
            "logloss": 7.244479934127703,
            "mae": 0.5465849198038528,
            "precision": 0.2727272727272727,
            "recall": 0.006085192697768763
        },
        "train": {
            "accuracy": 0.4983534577387486,
            "auc_prc": 0.7586350621692493,
            "auditor_fn_violation": 0.002352543389900733,
            "auditor_fp_violation": 0.0005561653860226858,
            "ave_precision_score": 0.759542409797179,
            "fpr": 0.003293084522502744,
            "logloss": 6.613280354388494,
            "mae": 0.5041334867298667,
            "precision": 0.7,
            "recall": 0.015184381778741865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8509728406735155,
            "auditor_fn_violation": 0.012076972349738443,
            "auditor_fp_violation": 0.019305049616882296,
            "ave_precision_score": 0.8512174114950666,
            "fpr": 0.125,
            "logloss": 0.5926630477681492,
            "mae": 0.28169631479321605,
            "precision": 0.7696969696969697,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8636231757089425,
            "auditor_fn_violation": 0.00921015974912554,
            "auditor_fp_violation": 0.023410171972191737,
            "ave_precision_score": 0.8638140369263005,
            "fpr": 0.13062568605927552,
            "logloss": 0.5114975596850683,
            "mae": 0.2657159794200954,
            "precision": 0.7566462167689162,
            "recall": 0.8026030368763557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8233746510772451,
            "auditor_fn_violation": 0.010982705241806341,
            "auditor_fp_violation": 0.019197755725830087,
            "ave_precision_score": 0.8239154727860054,
            "fpr": 0.20942982456140352,
            "logloss": 0.8741943923145593,
            "mae": 0.2802534356766094,
            "precision": 0.6992125984251969,
            "recall": 0.9006085192697769
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8334580956557173,
            "auditor_fn_violation": 0.003912174888266094,
            "auditor_fp_violation": 0.020373216245883657,
            "ave_precision_score": 0.8337644039486238,
            "fpr": 0.23380900109769484,
            "logloss": 0.8450125864021429,
            "mae": 0.2858989782008672,
            "precision": 0.6645669291338583,
            "recall": 0.9154013015184381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8516749708089457,
            "auditor_fn_violation": 0.010669104302337995,
            "auditor_fp_violation": 0.015748649667127256,
            "ave_precision_score": 0.8519536611791331,
            "fpr": 0.11513157894736842,
            "logloss": 0.7338946683151522,
            "mae": 0.281001127581378,
            "precision": 0.7857142857142857,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8651532934511058,
            "auditor_fn_violation": 0.011931776241692883,
            "auditor_fp_violation": 0.020241492864983536,
            "ave_precision_score": 0.8653445177509347,
            "fpr": 0.1251372118551043,
            "logloss": 0.5980853948132397,
            "mae": 0.2657697065555814,
            "precision": 0.7639751552795031,
            "recall": 0.8004338394793926
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.848176103883425,
            "auditor_fn_violation": 0.011727785488060923,
            "auditor_fp_violation": 0.016413348406816568,
            "ave_precision_score": 0.8485248466324207,
            "fpr": 0.11293859649122807,
            "logloss": 0.7478818041377991,
            "mae": 0.28374315666553174,
            "precision": 0.7863070539419087,
            "recall": 0.768762677484787
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.862588190386014,
            "auditor_fn_violation": 0.010067361794028637,
            "auditor_fp_violation": 0.020880595194535917,
            "ave_precision_score": 0.8627870885111716,
            "fpr": 0.12294182217343579,
            "logloss": 0.6045357853871984,
            "mae": 0.2661517728834413,
            "precision": 0.7661795407098121,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.8433626549147504,
            "auditor_fn_violation": 0.003972278566599053,
            "auditor_fp_violation": 0.014236067495708266,
            "ave_precision_score": 0.7959171111648431,
            "fpr": 0.4067982456140351,
            "logloss": 6.731536721228953,
            "mae": 0.4172365110200397,
            "precision": 0.5660818713450292,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8406858389253092,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.7905536401958144,
            "fpr": 0.45115257958287597,
            "logloss": 7.245292593205554,
            "mae": 0.4636981011319205,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.7323557937730834,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.0013293974793786374,
            "ave_precision_score": 0.7334977650303729,
            "fpr": 0.0021929824561403508,
            "logloss": 5.109926117690136,
            "mae": 0.5412227881150186,
            "precision": 0.5,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7822906586828301,
            "auditor_fn_violation": 0.0008405342273633339,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7831173803952093,
            "fpr": 0.0,
            "logloss": 4.635037259960594,
            "mae": 0.5013054016305221,
            "precision": 1.0,
            "recall": 0.010845986984815618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.8433866144364416,
            "auditor_fn_violation": 0.003972278566599053,
            "auditor_fp_violation": 0.015154607880082063,
            "ave_precision_score": 0.8280170056396899,
            "fpr": 0.4057017543859649,
            "logloss": 5.256151581082704,
            "mae": 0.4161746878353105,
            "precision": 0.5667447306791569,
            "recall": 0.9817444219066938
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.8402881647684506,
            "auditor_fn_violation": 0.004833667086536928,
            "auditor_fp_violation": 0.006761800219538982,
            "ave_precision_score": 0.8232972809681333,
            "fpr": 0.45115257958287597,
            "logloss": 5.676247413949471,
            "mae": 0.46296471790280797,
            "precision": 0.522093023255814,
            "recall": 0.9739696312364425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.8201304860309189,
            "auditor_fn_violation": 0.001483488132094943,
            "auditor_fp_violation": 0.007748712473307393,
            "ave_precision_score": 0.673193938054626,
            "fpr": 0.43859649122807015,
            "logloss": 11.093286612571339,
            "mae": 0.4434964502067052,
            "precision": 0.5500562429696289,
            "recall": 0.9918864097363083
        },
        "train": {
            "accuracy": 0.5071350164654226,
            "auc_prc": 0.799002795458527,
            "auditor_fn_violation": 0.0026954242078619716,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.6312680159924787,
            "fpr": 0.4829857299670692,
            "logloss": 12.408944675928348,
            "mae": 0.49275297287607295,
            "precision": 0.5067264573991032,
            "recall": 0.9804772234273319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.8570169101544356,
            "auditor_fn_violation": 0.001483488132094943,
            "auditor_fp_violation": 0.007748712473307393,
            "ave_precision_score": 0.857606565450753,
            "fpr": 0.43859649122807015,
            "logloss": 2.341258214633585,
            "mae": 0.4352189595541731,
            "precision": 0.5500562429696289,
            "recall": 0.9918864097363083
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.862187104536456,
            "auditor_fn_violation": 0.0026049417697888667,
            "auditor_fp_violation": 0.0024393218685205545,
            "ave_precision_score": 0.8623634003323675,
            "fpr": 0.4829857299670692,
            "logloss": 2.526595008526157,
            "mae": 0.4800954182720697,
            "precision": 0.5072788353863382,
            "recall": 0.982646420824295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8295719752214034,
            "auditor_fn_violation": 0.015237447065940716,
            "auditor_fp_violation": 0.020555939371100784,
            "ave_precision_score": 0.8303142243045323,
            "fpr": 0.14473684210526316,
            "logloss": 0.6996710210759806,
            "mae": 0.29548592241646143,
            "precision": 0.7391304347826086,
            "recall": 0.7586206896551724
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8474499416722137,
            "auditor_fn_violation": 0.015065325939171996,
            "auditor_fp_violation": 0.022832052689352372,
            "ave_precision_score": 0.847674593493327,
            "fpr": 0.14270032930845225,
            "logloss": 0.5970239670836615,
            "mae": 0.28398314975720096,
            "precision": 0.7325102880658436,
            "recall": 0.7722342733188721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 22571,
        "test": {
            "accuracy": 0.4298245614035088,
            "auc_prc": 0.5799620466349038,
            "auditor_fn_violation": 0.004399309633109147,
            "auditor_fp_violation": 0.006586798140937069,
            "ave_precision_score": 0.5772559134809319,
            "fpr": 0.07017543859649122,
            "logloss": 5.0698721248048955,
            "mae": 0.5476228547385522,
            "precision": 0.36633663366336633,
            "recall": 0.07505070993914807
        },
        "train": {
            "accuracy": 0.47200878155872666,
            "auc_prc": 0.551081879249309,
            "auditor_fn_violation": 0.0013619988046793855,
            "auditor_fp_violation": 0.013860226856933775,
            "ave_precision_score": 0.5511035676126417,
            "fpr": 0.07354555433589462,
            "logloss": 5.0619655280981934,
            "mae": 0.5082873855974324,
            "precision": 0.41228070175438597,
            "recall": 0.1019522776572668
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8613669829381294,
            "auditor_fn_violation": 0.008989893598092597,
            "auditor_fp_violation": 0.020498367039316675,
            "ave_precision_score": 0.860897363083581,
            "fpr": 0.23026315789473684,
            "logloss": 1.380125743141568,
            "mae": 0.2725779294801948,
            "precision": 0.6827794561933535,
            "recall": 0.9168356997971603
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8416992858053208,
            "auditor_fn_violation": 0.008976810303568582,
            "auditor_fp_violation": 0.025686059275521405,
            "ave_precision_score": 0.8414414719271498,
            "fpr": 0.2349066959385291,
            "logloss": 1.3935209001189606,
            "mae": 0.28269547998685535,
            "precision": 0.6651017214397497,
            "recall": 0.9219088937093276
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8442333685774559,
            "auditor_fn_violation": 0.0067346357780861945,
            "auditor_fp_violation": 0.005814805510195537,
            "ave_precision_score": 0.8445496838555312,
            "fpr": 0.09210526315789473,
            "logloss": 0.6261482730973307,
            "mae": 0.3333596225966814,
            "precision": 0.8077803203661327,
            "recall": 0.716024340770791
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8474652739288614,
            "auditor_fn_violation": 0.01002450169178348,
            "auditor_fp_violation": 0.009718258324185882,
            "ave_precision_score": 0.847702129852924,
            "fpr": 0.09440175631174534,
            "logloss": 0.5574359144487706,
            "mae": 0.3171069650715534,
            "precision": 0.7981220657276995,
            "recall": 0.737527114967462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.789724024112549,
            "auditor_fn_violation": 0.014554642183552194,
            "auditor_fp_violation": 0.011239689318762305,
            "ave_precision_score": 0.7886054997942001,
            "fpr": 0.12938596491228072,
            "logloss": 0.8699693023340606,
            "mae": 0.30819981162662036,
            "precision": 0.766798418972332,
            "recall": 0.7870182555780934
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8076980152963913,
            "auditor_fn_violation": 0.016436849211016957,
            "auditor_fp_violation": 0.007317965605561656,
            "ave_precision_score": 0.8077548245709638,
            "fpr": 0.12294182217343579,
            "logloss": 0.686421503477919,
            "mae": 0.2943247956389144,
            "precision": 0.7651991614255765,
            "recall": 0.7917570498915402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7128193629210063,
            "auditor_fn_violation": 0.006481086082345823,
            "auditor_fp_violation": 0.021228488883306126,
            "ave_precision_score": 0.7136168033550003,
            "fpr": 0.2543859649122807,
            "logloss": 1.157236999827577,
            "mae": 0.3258938066581067,
            "precision": 0.6598240469208211,
            "recall": 0.9127789046653144
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7141070700762059,
            "auditor_fn_violation": 0.005286079276902456,
            "auditor_fp_violation": 0.034335894621295285,
            "ave_precision_score": 0.7151992751109748,
            "fpr": 0.25905598243688255,
            "logloss": 1.0735733982793079,
            "mae": 0.31556644171228965,
            "precision": 0.6467065868263473,
            "recall": 0.9370932754880694
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.8498118327973001,
            "auditor_fn_violation": 0.0028246325753531905,
            "auditor_fp_violation": 0.024758719591341124,
            "ave_precision_score": 0.8501714254169103,
            "fpr": 0.3267543859649123,
            "logloss": 1.0352769819847527,
            "mae": 0.3460920465943178,
            "precision": 0.6134889753566797,
            "recall": 0.9594320486815415
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8604802785845241,
            "auditor_fn_violation": 0.004895576123113263,
            "auditor_fp_violation": 0.027957067935114037,
            "ave_precision_score": 0.8606787202311961,
            "fpr": 0.3413830954994512,
            "logloss": 1.0843954001435043,
            "mae": 0.3627454991547862,
            "precision": 0.5891677675033025,
            "recall": 0.9674620390455532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8821933195068592,
            "auditor_fn_violation": 0.011343012704174229,
            "auditor_fp_violation": 0.011428107859146676,
            "ave_precision_score": 0.8736326216248778,
            "fpr": 0.08771929824561403,
            "logloss": 2.0421904027438265,
            "mae": 0.22249307604026788,
            "precision": 0.8222222222222222,
            "recall": 0.7505070993914807
        },
        "train": {
            "accuracy": 0.8035126234906695,
            "auc_prc": 0.8692443447677968,
            "auditor_fn_violation": 0.009379219041314765,
            "auditor_fp_violation": 0.008674228564459086,
            "ave_precision_score": 0.8535739740621118,
            "fpr": 0.09001097694840834,
            "logloss": 1.9560300598412832,
            "mae": 0.19942675122474335,
            "precision": 0.8161434977578476,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 22571,
        "test": {
            "accuracy": 0.45614035087719296,
            "auc_prc": 0.7467753979872196,
            "auditor_fn_violation": 0.0010364399843422012,
            "auditor_fp_violation": 0.0027216011388853994,
            "ave_precision_score": 0.7478354163205025,
            "fpr": 0.005482456140350877,
            "logloss": 6.147941636597152,
            "mae": 0.544328417014458,
            "precision": 0.2857142857142857,
            "recall": 0.004056795131845842
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.7773206222302034,
            "auditor_fn_violation": 0.002352543389900733,
            "auditor_fp_violation": 0.001092816197097207,
            "ave_precision_score": 0.7781748863781336,
            "fpr": 0.0021953896816684962,
            "logloss": 5.5771154326064,
            "mae": 0.5030085696132077,
            "precision": 0.7777777777777778,
            "recall": 0.015184381778741865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8461959163567071,
            "auditor_fn_violation": 0.010019661222020571,
            "auditor_fp_violation": 0.01882353556923335,
            "ave_precision_score": 0.8465247256882256,
            "fpr": 0.2138157894736842,
            "logloss": 0.8126274414691568,
            "mae": 0.2837910500229874,
            "precision": 0.6953125,
            "recall": 0.9026369168356998
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8445485065024145,
            "auditor_fn_violation": 0.0067957073226484685,
            "auditor_fp_violation": 0.020563483351628248,
            "ave_precision_score": 0.8447961747400695,
            "fpr": 0.2305159165751921,
            "logloss": 0.8060911509025593,
            "mae": 0.29078239159517727,
            "precision": 0.6666666666666666,
            "recall": 0.911062906724512
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8539923908826623,
            "auditor_fn_violation": 0.01724805167075905,
            "auditor_fp_violation": 0.012566469873968932,
            "ave_precision_score": 0.8543373431786574,
            "fpr": 0.11074561403508772,
            "logloss": 0.7223416053943165,
            "mae": 0.2808430935994855,
            "precision": 0.7921810699588477,
            "recall": 0.7809330628803245
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.866824668159625,
            "auditor_fn_violation": 0.01602253488931379,
            "auditor_fp_violation": 0.01905110379314551,
            "ave_precision_score": 0.8670188849958876,
            "fpr": 0.1207464324917673,
            "logloss": 0.5934063415173475,
            "mae": 0.26334348662595825,
            "precision": 0.7679324894514767,
            "recall": 0.789587852494577
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.878206926693072,
            "auditor_fn_violation": 0.013504857478381564,
            "auditor_fp_violation": 0.008785014445421433,
            "ave_precision_score": 0.865727800288848,
            "fpr": 0.08662280701754387,
            "logloss": 2.7309399866031585,
            "mae": 0.22602022981966027,
            "precision": 0.8212669683257918,
            "recall": 0.7363083164300203
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.865258777060458,
            "auditor_fn_violation": 0.010876941503103792,
            "auditor_fp_violation": 0.00951091596536163,
            "ave_precision_score": 0.8419889875324982,
            "fpr": 0.09110867178924259,
            "logloss": 2.581580392072095,
            "mae": 0.2025416379942286,
            "precision": 0.8139013452914798,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8102362564623655,
            "auditor_fn_violation": 0.023193124799829185,
            "auditor_fp_violation": 0.03339980320730227,
            "ave_precision_score": 0.8105807996325817,
            "fpr": 0.14035087719298245,
            "logloss": 1.0610536621091362,
            "mae": 0.2797092663319178,
            "precision": 0.7485265225933202,
            "recall": 0.7728194726166329
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8371338063368443,
            "auditor_fn_violation": 0.02231106433539459,
            "auditor_fp_violation": 0.025478716916697158,
            "ave_precision_score": 0.8374114025135123,
            "fpr": 0.1394072447859495,
            "logloss": 0.832903357622631,
            "mae": 0.2660025740006512,
            "precision": 0.7408163265306122,
            "recall": 0.7874186550976139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 22571,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.8120997442936037,
            "auditor_fn_violation": 0.013298014305540728,
            "auditor_fp_violation": 0.02501779508436963,
            "ave_precision_score": 0.8125427038719025,
            "fpr": 0.3706140350877193,
            "logloss": 1.8800855514258565,
            "mae": 0.3890829100874232,
            "precision": 0.5822002472187886,
            "recall": 0.9553752535496958
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.8132172261187303,
            "auditor_fn_violation": 0.010534060685142546,
            "auditor_fp_violation": 0.027259421880717172,
            "ave_precision_score": 0.8134943212447893,
            "fpr": 0.411635565312843,
            "logloss": 1.92889909821277,
            "mae": 0.4212167926335641,
            "precision": 0.5415647921760391,
            "recall": 0.9609544468546638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 22571,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.6471327181413808,
            "auditor_fn_violation": 0.016716486957759513,
            "auditor_fp_violation": 0.007463467738558807,
            "ave_precision_score": 0.6465352160682003,
            "fpr": 0.043859649122807015,
            "logloss": 9.754579109902172,
            "mae": 0.4779957806459514,
            "precision": 0.7241379310344828,
            "recall": 0.2129817444219067
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6107553026283734,
            "auditor_fn_violation": 0.0067814206219001,
            "auditor_fp_violation": 0.008986461763629714,
            "ave_precision_score": 0.6107971715232917,
            "fpr": 0.052689352360043906,
            "logloss": 9.199207462144058,
            "mae": 0.4505105409957585,
            "precision": 0.6756756756756757,
            "recall": 0.21691973969631237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8202009885843362,
            "auditor_fn_violation": 0.010213159674032952,
            "auditor_fp_violation": 0.018789515554997287,
            "ave_precision_score": 0.8208019253309398,
            "fpr": 0.21162280701754385,
            "logloss": 0.8738437142076043,
            "mae": 0.282794293526005,
            "precision": 0.6979655712050078,
            "recall": 0.9046653144016227
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8327649639689352,
            "auditor_fn_violation": 0.004545551954777831,
            "auditor_fp_violation": 0.021605073789486527,
            "ave_precision_score": 0.8330950835853687,
            "fpr": 0.23161361141602635,
            "logloss": 0.8409978735050985,
            "mae": 0.2879929601360513,
            "precision": 0.6666666666666666,
            "recall": 0.9154013015184381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8544015572339554,
            "auditor_fn_violation": 0.014330006049606775,
            "auditor_fp_violation": 0.018059393711007832,
            "ave_precision_score": 0.8547288683548591,
            "fpr": 0.1118421052631579,
            "logloss": 0.7207768090797503,
            "mae": 0.2787972019487526,
            "precision": 0.7896907216494845,
            "recall": 0.7768762677484787
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8666162099744545,
            "auditor_fn_violation": 0.01681306566405776,
            "auditor_fp_violation": 0.02433711428222954,
            "ave_precision_score": 0.8668136074119505,
            "fpr": 0.11745334796926454,
            "logloss": 0.5929014529898962,
            "mae": 0.26230619393388477,
            "precision": 0.7742616033755274,
            "recall": 0.7960954446854663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 22571,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8493157571254595,
            "auditor_fn_violation": 0.016451816661328784,
            "auditor_fp_violation": 0.009447096260938745,
            "ave_precision_score": 0.849801346880892,
            "fpr": 0.10526315789473684,
            "logloss": 0.9336826463847593,
            "mae": 0.2767958503891016,
            "precision": 0.7913043478260869,
            "recall": 0.7383367139959433
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8537970978621586,
            "auditor_fn_violation": 0.00947684482976206,
            "auditor_fp_violation": 0.02130991584339554,
            "ave_precision_score": 0.8540157295880553,
            "fpr": 0.12184412733260154,
            "logloss": 0.8235977153535996,
            "mae": 0.26553010800457905,
            "precision": 0.7581699346405228,
            "recall": 0.754880694143167
        }
    }
]