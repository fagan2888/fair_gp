[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8023625215883771,
            "auditor_fn_violation": 0.009238911474929497,
            "auditor_fp_violation": 0.021980470807503753,
            "ave_precision_score": 0.803285245425213,
            "fpr": 0.12938596491228072,
            "logloss": 0.9372740158565189,
            "mae": 0.27588046656551735,
            "precision": 0.7536534446764092,
            "recall": 0.7536534446764092
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8465174454169423,
            "auditor_fn_violation": 0.016661852215610378,
            "auditor_fp_violation": 0.018779141783905176,
            "ave_precision_score": 0.846732884558812,
            "fpr": 0.132821075740944,
            "logloss": 0.9047620335484085,
            "mae": 0.2658079264646703,
            "precision": 0.7484407484407485,
            "recall": 0.7578947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8439610761388601,
            "auditor_fn_violation": 0.0008240852653554664,
            "auditor_fp_violation": 0.010324237267533738,
            "ave_precision_score": 0.8442735284977924,
            "fpr": 0.10416666666666667,
            "logloss": 0.5084427238531124,
            "mae": 0.32749269765739436,
            "precision": 0.7850678733031674,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8423078372459407,
            "auditor_fn_violation": 0.003776070252469812,
            "auditor_fp_violation": 0.009151653088147917,
            "ave_precision_score": 0.8430585645583455,
            "fpr": 0.09769484083424808,
            "logloss": 0.502097170057257,
            "mae": 0.3243095956024081,
            "precision": 0.7990970654627539,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7853337315611969,
            "auditor_fn_violation": 0.004058619931875622,
            "auditor_fp_violation": 0.009004902556622505,
            "ave_precision_score": 0.7785105034559984,
            "fpr": 0.06798245614035088,
            "logloss": 0.6604042711817011,
            "mae": 0.35946086552975554,
            "precision": 0.8143712574850299,
            "recall": 0.5678496868475992
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7925524037535104,
            "auditor_fn_violation": 0.0011392916979606075,
            "auditor_fp_violation": 0.007432099014088764,
            "ave_precision_score": 0.7855973994458693,
            "fpr": 0.06037321624588365,
            "logloss": 0.6408826745716761,
            "mae": 0.3551982292895618,
            "precision": 0.8220064724919094,
            "recall": 0.5347368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7679463569182992,
            "auditor_fn_violation": 0.007643390836171857,
            "auditor_fp_violation": 0.013704874194724687,
            "ave_precision_score": 0.7166888066950421,
            "fpr": 0.15460526315789475,
            "logloss": 4.6453633762079924,
            "mae": 0.29729167660325323,
            "precision": 0.7213438735177866,
            "recall": 0.7620041753653445
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7977903041257002,
            "auditor_fn_violation": 0.010655728233866775,
            "auditor_fp_violation": 0.019224765606904407,
            "ave_precision_score": 0.7478624867918389,
            "fpr": 0.1437980241492865,
            "logloss": 4.608616498054274,
            "mae": 0.27834368421197575,
            "precision": 0.738,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8135787785026639,
            "auditor_fn_violation": 0.005789198989122088,
            "auditor_fp_violation": 0.007921072890077388,
            "ave_precision_score": 0.7786362107041727,
            "fpr": 0.09320175438596491,
            "logloss": 0.5478794266171899,
            "mae": 0.3548114243241256,
            "precision": 0.8004694835680751,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8370747981352024,
            "auditor_fn_violation": 0.0011092495233693445,
            "auditor_fp_violation": 0.010118430195671659,
            "ave_precision_score": 0.7851366919864544,
            "fpr": 0.0867178924259056,
            "logloss": 0.5368862209567367,
            "mae": 0.35056627984235367,
            "precision": 0.8119047619047619,
            "recall": 0.7178947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5300061337619832,
            "auditor_fn_violation": 0.001467329597480148,
            "auditor_fp_violation": 0.0006786596977432034,
            "ave_precision_score": 0.5284548139660216,
            "fpr": 0.0010964912280701754,
            "logloss": 17.81984683580889,
            "mae": 0.5230547666014581,
            "precision": 0.8,
            "recall": 0.008350730688935281
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.358741016409248,
            "auditor_fn_violation": 0.0009428620948639562,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5217283774249514,
            "fpr": 0.0,
            "logloss": 17.832228441749905,
            "mae": 0.5209174034503645,
            "precision": 1.0,
            "recall": 0.004210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6658892836519127,
            "auditor_fn_violation": 0.006599549500054939,
            "auditor_fp_violation": 0.007817248085571904,
            "ave_precision_score": 0.667466983973038,
            "fpr": 0.3574561403508772,
            "logloss": 0.6484078308208289,
            "mae": 0.45502104283424843,
            "precision": 0.5564625850340136,
            "recall": 0.8538622129436325
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.689886474088643,
            "auditor_fn_violation": 0.0039863654746085855,
            "auditor_fp_violation": 0.011802737187685685,
            "ave_precision_score": 0.691569307683648,
            "fpr": 0.3556531284302964,
            "logloss": 0.6463839178933604,
            "mae": 0.4534067108196694,
            "precision": 0.5524861878453039,
            "recall": 0.8421052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8464169709462575,
            "auditor_fn_violation": 0.004591986228619568,
            "auditor_fp_violation": 0.004188444552489769,
            "ave_precision_score": 0.846722586145162,
            "fpr": 0.08114035087719298,
            "logloss": 0.5160324796524153,
            "mae": 0.332177029461028,
            "precision": 0.8154613466334164,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8575405396105661,
            "auditor_fn_violation": 0.009994800392859214,
            "auditor_fp_violation": 0.0066289690732031555,
            "ave_precision_score": 0.8577795079336773,
            "fpr": 0.06695938529088913,
            "logloss": 0.49794650748770397,
            "mae": 0.32735334598877425,
            "precision": 0.8419689119170984,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.7736379589607641,
            "auditor_fn_violation": 0.008359887191883679,
            "auditor_fp_violation": 0.02032433856002593,
            "ave_precision_score": 0.7703008137827619,
            "fpr": 0.16557017543859648,
            "logloss": 0.5504216995798884,
            "mae": 0.328925710907737,
            "precision": 0.7322695035460993,
            "recall": 0.8622129436325678
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.7627310976921994,
            "auditor_fn_violation": 0.004638049569588078,
            "auditor_fp_violation": 0.012558031802938602,
            "ave_precision_score": 0.7902664475627573,
            "fpr": 0.141602634467618,
            "logloss": 0.5160745841044087,
            "mae": 0.3171101636866682,
            "precision": 0.7593283582089553,
            "recall": 0.8568421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7976511866127132,
            "auditor_fn_violation": 0.004317291140167753,
            "auditor_fp_violation": 0.011830963089015855,
            "ave_precision_score": 0.6633972046292347,
            "fpr": 0.17105263157894737,
            "logloss": 0.6815917260913349,
            "mae": 0.42878883883863556,
            "precision": 0.7034220532319392,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8121270896240874,
            "auditor_fn_violation": 0.0026344676180021934,
            "auditor_fp_violation": 0.004509108853059953,
            "ave_precision_score": 0.6823940426307928,
            "fpr": 0.15697036223929747,
            "logloss": 0.6573187603477831,
            "mae": 0.4178736074311346,
            "precision": 0.7244701348747592,
            "recall": 0.791578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.6804933770621034,
            "auditor_fn_violation": 0.0049147529575504535,
            "auditor_fp_violation": 0.023515052064341003,
            "ave_precision_score": 0.6763052231575054,
            "fpr": 0.37280701754385964,
            "logloss": 1.5937919619912368,
            "mae": 0.38654090672028824,
            "precision": 0.5765877957658779,
            "recall": 0.9665970772442589
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6888475724136258,
            "auditor_fn_violation": 0.0005869778727829466,
            "auditor_fp_violation": 0.024720792757228178,
            "ave_precision_score": 0.6845074579636028,
            "fpr": 0.38309549945115257,
            "logloss": 1.582514531501246,
            "mae": 0.3900115332033579,
            "precision": 0.5669975186104218,
            "recall": 0.9621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6284794944060926,
            "auditor_fn_violation": 0.015403527084935736,
            "auditor_fp_violation": 0.015396458814472673,
            "ave_precision_score": 0.6070425634222513,
            "fpr": 0.14912280701754385,
            "logloss": 1.0806702938616057,
            "mae": 0.4763976827449177,
            "precision": 0.6136363636363636,
            "recall": 0.4509394572025052
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5705018254342086,
            "auditor_fn_violation": 0.008633658790224753,
            "auditor_fp_violation": 0.024098933524003267,
            "ave_precision_score": 0.5602159878700461,
            "fpr": 0.15587266739846323,
            "logloss": 1.2033571261958573,
            "mae": 0.4968806580305825,
            "precision": 0.5773809523809523,
            "recall": 0.40842105263157896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8389460299075255,
            "auditor_fn_violation": 0.005452697505768602,
            "auditor_fp_violation": 0.00787549126858718,
            "ave_precision_score": 0.838798153420016,
            "fpr": 0.12280701754385964,
            "logloss": 0.5133932799275758,
            "mae": 0.3344078384556301,
            "precision": 0.7676348547717843,
            "recall": 0.7724425887265136
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8413615589058867,
            "auditor_fn_violation": 0.00553931480732567,
            "auditor_fp_violation": 0.012185419792747168,
            "ave_precision_score": 0.8412034239233501,
            "fpr": 0.12184412733260154,
            "logloss": 0.5025252831691845,
            "mae": 0.33171366582063366,
            "precision": 0.7706611570247934,
            "recall": 0.7852631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8284302870233264,
            "auditor_fn_violation": 0.006361480423396696,
            "auditor_fp_violation": 0.01804272517321016,
            "ave_precision_score": 0.824387460368705,
            "fpr": 0.12719298245614036,
            "logloss": 0.5187438793526341,
            "mae": 0.3113415668189542,
            "precision": 0.7647058823529411,
            "recall": 0.7870563674321504
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8541225620861345,
            "auditor_fn_violation": 0.006493731584724716,
            "auditor_fp_violation": 0.0058283567810350585,
            "ave_precision_score": 0.8494759575056265,
            "fpr": 0.10428100987925357,
            "logloss": 0.47432918792017187,
            "mae": 0.29403340533420724,
            "precision": 0.8020833333333334,
            "recall": 0.8105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6381868336435661,
            "auditor_fn_violation": 0.039375251803831085,
            "auditor_fp_violation": 0.08157084396904501,
            "ave_precision_score": 0.6343551940474668,
            "fpr": 0.31140350877192985,
            "logloss": 0.6658459405513467,
            "mae": 0.4701672789330284,
            "precision": 0.5931232091690545,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.656356149709807,
            "auditor_fn_violation": 0.035995147033335256,
            "auditor_fp_violation": 0.0719644709412985,
            "ave_precision_score": 0.6536880307023437,
            "fpr": 0.3358946212952799,
            "logloss": 0.6711232530706002,
            "mae": 0.47290600473562133,
            "precision": 0.5761772853185596,
            "recall": 0.8757894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.8442187737907727,
            "auditor_fn_violation": 0.008423982712522433,
            "auditor_fp_violation": 0.019035391596774857,
            "ave_precision_score": 0.844641201390959,
            "fpr": 0.3673245614035088,
            "logloss": 0.688978782215989,
            "mae": 0.37764897364193756,
            "precision": 0.5743329097839899,
            "recall": 0.9436325678496869
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.848899375119856,
            "auditor_fn_violation": 0.004127332601536773,
            "auditor_fp_violation": 0.023215238824157346,
            "ave_precision_score": 0.8491660090983323,
            "fpr": 0.35236004390779363,
            "logloss": 0.6453982812027554,
            "mae": 0.36280919372949555,
            "precision": 0.5868725868725869,
            "recall": 0.96
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.6935474253301456,
            "auditor_fn_violation": 0.0005677031828004241,
            "auditor_fp_violation": 0.0048265872533527834,
            "ave_precision_score": 0.6944751733275729,
            "fpr": 0.09868421052631579,
            "logloss": 0.6826011083304538,
            "mae": 0.4258035077435667,
            "precision": 0.7794117647058824,
            "recall": 0.6638830897703549
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.6733429490215712,
            "auditor_fn_violation": 0.006683228378300312,
            "auditor_fp_violation": 0.0032729433327626663,
            "ave_precision_score": 0.6977115334745814,
            "fpr": 0.09879253567508232,
            "logloss": 0.6709304905964213,
            "mae": 0.4210343547369855,
            "precision": 0.7815533980582524,
            "recall": 0.6778947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6245725920383363,
            "auditor_fn_violation": 0.015568344138006814,
            "auditor_fp_violation": 0.02536110773469471,
            "ave_precision_score": 0.6132750261219215,
            "fpr": 0.30701754385964913,
            "logloss": 0.6469657468641895,
            "mae": 0.4468121333946392,
            "precision": 0.603399433427762,
            "recall": 0.8893528183716075
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.6031077622105563,
            "auditor_fn_violation": 0.015843780692125487,
            "auditor_fp_violation": 0.020538978237444484,
            "ave_precision_score": 0.6089008512499403,
            "fpr": 0.29527991218441274,
            "logloss": 0.645160647431008,
            "mae": 0.44442704694527563,
            "precision": 0.607871720116618,
            "recall": 0.8778947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.737340358042798,
            "auditor_fn_violation": 0.013675237153426367,
            "auditor_fp_violation": 0.023396033386005433,
            "ave_precision_score": 0.7316895527591945,
            "fpr": 0.17543859649122806,
            "logloss": 0.616278522507685,
            "mae": 0.40972227593965377,
            "precision": 0.6837944664031621,
            "recall": 0.7223382045929019
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7419788187088681,
            "auditor_fn_violation": 0.013687676931076323,
            "auditor_fp_violation": 0.02629432320567176,
            "ave_precision_score": 0.734599785098206,
            "fpr": 0.16794731064763996,
            "logloss": 0.5978050160002267,
            "mae": 0.4122432902749352,
            "precision": 0.697029702970297,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.805053319308184,
            "auditor_fn_violation": 0.013295242281068018,
            "auditor_fp_violation": 0.015733256351039265,
            "ave_precision_score": 0.78829519243073,
            "fpr": 0.1425438596491228,
            "logloss": 0.53710860199064,
            "mae": 0.3337659136915024,
            "precision": 0.7445972495088409,
            "recall": 0.791231732776618
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8357541171658939,
            "auditor_fn_violation": 0.0057080131723380905,
            "auditor_fp_violation": 0.006628969073203151,
            "ave_precision_score": 0.8232770999939258,
            "fpr": 0.11525795828759605,
            "logloss": 0.4859168946184522,
            "mae": 0.31056305104876847,
            "precision": 0.7857142857142857,
            "recall": 0.8105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7481265190719861,
            "auditor_fn_violation": 0.017209647291506425,
            "auditor_fp_violation": 0.013758052753129944,
            "ave_precision_score": 0.6527406652610134,
            "fpr": 0.17324561403508773,
            "logloss": 0.6655779333161845,
            "mae": 0.4618151866741021,
            "precision": 0.6572668112798264,
            "recall": 0.6325678496868476
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7459332739088254,
            "auditor_fn_violation": 0.005839736553238204,
            "auditor_fp_violation": 0.01446389188209348,
            "ave_precision_score": 0.6452728331654152,
            "fpr": 0.17672886937431395,
            "logloss": 0.6614072404946107,
            "mae": 0.45838686487710045,
            "precision": 0.6537634408602151,
            "recall": 0.64
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 8653,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7148278990441019,
            "auditor_fn_violation": 0.07971651466871771,
            "auditor_fp_violation": 0.07616182488553949,
            "ave_precision_score": 0.6899381745948865,
            "fpr": 0.23574561403508773,
            "logloss": 4.583109458357506,
            "mae": 0.3600678150750195,
            "precision": 0.6318493150684932,
            "recall": 0.7703549060542797
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.7351855708569165,
            "auditor_fn_violation": 0.07169218325726501,
            "auditor_fp_violation": 0.07911459329902618,
            "ave_precision_score": 0.7109357989478101,
            "fpr": 0.23380900109769484,
            "logloss": 4.344282800211717,
            "mae": 0.3513221700622706,
            "precision": 0.634020618556701,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8263759554750995,
            "auditor_fn_violation": 0.006803281690656706,
            "auditor_fp_violation": 0.014155625785016819,
            "ave_precision_score": 0.8266372651312439,
            "fpr": 0.07894736842105263,
            "logloss": 0.6044635812281951,
            "mae": 0.36401850082888576,
            "precision": 0.8134715025906736,
            "recall": 0.6555323590814196
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8162196759797388,
            "auditor_fn_violation": 0.010459298630770128,
            "auditor_fp_violation": 0.011505654639019529,
            "ave_precision_score": 0.8167055334155034,
            "fpr": 0.07683863885839737,
            "logloss": 0.595326457158478,
            "mae": 0.3627739020673232,
            "precision": 0.8087431693989071,
            "recall": 0.6231578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6299947185281013,
            "auditor_fn_violation": 0.025363513167051238,
            "auditor_fp_violation": 0.021268891049795395,
            "ave_precision_score": 0.6327478157662882,
            "fpr": 0.19407894736842105,
            "logloss": 4.395432339183092,
            "mae": 0.41804208491415235,
            "precision": 0.6143790849673203,
            "recall": 0.5887265135699373
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.6083750439825736,
            "auditor_fn_violation": 0.014859321740135191,
            "auditor_fp_violation": 0.03438101088631307,
            "ave_precision_score": 0.6102042356313129,
            "fpr": 0.19978046103183314,
            "logloss": 4.816707242442105,
            "mae": 0.4487295472352377,
            "precision": 0.5767441860465117,
            "recall": 0.5221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7827004335639575,
            "auditor_fn_violation": 0.0013482950591510098,
            "auditor_fp_violation": 0.01195504639196144,
            "ave_precision_score": 0.7833637122191122,
            "fpr": 0.18969298245614036,
            "logloss": 0.7367359348812129,
            "mae": 0.3223522477415635,
            "precision": 0.709731543624161,
            "recall": 0.8830897703549061
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8278238054141527,
            "auditor_fn_violation": 0.010322953376855971,
            "auditor_fp_violation": 0.014436197746200877,
            "ave_precision_score": 0.8281197472106994,
            "fpr": 0.18551042810098792,
            "logloss": 0.7082403934852561,
            "mae": 0.315216043454919,
            "precision": 0.707105719237435,
            "recall": 0.8589473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.690413313256976,
            "auditor_fn_violation": 0.01571713731091823,
            "auditor_fp_violation": 0.011696750536850216,
            "ave_precision_score": 0.6908526921088708,
            "fpr": 0.16885964912280702,
            "logloss": 3.800141224696201,
            "mae": 0.43206139541358857,
            "precision": 0.6051282051282051,
            "recall": 0.49269311064718163
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6488775533997944,
            "auditor_fn_violation": 0.010493962678375423,
            "auditor_fp_violation": 0.022759544406288083,
            "ave_precision_score": 0.6494317283186173,
            "fpr": 0.14489571899012074,
            "logloss": 4.240420019205201,
            "mae": 0.44931529809444015,
            "precision": 0.6012084592145015,
            "recall": 0.4189473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7215168080848304,
            "auditor_fn_violation": 0.013970534373512063,
            "auditor_fp_violation": 0.01257799521899437,
            "ave_precision_score": 0.6360098881755967,
            "fpr": 0.10855263157894737,
            "logloss": 0.666256201517363,
            "mae": 0.4640865847468376,
            "precision": 0.6677852348993288,
            "recall": 0.4154488517745303
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.697966145023931,
            "auditor_fn_violation": 0.045294355537581606,
            "auditor_fp_violation": 0.020800813704065505,
            "ave_precision_score": 0.6191810881771822,
            "fpr": 0.1163556531284303,
            "logloss": 0.6833023646719524,
            "mae": 0.4730640882391045,
            "precision": 0.6227758007117438,
            "recall": 0.3684210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7856423178933652,
            "auditor_fn_violation": 0.017131817016445085,
            "auditor_fp_violation": 0.009716482314330864,
            "ave_precision_score": 0.7830420294291148,
            "fpr": 0.11293859649122807,
            "logloss": 0.8912348551932671,
            "mae": 0.334760876055721,
            "precision": 0.7695749440715883,
            "recall": 0.7181628392484343
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7949259346915439,
            "auditor_fn_violation": 0.014087468946790693,
            "auditor_fp_violation": 0.01628163425613552,
            "ave_precision_score": 0.7927549872914166,
            "fpr": 0.10647639956092206,
            "logloss": 0.7960315618254419,
            "mae": 0.33278665228434157,
            "precision": 0.7770114942528735,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8084063910501824,
            "auditor_fn_violation": 0.013611141632787604,
            "auditor_fp_violation": 0.01961022649001256,
            "ave_precision_score": 0.8088164887405072,
            "fpr": 0.12171052631578948,
            "logloss": 0.5880043684895919,
            "mae": 0.3403145351259267,
            "precision": 0.7618025751072961,
            "recall": 0.7411273486430062
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8484572272026568,
            "auditor_fn_violation": 0.011469177884337637,
            "auditor_fp_violation": 0.009405935608616403,
            "ave_precision_score": 0.8487182808120558,
            "fpr": 0.1163556531284303,
            "logloss": 0.5359096589730226,
            "mae": 0.32022275090724656,
            "precision": 0.7695652173913043,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5989214948510702,
            "auditor_fn_violation": 0.0070917115335311165,
            "auditor_fp_violation": 0.0061991005226692585,
            "ave_precision_score": 0.5849049185515247,
            "fpr": 0.05043859649122807,
            "logloss": 0.9853009183493819,
            "mae": 0.49036479587748383,
            "precision": 0.6592592592592592,
            "recall": 0.18580375782881003
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5244041706228816,
            "auditor_fn_violation": 0.010688081344965062,
            "auditor_fp_violation": 0.009733229941892668,
            "ave_precision_score": 0.5215508111786962,
            "fpr": 0.06366630076838639,
            "logloss": 1.0545903135105248,
            "mae": 0.5131053197249754,
            "precision": 0.46296296296296297,
            "recall": 0.10526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7859290207930772,
            "auditor_fn_violation": 0.005310771710068495,
            "auditor_fp_violation": 0.008736477452291249,
            "ave_precision_score": 0.7457796190473749,
            "fpr": 0.17324561403508773,
            "logloss": 0.566009391087776,
            "mae": 0.3521648959926607,
            "precision": 0.7183600713012478,
            "recall": 0.8413361169102297
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8097763492745658,
            "auditor_fn_violation": 0.0014789993644924646,
            "auditor_fp_violation": 0.005790592050272412,
            "ave_precision_score": 0.7713886155407059,
            "fpr": 0.15806805708013172,
            "logloss": 0.5277945454216884,
            "mae": 0.33612410400295883,
            "precision": 0.740072202166065,
            "recall": 0.8631578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.7630092564587069,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.527009588647529,
            "fpr": 0.47478070175438597,
            "logloss": 16.251789048226826,
            "mae": 0.47346111027556553,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7630121816168327,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5260243632336655,
            "fpr": 0.47859495060373214,
            "logloss": 16.23628838069947,
            "mae": 0.4753315105265503,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8326163988196921,
            "auditor_fn_violation": 0.008852049225359851,
            "auditor_fp_violation": 0.007120862201693613,
            "ave_precision_score": 0.8264982340795219,
            "fpr": 0.08771929824561403,
            "logloss": 0.5292760509331412,
            "mae": 0.336215947071507,
            "precision": 0.803921568627451,
            "recall": 0.6847599164926931
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8637054612511831,
            "auditor_fn_violation": 0.002877115951239246,
            "auditor_fp_violation": 0.016342057825355746,
            "ave_precision_score": 0.8584600309116274,
            "fpr": 0.07354555433589462,
            "logloss": 0.4910784780887813,
            "mae": 0.31818722147554873,
            "precision": 0.8353808353808354,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7815785207404172,
            "auditor_fn_violation": 0.00645762370435484,
            "auditor_fp_violation": 0.0021094161500749557,
            "ave_precision_score": 0.781959143149551,
            "fpr": 0.03508771929824561,
            "logloss": 0.75515446638994,
            "mae": 0.3752155223092702,
            "precision": 0.8704453441295547,
            "recall": 0.4488517745302714
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8017083792787606,
            "auditor_fn_violation": 0.008039748107920736,
            "auditor_fp_violation": 0.003222590358412472,
            "ave_precision_score": 0.8031972086078742,
            "fpr": 0.026344676180021953,
            "logloss": 0.701476878640767,
            "mae": 0.36323983355053563,
            "precision": 0.8991596638655462,
            "recall": 0.45052631578947366
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8309819403421748,
            "auditor_fn_violation": 0.00825000915650295,
            "auditor_fp_violation": 0.007743811028726556,
            "ave_precision_score": 0.8231915993444374,
            "fpr": 0.1206140350877193,
            "logloss": 0.5262305392168022,
            "mae": 0.35498173275080164,
            "precision": 0.7644539614561028,
            "recall": 0.7453027139874739
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8141564665255058,
            "auditor_fn_violation": 0.0016476977295048882,
            "auditor_fp_violation": 0.01222821982094483,
            "ave_precision_score": 0.8126944866850281,
            "fpr": 0.13062568605927552,
            "logloss": 0.5364371689641922,
            "mae": 0.36150634444178653,
            "precision": 0.7440860215053764,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7785754833778086,
            "auditor_fn_violation": 0.0018610592242610728,
            "auditor_fp_violation": 0.004373303350755643,
            "ave_precision_score": 0.7527349900913647,
            "fpr": 0.051535087719298246,
            "logloss": 0.7945563972335073,
            "mae": 0.369291684640294,
            "precision": 0.8517350157728707,
            "recall": 0.5636743215031316
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7912824404246721,
            "auditor_fn_violation": 0.008074412155526026,
            "auditor_fp_violation": 0.009990030111078664,
            "ave_precision_score": 0.7558262439770355,
            "fpr": 0.050493962678375415,
            "logloss": 0.6933869835926341,
            "mae": 0.36536109089256985,
            "precision": 0.853035143769968,
            "recall": 0.5621052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.780937207157696,
            "auditor_fn_violation": 0.008433139215470828,
            "auditor_fp_violation": 0.011489100927839235,
            "ave_precision_score": 0.7813749306703055,
            "fpr": 0.3607456140350877,
            "logloss": 1.0592689777179862,
            "mae": 0.3873812924889774,
            "precision": 0.5824873096446701,
            "recall": 0.9582463465553236
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.8387487378659368,
            "auditor_fn_violation": 0.005181119648737651,
            "auditor_fp_violation": 0.012608384777288815,
            "ave_precision_score": 0.8389733354473037,
            "fpr": 0.3578485181119649,
            "logloss": 0.9485394946794949,
            "mae": 0.371496991613475,
            "precision": 0.5831202046035806,
            "recall": 0.96
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.6417455833189581,
            "auditor_fn_violation": 0.015460755228363194,
            "auditor_fp_violation": 0.026381629593614526,
            "ave_precision_score": 0.6428337616097505,
            "fpr": 0.12280701754385964,
            "logloss": 0.6707198938646074,
            "mae": 0.46521032392047346,
            "precision": 0.6410256410256411,
            "recall": 0.4175365344467641
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6056376497956673,
            "auditor_fn_violation": 0.017359755040730243,
            "auditor_fp_violation": 0.02417949828296358,
            "ave_precision_score": 0.6068609146474746,
            "fpr": 0.13611416026344675,
            "logloss": 0.6753417048978351,
            "mae": 0.46688421486859527,
            "precision": 0.5894039735099338,
            "recall": 0.37473684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.5592531054261902,
            "auditor_fn_violation": 0.004031150423030437,
            "auditor_fp_violation": 0.0010433126696649348,
            "ave_precision_score": 0.5604621674058918,
            "fpr": 0.4725877192982456,
            "logloss": 0.7490067126580133,
            "mae": 0.49352237693311873,
            "precision": 0.5195094760312151,
            "recall": 0.9728601252609603
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6135104437561342,
            "auditor_fn_violation": 0.002592870760875845,
            "auditor_fp_violation": 0.0018026364817369744,
            "ave_precision_score": 0.6144679827700491,
            "fpr": 0.47200878155872666,
            "logloss": 0.7356557532373355,
            "mae": 0.48670244534243345,
            "precision": 0.5211581291759465,
            "recall": 0.9852631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6785397075273188,
            "auditor_fn_violation": 0.020018404570926275,
            "auditor_fp_violation": 0.03673118998419839,
            "ave_precision_score": 0.665686197929086,
            "fpr": 0.34539473684210525,
            "logloss": 0.6552187705266428,
            "mae": 0.45251016923340787,
            "precision": 0.5777479892761395,
            "recall": 0.8997912317327766
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6761888075645778,
            "auditor_fn_violation": 0.02367554451441447,
            "auditor_fp_violation": 0.02826815980019941,
            "ave_precision_score": 0.6725013413835004,
            "fpr": 0.3534577387486279,
            "logloss": 0.6511627251933508,
            "mae": 0.4519502743751498,
            "precision": 0.5672043010752689,
            "recall": 0.888421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8482129679983182,
            "auditor_fn_violation": 0.004852946562648793,
            "auditor_fp_violation": 0.009794983995786233,
            "ave_precision_score": 0.8214168103223662,
            "fpr": 0.09210526315789473,
            "logloss": 0.5189593950285506,
            "mae": 0.31191954784618137,
            "precision": 0.8068965517241379,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.8068057080131723,
            "auc_prc": 0.8762167588300728,
            "auditor_fn_violation": 0.011288924836790117,
            "auditor_fp_violation": 0.007109839978247519,
            "ave_precision_score": 0.8535044002303404,
            "fpr": 0.07793633369923161,
            "logloss": 0.47478320844218813,
            "mae": 0.2908292770872361,
            "precision": 0.8390022675736961,
            "recall": 0.7789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6177949272477706,
            "auditor_fn_violation": 0.0064530454528806585,
            "auditor_fp_violation": 0.012251326931647828,
            "ave_precision_score": 0.5928810206342401,
            "fpr": 0.1699561403508772,
            "logloss": 0.7151906855373816,
            "mae": 0.4819373095963608,
            "precision": 0.6035805626598465,
            "recall": 0.49269311064718163
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5511598576327399,
            "auditor_fn_violation": 0.009696689583453696,
            "auditor_fp_violation": 0.007918005216568148,
            "ave_precision_score": 0.5547261607687788,
            "fpr": 0.18551042810098792,
            "logloss": 0.7359384316571425,
            "mae": 0.4931707737801758,
            "precision": 0.5564304461942258,
            "recall": 0.4463157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8442900748153319,
            "auditor_fn_violation": 0.0035687470241365414,
            "auditor_fp_violation": 0.0032312305011952527,
            "ave_precision_score": 0.8441222291776646,
            "fpr": 0.09649122807017543,
            "logloss": 0.5045450776286375,
            "mae": 0.3283360535503578,
            "precision": 0.7995444191343963,
            "recall": 0.732776617954071
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8475291927059408,
            "auditor_fn_violation": 0.00018949679357560257,
            "auditor_fp_violation": 0.012399419933735485,
            "ave_precision_score": 0.8473497960923702,
            "fpr": 0.09549945115257959,
            "logloss": 0.49960221235289354,
            "mae": 0.327709460614656,
            "precision": 0.8004587155963303,
            "recall": 0.7347368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.836292598831602,
            "auditor_fn_violation": 0.0005127641651100716,
            "auditor_fp_violation": 0.009974778169442082,
            "ave_precision_score": 0.7360449445761219,
            "fpr": 0.09758771929824561,
            "logloss": 0.551711943690125,
            "mae": 0.34378971306509093,
            "precision": 0.7958715596330275,
            "recall": 0.7244258872651357
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8446589108343074,
            "auditor_fn_violation": 0.007376509330406149,
            "auditor_fp_violation": 0.006661698506530786,
            "ave_precision_score": 0.7509275952290009,
            "fpr": 0.09001097694840834,
            "logloss": 0.5382600668519443,
            "mae": 0.3384565016996978,
            "precision": 0.8066037735849056,
            "recall": 0.72
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 8653,
        "test": {
            "accuracy": 0.46381578947368424,
            "auc_prc": 0.49435247934600374,
            "auditor_fn_violation": 0.0034405559828590226,
            "auditor_fp_violation": 0.005416616020420567,
            "ave_precision_score": 0.5074606387555295,
            "fpr": 0.02412280701754386,
            "logloss": 1.074456569242438,
            "mae": 0.5300051103256185,
            "precision": 0.35294117647058826,
            "recall": 0.025052192066805846
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.49706082107680655,
            "auditor_fn_violation": 0.0011000057773412708,
            "auditor_fp_violation": 0.0031495785456046896,
            "ave_precision_score": 0.5110639251749933,
            "fpr": 0.025246981339187707,
            "logloss": 1.0616452457002425,
            "mae": 0.5242300049640017,
            "precision": 0.34285714285714286,
            "recall": 0.02526315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.6525879773978498,
            "auditor_fn_violation": 0.0124253745009706,
            "auditor_fp_violation": 0.017718589198168638,
            "ave_precision_score": 0.6552252340296755,
            "fpr": 0.15789473684210525,
            "logloss": 0.8787573900502399,
            "mae": 0.3830289642751348,
            "precision": 0.6876355748373102,
            "recall": 0.6617954070981211
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.653248704903563,
            "auditor_fn_violation": 0.011078629614651347,
            "auditor_fp_violation": 0.02249015599351455,
            "ave_precision_score": 0.6594514730866603,
            "fpr": 0.16136114160263446,
            "logloss": 0.9980204233888412,
            "mae": 0.3740709825888129,
            "precision": 0.6924686192468619,
            "recall": 0.6968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7622181021391258,
            "auditor_fn_violation": 0.0012910669157235473,
            "auditor_fp_violation": 0.0034819294193914442,
            "ave_precision_score": 0.5397929738999109,
            "fpr": 0.43201754385964913,
            "logloss": 0.6847356522247482,
            "mae": 0.4930369199106568,
            "precision": 0.5402567094515752,
            "recall": 0.9665970772442589
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7592985569045692,
            "auditor_fn_violation": 0.003549598474781906,
            "auditor_fp_violation": 0.003685837722434278,
            "ave_precision_score": 0.5294887264022649,
            "fpr": 0.4522502744237102,
            "logloss": 0.688743324783727,
            "mae": 0.49578561050700826,
            "precision": 0.5296803652968036,
            "recall": 0.9768421052631578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.568379762365923,
            "auditor_fn_violation": 0.012626817565835256,
            "auditor_fp_violation": 0.022264089785665103,
            "ave_precision_score": 0.5502012688025721,
            "fpr": 0.40899122807017546,
            "logloss": 0.6868069917119226,
            "mae": 0.48734878805024845,
            "precision": 0.5456760048721072,
            "recall": 0.9352818371607515
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5878734308886882,
            "auditor_fn_violation": 0.009784505170720435,
            "auditor_fp_violation": 0.013252902848971291,
            "ave_precision_score": 0.5685497002543345,
            "fpr": 0.3907793633369923,
            "logloss": 0.6671672416763006,
            "mae": 0.47652153731308444,
            "precision": 0.5577639751552795,
            "recall": 0.9452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.763011671760687,
            "auditor_fn_violation": 0.0006226422004907885,
            "auditor_fp_violation": 0.0021474008346501518,
            "ave_precision_score": 0.5270120038176959,
            "fpr": 0.47039473684210525,
            "logloss": 16.26057306200789,
            "mae": 0.4714912769945332,
            "precision": 0.5270121278941565,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7630121816168327,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0038167554557447846,
            "ave_precision_score": 0.5260243632336655,
            "fpr": 0.4698133918770582,
            "logloss": 16.227155422626325,
            "mae": 0.46981346354554865,
            "precision": 0.5260243632336655,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7213924922934078,
            "auditor_fn_violation": 0.02235560194850383,
            "auditor_fp_violation": 0.015735788663344272,
            "ave_precision_score": 0.7521181227855889,
            "fpr": 0.1162280701754386,
            "logloss": 0.5785820582216072,
            "mae": 0.37223357334324536,
            "precision": 0.7725321888412017,
            "recall": 0.7515657620041754
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7364516191809439,
            "auditor_fn_violation": 0.018328037437171416,
            "auditor_fp_violation": 0.02119608455271453,
            "ave_precision_score": 0.7363794836823973,
            "fpr": 0.11745334796926454,
            "logloss": 0.5941176387049768,
            "mae": 0.37554585681788616,
            "precision": 0.7663755458515283,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7526334679426241,
            "auditor_fn_violation": 0.014728234992491668,
            "auditor_fp_violation": 0.010045682913982432,
            "ave_precision_score": 0.5307889801399994,
            "fpr": 0.4418859649122807,
            "logloss": 0.692598042868728,
            "mae": 0.49663054639179455,
            "precision": 0.5297549591598599,
            "recall": 0.9478079331941545
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.7571556727036575,
            "auditor_fn_violation": 0.004504015252180946,
            "auditor_fp_violation": 0.007366640147433523,
            "ave_precision_score": 0.5322085132692331,
            "fpr": 0.4489571899012075,
            "logloss": 0.692500969982639,
            "mae": 0.4965627716872616,
            "precision": 0.5277136258660509,
            "recall": 0.9621052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6388668376704145,
            "auditor_fn_violation": 0.0006226422004907885,
            "auditor_fp_violation": 0.0026589279202625517,
            "ave_precision_score": 0.6403608911020047,
            "fpr": 0.4692982456140351,
            "logloss": 0.7344382538328754,
            "mae": 0.46823737752346095,
            "precision": 0.5275938189845475,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6357765702416229,
            "auditor_fn_violation": 0.0005985325553180426,
            "auditor_fp_violation": 0.0038872496198350446,
            "ave_precision_score": 0.6377850778334726,
            "fpr": 0.4676180021953897,
            "logloss": 0.7305903649778568,
            "mae": 0.46600368130710856,
            "precision": 0.5266666666666666,
            "recall": 0.9978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.6015609180580176,
            "auditor_fn_violation": 0.007029905138629459,
            "auditor_fp_violation": 0.012046209634941858,
            "ave_precision_score": 0.612772749693357,
            "fpr": 0.03837719298245614,
            "logloss": 0.9751949571186607,
            "mae": 0.47920833292760345,
            "precision": 0.38596491228070173,
            "recall": 0.04592901878914405
        },
        "train": {
            "accuracy": 0.4489571899012075,
            "auc_prc": 0.549822429687509,
            "auditor_fn_violation": 0.0032722860939395763,
            "auditor_fp_violation": 0.005584144855436613,
            "ave_precision_score": 0.5690442216121213,
            "fpr": 0.04939626783754116,
            "logloss": 1.0233279652695064,
            "mae": 0.49240714082602743,
            "precision": 0.2857142857142857,
            "recall": 0.037894736842105266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4298245614035088,
            "auc_prc": 0.41106418223701596,
            "auditor_fn_violation": 0.0008103505109328718,
            "auditor_fp_violation": 0.01789585105951947,
            "ave_precision_score": 0.5407107754291998,
            "fpr": 0.05592105263157895,
            "logloss": 0.9794259567870266,
            "mae": 0.5105216807334504,
            "precision": 0.16393442622950818,
            "recall": 0.020876826722338204
        },
        "train": {
            "accuracy": 0.45773874862788144,
            "auc_prc": 0.46808691117540674,
            "auditor_fn_violation": 0.00685192674331272,
            "auditor_fp_violation": 0.009232217847108228,
            "ave_precision_score": 0.5370806253006777,
            "fpr": 0.042810098792535674,
            "logloss": 0.9531261265488354,
            "mae": 0.5028577668257017,
            "precision": 0.3389830508474576,
            "recall": 0.042105263157894736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7894736842105263,
            "auc_prc": 0.8614421052594559,
            "auditor_fn_violation": 0.005006317987034396,
            "auditor_fp_violation": 0.009772193185041127,
            "ave_precision_score": 0.86200080598018,
            "fpr": 0.08333333333333333,
            "logloss": 0.4753550114599599,
            "mae": 0.29916218033825936,
            "precision": 0.826879271070615,
            "recall": 0.7578288100208769
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.867280018959341,
            "auditor_fn_violation": 0.0088185337107863,
            "auditor_fp_violation": 0.009957300677751035,
            "ave_precision_score": 0.8685166477789965,
            "fpr": 0.09110867178924259,
            "logloss": 0.47055745919058883,
            "mae": 0.2954269088439566,
            "precision": 0.8100686498855835,
            "recall": 0.7452631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8017554387932098,
            "auditor_fn_violation": 0.0042943998827967645,
            "auditor_fp_violation": 0.00247153680969167,
            "ave_precision_score": 0.7714004801529998,
            "fpr": 0.07785087719298246,
            "logloss": 0.567846976868845,
            "mae": 0.3947146775021234,
            "precision": 0.8,
            "recall": 0.592901878914405
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7989986513193446,
            "auditor_fn_violation": 0.0038477092841874157,
            "auditor_fp_violation": 0.004224614547981353,
            "ave_precision_score": 0.7653672678554221,
            "fpr": 0.0801317233809001,
            "logloss": 0.5774870853318056,
            "mae": 0.3995215069629358,
            "precision": 0.7955182072829131,
            "recall": 0.5978947368421053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.5519483810509813,
            "auditor_fn_violation": 0.0006226422004907972,
            "auditor_fp_violation": 0.002147400834650136,
            "ave_precision_score": 0.5526656308956541,
            "fpr": 0.0043859649122807015,
            "logloss": 0.8375343663517427,
            "mae": 0.4946897101768276,
            "precision": 0.2,
            "recall": 0.0020876826722338203
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.5162282744298932,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003816755455744771,
            "ave_precision_score": 0.5179331284250033,
            "fpr": 0.008781558726673985,
            "logloss": 0.9993130763311655,
            "mae": 0.502786524732864,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.8510382225475767,
            "auditor_fn_violation": 0.0029438156979086564,
            "auditor_fp_violation": 0.01441392164012804,
            "ave_precision_score": 0.8517602387838474,
            "fpr": 0.26973684210526316,
            "logloss": 0.5979713671189396,
            "mae": 0.343812469497176,
            "precision": 0.6429608127721336,
            "recall": 0.9248434237995825
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8646720735513762,
            "auditor_fn_violation": 0.007607602981108093,
            "auditor_fp_violation": 0.018630600509572104,
            "ave_precision_score": 0.864867924027207,
            "fpr": 0.25686059275521406,
            "logloss": 0.5883989182844285,
            "mae": 0.340147051054465,
            "precision": 0.654357459379616,
            "recall": 0.9326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5465874800051097,
            "auditor_fn_violation": 0.0027881551477859593,
            "auditor_fp_violation": 0.0026538632956525287,
            "ave_precision_score": 0.5453956892809837,
            "fpr": 0.3081140350877193,
            "logloss": 1.2669094701283425,
            "mae": 0.4718024356356054,
            "precision": 0.5716463414634146,
            "recall": 0.7828810020876826
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.5544904151502738,
            "auditor_fn_violation": 0.01068808134496505,
            "auditor_fp_violation": 0.003836896645484848,
            "ave_precision_score": 0.5548562057021151,
            "fpr": 0.30735455543358947,
            "logloss": 1.208322936977524,
            "mae": 0.467279467621305,
            "precision": 0.573820395738204,
            "recall": 0.7936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.708062122866561,
            "auditor_fn_violation": 0.022044280848258425,
            "auditor_fp_violation": 0.0036439974069121996,
            "ave_precision_score": 0.705427197755101,
            "fpr": 0.01864035087719298,
            "logloss": 0.9519676417551708,
            "mae": 0.46065140231262314,
            "precision": 0.7951807228915663,
            "recall": 0.13778705636743216
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6900006875046725,
            "auditor_fn_violation": 0.023155583800335087,
            "auditor_fp_violation": 0.005080615111934663,
            "ave_precision_score": 0.689877661832886,
            "fpr": 0.019758507135016465,
            "logloss": 0.9462670825452054,
            "mae": 0.4602132837814542,
            "precision": 0.7954545454545454,
            "recall": 0.14736842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8518798405372625,
            "auditor_fn_violation": 0.003896092004541633,
            "auditor_fp_violation": 0.0054267452696406164,
            "ave_precision_score": 0.8522285404702687,
            "fpr": 0.11074561403508772,
            "logloss": 0.4991093247116345,
            "mae": 0.3327619937113731,
            "precision": 0.7818574514038877,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8534397237180567,
            "auditor_fn_violation": 0.0008319371425270091,
            "auditor_fp_violation": 0.009008147111249866,
            "ave_precision_score": 0.853668692724494,
            "fpr": 0.11086717892425905,
            "logloss": 0.4978781329483904,
            "mae": 0.3315390233281677,
            "precision": 0.7827956989247312,
            "recall": 0.7663157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6260966115844182,
            "auditor_fn_violation": 0.05828800864373879,
            "auditor_fp_violation": 0.02564472671285604,
            "ave_precision_score": 0.6128757782394418,
            "fpr": 0.20175438596491227,
            "logloss": 0.8296787844840936,
            "mae": 0.4576973135164352,
            "precision": 0.599128540305011,
            "recall": 0.5741127348643006
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.648279412224188,
            "auditor_fn_violation": 0.05245825870934196,
            "auditor_fp_violation": 0.02983917259992548,
            "ave_precision_score": 0.6295723209618982,
            "fpr": 0.19978046103183314,
            "logloss": 0.8069914506999971,
            "mae": 0.44112211448886024,
            "precision": 0.614406779661017,
            "recall": 0.6105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8129768249985734,
            "auditor_fn_violation": 0.006670512397904991,
            "auditor_fp_violation": 0.01142832543251894,
            "ave_precision_score": 0.8096736728570935,
            "fpr": 0.12171052631578948,
            "logloss": 0.5125874565295296,
            "mae": 0.32747206740947277,
            "precision": 0.7753036437246964,
            "recall": 0.7995824634655533
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8540300150050801,
            "auditor_fn_violation": 0.005382171124848345,
            "auditor_fp_violation": 0.009697982859847536,
            "ave_precision_score": 0.8447572418617975,
            "fpr": 0.10976948408342481,
            "logloss": 0.4828196303038979,
            "mae": 0.31343140938492037,
            "precision": 0.7942386831275721,
            "recall": 0.8126315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.7630104682249965,
            "auditor_fn_violation": 0.0006226422004907885,
            "auditor_fp_violation": 0.0021474008346501518,
            "ave_precision_score": 0.527008385034765,
            "fpr": 0.47039473684210525,
            "logloss": 0.6957633602451012,
            "mae": 0.4967128325329931,
            "precision": 0.5270121278941565,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7630121816168327,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0038167554557447846,
            "ave_precision_score": 0.5260243632336655,
            "fpr": 0.4698133918770582,
            "logloss": 0.6857658860000801,
            "mae": 0.49403651575297197,
            "precision": 0.5260243632336655,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5608986930609262,
            "auditor_fn_violation": 0.05000366260117936,
            "auditor_fp_violation": 0.04731372310684333,
            "ave_precision_score": 0.5622880883802603,
            "fpr": 0.35635964912280704,
            "logloss": 0.6897854211662621,
            "mae": 0.489742627922903,
            "precision": 0.5473537604456824,
            "recall": 0.8204592901878914
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5294607413277341,
            "auditor_fn_violation": 0.050279045583222604,
            "auditor_fp_violation": 0.05049899797581044,
            "ave_precision_score": 0.5315563732245681,
            "fpr": 0.35236004390779363,
            "logloss": 0.6953007048114586,
            "mae": 0.49286624471913576,
            "precision": 0.5472496473906912,
            "recall": 0.8168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7795308397939966,
            "auditor_fn_violation": 0.04453036296377688,
            "auditor_fp_violation": 0.05426492038410114,
            "ave_precision_score": 0.7805837615136084,
            "fpr": 0.2532894736842105,
            "logloss": 1.9247631903874598,
            "mae": 0.35833975263168494,
            "precision": 0.6339144215530903,
            "recall": 0.8350730688935282
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8103252345438525,
            "auditor_fn_violation": 0.042840140967126926,
            "auditor_fp_violation": 0.05795627347707429,
            "ave_precision_score": 0.8106499805837735,
            "fpr": 0.24588364434687157,
            "logloss": 1.6780118692563704,
            "mae": 0.3461258312276206,
            "precision": 0.643312101910828,
            "recall": 0.8505263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7859853342636098,
            "auditor_fn_violation": 0.005310771710068495,
            "auditor_fp_violation": 0.008736477452291249,
            "ave_precision_score": 0.766553444790776,
            "fpr": 0.17324561403508773,
            "logloss": 0.5481904000647709,
            "mae": 0.3458669489298604,
            "precision": 0.7183600713012478,
            "recall": 0.8413361169102297
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8233958394490032,
            "auditor_fn_violation": 0.00279854411000058,
            "auditor_fp_violation": 0.005790592050272412,
            "ave_precision_score": 0.8065178410844476,
            "fpr": 0.15806805708013172,
            "logloss": 0.5022282998505541,
            "mae": 0.32796668245750515,
            "precision": 0.7405405405405405,
            "recall": 0.8652631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7108969746541121,
            "auditor_fn_violation": 0.024406658608944073,
            "auditor_fp_violation": 0.029888882136056075,
            "ave_precision_score": 0.711763345532444,
            "fpr": 0.20723684210526316,
            "logloss": 0.6425575014228456,
            "mae": 0.3965596793211278,
            "precision": 0.6741379310344827,
            "recall": 0.8162839248434238
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.702570062428681,
            "auditor_fn_violation": 0.025207695418568377,
            "auditor_fp_violation": 0.02944641939999397,
            "ave_precision_score": 0.7041661843048568,
            "fpr": 0.21734357848518113,
            "logloss": 0.6712423949961853,
            "mae": 0.40613545846239013,
            "precision": 0.6507936507936508,
            "recall": 0.7768421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7299686737956437,
            "auditor_fn_violation": 0.012489470021609347,
            "auditor_fp_violation": 0.024006320651513313,
            "ave_precision_score": 0.7301521825096899,
            "fpr": 0.15460526315789475,
            "logloss": 1.2085707482563457,
            "mae": 0.33060018747160014,
            "precision": 0.6987179487179487,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7654891455940819,
            "auditor_fn_violation": 0.014889363914726447,
            "auditor_fp_violation": 0.026223829041581492,
            "ave_precision_score": 0.7649969907286086,
            "fpr": 0.15806805708013172,
            "logloss": 1.1859477291720188,
            "mae": 0.3115557362691205,
            "precision": 0.6974789915966386,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7790483333469866,
            "auditor_fn_violation": 0.0331534080503974,
            "auditor_fp_violation": 0.03823031886876545,
            "ave_precision_score": 0.7524519669760249,
            "fpr": 0.20065789473684212,
            "logloss": 0.6078226538044698,
            "mae": 0.4319326764609861,
            "precision": 0.6672727272727272,
            "recall": 0.7661795407098121
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7743424709589827,
            "auditor_fn_violation": 0.022369865387948468,
            "auditor_fp_violation": 0.020292248663128534,
            "ave_precision_score": 0.7482847822741687,
            "fpr": 0.19538968166849616,
            "logloss": 0.6037674850641898,
            "mae": 0.43096731139426697,
            "precision": 0.6763636363636364,
            "recall": 0.783157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.586263136883447,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5730255258873925,
            "fpr": 0.47478070175438597,
            "logloss": 0.6922998403036518,
            "mae": 0.49947936519196157,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5227045160656079,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5190006836045371,
            "fpr": 0.47859495060373214,
            "logloss": 0.6925090529096386,
            "mae": 0.49958451224734307,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7517603575831018,
            "auditor_fn_violation": 0.01639242940336227,
            "auditor_fp_violation": 0.021947550747538597,
            "ave_precision_score": 0.7344063716462136,
            "fpr": 0.14912280701754385,
            "logloss": 0.5958689374292762,
            "mae": 0.41021396510564445,
            "precision": 0.7056277056277056,
            "recall": 0.6805845511482255
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6670899726655408,
            "auditor_fn_violation": 0.0196429603096655,
            "auditor_fp_violation": 0.026359782072327018,
            "ave_precision_score": 0.7142861278719077,
            "fpr": 0.15148188803512624,
            "logloss": 0.5983809970990485,
            "mae": 0.41061418869918054,
            "precision": 0.7019438444924406,
            "recall": 0.6842105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8144585031965432,
            "auditor_fn_violation": 0.005821246749441455,
            "auditor_fp_violation": 0.007057554394068312,
            "ave_precision_score": 0.8065308623213445,
            "fpr": 0.1875,
            "logloss": 0.530628095833351,
            "mae": 0.32601946763890355,
            "precision": 0.7096774193548387,
            "recall": 0.872651356993737
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8372438962159074,
            "auditor_fn_violation": 0.009953203535732856,
            "auditor_fp_violation": 0.012336478715797745,
            "ave_precision_score": 0.8235238330800818,
            "fpr": 0.18660812294182216,
            "logloss": 0.5323340200241856,
            "mae": 0.3279781235641627,
            "precision": 0.7084048027444254,
            "recall": 0.8694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7535661079958665,
            "auditor_fn_violation": 0.015451598725414796,
            "auditor_fp_violation": 0.01310471617843686,
            "ave_precision_score": 0.7541355921795694,
            "fpr": 0.15350877192982457,
            "logloss": 0.6773828339736064,
            "mae": 0.3502965321812346,
            "precision": 0.6989247311827957,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7840187598267344,
            "auditor_fn_violation": 0.01761626899300942,
            "auditor_fp_violation": 0.01864570640187717,
            "ave_precision_score": 0.7845998178294324,
            "fpr": 0.1394072447859495,
            "logloss": 0.6268630217462653,
            "mae": 0.3301271206643596,
            "precision": 0.7196467991169978,
            "recall": 0.6863157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5948873946255474,
            "auditor_fn_violation": 0.0011949236347654107,
            "auditor_fp_violation": 0.0012712207771160128,
            "ave_precision_score": 0.5399518756215393,
            "fpr": 0.4725877192982456,
            "logloss": 0.7384402175890382,
            "mae": 0.4937510389769286,
            "precision": 0.525330396475771,
            "recall": 0.9958246346555324
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6071666307149817,
            "auditor_fn_violation": 0.0007394996822462306,
            "auditor_fp_violation": 0.0010825889485291886,
            "ave_precision_score": 0.5373949308688375,
            "fpr": 0.47639956092206365,
            "logloss": 0.7293755886156947,
            "mae": 0.49083389840717506,
            "precision": 0.5209713024282561,
            "recall": 0.9936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7652404506355949,
            "auditor_fn_violation": 0.02002069369666338,
            "auditor_fp_violation": 0.016860135326769582,
            "ave_precision_score": 0.7271879734671511,
            "fpr": 0.13706140350877194,
            "logloss": 3.9978546094638596,
            "mae": 0.3042986237880905,
            "precision": 0.7340425531914894,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7917330117621147,
            "auditor_fn_violation": 0.013361834883586571,
            "auditor_fp_violation": 0.02299116808829898,
            "ave_precision_score": 0.7534560201025532,
            "fpr": 0.14270032930845225,
            "logloss": 4.193455709225717,
            "mae": 0.28739956642408715,
            "precision": 0.7308488612836439,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8385603722996187,
            "auditor_fn_violation": 0.0051161960224151235,
            "auditor_fp_violation": 0.0063231838256148495,
            "ave_precision_score": 0.8391849157148137,
            "fpr": 0.08662280701754387,
            "logloss": 0.5236389662772337,
            "mae": 0.3082126305518231,
            "precision": 0.808252427184466,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8590960792594708,
            "auditor_fn_violation": 0.0067525564735109,
            "auditor_fp_violation": 0.006404898337344788,
            "ave_precision_score": 0.8593302355920437,
            "fpr": 0.0801317233809001,
            "logloss": 0.513529836874738,
            "mae": 0.3018269234538307,
            "precision": 0.8228155339805825,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7644951903660653,
            "auditor_fn_violation": 0.011894297329963742,
            "auditor_fp_violation": 0.01783001093958917,
            "ave_precision_score": 0.756363211793928,
            "fpr": 0.13925438596491227,
            "logloss": 1.3878080165059061,
            "mae": 0.30387836038602534,
            "precision": 0.7309322033898306,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7913332468910309,
            "auditor_fn_violation": 0.00863828066323878,
            "auditor_fp_violation": 0.02284766211140092,
            "ave_precision_score": 0.7828540740908425,
            "fpr": 0.13721185510428102,
            "logloss": 1.3469769188572718,
            "mae": 0.28275891156967475,
            "precision": 0.7373949579831933,
            "recall": 0.7389473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.6012278557818141,
            "auditor_fn_violation": 0.008130974618173834,
            "auditor_fp_violation": 0.004269478546250152,
            "ave_precision_score": 0.6120960829189879,
            "fpr": 0.03399122807017544,
            "logloss": 1.9799918143261654,
            "mae": 0.4512496208309976,
            "precision": 0.8012820512820513,
            "recall": 0.2609603340292276
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5786509548791983,
            "auditor_fn_violation": 0.004610318331503864,
            "auditor_fp_violation": 0.004879203214533883,
            "ave_precision_score": 0.5839434766326469,
            "fpr": 0.025246981339187707,
            "logloss": 2.1682254168000386,
            "mae": 0.47509203680197254,
            "precision": 0.8050847457627118,
            "recall": 0.2
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7310830052926277,
            "auditor_fn_violation": 0.015813280591876352,
            "auditor_fp_violation": 0.01792623880717962,
            "ave_precision_score": 0.7321211048719533,
            "fpr": 0.16228070175438597,
            "logloss": 1.059547592122407,
            "mae": 0.331695211974798,
            "precision": 0.6954732510288066,
            "recall": 0.7056367432150313
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.772294228780674,
            "auditor_fn_violation": 0.012308047836385701,
            "auditor_fp_violation": 0.024753522190555807,
            "ave_precision_score": 0.7728046083543213,
            "fpr": 0.1668496158068057,
            "logloss": 1.0336391655072195,
            "mae": 0.31408458699677977,
            "precision": 0.689161554192229,
            "recall": 0.7094736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8334839673495731,
            "auditor_fn_violation": 0.0022273193421968314,
            "auditor_fp_violation": 0.004593614521291682,
            "ave_precision_score": 0.7790126022072202,
            "fpr": 0.17982456140350878,
            "logloss": 0.5276288979638468,
            "mae": 0.3399177975952625,
            "precision": 0.7162629757785467,
            "recall": 0.8643006263048016
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8598875132969332,
            "auditor_fn_violation": 0.006724825235426658,
            "auditor_fp_violation": 0.016342057825355746,
            "ave_precision_score": 0.806592533780353,
            "fpr": 0.17453347969264543,
            "logloss": 0.5079197978674753,
            "mae": 0.3324062201868166,
            "precision": 0.7200704225352113,
            "recall": 0.8610526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.8302260413409742,
            "auditor_fn_violation": 0.0006226422004907885,
            "auditor_fp_violation": 0.0021474008346501518,
            "ave_precision_score": 0.8306471600758185,
            "fpr": 0.47039473684210525,
            "logloss": 3.5064148712249015,
            "mae": 0.47063893482533703,
            "precision": 0.5270121278941565,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.8346110598217351,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0038167554557447846,
            "ave_precision_score": 0.8348475687445385,
            "fpr": 0.4698133918770582,
            "logloss": 3.4644820261769773,
            "mae": 0.4688339383025301,
            "precision": 0.5260243632336655,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.7307996286392364,
            "auditor_fn_violation": 0.012704647840896607,
            "auditor_fp_violation": 0.018070580608565295,
            "ave_precision_score": 0.731607634999383,
            "fpr": 0.11732456140350878,
            "logloss": 1.450813346399248,
            "mae": 0.36391357444046335,
            "precision": 0.7235142118863049,
            "recall": 0.5845511482254697
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7515888056151099,
            "auditor_fn_violation": 0.00987000982148016,
            "auditor_fp_violation": 0.01784509410970906,
            "ave_precision_score": 0.7521138498211618,
            "fpr": 0.10976948408342481,
            "logloss": 1.7330097977542376,
            "mae": 0.34654609856771845,
            "precision": 0.7375328083989501,
            "recall": 0.5915789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.6436631772084234,
            "auditor_fn_violation": 0.0014925099805882139,
            "auditor_fp_violation": 0.00512033548073417,
            "ave_precision_score": 0.6523517381169981,
            "fpr": 0.03070175438596491,
            "logloss": 0.8717718014877747,
            "mae": 0.4667437280111603,
            "precision": 0.6853932584269663,
            "recall": 0.12734864300626306
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6412090023220006,
            "auditor_fn_violation": 0.00621641920388237,
            "auditor_fp_violation": 0.0014803774458957291,
            "ave_precision_score": 0.6509174416002598,
            "fpr": 0.021953896816684963,
            "logloss": 0.8905360699022669,
            "mae": 0.47101959312573877,
            "precision": 0.6923076923076923,
            "recall": 0.09473684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6859148501194119,
            "auditor_fn_violation": 0.13082353587517856,
            "auditor_fp_violation": 0.11390340747943763,
            "ave_precision_score": 0.5621412880999515,
            "fpr": 0.18969298245614036,
            "logloss": 0.6838812192849458,
            "mae": 0.49103337059026225,
            "precision": 0.594847775175644,
            "recall": 0.5302713987473904
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6867725828510514,
            "auditor_fn_violation": 0.12907504766306546,
            "auditor_fp_violation": 0.11638586491304041,
            "ave_precision_score": 0.5586372412634668,
            "fpr": 0.19978046103183314,
            "logloss": 0.6837375658451612,
            "mae": 0.4909019211121108,
            "precision": 0.5891647855530474,
            "recall": 0.5494736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 8653,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7176671469964223,
            "auditor_fn_violation": 0.0157423176940263,
            "auditor_fp_violation": 0.026158786110773463,
            "ave_precision_score": 0.6582544700917341,
            "fpr": 0.22478070175438597,
            "logloss": 3.671281602495213,
            "mae": 0.4104606788789265,
            "precision": 0.5956607495069034,
            "recall": 0.6304801670146137
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7584442663103464,
            "auditor_fn_violation": 0.018748627881448956,
            "auditor_fp_violation": 0.030309972910099806,
            "ave_precision_score": 0.7053694186938206,
            "fpr": 0.22063666300768386,
            "logloss": 3.121952388147017,
            "mae": 0.38107842448526336,
            "precision": 0.6200378071833649,
            "recall": 0.6905263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.762609649122807,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5252192982456141,
            "fpr": 0.47478070175438597,
            "logloss": 0.69189299523585,
            "mae": 0.4985752940962189,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7607025246981339,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5214050493962679,
            "fpr": 0.47859495060373214,
            "logloss": 0.6923244088955463,
            "mae": 0.49879077125982707,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6688785099139473,
            "auditor_fn_violation": 0.011592132732666736,
            "auditor_fp_violation": 0.017665410639763384,
            "ave_precision_score": 0.5805622981174137,
            "fpr": 0.14583333333333334,
            "logloss": 3.214898729754213,
            "mae": 0.4866461504980888,
            "precision": 0.5993975903614458,
            "recall": 0.4154488517745303
        },
        "train": {
            "accuracy": 0.49396267837541163,
            "auc_prc": 0.6074030469750267,
            "auditor_fn_violation": 0.007464324917672898,
            "auditor_fp_violation": 0.016410034340728512,
            "ave_precision_score": 0.5428833151302195,
            "fpr": 0.15148188803512624,
            "logloss": 3.668108530434639,
            "mae": 0.5141388463001488,
            "precision": 0.5241379310344828,
            "recall": 0.32
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.770806340131996,
            "auditor_fn_violation": 0.01701736072959017,
            "auditor_fp_violation": 0.024664721850816418,
            "ave_precision_score": 0.6927360828980582,
            "fpr": 0.14473684210526316,
            "logloss": 8.374133465265942,
            "mae": 0.31238921901919403,
            "precision": 0.7142857142857143,
            "recall": 0.6889352818371608
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7893605572623085,
            "auditor_fn_violation": 0.018210179675313427,
            "auditor_fp_violation": 0.019443801045327756,
            "ave_precision_score": 0.7120725400455038,
            "fpr": 0.14818880351262348,
            "logloss": 8.20815547809531,
            "mae": 0.3113344765740673,
            "precision": 0.7077922077922078,
            "recall": 0.6884210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 8653,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7915859683734775,
            "auditor_fn_violation": 0.005310771710068495,
            "auditor_fp_violation": 0.008736477452291249,
            "ave_precision_score": 0.7633571337493064,
            "fpr": 0.17324561403508773,
            "logloss": 0.5414906595281802,
            "mae": 0.33950255855329725,
            "precision": 0.7183600713012478,
            "recall": 0.8413361169102297
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8232046837008814,
            "auditor_fn_violation": 0.00279854411000058,
            "auditor_fp_violation": 0.005790592050272412,
            "ave_precision_score": 0.7976711034082227,
            "fpr": 0.15806805708013172,
            "logloss": 0.5108254477916636,
            "mae": 0.32310821073442597,
            "precision": 0.7405405405405405,
            "recall": 0.8652631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5498824941923743,
            "auditor_fn_violation": 0.03497326301139069,
            "auditor_fp_violation": 0.04336078359871967,
            "ave_precision_score": 0.5510237982236741,
            "fpr": 0.3881578947368421,
            "logloss": 2.1027253621095325,
            "mae": 0.4817174451523705,
            "precision": 0.5432258064516129,
            "recall": 0.8789144050104384
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6019704127206026,
            "auditor_fn_violation": 0.025780807672309208,
            "auditor_fp_violation": 0.03996263809303219,
            "ave_precision_score": 0.6032436085596631,
            "fpr": 0.3721185510428101,
            "logloss": 1.9451652033297406,
            "mae": 0.47525117488252866,
            "precision": 0.5545335085413929,
            "recall": 0.888421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.6356114712871581,
            "auditor_fn_violation": 0.0020029850199611817,
            "auditor_fp_violation": 0.0020309144686195863,
            "ave_precision_score": 0.6669903371870529,
            "fpr": 0.01864035087719298,
            "logloss": 2.53797012235575,
            "mae": 0.5313100480442096,
            "precision": 0.46875,
            "recall": 0.031315240083507306
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.6697426360960206,
            "auditor_fn_violation": 0.0010537870472009027,
            "auditor_fp_violation": 0.0025654840431424287,
            "ave_precision_score": 0.7070623014016023,
            "fpr": 0.014270032930845226,
            "logloss": 2.5174372822811835,
            "mae": 0.5235700136709006,
            "precision": 0.4090909090909091,
            "recall": 0.018947368421052633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6180111193349691,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005469794578825847,
            "ave_precision_score": 0.6198165247086467,
            "fpr": 0.47368421052631576,
            "logloss": 0.7552255819899504,
            "mae": 0.4750946035706683,
            "precision": 0.5257958287596048,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6323022850239454,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00015609422048561413,
            "ave_precision_score": 0.6331343996143582,
            "fpr": 0.47639956092206365,
            "logloss": 0.7534766311693722,
            "mae": 0.47527592376479727,
            "precision": 0.5225522552255225,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7731084560387955,
            "auditor_fn_violation": 0.006370636926345094,
            "auditor_fp_violation": 0.012038612698026826,
            "ave_precision_score": 0.7828684373774859,
            "fpr": 0.18859649122807018,
            "logloss": 0.5748618978763795,
            "mae": 0.33374709354431714,
            "precision": 0.7044673539518901,
            "recall": 0.8559498956158664
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8173050888434434,
            "auditor_fn_violation": 0.0028609393956901064,
            "auditor_fp_violation": 0.004154120383891081,
            "ave_precision_score": 0.8214615048189686,
            "fpr": 0.1734357848518112,
            "logloss": 0.525937399070424,
            "mae": 0.3129324225711909,
            "precision": 0.7198581560283688,
            "recall": 0.8547368421052631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6867444933467961,
            "auditor_fn_violation": 0.125789748379299,
            "auditor_fp_violation": 0.10272071634050484,
            "ave_precision_score": 0.5618722138749314,
            "fpr": 0.19298245614035087,
            "logloss": 0.684326064491874,
            "mae": 0.4927679889165519,
            "precision": 0.5935334872979214,
            "recall": 0.5365344467640919
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6751738498276427,
            "auditor_fn_violation": 0.12589057715639262,
            "auditor_fp_violation": 0.10292651486923333,
            "ave_precision_score": 0.5468019932840942,
            "fpr": 0.21624588364434688,
            "logloss": 0.6881902319736773,
            "mae": 0.49463510860072535,
            "precision": 0.5679824561403509,
            "recall": 0.5452631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8166547475160804,
            "auditor_fn_violation": 0.004566805845511483,
            "auditor_fp_violation": 0.01970645435760302,
            "ave_precision_score": 0.8087652854942564,
            "fpr": 0.08771929824561403,
            "logloss": 0.5720009790653764,
            "mae": 0.3460695428876901,
            "precision": 0.7916666666666666,
            "recall": 0.6346555323590815
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8510500048387151,
            "auditor_fn_violation": 0.01138829510659196,
            "auditor_fp_violation": 0.025355240234040632,
            "ave_precision_score": 0.8421051659691319,
            "fpr": 0.09549945115257959,
            "logloss": 0.5321709827655006,
            "mae": 0.3297602764645675,
            "precision": 0.7883211678832117,
            "recall": 0.6821052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6816719405922715,
            "auditor_fn_violation": 0.009641797604658832,
            "auditor_fp_violation": 0.0025702969895871337,
            "ave_precision_score": 0.681611256437429,
            "fpr": 0.06798245614035088,
            "logloss": 0.7550164828110574,
            "mae": 0.4439195244442345,
            "precision": 0.7596899224806202,
            "recall": 0.4091858037578288
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7045196998003047,
            "auditor_fn_violation": 0.01769946270726213,
            "auditor_fp_violation": 0.007766946293517558,
            "ave_precision_score": 0.695939739958549,
            "fpr": 0.06256860592755215,
            "logloss": 0.7272484759596161,
            "mae": 0.4375744754884036,
            "precision": 0.7764705882352941,
            "recall": 0.4168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 8653,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.5894590932363615,
            "auditor_fn_violation": 0.0034863384976009937,
            "auditor_fp_violation": 0.00529506502978,
            "ave_precision_score": 0.5372924002716644,
            "fpr": 0.16228070175438597,
            "logloss": 4.021122238627479,
            "mae": 0.48520564634287566,
            "precision": 0.5147540983606558,
            "recall": 0.3277661795407098
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5856129594985195,
            "auditor_fn_violation": 0.007002137616269001,
            "auditor_fp_violation": 0.013021279166960404,
            "ave_precision_score": 0.5268428810871768,
            "fpr": 0.18880351262349068,
            "logloss": 4.471380274486495,
            "mae": 0.49549674454557124,
            "precision": 0.48036253776435045,
            "recall": 0.33473684210526317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5423636276055863,
            "auditor_fn_violation": 0.0029003223089037835,
            "auditor_fp_violation": 0.01019508933997814,
            "ave_precision_score": 0.543842359740367,
            "fpr": 0.43640350877192985,
            "logloss": 0.8254822635212138,
            "mae": 0.48029194272270326,
            "precision": 0.5345029239766081,
            "recall": 0.954070981210856
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5680867155350704,
            "auditor_fn_violation": 0.0025558957767635336,
            "auditor_fp_violation": 0.0033232963071128906,
            "ave_precision_score": 0.5698039494145296,
            "fpr": 0.43907793633369924,
            "logloss": 0.8106929954263974,
            "mae": 0.4711805668083949,
            "precision": 0.538638985005767,
            "recall": 0.9831578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 8653,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5844999454979075,
            "auditor_fn_violation": 0.01798108266490862,
            "auditor_fp_violation": 0.022899700174223086,
            "ave_precision_score": 0.585881491805935,
            "fpr": 0.0625,
            "logloss": 0.927681456691761,
            "mae": 0.4819489590172133,
            "precision": 0.6013986013986014,
            "recall": 0.17954070981210857
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5400238137839164,
            "auditor_fn_violation": 0.0072124328384077846,
            "auditor_fp_violation": 0.018864741840300507,
            "ave_precision_score": 0.5421328252183325,
            "fpr": 0.05817782656421515,
            "logloss": 1.0124667710530098,
            "mae": 0.49720502760707025,
            "precision": 0.5546218487394958,
            "recall": 0.13894736842105262
        }
    }
]