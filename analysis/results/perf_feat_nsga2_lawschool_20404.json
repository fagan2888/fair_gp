[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 16.89067354400237,
            "mae": 0.48903508771929827,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 19.259822621969953,
            "mae": 0.557628979143798,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 16.89067354400237,
            "mae": 0.48903508771929827,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.442371020856202,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 19.259822621969953,
            "mae": 0.557628979143798,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8119487848371639,
            "auditor_fn_violation": 0.0077000236016049085,
            "auditor_fp_violation": 0.004103606656125292,
            "ave_precision_score": 0.8115062373550752,
            "fpr": 0.021929824561403508,
            "logloss": 0.6642677716190435,
            "mae": 0.4255246065434339,
            "precision": 0.900497512437811,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.8721607318254738,
            "auditor_fn_violation": 0.0018431765732905827,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.870983242364633,
            "fpr": 0.019758507135016465,
            "logloss": 0.6129873047781552,
            "mae": 0.4344552765184308,
            "precision": 0.9113300492610837,
            "recall": 0.3641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8130041436118198,
            "auditor_fn_violation": 0.0077000236016049085,
            "auditor_fp_violation": 0.004103606656125292,
            "ave_precision_score": 0.8036204109074021,
            "fpr": 0.021929824561403508,
            "logloss": 0.6510511773935505,
            "mae": 0.4259733499803516,
            "precision": 0.900497512437811,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.870026277307183,
            "auditor_fn_violation": 0.0018431765732905827,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8611587361771276,
            "fpr": 0.019758507135016465,
            "logloss": 0.6084384448710951,
            "mae": 0.4343916724009196,
            "precision": 0.9113300492610837,
            "recall": 0.3641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6453035817400685,
            "auditor_fn_violation": 0.0006047911257965542,
            "auditor_fp_violation": 0.00789191325954371,
            "ave_precision_score": 0.5926635417205053,
            "fpr": 0.4868421052631579,
            "logloss": 7.69749013077608,
            "mae": 0.4868802660499586,
            "precision": 0.500562429696288,
            "recall": 0.9977578475336323
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7194382866607261,
            "auditor_fn_violation": 0.0033060494221976372,
            "auditor_fp_violation": 0.009887424993122394,
            "ave_precision_score": 0.6762637515634885,
            "fpr": 0.407244785949506,
            "logloss": 6.427812671019679,
            "mae": 0.412194399243176,
            "precision": 0.5755148741418764,
            "recall": 0.9901574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8083103227093202,
            "auditor_fn_violation": 0.005187436078986731,
            "auditor_fp_violation": 0.008880167156087644,
            "ave_precision_score": 0.8076292670942198,
            "fpr": 0.03508771929824561,
            "logloss": 0.6392794442358264,
            "mae": 0.4149223442134331,
            "precision": 0.8497652582159625,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8684544909064456,
            "auditor_fn_violation": 0.0006223151853548756,
            "auditor_fp_violation": 0.0014599613763949303,
            "ave_precision_score": 0.8676288275210047,
            "fpr": 0.027442371020856202,
            "logloss": 0.5994655929283027,
            "mae": 0.4233767672687575,
            "precision": 0.8888888888888888,
            "recall": 0.3937007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.768656007760214,
            "auditor_fn_violation": 0.012806329163716467,
            "auditor_fp_violation": 0.016607371432874034,
            "ave_precision_score": 0.7685622100127206,
            "fpr": 0.16337719298245615,
            "logloss": 0.984703152822134,
            "mae": 0.3544906711059397,
            "precision": 0.6959183673469388,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7999907553551235,
            "auditor_fn_violation": 0.0032930845225027385,
            "auditor_fp_violation": 0.0201507355644957,
            "ave_precision_score": 0.8002995902963944,
            "fpr": 0.12733260153677278,
            "logloss": 0.8441126259588455,
            "mae": 0.33989284948147985,
            "precision": 0.7583333333333333,
            "recall": 0.7165354330708661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 20404,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.6677176613979535,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.00243533995934041,
            "ave_precision_score": 0.6221604593103564,
            "fpr": 0.5054824561403509,
            "logloss": 7.785783372557395,
            "mae": 0.506012220139893,
            "precision": 0.49173098125689085,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.7352244769493268,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002830037071034215,
            "ave_precision_score": 0.698911393169618,
            "fpr": 0.43468715697036225,
            "logloss": 6.587895011926996,
            "mae": 0.4333696033985535,
            "precision": 0.5619469026548672,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7708064757688098,
            "auditor_fn_violation": 0.01403803791991189,
            "auditor_fp_violation": 0.016607371432874034,
            "ave_precision_score": 0.7712151889470487,
            "fpr": 0.16337719298245615,
            "logloss": 0.9794562856867525,
            "mae": 0.3548148893222866,
            "precision": 0.6952965235173824,
            "recall": 0.7623318385650224
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8044298288775791,
            "auditor_fn_violation": 0.0028998158984243337,
            "auditor_fp_violation": 0.0201507355644957,
            "ave_precision_score": 0.8046497645651178,
            "fpr": 0.12733260153677278,
            "logloss": 0.8314066881839656,
            "mae": 0.34027073989409,
            "precision": 0.7578288100208769,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6910632628606554,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004776560499962376,
            "ave_precision_score": 0.6131014274074836,
            "fpr": 0.4901315789473684,
            "logloss": 8.720196548558729,
            "mae": 0.49156896332512534,
            "precision": 0.49944008958566627,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7656495703323956,
            "auditor_fn_violation": 0.0015730744963136471,
            "auditor_fp_violation": 0.008530968341173369,
            "ave_precision_score": 0.7072980112495457,
            "fpr": 0.4094401756311745,
            "logloss": 7.04268176676307,
            "mae": 0.4154652615007981,
            "precision": 0.5746864310148233,
            "recall": 0.9921259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.524033149504154,
            "auditor_fn_violation": 0.051648178742821176,
            "auditor_fp_violation": 0.04424553873955275,
            "ave_precision_score": 0.5316651086808235,
            "fpr": 0.37719298245614036,
            "logloss": 0.695374053274974,
            "mae": 0.49287911752859753,
            "precision": 0.5195530726256983,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6028906223355809,
            "auditor_fn_violation": 0.059163158941027,
            "auditor_fp_violation": 0.0559361321373998,
            "ave_precision_score": 0.6222379288635069,
            "fpr": 0.31284302963776073,
            "logloss": 0.6728714919702096,
            "mae": 0.4812924589074404,
            "precision": 0.597457627118644,
            "recall": 0.8326771653543307
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6908745058091952,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004776560499962376,
            "ave_precision_score": 0.6129404439912446,
            "fpr": 0.4901315789473684,
            "logloss": 8.716908371913568,
            "mae": 0.4912894883028349,
            "precision": 0.49944008958566627,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7653369317018935,
            "auditor_fn_violation": 0.0015730744963136471,
            "auditor_fp_violation": 0.008781558726674007,
            "ave_precision_score": 0.7069455012346978,
            "fpr": 0.4083424807903403,
            "logloss": 7.041071368142895,
            "mae": 0.4153050635550287,
            "precision": 0.5753424657534246,
            "recall": 0.9921259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.763099265781795,
            "auditor_fn_violation": 0.01401099441428684,
            "auditor_fp_violation": 0.016607371432874034,
            "ave_precision_score": 0.7595951064599366,
            "fpr": 0.16337719298245615,
            "logloss": 1.248844495312329,
            "mae": 0.355672966286864,
            "precision": 0.694672131147541,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7980354099496632,
            "auditor_fn_violation": 0.002882529365497814,
            "auditor_fp_violation": 0.019829326157005774,
            "ave_precision_score": 0.7944172816628963,
            "fpr": 0.12843029637760703,
            "logloss": 1.0769189907415906,
            "mae": 0.3396877088141237,
            "precision": 0.7572614107883817,
            "recall": 0.718503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.5452223159499965,
            "auditor_fn_violation": 0.05754857997010464,
            "auditor_fp_violation": 0.0597634779007605,
            "ave_precision_score": 0.5196997232228223,
            "fpr": 0.40021929824561403,
            "logloss": 0.7024571073983116,
            "mae": 0.49817897189866034,
            "precision": 0.5034013605442177,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6287292602160616,
            "auditor_fn_violation": 0.06469917111074618,
            "auditor_fp_violation": 0.06530875731683068,
            "ave_precision_score": 0.6016685241788989,
            "fpr": 0.33479692645444564,
            "logloss": 0.6829797962965217,
            "mae": 0.4884060111906866,
            "precision": 0.5798898071625345,
            "recall": 0.8287401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.5693324562849928,
            "auditor_fn_violation": 0.0062765518055227796,
            "auditor_fp_violation": 0.00965429937504706,
            "ave_precision_score": 0.5509139015280125,
            "fpr": 0.11293859649122807,
            "logloss": 3.475325525735512,
            "mae": 0.4728687431728631,
            "precision": 0.6448275862068965,
            "recall": 0.4192825112107623
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6421693858022781,
            "auditor_fn_violation": 0.010434583437772812,
            "auditor_fp_violation": 0.003745236739819091,
            "ave_precision_score": 0.6180707744210816,
            "fpr": 0.10867178924259056,
            "logloss": 3.251598104722659,
            "mae": 0.4705412185676273,
            "precision": 0.6785714285714286,
            "recall": 0.41141732283464566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8176612183419256,
            "auditor_fn_violation": 0.009248878923766817,
            "auditor_fp_violation": 0.017541506663654855,
            "ave_precision_score": 0.8181367999901668,
            "fpr": 0.17214912280701755,
            "logloss": 0.6567209470462507,
            "mae": 0.278098449189329,
            "precision": 0.70817843866171,
            "recall": 0.8542600896860987
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8735450373072577,
            "auditor_fn_violation": 0.010596644683958963,
            "auditor_fp_violation": 0.016844031999302705,
            "ave_precision_score": 0.87376284128643,
            "fpr": 0.132821075740944,
            "logloss": 0.5464246776935429,
            "mae": 0.26093485342374684,
            "precision": 0.7755102040816326,
            "recall": 0.8228346456692913
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 20404,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6943790537163533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003562419998494092,
            "ave_precision_score": 0.6308463206149042,
            "fpr": 0.5010964912280702,
            "logloss": 8.337464316006468,
            "mae": 0.4993841623425271,
            "precision": 0.4939091915836102,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7647345279039294,
            "auditor_fn_violation": 0.0005510082370329395,
            "auditor_fp_violation": 0.004003998550933856,
            "ave_precision_score": 0.7156844649601856,
            "fpr": 0.42371020856201974,
            "logloss": 6.958155571568713,
            "mae": 0.4239810443414588,
            "precision": 0.5677491601343785,
            "recall": 0.9980314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 20404,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6639781499363808,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003562419998494092,
            "ave_precision_score": 0.6137361510885122,
            "fpr": 0.5010964912280702,
            "logloss": 7.871944087269995,
            "mae": 0.4974996836160432,
            "precision": 0.4939091915836102,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7368393634297123,
            "auditor_fn_violation": 0.0011452328063821882,
            "auditor_fp_violation": 0.004374436512108685,
            "ave_precision_score": 0.6966424467241791,
            "fpr": 0.42151481888035125,
            "logloss": 6.651036778558902,
            "mae": 0.4223759231452467,
            "precision": 0.5685393258426966,
            "recall": 0.9960629921259843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.817628477878519,
            "auditor_fn_violation": 0.009789749036267805,
            "auditor_fp_violation": 0.005637753181236353,
            "ave_precision_score": 0.817669602040982,
            "fpr": 0.07236842105263158,
            "logloss": 0.5504380050179742,
            "mae": 0.3744370883755517,
            "precision": 0.8092485549132948,
            "recall": 0.6278026905829597
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8746645436269189,
            "auditor_fn_violation": 0.007871854931415689,
            "auditor_fp_violation": 0.006117673976460848,
            "ave_precision_score": 0.8743983879868252,
            "fpr": 0.05159165751920966,
            "logloss": 0.5294705101548818,
            "mae": 0.37030399856530744,
            "precision": 0.8708791208791209,
            "recall": 0.6240157480314961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.49920815846056243,
            "auditor_fn_violation": 0.007375501534104319,
            "auditor_fp_violation": 0.006456592124087043,
            "ave_precision_score": 0.492657447145104,
            "fpr": 0.0625,
            "logloss": 0.6939115135144168,
            "mae": 0.4986002732787216,
            "precision": 0.4722222222222222,
            "recall": 0.11434977578475336
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.5873362178606767,
            "auditor_fn_violation": 0.010709007147981365,
            "auditor_fp_violation": 0.00682858800489196,
            "ave_precision_score": 0.5778515331418203,
            "fpr": 0.04939626783754116,
            "logloss": 0.6998104642521218,
            "mae": 0.5015952714057444,
            "precision": 0.5909090909090909,
            "recall": 0.1279527559055118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.6882044645474916,
            "auditor_fn_violation": 0.0006047911257965542,
            "auditor_fp_violation": 0.004776560499962376,
            "ave_precision_score": 0.6107768100350529,
            "fpr": 0.4901315789473684,
            "logloss": 8.706448594930565,
            "mae": 0.49066031217518336,
            "precision": 0.49887892376681614,
            "recall": 0.9977578475336323
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7644931478133896,
            "auditor_fn_violation": 0.0015730744963136471,
            "auditor_fp_violation": 0.008781558726674007,
            "ave_precision_score": 0.7062611298099013,
            "fpr": 0.4083424807903403,
            "logloss": 7.0344246023431465,
            "mae": 0.4148672069712598,
            "precision": 0.5753424657534246,
            "recall": 0.9921259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8189090346290185,
            "auditor_fn_violation": 0.010478129179450872,
            "auditor_fp_violation": 0.011727279572321366,
            "ave_precision_score": 0.8193531054269575,
            "fpr": 0.16557017543859648,
            "logloss": 0.6448215048086852,
            "mae": 0.2772065630540231,
            "precision": 0.7150943396226415,
            "recall": 0.8497757847533632
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.874846133380763,
            "auditor_fn_violation": 0.0126018825034357,
            "auditor_fp_violation": 0.01832033622692594,
            "ave_precision_score": 0.8750619845725789,
            "fpr": 0.12733260153677278,
            "logloss": 0.5396696168642008,
            "mae": 0.2609019195291823,
            "precision": 0.7819548872180451,
            "recall": 0.8188976377952756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7420892309538505,
            "auditor_fn_violation": 0.011849972464794283,
            "auditor_fp_violation": 0.017082674497402316,
            "ave_precision_score": 0.6581272161425269,
            "fpr": 0.16228070175438597,
            "logloss": 3.4757224621055562,
            "mae": 0.3965484808084735,
            "precision": 0.6796536796536796,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7869109894804573,
            "auditor_fn_violation": 0.0047797263541837715,
            "auditor_fp_violation": 0.02083985912462242,
            "ave_precision_score": 0.7189377029343076,
            "fpr": 0.12403951701427003,
            "logloss": 2.6088274911385123,
            "mae": 0.3729145538662974,
            "precision": 0.7483296213808464,
            "recall": 0.6614173228346457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5120614035087719,
            "auc_prc": 0.6387471514343087,
            "auditor_fn_violation": 0.0006047911257965542,
            "auditor_fp_violation": 0.00789191325954371,
            "ave_precision_score": 0.5887404490039876,
            "fpr": 0.4868421052631579,
            "logloss": 7.6311357593081155,
            "mae": 0.4859381847772477,
            "precision": 0.500562429696288,
            "recall": 0.9977578475336323
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7147146899663032,
            "auditor_fn_violation": 0.0033060494221976372,
            "auditor_fp_violation": 0.009887424993122394,
            "ave_precision_score": 0.6730596371083328,
            "fpr": 0.407244785949506,
            "logloss": 6.388487091147903,
            "mae": 0.4116038930773441,
            "precision": 0.5755148741418764,
            "recall": 0.9901574803149606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8012601196272142,
            "auditor_fn_violation": 0.0077000236016049085,
            "auditor_fp_violation": 0.004103606656125292,
            "ave_precision_score": 0.7669815677279757,
            "fpr": 0.021929824561403508,
            "logloss": 0.6601215697376341,
            "mae": 0.4297382836171102,
            "precision": 0.900497512437811,
            "recall": 0.40582959641255606
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.860844284536362,
            "auditor_fn_violation": 0.0018431765732905827,
            "auditor_fp_violation": 0.0004467046002402401,
            "ave_precision_score": 0.8289222468210217,
            "fpr": 0.019758507135016465,
            "logloss": 0.6136069679712082,
            "mae": 0.43818884646556694,
            "precision": 0.9113300492610837,
            "recall": 0.3641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8269522628264734,
            "auditor_fn_violation": 0.006298678310125093,
            "auditor_fp_violation": 0.023327497929372786,
            "ave_precision_score": 0.8273095248718245,
            "fpr": 0.14035087719298245,
            "logloss": 0.7105674264001903,
            "mae": 0.27285483132762445,
            "precision": 0.7344398340248963,
            "recall": 0.7937219730941704
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.891080364206996,
            "auditor_fn_violation": 0.0076320042870601686,
            "auditor_fp_violation": 0.014201937717393972,
            "ave_precision_score": 0.8912313754771796,
            "fpr": 0.08781558726673985,
            "logloss": 0.6146645319425024,
            "mae": 0.25497759262127956,
            "precision": 0.8275862068965517,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.5814680207786265,
            "auditor_fn_violation": 0.010714145228542207,
            "auditor_fp_violation": 0.013508489571568407,
            "ave_precision_score": 0.5674421416635133,
            "fpr": 0.24890350877192982,
            "logloss": 3.7006960918462077,
            "mae": 0.3460849551810661,
            "precision": 0.6197654941373534,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6622963536111884,
            "auditor_fn_violation": 0.00872537749466279,
            "auditor_fp_violation": 0.01863902182587782,
            "ave_precision_score": 0.6411000432165306,
            "fpr": 0.19209659714599342,
            "logloss": 3.360179175908489,
            "mae": 0.3114819074377814,
            "precision": 0.7033898305084746,
            "recall": 0.8169291338582677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 20404,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5233214233651364,
            "auditor_fn_violation": 0.056034143655101884,
            "auditor_fp_violation": 0.053659833596867726,
            "ave_precision_score": 0.5310401045562536,
            "fpr": 0.40021929824561403,
            "logloss": 0.6978731228624644,
            "mae": 0.4953411147978745,
            "precision": 0.5047489823609227,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6102293913514829,
            "auditor_fn_violation": 0.06397745836106382,
            "auditor_fp_violation": 0.06341571038288576,
            "ave_precision_score": 0.62248544601612,
            "fpr": 0.33260153677277715,
            "logloss": 0.6767879838929212,
            "mae": 0.48452034739840827,
            "precision": 0.5814917127071824,
            "recall": 0.8287401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7420892309538505,
            "auditor_fn_violation": 0.011849972464794283,
            "auditor_fp_violation": 0.017082674497402316,
            "ave_precision_score": 0.6581272161425269,
            "fpr": 0.16228070175438597,
            "logloss": 3.4608708900210448,
            "mae": 0.39618785734892936,
            "precision": 0.6796536796536796,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7869109894804573,
            "auditor_fn_violation": 0.0047797263541837715,
            "auditor_fp_violation": 0.02083985912462242,
            "ave_precision_score": 0.7189377029343076,
            "fpr": 0.12403951701427003,
            "logloss": 2.5954899345033424,
            "mae": 0.37267828579791684,
            "precision": 0.7483296213808464,
            "recall": 0.6614173228346457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 20404,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6999106933950788,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016235599728936124,
            "ave_precision_score": 0.6385183255408745,
            "fpr": 0.5076754385964912,
            "logloss": 8.172359657609642,
            "mae": 0.5075917361598266,
            "precision": 0.49064906490649063,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7714581766586798,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026284752392184895,
            "ave_precision_score": 0.7216734578595927,
            "fpr": 0.43688254665203075,
            "logloss": 6.872860884724539,
            "mae": 0.4356444050877638,
            "precision": 0.5607064017660044,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8295017097548321,
            "auditor_fn_violation": 0.009081700888993786,
            "auditor_fp_violation": 0.015214404035840687,
            "ave_precision_score": 0.8300218654544878,
            "fpr": 0.17763157894736842,
            "logloss": 0.6259998973802122,
            "mae": 0.28542422189269,
            "precision": 0.7032967032967034,
            "recall": 0.8609865470852018
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8850563463150103,
            "auditor_fn_violation": 0.012707762517610658,
            "auditor_fp_violation": 0.013673518861012228,
            "ave_precision_score": 0.8852259408655145,
            "fpr": 0.141602634467618,
            "logloss": 0.49570046979587173,
            "mae": 0.26573146874765924,
            "precision": 0.7712765957446809,
            "recall": 0.8562992125984252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5616893965915519,
            "auditor_fn_violation": 0.08368735740697035,
            "auditor_fp_violation": 0.1019878021233341,
            "ave_precision_score": 0.5629790148081351,
            "fpr": 0.30043859649122806,
            "logloss": 0.6820680535597042,
            "mae": 0.48811155060927075,
            "precision": 0.547107438016529,
            "recall": 0.742152466367713
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6165039972275527,
            "auditor_fn_violation": 0.09822208008850705,
            "auditor_fp_violation": 0.08532875007149998,
            "ave_precision_score": 0.6183078091771763,
            "fpr": 0.26344676180021953,
            "logloss": 0.6778242500508702,
            "mae": 0.4862132893566504,
            "precision": 0.6019900497512438,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7420892309538505,
            "auditor_fn_violation": 0.011849972464794283,
            "auditor_fp_violation": 0.017082674497402316,
            "ave_precision_score": 0.6581272161425269,
            "fpr": 0.16228070175438597,
            "logloss": 3.4716400105887844,
            "mae": 0.3964547231270556,
            "precision": 0.6796536796536796,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7869109894804573,
            "auditor_fn_violation": 0.0047797263541837715,
            "auditor_fp_violation": 0.02083985912462242,
            "ave_precision_score": 0.7189377029343076,
            "fpr": 0.12403951701427003,
            "logloss": 2.605145753492859,
            "mae": 0.3728530866254436,
            "precision": 0.7483296213808464,
            "recall": 0.6614173228346457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6980865022383471,
            "auditor_fn_violation": 0.08140586893242074,
            "auditor_fp_violation": 0.10431255176568029,
            "ave_precision_score": 0.526348939611379,
            "fpr": 0.3026315789473684,
            "logloss": 0.6850563493017152,
            "mae": 0.4908743955260306,
            "precision": 0.5384615384615384,
            "recall": 0.7219730941704036
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7453023252433911,
            "auditor_fn_violation": 0.09539573195502044,
            "auditor_fp_violation": 0.08808796812054487,
            "ave_precision_score": 0.6053701922015414,
            "fpr": 0.2414928649835346,
            "logloss": 0.6753552492253605,
            "mae": 0.48595289109043704,
            "precision": 0.6226415094339622,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7647969683325522,
            "auditor_fn_violation": 0.013669262843206673,
            "auditor_fp_violation": 0.017546212634590767,
            "ave_precision_score": 0.6957162102551123,
            "fpr": 0.16557017543859648,
            "logloss": 3.404501789846157,
            "mae": 0.3744914767316036,
            "precision": 0.6924643584521385,
            "recall": 0.7623318385650224
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8088256277563326,
            "auditor_fn_violation": 0.0021781031487419725,
            "auditor_fp_violation": 0.019834773774081882,
            "ave_precision_score": 0.7601275074818725,
            "fpr": 0.12952799121844127,
            "logloss": 2.5451525322359507,
            "mae": 0.3556893844766753,
            "precision": 0.7551867219917012,
            "recall": 0.7165354330708661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7676708980110155,
            "auditor_fn_violation": 0.013789729368263708,
            "auditor_fp_violation": 0.016005007153075828,
            "ave_precision_score": 0.739554728505706,
            "fpr": 0.16447368421052633,
            "logloss": 2.1886915623583105,
            "mae": 0.3603110216469915,
            "precision": 0.696969696969697,
            "recall": 0.773542600896861
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8048678288375375,
            "auditor_fn_violation": 0.003932686240784121,
            "auditor_fp_violation": 0.019360831088461133,
            "ave_precision_score": 0.7799025495995406,
            "fpr": 0.132821075740944,
            "logloss": 1.9151472986000484,
            "mae": 0.3428112320418461,
            "precision": 0.7545638945233266,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 20404,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6878068200560241,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016235599728936124,
            "ave_precision_score": 0.634648561773118,
            "fpr": 0.5076754385964912,
            "logloss": 7.933147551213508,
            "mae": 0.5069638545085725,
            "precision": 0.49064906490649063,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.7548772290213263,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0022035611072826525,
            "ave_precision_score": 0.7107034360894814,
            "fpr": 0.43578485181119647,
            "logloss": 6.7117615952007075,
            "mae": 0.43495019224117604,
            "precision": 0.5613259668508287,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5823044935180233,
            "auditor_fn_violation": 0.0018094563763669266,
            "auditor_fp_violation": 0.009875480009035476,
            "ave_precision_score": 0.5649799602038851,
            "fpr": 0.44627192982456143,
            "logloss": 5.43557185271995,
            "mae": 0.45552064401299885,
            "precision": 0.5172004744958482,
            "recall": 0.9775784753363229
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6652919766819456,
            "auditor_fn_violation": 0.006525666179762656,
            "auditor_fp_violation": 0.013722547414697132,
            "ave_precision_score": 0.6439332973944323,
            "fpr": 0.3765093304061471,
            "logloss": 4.6209975757411055,
            "mae": 0.3910182197610055,
            "precision": 0.5892215568862276,
            "recall": 0.968503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.5842748213117213,
            "auditor_fn_violation": 0.011495948391157267,
            "auditor_fp_violation": 0.013586138092011148,
            "ave_precision_score": 0.5702620588347675,
            "fpr": 0.25219298245614036,
            "logloss": 3.6932001653315685,
            "mae": 0.3464269486489686,
            "precision": 0.6140939597315436,
            "recall": 0.820627802690583
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6658650973908433,
            "auditor_fn_violation": 0.011469614596748405,
            "auditor_fp_violation": 0.018323060035463988,
            "ave_precision_score": 0.6446648691453815,
            "fpr": 0.19099890230515917,
            "logloss": 3.379023845567364,
            "mae": 0.3141071213091908,
            "precision": 0.7030716723549488,
            "recall": 0.8110236220472441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8276797246472012,
            "auditor_fn_violation": 0.009236586421209978,
            "auditor_fp_violation": 0.015214404035840687,
            "ave_precision_score": 0.8280173108747222,
            "fpr": 0.17763157894736842,
            "logloss": 0.6257516597302781,
            "mae": 0.28799138832306326,
            "precision": 0.7038391224862889,
            "recall": 0.8632286995515696
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8851047274597493,
            "auditor_fn_violation": 0.00872321667804697,
            "auditor_fp_violation": 0.016340127419763414,
            "ave_precision_score": 0.8852966957304522,
            "fpr": 0.1437980241492865,
            "logloss": 0.4924272807624937,
            "mae": 0.26648692025176357,
            "precision": 0.7701754385964912,
            "recall": 0.8641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8022912660186716,
            "auditor_fn_violation": 0.016486704429234524,
            "auditor_fp_violation": 0.01412967773511031,
            "ave_precision_score": 0.8026763659828193,
            "fpr": 0.09539473684210527,
            "logloss": 0.573557872515563,
            "mae": 0.31680684417931426,
            "precision": 0.7867647058823529,
            "recall": 0.7197309417040358
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8921687169666848,
            "auditor_fn_violation": 0.018695385360035264,
            "auditor_fp_violation": 0.012682052553161934,
            "ave_precision_score": 0.8923000202598211,
            "fpr": 0.07903402854006586,
            "logloss": 0.4810839132456011,
            "mae": 0.3022033460036996,
            "precision": 0.84,
            "recall": 0.7440944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.47674052982437437,
            "auditor_fn_violation": 0.06038077255920069,
            "auditor_fp_violation": 0.06625065883593104,
            "ave_precision_score": 0.49223015650642726,
            "fpr": 0.3881578947368421,
            "logloss": 0.7013290865490857,
            "mae": 0.49889593725011017,
            "precision": 0.5083333333333333,
            "recall": 0.820627802690583
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5920332289339324,
            "auditor_fn_violation": 0.06937949990060244,
            "auditor_fp_violation": 0.07230894525961981,
            "ave_precision_score": 0.5902163992486416,
            "fpr": 0.3238199780461032,
            "logloss": 0.6837068547533027,
            "mae": 0.48997743494816853,
            "precision": 0.5850914205344585,
            "recall": 0.8188976377952756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7644557028908795,
            "auditor_fn_violation": 0.014878845094799784,
            "auditor_fp_violation": 0.016757962502823586,
            "ave_precision_score": 0.7615381457061788,
            "fpr": 0.16228070175438597,
            "logloss": 1.16854584400831,
            "mae": 0.34458199626600244,
            "precision": 0.6954732510288066,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8002303176730103,
            "auditor_fn_violation": 0.0038397711263040537,
            "auditor_fp_violation": 0.02338117249062329,
            "ave_precision_score": 0.7970109003263663,
            "fpr": 0.12294182217343579,
            "logloss": 1.036511895573858,
            "mae": 0.3285908682723806,
            "precision": 0.7642105263157895,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5358279723808201,
            "auditor_fn_violation": 0.07819998426559673,
            "auditor_fp_violation": 0.09891009713124012,
            "ave_precision_score": 0.537506351222322,
            "fpr": 0.28728070175438597,
            "logloss": 0.692316013759445,
            "mae": 0.4846027163102439,
            "precision": 0.5467128027681661,
            "recall": 0.7085201793721974
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6142860657430237,
            "auditor_fn_violation": 0.08953559729292895,
            "auditor_fp_violation": 0.08225629404057931,
            "ave_precision_score": 0.6162477697331925,
            "fpr": 0.2283205268935236,
            "logloss": 0.6723085563630731,
            "mae": 0.4755837404701765,
            "precision": 0.6258992805755396,
            "recall": 0.6850393700787402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.8092852168904574,
            "auditor_fn_violation": 0.0028764455983006933,
            "auditor_fp_violation": 0.008880167156087644,
            "ave_precision_score": 0.808468711280435,
            "fpr": 0.03508771929824561,
            "logloss": 0.6363170230818678,
            "mae": 0.4132484755807921,
            "precision": 0.8518518518518519,
            "recall": 0.4125560538116592
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.868571486069422,
            "auditor_fn_violation": 0.0027507195519330657,
            "auditor_fp_violation": 0.0021599801706738424,
            "ave_precision_score": 0.8675827131119322,
            "fpr": 0.02854006586169045,
            "logloss": 0.5968429626815327,
            "mae": 0.4214890702916483,
            "precision": 0.8854625550660793,
            "recall": 0.3956692913385827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8311062765017201,
            "auditor_fn_violation": 0.008223684210526319,
            "auditor_fp_violation": 0.01690384760183721,
            "ave_precision_score": 0.831444151309569,
            "fpr": 0.17543859649122806,
            "logloss": 0.6114728273993315,
            "mae": 0.28651460601586703,
            "precision": 0.7074954296160878,
            "recall": 0.8677130044843049
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.888582196484975,
            "auditor_fn_violation": 0.006242599203090834,
            "auditor_fp_violation": 0.014684051828628869,
            "ave_precision_score": 0.8887625581435505,
            "fpr": 0.141602634467618,
            "logloss": 0.4831981528986409,
            "mae": 0.2659256136495698,
            "precision": 0.772887323943662,
            "recall": 0.8641732283464567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6062476676331342,
            "auditor_fn_violation": 0.06889947683109118,
            "auditor_fp_violation": 0.11022325126120021,
            "ave_precision_score": 0.5761308399092426,
            "fpr": 0.3256578947368421,
            "logloss": 0.6663015072346811,
            "mae": 0.4742613025009632,
            "precision": 0.5416666666666666,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6960349765777322,
            "auditor_fn_violation": 0.08622522623749969,
            "auditor_fp_violation": 0.1013011633386266,
            "ave_precision_score": 0.6627765637054017,
            "fpr": 0.27771679473106475,
            "logloss": 0.6539571662236559,
            "mae": 0.4714232657337817,
            "precision": 0.6077519379844961,
            "recall": 0.7716535433070866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8279834374076618,
            "auditor_fn_violation": 0.010360121154905205,
            "auditor_fp_violation": 0.015555586928695127,
            "ave_precision_score": 0.8283216631122634,
            "fpr": 0.1699561403508772,
            "logloss": 0.6169616038116209,
            "mae": 0.28569243109239706,
            "precision": 0.712430426716141,
            "recall": 0.8609865470852018
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8858190606073848,
            "auditor_fn_violation": 0.01269695843453158,
            "auditor_fp_violation": 0.01472763276523767,
            "ave_precision_score": 0.8860055432591981,
            "fpr": 0.141602634467618,
            "logloss": 0.48718822349183144,
            "mae": 0.2655750195762607,
            "precision": 0.7700534759358288,
            "recall": 0.8503937007874016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7642199945055256,
            "auditor_fn_violation": 0.014878845094799784,
            "auditor_fp_violation": 0.016757962502823586,
            "ave_precision_score": 0.7613904892194345,
            "fpr": 0.16228070175438597,
            "logloss": 1.1639865901688156,
            "mae": 0.34412433835578693,
            "precision": 0.6954732510288066,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7991836431003186,
            "auditor_fn_violation": 0.0014758377486019589,
            "auditor_fp_violation": 0.02338117249062329,
            "ave_precision_score": 0.7960088062148389,
            "fpr": 0.12294182217343579,
            "logloss": 1.0364025148975893,
            "mae": 0.3282702771737149,
            "precision": 0.7642105263157895,
            "recall": 0.7145669291338582
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.814848724620494,
            "auditor_fn_violation": 0.005944654236488084,
            "auditor_fp_violation": 0.016856787892477975,
            "ave_precision_score": 0.8153017029222681,
            "fpr": 0.17105263157894737,
            "logloss": 0.661865183178377,
            "mae": 0.27977982236970683,
            "precision": 0.7111111111111111,
            "recall": 0.8609865470852018
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8725285808788783,
            "auditor_fn_violation": 0.004330276498094164,
            "auditor_fp_violation": 0.01258399544579213,
            "ave_precision_score": 0.8727545175833907,
            "fpr": 0.1350164654226125,
            "logloss": 0.5481100536822355,
            "mae": 0.2624459593556647,
            "precision": 0.7734806629834254,
            "recall": 0.8267716535433071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7631264084678107,
            "auditor_fn_violation": 0.01401099441428684,
            "auditor_fp_violation": 0.016607371432874034,
            "ave_precision_score": 0.7595846822409663,
            "fpr": 0.16337719298245615,
            "logloss": 1.2380988814792808,
            "mae": 0.3551171175288721,
            "precision": 0.694672131147541,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7980490930171487,
            "auditor_fn_violation": 0.0057909885303854105,
            "auditor_fp_violation": 0.019829326157005774,
            "ave_precision_score": 0.794441524250505,
            "fpr": 0.12843029637760703,
            "logloss": 1.0752638051436918,
            "mae": 0.3391025784933017,
            "precision": 0.7587628865979381,
            "recall": 0.7244094488188977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7671644316307284,
            "auditor_fn_violation": 0.013789729368263708,
            "auditor_fp_violation": 0.016005007153075828,
            "ave_precision_score": 0.7393676484917544,
            "fpr": 0.16447368421052633,
            "logloss": 2.11122945353964,
            "mae": 0.3610012381189806,
            "precision": 0.696969696969697,
            "recall": 0.773542600896861
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8028836702685916,
            "auditor_fn_violation": 0.003932686240784121,
            "auditor_fp_violation": 0.020044507031511748,
            "ave_precision_score": 0.7782159047022039,
            "fpr": 0.13172338090010977,
            "logloss": 1.8761417072561248,
            "mae": 0.343789977879684,
            "precision": 0.7560975609756098,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8135884203406125,
            "auditor_fn_violation": 0.00994709306899536,
            "auditor_fp_violation": 0.019532132369550488,
            "ave_precision_score": 0.8140291437199776,
            "fpr": 0.15899122807017543,
            "logloss": 0.6731004411792303,
            "mae": 0.2766497166333175,
            "precision": 0.7211538461538461,
            "recall": 0.8408071748878924
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.867514178585215,
            "auditor_fn_violation": 0.010834334511698662,
            "auditor_fp_violation": 0.019009459787052655,
            "ave_precision_score": 0.8677547637800422,
            "fpr": 0.1207464324917673,
            "logloss": 0.5433246154584164,
            "mae": 0.2626293575890571,
            "precision": 0.7880539499036608,
            "recall": 0.8051181102362205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.526859647529458,
            "auditor_fn_violation": 0.08133703091810243,
            "auditor_fp_violation": 0.10553139823808448,
            "ave_precision_score": 0.5283026524651416,
            "fpr": 0.3092105263157895,
            "logloss": 0.7015865958733628,
            "mae": 0.4883477036236671,
            "precision": 0.5369458128078818,
            "recall": 0.7331838565022422
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6032152534778296,
            "auditor_fn_violation": 0.09289134549729035,
            "auditor_fp_violation": 0.09231259516306081,
            "ave_precision_score": 0.6051746147004714,
            "fpr": 0.25686059275521406,
            "logloss": 0.6750435812041359,
            "mae": 0.47639375130117395,
            "precision": 0.6,
            "recall": 0.6909448818897638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7420892309538505,
            "auditor_fn_violation": 0.011849972464794283,
            "auditor_fp_violation": 0.017082674497402316,
            "ave_precision_score": 0.6581272161425269,
            "fpr": 0.16228070175438597,
            "logloss": 3.4746016031931464,
            "mae": 0.3946739011362456,
            "precision": 0.6796536796536796,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7869109894804573,
            "auditor_fn_violation": 0.0047797263541837715,
            "auditor_fp_violation": 0.02083985912462242,
            "ave_precision_score": 0.7189377029343076,
            "fpr": 0.12403951701427003,
            "logloss": 2.6110022736583987,
            "mae": 0.3720215950590588,
            "precision": 0.7483296213808464,
            "recall": 0.6614173228346457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.5208994761256087,
            "auditor_fn_violation": 0.00681496341751239,
            "auditor_fp_violation": 0.014047323243731662,
            "ave_precision_score": 0.5231941604632746,
            "fpr": 0.4791666666666667,
            "logloss": 0.7218428475978564,
            "mae": 0.4893200412523328,
            "precision": 0.4965437788018433,
            "recall": 0.9663677130044843
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6086670613421441,
            "auditor_fn_violation": 0.011536599911838682,
            "auditor_fp_violation": 0.00927729188059913,
            "ave_precision_score": 0.6106403479013682,
            "fpr": 0.4039517014270033,
            "logloss": 0.6796689363508318,
            "mae": 0.4706820641469484,
            "precision": 0.5695906432748538,
            "recall": 0.9586614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.5861814694622636,
            "auditor_fn_violation": 0.004169616867280309,
            "auditor_fp_violation": 0.022089827573224904,
            "ave_precision_score": 0.5721528529496761,
            "fpr": 0.3925438596491228,
            "logloss": 3.733701829542663,
            "mae": 0.41546476587424414,
            "precision": 0.5421994884910486,
            "recall": 0.9506726457399103
        },
        "train": {
            "accuracy": 0.6476399560922064,
            "auc_prc": 0.6597810595254947,
            "auditor_fn_violation": 0.006787124990276325,
            "auditor_fp_violation": 0.02508627663544276,
            "ave_precision_score": 0.6386795809808556,
            "fpr": 0.3205268935236004,
            "logloss": 3.3542865456942743,
            "mae": 0.36098492035640223,
            "precision": 0.6212710765239948,
            "recall": 0.9429133858267716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6912448132046533,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004776560499962376,
            "ave_precision_score": 0.6132308184765959,
            "fpr": 0.4901315789473684,
            "logloss": 8.719881196766277,
            "mae": 0.49164456023904274,
            "precision": 0.49944008958566627,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.7655320100543523,
            "auditor_fn_violation": 0.0015730744963136471,
            "auditor_fp_violation": 0.008530968341173369,
            "ave_precision_score": 0.7074007394089539,
            "fpr": 0.4094401756311745,
            "logloss": 7.04261857313891,
            "mae": 0.41563135919981575,
            "precision": 0.5746864310148233,
            "recall": 0.9921259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6157832209831811,
            "auditor_fn_violation": 0.011132090315474793,
            "auditor_fp_violation": 0.010291958436864717,
            "ave_precision_score": 0.5666821642535136,
            "fpr": 0.25219298245614036,
            "logloss": 4.883559369853411,
            "mae": 0.382465670911267,
            "precision": 0.5971978984238179,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6821024892691905,
            "auditor_fn_violation": 0.005276714175821326,
            "auditor_fp_violation": 0.01091430081196733,
            "ave_precision_score": 0.6365705621191226,
            "fpr": 0.1964873765093304,
            "logloss": 4.586926471948904,
            "mae": 0.35088969358563105,
            "precision": 0.6826241134751773,
            "recall": 0.7578740157480315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.618753161292921,
            "auditor_fn_violation": 0.008157304696719374,
            "auditor_fp_violation": 0.009604886680219867,
            "ave_precision_score": 0.5687898623104688,
            "fpr": 0.23903508771929824,
            "logloss": 4.871769065702642,
            "mae": 0.378010420437311,
            "precision": 0.6064981949458483,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.684140050169868,
            "auditor_fn_violation": 0.005661339533436475,
            "auditor_fp_violation": 0.00863174925708122,
            "ave_precision_score": 0.6380216615447306,
            "fpr": 0.1877058177826564,
            "logloss": 4.589782665701423,
            "mae": 0.3492857398286412,
            "precision": 0.6896551724137931,
            "recall": 0.7480314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.822452930068841,
            "auditor_fn_violation": 0.010237196129336797,
            "auditor_fp_violation": 0.016892082674497405,
            "ave_precision_score": 0.8228656493564399,
            "fpr": 0.16557017543859648,
            "logloss": 0.6351778889956955,
            "mae": 0.2746541593832374,
            "precision": 0.713472485768501,
            "recall": 0.8430493273542601
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8787172822095001,
            "auditor_fn_violation": 0.008409898268753728,
            "auditor_fp_violation": 0.014324509101606233,
            "ave_precision_score": 0.8789244316000194,
            "fpr": 0.1251372118551043,
            "logloss": 0.5337535899394554,
            "mae": 0.2593545832128462,
            "precision": 0.7824427480916031,
            "recall": 0.8070866141732284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 20404,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5020012132351895,
            "auditor_fn_violation": 0.0010620722209110276,
            "auditor_fp_violation": 0.0051718620585799275,
            "ave_precision_score": 0.5063914644698351,
            "fpr": 0.015350877192982455,
            "logloss": 0.7368819093873469,
            "mae": 0.48511902850709465,
            "precision": 0.4166666666666667,
            "recall": 0.02242152466367713
        },
        "train": {
            "accuracy": 0.4226125137211855,
            "auc_prc": 0.540781004166155,
            "auditor_fn_violation": 0.001832372490211518,
            "auditor_fp_violation": 0.006090435891080344,
            "ave_precision_score": 0.5449239246975898,
            "fpr": 0.02854006586169045,
            "logloss": 0.8015311828651901,
            "mae": 0.5133011537378104,
            "precision": 0.23529411764705882,
            "recall": 0.015748031496062992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 20404,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6185017607324695,
            "auditor_fn_violation": 0.0069723074502399535,
            "auditor_fp_violation": 0.008249567050673905,
            "ave_precision_score": 0.5685236058784636,
            "fpr": 0.23793859649122806,
            "logloss": 4.8802989387875515,
            "mae": 0.378360895348504,
            "precision": 0.609009009009009,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6832656612494685,
            "auditor_fn_violation": 0.005298322341979487,
            "auditor_fp_violation": 0.012140014654089941,
            "ave_precision_score": 0.637327848591767,
            "fpr": 0.19209659714599342,
            "logloss": 4.596249356643838,
            "mae": 0.3491726037941594,
            "precision": 0.6858168761220825,
            "recall": 0.7519685039370079
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7272144218900038,
            "auditor_fn_violation": 0.07982259460309968,
            "auditor_fp_violation": 0.1041713726376026,
            "ave_precision_score": 0.7282610066510438,
            "fpr": 0.31469298245614036,
            "logloss": 0.689221416130645,
            "mae": 0.4908556087890215,
            "precision": 0.5340909090909091,
            "recall": 0.7376681614349776
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7791107233921557,
            "auditor_fn_violation": 0.09256938382153385,
            "auditor_fp_violation": 0.09341029000389506,
            "ave_precision_score": 0.7798682272148625,
            "fpr": 0.25686059275521406,
            "logloss": 0.6754591775553187,
            "mae": 0.48428716705999575,
            "precision": 0.6006825938566553,
            "recall": 0.6929133858267716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.767444515614806,
            "auditor_fn_violation": 0.013789729368263708,
            "auditor_fp_violation": 0.016005007153075828,
            "ave_precision_score": 0.7393170594105738,
            "fpr": 0.16447368421052633,
            "logloss": 2.194919650904419,
            "mae": 0.3616256545135158,
            "precision": 0.696969696969697,
            "recall": 0.773542600896861
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8048772825788026,
            "auditor_fn_violation": 0.003932686240784121,
            "auditor_fp_violation": 0.019360831088461133,
            "ave_precision_score": 0.7799481432463804,
            "fpr": 0.132821075740944,
            "logloss": 1.918215772772422,
            "mae": 0.3435245280521646,
            "precision": 0.7545638945233266,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6142701100090474,
            "auditor_fn_violation": 0.06889947683109118,
            "auditor_fp_violation": 0.11022325126120021,
            "ave_precision_score": 0.603656101362371,
            "fpr": 0.3256578947368421,
            "logloss": 0.6664652734358835,
            "mae": 0.4741941699921562,
            "precision": 0.5416666666666666,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6994540169947798,
            "auditor_fn_violation": 0.08622522623749969,
            "auditor_fp_violation": 0.1013011633386266,
            "ave_precision_score": 0.6868890902412723,
            "fpr": 0.27771679473106475,
            "logloss": 0.6538145819049116,
            "mae": 0.47120098728772447,
            "precision": 0.6077519379844961,
            "recall": 0.7716535433070866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7420892309538505,
            "auditor_fn_violation": 0.011849972464794283,
            "auditor_fp_violation": 0.017082674497402316,
            "ave_precision_score": 0.6581272161425269,
            "fpr": 0.16228070175438597,
            "logloss": 3.4792356114512426,
            "mae": 0.39477120189551723,
            "precision": 0.6796536796536796,
            "recall": 0.7040358744394619
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7869109894804573,
            "auditor_fn_violation": 0.0047797263541837715,
            "auditor_fp_violation": 0.02083985912462242,
            "ave_precision_score": 0.7189377029343076,
            "fpr": 0.12403951701427003,
            "logloss": 2.6152343235254283,
            "mae": 0.3720853781464595,
            "precision": 0.7483296213808464,
            "recall": 0.6614173228346457
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7607517899985831,
            "auditor_fn_violation": 0.015505762725198657,
            "auditor_fp_violation": 0.01569676605677284,
            "ave_precision_score": 0.7551533954611426,
            "fpr": 0.16337719298245615,
            "logloss": 1.2404527909957588,
            "mae": 0.3570119819635517,
            "precision": 0.6895833333333333,
            "recall": 0.742152466367713
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7949854525034561,
            "auditor_fn_violation": 0.004397261813184448,
            "auditor_fp_violation": 0.022406049034001303,
            "ave_precision_score": 0.7899579982874724,
            "fpr": 0.12294182217343579,
            "logloss": 1.0954549031382494,
            "mae": 0.34280380897894075,
            "precision": 0.7601713062098501,
            "recall": 0.6988188976377953
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5841713640858603,
            "auditor_fn_violation": 0.06889947683109118,
            "auditor_fp_violation": 0.11022325126120021,
            "ave_precision_score": 0.5704925476840264,
            "fpr": 0.3256578947368421,
            "logloss": 0.6666424101847547,
            "mae": 0.4744837835692523,
            "precision": 0.5416666666666666,
            "recall": 0.7869955156950673
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6618119571800184,
            "auditor_fn_violation": 0.08622522623749969,
            "auditor_fp_violation": 0.1013011633386266,
            "ave_precision_score": 0.6488201160607341,
            "fpr": 0.27771679473106475,
            "logloss": 0.6551493580397977,
            "mae": 0.4720454201282183,
            "precision": 0.6077519379844961,
            "recall": 0.7716535433070866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.5847978014494637,
            "auditor_fn_violation": 0.01180571945558965,
            "auditor_fp_violation": 0.014922633837813426,
            "ave_precision_score": 0.5707693667907661,
            "fpr": 0.24013157894736842,
            "logloss": 3.6541839618254555,
            "mae": 0.3436146875716645,
            "precision": 0.6211072664359861,
            "recall": 0.804932735426009
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6665190667320187,
            "auditor_fn_violation": 0.013418671184213943,
            "auditor_fp_violation": 0.016163079864790143,
            "ave_precision_score": 0.6453189699787834,
            "fpr": 0.17672886937431395,
            "logloss": 3.3449371915914066,
            "mae": 0.3119406659010543,
            "precision": 0.7140319715808171,
            "recall": 0.7913385826771654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7789149370445042,
            "auditor_fn_violation": 0.014736252065140431,
            "auditor_fp_violation": 0.016757962502823586,
            "ave_precision_score": 0.7794596106150198,
            "fpr": 0.16228070175438597,
            "logloss": 0.9683099046065825,
            "mae": 0.34339481700435753,
            "precision": 0.6942148760330579,
            "recall": 0.7533632286995515
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.822841883518688,
            "auditor_fn_violation": 0.002238606013984809,
            "auditor_fp_violation": 0.02305703927459531,
            "ave_precision_score": 0.8231076253898792,
            "fpr": 0.11964873765093303,
            "logloss": 0.7924673782655631,
            "mae": 0.3285356422494536,
            "precision": 0.767590618336887,
            "recall": 0.7086614173228346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7681130955562233,
            "auditor_fn_violation": 0.013902820391786641,
            "auditor_fp_violation": 0.017546212634590767,
            "ave_precision_score": 0.6975991503038094,
            "fpr": 0.16557017543859648,
            "logloss": 3.503343443901229,
            "mae": 0.37615650075308066,
            "precision": 0.693089430894309,
            "recall": 0.7645739910313901
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8097838728590099,
            "auditor_fn_violation": 0.0043432413977890555,
            "auditor_fp_violation": 0.019834773774081882,
            "ave_precision_score": 0.7600990048995171,
            "fpr": 0.12952799121844127,
            "logloss": 2.6395613877862445,
            "mae": 0.35676894439169654,
            "precision": 0.756198347107438,
            "recall": 0.7204724409448819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7566706842706693,
            "auditor_fn_violation": 0.015375462198096138,
            "auditor_fp_violation": 0.017546212634590767,
            "ave_precision_score": 0.7286702458626311,
            "fpr": 0.16557017543859648,
            "logloss": 2.1618154014446933,
            "mae": 0.3734189715367137,
            "precision": 0.688659793814433,
            "recall": 0.7488789237668162
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7915423104704546,
            "auditor_fn_violation": 0.004485855294432881,
            "auditor_fp_violation": 0.02158890647258623,
            "ave_precision_score": 0.7667519491679412,
            "fpr": 0.12403951701427003,
            "logloss": 1.916416362784977,
            "mae": 0.35661047265244367,
            "precision": 0.760593220338983,
            "recall": 0.7066929133858267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5230219868662878,
            "auditor_fn_violation": 0.056034143655101884,
            "auditor_fp_violation": 0.05692342444093065,
            "ave_precision_score": 0.5307102490283723,
            "fpr": 0.3991228070175439,
            "logloss": 0.6976982658994934,
            "mae": 0.49524708945108087,
            "precision": 0.5054347826086957,
            "recall": 0.8340807174887892
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.610177785776746,
            "auditor_fn_violation": 0.06397745836106382,
            "auditor_fp_violation": 0.06411572917716468,
            "ave_precision_score": 0.6225958137986745,
            "fpr": 0.33150384193194293,
            "logloss": 0.676652130274934,
            "mae": 0.484438483657481,
            "precision": 0.5822959889349931,
            "recall": 0.8287401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 20404,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.6964972188501113,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0016235599728936124,
            "ave_precision_score": 0.6388705241538514,
            "fpr": 0.5076754385964912,
            "logloss": 8.030223246031499,
            "mae": 0.5072688341238781,
            "precision": 0.49064906490649063,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7621015186644067,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0026284752392184895,
            "ave_precision_score": 0.7156285152072412,
            "fpr": 0.43688254665203075,
            "logloss": 6.795509538307474,
            "mae": 0.43534975692757094,
            "precision": 0.5607064017660044,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 20404,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6830354443387342,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003562419998494092,
            "ave_precision_score": 0.625694189680994,
            "fpr": 0.5010964912280702,
            "logloss": 8.18843721951382,
            "mae": 0.49932646474938164,
            "precision": 0.4939091915836102,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7511160427618238,
            "auditor_fn_violation": 0.0005510082370329395,
            "auditor_fp_violation": 0.004003998550933856,
            "ave_precision_score": 0.707882097589524,
            "fpr": 0.42371020856201974,
            "logloss": 6.861430782471098,
            "mae": 0.4239896860984231,
            "precision": 0.5677491601343785,
            "recall": 0.9980314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.5822305904285878,
            "auditor_fn_violation": 0.010242113130359535,
            "auditor_fp_violation": 0.011331978013703791,
            "ave_precision_score": 0.5682174008769221,
            "fpr": 0.24451754385964913,
            "logloss": 3.698218842354732,
            "mae": 0.3462132451262501,
            "precision": 0.6161790017211703,
            "recall": 0.8026905829596412
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6639672057566178,
            "auditor_fn_violation": 0.009715031504706264,
            "auditor_fp_violation": 0.011347386369517315,
            "ave_precision_score": 0.6427689396190894,
            "fpr": 0.1778265642151482,
            "logloss": 3.3819689833605433,
            "mae": 0.3129153048892735,
            "precision": 0.7152899824253075,
            "recall": 0.8011811023622047
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5823133805088028,
            "auditor_fn_violation": 0.0018094563763669266,
            "auditor_fp_violation": 0.009875480009035476,
            "ave_precision_score": 0.5649808053003642,
            "fpr": 0.44627192982456143,
            "logloss": 5.43574523785087,
            "mae": 0.45552738258566283,
            "precision": 0.5172004744958482,
            "recall": 0.9775784753363229
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.665295544187136,
            "auditor_fn_violation": 0.006525666179762656,
            "auditor_fp_violation": 0.013722547414697132,
            "ave_precision_score": 0.6439529215398339,
            "fpr": 0.3765093304061471,
            "logloss": 4.6211391752854585,
            "mae": 0.39102249340311757,
            "precision": 0.5892215568862276,
            "recall": 0.968503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5087719298245614,
            "auc_prc": 0.6881671248560985,
            "auditor_fn_violation": 0.0006047911257965542,
            "auditor_fp_violation": 0.004776560499962376,
            "ave_precision_score": 0.610701934936205,
            "fpr": 0.4901315789473684,
            "logloss": 8.706396593158285,
            "mae": 0.4906089098268367,
            "precision": 0.49887892376681614,
            "recall": 0.9977578475336323
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.7644779048679867,
            "auditor_fn_violation": 0.0015730744963136471,
            "auditor_fp_violation": 0.008781558726674007,
            "ave_precision_score": 0.7062514964673754,
            "fpr": 0.4083424807903403,
            "logloss": 7.03375411873907,
            "mae": 0.41483101525209765,
            "precision": 0.5753424657534246,
            "recall": 0.9921259842519685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.8073449415873744,
            "auditor_fn_violation": 0.004267956887735038,
            "auditor_fp_violation": 0.008880167156087642,
            "ave_precision_score": 0.8069134830088134,
            "fpr": 0.03399122807017544,
            "logloss": 0.6397476645429052,
            "mae": 0.4151863811390034,
            "precision": 0.8530805687203792,
            "recall": 0.40358744394618834
        },
        "train": {
            "accuracy": 0.6311745334796927,
            "auc_prc": 0.8684202673667102,
            "auditor_fn_violation": 0.0007001045835242013,
            "auditor_fp_violation": 0.003758855782509336,
            "ave_precision_score": 0.8675954984978733,
            "fpr": 0.026344676180021953,
            "logloss": 0.5998837707983914,
            "mae": 0.4236788732424255,
            "precision": 0.8909090909090909,
            "recall": 0.3858267716535433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5153508771929824,
            "auc_prc": 0.6401762385574005,
            "auditor_fn_violation": 0.0006047911257965542,
            "auditor_fp_violation": 0.010101366613959804,
            "ave_precision_score": 0.5980026690177509,
            "fpr": 0.48355263157894735,
            "logloss": 7.265362036153252,
            "mae": 0.486575565758945,
            "precision": 0.5022573363431151,
            "recall": 0.9977578475336323
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7176064200956094,
            "auditor_fn_violation": 0.001957699853928797,
            "auditor_fp_violation": 0.008773387301059834,
            "ave_precision_score": 0.6791987851229602,
            "fpr": 0.4127332601536773,
            "logloss": 6.089798242866036,
            "mae": 0.4137417811425595,
            "precision": 0.5732122587968218,
            "recall": 0.9940944881889764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 20404,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4653413488466959,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4836630273031137,
            "fpr": 0.5109649122807017,
            "logloss": 0.728154248492406,
            "mae": 0.500425299858315,
            "precision": 0.48903508771929827,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5762876608320795,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5837684626528952,
            "fpr": 0.442371020856202,
            "logloss": 0.6907287410974572,
            "mae": 0.4822848063007275,
            "precision": 0.557628979143798,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.529455401913134,
            "auditor_fn_violation": 0.05169243175202581,
            "auditor_fp_violation": 0.041916083126270626,
            "ave_precision_score": 0.5317998709244075,
            "fpr": 0.3684210526315789,
            "logloss": 0.6949632081472065,
            "mae": 0.49234881356619953,
            "precision": 0.5240793201133145,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6018741880507779,
            "auditor_fn_violation": 0.05921069690657493,
            "auditor_fp_violation": 0.055064513405223725,
            "ave_precision_score": 0.6213797641095925,
            "fpr": 0.30954994511525796,
            "logloss": 0.6721965081251499,
            "mae": 0.48059519091631264,
            "precision": 0.5988620199146515,
            "recall": 0.8287401574803149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 20404,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8261419900312248,
            "auditor_fn_violation": 0.005806978207851468,
            "auditor_fp_violation": 0.02357456140350878,
            "ave_precision_score": 0.8264957306616332,
            "fpr": 0.14144736842105263,
            "logloss": 0.7163047861247083,
            "mae": 0.27302461738510003,
            "precision": 0.7323651452282157,
            "recall": 0.7914798206278026
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8903414054824756,
            "auditor_fn_violation": 0.007899945547421287,
            "auditor_fp_violation": 0.014901956511672884,
            "ave_precision_score": 0.8904953147495545,
            "fpr": 0.0889132821075741,
            "logloss": 0.6201225756392295,
            "mae": 0.25508396013671447,
            "precision": 0.8258064516129032,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 20404,
        "test": {
            "accuracy": 0.49890350877192985,
            "auc_prc": 0.6951348332618861,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.003562419998494092,
            "ave_precision_score": 0.6312815364142039,
            "fpr": 0.5010964912280702,
            "logloss": 8.33733436106036,
            "mae": 0.4993693882636866,
            "precision": 0.4939091915836102,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7647239073291502,
            "auditor_fn_violation": 0.0005510082370329395,
            "auditor_fp_violation": 0.004003998550933856,
            "ave_precision_score": 0.7156677011882634,
            "fpr": 0.42371020856201974,
            "logloss": 6.957855148885361,
            "mae": 0.42396419042589284,
            "precision": 0.5677491601343785,
            "recall": 0.9980314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7646251592044084,
            "auditor_fn_violation": 0.015370545197073402,
            "auditor_fp_violation": 0.016757962502823586,
            "ave_precision_score": 0.7616089368973078,
            "fpr": 0.16228070175438597,
            "logloss": 1.1562674663951682,
            "mae": 0.3438638944179856,
            "precision": 0.6960985626283368,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.800844708823874,
            "auditor_fn_violation": 0.005244301926584095,
            "auditor_fp_violation": 0.02338117249062329,
            "ave_precision_score": 0.7976361004231893,
            "fpr": 0.12294182217343579,
            "logloss": 1.0346195582727453,
            "mae": 0.32794378842673794,
            "precision": 0.7661795407098121,
            "recall": 0.7224409448818898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 20404,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.6879646798664578,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0018965062871771667,
            "ave_precision_score": 0.6327242339849064,
            "fpr": 0.5043859649122807,
            "logloss": 8.144399650313824,
            "mae": 0.5024949278118392,
            "precision": 0.4922737306843267,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7584001618339495,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.005028150561240759,
            "ave_precision_score": 0.713052945407894,
            "fpr": 0.4281009879253567,
            "logloss": 6.880917109678487,
            "mae": 0.42840826820349837,
            "precision": 0.5657015590200446,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8204105097573438,
            "auditor_fn_violation": 0.00883093383683424,
            "auditor_fp_violation": 0.022322773134553126,
            "ave_precision_score": 0.820849356263708,
            "fpr": 0.14583333333333334,
            "logloss": 0.7368014867883115,
            "mae": 0.2746104074589402,
            "precision": 0.7234927234927235,
            "recall": 0.7802690582959642
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8868664878926606,
            "auditor_fn_violation": 0.011780772189425831,
            "auditor_fp_violation": 0.01979119283747307,
            "ave_precision_score": 0.8870353076851649,
            "fpr": 0.09549945115257959,
            "logloss": 0.6462565935407242,
            "mae": 0.25875880525155337,
            "precision": 0.8152866242038217,
            "recall": 0.7559055118110236
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.5878689984269211,
            "auditor_fn_violation": 0.012617024624341125,
            "auditor_fp_violation": 0.02464516979143139,
            "ave_precision_score": 0.5738399042397839,
            "fpr": 0.3267543859649123,
            "logloss": 3.469691602761106,
            "mae": 0.38396617134812433,
            "precision": 0.5730659025787965,
            "recall": 0.8968609865470852
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6597346207461265,
            "auditor_fn_violation": 0.013725507143659735,
            "auditor_fp_violation": 0.025810809706564106,
            "ave_precision_score": 0.6386333174280114,
            "fpr": 0.265642151481888,
            "logloss": 3.1933442547765245,
            "mae": 0.351669117808342,
            "precision": 0.6532951289398281,
            "recall": 0.8976377952755905
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 20404,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7867307451378297,
            "auditor_fn_violation": 0.009445558964676264,
            "auditor_fp_violation": 0.01676266847375951,
            "ave_precision_score": 0.7873325374972067,
            "fpr": 0.10197368421052631,
            "logloss": 0.612217357393416,
            "mae": 0.32636822235660173,
            "precision": 0.7596899224806202,
            "recall": 0.6591928251121076
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8873154289230015,
            "auditor_fn_violation": 0.013299826270344093,
            "auditor_fp_violation": 0.0069756736659466745,
            "ave_precision_score": 0.887499548819654,
            "fpr": 0.054884742041712405,
            "logloss": 0.5265906370544828,
            "mae": 0.31409504796110216,
            "precision": 0.8727735368956743,
            "recall": 0.6751968503937008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.6546632422106917,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.004028311121150516,
            "ave_precision_score": 0.6133234692232172,
            "fpr": 0.49890350877192985,
            "logloss": 7.460194543192098,
            "mae": 0.4955543430847452,
            "precision": 0.49500554938956715,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7299333541518817,
            "auditor_fn_violation": 0.0005510082370329395,
            "auditor_fp_violation": 0.0059569692727159005,
            "ave_precision_score": 0.6914345209078063,
            "fpr": 0.41822173435784854,
            "logloss": 6.270652646808875,
            "mae": 0.42021100089027663,
            "precision": 0.5709459459459459,
            "recall": 0.9980314960629921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7630291326259309,
            "auditor_fn_violation": 0.01401099441428684,
            "auditor_fp_violation": 0.016607371432874034,
            "ave_precision_score": 0.759431294739781,
            "fpr": 0.16337719298245615,
            "logloss": 1.2422757903307777,
            "mae": 0.3553401041738729,
            "precision": 0.694672131147541,
            "recall": 0.7600896860986547
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7980416456556596,
            "auditor_fn_violation": 0.003422733519451679,
            "auditor_fp_violation": 0.019829326157005774,
            "ave_precision_score": 0.7944571887616927,
            "fpr": 0.12843029637760703,
            "logloss": 1.0758957928112518,
            "mae": 0.3393372188689249,
            "precision": 0.7577639751552795,
            "recall": 0.7204724409448819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8224559751345794,
            "auditor_fn_violation": 0.007542679568877358,
            "auditor_fp_violation": 0.017045026729914915,
            "ave_precision_score": 0.8230103825725583,
            "fpr": 0.1162280701754386,
            "logloss": 0.725563093580647,
            "mae": 0.2740984447314791,
            "precision": 0.7579908675799086,
            "recall": 0.7443946188340808
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8921643345684505,
            "auditor_fn_violation": 0.009585382507757345,
            "auditor_fp_violation": 0.008217730359297584,
            "ave_precision_score": 0.8923040645362659,
            "fpr": 0.05598243688254665,
            "logloss": 0.7136003918159051,
            "mae": 0.2634358283099381,
            "precision": 0.8740740740740741,
            "recall": 0.6968503937007874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8199580165909522,
            "auditor_fn_violation": 0.00883093383683424,
            "auditor_fp_violation": 0.02232042014908516,
            "ave_precision_score": 0.820398661616933,
            "fpr": 0.14583333333333334,
            "logloss": 0.7448893137693132,
            "mae": 0.2743613940527616,
            "precision": 0.7234927234927235,
            "recall": 0.7802690582959642
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8862154183913674,
            "auditor_fn_violation": 0.009025731004261135,
            "auditor_fp_violation": 0.019608697665423704,
            "ave_precision_score": 0.886385489624481,
            "fpr": 0.09440175631174534,
            "logloss": 0.6574185990876066,
            "mae": 0.2586528830277303,
            "precision": 0.8166311300639659,
            "recall": 0.7539370078740157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7679426292731188,
            "auditor_fn_violation": 0.013789729368263708,
            "auditor_fp_violation": 0.016005007153075828,
            "ave_precision_score": 0.7398838704993819,
            "fpr": 0.16447368421052633,
            "logloss": 2.1851794941102707,
            "mae": 0.35953879324066623,
            "precision": 0.696969696969697,
            "recall": 0.773542600896861
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8053611778793441,
            "auditor_fn_violation": 0.003932686240784121,
            "auditor_fp_violation": 0.019360831088461133,
            "ave_precision_score": 0.7804032170441284,
            "fpr": 0.132821075740944,
            "logloss": 1.9133656877767566,
            "mae": 0.34207624230163897,
            "precision": 0.7545638945233266,
            "recall": 0.7322834645669292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.833211282920212,
            "auditor_fn_violation": 0.011397608370702545,
            "auditor_fp_violation": 0.024085159250056474,
            "ave_precision_score": 0.8335374717232188,
            "fpr": 0.15021929824561403,
            "logloss": 0.5890234980411393,
            "mae": 0.2750789552016629,
            "precision": 0.732943469785575,
            "recall": 0.8430493273542601
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8904038364939095,
            "auditor_fn_violation": 0.010622574483348749,
            "auditor_fp_violation": 0.02050483067444224,
            "ave_precision_score": 0.8905801561237716,
            "fpr": 0.1207464324917673,
            "logloss": 0.4748996520892665,
            "mae": 0.26154803140428834,
            "precision": 0.7908745247148289,
            "recall": 0.8188976377952756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 20404,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7272647347307548,
            "auditor_fn_violation": 0.07982259460309968,
            "auditor_fp_violation": 0.1041713726376026,
            "ave_precision_score": 0.7283541981843419,
            "fpr": 0.31469298245614036,
            "logloss": 0.6905579722937308,
            "mae": 0.4923090477261627,
            "precision": 0.5340909090909091,
            "recall": 0.7376681614349776
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.7789853470447681,
            "auditor_fn_violation": 0.09256938382153385,
            "auditor_fp_violation": 0.09341029000389506,
            "ave_precision_score": 0.7797030810479119,
            "fpr": 0.25686059275521406,
            "logloss": 0.680724644483494,
            "mae": 0.4875353102364734,
            "precision": 0.6006825938566553,
            "recall": 0.6929133858267716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 20404,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7546414141502984,
            "auditor_fn_violation": 0.017140665565258433,
            "auditor_fp_violation": 0.019807431669302017,
            "ave_precision_score": 0.7519686913116771,
            "fpr": 0.16337719298245615,
            "logloss": 1.160003981870391,
            "mae": 0.351010345768596,
            "precision": 0.6940451745379876,
            "recall": 0.757847533632287
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.7871533024366575,
            "auditor_fn_violation": 0.015581648616645202,
            "auditor_fp_violation": 0.025881628728553416,
            "ave_precision_score": 0.7856231262685186,
            "fpr": 0.12294182217343579,
            "logloss": 1.0089043618073947,
            "mae": 0.3427408013536782,
            "precision": 0.7570498915401301,
            "recall": 0.687007874015748
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 20404,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.5811700202140893,
            "auditor_fn_violation": 0.010714145228542207,
            "auditor_fp_violation": 0.012409645358030269,
            "ave_precision_score": 0.5671442484553614,
            "fpr": 0.25,
            "logloss": 3.7029414384184056,
            "mae": 0.3462745449326803,
            "precision": 0.6187290969899666,
            "recall": 0.8295964125560538
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6621416861331424,
            "auditor_fn_violation": 0.007562858155354072,
            "auditor_fp_violation": 0.01863902182587782,
            "ave_precision_score": 0.6409508450854844,
            "fpr": 0.19209659714599342,
            "logloss": 3.3610777083028816,
            "mae": 0.31154105268828913,
            "precision": 0.7043918918918919,
            "recall": 0.8208661417322834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 20404,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.4619116718656151,
            "auditor_fn_violation": 0.04435134922508067,
            "auditor_fp_violation": 0.014023793389052033,
            "ave_precision_score": 0.4745191766643567,
            "fpr": 0.10416666666666667,
            "logloss": 0.6999223100997546,
            "mae": 0.5015984088705298,
            "precision": 0.43452380952380953,
            "recall": 0.16367713004484305
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.543564706852835,
            "auditor_fn_violation": 0.05733942971727876,
            "auditor_fp_violation": 0.021760506410483396,
            "ave_precision_score": 0.5537829159472278,
            "fpr": 0.08122941822173436,
            "logloss": 0.70282322533749,
            "mae": 0.5030952549072312,
            "precision": 0.5375,
            "recall": 0.16929133858267717
        }
    }
]