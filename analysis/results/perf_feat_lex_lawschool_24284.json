[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8418690321289446,
            "auditor_fn_violation": 0.00748035733505543,
            "auditor_fp_violation": 0.01545197212890382,
            "ave_precision_score": 0.8426311476283483,
            "fpr": 0.14144736842105263,
            "logloss": 0.7819022090957964,
            "mae": 0.2678491152200838,
            "precision": 0.75,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8118326350119992,
            "auditor_fn_violation": 0.00788923904960873,
            "auditor_fp_violation": 0.025136227375426406,
            "ave_precision_score": 0.8121951975075627,
            "fpr": 0.15916575192096596,
            "logloss": 0.8812785240448032,
            "mae": 0.2749495072987778,
            "precision": 0.720616570327553,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.848333994597333,
            "auditor_fn_violation": 0.013823861801743624,
            "auditor_fp_violation": 0.018845132926879858,
            "ave_precision_score": 0.8489516702560479,
            "fpr": 0.1699561403508772,
            "logloss": 0.8140711301286389,
            "mae": 0.27043673766855525,
            "precision": 0.726148409893993,
            "recall": 0.8404907975460123
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8119041716432557,
            "auditor_fn_violation": 0.015934279947593926,
            "auditor_fp_violation": 0.03518038128897924,
            "ave_precision_score": 0.8122473291798828,
            "fpr": 0.1986827661909989,
            "logloss": 0.9540647471519286,
            "mae": 0.28027887385359324,
            "precision": 0.6863084922010398,
            "recall": 0.8516129032258064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8749913894367792,
            "auditor_fn_violation": 0.01799232231909016,
            "auditor_fp_violation": 0.0165899382024802,
            "ave_precision_score": 0.8751689654610368,
            "fpr": 0.10635964912280702,
            "logloss": 0.610367676036568,
            "mae": 0.26484461634296513,
            "precision": 0.7913978494623656,
            "recall": 0.7525562372188139
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8368238008437825,
            "auditor_fn_violation": 0.021713112141921318,
            "auditor_fp_violation": 0.019194892519431173,
            "ave_precision_score": 0.837124676940445,
            "fpr": 0.13721185510428102,
            "logloss": 0.659777751907053,
            "mae": 0.27117191461318646,
            "precision": 0.7433264887063655,
            "recall": 0.7784946236559139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8697257293533263,
            "auditor_fn_violation": 0.005202166971621283,
            "auditor_fp_violation": 0.016351457840819542,
            "ave_precision_score": 0.8699611805327172,
            "fpr": 0.20175438596491227,
            "logloss": 0.5800110133393783,
            "mae": 0.29781780890475046,
            "precision": 0.7051282051282052,
            "recall": 0.8997955010224948
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8252096972437091,
            "auditor_fn_violation": 0.0034418044686802905,
            "auditor_fp_violation": 0.021215537058276276,
            "ave_precision_score": 0.8266563487639451,
            "fpr": 0.2283205268935236,
            "logloss": 0.6555405969595223,
            "mae": 0.312794487924406,
            "precision": 0.6703645007923931,
            "recall": 0.9096774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8484674858881052,
            "auditor_fn_violation": 0.014411347899400852,
            "auditor_fp_violation": 0.01825411637841649,
            "ave_precision_score": 0.8488155296191975,
            "fpr": 0.13706140350877194,
            "logloss": 0.7456885781439557,
            "mae": 0.26646312578711595,
            "precision": 0.7539370078740157,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8137092461895541,
            "auditor_fn_violation": 0.013162895553745736,
            "auditor_fp_violation": 0.024141902900769372,
            "ave_precision_score": 0.8140599060589349,
            "fpr": 0.1525795828759605,
            "logloss": 0.8410479992847627,
            "mae": 0.27493559053476063,
            "precision": 0.7290448343079922,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8306125343978376,
            "auditor_fn_violation": 0.004975693323287768,
            "auditor_fp_violation": 0.014184397163120572,
            "ave_precision_score": 0.8320620985408471,
            "fpr": 0.11842105263157894,
            "logloss": 0.8162827939215608,
            "mae": 0.26739930009104684,
            "precision": 0.7716701902748414,
            "recall": 0.7464212678936605
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8021281419829688,
            "auditor_fn_violation": 0.011484484732599179,
            "auditor_fp_violation": 0.018660812294182223,
            "ave_precision_score": 0.8035018864984916,
            "fpr": 0.13611416026344675,
            "logloss": 0.888803100680542,
            "mae": 0.2755048718724414,
            "precision": 0.7416666666666667,
            "recall": 0.7655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8504174515806695,
            "auditor_fn_violation": 0.014411347899400852,
            "auditor_fp_violation": 0.0168387872755174,
            "ave_precision_score": 0.8507200674602586,
            "fpr": 0.13267543859649122,
            "logloss": 0.7321100083764774,
            "mae": 0.2662872404697032,
            "precision": 0.7599206349206349,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8143913425826022,
            "auditor_fn_violation": 0.011800809697484744,
            "auditor_fp_violation": 0.021274605838948975,
            "ave_precision_score": 0.814739677022959,
            "fpr": 0.15148188803512624,
            "logloss": 0.8264224230294936,
            "mae": 0.2747877311245126,
            "precision": 0.7299412915851272,
            "recall": 0.8021505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8481692996503127,
            "auditor_fn_violation": 0.011056847128045064,
            "auditor_fp_violation": 0.015887458006718928,
            "ave_precision_score": 0.848697111814977,
            "fpr": 0.12828947368421054,
            "logloss": 0.7610303459855797,
            "mae": 0.265047841203314,
            "precision": 0.7655310621242485,
            "recall": 0.7811860940695297
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8128757553755991,
            "auditor_fn_violation": 0.015974410726721195,
            "auditor_fp_violation": 0.03163133205022816,
            "ave_precision_score": 0.8131977467579949,
            "fpr": 0.16355653128430298,
            "logloss": 0.8659469820500956,
            "mae": 0.27466385046176256,
            "precision": 0.7145593869731801,
            "recall": 0.8021505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5448899017644924,
            "auditor_fn_violation": 0.004980177949987444,
            "auditor_fp_violation": 0.006858902575587913,
            "ave_precision_score": 0.5462705786287667,
            "fpr": 0.39473684210526316,
            "logloss": 1.2294842799404015,
            "mae": 0.4638699554397087,
            "precision": 0.55,
            "recall": 0.8997955010224948
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5170102073801055,
            "auditor_fn_violation": 0.00813238435843868,
            "auditor_fp_violation": 0.0063252819303677614,
            "ave_precision_score": 0.5184810255595804,
            "fpr": 0.41931942919868276,
            "logloss": 1.3234285327918707,
            "mae": 0.4772853248565571,
            "precision": 0.5176767676767676,
            "recall": 0.8817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8469845494930519,
            "auditor_fn_violation": 0.010148710221361178,
            "auditor_fp_violation": 0.016260731616274726,
            "ave_precision_score": 0.8473433959891193,
            "fpr": 0.125,
            "logloss": 0.7357443599819893,
            "mae": 0.26678915652475965,
            "precision": 0.7649484536082474,
            "recall": 0.7586912065439673
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.818607691238604,
            "auditor_fn_violation": 0.011220093717172436,
            "auditor_fp_violation": 0.019556688801051433,
            "ave_precision_score": 0.8189124980713125,
            "fpr": 0.14489571899012074,
            "logloss": 0.8018062972075976,
            "mae": 0.27243767475634745,
            "precision": 0.7354709418837675,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8601351738641879,
            "auditor_fn_violation": 0.01453915976034156,
            "auditor_fp_violation": 0.014837625979843228,
            "ave_precision_score": 0.8603371868584413,
            "fpr": 0.10855263157894737,
            "logloss": 0.744613859732246,
            "mae": 0.26212179859805573,
            "precision": 0.7847826086956522,
            "recall": 0.7382413087934561
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.813964447203808,
            "auditor_fn_violation": 0.017053220495024966,
            "auditor_fp_violation": 0.018498373147332305,
            "ave_precision_score": 0.8143377011958061,
            "fpr": 0.13830954994511527,
            "logloss": 0.8354253550895361,
            "mae": 0.2708860109774783,
            "precision": 0.7423312883435583,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8603426635535487,
            "auditor_fn_violation": 0.03169285688659276,
            "auditor_fp_violation": 0.018816618970594334,
            "ave_precision_score": 0.8604082140630376,
            "fpr": 0.09100877192982457,
            "logloss": 2.0739835614721924,
            "mae": 0.27488281809189236,
            "precision": 0.8042452830188679,
            "recall": 0.6973415132924335
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8254518842505818,
            "auditor_fn_violation": 0.0300768386388584,
            "auditor_fp_violation": 0.026251150610623518,
            "ave_precision_score": 0.8255817592307402,
            "fpr": 0.1207464324917673,
            "logloss": 1.897948337870521,
            "mae": 0.2789365949748221,
            "precision": 0.7560975609756098,
            "recall": 0.7333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8454014255491664,
            "auditor_fn_violation": 0.0053725827862088765,
            "auditor_fp_violation": 0.018368172203558547,
            "ave_precision_score": 0.8456570485604714,
            "fpr": 0.1513157894736842,
            "logloss": 0.7737518772536257,
            "mae": 0.26835360818402093,
            "precision": 0.7410881801125704,
            "recall": 0.8077709611451943
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8089717747456929,
            "auditor_fn_violation": 0.00653659572961298,
            "auditor_fp_violation": 0.023401081943165987,
            "ave_precision_score": 0.8092969846328316,
            "fpr": 0.1668496158068057,
            "logloss": 0.882414883750713,
            "mae": 0.27835116554711287,
            "precision": 0.7132075471698113,
            "recall": 0.8129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8473249126799443,
            "auditor_fn_violation": 0.014604186847486818,
            "auditor_fp_violation": 0.02120401476504501,
            "ave_precision_score": 0.8475885611885573,
            "fpr": 0.11732456140350878,
            "logloss": 0.8209499114062293,
            "mae": 0.27055102200424863,
            "precision": 0.7693965517241379,
            "recall": 0.7300613496932515
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8008668086945638,
            "auditor_fn_violation": 0.021177248208868907,
            "auditor_fp_violation": 0.03303421559120467,
            "ave_precision_score": 0.8012300539781532,
            "fpr": 0.1437980241492865,
            "logloss": 0.9132626103981177,
            "mae": 0.2776292037284686,
            "precision": 0.7353535353535353,
            "recall": 0.7827956989247312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 24284,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8488713811389439,
            "auditor_fn_violation": 0.014689394754780614,
            "auditor_fp_violation": 0.02055597030401062,
            "ave_precision_score": 0.8495316066573085,
            "fpr": 0.17214912280701755,
            "logloss": 0.8150846542913177,
            "mae": 0.27056696129590296,
            "precision": 0.7240773286467487,
            "recall": 0.8425357873210634
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8118963060619364,
            "auditor_fn_violation": 0.015360645869480542,
            "auditor_fp_violation": 0.035392044419723066,
            "ave_precision_score": 0.812240587020338,
            "fpr": 0.19758507135016465,
            "logloss": 0.9566803330413456,
            "mae": 0.2803662294511673,
            "precision": 0.6880415944540728,
            "recall": 0.853763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8403123567829062,
            "auditor_fn_violation": 0.008529759982779037,
            "auditor_fp_violation": 0.01716021732819045,
            "ave_precision_score": 0.8409500866790989,
            "fpr": 0.13925438596491227,
            "logloss": 0.7977210799814722,
            "mae": 0.2682541877684037,
            "precision": 0.748015873015873,
            "recall": 0.7709611451942741
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8067652734913867,
            "auditor_fn_violation": 0.008314153181544564,
            "auditor_fp_violation": 0.019945558273813335,
            "ave_precision_score": 0.8071728000484196,
            "fpr": 0.14928649835345773,
            "logloss": 0.9004143277675586,
            "mae": 0.2756357302648298,
            "precision": 0.7301587301587301,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8392799585880355,
            "auditor_fn_violation": 0.009837028665733865,
            "auditor_fp_violation": 0.018282630334702007,
            "ave_precision_score": 0.8405136510003686,
            "fpr": 0.14364035087719298,
            "logloss": 0.8317142934299938,
            "mae": 0.2666132221050141,
            "precision": 0.7461240310077519,
            "recall": 0.787321063394683
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8007694964289223,
            "auditor_fn_violation": 0.016899779280714802,
            "auditor_fp_violation": 0.03515330809783759,
            "ave_precision_score": 0.8010861397781112,
            "fpr": 0.17014270032930845,
            "logloss": 0.9747591084416364,
            "mae": 0.27923870569484094,
            "precision": 0.7086466165413534,
            "recall": 0.810752688172043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8425394272796238,
            "auditor_fn_violation": 0.010801223406163669,
            "auditor_fp_violation": 0.016913960432997394,
            "ave_precision_score": 0.8428905221853848,
            "fpr": 0.13157894736842105,
            "logloss": 0.7852365008598919,
            "mae": 0.2671827607401139,
            "precision": 0.757085020242915,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8079001277689747,
            "auditor_fn_violation": 0.009428372460842988,
            "auditor_fp_violation": 0.021043253114647588,
            "ave_precision_score": 0.8083251741689028,
            "fpr": 0.14928649835345773,
            "logloss": 0.8867909711730665,
            "mae": 0.2749665185755089,
            "precision": 0.7296222664015904,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8674038706158862,
            "auditor_fn_violation": 0.004383722598930868,
            "auditor_fp_violation": 0.01907324457716396,
            "ave_precision_score": 0.8675902829106414,
            "fpr": 0.2050438596491228,
            "logloss": 0.6527560367941596,
            "mae": 0.2887585220752251,
            "precision": 0.7031746031746032,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8378898769504255,
            "auditor_fn_violation": 0.005637194150348786,
            "auditor_fp_violation": 0.02292853169778444,
            "ave_precision_score": 0.838266785789582,
            "fpr": 0.2305159165751921,
            "logloss": 0.7329056512765061,
            "mae": 0.3017458684811968,
            "precision": 0.6682464454976303,
            "recall": 0.9096774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.827462633637804,
            "auditor_fn_violation": 0.004520503713270908,
            "auditor_fp_violation": 0.0126938949027415,
            "ave_precision_score": 0.8282189340633372,
            "fpr": 0.27521929824561403,
            "logloss": 0.8293877920678521,
            "mae": 0.33641363668925406,
            "precision": 0.6499302649930265,
            "recall": 0.9529652351738241
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.8264734639668774,
            "auditor_fn_violation": 0.004225534978695279,
            "auditor_fp_violation": 0.02082666758551437,
            "ave_precision_score": 0.8269556834826312,
            "fpr": 0.30954994511525796,
            "logloss": 0.8930536392282672,
            "mae": 0.35325274504025994,
            "precision": 0.6104972375690608,
            "recall": 0.9505376344086022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.862769498994228,
            "auditor_fn_violation": 0.008058874179313318,
            "auditor_fp_violation": 0.01566971506781137,
            "ave_precision_score": 0.8629580488334923,
            "fpr": 0.125,
            "logloss": 0.8463932101811118,
            "mae": 0.27827988286116934,
            "precision": 0.762993762993763,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8195332753487101,
            "auditor_fn_violation": 0.0019900145178995085,
            "auditor_fp_violation": 0.015923958789680684,
            "ave_precision_score": 0.8199466347719468,
            "fpr": 0.11855104281009879,
            "logloss": 0.9175426148941324,
            "mae": 0.2785068334378459,
            "precision": 0.7662337662337663,
            "recall": 0.7612903225806451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8520357610321336,
            "auditor_fn_violation": 0.010816919599612536,
            "auditor_fp_violation": 0.01518756998880179,
            "ave_precision_score": 0.852294955304238,
            "fpr": 0.11842105263157894,
            "logloss": 0.7048891904318227,
            "mae": 0.2716069810618125,
            "precision": 0.7692307692307693,
            "recall": 0.7361963190184049
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.822683220328899,
            "auditor_fn_violation": 0.009671517769672934,
            "auditor_fp_violation": 0.021259838643780806,
            "ave_precision_score": 0.823021351331356,
            "fpr": 0.1394072447859495,
            "logloss": 0.750654644260235,
            "mae": 0.2736768438949812,
            "precision": 0.7381443298969073,
            "recall": 0.7698924731182796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8706182661672748,
            "auditor_fn_violation": 0.01225648477020773,
            "auditor_fp_violation": 0.009443303886193024,
            "ave_precision_score": 0.870826608150669,
            "fpr": 0.04824561403508772,
            "logloss": 0.5909423913765139,
            "mae": 0.3223775811181846,
            "precision": 0.8713450292397661,
            "recall": 0.6094069529652352
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8372661706205657,
            "auditor_fn_violation": 0.013620858562609924,
            "auditor_fp_violation": 0.011739920158698127,
            "ave_precision_score": 0.8375397636146544,
            "fpr": 0.059275521405049394,
            "logloss": 0.5895930390137518,
            "mae": 0.32255802352287966,
            "precision": 0.8439306358381503,
            "recall": 0.6279569892473118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8789662129828498,
            "auditor_fn_violation": 0.020927510494026476,
            "auditor_fp_violation": 0.021159947741694662,
            "ave_precision_score": 0.8791442245034715,
            "fpr": 0.12171052631578948,
            "logloss": 0.7050290921220691,
            "mae": 0.26371665993390453,
            "precision": 0.7766599597585513,
            "recall": 0.7893660531697342
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8419823581754673,
            "auditor_fn_violation": 0.02278247937395985,
            "auditor_fp_violation": 0.02481381028092128,
            "ave_precision_score": 0.8422914147821958,
            "fpr": 0.1525795828759605,
            "logloss": 0.7716964962514282,
            "mae": 0.27170552295568007,
            "precision": 0.7311411992263056,
            "recall": 0.8129032258064516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8721200315695383,
            "auditor_fn_violation": 0.009462562336311129,
            "auditor_fp_violation": 0.009137426900584802,
            "ave_precision_score": 0.8722967908546715,
            "fpr": 0.10307017543859649,
            "logloss": 0.5313366960378881,
            "mae": 0.28073599867919957,
            "precision": 0.793859649122807,
            "recall": 0.7402862985685071
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.837199573271963,
            "auditor_fn_violation": 0.009234800467405546,
            "auditor_fp_violation": 0.01957637839460899,
            "ave_precision_score": 0.8374846952361049,
            "fpr": 0.1207464324917673,
            "logloss": 0.5430456741998644,
            "mae": 0.2787536782934305,
            "precision": 0.7664543524416136,
            "recall": 0.7763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8446986379277919,
            "auditor_fn_violation": 0.014180389624367667,
            "auditor_fp_violation": 0.016112977479158887,
            "ave_precision_score": 0.8452259900099013,
            "fpr": 0.12390350877192982,
            "logloss": 0.7986001941036847,
            "mae": 0.26818999907895,
            "precision": 0.7684426229508197,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8036300653706248,
            "auditor_fn_violation": 0.01951772246025283,
            "auditor_fp_violation": 0.030956963470881563,
            "ave_precision_score": 0.804002278096683,
            "fpr": 0.15697036223929747,
            "logloss": 0.912570203146682,
            "mae": 0.27713745392567496,
            "precision": 0.717391304347826,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8606169238806585,
            "auditor_fn_violation": 0.017893660531697345,
            "auditor_fp_violation": 0.017429803823980756,
            "ave_precision_score": 0.860811371615532,
            "fpr": 0.12280701754385964,
            "logloss": 0.7069449435829476,
            "mae": 0.267237214063513,
            "precision": 0.7695473251028807,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8286758548763657,
            "auditor_fn_violation": 0.013356467547183181,
            "auditor_fp_violation": 0.020846357179071937,
            "ave_precision_score": 0.8290138516755112,
            "fpr": 0.13391877058177826,
            "logloss": 0.7681120455467204,
            "mae": 0.26971379194202466,
            "precision": 0.75,
            "recall": 0.7870967741935484
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8481994482322881,
            "auditor_fn_violation": 0.010897642880206653,
            "auditor_fp_violation": 0.014682095309194976,
            "ave_precision_score": 0.84856295639096,
            "fpr": 0.13486842105263158,
            "logloss": 0.49963496922066314,
            "mae": 0.32477443802411454,
            "precision": 0.7588235294117647,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8341556913449908,
            "auditor_fn_violation": 0.00914273573881945,
            "auditor_fp_violation": 0.012699787844629423,
            "ave_precision_score": 0.8344853824983794,
            "fpr": 0.14489571899012074,
            "logloss": 0.5120134499882876,
            "mae": 0.324894885330141,
            "precision": 0.7426900584795322,
            "recall": 0.8193548387096774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8553775534358312,
            "auditor_fn_violation": 0.016830804003874725,
            "auditor_fp_violation": 0.013199369582348307,
            "ave_precision_score": 0.8557552961110764,
            "fpr": 0.11074561403508772,
            "logloss": 0.6868567396254676,
            "mae": 0.26255583528822124,
            "precision": 0.7823275862068966,
            "recall": 0.7423312883435583
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8239855700443826,
            "auditor_fn_violation": 0.01775196817865279,
            "auditor_fp_violation": 0.023460150723838686,
            "ave_precision_score": 0.8242683069861714,
            "fpr": 0.13721185510428102,
            "logloss": 0.7608610059398713,
            "mae": 0.270061243877029,
            "precision": 0.7448979591836735,
            "recall": 0.7849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.846363328594135,
            "auditor_fn_violation": 0.013803680981595096,
            "auditor_fp_violation": 0.019651300236406627,
            "ave_precision_score": 0.8466890035220728,
            "fpr": 0.15679824561403508,
            "logloss": 0.8298380911364744,
            "mae": 0.27115337328710337,
            "precision": 0.7332089552238806,
            "recall": 0.803680981595092
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8094473417988948,
            "auditor_fn_violation": 0.015839854584941516,
            "auditor_fp_violation": 0.034254970391773686,
            "ave_precision_score": 0.8097802762558137,
            "fpr": 0.18551042810098792,
            "logloss": 0.9568588706269349,
            "mae": 0.27913470131606294,
            "precision": 0.6938405797101449,
            "recall": 0.8236559139784946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8758279164378265,
            "auditor_fn_violation": 0.01801474545258853,
            "auditor_fp_violation": 0.0165899382024802,
            "ave_precision_score": 0.8760063281383776,
            "fpr": 0.10635964912280702,
            "logloss": 0.6130074725354171,
            "mae": 0.2625979418088581,
            "precision": 0.7913978494623656,
            "recall": 0.7525562372188139
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8359655883431835,
            "auditor_fn_violation": 0.022081371056265713,
            "auditor_fp_violation": 0.01914320733634257,
            "ave_precision_score": 0.8362808498179987,
            "fpr": 0.13830954994511527,
            "logloss": 0.6663710326192113,
            "mae": 0.26978659101251523,
            "precision": 0.7428571428571429,
            "recall": 0.7827956989247312
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.8662822236320951,
            "auditor_fn_violation": 0.005146109137875367,
            "auditor_fp_violation": 0.0038364232093235457,
            "ave_precision_score": 0.8664667368208095,
            "fpr": 0.020833333333333332,
            "logloss": 0.8579189106357624,
            "mae": 0.33949454515877414,
            "precision": 0.9221311475409836,
            "recall": 0.4601226993865031
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.8324113231406213,
            "auditor_fn_violation": 0.005179231141484604,
            "auditor_fp_violation": 0.01069144930175779,
            "ave_precision_score": 0.8328139651304325,
            "fpr": 0.03293084522502744,
            "logloss": 0.8099711517550873,
            "mae": 0.3353060999693902,
            "precision": 0.871244635193133,
            "recall": 0.43655913978494626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8601573161055358,
            "auditor_fn_violation": 0.014364259319054284,
            "auditor_fp_violation": 0.012527995520716687,
            "ave_precision_score": 0.8603742019980409,
            "fpr": 0.11074561403508772,
            "logloss": 0.7269961698860102,
            "mae": 0.26307770977978717,
            "precision": 0.7827956989247312,
            "recall": 0.7443762781186094
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8170628500758204,
            "auditor_fn_violation": 0.0173152508763854,
            "auditor_fp_violation": 0.02312050523497069,
            "ave_precision_score": 0.8173808947610584,
            "fpr": 0.141602634467618,
            "logloss": 0.8266385033696485,
            "mae": 0.27214289724451807,
            "precision": 0.7372708757637475,
            "recall": 0.7784946236559139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8715587352426805,
            "auditor_fn_violation": 0.015790370609550464,
            "auditor_fp_violation": 0.013012732777570405,
            "ave_precision_score": 0.871728703642711,
            "fpr": 0.11732456140350878,
            "logloss": 0.5249645613745116,
            "mae": 0.27380619107428,
            "precision": 0.7784679089026915,
            "recall": 0.7689161554192229
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8313216799674903,
            "auditor_fn_violation": 0.01199438169092219,
            "auditor_fp_violation": 0.01686905928044381,
            "ave_precision_score": 0.8316773375901552,
            "fpr": 0.13830954994511527,
            "logloss": 0.5711372257033034,
            "mae": 0.2815853664472609,
            "precision": 0.748,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8390597497606788,
            "auditor_fn_violation": 0.01151427905141177,
            "auditor_fp_violation": 0.01705393803658082,
            "ave_precision_score": 0.8409755898553791,
            "fpr": 0.14802631578947367,
            "logloss": 0.8475101686416794,
            "mae": 0.27139463897705773,
            "precision": 0.7438330170777988,
            "recall": 0.8016359918200409
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7993598902021317,
            "auditor_fn_violation": 0.015499923279392848,
            "auditor_fp_violation": 0.03785324361441869,
            "ave_precision_score": 0.7997521246843811,
            "fpr": 0.1800219538968167,
            "logloss": 0.986127745903683,
            "mae": 0.2801477587848885,
            "precision": 0.6996336996336996,
            "recall": 0.821505376344086
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8751808791684742,
            "auditor_fn_violation": 0.0013767803967997703,
            "auditor_fp_violation": 0.019837937041184535,
            "ave_precision_score": 0.875383123592101,
            "fpr": 0.20285087719298245,
            "logloss": 0.5879587406394002,
            "mae": 0.29249179736596714,
            "precision": 0.7054140127388535,
            "recall": 0.9059304703476483
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8362818693855664,
            "auditor_fn_violation": 0.004083896934716665,
            "auditor_fp_violation": 0.020836512382293143,
            "ave_precision_score": 0.8366606053985095,
            "fpr": 0.2327113062568606,
            "logloss": 0.673275213792836,
            "mae": 0.30839411220814866,
            "precision": 0.6666666666666666,
            "recall": 0.9118279569892473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8717527729206915,
            "auditor_fn_violation": 0.009222634807878596,
            "auditor_fp_violation": 0.01804155779519721,
            "ave_precision_score": 0.8719261087664651,
            "fpr": 0.14035087719298245,
            "logloss": 0.5355510830202024,
            "mae": 0.27413951271425996,
            "precision": 0.7543186180422264,
            "recall": 0.803680981595092
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8321196517115084,
            "auditor_fn_violation": 0.012891422636120062,
            "auditor_fp_violation": 0.023799796212706687,
            "ave_precision_score": 0.832473953468519,
            "fpr": 0.16465422612513722,
            "logloss": 0.5948642176540636,
            "mae": 0.28205088228365544,
            "precision": 0.7217068645640075,
            "recall": 0.8365591397849462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.864841931435392,
            "auditor_fn_violation": 0.009982779033473261,
            "auditor_fp_violation": 0.01487910082534943,
            "ave_precision_score": 0.8650265844136605,
            "fpr": 0.11293859649122807,
            "logloss": 0.7981584984013341,
            "mae": 0.2807493686893328,
            "precision": 0.778969957081545,
            "recall": 0.7423312883435583
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8249986000873252,
            "auditor_fn_violation": 0.006701840114254687,
            "auditor_fp_violation": 0.0160839367373359,
            "ave_precision_score": 0.8253720880520911,
            "fpr": 0.11086717892425905,
            "logloss": 0.861209464324704,
            "mae": 0.28033852114303703,
            "precision": 0.7755555555555556,
            "recall": 0.7505376344086021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.8372428157601953,
            "auditor_fn_violation": 0.010944731460553227,
            "auditor_fp_violation": 0.005477271784662603,
            "ave_precision_score": 0.8384694527369885,
            "fpr": 0.03508771929824561,
            "logloss": 1.3180175467328084,
            "mae": 0.3370466526976977,
            "precision": 0.8745098039215686,
            "recall": 0.4560327198364008
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8154481236378865,
            "auditor_fn_violation": 0.017626854573138354,
            "auditor_fp_violation": 0.008156414131221298,
            "ave_precision_score": 0.8157438105091566,
            "fpr": 0.050493962678375415,
            "logloss": 1.277540118567797,
            "mae": 0.3335702203507556,
            "precision": 0.8181818181818182,
            "recall": 0.44516129032258067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8390759662481484,
            "auditor_fn_violation": 0.014066031643525993,
            "auditor_fp_violation": 0.01518238563311352,
            "ave_precision_score": 0.840286332875251,
            "fpr": 0.10087719298245613,
            "logloss": 0.8593051761325701,
            "mae": 0.2737544505001072,
            "precision": 0.786046511627907,
            "recall": 0.6912065439672802
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8071948711488932,
            "auditor_fn_violation": 0.017371906093976847,
            "auditor_fp_violation": 0.022761170152545123,
            "ave_precision_score": 0.8075448429759946,
            "fpr": 0.12294182217343579,
            "logloss": 0.9277311973559094,
            "mae": 0.2783149173798583,
            "precision": 0.7533039647577092,
            "recall": 0.7354838709677419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 24284,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8694462197942392,
            "auditor_fn_violation": 0.022761722814192947,
            "auditor_fp_violation": 0.008468645016797314,
            "ave_precision_score": 0.8696320542114795,
            "fpr": 0.07456140350877193,
            "logloss": 0.8945263830165482,
            "mae": 0.28172782971432314,
            "precision": 0.8287153652392947,
            "recall": 0.6728016359918201
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8377542399104247,
            "auditor_fn_violation": 0.019203758129433573,
            "auditor_fp_violation": 0.01074805688323579,
            "ave_precision_score": 0.8380878788176908,
            "fpr": 0.08232711306256861,
            "logloss": 0.9265737486590174,
            "mae": 0.277518170868931,
            "precision": 0.8138957816377171,
            "recall": 0.7053763440860215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8635745042278586,
            "auditor_fn_violation": 0.017375686147885056,
            "auditor_fp_violation": 0.018617021276595754,
            "ave_precision_score": 0.8637647670283717,
            "fpr": 0.11842105263157894,
            "logloss": 0.6948224144162245,
            "mae": 0.2627325181331007,
            "precision": 0.7740585774058577,
            "recall": 0.7566462167689162
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8164890882604169,
            "auditor_fn_violation": 0.018450715862280614,
            "auditor_fp_violation": 0.02631268059049091,
            "ave_precision_score": 0.8168464557092652,
            "fpr": 0.14818880351262348,
            "logloss": 0.8011970978260642,
            "mae": 0.2737825213487649,
            "precision": 0.7310756972111554,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8741311045647474,
            "auditor_fn_violation": 0.013263283464284443,
            "auditor_fp_violation": 0.013282319273360712,
            "ave_precision_score": 0.8743038452801303,
            "fpr": 0.09978070175438597,
            "logloss": 0.609758397266686,
            "mae": 0.27452571928874103,
            "precision": 0.7977777777777778,
            "recall": 0.7341513292433538
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8530644359295207,
            "auditor_fn_violation": 0.010332495308239797,
            "auditor_fp_violation": 0.019015224978218392,
            "ave_precision_score": 0.8532969499631397,
            "fpr": 0.11525795828759605,
            "logloss": 0.6599314415693339,
            "mae": 0.2727723673927423,
            "precision": 0.7756410256410257,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8717539418217584,
            "auditor_fn_violation": 0.00793778925842213,
            "auditor_fp_violation": 0.019705735971133512,
            "ave_precision_score": 0.8719275085194385,
            "fpr": 0.14583333333333334,
            "logloss": 0.5358707224148777,
            "mae": 0.27464757580310106,
            "precision": 0.7485822306238186,
            "recall": 0.8098159509202454
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8321367084951867,
            "auditor_fn_violation": 0.014659537551786414,
            "auditor_fp_violation": 0.02300729007201469,
            "ave_precision_score": 0.8324921326448091,
            "fpr": 0.16794731064763996,
            "logloss": 0.5973322663839967,
            "mae": 0.2828028395211756,
            "precision": 0.71875,
            "recall": 0.8408602150537634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8644287270477582,
            "auditor_fn_violation": 0.014501040433394336,
            "auditor_fp_violation": 0.015778586537265153,
            "ave_precision_score": 0.8646223547494876,
            "fpr": 0.10526315789473684,
            "logloss": 0.6949882039773627,
            "mae": 0.2628378685695589,
            "precision": 0.7903930131004366,
            "recall": 0.7402862985685071
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8192393314468023,
            "auditor_fn_violation": 0.018781204631564043,
            "auditor_fp_violation": 0.02223447352488026,
            "ave_precision_score": 0.8195545798648362,
            "fpr": 0.1394072447859495,
            "logloss": 0.7906100164494256,
            "mae": 0.27269714646292553,
            "precision": 0.7397540983606558,
            "recall": 0.7763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8581336651629831,
            "auditor_fn_violation": 0.03053358088472715,
            "auditor_fp_violation": 0.03480776409107876,
            "ave_precision_score": 0.8584396098476618,
            "fpr": 0.17105263157894737,
            "logloss": 0.552019455193553,
            "mae": 0.30205690826479487,
            "precision": 0.7267950963222417,
            "recall": 0.8486707566462167
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8291925229249477,
            "auditor_fn_violation": 0.02974634986957497,
            "auditor_fp_violation": 0.042549211677897936,
            "ave_precision_score": 0.8297237210363579,
            "fpr": 0.2052689352360044,
            "logloss": 0.5957716539570752,
            "mae": 0.31276058713074506,
            "precision": 0.6803418803418804,
            "recall": 0.8559139784946237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8458899458320279,
            "auditor_fn_violation": 0.011343863236824169,
            "auditor_fp_violation": 0.018026004728132396,
            "ave_precision_score": 0.8462833626748467,
            "fpr": 0.13596491228070176,
            "logloss": 0.7205013558980254,
            "mae": 0.26623726127078107,
            "precision": 0.7554240631163708,
            "recall": 0.7832310838445807
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8130799018334611,
            "auditor_fn_violation": 0.009652632697142451,
            "auditor_fp_violation": 0.02546602806751562,
            "ave_precision_score": 0.8134029413966803,
            "fpr": 0.15916575192096596,
            "logloss": 0.8098728169743179,
            "mae": 0.2761838564583669,
            "precision": 0.7189922480620154,
            "recall": 0.7978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 24284,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8534052178952538,
            "auditor_fn_violation": 0.015323969432784414,
            "auditor_fp_violation": 0.0179093567251462,
            "ave_precision_score": 0.8538333233037607,
            "fpr": 0.15460526315789475,
            "logloss": 0.7658662721212491,
            "mae": 0.26442494729425353,
            "precision": 0.7403314917127072,
            "recall": 0.8220858895705522
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8144613121357938,
            "auditor_fn_violation": 0.018252422600710555,
            "auditor_fp_violation": 0.034082686448144994,
            "ave_precision_score": 0.8147950087896945,
            "fpr": 0.18441273326015367,
            "logloss": 0.89842247273677,
            "mae": 0.27470908557727497,
            "precision": 0.6994633273703041,
            "recall": 0.8408602150537634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 24284,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.8600080811741633,
            "auditor_fn_violation": 0.032867829081907225,
            "auditor_fp_violation": 0.03941406412011118,
            "ave_precision_score": 0.8602114044360296,
            "fpr": 0.23464912280701755,
            "logloss": 0.5989934658773476,
            "mae": 0.33459485673515305,
            "precision": 0.6651017214397497,
            "recall": 0.869120654396728
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.8333797654417714,
            "auditor_fn_violation": 0.02372437236641762,
            "auditor_fp_violation": 0.04398162960921079,
            "ave_precision_score": 0.8336825521832723,
            "fpr": 0.25466520307354557,
            "logloss": 0.6452093374794717,
            "mae": 0.3417944713766752,
            "precision": 0.6386292834890965,
            "recall": 0.8817204301075269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8400999901407595,
            "auditor_fn_violation": 0.010574749757830161,
            "auditor_fp_violation": 0.01409885529426403,
            "ave_precision_score": 0.8413166355035613,
            "fpr": 0.13048245614035087,
            "logloss": 0.8246647044603886,
            "mae": 0.26808921299090205,
            "precision": 0.7634194831013916,
            "recall": 0.7852760736196319
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8046864705189545,
            "auditor_fn_violation": 0.016878533574118015,
            "auditor_fp_violation": 0.030956963470881563,
            "ave_precision_score": 0.8050391468644522,
            "fpr": 0.15697036223929747,
            "logloss": 0.9450789665440192,
            "mae": 0.2759878192723057,
            "precision": 0.7212475633528265,
            "recall": 0.7956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8650866548981888,
            "auditor_fn_violation": 0.006639489828866647,
            "auditor_fp_violation": 0.012185828045290531,
            "ave_precision_score": 0.8652667833182938,
            "fpr": 0.11513157894736842,
            "logloss": 0.8302344051490967,
            "mae": 0.27720469943642384,
            "precision": 0.7761194029850746,
            "recall": 0.7443762781186094
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8251899458419111,
            "auditor_fn_violation": 0.011741793845826987,
            "auditor_fp_violation": 0.013246174065851851,
            "ave_precision_score": 0.8257479063596903,
            "fpr": 0.1141602634467618,
            "logloss": 0.88140377790278,
            "mae": 0.27467797460159765,
            "precision": 0.7739130434782608,
            "recall": 0.7655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8720289311597137,
            "auditor_fn_violation": 0.00700498690489004,
            "auditor_fp_violation": 0.016859524698270505,
            "ave_precision_score": 0.872202143041338,
            "fpr": 0.14692982456140352,
            "logloss": 0.5381254994467343,
            "mae": 0.2747827917858223,
            "precision": 0.7495327102803738,
            "recall": 0.820040899795501
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8308673997631315,
            "auditor_fn_violation": 0.013491023688962859,
            "auditor_fp_violation": 0.022409218667703654,
            "ave_precision_score": 0.8312266478082144,
            "fpr": 0.17014270032930845,
            "logloss": 0.6064841683559075,
            "mae": 0.2839577435628275,
            "precision": 0.7186932849364791,
            "recall": 0.8516129032258064
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8718859344751994,
            "auditor_fn_violation": 0.012417931331395977,
            "auditor_fp_violation": 0.01694506656712704,
            "ave_precision_score": 0.8720711537941044,
            "fpr": 0.13048245614035087,
            "logloss": 0.5294373603285515,
            "mae": 0.27314252538193967,
            "precision": 0.7648221343873518,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8290397049226745,
            "auditor_fn_violation": 0.012570376403101878,
            "auditor_fp_violation": 0.024858111866425805,
            "ave_precision_score": 0.8294057173488586,
            "fpr": 0.14928649835345773,
            "logloss": 0.5927298570951128,
            "mae": 0.28130029490049907,
            "precision": 0.7389635316698656,
            "recall": 0.8279569892473119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8477723656208063,
            "auditor_fn_violation": 0.014236447458113588,
            "auditor_fp_violation": 0.018334473891584758,
            "ave_precision_score": 0.848349418933387,
            "fpr": 0.16885964912280702,
            "logloss": 0.8143931824395867,
            "mae": 0.2704735160138314,
            "precision": 0.7254901960784313,
            "recall": 0.8323108384458078
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8112743634862011,
            "auditor_fn_violation": 0.018339766061164033,
            "auditor_fp_violation": 0.03518038128897924,
            "ave_precision_score": 0.8116197735167099,
            "fpr": 0.1986827661909989,
            "logloss": 0.9538005086097195,
            "mae": 0.2801806599532326,
            "precision": 0.6852173913043478,
            "recall": 0.8473118279569892
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8766577520964105,
            "auditor_fn_violation": 0.015817278369748507,
            "auditor_fp_violation": 0.015459748662436235,
            "ave_precision_score": 0.8768292115262428,
            "fpr": 0.10964912280701754,
            "logloss": 0.6009508158305403,
            "mae": 0.2625727489103395,
            "precision": 0.7876857749469215,
            "recall": 0.7586912065439673
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8408128028894284,
            "auditor_fn_violation": 0.0161821465245565,
            "auditor_fp_violation": 0.016216841493849467,
            "ave_precision_score": 0.8410998942056744,
            "fpr": 0.141602634467618,
            "logloss": 0.6532232744768822,
            "mae": 0.2691476065595503,
            "precision": 0.7388663967611336,
            "recall": 0.7849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8425162724413826,
            "auditor_fn_violation": 0.012469504538442224,
            "auditor_fp_violation": 0.013297872340425539,
            "ave_precision_score": 0.8444280181914785,
            "fpr": 0.125,
            "logloss": 0.7717674717566149,
            "mae": 0.2647421418125254,
            "precision": 0.7663934426229508,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8087320155427096,
            "auditor_fn_violation": 0.016191589060821743,
            "auditor_fp_violation": 0.02716671671105029,
            "ave_precision_score": 0.8090746814194665,
            "fpr": 0.14818880351262348,
            "logloss": 0.8831585338465755,
            "mae": 0.2748502000490384,
            "precision": 0.7310756972111554,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8628210410039701,
            "auditor_fn_violation": 0.009236088687977616,
            "auditor_fp_violation": 0.02024490896271412,
            "ave_precision_score": 0.8630241622047181,
            "fpr": 0.1787280701754386,
            "logloss": 0.817115015632972,
            "mae": 0.27345789809932347,
            "precision": 0.7175043327556326,
            "recall": 0.8466257668711656
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8230698515610726,
            "auditor_fn_violation": 0.006066829550417245,
            "auditor_fp_violation": 0.023430616333502335,
            "ave_precision_score": 0.8234331364482753,
            "fpr": 0.20417124039517015,
            "logloss": 0.907695545932994,
            "mae": 0.28288865326049606,
            "precision": 0.6798623063683304,
            "recall": 0.8494623655913979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8391775486456727,
            "auditor_fn_violation": 0.013548057259713697,
            "auditor_fp_violation": 0.012341358715938784,
            "ave_precision_score": 0.8394858540245983,
            "fpr": 0.12171052631578948,
            "logloss": 0.8483812961584606,
            "mae": 0.26613092783843045,
            "precision": 0.7692307692307693,
            "recall": 0.7566462167689162
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8058209749487436,
            "auditor_fn_violation": 0.008729624777215164,
            "auditor_fp_violation": 0.02135090301398454,
            "ave_precision_score": 0.8061730285635117,
            "fpr": 0.141602634467618,
            "logloss": 0.9399606099285557,
            "mae": 0.27391943831636395,
            "precision": 0.736734693877551,
            "recall": 0.7763440860215054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8404335501481748,
            "auditor_fn_violation": 0.009115003767086433,
            "auditor_fp_violation": 0.015698229024096892,
            "ave_precision_score": 0.84103714872658,
            "fpr": 0.1337719298245614,
            "logloss": 0.7908164701086984,
            "mae": 0.2670861928270579,
            "precision": 0.7550200803212851,
            "recall": 0.7689161554192229
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.807529466934625,
            "auditor_fn_violation": 0.008108778017775575,
            "auditor_fp_violation": 0.02101371872431123,
            "ave_precision_score": 0.8079360578108644,
            "fpr": 0.15148188803512624,
            "logloss": 0.895151440191929,
            "mae": 0.27526358936112344,
            "precision": 0.7283464566929134,
            "recall": 0.7956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.871604279942942,
            "auditor_fn_violation": 0.010413303196641912,
            "auditor_fp_violation": 0.017831591389822078,
            "ave_precision_score": 0.8717801527773503,
            "fpr": 0.13157894736842105,
            "logloss": 0.5385727031713767,
            "mae": 0.27175265028786827,
            "precision": 0.7633136094674556,
            "recall": 0.7914110429447853
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8263233137139134,
            "auditor_fn_violation": 0.013432007837305106,
            "auditor_fp_violation": 0.025955806707260047,
            "ave_precision_score": 0.8266433862520979,
            "fpr": 0.14928649835345773,
            "logloss": 0.6114179442914569,
            "mae": 0.28072641302016693,
            "precision": 0.7389635316698656,
            "recall": 0.8279569892473119
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8750252107007706,
            "auditor_fn_violation": 0.019552972410576547,
            "auditor_fp_violation": 0.0165899382024802,
            "ave_precision_score": 0.8752025372438449,
            "fpr": 0.10635964912280702,
            "logloss": 0.6131875028251788,
            "mae": 0.2649227826856125,
            "precision": 0.790948275862069,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8365804393885065,
            "auditor_fn_violation": 0.01975378586688385,
            "auditor_fp_violation": 0.019194892519431173,
            "ave_precision_score": 0.8368824349683748,
            "fpr": 0.13721185510428102,
            "logloss": 0.662856535242975,
            "mae": 0.2713738650834628,
            "precision": 0.7433264887063655,
            "recall": 0.7784946236559139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8193471828654788,
            "auditor_fn_violation": 0.014066031643525998,
            "auditor_fp_violation": 0.013935548090083365,
            "ave_precision_score": 0.8081865587219725,
            "fpr": 0.14583333333333334,
            "logloss": 1.2615417112247618,
            "mae": 0.2656857514484089,
            "precision": 0.7509363295880149,
            "recall": 0.820040899795501
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7776293310250197,
            "auditor_fn_violation": 0.0144258347792217,
            "auditor_fp_violation": 0.025131304977037014,
            "ave_precision_score": 0.7645628689072466,
            "fpr": 0.16794731064763996,
            "logloss": 1.4975979890045368,
            "mae": 0.2775644515330188,
            "precision": 0.7197802197802198,
            "recall": 0.8451612903225807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 24284,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8344847825712622,
            "auditor_fn_violation": 0.011254170702830697,
            "auditor_fp_violation": 0.020377110032765128,
            "ave_precision_score": 0.8350037147940715,
            "fpr": 0.17324561403508773,
            "logloss": 0.7002415325916005,
            "mae": 0.28923622320042386,
            "precision": 0.7178571428571429,
            "recall": 0.8220858895705522
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8198867623910646,
            "auditor_fn_violation": 0.013217190137270872,
            "auditor_fp_violation": 0.027513745797502372,
            "ave_precision_score": 0.8201903441443259,
            "fpr": 0.1986827661909989,
            "logloss": 0.7566312202947981,
            "mae": 0.2942907082271393,
            "precision": 0.6818980667838312,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8570940935001099,
            "auditor_fn_violation": 0.014584006027338291,
            "auditor_fp_violation": 0.022116461366181416,
            "ave_precision_score": 0.8573235210722046,
            "fpr": 0.13815789473684212,
            "logloss": 0.7560479260175927,
            "mae": 0.2629883663840356,
            "precision": 0.754863813229572,
            "recall": 0.7934560327198364
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8080891746359895,
            "auditor_fn_violation": 0.023646471442229387,
            "auditor_fp_violation": 0.03530344124871403,
            "ave_precision_score": 0.8084427618007256,
            "fpr": 0.17453347969264543,
            "logloss": 0.9036595349890802,
            "mae": 0.27750979378439455,
            "precision": 0.7055555555555556,
            "recall": 0.8193548387096774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.853718258375572,
            "auditor_fn_violation": 0.01954848778387687,
            "auditor_fp_violation": 0.0124942972087429,
            "ave_precision_score": 0.853955613244227,
            "fpr": 0.08333333333333333,
            "logloss": 0.7821931792915876,
            "mae": 0.27110464895750536,
            "precision": 0.8164251207729468,
            "recall": 0.6912065439672802
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8106536424686345,
            "auditor_fn_violation": 0.015403137282674133,
            "auditor_fp_violation": 0.016012561960689727,
            "ave_precision_score": 0.8109936174590154,
            "fpr": 0.11855104281009879,
            "logloss": 0.8525907821400514,
            "mae": 0.2794181375581829,
            "precision": 0.757847533632287,
            "recall": 0.7268817204301076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8798436198370434,
            "auditor_fn_violation": 0.007491568901804613,
            "auditor_fp_violation": 0.018212641532910297,
            "ave_precision_score": 0.8801531455698479,
            "fpr": 0.13048245614035087,
            "logloss": 0.4724013580852887,
            "mae": 0.2676667892392288,
            "precision": 0.7733333333333333,
            "recall": 0.8302658486707567
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8584930409818181,
            "auditor_fn_violation": 0.003186855989518785,
            "auditor_fp_violation": 0.015271741003086346,
            "ave_precision_score": 0.8587405099277923,
            "fpr": 0.141602634467618,
            "logloss": 0.510722392117319,
            "mae": 0.27343194365950774,
            "precision": 0.7514450867052023,
            "recall": 0.8387096774193549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8697631541927028,
            "auditor_fn_violation": 0.021003749147920928,
            "auditor_fp_violation": 0.017725312098212438,
            "ave_precision_score": 0.8699429345842866,
            "fpr": 0.09320175438596491,
            "logloss": 0.847717435831957,
            "mae": 0.27036056628642624,
            "precision": 0.8068181818181818,
            "recall": 0.7259713701431493
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8348143378554247,
            "auditor_fn_violation": 0.02581353351510216,
            "auditor_fp_violation": 0.023396159544776595,
            "ave_precision_score": 0.8351213896635912,
            "fpr": 0.11855104281009879,
            "logloss": 0.8965705709996388,
            "mae": 0.27358676555579226,
            "precision": 0.7631578947368421,
            "recall": 0.7483870967741936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8750318311063974,
            "auditor_fn_violation": 0.015965271050837733,
            "auditor_fp_violation": 0.013227883538633821,
            "ave_precision_score": 0.8752053994632277,
            "fpr": 0.12828947368421054,
            "logloss": 0.5371253322397015,
            "mae": 0.2652367391099432,
            "precision": 0.7683168316831683,
            "recall": 0.7934560327198364
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8429390457869307,
            "auditor_fn_violation": 0.006756134697779824,
            "auditor_fp_violation": 0.01680260690218703,
            "ave_precision_score": 0.8432112758758249,
            "fpr": 0.145993413830955,
            "logloss": 0.5802709293279862,
            "mae": 0.2701278625817895,
            "precision": 0.740234375,
            "recall": 0.8150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8402562082843973,
            "auditor_fn_violation": 0.007906396871524422,
            "auditor_fp_violation": 0.016385156152793328,
            "ave_precision_score": 0.8408182923488754,
            "fpr": 0.13706140350877194,
            "logloss": 0.7912166253508445,
            "mae": 0.2671864128282173,
            "precision": 0.751984126984127,
            "recall": 0.7750511247443763
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8076285009255888,
            "auditor_fn_violation": 0.008108778017775575,
            "auditor_fp_violation": 0.02101371872431123,
            "ave_precision_score": 0.8080541352844475,
            "fpr": 0.15148188803512624,
            "logloss": 0.8953912938980009,
            "mae": 0.27479750056008034,
            "precision": 0.7283464566929134,
            "recall": 0.7956989247311828
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8754725437460209,
            "auditor_fn_violation": 0.007258368313421594,
            "auditor_fp_violation": 0.019433557297499075,
            "ave_precision_score": 0.8756458623226614,
            "fpr": 0.18311403508771928,
            "logloss": 0.5913449330323999,
            "mae": 0.2758574697128783,
            "precision": 0.7197986577181208,
            "recall": 0.8773006134969326
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8363156330782369,
            "auditor_fn_violation": 0.008299989377146702,
            "auditor_fp_violation": 0.024885185057567448,
            "ave_precision_score": 0.8367287904430643,
            "fpr": 0.2074643249176729,
            "logloss": 0.672424605937875,
            "mae": 0.2876653210904028,
            "precision": 0.6881188118811881,
            "recall": 0.896774193548387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8788522829859882,
            "auditor_fn_violation": 0.01564686255516091,
            "auditor_fp_violation": 0.008821181203600021,
            "ave_precision_score": 0.879011333308382,
            "fpr": 0.10964912280701754,
            "logloss": 0.5067442098964269,
            "mae": 0.26868467577610555,
            "precision": 0.7894736842105263,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8381068855431576,
            "auditor_fn_violation": 0.01624588364434687,
            "auditor_fp_violation": 0.015540011715308171,
            "ave_precision_score": 0.838414936489093,
            "fpr": 0.13611416026344675,
            "logloss": 0.5607062964515144,
            "mae": 0.2778181595649595,
            "precision": 0.75,
            "recall": 0.8
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8372276072336846,
            "auditor_fn_violation": 0.01766718688336383,
            "auditor_fp_violation": 0.01330564887395795,
            "ave_precision_score": 0.8376227433602246,
            "fpr": 0.1162280701754386,
            "logloss": 0.8340099558170595,
            "mae": 0.2660170766355768,
            "precision": 0.7773109243697479,
            "recall": 0.7566462167689162
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.805500514352735,
            "auditor_fn_violation": 0.007967139973796966,
            "auditor_fp_violation": 0.01863127790384587,
            "ave_precision_score": 0.8058385693375854,
            "fpr": 0.12952799121844127,
            "logloss": 0.9176694309249777,
            "mae": 0.275497395897064,
            "precision": 0.75,
            "recall": 0.7612903225806451
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8445879276697661,
            "auditor_fn_violation": 0.00890646862555161,
            "auditor_fp_violation": 0.018018228194599983,
            "ave_precision_score": 0.8450597871972477,
            "fpr": 0.1337719298245614,
            "logloss": 0.7134148443630977,
            "mae": 0.26494355488533844,
            "precision": 0.758893280632411,
            "recall": 0.7852760736196319
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.811335977899119,
            "auditor_fn_violation": 0.010186135996128566,
            "auditor_fp_violation": 0.02464644873568197,
            "ave_precision_score": 0.8116993602104325,
            "fpr": 0.15148188803512624,
            "logloss": 0.8116185901315088,
            "mae": 0.27339200552158954,
            "precision": 0.7335907335907336,
            "recall": 0.8172043010752689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 24284,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.6546273296850986,
            "auditor_fn_violation": 6.278477379543117e-05,
            "auditor_fp_violation": 0.012310252581809131,
            "ave_precision_score": 0.5382610471700027,
            "fpr": 0.3168859649122807,
            "logloss": 8.88551508199436,
            "mae": 0.41983902602299766,
            "precision": 0.586552217453505,
            "recall": 0.8384458077709611
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6238236412096543,
            "auditor_fn_violation": 0.009529879725694326,
            "auditor_fp_violation": 0.011031094790625792,
            "ave_precision_score": 0.5034495357718856,
            "fpr": 0.3402854006586169,
            "logloss": 9.526595178171405,
            "mae": 0.43660512018097003,
            "precision": 0.5658263305322129,
            "recall": 0.8688172043010752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8669062315661504,
            "auditor_fn_violation": 0.00891319556560112,
            "auditor_fp_violation": 0.01891252955082742,
            "ave_precision_score": 0.8670893696816167,
            "fpr": 0.13925438596491227,
            "logloss": 0.5465108373990722,
            "mae": 0.27726804704319585,
            "precision": 0.7552986512524085,
            "recall": 0.8016359918200409
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8301164293090103,
            "auditor_fn_violation": 0.010986390944607722,
            "auditor_fp_violation": 0.019010302579828997,
            "ave_precision_score": 0.8304699349511325,
            "fpr": 0.16465422612513722,
            "logloss": 0.5958588513847706,
            "mae": 0.2824332986791689,
            "precision": 0.7211895910780669,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8639330049900401,
            "auditor_fn_violation": 0.007552111362250211,
            "auditor_fp_violation": 0.008613806976069014,
            "ave_precision_score": 0.8641176466346239,
            "fpr": 0.09649122807017543,
            "logloss": 0.7865008451622242,
            "mae": 0.280856697705832,
            "precision": 0.8044444444444444,
            "recall": 0.7402862985685071
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8275787215875027,
            "auditor_fn_violation": 0.007995467582592687,
            "auditor_fp_violation": 0.009830029583614319,
            "ave_precision_score": 0.8279097552444183,
            "fpr": 0.10208562019758508,
            "logloss": 0.8460579096187788,
            "mae": 0.2799307307420734,
            "precision": 0.786697247706422,
            "recall": 0.7376344086021506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8750938211385054,
            "auditor_fn_violation": 0.013736411581099991,
            "auditor_fp_violation": 0.01769161378623865,
            "ave_precision_score": 0.8752668078314313,
            "fpr": 0.125,
            "logloss": 0.5241599344416316,
            "mae": 0.26920126002554307,
            "precision": 0.7696969696969697,
            "recall": 0.7791411042944786
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8406335951623894,
            "auditor_fn_violation": 0.007365178286887857,
            "auditor_fp_violation": 0.019647753171255163,
            "ave_precision_score": 0.8409284332311773,
            "fpr": 0.1437980241492865,
            "logloss": 0.5621957821543996,
            "mae": 0.27358489263920077,
            "precision": 0.7431372549019608,
            "recall": 0.8150537634408602
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8404516757387501,
            "auditor_fn_violation": 0.01270046281347541,
            "auditor_fp_violation": 0.013463771722450337,
            "ave_precision_score": 0.8416622009316981,
            "fpr": 0.11951754385964912,
            "logloss": 0.8078430199568041,
            "mae": 0.2681596431970986,
            "precision": 0.7710084033613446,
            "recall": 0.7505112474437627
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7987034943475542,
            "auditor_fn_violation": 0.013349385644984245,
            "auditor_fp_violation": 0.029189822449090092,
            "ave_precision_score": 0.7991022964169825,
            "fpr": 0.150384193194292,
            "logloss": 0.9325833373078029,
            "mae": 0.27819436253837226,
            "precision": 0.7270916334661355,
            "recall": 0.7849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8450966940895034,
            "auditor_fn_violation": 0.01209279589566965,
            "auditor_fp_violation": 0.01606372610012028,
            "ave_precision_score": 0.8454366352249574,
            "fpr": 0.1206140350877193,
            "logloss": 0.7718601766622798,
            "mae": 0.26730091920741056,
            "precision": 0.7649572649572649,
            "recall": 0.7321063394683026
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.809812650608358,
            "auditor_fn_violation": 0.014199213908855923,
            "auditor_fp_violation": 0.01840238637873918,
            "ave_precision_score": 0.8101837494621065,
            "fpr": 0.141602634467618,
            "logloss": 0.8631617462878123,
            "mae": 0.274887049310521,
            "precision": 0.7361963190184049,
            "recall": 0.7741935483870968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8726412201376065,
            "auditor_fn_violation": 0.0042245183510924685,
            "auditor_fp_violation": 0.002796959893824397,
            "ave_precision_score": 0.8727875538908145,
            "fpr": 0.05482456140350877,
            "logloss": 0.9443838818259289,
            "mae": 0.2842562487085236,
            "precision": 0.8622589531680441,
            "recall": 0.6400817995910021
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8284043216101799,
            "auditor_fn_violation": 0.011250781960034475,
            "auditor_fp_violation": 0.01720624357011711,
            "ave_precision_score": 0.8297431209151666,
            "fpr": 0.06915477497255763,
            "logloss": 0.9700166840202651,
            "mae": 0.28666988421443323,
            "precision": 0.8328912466843501,
            "recall": 0.6752688172043011
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8670623581696164,
            "auditor_fn_violation": 0.0156401356151114,
            "auditor_fp_violation": 0.005142880842768862,
            "ave_precision_score": 0.8672411287146247,
            "fpr": 0.0581140350877193,
            "logloss": 0.6409840435903509,
            "mae": 0.29484784473954695,
            "precision": 0.8498583569405099,
            "recall": 0.6134969325153374
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8314847958960683,
            "auditor_fn_violation": 0.008023795191388409,
            "auditor_fp_violation": 0.013526750774047152,
            "ave_precision_score": 0.8318269879404481,
            "fpr": 0.08232711306256861,
            "logloss": 0.626792881293239,
            "mae": 0.29350975716449706,
            "precision": 0.8015873015873016,
            "recall": 0.6516129032258065
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8594316802087745,
            "auditor_fn_violation": 0.01782190650450257,
            "auditor_fp_violation": 0.014495458504417079,
            "ave_precision_score": 0.8597567837373098,
            "fpr": 0.12171052631578948,
            "logloss": 0.6566833668570542,
            "mae": 0.2659258461416588,
            "precision": 0.7720739219712526,
            "recall": 0.7689161554192229
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8253414683638116,
            "auditor_fn_violation": 0.014090624741805653,
            "auditor_fp_violation": 0.025379886095701274,
            "ave_precision_score": 0.825606420032289,
            "fpr": 0.14489571899012074,
            "logloss": 0.7386144875451799,
            "mae": 0.27401840528479227,
            "precision": 0.7375745526838966,
            "recall": 0.7978494623655914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 24284,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.86987480619147,
            "auditor_fn_violation": 0.02254421841925879,
            "auditor_fp_violation": 0.017082451992866326,
            "ave_precision_score": 0.8700552382439948,
            "fpr": 0.09429824561403509,
            "logloss": 0.8577573439512297,
            "mae": 0.2701500379675988,
            "precision": 0.8041002277904328,
            "recall": 0.721881390593047
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8352133530060085,
            "auditor_fn_violation": 0.023958075138982328,
            "auditor_fp_violation": 0.01896846219351917,
            "ave_precision_score": 0.8355163998686759,
            "fpr": 0.11964873765093303,
            "logloss": 0.907555682639669,
            "mae": 0.27315806777142027,
            "precision": 0.7620087336244541,
            "recall": 0.7505376344086021
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8380926043845303,
            "auditor_fn_violation": 0.010229433501955296,
            "auditor_fp_violation": 0.02149433868358842,
            "ave_precision_score": 0.8385032971861642,
            "fpr": 0.22478070175438597,
            "logloss": 0.8601606277687166,
            "mae": 0.2918039608197988,
            "precision": 0.6776729559748428,
            "recall": 0.8813905930470347
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8196499085895738,
            "auditor_fn_violation": 0.013070830825159637,
            "auditor_fp_violation": 0.030474568428721215,
            "ave_precision_score": 0.8199944970002988,
            "fpr": 0.2349066959385291,
            "logloss": 0.9401526153145081,
            "mae": 0.3021166257406632,
            "precision": 0.6548387096774193,
            "recall": 0.8731182795698925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8495564723439606,
            "auditor_fn_violation": 0.009821332472285015,
            "auditor_fp_violation": 0.01137706855791962,
            "ave_precision_score": 0.8497802824298095,
            "fpr": 0.05263157894736842,
            "logloss": 0.9268969853401925,
            "mae": 0.3097719900007259,
            "precision": 0.8579881656804734,
            "recall": 0.5930470347648262
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8226960027899715,
            "auditor_fn_violation": 0.010115316974139258,
            "auditor_fp_violation": 0.01654418098674398,
            "ave_precision_score": 0.8230628792447253,
            "fpr": 0.06256860592755215,
            "logloss": 0.9226250456862535,
            "mae": 0.29932305048123836,
            "precision": 0.8371428571428572,
            "recall": 0.6301075268817204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8749729180526928,
            "auditor_fn_violation": 0.01799232231909016,
            "auditor_fp_violation": 0.0165899382024802,
            "ave_precision_score": 0.8751504998359965,
            "fpr": 0.10635964912280702,
            "logloss": 0.6109016778283058,
            "mae": 0.26486398932887634,
            "precision": 0.7913978494623656,
            "recall": 0.7525562372188139
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8367908187275598,
            "auditor_fn_violation": 0.020480861159307393,
            "auditor_fp_violation": 0.019194892519431173,
            "ave_precision_score": 0.8370916211587269,
            "fpr": 0.13721185510428102,
            "logloss": 0.6603408737644068,
            "mae": 0.2712086161594227,
            "precision": 0.7438524590163934,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8363239697956071,
            "auditor_fn_violation": 0.005430882933304634,
            "auditor_fp_violation": 0.008701941022769694,
            "ave_precision_score": 0.8377158536102854,
            "fpr": 0.1118421052631579,
            "logloss": 0.5145004955809725,
            "mae": 0.3123393578300653,
            "precision": 0.7829787234042553,
            "recall": 0.7525562372188139
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7651211887573035,
            "auditor_fn_violation": 0.008094614213377717,
            "auditor_fp_violation": 0.00505530314590481,
            "ave_precision_score": 0.7667333794374356,
            "fpr": 0.15367727771679474,
            "logloss": 0.5835150877730843,
            "mae": 0.33144062123201073,
            "precision": 0.7216699801192843,
            "recall": 0.7806451612903226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.849475262532741,
            "auditor_fn_violation": 0.0020135973881534107,
            "auditor_fp_violation": 0.0194983617436025,
            "ave_precision_score": 0.8499471356916879,
            "fpr": 0.22587719298245615,
            "logloss": 0.8249356582563717,
            "mae": 0.2873517349441356,
            "precision": 0.6878787878787879,
            "recall": 0.9284253578732107
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.828682107840616,
            "auditor_fn_violation": 0.008193760844162744,
            "auditor_fp_violation": 0.023022057267182875,
            "ave_precision_score": 0.82896748050019,
            "fpr": 0.24807903402854006,
            "logloss": 0.9414128941875247,
            "mae": 0.30396627063927556,
            "precision": 0.6533742331288344,
            "recall": 0.9161290322580645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8801771983500146,
            "auditor_fn_violation": 0.012666828113227861,
            "auditor_fp_violation": 0.0156230558666169,
            "ave_precision_score": 0.8803471716140151,
            "fpr": 0.11951754385964912,
            "logloss": 0.4767216664165167,
            "mae": 0.2796069478657987,
            "precision": 0.7837301587301587,
            "recall": 0.8077709611451943
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8447262912214222,
            "auditor_fn_violation": 0.01304958511856285,
            "auditor_fp_violation": 0.019266267296077343,
            "ave_precision_score": 0.8450718822558456,
            "fpr": 0.1525795828759605,
            "logloss": 0.5141505036217628,
            "mae": 0.28611202064122593,
            "precision": 0.7362428842504743,
            "recall": 0.8344086021505376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.838246046254475,
            "auditor_fn_violation": 0.013682596060703918,
            "auditor_fp_violation": 0.011439280826178929,
            "ave_precision_score": 0.8385919562695967,
            "fpr": 0.11951754385964912,
            "logloss": 0.837365340846199,
            "mae": 0.26562612027772226,
            "precision": 0.7747933884297521,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8050179838404602,
            "auditor_fn_violation": 0.00954640416415849,
            "auditor_fp_violation": 0.018461455159411874,
            "ave_precision_score": 0.805351956559806,
            "fpr": 0.13721185510428102,
            "logloss": 0.9328792185862748,
            "mae": 0.27618937556260226,
            "precision": 0.7401247401247402,
            "recall": 0.7655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8462996692440041,
            "auditor_fn_violation": 0.006332292899939009,
            "auditor_fp_violation": 0.01706171457011323,
            "ave_precision_score": 0.8465638067455333,
            "fpr": 0.125,
            "logloss": 0.7481964281234793,
            "mae": 0.26799385987912694,
            "precision": 0.7673469387755102,
            "recall": 0.7689161554192229
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8094758303180374,
            "auditor_fn_violation": 0.009879253567508232,
            "auditor_fp_violation": 0.018783872253917006,
            "ave_precision_score": 0.8098085177510815,
            "fpr": 0.14489571899012074,
            "logloss": 0.8338198882576049,
            "mae": 0.27659028066290914,
            "precision": 0.7344064386317908,
            "recall": 0.7849462365591398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8404617317650824,
            "auditor_fn_violation": 0.0117788720266925,
            "auditor_fp_violation": 0.016276284683339557,
            "ave_precision_score": 0.8409824517700675,
            "fpr": 0.13486842105263158,
            "logloss": 0.7898304129606215,
            "mae": 0.2673546909095296,
            "precision": 0.7530120481927711,
            "recall": 0.7668711656441718
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8077044053855909,
            "auditor_fn_violation": 0.009858007860911443,
            "auditor_fp_violation": 0.021043253114647588,
            "ave_precision_score": 0.8081345295096152,
            "fpr": 0.14928649835345773,
            "logloss": 0.8915332571620963,
            "mae": 0.2749084373499446,
            "precision": 0.7306930693069307,
            "recall": 0.7935483870967742
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8398818976461957,
            "auditor_fn_violation": 0.007475872708355759,
            "auditor_fp_violation": 0.01863257434366057,
            "ave_precision_score": 0.8401590690063467,
            "fpr": 0.1425438596491228,
            "logloss": 0.8035032179401304,
            "mae": 0.27032291135158676,
            "precision": 0.748062015503876,
            "recall": 0.7893660531697342
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8058484565772925,
            "auditor_fn_violation": 0.00694262478901833,
            "auditor_fp_violation": 0.02314019482852826,
            "ave_precision_score": 0.8061737437201102,
            "fpr": 0.15477497255762898,
            "logloss": 0.9050484792450844,
            "mae": 0.27966485755882203,
            "precision": 0.7224409448818898,
            "recall": 0.789247311827957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8545904823038526,
            "auditor_fn_violation": 0.01887579377892585,
            "auditor_fp_violation": 0.013572643191904111,
            "ave_precision_score": 0.8549203467431037,
            "fpr": 0.1162280701754386,
            "logloss": 0.7063976792224806,
            "mae": 0.26153865026183765,
            "precision": 0.7782426778242678,
            "recall": 0.7607361963190185
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8177285556073194,
            "auditor_fn_violation": 0.012940995951512584,
            "auditor_fp_violation": 0.018577131521562568,
            "ave_precision_score": 0.8180381395700618,
            "fpr": 0.14270032930845225,
            "logloss": 0.8015257921248266,
            "mae": 0.2719908842676761,
            "precision": 0.7389558232931727,
            "recall": 0.7913978494623656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8618356024472973,
            "auditor_fn_violation": 0.004868062282495606,
            "auditor_fp_violation": 0.015039815851685954,
            "ave_precision_score": 0.8621190923565575,
            "fpr": 0.17324561403508773,
            "logloss": 0.4980758322213717,
            "mae": 0.3095324564226821,
            "precision": 0.7312925170068028,
            "recall": 0.8793456032719836
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8418677483833419,
            "auditor_fn_violation": 0.005615948443751996,
            "auditor_fp_violation": 0.009079363829232152,
            "ave_precision_score": 0.8421852352069785,
            "fpr": 0.17892425905598244,
            "logloss": 0.534820717346411,
            "mae": 0.32055450596720897,
            "precision": 0.7145359019264448,
            "recall": 0.8774193548387097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8421867813858512,
            "auditor_fn_violation": 0.011168962795536898,
            "auditor_fp_violation": 0.01691396043299739,
            "ave_precision_score": 0.8429985863413496,
            "fpr": 0.13815789473684212,
            "logloss": 0.7771955405228259,
            "mae": 0.26753174879689096,
            "precision": 0.75390625,
            "recall": 0.7893660531697342
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8119651539660736,
            "auditor_fn_violation": 0.00788923904960873,
            "auditor_fp_violation": 0.022731635762208782,
            "ave_precision_score": 0.8123301581562195,
            "fpr": 0.15806805708013172,
            "logloss": 0.8763700016966476,
            "mae": 0.27494900106920545,
            "precision": 0.722007722007722,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8434968830469032,
            "auditor_fn_violation": 0.012951601908657127,
            "auditor_fp_violation": 0.016162228858197514,
            "ave_precision_score": 0.843964750300164,
            "fpr": 0.1337719298245614,
            "logloss": 0.7565560524749397,
            "mae": 0.2689933795637297,
            "precision": 0.7564870259481038,
            "recall": 0.7750511247443763
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8103188812024151,
            "auditor_fn_violation": 0.011135110890785265,
            "auditor_fp_violation": 0.021953896816684963,
            "ave_precision_score": 0.8106464163573024,
            "fpr": 0.15148188803512624,
            "logloss": 0.8464128041008525,
            "mae": 0.2766510928089393,
            "precision": 0.73046875,
            "recall": 0.8043010752688172
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8626708136440687,
            "auditor_fn_violation": 0.00952983173680623,
            "auditor_fp_violation": 0.010368711376550122,
            "ave_precision_score": 0.8628596767894405,
            "fpr": 0.10087719298245613,
            "logloss": 0.8397674422189665,
            "mae": 0.2837148478855383,
            "precision": 0.7927927927927928,
            "recall": 0.7198364008179959
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8277560222696262,
            "auditor_fn_violation": 0.010799900853369222,
            "auditor_fp_violation": 0.016667240946478767,
            "ave_precision_score": 0.8281464890279774,
            "fpr": 0.09659714599341383,
            "logloss": 0.880739734151991,
            "mae": 0.27808070158495735,
            "precision": 0.7934272300469484,
            "recall": 0.7268817204301076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.836994861627294,
            "auditor_fn_violation": 0.010538872744232774,
            "auditor_fp_violation": 0.011439280826178929,
            "ave_precision_score": 0.8373550399007448,
            "fpr": 0.11951754385964912,
            "logloss": 0.8491062352602176,
            "mae": 0.265700781096492,
            "precision": 0.7743271221532091,
            "recall": 0.7648261758691206
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8042330712234016,
            "auditor_fn_violation": 0.00954640416415849,
            "auditor_fp_violation": 0.015909191594512515,
            "ave_precision_score": 0.8045676319392674,
            "fpr": 0.13611416026344675,
            "logloss": 0.9430645294761251,
            "mae": 0.27610059797753983,
            "precision": 0.7416666666666667,
            "recall": 0.7655913978494624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 24284,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8541670114489863,
            "auditor_fn_violation": 0.01059044595127902,
            "auditor_fp_violation": 0.013852598399070964,
            "ave_precision_score": 0.8544273004648801,
            "fpr": 0.10635964912280702,
            "logloss": 0.7749942698688915,
            "mae": 0.26440996604683303,
            "precision": 0.7858719646799117,
            "recall": 0.7280163599182005
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8078969861118287,
            "auditor_fn_violation": 0.016267129350943665,
            "auditor_fp_violation": 0.025178067761736235,
            "ave_precision_score": 0.8082667943345043,
            "fpr": 0.13611416026344675,
            "logloss": 0.8790288060899594,
            "mae": 0.27488139430381503,
            "precision": 0.7394957983193278,
            "recall": 0.7569892473118279
        }
    }
]