[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6970566261914519,
            "auditor_fn_violation": 0.01580048447478529,
            "auditor_fp_violation": 0.034645585738539895,
            "ave_precision_score": 0.6783709220075447,
            "fpr": 0.2225877192982456,
            "logloss": 2.228889116547452,
            "mae": 0.30694449430213155,
            "precision": 0.6720516962843296,
            "recall": 0.8702928870292888
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7000778354323038,
            "auditor_fn_violation": 0.007861432168915867,
            "auditor_fp_violation": 0.02330393529909031,
            "ave_precision_score": 0.6857491865259996,
            "fpr": 0.21185510428100987,
            "logloss": 2.2034496653431592,
            "mae": 0.28818021272897887,
            "precision": 0.6866883116883117,
            "recall": 0.8886554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.778113095285409,
            "auditor_fn_violation": 0.028460599721059975,
            "auditor_fp_violation": 0.040385742582262116,
            "ave_precision_score": 0.7785875057649885,
            "fpr": 0.13486842105263158,
            "logloss": 1.8548436489852778,
            "mae": 0.328066282486338,
            "precision": 0.716589861751152,
            "recall": 0.6506276150627615
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8266842442821546,
            "auditor_fn_violation": 0.022553478032266698,
            "auditor_fp_violation": 0.021726787539270983,
            "ave_precision_score": 0.826972380114939,
            "fpr": 0.11086717892425905,
            "logloss": 1.5354552580252896,
            "mae": 0.2954217097970667,
            "precision": 0.7589498806682577,
            "recall": 0.6680672268907563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.6797478658464298,
            "auditor_fn_violation": 0.00875816633634295,
            "auditor_fp_violation": 0.02910249413857224,
            "ave_precision_score": 0.6586225398178698,
            "fpr": 0.2949561403508772,
            "logloss": 2.6469145072072107,
            "mae": 0.3403943430032201,
            "precision": 0.6205923836389281,
            "recall": 0.9205020920502092
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6842448988572545,
            "auditor_fn_violation": 0.00814046804232121,
            "auditor_fp_violation": 0.010131597209079331,
            "ave_precision_score": 0.666702078805022,
            "fpr": 0.2722283205268935,
            "logloss": 2.6067143912355104,
            "mae": 0.3192573702667068,
            "precision": 0.6421356421356421,
            "recall": 0.9348739495798319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6846229903416836,
            "auditor_fn_violation": 0.012029288702928872,
            "auditor_fp_violation": 0.025815546931845748,
            "ave_precision_score": 0.663495226585542,
            "fpr": 0.22587719298245615,
            "logloss": 2.491483392749003,
            "mae": 0.31432499464480307,
            "precision": 0.6633986928104575,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6821165678172738,
            "auditor_fn_violation": 0.005488474204171244,
            "auditor_fp_violation": 0.02208006863747051,
            "ave_precision_score": 0.6651542434411409,
            "fpr": 0.20856201975850713,
            "logloss": 2.444721075836733,
            "mae": 0.2928499197575573,
            "precision": 0.6822742474916388,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6816318283984879,
            "auditor_fn_violation": 0.005450341334507819,
            "auditor_fp_violation": 0.02842539817285149,
            "ave_precision_score": 0.6626648297333868,
            "fpr": 0.1962719298245614,
            "logloss": 2.357582526681499,
            "mae": 0.31540388552345183,
            "precision": 0.6797853309481217,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6772710287910884,
            "auditor_fn_violation": 0.0038465441061166523,
            "auditor_fp_violation": 0.02572138738534136,
            "ave_precision_score": 0.6616663934636945,
            "fpr": 0.1800219538968167,
            "logloss": 2.3568948702668284,
            "mae": 0.2952201872555539,
            "precision": 0.6996336996336996,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5374175775548232,
            "auditor_fn_violation": 0.03246348087792703,
            "auditor_fp_violation": 0.03960253456221199,
            "ave_precision_score": 0.5244482280447963,
            "fpr": 0.33881578947368424,
            "logloss": 4.5788957552295235,
            "mae": 0.45954228394901486,
            "precision": 0.5515239477503628,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.5558945974468656,
            "auditor_fn_violation": 0.025505262478207533,
            "auditor_fp_violation": 0.04768537794768917,
            "ave_precision_score": 0.5469504887137211,
            "fpr": 0.3358946212952799,
            "logloss": 4.090208703469987,
            "mae": 0.4335707706671356,
            "precision": 0.5616045845272206,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.686373584488134,
            "auditor_fn_violation": 0.014580121852749034,
            "auditor_fp_violation": 0.035502061605626974,
            "ave_precision_score": 0.670372842415131,
            "fpr": 0.15570175438596492,
            "logloss": 2.194659662443127,
            "mae": 0.3092323074734582,
            "precision": 0.714859437751004,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6856489956123777,
            "auditor_fn_violation": 0.009685542713243367,
            "auditor_fp_violation": 0.03551232067829971,
            "ave_precision_score": 0.6744101644282328,
            "fpr": 0.15806805708013172,
            "logloss": 2.109208450819832,
            "mae": 0.2968462391112213,
            "precision": 0.7142857142857143,
            "recall": 0.7563025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7927235090401966,
            "auditor_fn_violation": 0.014958617778756516,
            "auditor_fp_violation": 0.030254567871291126,
            "ave_precision_score": 0.7935606478845465,
            "fpr": 0.22697368421052633,
            "logloss": 0.999482445888868,
            "mae": 0.30558496250760553,
            "precision": 0.6714285714285714,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8366887485217052,
            "auditor_fn_violation": 0.006415519006724532,
            "auditor_fp_violation": 0.018809695042709167,
            "ave_precision_score": 0.8371356361701616,
            "fpr": 0.2052689352360044,
            "logloss": 0.8627470865357585,
            "mae": 0.27621360647940135,
            "precision": 0.6964285714285714,
            "recall": 0.9012605042016807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8233807262435091,
            "auditor_fn_violation": 0.01855776994788226,
            "auditor_fp_violation": 0.027596713558088775,
            "ave_precision_score": 0.8236967972891465,
            "fpr": 0.14802631578947367,
            "logloss": 0.7335282826043806,
            "mae": 0.28769118195897425,
            "precision": 0.7294589178356713,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8691275940225647,
            "auditor_fn_violation": 0.016820559178665977,
            "auditor_fp_violation": 0.014333118841238,
            "ave_precision_score": 0.8694737704842561,
            "fpr": 0.12623490669593854,
            "logloss": 0.6238748609168202,
            "mae": 0.2535170240203849,
            "precision": 0.7653061224489796,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6815299332557534,
            "auditor_fn_violation": 0.01441954782353373,
            "auditor_fp_violation": 0.03448641765704585,
            "ave_precision_score": 0.6615961705082033,
            "fpr": 0.2412280701754386,
            "logloss": 2.632349033327136,
            "mae": 0.3209543506358366,
            "precision": 0.6529968454258676,
            "recall": 0.8661087866108786
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6811648386994026,
            "auditor_fn_violation": 0.001955557195435808,
            "auditor_fp_violation": 0.014214517329699595,
            "ave_precision_score": 0.6645446881332835,
            "fpr": 0.2217343578485181,
            "logloss": 2.588947069595962,
            "mae": 0.299533676959571,
            "precision": 0.6726094003241491,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 13352,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6788997384438682,
            "auditor_fn_violation": 0.008893507303824419,
            "auditor_fp_violation": 0.029453674508852792,
            "ave_precision_score": 0.658701776106968,
            "fpr": 0.20942982456140352,
            "logloss": 2.5926011303407703,
            "mae": 0.30959568691705397,
            "precision": 0.6773648648648649,
            "recall": 0.8389121338912134
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6684286596969774,
            "auditor_fn_violation": 0.006410906843527752,
            "auditor_fp_violation": 0.030213104205306797,
            "ave_precision_score": 0.6509592409417926,
            "fpr": 0.1942919868276619,
            "logloss": 2.6498763827473946,
            "mae": 0.2988784557908245,
            "precision": 0.6905594405594405,
            "recall": 0.8298319327731093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6805883313599975,
            "auditor_fn_violation": 0.012694523966820817,
            "auditor_fp_violation": 0.028660360578866517,
            "ave_precision_score": 0.6592080749514964,
            "fpr": 0.2138157894736842,
            "logloss": 2.4630602467824434,
            "mae": 0.316624694065773,
            "precision": 0.6678023850085179,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.6800228085456339,
            "auditor_fn_violation": 0.007462480052394174,
            "auditor_fp_violation": 0.02133565489483578,
            "ave_precision_score": 0.6626694268413535,
            "fpr": 0.20197585071350166,
            "logloss": 2.4206007272161054,
            "mae": 0.2936559444891842,
            "precision": 0.6833046471600689,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.824084722973669,
            "auditor_fn_violation": 0.025930411803567494,
            "auditor_fp_violation": 0.038639946640795536,
            "ave_precision_score": 0.8244883669633215,
            "fpr": 0.14912280701754385,
            "logloss": 0.6962232686615389,
            "mae": 0.2881396283889161,
            "precision": 0.7301587301587301,
            "recall": 0.7698744769874477
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8694825201052897,
            "auditor_fn_violation": 0.023932514828104684,
            "auditor_fp_violation": 0.023278700934933196,
            "ave_precision_score": 0.8698914223433836,
            "fpr": 0.12623490669593854,
            "logloss": 0.5922976931613533,
            "mae": 0.25105447151103666,
            "precision": 0.766260162601626,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.686939002902786,
            "auditor_fn_violation": 0.012905564119503783,
            "auditor_fp_violation": 0.02696004123211255,
            "ave_precision_score": 0.6674262898651211,
            "fpr": 0.2138157894736842,
            "logloss": 2.2350562729058026,
            "mae": 0.31401547191809076,
            "precision": 0.6733668341708543,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6844664792453814,
            "auditor_fn_violation": 0.010654096984567705,
            "auditor_fp_violation": 0.017661531473560706,
            "ave_precision_score": 0.6688651697877734,
            "fpr": 0.1986827661909989,
            "logloss": 2.236138956322372,
            "mae": 0.2945744332311901,
            "precision": 0.6916524701873935,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6861025908742054,
            "auditor_fn_violation": 0.010698818175144979,
            "auditor_fp_violation": 0.03236922952542648,
            "ave_precision_score": 0.6674120728543833,
            "fpr": 0.21052631578947367,
            "logloss": 2.261850314780086,
            "mae": 0.31308806749171036,
            "precision": 0.6712328767123288,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6855091766280215,
            "auditor_fn_violation": 0.0022691842928170185,
            "auditor_fp_violation": 0.024073583405882126,
            "ave_precision_score": 0.6708654484415834,
            "fpr": 0.1942919868276619,
            "logloss": 2.2463245938242844,
            "mae": 0.29354689072489276,
            "precision": 0.6900175131348512,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.825776575334323,
            "auditor_fn_violation": 0.006847335388680908,
            "auditor_fp_violation": 0.012470692861185224,
            "ave_precision_score": 0.8262529298761232,
            "fpr": 0.16447368421052633,
            "logloss": 0.5233099463547405,
            "mae": 0.32115588235677006,
            "precision": 0.7257769652650823,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8737291314587201,
            "auditor_fn_violation": 0.011825586436550472,
            "auditor_fp_violation": 0.019397655727569806,
            "ave_precision_score": 0.8739002270583134,
            "fpr": 0.1525795828759605,
            "logloss": 0.4882862014090778,
            "mae": 0.30606601173599973,
            "precision": 0.7430683918669131,
            "recall": 0.8445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8225287802705016,
            "auditor_fn_violation": 0.020686522792336494,
            "auditor_fp_violation": 0.03597703937262512,
            "ave_precision_score": 0.8229106553452827,
            "fpr": 0.1425438596491228,
            "logloss": 0.7083644618758901,
            "mae": 0.28877832070126414,
            "precision": 0.7373737373737373,
            "recall": 0.7635983263598326
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8714432471440676,
            "auditor_fn_violation": 0.02093460875019602,
            "auditor_fp_violation": 0.01940774947323266,
            "ave_precision_score": 0.8719341038683532,
            "fpr": 0.12403951701427003,
            "logloss": 0.5925486986812101,
            "mae": 0.2504264815723859,
            "precision": 0.7679671457905544,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6785516113341385,
            "auditor_fn_violation": 0.01252018644938707,
            "auditor_fp_violation": 0.02751333980111569,
            "ave_precision_score": 0.6566764832091627,
            "fpr": 0.24342105263157895,
            "logloss": 2.6403458376722657,
            "mae": 0.32041551079687436,
            "precision": 0.6476190476190476,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.6775739221181389,
            "auditor_fn_violation": 0.0058436107703234985,
            "auditor_fp_violation": 0.025219223538614888,
            "ave_precision_score": 0.6585206131874142,
            "fpr": 0.21844127332601537,
            "logloss": 2.5627906287311233,
            "mae": 0.2994119141547283,
            "precision": 0.6748366013071896,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.693136305318097,
            "auditor_fn_violation": 0.014538831388093667,
            "auditor_fp_violation": 0.0284026598754952,
            "ave_precision_score": 0.6722840515286777,
            "fpr": 0.24451754385964913,
            "logloss": 2.46360503753168,
            "mae": 0.311600359899393,
            "precision": 0.6553323029366306,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.688985474544395,
            "auditor_fn_violation": 0.00911363447684233,
            "auditor_fp_violation": 0.02215577172994184,
            "ave_precision_score": 0.6724223754817111,
            "fpr": 0.22502744237102085,
            "logloss": 2.417967306364594,
            "mae": 0.2893926915751895,
            "precision": 0.6761453396524486,
            "recall": 0.8991596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6856177069854934,
            "auditor_fn_violation": 0.009405050282610293,
            "auditor_fp_violation": 0.027783672891907193,
            "ave_precision_score": 0.6666164066989233,
            "fpr": 0.20723684210526316,
            "logloss": 2.3221949812160725,
            "mae": 0.31318223189988015,
            "precision": 0.6746987951807228,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.6812751132383645,
            "auditor_fn_violation": 0.005271702533922461,
            "auditor_fp_violation": 0.026882168136568376,
            "ave_precision_score": 0.6656697707982648,
            "fpr": 0.1942919868276619,
            "logloss": 2.3286425698359374,
            "mae": 0.2922483006015141,
            "precision": 0.6916376306620209,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.6342235350286966,
            "auditor_fn_violation": 0.006234860162959704,
            "auditor_fp_violation": 0.010924488640957235,
            "ave_precision_score": 0.5771568587750202,
            "fpr": 0.2708333333333333,
            "logloss": 4.912794121347877,
            "mae": 0.3769651950212408,
            "precision": 0.6170542635658914,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6370311270206195,
            "auditor_fn_violation": 0.00707044618066766,
            "auditor_fp_violation": 0.010023089443203756,
            "ave_precision_score": 0.5862382035776906,
            "fpr": 0.2711306256860593,
            "logloss": 4.512193714146104,
            "mae": 0.3728908922821774,
            "precision": 0.6164596273291926,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6828294046268789,
            "auditor_fn_violation": 0.00820533289290171,
            "auditor_fp_violation": 0.04091377637642493,
            "ave_precision_score": 0.6650687159867378,
            "fpr": 0.16666666666666666,
            "logloss": 2.2236222329734883,
            "mae": 0.3091460196211748,
            "precision": 0.7115749525616698,
            "recall": 0.7845188284518828
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.6793709643466578,
            "auditor_fn_violation": 0.0021215950705199766,
            "auditor_fp_violation": 0.033914985427154716,
            "ave_precision_score": 0.664733809192549,
            "fpr": 0.1690450054884742,
            "logloss": 2.2183922765760613,
            "mae": 0.2973884337164792,
            "precision": 0.7094339622641509,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6841891273922717,
            "auditor_fn_violation": 0.009212361447551937,
            "auditor_fp_violation": 0.027412280701754384,
            "ave_precision_score": 0.6652331022599124,
            "fpr": 0.20175438596491227,
            "logloss": 2.359939912014047,
            "mae": 0.3130966020832818,
            "precision": 0.6777583187390543,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6800763162964514,
            "auditor_fn_violation": 0.008066673431172688,
            "auditor_fp_violation": 0.024368825466520312,
            "ave_precision_score": 0.6643589150007543,
            "fpr": 0.19099890230515917,
            "logloss": 2.379734092407359,
            "mae": 0.2922371001552882,
            "precision": 0.6909413854351687,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6809318436430256,
            "auditor_fn_violation": 0.01172419804741981,
            "auditor_fp_violation": 0.0252546689303905,
            "ave_precision_score": 0.6587448846794588,
            "fpr": 0.23026315789473684,
            "logloss": 2.677014210728764,
            "mae": 0.3181143801240704,
            "precision": 0.6585365853658537,
            "recall": 0.8472803347280334
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6817223736752511,
            "auditor_fn_violation": 0.007582396295510524,
            "auditor_fp_violation": 0.027222832052689366,
            "ave_precision_score": 0.6620844439933011,
            "fpr": 0.21734357848518113,
            "logloss": 2.6288936387005104,
            "mae": 0.2992304182358635,
            "precision": 0.6688963210702341,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6784294006865106,
            "auditor_fn_violation": 0.011292942083241579,
            "auditor_fp_violation": 0.025911553076238995,
            "ave_precision_score": 0.6558747816918181,
            "fpr": 0.2730263157894737,
            "logloss": 2.785594593331653,
            "mae": 0.33398673293981174,
            "precision": 0.6359649122807017,
            "recall": 0.9100418410041841
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6821831162385009,
            "auditor_fn_violation": 0.004985748415721944,
            "auditor_fp_violation": 0.01702562549680156,
            "ave_precision_score": 0.6625422400011665,
            "fpr": 0.2623490669593853,
            "logloss": 2.700909353307241,
            "mae": 0.31332168192070825,
            "precision": 0.6510948905109489,
            "recall": 0.9369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.712293770482959,
            "auditor_fn_violation": 0.018672465683036044,
            "auditor_fp_violation": 0.029009014471663035,
            "ave_precision_score": 0.707410240761132,
            "fpr": 0.24780701754385964,
            "logloss": 1.8470779800143986,
            "mae": 0.31726506492923806,
            "precision": 0.6490683229813664,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7689894282959175,
            "auditor_fn_violation": 0.014103995055761055,
            "auditor_fp_violation": 0.018625484184362266,
            "ave_precision_score": 0.764821035985748,
            "fpr": 0.21185510428100987,
            "logloss": 1.5190102626361919,
            "mae": 0.2724549893366889,
            "precision": 0.6907051282051282,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.6790251403090304,
            "auditor_fn_violation": 0.012671584819790062,
            "auditor_fp_violation": 0.02902669981405127,
            "ave_precision_score": 0.6610561264687983,
            "fpr": 0.24013157894736842,
            "logloss": 2.537273526519326,
            "mae": 0.3205597408304775,
            "precision": 0.652931854199683,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6842666754896476,
            "auditor_fn_violation": 0.011917829700486122,
            "auditor_fp_violation": 0.01855987483755379,
            "ave_precision_score": 0.6701865774822996,
            "fpr": 0.2349066959385291,
            "logloss": 2.331106263229425,
            "mae": 0.30274936814771924,
            "precision": 0.65814696485623,
            "recall": 0.865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6857179229589128,
            "auditor_fn_violation": 0.006078873963150554,
            "auditor_fp_violation": 0.026684655186352983,
            "ave_precision_score": 0.6667406448880482,
            "fpr": 0.1962719298245614,
            "logloss": 2.3439862267799865,
            "mae": 0.31340574756545686,
            "precision": 0.6837455830388692,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.683227084724083,
            "auditor_fn_violation": 0.005091828169247942,
            "auditor_fp_violation": 0.022385404443771538,
            "ave_precision_score": 0.6681739275977738,
            "fpr": 0.18551042810098792,
            "logloss": 2.3234010970416676,
            "mae": 0.2920229586060274,
            "precision": 0.6971326164874552,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.699472283271865,
            "auditor_fn_violation": 0.012680760478602365,
            "auditor_fp_violation": 0.03204331392998626,
            "ave_precision_score": 0.6939736546225539,
            "fpr": 0.24890350877192982,
            "logloss": 1.7264909077463242,
            "mae": 0.31860000441405356,
            "precision": 0.6550151975683891,
            "recall": 0.9016736401673641
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7374953624840558,
            "auditor_fn_violation": 0.006355560885166362,
            "auditor_fp_violation": 0.022435873172085747,
            "ave_precision_score": 0.7317466536495881,
            "fpr": 0.22941822173435786,
            "logloss": 1.5203804454883163,
            "mae": 0.299449561950513,
            "precision": 0.6744548286604362,
            "recall": 0.9096638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.6882865177950421,
            "auditor_fn_violation": 0.01113924979813551,
            "auditor_fp_violation": 0.03262945670628183,
            "ave_precision_score": 0.6695998336978252,
            "fpr": 0.2532894736842105,
            "logloss": 2.3805409636854673,
            "mae": 0.32230330749505237,
            "precision": 0.6478658536585366,
            "recall": 0.8891213389121339
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6891500492073196,
            "auditor_fn_violation": 0.005437740409006634,
            "auditor_fp_violation": 0.024081153715129262,
            "ave_precision_score": 0.674523616211009,
            "fpr": 0.24039517014270034,
            "logloss": 2.3535674783280367,
            "mae": 0.3039270240689411,
            "precision": 0.6604651162790698,
            "recall": 0.8949579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 13352,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6920264785460118,
            "auditor_fn_violation": 0.018989025912060486,
            "auditor_fp_violation": 0.028665413533834585,
            "ave_precision_score": 0.6760963390999384,
            "fpr": 0.20394736842105263,
            "logloss": 2.21584011246636,
            "mae": 0.3041017928716754,
            "precision": 0.6804123711340206,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.6958175164341036,
            "auditor_fn_violation": 0.0054423525722034185,
            "auditor_fp_violation": 0.02587531700669973,
            "ave_precision_score": 0.6824532729352535,
            "fpr": 0.19538968166849616,
            "logloss": 2.1677158198477664,
            "mae": 0.2865927782551272,
            "precision": 0.6920415224913494,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.680095657830676,
            "auditor_fn_violation": 0.029256588123027234,
            "auditor_fp_violation": 0.02466852615409493,
            "ave_precision_score": 0.6630158893318041,
            "fpr": 0.24671052631578946,
            "logloss": 3.188823289466516,
            "mae": 0.3415265857641897,
            "precision": 0.6422893481717011,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7096307076227054,
            "auditor_fn_violation": 0.02036039443219659,
            "auditor_fp_violation": 0.023505810212347177,
            "ave_precision_score": 0.6930865609874362,
            "fpr": 0.22502744237102085,
            "logloss": 2.729222962110259,
            "mae": 0.2973066212041903,
            "precision": 0.6704180064308681,
            "recall": 0.8760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7856461963806263,
            "auditor_fn_violation": 0.03820744329442854,
            "auditor_fp_violation": 0.0439809200420406,
            "ave_precision_score": 0.7857689628191452,
            "fpr": 0.18311403508771928,
            "logloss": 2.5736014724733423,
            "mae": 0.32119082611599525,
            "precision": 0.6872659176029963,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8362914718323603,
            "auditor_fn_violation": 0.04041177393020875,
            "auditor_fp_violation": 0.03665543737461675,
            "ave_precision_score": 0.8361812557567461,
            "fpr": 0.1602634467618002,
            "logloss": 2.03748221844374,
            "mae": 0.27333282610564535,
            "precision": 0.7245283018867924,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.680749973440093,
            "auditor_fn_violation": 0.013350583571900467,
            "auditor_fp_violation": 0.03756619371008167,
            "ave_precision_score": 0.6638111148844859,
            "fpr": 0.1787280701754386,
            "logloss": 2.2909686427921128,
            "mae": 0.3078115125272695,
            "precision": 0.6981481481481482,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6826014326528975,
            "auditor_fn_violation": 0.0060696067669658476,
            "auditor_fp_violation": 0.03146977554033083,
            "ave_precision_score": 0.668854522375687,
            "fpr": 0.17892425905598244,
            "logloss": 2.249644679887472,
            "mae": 0.29440244307792857,
            "precision": 0.6987060998151571,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7358397068738141,
            "auditor_fn_violation": 0.013350583571900465,
            "auditor_fp_violation": 0.025686696580160092,
            "ave_precision_score": 0.6758872121180907,
            "fpr": 0.25548245614035087,
            "logloss": 4.015193148608736,
            "mae": 0.33490145928164294,
            "precision": 0.6464339908952959,
            "recall": 0.891213389121339
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7597298471246868,
            "auditor_fn_violation": 0.005617614773681155,
            "auditor_fp_violation": 0.017134133262677126,
            "ave_precision_score": 0.7070960112112274,
            "fpr": 0.2414928649835346,
            "logloss": 3.5129836845989884,
            "mae": 0.3141487910841254,
            "precision": 0.6636085626911316,
            "recall": 0.9117647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6355642256399094,
            "auditor_fn_violation": 0.015227005799016376,
            "auditor_fp_violation": 0.012710708222168325,
            "ave_precision_score": 0.5769871172524389,
            "fpr": 0.28618421052631576,
            "logloss": 5.014235258248189,
            "mae": 0.37979547749841513,
            "precision": 0.6045454545454545,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.6430861631473872,
            "auditor_fn_violation": 0.020558717449658235,
            "auditor_fp_violation": 0.028060612942705378,
            "ave_precision_score": 0.5902207943451908,
            "fpr": 0.2689352360043908,
            "logloss": 4.607580416999999,
            "mae": 0.3649028066348723,
            "precision": 0.6207430340557275,
            "recall": 0.842436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6346479615686031,
            "auditor_fn_violation": 0.014314027747192253,
            "auditor_fp_violation": 0.011760752688172043,
            "ave_precision_score": 0.5757611399031415,
            "fpr": 0.28399122807017546,
            "logloss": 5.050395734598002,
            "mae": 0.38078131780813046,
            "precision": 0.6069802731411229,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6428807608043198,
            "auditor_fn_violation": 0.020870038465441065,
            "auditor_fp_violation": 0.028060612942705378,
            "ave_precision_score": 0.5897870831654126,
            "fpr": 0.2689352360043908,
            "logloss": 4.627097690801208,
            "mae": 0.36561563409298264,
            "precision": 0.6213292117465224,
            "recall": 0.8445378151260504
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6165079381268328,
            "auditor_fn_violation": 0.008446193936724657,
            "auditor_fp_violation": 0.009966953674508863,
            "ave_precision_score": 0.5543081609841378,
            "fpr": 0.3782894736842105,
            "logloss": 5.826983172458998,
            "mae": 0.41992751059925676,
            "precision": 0.5649432534678437,
            "recall": 0.9372384937238494
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6309123663571626,
            "auditor_fn_violation": 0.010557241557435268,
            "auditor_fp_violation": 0.019279054216031398,
            "ave_precision_score": 0.5759085294810433,
            "fpr": 0.3809001097694841,
            "logloss": 5.22537214035635,
            "mae": 0.4095269360355249,
            "precision": 0.5667915106117354,
            "recall": 0.9537815126050421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7988024496829604,
            "auditor_fn_violation": 0.01374054907142333,
            "auditor_fp_violation": 0.025550266796022323,
            "ave_precision_score": 0.7992208857204007,
            "fpr": 0.17434210526315788,
            "logloss": 0.9865184737098799,
            "mae": 0.2902022596964309,
            "precision": 0.7039106145251397,
            "recall": 0.7907949790794979
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8383974037611148,
            "auditor_fn_violation": 0.00642013116992132,
            "auditor_fp_violation": 0.020008327340171845,
            "ave_precision_score": 0.8387178078450044,
            "fpr": 0.15477497255762898,
            "logloss": 0.8458207501825598,
            "mae": 0.2642561068439965,
            "precision": 0.7334593572778828,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6907990621428631,
            "auditor_fn_violation": 0.014630587976216695,
            "auditor_fp_violation": 0.029665898617511528,
            "ave_precision_score": 0.6699273255230183,
            "fpr": 0.2412280701754386,
            "logloss": 2.54302518081138,
            "mae": 0.3116666227598903,
            "precision": 0.6573208722741433,
            "recall": 0.8828451882845189
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6871553661478278,
            "auditor_fn_violation": 0.009549483898938279,
            "auditor_fp_violation": 0.023664786706536958,
            "ave_precision_score": 0.6700635159769015,
            "fpr": 0.2239297475301866,
            "logloss": 2.499802217911832,
            "mae": 0.29082034297913384,
            "precision": 0.6736,
            "recall": 0.884453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7977188372802952,
            "auditor_fn_violation": 0.008762754165749105,
            "auditor_fp_violation": 0.018781833616298822,
            "ave_precision_score": 0.7981615032254512,
            "fpr": 0.12280701754385964,
            "logloss": 0.988009152906917,
            "mae": 0.2923215237729699,
            "precision": 0.7522123893805309,
            "recall": 0.7112970711297071
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8361798881945826,
            "auditor_fn_violation": 0.010548017231041712,
            "auditor_fp_violation": 0.007456754608425755,
            "ave_precision_score": 0.8364732322000302,
            "fpr": 0.1163556531284303,
            "logloss": 0.8343991360842993,
            "mae": 0.26694333512147383,
            "precision": 0.7680525164113785,
            "recall": 0.7373949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7254815275022163,
            "auditor_fn_violation": 0.013616677677457244,
            "auditor_fp_violation": 0.01800367855121676,
            "ave_precision_score": 0.7264401432360326,
            "fpr": 0.16447368421052633,
            "logloss": 2.3187183679116914,
            "mae": 0.39940505137140403,
            "precision": 0.6828752642706131,
            "recall": 0.6757322175732218
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.7436929185121204,
            "auditor_fn_violation": 0.0008878414153806488,
            "auditor_fp_violation": 0.012892236647867072,
            "ave_precision_score": 0.7456489555480392,
            "fpr": 0.15697036223929747,
            "logloss": 2.5640468935765255,
            "mae": 0.3952847161174905,
            "precision": 0.6877729257641921,
            "recall": 0.6617647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.6805504936547524,
            "auditor_fn_violation": 0.012939972840049916,
            "auditor_fp_violation": 0.02848350715498424,
            "ave_precision_score": 0.6552669405813655,
            "fpr": 0.24342105263157895,
            "logloss": 2.6520374330456677,
            "mae": 0.32989733857741094,
            "precision": 0.6558139534883721,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.6827633216142792,
            "auditor_fn_violation": 0.00841258567093138,
            "auditor_fp_violation": 0.015556985502857792,
            "ave_precision_score": 0.6620354673617705,
            "fpr": 0.2305159165751921,
            "logloss": 2.6076957261198337,
            "mae": 0.3068412922873882,
            "precision": 0.672386895475819,
            "recall": 0.9054621848739496
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8198920912211356,
            "auditor_fn_violation": 0.018791749247595975,
            "auditor_fp_violation": 0.026608860861832,
            "ave_precision_score": 0.820262797079958,
            "fpr": 0.14473684210526316,
            "logloss": 0.8106361692319752,
            "mae": 0.2846620186069271,
            "precision": 0.7333333333333333,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8617062414364133,
            "auditor_fn_violation": 0.015372339934876262,
            "auditor_fp_violation": 0.011923237064234074,
            "ave_precision_score": 0.8619345980084462,
            "fpr": 0.12403951701427003,
            "logloss": 0.6996951421157774,
            "mae": 0.2544326752416611,
            "precision": 0.7674897119341564,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.7448153066940475,
            "auditor_fn_violation": 0.005216362034794099,
            "auditor_fp_violation": 0.024299660441426167,
            "ave_precision_score": 0.6826876772345872,
            "fpr": 0.3168859649122807,
            "logloss": 4.3139122810524535,
            "mae": 0.34708784921846725,
            "precision": 0.6089309878213802,
            "recall": 0.9414225941422594
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7602972832684262,
            "auditor_fn_violation": 0.002250735640029887,
            "auditor_fp_violation": 0.025814754532722663,
            "ave_precision_score": 0.7045118007247126,
            "fpr": 0.29637760702524696,
            "logloss": 3.9209230398299404,
            "mae": 0.3313477352907515,
            "precision": 0.6265560165975104,
            "recall": 0.9516806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6865980138192458,
            "auditor_fn_violation": 0.010646058136974237,
            "auditor_fp_violation": 0.026416848573045527,
            "ave_precision_score": 0.6663417022325139,
            "fpr": 0.24342105263157895,
            "logloss": 2.349875565810811,
            "mae": 0.3218197510965151,
            "precision": 0.6536661466458659,
            "recall": 0.8765690376569037
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.6836917911106706,
            "auditor_fn_violation": 0.009448016308609065,
            "auditor_fp_violation": 0.024717059691888414,
            "ave_precision_score": 0.6675187383450998,
            "fpr": 0.21953896816684962,
            "logloss": 2.331951898018918,
            "mae": 0.3020853746965329,
            "precision": 0.68,
            "recall": 0.8928571428571429
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6713214943356589,
            "auditor_fn_violation": 0.01199258606767966,
            "auditor_fp_violation": 0.010676893847522037,
            "ave_precision_score": 0.6523454521047849,
            "fpr": 0.17982456140350878,
            "logloss": 2.330365847469595,
            "mae": 0.3251205012068767,
            "precision": 0.6870229007633588,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6734942903182947,
            "auditor_fn_violation": 0.017240266029573195,
            "auditor_fp_violation": 0.014436579734282149,
            "ave_precision_score": 0.6585032779938281,
            "fpr": 0.17672886937431395,
            "logloss": 2.306958986133405,
            "mae": 0.3009832499691898,
            "precision": 0.6979362101313321,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6789670043854692,
            "auditor_fn_violation": 0.011664556265139835,
            "auditor_fp_violation": 0.024855485487913328,
            "ave_precision_score": 0.6573142876444981,
            "fpr": 0.22807017543859648,
            "logloss": 2.5413462724290032,
            "mae": 0.3168416012853507,
            "precision": 0.6595744680851063,
            "recall": 0.8430962343096234
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6800949692482379,
            "auditor_fn_violation": 0.009867723159516277,
            "auditor_fp_violation": 0.019036804320123144,
            "ave_precision_score": 0.6622716168106774,
            "fpr": 0.21185510428100987,
            "logloss": 2.477353095206113,
            "mae": 0.29228083779662756,
            "precision": 0.6794019933554817,
            "recall": 0.8592436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6609828605898784,
            "auditor_fn_violation": 0.006367907215738091,
            "auditor_fp_violation": 0.010272657450076815,
            "ave_precision_score": 0.6398917487704887,
            "fpr": 0.33223684210526316,
            "logloss": 2.660821836836065,
            "mae": 0.3796578504685992,
            "precision": 0.5932885906040268,
            "recall": 0.9246861924686193
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.6599267793700266,
            "auditor_fn_violation": 0.009708603529227281,
            "auditor_fp_violation": 0.017929015733626062,
            "ave_precision_score": 0.642946261652875,
            "fpr": 0.31833150384193193,
            "logloss": 2.6290540639256506,
            "mae": 0.366151141976267,
            "precision": 0.6016483516483516,
            "recall": 0.9201680672268907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.819663254354573,
            "auditor_fn_violation": 0.023771838067973276,
            "auditor_fp_violation": 0.03871574096531652,
            "ave_precision_score": 0.8200578703484119,
            "fpr": 0.14473684210526316,
            "logloss": 0.7184641380429999,
            "mae": 0.28969498048346404,
            "precision": 0.7333333333333333,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8726256932421839,
            "auditor_fn_violation": 0.01986919905173925,
            "auditor_fp_violation": 0.01620803209811121,
            "ave_precision_score": 0.8729709186011544,
            "fpr": 0.1251372118551043,
            "logloss": 0.5966732779334134,
            "mae": 0.2514565194348809,
            "precision": 0.7654320987654321,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.817596017950832,
            "auditor_fn_violation": 0.03653747339058945,
            "auditor_fp_violation": 0.03051984800711456,
            "ave_precision_score": 0.8179440550998542,
            "fpr": 0.14473684210526316,
            "logloss": 0.5506008580470986,
            "mae": 0.3271280239488605,
            "precision": 0.7306122448979592,
            "recall": 0.7489539748953975
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8725744527116105,
            "auditor_fn_violation": 0.030444889261961643,
            "auditor_fp_violation": 0.02597625446332816,
            "ave_precision_score": 0.8727600343513102,
            "fpr": 0.1141602634467618,
            "logloss": 0.47971430499662077,
            "mae": 0.2949011371480955,
            "precision": 0.7842323651452282,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6851998521799832,
            "auditor_fn_violation": 0.009691789620494752,
            "auditor_fp_violation": 0.03137885035168567,
            "ave_precision_score": 0.6665097720701512,
            "fpr": 0.19078947368421054,
            "logloss": 2.272597307654563,
            "mae": 0.3139084291928508,
            "precision": 0.6842105263157895,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.6844240310989013,
            "auditor_fn_violation": 0.005423903919416285,
            "auditor_fp_violation": 0.02787387864794277,
            "ave_precision_score": 0.6698071253120665,
            "fpr": 0.1778265642151482,
            "logloss": 2.2555912644057052,
            "mae": 0.2935287850666153,
            "precision": 0.7038391224862889,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6822435465870189,
            "auditor_fn_violation": 0.00952892167657638,
            "auditor_fp_violation": 0.026336001293556472,
            "ave_precision_score": 0.6626129125995505,
            "fpr": 0.22587719298245615,
            "logloss": 2.5615625453081354,
            "mae": 0.3150932890373756,
            "precision": 0.6589403973509934,
            "recall": 0.8326359832635983
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6805712836661164,
            "auditor_fn_violation": 0.00770692470182365,
            "auditor_fp_violation": 0.020944522250400593,
            "ave_precision_score": 0.6648801288315689,
            "fpr": 0.2030735455543359,
            "logloss": 2.4971035268884094,
            "mae": 0.29358730671788696,
            "precision": 0.685374149659864,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.7631588374599124,
            "auditor_fn_violation": 0.0011561330103501434,
            "auditor_fp_violation": 0.003933725442638871,
            "ave_precision_score": 0.5360582705584946,
            "fpr": 0.4550438596491228,
            "logloss": 15.386524520409951,
            "mae": 0.458816710987377,
            "precision": 0.5337078651685393,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.7579669713984275,
            "auditor_fn_violation": 0.001485116549363983,
            "auditor_fp_violation": 0.0001059843294598684,
            "ave_precision_score": 0.5325663003509415,
            "fpr": 0.4478594950603732,
            "logloss": 15.307153803166761,
            "mae": 0.4545169165083788,
            "precision": 0.5353075170842825,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 13352,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.5340522071383509,
            "auditor_fn_violation": 0.0320620458048888,
            "auditor_fp_violation": 0.04129780095399791,
            "ave_precision_score": 0.5218366525807285,
            "fpr": 0.34649122807017546,
            "logloss": 4.504398290468819,
            "mae": 0.46085560107635554,
            "precision": 0.5453237410071943,
            "recall": 0.7928870292887029
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.552746944040807,
            "auditor_fn_violation": 0.02545914084623971,
            "auditor_fp_violation": 0.044097051364548244,
            "ave_precision_score": 0.544022478185463,
            "fpr": 0.3402854006586169,
            "logloss": 4.012157147751697,
            "mae": 0.4365276024074405,
            "precision": 0.5590327169274538,
            "recall": 0.8256302521008403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.681374434410128,
            "auditor_fn_violation": 0.008359025178007785,
            "auditor_fp_violation": 0.025042444821731756,
            "ave_precision_score": 0.657952446689648,
            "fpr": 0.22697368421052633,
            "logloss": 2.727340202161666,
            "mae": 0.31748847675358083,
            "precision": 0.6584158415841584,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6828639168187491,
            "auditor_fn_violation": 0.006457028475495582,
            "auditor_fp_violation": 0.025991395081822428,
            "ave_precision_score": 0.6630472770594429,
            "fpr": 0.20856201975850713,
            "logloss": 2.6194089413903425,
            "mae": 0.29627217741532474,
            "precision": 0.6774193548387096,
            "recall": 0.8382352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.699169950491914,
            "auditor_fn_violation": 0.01289180063128533,
            "auditor_fp_violation": 0.027013097259277228,
            "ave_precision_score": 0.6898901310576124,
            "fpr": 0.20614035087719298,
            "logloss": 1.9949107319290886,
            "mae": 0.3040867919391354,
            "precision": 0.6769759450171822,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7402555608967663,
            "auditor_fn_violation": 0.011216780894575175,
            "auditor_fp_violation": 0.014640978083954738,
            "ave_precision_score": 0.7337574294654645,
            "fpr": 0.16794731064763996,
            "logloss": 1.6017196797266657,
            "mae": 0.2717572242493304,
            "precision": 0.7213114754098361,
            "recall": 0.8319327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8066915454344115,
            "auditor_fn_violation": 0.02419391837333921,
            "auditor_fp_violation": 0.03529994340690436,
            "ave_precision_score": 0.8071473011160533,
            "fpr": 0.17653508771929824,
            "logloss": 0.9599366535014652,
            "mae": 0.2862174760126242,
            "precision": 0.7062043795620438,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8527709593811235,
            "auditor_fn_violation": 0.021501904823400277,
            "auditor_fp_violation": 0.021764639085506642,
            "ave_precision_score": 0.8530980843703087,
            "fpr": 0.14818880351262348,
            "logloss": 0.7980654558581755,
            "mae": 0.25129002890405006,
            "precision": 0.7438330170777988,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8236868167652036,
            "auditor_fn_violation": 0.019388167070395656,
            "auditor_fp_violation": 0.029112600048508373,
            "ave_precision_score": 0.8240524882674287,
            "fpr": 0.13925438596491227,
            "logloss": 0.699820610834864,
            "mae": 0.28664557304996935,
            "precision": 0.7386831275720165,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8723897324328201,
            "auditor_fn_violation": 0.017470874189412323,
            "auditor_fp_violation": 0.010812925041321269,
            "ave_precision_score": 0.8726153914514598,
            "fpr": 0.11964873765093303,
            "logloss": 0.6005252783191805,
            "mae": 0.25315507100225676,
            "precision": 0.7733887733887734,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6626995390256869,
            "auditor_fn_violation": 0.020718637598179553,
            "auditor_fp_violation": 0.03424387581857872,
            "ave_precision_score": 0.6411164506409477,
            "fpr": 0.20614035087719298,
            "logloss": 3.7205579203096137,
            "mae": 0.3439180326953738,
            "precision": 0.6544117647058824,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6480263157565678,
            "auditor_fn_violation": 0.00712579213902905,
            "auditor_fp_violation": 0.025819801405554083,
            "ave_precision_score": 0.631439676588202,
            "fpr": 0.17672886937431395,
            "logloss": 4.097932937984101,
            "mae": 0.32818657205880125,
            "precision": 0.6830708661417323,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 13352,
        "test": {
            "accuracy": 0.47149122807017546,
            "auc_prc": 0.6754573745808404,
            "auditor_fn_violation": 0.0006789987521104288,
            "auditor_fp_violation": 0.0039362519201228885,
            "ave_precision_score": 0.6774453153356625,
            "fpr": 0.013157894736842105,
            "logloss": 14.970266621408408,
            "mae": 0.5292004514045158,
            "precision": 0.4,
            "recall": 0.016736401673640166
        },
        "train": {
            "accuracy": 0.4862788144895719,
            "auc_prc": 0.6994196590488553,
            "auditor_fn_violation": 0.002414467433515665,
            "auditor_fp_violation": 0.0008832027454988202,
            "ave_precision_score": 0.7003477936222124,
            "fpr": 0.005488474204171241,
            "logloss": 14.552401899205117,
            "mae": 0.5163336464567929,
            "precision": 0.7222222222222222,
            "recall": 0.0273109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7357416358772426,
            "auditor_fn_violation": 0.02721041620788373,
            "auditor_fp_violation": 0.035373211253941314,
            "ave_precision_score": 0.7300927770535253,
            "fpr": 0.16337719298245615,
            "logloss": 2.38983704629887,
            "mae": 0.31246788602630976,
            "precision": 0.6989898989898989,
            "recall": 0.7238493723849372
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7553550836187667,
            "auditor_fn_violation": 0.021049912830115577,
            "auditor_fp_violation": 0.01784574233190759,
            "ave_precision_score": 0.7499007323137304,
            "fpr": 0.14050493962678376,
            "logloss": 1.9810111848708916,
            "mae": 0.2812224397703857,
            "precision": 0.7382413087934561,
            "recall": 0.7584033613445378
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8223497893679124,
            "auditor_fn_violation": 0.014905857740585778,
            "auditor_fp_violation": 0.026138936049801925,
            "ave_precision_score": 0.8228289945194744,
            "fpr": 0.13815789473684212,
            "logloss": 0.6724479963727207,
            "mae": 0.2893774600466841,
            "precision": 0.738045738045738,
            "recall": 0.7426778242677824
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8687412228372012,
            "auditor_fn_violation": 0.011000009224326392,
            "auditor_fp_violation": 0.013694689428063136,
            "ave_precision_score": 0.8690252603452372,
            "fpr": 0.12294182217343579,
            "logloss": 0.5925281418498441,
            "mae": 0.2603094283651572,
            "precision": 0.7690721649484537,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.745563711825771,
            "auditor_fn_violation": 0.011565917932907585,
            "auditor_fp_violation": 0.030666383701188463,
            "ave_precision_score": 0.6800965357077131,
            "fpr": 0.24561403508771928,
            "logloss": 4.1601219142715955,
            "mae": 0.3299385969907027,
            "precision": 0.6521739130434783,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7695495990564771,
            "auditor_fn_violation": 0.013794980121576624,
            "auditor_fp_violation": 0.029713463794996033,
            "ave_precision_score": 0.7119368242079485,
            "fpr": 0.2305159165751921,
            "logloss": 3.660281260151052,
            "mae": 0.3100943089091395,
            "precision": 0.6677215189873418,
            "recall": 0.8865546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.6789474960226772,
            "auditor_fn_violation": 0.007776370843426559,
            "auditor_fp_violation": 0.02768008731506185,
            "ave_precision_score": 0.6572919834552373,
            "fpr": 0.28289473684210525,
            "logloss": 2.6598819402642424,
            "mae": 0.33599417716056623,
            "precision": 0.6293103448275862,
            "recall": 0.9163179916317992
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6818479744594695,
            "auditor_fn_violation": 0.010282817847226709,
            "auditor_fp_violation": 0.0050342556493432845,
            "ave_precision_score": 0.6638029715380667,
            "fpr": 0.26344676180021953,
            "logloss": 2.61155407906335,
            "mae": 0.31552524762227624,
            "precision": 0.6475770925110133,
            "recall": 0.9264705882352942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7849795545480363,
            "auditor_fn_violation": 0.038936908170006605,
            "auditor_fp_violation": 0.04536795618077453,
            "ave_precision_score": 0.7851068039362783,
            "fpr": 0.18530701754385964,
            "logloss": 2.5661161704989444,
            "mae": 0.32210641538072793,
            "precision": 0.6841121495327103,
            "recall": 0.7656903765690377
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8362508583857321,
            "auditor_fn_violation": 0.04041177393020875,
            "auditor_fp_violation": 0.03708694500170332,
            "ave_precision_score": 0.8361431954437928,
            "fpr": 0.16136114160263446,
            "logloss": 2.0328540099017296,
            "mae": 0.27417071021786865,
            "precision": 0.7231638418079096,
            "recall": 0.8067226890756303
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 13352,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7413769908280203,
            "auditor_fn_violation": 0.03333287455039272,
            "auditor_fp_violation": 0.032035734497534156,
            "ave_precision_score": 0.7419163085817724,
            "fpr": 0.20175438596491227,
            "logloss": 1.3668416940959545,
            "mae": 0.30901160707947734,
            "precision": 0.6754850088183422,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8027456741298957,
            "auditor_fn_violation": 0.028226438764309237,
            "auditor_fp_violation": 0.03145463492183656,
            "ave_precision_score": 0.8031308949065885,
            "fpr": 0.18441273326015367,
            "logloss": 1.0797258226608322,
            "mae": 0.2711397128161407,
            "precision": 0.7031802120141343,
            "recall": 0.8361344537815126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 13352,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6894053544928389,
            "auditor_fn_violation": 0.012827571019599207,
            "auditor_fp_violation": 0.03602504244482174,
            "ave_precision_score": 0.6721777640378729,
            "fpr": 0.19188596491228072,
            "logloss": 2.1552674827015865,
            "mae": 0.30637194637069787,
            "precision": 0.6875,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.6853914684620044,
            "auditor_fn_violation": 0.006973590753535224,
            "auditor_fp_violation": 0.034460047692948255,
            "ave_precision_score": 0.6721389435209134,
            "fpr": 0.1778265642151482,
            "logloss": 2.191031254036057,
            "mae": 0.2941855461687196,
            "precision": 0.7038391224862889,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6811797806713011,
            "auditor_fn_violation": 0.0126302943551347,
            "auditor_fp_violation": 0.025797861589457523,
            "ave_precision_score": 0.6587958584722775,
            "fpr": 0.23135964912280702,
            "logloss": 2.6914938582261403,
            "mae": 0.31720855365528927,
            "precision": 0.6580226904376013,
            "recall": 0.8493723849372385
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6804538492171842,
            "auditor_fn_violation": 0.010275899602431532,
            "auditor_fp_violation": 0.021739404721349543,
            "ave_precision_score": 0.660468958670427,
            "fpr": 0.21844127332601537,
            "logloss": 2.644835877988477,
            "mae": 0.2987682482202016,
            "precision": 0.6705298013245033,
            "recall": 0.8508403361344538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6916006000961431,
            "auditor_fn_violation": 0.014823276811275049,
            "auditor_fp_violation": 0.03326107607729001,
            "ave_precision_score": 0.672946349034077,
            "fpr": 0.23355263157894737,
            "logloss": 2.4053235260874173,
            "mae": 0.3070319545268924,
            "precision": 0.6624405705229794,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6883473501045969,
            "auditor_fn_violation": 0.004713630787111771,
            "auditor_fp_violation": 0.023801052272985356,
            "ave_precision_score": 0.6732766346579033,
            "fpr": 0.22063666300768386,
            "logloss": 2.350080881555849,
            "mae": 0.28842307249213894,
            "precision": 0.6763285024154589,
            "recall": 0.8823529411764706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6873083739112145,
            "auditor_fn_violation": 0.012905564119503783,
            "auditor_fp_violation": 0.02696004123211255,
            "ave_precision_score": 0.6677953407553652,
            "fpr": 0.2138157894736842,
            "logloss": 2.23338558719241,
            "mae": 0.31377135454934896,
            "precision": 0.6733668341708543,
            "recall": 0.8410041841004184
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6846942149404616,
            "auditor_fn_violation": 0.010190574583291059,
            "auditor_fp_violation": 0.017661531473560706,
            "ave_precision_score": 0.6690787407320395,
            "fpr": 0.1986827661909989,
            "logloss": 2.2347299968570074,
            "mae": 0.2944871324698367,
            "precision": 0.6921768707482994,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.760940925132691,
            "auditor_fn_violation": 0.009680320046979376,
            "auditor_fp_violation": 0.022035936615732884,
            "ave_precision_score": 0.7615172256099941,
            "fpr": 0.12390350877192982,
            "logloss": 2.301767316677738,
            "mae": 0.34071592524292615,
            "precision": 0.7250608272506083,
            "recall": 0.6234309623430963
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8017289809961724,
            "auditor_fn_violation": 0.01003145495300206,
            "auditor_fp_violation": 0.019458218201546865,
            "ave_precision_score": 0.8020275604154121,
            "fpr": 0.1163556531284303,
            "logloss": 2.006015682585157,
            "mae": 0.3178590205331678,
            "precision": 0.7458033573141487,
            "recall": 0.6533613445378151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.6329915055730293,
            "auditor_fn_violation": 0.014492953094032155,
            "auditor_fp_violation": 0.013445913170021822,
            "ave_precision_score": 0.5722152906492729,
            "fpr": 0.2883771929824561,
            "logloss": 5.214877774633202,
            "mae": 0.3822440545460076,
            "precision": 0.6033182503770739,
            "recall": 0.8368200836820083
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6384448959081569,
            "auditor_fn_violation": 0.020399597819369248,
            "auditor_fp_violation": 0.02827762847445652,
            "ave_precision_score": 0.5832843564817184,
            "fpr": 0.2722283205268935,
            "logloss": 4.834725358638169,
            "mae": 0.3695486455885512,
            "precision": 0.6160990712074303,
            "recall": 0.8361344537815126
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8227388686765826,
            "auditor_fn_violation": 0.02318918373339206,
            "auditor_fp_violation": 0.03690425660926511,
            "ave_precision_score": 0.8231186999801923,
            "fpr": 0.14802631578947367,
            "logloss": 0.7106644725357741,
            "mae": 0.28867298669273733,
            "precision": 0.7310756972111554,
            "recall": 0.7677824267782427
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.871782644234047,
            "auditor_fn_violation": 0.02109603446208341,
            "auditor_fp_violation": 0.01822930466709565,
            "ave_precision_score": 0.8722735972047395,
            "fpr": 0.12843029637760703,
            "logloss": 0.5925950807225742,
            "mae": 0.24999891725211035,
            "precision": 0.7626774847870182,
            "recall": 0.7899159663865546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6609761001926009,
            "auditor_fn_violation": 0.021214123174043895,
            "auditor_fp_violation": 0.038422669577168736,
            "ave_precision_score": 0.6393857409401766,
            "fpr": 0.18859649122807018,
            "logloss": 3.339539568488974,
            "mae": 0.336429995214909,
            "precision": 0.6723809523809524,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6535642008519933,
            "auditor_fn_violation": 0.00749015303157487,
            "auditor_fp_violation": 0.03307468110072297,
            "ave_precision_score": 0.6355697163835887,
            "fpr": 0.1712403951701427,
            "logloss": 3.421202847457413,
            "mae": 0.32243672797025485,
            "precision": 0.6904761904761905,
            "recall": 0.7310924369747899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.6831313222815157,
            "auditor_fn_violation": 0.010655233795786536,
            "auditor_fp_violation": 0.02838244805562293,
            "ave_precision_score": 0.661751900242557,
            "fpr": 0.24890350877192982,
            "logloss": 2.6085383802903532,
            "mae": 0.32329569204864606,
            "precision": 0.651840490797546,
            "recall": 0.8891213389121339
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6843279054205684,
            "auditor_fn_violation": 0.013769613223994318,
            "auditor_fp_violation": 0.008698285324955531,
            "ave_precision_score": 0.6662698748092476,
            "fpr": 0.24039517014270034,
            "logloss": 2.555624528840731,
            "mae": 0.2984294861040211,
            "precision": 0.6609907120743034,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.6924436340977822,
            "auditor_fn_violation": 0.00763873596124202,
            "auditor_fp_violation": 0.030835657692618652,
            "ave_precision_score": 0.6715746806666026,
            "fpr": 0.18311403508771928,
            "logloss": 2.33481010942387,
            "mae": 0.30369451282021503,
            "precision": 0.6990990990990991,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6856877014141023,
            "auditor_fn_violation": 0.0038096468005423957,
            "auditor_fp_violation": 0.026210934049989282,
            "ave_precision_score": 0.6699160448238192,
            "fpr": 0.18331503841931943,
            "logloss": 2.2950848561129997,
            "mae": 0.2899547719592701,
            "precision": 0.697463768115942,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7263685694522956,
            "auditor_fn_violation": 0.01892479630037437,
            "auditor_fp_violation": 0.03593914221036462,
            "ave_precision_score": 0.7225124865128769,
            "fpr": 0.22697368421052633,
            "logloss": 1.5554641887578524,
            "mae": 0.32820767124779693,
            "precision": 0.6584158415841584,
            "recall": 0.8347280334728033
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7603355321470953,
            "auditor_fn_violation": 0.018397918991965613,
            "auditor_fp_violation": 0.023215615024540424,
            "ave_precision_score": 0.7583624395990793,
            "fpr": 0.2030735455543359,
            "logloss": 1.2261547494216691,
            "mae": 0.28783760593050023,
            "precision": 0.6885521885521886,
            "recall": 0.8592436974789915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 13352,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.6782512663563466,
            "auditor_fn_violation": 0.008833865521544446,
            "auditor_fp_violation": 0.031800772091519124,
            "ave_precision_score": 0.6582790133408466,
            "fpr": 0.29714912280701755,
            "logloss": 2.647172274515245,
            "mae": 0.34114417713453554,
            "precision": 0.6225626740947076,
            "recall": 0.9351464435146444
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6851419901744932,
            "auditor_fn_violation": 0.0071234860574306575,
            "auditor_fp_violation": 0.006399434750242887,
            "ave_precision_score": 0.6676538357000891,
            "fpr": 0.2810098792535675,
            "logloss": 2.60830980764795,
            "mae": 0.320637666065863,
            "precision": 0.635846372688478,
            "recall": 0.9390756302521008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7297267467407302,
            "auditor_fn_violation": 0.03706048594289069,
            "auditor_fp_violation": 0.032151952461799665,
            "ave_precision_score": 0.7200664949377479,
            "fpr": 0.16885964912280702,
            "logloss": 1.2832323174339113,
            "mae": 0.34821764458075977,
            "precision": 0.6844262295081968,
            "recall": 0.698744769874477
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8066746954473183,
            "auditor_fn_violation": 0.040483262459758876,
            "auditor_fp_violation": 0.03151772083222933,
            "ave_precision_score": 0.8008294101794655,
            "fpr": 0.14928649835345773,
            "logloss": 0.934566558407728,
            "mae": 0.2993491657987713,
            "precision": 0.7296222664015904,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 13352,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8340569781172368,
            "auditor_fn_violation": 0.015497687733979299,
            "auditor_fp_violation": 0.02580038806694155,
            "ave_precision_score": 0.8343519104754572,
            "fpr": 0.14144736842105263,
            "logloss": 0.63649085362896,
            "mae": 0.28563594806230375,
            "precision": 0.7372708757637475,
            "recall": 0.7573221757322176
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8683542129979975,
            "auditor_fn_violation": 0.007803780128956087,
            "auditor_fp_violation": 0.014504712517506346,
            "ave_precision_score": 0.8686631369452713,
            "fpr": 0.12843029637760703,
            "logloss": 0.5832781548163238,
            "mae": 0.2620435637245254,
            "precision": 0.7607361963190185,
            "recall": 0.7815126050420168
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6866967633058916,
            "auditor_fn_violation": 0.005211774205387948,
            "auditor_fp_violation": 0.02313242784380306,
            "ave_precision_score": 0.667701562036666,
            "fpr": 0.18421052631578946,
            "logloss": 2.2352861836677635,
            "mae": 0.3121712431851565,
            "precision": 0.691743119266055,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.6812085190080068,
            "auditor_fn_violation": 0.005908181055078457,
            "auditor_fp_violation": 0.024421817631250238,
            "ave_precision_score": 0.6655791916822289,
            "fpr": 0.17453347969264543,
            "logloss": 2.2612331222943913,
            "mae": 0.29084260927327943,
            "precision": 0.708256880733945,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8219885592088183,
            "auditor_fn_violation": 0.011749431109153635,
            "auditor_fp_violation": 0.022425014148273914,
            "ave_precision_score": 0.8223621255079989,
            "fpr": 0.13925438596491227,
            "logloss": 0.7726212120213171,
            "mae": 0.2890114198248669,
            "precision": 0.7354166666666667,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8551125563888918,
            "auditor_fn_violation": 0.0054054552666291614,
            "auditor_fp_violation": 0.007903402854006585,
            "ave_precision_score": 0.8556181005067374,
            "fpr": 0.12733260153677278,
            "logloss": 0.68857573785731,
            "mae": 0.2633422663912923,
            "precision": 0.7578288100208769,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7991055228669063,
            "auditor_fn_violation": 0.011676025838655218,
            "auditor_fp_violation": 0.029208606192901616,
            "ave_precision_score": 0.7995436192214505,
            "fpr": 0.17434210526315788,
            "logloss": 0.9821369092068618,
            "mae": 0.29006636163195054,
            "precision": 0.7044609665427509,
            "recall": 0.7928870292887029
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8385412770429111,
            "auditor_fn_violation": 0.006466252801889144,
            "auditor_fp_violation": 0.0216611781924625,
            "ave_precision_score": 0.8388594627524298,
            "fpr": 0.15587266739846323,
            "logloss": 0.8444241923044671,
            "mae": 0.2647103328344129,
            "precision": 0.7310606060606061,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7166565837851968,
            "auditor_fn_violation": 0.013222124348528227,
            "auditor_fp_violation": 0.025004547659471268,
            "ave_precision_score": 0.7175068432893296,
            "fpr": 0.13706140350877194,
            "logloss": 2.396709157451094,
            "mae": 0.36497442314723116,
            "precision": 0.7002398081534772,
            "recall": 0.6108786610878661
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7397108274765056,
            "auditor_fn_violation": 0.004888892988589516,
            "auditor_fp_violation": 0.009854019203351131,
            "ave_precision_score": 0.7406101738275408,
            "fpr": 0.1207464324917673,
            "logloss": 2.6066551822955004,
            "mae": 0.3578874261987635,
            "precision": 0.7208121827411168,
            "recall": 0.5966386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6871353557234074,
            "auditor_fn_violation": 0.010313440505028264,
            "auditor_fp_violation": 0.022665029509257015,
            "ave_precision_score": 0.6670992830215254,
            "fpr": 0.21600877192982457,
            "logloss": 2.261462752456653,
            "mae": 0.31572916860571704,
            "precision": 0.6722129783693843,
            "recall": 0.8451882845188284
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.6823559009936467,
            "auditor_fn_violation": 0.009551789980536674,
            "auditor_fp_violation": 0.016874219311858896,
            "ave_precision_score": 0.6666376008893473,
            "fpr": 0.20087815587266739,
            "logloss": 2.2734397142973735,
            "mae": 0.29663317980078374,
            "precision": 0.6934673366834171,
            "recall": 0.8697478991596639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8159061540311174,
            "auditor_fn_violation": 0.036771452690303165,
            "auditor_fp_violation": 0.03861215538847118,
            "ave_precision_score": 0.8162617067375137,
            "fpr": 0.1699561403508772,
            "logloss": 0.5854997604530754,
            "mae": 0.3311833202194401,
            "precision": 0.712430426716141,
            "recall": 0.803347280334728
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8625587323588371,
            "auditor_fn_violation": 0.031747825365052725,
            "auditor_fp_violation": 0.034760336626417865,
            "ave_precision_score": 0.862802759348102,
            "fpr": 0.15916575192096596,
            "logloss": 0.5185263913149916,
            "mae": 0.300878484691552,
            "precision": 0.7354014598540146,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 13352,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.6877385024402238,
            "auditor_fn_violation": 0.014036464068120093,
            "auditor_fp_violation": 0.032258064516129045,
            "ave_precision_score": 0.6685250420187032,
            "fpr": 0.24561403508771928,
            "logloss": 2.495088796977775,
            "mae": 0.31253996302380227,
            "precision": 0.6537867078825348,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.6835317661870608,
            "auditor_fn_violation": 0.006420131169921317,
            "auditor_fp_violation": 0.01827724995899417,
            "ave_precision_score": 0.6673535302211158,
            "fpr": 0.2261251372118551,
            "logloss": 2.4555678304626833,
            "mae": 0.2922956740183703,
            "precision": 0.6740506329113924,
            "recall": 0.8949579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7396359085095873,
            "auditor_fn_violation": 0.011451222197753805,
            "auditor_fp_violation": 0.029534521788341823,
            "ave_precision_score": 0.6769738265796993,
            "fpr": 0.2149122807017544,
            "logloss": 5.387872087742759,
            "mae": 0.31310611417392203,
            "precision": 0.6655290102389079,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7609369571767203,
            "auditor_fn_violation": 0.006254093294837146,
            "auditor_fp_violation": 0.01960710095007381,
            "ave_precision_score": 0.7073778219830287,
            "fpr": 0.1942919868276619,
            "logloss": 4.680414936454839,
            "mae": 0.2920372609468775,
            "precision": 0.6856127886323268,
            "recall": 0.8109243697478992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6860229512705043,
            "auditor_fn_violation": 0.013176246054466711,
            "auditor_fp_violation": 0.033122119815668205,
            "ave_precision_score": 0.6673328333768528,
            "fpr": 0.20175438596491227,
            "logloss": 2.2406899109562497,
            "mae": 0.3131248612226045,
            "precision": 0.6788830715532286,
            "recall": 0.8138075313807531
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6857167788195568,
            "auditor_fn_violation": 0.004003357654807259,
            "auditor_fp_violation": 0.025638113983622896,
            "ave_precision_score": 0.6710727877162472,
            "fpr": 0.18990120746432493,
            "logloss": 2.2292196481242628,
            "mae": 0.2934713334228073,
            "precision": 0.6938053097345133,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6898398529348817,
            "auditor_fn_violation": 0.01017580562284372,
            "auditor_fp_violation": 0.02983769908642575,
            "ave_precision_score": 0.6721296582680613,
            "fpr": 0.21710526315789475,
            "logloss": 2.2884224612419293,
            "mae": 0.3070305617186255,
            "precision": 0.6754098360655738,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.6920790339858636,
            "auditor_fn_violation": 0.004649060502356816,
            "auditor_fp_violation": 0.019607100950073814,
            "ave_precision_score": 0.6769979375127116,
            "fpr": 0.20856201975850713,
            "logloss": 2.2463921587243494,
            "mae": 0.28762256835353434,
            "precision": 0.6849087893864013,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8398400269489321,
            "auditor_fn_violation": 0.029545621375614773,
            "auditor_fp_violation": 0.033038746058695126,
            "ave_precision_score": 0.8402097968465942,
            "fpr": 0.13486842105263158,
            "logloss": 0.6073463438755704,
            "mae": 0.2846264433833781,
            "precision": 0.7510121457489879,
            "recall": 0.7761506276150628
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8820545261495318,
            "auditor_fn_violation": 0.03453126585431099,
            "auditor_fp_violation": 0.03096256482077293,
            "ave_precision_score": 0.882328940906037,
            "fpr": 0.11525795828759605,
            "logloss": 0.5324833307424703,
            "mae": 0.253710118401461,
            "precision": 0.7865853658536586,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6633062731136025,
            "auditor_fn_violation": 0.01787418336636571,
            "auditor_fp_violation": 0.040206362680895794,
            "ave_precision_score": 0.641713439105339,
            "fpr": 0.20065789473684212,
            "logloss": 3.1872176018152336,
            "mae": 0.33749873092333965,
            "precision": 0.660482374768089,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6578926661818385,
            "auditor_fn_violation": 0.003929563043658734,
            "auditor_fp_violation": 0.02998599492789281,
            "ave_precision_score": 0.6398980029470496,
            "fpr": 0.1800219538968167,
            "logloss": 3.2747385378258755,
            "mae": 0.31886419011232003,
            "precision": 0.6846153846153846,
            "recall": 0.7478991596638656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6788437162684078,
            "auditor_fn_violation": 0.008969206489025912,
            "auditor_fp_violation": 0.029264188697550333,
            "ave_precision_score": 0.6577072017229696,
            "fpr": 0.28618421052631576,
            "logloss": 2.6460915781912404,
            "mae": 0.3366865986878043,
            "precision": 0.6276747503566333,
            "recall": 0.9205020920502092
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.6821271247875941,
            "auditor_fn_violation": 0.014915735778394784,
            "auditor_fp_violation": 0.004744060461536525,
            "ave_precision_score": 0.6640491056324416,
            "fpr": 0.2689352360043908,
            "logloss": 2.6153556868086585,
            "mae": 0.3164056156939169,
            "precision": 0.6428571428571429,
            "recall": 0.9264705882352942
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6917175682198728,
            "auditor_fn_violation": 0.011467279600675331,
            "auditor_fp_violation": 0.03466327108092813,
            "ave_precision_score": 0.6730250545287073,
            "fpr": 0.19736842105263158,
            "logloss": 2.255124654339932,
            "mae": 0.30548983847758493,
            "precision": 0.6836555360281195,
            "recall": 0.8138075313807531
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.6955639328374836,
            "auditor_fn_violation": 0.007370236788458524,
            "auditor_fp_violation": 0.026135230957517946,
            "ave_precision_score": 0.6806647318206249,
            "fpr": 0.1800219538968167,
            "logloss": 2.2356598157534835,
            "mae": 0.28619439149083886,
            "precision": 0.7045045045045045,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7697966531081293,
            "auditor_fn_violation": 0.009017378697790502,
            "auditor_fp_violation": 0.01912543455412726,
            "ave_precision_score": 0.7702923120686616,
            "fpr": 0.16776315789473684,
            "logloss": 0.9768732853734194,
            "mae": 0.2857184653603325,
            "precision": 0.7156133828996283,
            "recall": 0.805439330543933
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8147840692905174,
            "auditor_fn_violation": 0.0030855371786475314,
            "auditor_fp_violation": 0.018567445146800927,
            "ave_precision_score": 0.8132349066681911,
            "fpr": 0.15587266739846323,
            "logloss": 0.9027578797002828,
            "mae": 0.2600504391605984,
            "precision": 0.7365491651205937,
            "recall": 0.8340336134453782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6892040084433859,
            "auditor_fn_violation": 0.0066592343830287,
            "auditor_fp_violation": 0.03542374080362196,
            "ave_precision_score": 0.6742575276158761,
            "fpr": 0.20065789473684212,
            "logloss": 2.150927006011254,
            "mae": 0.3074564932068601,
            "precision": 0.6789473684210526,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.6908797549813793,
            "auditor_fn_violation": 0.002167716702487808,
            "auditor_fp_violation": 0.0335440402740452,
            "ave_precision_score": 0.6799789491580783,
            "fpr": 0.18551042810098792,
            "logloss": 2.0465772604697543,
            "mae": 0.29491493429224014,
            "precision": 0.696588868940754,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 13352,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7753437213611665,
            "auditor_fn_violation": 0.0163097335388681,
            "auditor_fp_violation": 0.0337638450966125,
            "ave_precision_score": 0.7759721035180142,
            "fpr": 0.17543859649122806,
            "logloss": 0.923362013511258,
            "mae": 0.3012371730981914,
            "precision": 0.700374531835206,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8051126609898877,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.019321952635098477,
            "ave_precision_score": 0.8056461300437257,
            "fpr": 0.150384193194292,
            "logloss": 0.8404108948764437,
            "mae": 0.2724876638351686,
            "precision": 0.7318982387475538,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.755033560752808,
            "auditor_fn_violation": 0.019300998311678783,
            "auditor_fp_violation": 0.029577471905570384,
            "ave_precision_score": 0.755815184023451,
            "fpr": 0.14364035087719298,
            "logloss": 1.9636069997941012,
            "mae": 0.32933922348683664,
            "precision": 0.7095343680709535,
            "recall": 0.6694560669456067
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7974280845760076,
            "auditor_fn_violation": 0.0191681502458283,
            "auditor_fp_violation": 0.013573564480109018,
            "ave_precision_score": 0.7978620609784892,
            "fpr": 0.1251372118551043,
            "logloss": 2.0149551307666362,
            "mae": 0.30878556617212133,
            "precision": 0.7348837209302326,
            "recall": 0.6638655462184874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 13352,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.6895497203326937,
            "auditor_fn_violation": 0.008735227189312196,
            "auditor_fp_violation": 0.021171881316193724,
            "ave_precision_score": 0.6804576819385,
            "fpr": 0.21600877192982457,
            "logloss": 1.7614780497647258,
            "mae": 0.3181189512073807,
            "precision": 0.6632478632478632,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.705935413470127,
            "auditor_fn_violation": 0.007273381361326095,
            "auditor_fp_violation": 0.01866081229418222,
            "ave_precision_score": 0.6993897187633502,
            "fpr": 0.19099890230515917,
            "logloss": 1.5196707336129305,
            "mae": 0.2932227589206938,
            "precision": 0.6942003514938488,
            "recall": 0.8298319327731093
        }
    }
]