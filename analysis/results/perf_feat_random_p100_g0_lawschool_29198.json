[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 29198,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8402352023498607,
            "auditor_fn_violation": 0.01852111622339431,
            "auditor_fp_violation": 0.027073185220387316,
            "ave_precision_score": 0.8406481546750751,
            "fpr": 0.13706140350877194,
            "logloss": 0.7412306797143067,
            "mae": 0.2693682671293139,
            "precision": 0.7422680412371134,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8420431699890503,
            "auditor_fn_violation": 0.015498998494913263,
            "auditor_fp_violation": 0.01683647438969713,
            "ave_precision_score": 0.8423137599493741,
            "fpr": 0.12403951701427003,
            "logloss": 0.7532248019519985,
            "mae": 0.2633703853544323,
            "precision": 0.771255060728745,
            "recall": 0.7855670103092783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7278596842094047,
            "auditor_fn_violation": 0.027599315452811128,
            "auditor_fp_violation": 0.007999683180864123,
            "ave_precision_score": 0.7116566028966909,
            "fpr": 0.051535087719298246,
            "logloss": 0.7158103385272646,
            "mae": 0.4087139039481388,
            "precision": 0.780373831775701,
            "recall": 0.35607675906183367
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.7415033772353626,
            "auditor_fn_violation": 0.03940837643011533,
            "auditor_fp_violation": 0.00896708461526569,
            "ave_precision_score": 0.7257048163482582,
            "fpr": 0.05159165751920966,
            "logloss": 0.7228657197840254,
            "mae": 0.41252736104386484,
            "precision": 0.7844036697247706,
            "recall": 0.3525773195876289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7937284061635815,
            "auditor_fn_violation": 0.013980847641491793,
            "auditor_fp_violation": 0.025028711734188743,
            "ave_precision_score": 0.794523142940537,
            "fpr": 0.14364035087719298,
            "logloss": 0.6948409010511806,
            "mae": 0.3358685356664896,
            "precision": 0.7348178137651822,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8387140679300955,
            "auditor_fn_violation": 0.00948996797447011,
            "auditor_fp_violation": 0.02750936648062543,
            "ave_precision_score": 0.838995906613441,
            "fpr": 0.12733260153677278,
            "logloss": 0.6630026803244722,
            "mae": 0.3263973390170333,
            "precision": 0.7647058823529411,
            "recall": 0.777319587628866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8486926370357655,
            "auditor_fn_violation": 0.006976396214416637,
            "auditor_fp_violation": 0.014224684170923922,
            "ave_precision_score": 0.8293837724278779,
            "fpr": 0.09539473684210527,
            "logloss": 0.5180813813508178,
            "mae": 0.3138288064132722,
            "precision": 0.7948113207547169,
            "recall": 0.7185501066098081
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8691772593097324,
            "auditor_fn_violation": 0.004381726210010526,
            "auditor_fp_violation": 0.004102183536638788,
            "ave_precision_score": 0.8504657886920777,
            "fpr": 0.07354555433589462,
            "logloss": 0.4873218331650397,
            "mae": 0.2969260341625837,
            "precision": 0.8419811320754716,
            "recall": 0.7360824742268042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7378571497824126,
            "auditor_fn_violation": 0.011472244042943183,
            "auditor_fp_violation": 0.03024137657914538,
            "ave_precision_score": 0.735747419318595,
            "fpr": 0.1699561403508772,
            "logloss": 1.191172410794498,
            "mae": 0.3219765541512607,
            "precision": 0.6843177189409368,
            "recall": 0.7164179104477612
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7449561046688157,
            "auditor_fn_violation": 0.01138434030803355,
            "auditor_fp_violation": 0.019377148364022403,
            "ave_precision_score": 0.7433549912751253,
            "fpr": 0.16355653128430298,
            "logloss": 1.2248581205743585,
            "mae": 0.3299679398140852,
            "precision": 0.6971544715447154,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 29198,
        "test": {
            "accuracy": 0.48355263157894735,
            "auc_prc": 0.7723376997234637,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 2.722664448932718e-05,
            "ave_precision_score": 0.7738110418112696,
            "fpr": 0.0021929824561403508,
            "logloss": 7.877405873921997,
            "mae": 0.5161066442442813,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.7788209761149995,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 7.214895667455151e-05,
            "ave_precision_score": 0.7801471578665939,
            "fpr": 0.0021953896816684962,
            "logloss": 8.201819250563467,
            "mae": 0.5346227168220072,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.686091233718793,
            "auditor_fn_violation": 0.010141959376052079,
            "auditor_fp_violation": 0.029805750267316144,
            "ave_precision_score": 0.6869159348453311,
            "fpr": 0.16885964912280702,
            "logloss": 0.625488219626019,
            "mae": 0.42705932231783345,
            "precision": 0.6844262295081968,
            "recall": 0.7121535181236673
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7331505151622997,
            "auditor_fn_violation": 0.015050867405253097,
            "auditor_fp_violation": 0.01969666517215257,
            "ave_precision_score": 0.7336036596010955,
            "fpr": 0.16465422612513722,
            "logloss": 0.6261895005102069,
            "mae": 0.42779187668364343,
            "precision": 0.696969696969697,
            "recall": 0.711340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.6628966279242181,
            "auditor_fn_violation": 0.007432293420117463,
            "auditor_fp_violation": 0.01138073739653875,
            "ave_precision_score": 0.6641269883759022,
            "fpr": 0.20065789473684212,
            "logloss": 0.8400672818601466,
            "mae": 0.37605064737454136,
            "precision": 0.6666666666666666,
            "recall": 0.7803837953091685
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7123879392013218,
            "auditor_fn_violation": 0.01072572340353299,
            "auditor_fp_violation": 0.011881387115227042,
            "ave_precision_score": 0.7134242442345563,
            "fpr": 0.18111964873765093,
            "logloss": 0.7395218827238349,
            "mae": 0.3581091458808999,
            "precision": 0.6921641791044776,
            "recall": 0.7649484536082474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8211861981152198,
            "auditor_fn_violation": 0.00703718250851008,
            "auditor_fp_violation": 0.011482218525998972,
            "ave_precision_score": 0.8220670543990086,
            "fpr": 0.1600877192982456,
            "logloss": 0.535575014414512,
            "mae": 0.3319510290962889,
            "precision": 0.7286245353159851,
            "recall": 0.835820895522388
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8720999375424541,
            "auditor_fn_violation": 0.0032659250625233405,
            "auditor_fp_violation": 0.009600964734620675,
            "ave_precision_score": 0.8723278145467606,
            "fpr": 0.13830954994511527,
            "logloss": 0.48595126480009976,
            "mae": 0.3152233858794203,
            "precision": 0.7636022514071295,
            "recall": 0.8391752577319588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.5217901075880178,
            "auditor_fn_violation": 0.007441645157670306,
            "auditor_fp_violation": 0.01632608609560018,
            "ave_precision_score": 0.5230571150422658,
            "fpr": 0.1206140350877193,
            "logloss": 0.6975421926813162,
            "mae": 0.5007618721574545,
            "precision": 0.5299145299145299,
            "recall": 0.26439232409381663
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5841179576386488,
            "auditor_fn_violation": 0.005472631185849931,
            "auditor_fp_violation": 0.015244043845951676,
            "ave_precision_score": 0.5855917251653204,
            "fpr": 0.09549945115257959,
            "logloss": 0.6935948470137737,
            "mae": 0.4989022758148373,
            "precision": 0.6313559322033898,
            "recall": 0.30721649484536084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.5588098559564425,
            "auditor_fn_violation": 0.004855889724310777,
            "auditor_fp_violation": 0.013910340184547152,
            "ave_precision_score": 0.5602282539312831,
            "fpr": 0.33223684210526316,
            "logloss": 0.7190559444429766,
            "mae": 0.4749979053771025,
            "precision": 0.5702127659574469,
            "recall": 0.8571428571428571
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6095298954000447,
            "auditor_fn_violation": 0.007959985062297014,
            "auditor_fp_violation": 0.01614848255283624,
            "ave_precision_score": 0.6107108964462844,
            "fpr": 0.3260153677277717,
            "logloss": 0.6982397695528845,
            "mae": 0.4652541199807409,
            "precision": 0.5875,
            "recall": 0.8721649484536083
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7695611782862255,
            "auditor_fn_violation": 0.0031819287023529025,
            "auditor_fp_violation": 0.012724743574511903,
            "ave_precision_score": 0.7600393620719529,
            "fpr": 0.1074561403508772,
            "logloss": 0.576236667848302,
            "mae": 0.3486086444014396,
            "precision": 0.7752293577981652,
            "recall": 0.720682302771855
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.836203445166028,
            "auditor_fn_violation": 0.004802697839691295,
            "auditor_fp_violation": 0.006222847513180069,
            "ave_precision_score": 0.8183462347064323,
            "fpr": 0.08232711306256861,
            "logloss": 0.5045091085604432,
            "mae": 0.3302965852380723,
            "precision": 0.8271889400921659,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6704661198590744,
            "auditor_fn_violation": 0.05001075449818578,
            "auditor_fp_violation": 0.08567234960991645,
            "ave_precision_score": 0.5986012345258509,
            "fpr": 0.22587719298245615,
            "logloss": 0.6978995115142723,
            "mae": 0.4591705453369701,
            "precision": 0.5928853754940712,
            "recall": 0.6396588486140725
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6867660030067337,
            "auditor_fn_violation": 0.05793791800106375,
            "auditor_fp_violation": 0.08415145096705369,
            "ave_precision_score": 0.6161520434221975,
            "fpr": 0.22283205268935236,
            "logloss": 0.692275367734613,
            "mae": 0.4556147973048046,
            "precision": 0.6103646833013435,
            "recall": 0.6556701030927835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6259521310594902,
            "auditor_fn_violation": 0.00924185463659148,
            "auditor_fp_violation": 0.0251153419666548,
            "ave_precision_score": 0.5573877269893992,
            "fpr": 0.39364035087719296,
            "logloss": 3.3861360395968525,
            "mae": 0.4299366352099337,
            "precision": 0.5556930693069307,
            "recall": 0.9573560767590619
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6566861702235426,
            "auditor_fn_violation": 0.006488847646745959,
            "auditor_fp_violation": 0.016388120158933844,
            "ave_precision_score": 0.5946723690128488,
            "fpr": 0.3754116355653128,
            "logloss": 3.2301883580851842,
            "mae": 0.41088324734526066,
            "precision": 0.5767326732673267,
            "recall": 0.9608247422680413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7702051765885717,
            "auditor_fn_violation": 0.015332173717876785,
            "auditor_fp_violation": 0.028107797710981746,
            "ave_precision_score": 0.7703448395456908,
            "fpr": 0.14802631578947367,
            "logloss": 1.1462771841744046,
            "mae": 0.317541814740061,
            "precision": 0.7096774193548387,
            "recall": 0.7036247334754797
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7735047904293345,
            "auditor_fn_violation": 0.015467312458270625,
            "auditor_fp_violation": 0.014568935751354085,
            "ave_precision_score": 0.7731917410048507,
            "fpr": 0.14270032930845225,
            "logloss": 1.188538306887737,
            "mae": 0.3202829232928062,
            "precision": 0.7198275862068966,
            "recall": 0.688659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7972046619858634,
            "auditor_fn_violation": 0.01046225638723676,
            "auditor_fp_violation": 0.014078650350481172,
            "ave_precision_score": 0.7975477773409181,
            "fpr": 0.0712719298245614,
            "logloss": 0.8253462405221919,
            "mae": 0.335215493452327,
            "precision": 0.8012232415902141,
            "recall": 0.55863539445629
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8064703461745129,
            "auditor_fn_violation": 0.0036755802505460374,
            "auditor_fp_violation": 0.00410218353663879,
            "ave_precision_score": 0.8069070294349652,
            "fpr": 0.07135016465422613,
            "logloss": 0.8531494179189664,
            "mae": 0.33827823994963657,
            "precision": 0.8137535816618912,
            "recall": 0.5855670103092784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8303823378927305,
            "auditor_fn_violation": 0.004236337111435309,
            "auditor_fp_violation": 0.012328719654667144,
            "ave_precision_score": 0.7998135110268041,
            "fpr": 0.10855263157894737,
            "logloss": 0.5244530846986359,
            "mae": 0.33223589895325795,
            "precision": 0.7744874715261959,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8519592733545291,
            "auditor_fn_violation": 0.003947174850340064,
            "auditor_fp_violation": 0.006977834809810198,
            "ave_precision_score": 0.8245712827484548,
            "fpr": 0.0801317233809001,
            "logloss": 0.4846554224234773,
            "mae": 0.31554637886951836,
            "precision": 0.8310185185185185,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8225947504596237,
            "auditor_fn_violation": 0.00461274454793701,
            "auditor_fp_violation": 0.009289236069858622,
            "ave_precision_score": 0.7065730043500551,
            "fpr": 0.10307017543859649,
            "logloss": 0.5589526974283792,
            "mae": 0.3643162520929125,
            "precision": 0.7819025522041764,
            "recall": 0.7185501066098081
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8536994769794493,
            "auditor_fn_violation": 0.008412642728620414,
            "auditor_fp_violation": 0.006230577758538057,
            "ave_precision_score": 0.7521431489680516,
            "fpr": 0.07903402854006586,
            "logloss": 0.5248463267196101,
            "mae": 0.3492459025229895,
            "precision": 0.8317757009345794,
            "recall": 0.734020618556701
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7571271929824561,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5142543859649122,
            "fpr": 0.4857456140350877,
            "logloss": 0.6950918585137068,
            "mae": 0.4986189795952094,
            "precision": 0.5142543859649122,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7661909989023051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5323819978046103,
            "fpr": 0.4676180021953897,
            "logloss": 0.6915682588265326,
            "mae": 0.49686270598915094,
            "precision": 0.5323819978046103,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.8073462227960024,
            "auditor_fn_violation": 0.005816780757864811,
            "auditor_fp_violation": 0.014779117658706582,
            "ave_precision_score": 0.8087977128194382,
            "fpr": 0.3125,
            "logloss": 0.746628879189872,
            "mae": 0.35362355005991425,
            "precision": 0.611716621253406,
            "recall": 0.9573560767590619
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8346016023934645,
            "auditor_fn_violation": 0.0038679597587334635,
            "auditor_fp_violation": 0.009776183629401743,
            "ave_precision_score": 0.8358780036429835,
            "fpr": 0.29857299670691545,
            "logloss": 0.7091030587879104,
            "mae": 0.33707395003666735,
            "precision": 0.6299319727891156,
            "recall": 0.954639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6963071518254271,
            "auditor_fn_violation": 0.03741162608012569,
            "auditor_fp_violation": 0.034132311591620126,
            "ave_precision_score": 0.613292138255551,
            "fpr": 0.27960526315789475,
            "logloss": 1.1243404728986703,
            "mae": 0.4420104394893736,
            "precision": 0.5735785953177257,
            "recall": 0.7313432835820896
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.7489732918926693,
            "auditor_fn_violation": 0.03156155578439916,
            "auditor_fp_violation": 0.04763634864437265,
            "ave_precision_score": 0.6651877041280023,
            "fpr": 0.2491767288693743,
            "logloss": 1.0716935578939957,
            "mae": 0.42175679162921664,
            "precision": 0.6152542372881356,
            "recall": 0.7484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.7952226545919714,
            "auditor_fn_violation": 0.0030603561141660123,
            "auditor_fp_violation": 0.0062448021860520555,
            "ave_precision_score": 0.7956657357547218,
            "fpr": 0.4473684210526316,
            "logloss": 0.8423890084260118,
            "mae": 0.42611417151464703,
            "precision": 0.5310344827586206,
            "recall": 0.9850746268656716
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.8258431178621907,
            "auditor_fn_violation": 0.0025009336064367926,
            "auditor_fp_violation": 0.011162474296934195,
            "ave_precision_score": 0.8261519904757608,
            "fpr": 0.4281009879253567,
            "logloss": 0.8025594533640706,
            "mae": 0.4118410780224397,
            "precision": 0.5512082853855006,
            "recall": 0.9876288659793815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8331967374091123,
            "auditor_fn_violation": 0.009931545281113233,
            "auditor_fp_violation": 0.005767098332739305,
            "ave_precision_score": 0.8224542857234289,
            "fpr": 0.13157894736842105,
            "logloss": 0.5229384061484846,
            "mae": 0.3302214778959751,
            "precision": 0.7515527950310559,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.8764054349841571,
            "auditor_fn_violation": 0.009245532834655476,
            "auditor_fp_violation": 0.005939405183387192,
            "ave_precision_score": 0.8678072944020077,
            "fpr": 0.09769484083424808,
            "logloss": 0.46706461666629,
            "mae": 0.3053209301570899,
            "precision": 0.8122362869198312,
            "recall": 0.7938144329896907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.79779229714856,
            "auditor_fn_violation": 0.004584689335278496,
            "auditor_fp_violation": 0.0005890855807690858,
            "ave_precision_score": 0.7984327740076975,
            "fpr": 0.1875,
            "logloss": 0.5442247349073571,
            "mae": 0.37006359083757717,
            "precision": 0.7041522491349481,
            "recall": 0.8678038379530917
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8355288525014379,
            "auditor_fn_violation": 0.006407369266807745,
            "auditor_fp_violation": 0.005457553222739289,
            "ave_precision_score": 0.8358857800667985,
            "fpr": 0.1712403951701427,
            "logloss": 0.5264581139974569,
            "mae": 0.3601857962170626,
            "precision": 0.7286956521739131,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.811571943865742,
            "auditor_fn_violation": 0.01604524370628064,
            "auditor_fp_violation": 0.0010321373410954022,
            "ave_precision_score": 0.7930958725161182,
            "fpr": 0.0043859649122807015,
            "logloss": 0.689884017176202,
            "mae": 0.4666152391909507,
            "precision": 0.9428571428571428,
            "recall": 0.14072494669509594
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.8354710719117798,
            "auditor_fn_violation": 0.022972376565912618,
            "auditor_fp_violation": 0.0012935277232366024,
            "ave_precision_score": 0.817457336804033,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6961126334952461,
            "mae": 0.4700298026024183,
            "precision": 0.9420289855072463,
            "recall": 0.13402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7811237851617815,
            "auditor_fn_violation": 0.004236337111435309,
            "auditor_fp_violation": 0.012328719654667144,
            "ave_precision_score": 0.8177461926265687,
            "fpr": 0.10855263157894737,
            "logloss": 0.5249866238444932,
            "mae": 0.3502085971270214,
            "precision": 0.7744874715261959,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.863449265915323,
            "auditor_fn_violation": 0.003947174850340064,
            "auditor_fp_violation": 0.006977834809810198,
            "ave_precision_score": 0.8376035466808143,
            "fpr": 0.0801317233809001,
            "logloss": 0.48965541925745654,
            "mae": 0.33253809009830987,
            "precision": 0.8310185185185185,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7382136333775783,
            "auditor_fn_violation": 0.01052304268133019,
            "auditor_fp_violation": 0.0212046057581878,
            "ave_precision_score": 0.7347593481944108,
            "fpr": 0.1611842105263158,
            "logloss": 1.324583576343074,
            "mae": 0.2978025410631475,
            "precision": 0.7054108216432866,
            "recall": 0.7505330490405118
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.736615347484443,
            "auditor_fn_violation": 0.005115031629454434,
            "auditor_fp_violation": 0.016099524332235642,
            "ave_precision_score": 0.7359394913664618,
            "fpr": 0.15587266739846323,
            "logloss": 1.2891091061215885,
            "mae": 0.2942440138664747,
            "precision": 0.7279693486590039,
            "recall": 0.7835051546391752
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6003197226628871,
            "auditor_fn_violation": 0.012779149365952211,
            "auditor_fp_violation": 0.02298176309849116,
            "ave_precision_score": 0.5992675339093889,
            "fpr": 0.1513157894736842,
            "logloss": 7.3352786134727275,
            "mae": 0.4521669350563257,
            "precision": 0.5892857142857143,
            "recall": 0.42217484008528783
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6134058569270654,
            "auditor_fn_violation": 0.011773625901071684,
            "auditor_fp_violation": 0.013986590601052349,
            "ave_precision_score": 0.6125926949461317,
            "fpr": 0.1525795828759605,
            "logloss": 7.621912463243971,
            "mae": 0.45421453761800795,
            "precision": 0.611731843575419,
            "recall": 0.4515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7495200911898925,
            "auditor_fn_violation": 0.010700725694834103,
            "auditor_fp_violation": 0.03348382242287436,
            "ave_precision_score": 0.61441442855001,
            "fpr": 0.32785087719298245,
            "logloss": 0.6442078118478671,
            "mae": 0.4500663927511165,
            "precision": 0.5835654596100278,
            "recall": 0.8933901918976546
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7664531636190499,
            "auditor_fn_violation": 0.012217230414068601,
            "auditor_fp_violation": 0.02325773153373224,
            "ave_precision_score": 0.642935103756626,
            "fpr": 0.31833150384193193,
            "logloss": 0.6333636594738118,
            "mae": 0.4453844627862312,
            "precision": 0.6016483516483516,
            "recall": 0.9030927835051547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.5602343077843863,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5153513447798601,
            "fpr": 0.4857456140350877,
            "logloss": 0.6931205363760808,
            "mae": 0.499165142053052,
            "precision": 0.5142543859649122,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7666730793169395,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5333461586338791,
            "fpr": 0.4676180021953897,
            "logloss": 0.6915164007225527,
            "mae": 0.49900448400809394,
            "precision": 0.5323819978046103,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7571271929824561,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5142543859649122,
            "fpr": 0.4857456140350877,
            "logloss": 0.6929110058973328,
            "mae": 0.4993308112025261,
            "precision": 0.5142543859649122,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7661909989023051,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5323819978046103,
            "fpr": 0.4676180021953897,
            "logloss": 0.6912077100191266,
            "mae": 0.49847978929264225,
            "precision": 0.5323819978046103,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8350757402252542,
            "auditor_fn_violation": 0.00240807241985561,
            "auditor_fp_violation": 0.012754445368500263,
            "ave_precision_score": 0.8225248240135676,
            "fpr": 0.10197368421052631,
            "logloss": 2.5608059479561542,
            "mae": 0.2544616964191047,
            "precision": 0.7811764705882352,
            "recall": 0.7078891257995735
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8681064851366391,
            "auditor_fn_violation": 0.013059173673430131,
            "auditor_fp_violation": 0.009799374365475693,
            "ave_precision_score": 0.8585031824489884,
            "fpr": 0.07354555433589462,
            "logloss": 2.32511940268709,
            "mae": 0.22498886244035426,
            "precision": 0.8389423076923077,
            "recall": 0.7195876288659794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.6432383302291158,
            "auditor_fn_violation": 0.011472244042943183,
            "auditor_fp_violation": 0.029580511662904443,
            "ave_precision_score": 0.654441839910245,
            "fpr": 0.17105263157894737,
            "logloss": 0.6154852617291175,
            "mae": 0.42850152950472475,
            "precision": 0.6829268292682927,
            "recall": 0.7164179104477612
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6570299353117933,
            "auditor_fn_violation": 0.015050867405253097,
            "auditor_fp_violation": 0.01969666517215257,
            "ave_precision_score": 0.6810630513877102,
            "fpr": 0.16465422612513722,
            "logloss": 0.6114514730790174,
            "mae": 0.42747937504337075,
            "precision": 0.696969696969697,
            "recall": 0.711340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.829347684488314,
            "auditor_fn_violation": 0.009950248756218914,
            "auditor_fp_violation": 0.02959536255989862,
            "ave_precision_score": 0.8297229105696943,
            "fpr": 0.15899122807017543,
            "logloss": 0.5438620537469341,
            "mae": 0.3388241175020914,
            "precision": 0.7189922480620154,
            "recall": 0.7910447761194029
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.825051771007136,
            "auditor_fn_violation": 0.0076476512725338645,
            "auditor_fp_violation": 0.015256927588214985,
            "ave_precision_score": 0.8253764181588747,
            "fpr": 0.1525795828759605,
            "logloss": 0.5444871931925528,
            "mae": 0.3391274981513521,
            "precision": 0.7326923076923076,
            "recall": 0.7855670103092783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8206197342550487,
            "auditor_fn_violation": 0.003941757378520925,
            "auditor_fp_violation": 0.011932695734822385,
            "ave_precision_score": 0.7820397687541956,
            "fpr": 0.10964912280701754,
            "logloss": 0.5373756719135282,
            "mae": 0.34359282313176154,
            "precision": 0.7732426303854876,
            "recall": 0.7270788912579957
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8540659229552086,
            "auditor_fn_violation": 0.003947174850340064,
            "auditor_fp_violation": 0.010879031967141304,
            "ave_precision_score": 0.8192844917305513,
            "fpr": 0.08122941822173436,
            "logloss": 0.4978922778775608,
            "mae": 0.32408702734992745,
            "precision": 0.8290993071593533,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.782747185077256,
            "auditor_fn_violation": 0.06228023416750833,
            "auditor_fp_violation": 0.03207546235792642,
            "ave_precision_score": 0.7818376988812714,
            "fpr": 0.13267543859649122,
            "logloss": 3.6824841890713813,
            "mae": 0.34279779393200016,
            "precision": 0.7218390804597701,
            "recall": 0.6695095948827292
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8013548328690393,
            "auditor_fn_violation": 0.06991071327531773,
            "auditor_fp_violation": 0.03300557093015466,
            "ave_precision_score": 0.7993853893546681,
            "fpr": 0.11086717892425905,
            "logloss": 3.7663203485444443,
            "mae": 0.3259865099817179,
            "precision": 0.7662037037037037,
            "recall": 0.6824742268041237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8447648335595505,
            "auditor_fn_violation": 0.006359181535929376,
            "auditor_fp_violation": 0.024313393528969156,
            "ave_precision_score": 0.8450892894671094,
            "fpr": 0.3168859649122807,
            "logloss": 0.6898812792834222,
            "mae": 0.3601800600197493,
            "precision": 0.6068027210884354,
            "recall": 0.9509594882729211
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.8723061472128355,
            "auditor_fn_violation": 0.0013194970973327144,
            "auditor_fp_violation": 0.023391722453270678,
            "ave_precision_score": 0.8725469445833387,
            "fpr": 0.3029637760702525,
            "logloss": 0.6300229908372162,
            "mae": 0.34314786509480877,
            "precision": 0.6265223274695535,
            "recall": 0.954639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7686325303976237,
            "auditor_fn_violation": 0.01653153405902817,
            "auditor_fp_violation": 0.023828264227159338,
            "ave_precision_score": 0.7585364787436616,
            "fpr": 0.20175438596491227,
            "logloss": 0.5784622823791511,
            "mae": 0.36328542537235636,
            "precision": 0.68,
            "recall": 0.8336886993603412
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7807894011271097,
            "auditor_fn_violation": 0.010101055824006703,
            "auditor_fp_violation": 0.01190457785130101,
            "ave_precision_score": 0.775634429860202,
            "fpr": 0.18990120746432493,
            "logloss": 0.5566928703135038,
            "mae": 0.3516908581445908,
            "precision": 0.7067796610169491,
            "recall": 0.8597938144329897
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8059048196494474,
            "auditor_fn_violation": 0.002683948677664307,
            "auditor_fp_violation": 0.006425488099481213,
            "ave_precision_score": 0.8040022960526515,
            "fpr": 0.12609649122807018,
            "logloss": 0.5225776538314195,
            "mae": 0.3365573866064088,
            "precision": 0.7553191489361702,
            "recall": 0.7569296375266524
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8614900012488871,
            "auditor_fn_violation": 0.004802697839691292,
            "auditor_fp_violation": 0.00844142793092253,
            "ave_precision_score": 0.8500814649538599,
            "fpr": 0.10757409440175632,
            "logloss": 0.47772844346646615,
            "mae": 0.31801535061567726,
            "precision": 0.7941176470588235,
            "recall": 0.7793814432989691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.726317151403496,
            "mae": 0.5149759564127923,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.4884085530923434,
            "auditor_fn_violation": 0.0013715527289599014,
            "auditor_fp_violation": 0.0005591544142277742,
            "ave_precision_score": 0.5328594887734611,
            "fpr": 0.0010976948408342481,
            "logloss": 18.24282050239899,
            "mae": 0.5317296853327856,
            "precision": 0.75,
            "recall": 0.006185567010309278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6817266269485218,
            "auditor_fn_violation": 0.01690326562675346,
            "auditor_fp_violation": 0.05001287077739497,
            "ave_precision_score": 0.6612116807515547,
            "fpr": 0.16776315789473684,
            "logloss": 0.6447985429419418,
            "mae": 0.390245460137202,
            "precision": 0.697029702970297,
            "recall": 0.7505330490405118
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6993457677395513,
            "auditor_fn_violation": 0.013120282458383791,
            "auditor_fp_violation": 0.05671423344310282,
            "ave_precision_score": 0.6776284274568163,
            "fpr": 0.16245883644346873,
            "logloss": 0.6694115825348734,
            "mae": 0.3834180063409003,
            "precision": 0.7159309021113244,
            "recall": 0.7690721649484537
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7583274641920931,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5176917702061256,
            "fpr": 0.4857456140350877,
            "logloss": 16.553333748715524,
            "mae": 0.4857138497264762,
            "precision": 0.5142543859649122,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7676600441501104,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5353200883002207,
            "fpr": 0.4676180021953897,
            "logloss": 15.991080019993687,
            "mae": 0.4675864358110564,
            "precision": 0.5323819978046103,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7491992370767677,
            "auditor_fn_violation": 0.015245670145513042,
            "auditor_fp_violation": 0.029850302958298686,
            "ave_precision_score": 0.7497479003505466,
            "fpr": 0.1524122807017544,
            "logloss": 0.8654290689671064,
            "mae": 0.35156213840175615,
            "precision": 0.7017167381974249,
            "recall": 0.697228144989339
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.745319275063023,
            "auditor_fn_violation": 0.01688639424219449,
            "auditor_fp_violation": 0.018591240085960335,
            "ave_precision_score": 0.7460069924117064,
            "fpr": 0.14818880351262348,
            "logloss": 0.8631015941393758,
            "mae": 0.354491342542004,
            "precision": 0.7109207708779444,
            "recall": 0.6845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6293751747847022,
            "auditor_fn_violation": 0.07489105225750944,
            "auditor_fp_violation": 0.08855837392578512,
            "ave_precision_score": 0.6143303850910883,
            "fpr": 0.2631578947368421,
            "logloss": 0.7110293657566749,
            "mae": 0.4426576674981947,
            "precision": 0.6,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6804157765431397,
            "auditor_fn_violation": 0.08041237113402062,
            "auditor_fp_violation": 0.08760687064207417,
            "ave_precision_score": 0.6598093956172408,
            "fpr": 0.24698133918770582,
            "logloss": 0.6710179141410283,
            "mae": 0.43164416918639426,
            "precision": 0.6231155778894473,
            "recall": 0.7670103092783506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.6876779337268448,
            "auditor_fn_violation": 0.007532824598810461,
            "auditor_fp_violation": 0.004730010692645836,
            "ave_precision_score": 0.6887163919981202,
            "fpr": 0.01644736842105263,
            "logloss": 1.3301953204383425,
            "mae": 0.4730774785271567,
            "precision": 0.5945945945945946,
            "recall": 0.046908315565031986
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0.7062159084244919,
            "auditor_fn_violation": 0.002213495988321448,
            "auditor_fp_violation": 0.00451961678597012,
            "ave_precision_score": 0.7078067005498643,
            "fpr": 0.010976948408342482,
            "logloss": 1.3587720913824202,
            "mae": 0.48746904314541756,
            "precision": 0.6428571428571429,
            "recall": 0.03711340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8213632563396065,
            "auditor_fn_violation": 0.015208263195301691,
            "auditor_fp_violation": 0.026791018177497926,
            "ave_precision_score": 0.8217567010728668,
            "fpr": 0.15679824561403508,
            "logloss": 0.7951496080738717,
            "mae": 0.2797832090305789,
            "precision": 0.7157057654075547,
            "recall": 0.767590618336887
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.828107150695631,
            "auditor_fn_violation": 0.0008147837993821277,
            "auditor_fp_violation": 0.01834387223450473,
            "ave_precision_score": 0.8284238237870142,
            "fpr": 0.141602634467618,
            "logloss": 0.8062919568369862,
            "mae": 0.27193882249730705,
            "precision": 0.7495145631067961,
            "recall": 0.7958762886597938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7800940872118556,
            "auditor_fn_violation": 0.031585493584708045,
            "auditor_fp_violation": 0.023830739376658354,
            "ave_precision_score": 0.7285626115727126,
            "fpr": 0.13267543859649122,
            "logloss": 0.6399915374246706,
            "mae": 0.42611828792774886,
            "precision": 0.717948717948718,
            "recall": 0.6567164179104478
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.809240202776042,
            "auditor_fn_violation": 0.03326581189810676,
            "auditor_fp_violation": 0.017702261869791746,
            "ave_precision_score": 0.760996313921048,
            "fpr": 0.10537870472008781,
            "logloss": 0.6277099257896404,
            "mae": 0.4187608136336445,
            "precision": 0.7697841726618705,
            "recall": 0.6618556701030928
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 29198,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8335743250352973,
            "auditor_fn_violation": 0.023608461452137814,
            "auditor_fp_violation": 0.030582947210011483,
            "ave_precision_score": 0.8078890666316599,
            "fpr": 0.17982456140350878,
            "logloss": 0.5294495613113263,
            "mae": 0.3562555648304783,
            "precision": 0.7028985507246377,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.849988109437789,
            "auditor_fn_violation": 0.02300632589088687,
            "auditor_fp_violation": 0.03126111222770211,
            "ave_precision_score": 0.8285600271518339,
            "fpr": 0.15806805708013172,
            "logloss": 0.5140013435420697,
            "mae": 0.3475882730453912,
            "precision": 0.7377049180327869,
            "recall": 0.8350515463917526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7211076540644973,
            "auditor_fn_violation": 0.00798404593573487,
            "auditor_fp_violation": 0.014573680250287123,
            "ave_precision_score": 0.7011393138180261,
            "fpr": 0.11293859649122807,
            "logloss": 0.6081599863148573,
            "mae": 0.41157039121741,
            "precision": 0.7412060301507538,
            "recall": 0.6289978678038379
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7732023954637574,
            "auditor_fn_violation": 0.014163658379259224,
            "auditor_fp_violation": 0.004779868379689039,
            "ave_precision_score": 0.7511070566049942,
            "fpr": 0.09989023051591657,
            "logloss": 0.5843311626529467,
            "mae": 0.40177107276855,
            "precision": 0.7780487804878049,
            "recall": 0.6577319587628866
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.536654014209795,
            "auditor_fn_violation": 0.06384197433883215,
            "auditor_fp_violation": 0.07449457447229813,
            "ave_precision_score": 0.5437150907785383,
            "fpr": 0.1611842105263158,
            "logloss": 0.6921901670555896,
            "mae": 0.4894135852850843,
            "precision": 0.5434782608695652,
            "recall": 0.373134328358209
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.5642539889913518,
            "auditor_fn_violation": 0.055878325619292284,
            "auditor_fp_violation": 0.06106893832810254,
            "ave_precision_score": 0.5678908909417865,
            "fpr": 0.15148188803512624,
            "logloss": 0.6961739246628,
            "mae": 0.49302631510272377,
            "precision": 0.5740740740740741,
            "recall": 0.3835051546391753
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7944570530815159,
            "auditor_fn_violation": 0.005187876407436502,
            "auditor_fp_violation": 0.018689853867173582,
            "ave_precision_score": 0.7818404111128019,
            "fpr": 0.15899122807017543,
            "logloss": 0.5410488442850819,
            "mae": 0.33651640907485497,
            "precision": 0.7289719626168224,
            "recall": 0.8315565031982942
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8106814338154533,
            "auditor_fn_violation": 0.0029377482544388754,
            "auditor_fp_violation": 0.012409620548022863,
            "ave_precision_score": 0.7990430038780936,
            "fpr": 0.145993413830955,
            "logloss": 0.5077479027328468,
            "mae": 0.3226524688969632,
            "precision": 0.7564102564102564,
            "recall": 0.8515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 29198,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.5513987593763442,
            "auditor_fn_violation": 0.024206972655519392,
            "auditor_fp_violation": 0.020330877985030298,
            "ave_precision_score": 0.5483406695272964,
            "fpr": 0.07346491228070176,
            "logloss": 0.685722945519654,
            "mae": 0.4819783630286621,
            "precision": 0.5379310344827586,
            "recall": 0.16631130063965885
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5911594319048145,
            "auditor_fn_violation": 0.028646440413276464,
            "auditor_fp_violation": 0.024816664347593057,
            "ave_precision_score": 0.5756930671277901,
            "fpr": 0.06476399560922064,
            "logloss": 0.6802317416319583,
            "mae": 0.4817897281512356,
            "precision": 0.572463768115942,
            "recall": 0.16288659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7481930038519308,
            "auditor_fn_violation": 0.007528148730034042,
            "auditor_fp_violation": 0.011271830818581439,
            "ave_precision_score": 0.7352385727386044,
            "fpr": 0.10087719298245613,
            "logloss": 0.5913782781186477,
            "mae": 0.3941158055033731,
            "precision": 0.7616580310880829,
            "recall": 0.6268656716417911
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8033882787310599,
            "auditor_fn_violation": 0.003569205698960022,
            "auditor_fp_violation": 0.0003298238019408088,
            "ave_precision_score": 0.786413491075228,
            "fpr": 0.07025246981339188,
            "logloss": 0.5571213706435664,
            "mae": 0.37865666233812806,
            "precision": 0.8315789473684211,
            "recall": 0.6515463917525773
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7747125812589986,
            "auditor_fn_violation": 0.004236337111435309,
            "auditor_fp_violation": 0.012328719654667144,
            "ave_precision_score": 0.7582166158624202,
            "fpr": 0.10855263157894737,
            "logloss": 0.5646624242000019,
            "mae": 0.357281164396881,
            "precision": 0.7744874715261959,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8276092175512982,
            "auditor_fn_violation": 0.003947174850340064,
            "auditor_fp_violation": 0.006977834809810198,
            "ave_precision_score": 0.8138635626319044,
            "fpr": 0.0801317233809001,
            "logloss": 0.5118993234256671,
            "mae": 0.3362032515124615,
            "precision": 0.8310185185185185,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8085552804574313,
            "auditor_fn_violation": 0.00522294542325964,
            "auditor_fp_violation": 0.010781751217773557,
            "ave_precision_score": 0.7787172323263037,
            "fpr": 0.10307017543859649,
            "logloss": 0.5442505790975338,
            "mae": 0.33762505931550996,
            "precision": 0.783410138248848,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8490243720595919,
            "auditor_fn_violation": 0.0038611698937386168,
            "auditor_fp_violation": 0.002288152625964352,
            "ave_precision_score": 0.8226746763019701,
            "fpr": 0.08232711306256861,
            "logloss": 0.5034087694792838,
            "mae": 0.3170179935697667,
            "precision": 0.8271889400921659,
            "recall": 0.7402061855670103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.5898871834890989,
            "auditor_fn_violation": 0.03125116896719411,
            "auditor_fp_violation": 0.043176507861074805,
            "ave_precision_score": 0.5739602178864855,
            "fpr": 0.38048245614035087,
            "logloss": 0.8246324058046227,
            "mae": 0.46767169820438875,
            "precision": 0.54521625163827,
            "recall": 0.8869936034115139
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6249141028968641,
            "auditor_fn_violation": 0.0359862844727104,
            "auditor_fp_violation": 0.04865416428317436,
            "ave_precision_score": 0.6095416094888735,
            "fpr": 0.35016465422612514,
            "logloss": 0.774248910208148,
            "mae": 0.4548076935742218,
            "precision": 0.5729585006693441,
            "recall": 0.8824742268041237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 29198,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7078338092063945,
            "auditor_fn_violation": 0.009922193543560396,
            "auditor_fp_violation": 0.007920478396895173,
            "ave_precision_score": 0.6624796080917166,
            "fpr": 0.03837719298245614,
            "logloss": 0.6834860684771155,
            "mae": 0.41863167943155166,
            "precision": 0.8364485981308412,
            "recall": 0.3816631130063966
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7202986666191806,
            "auditor_fn_violation": 0.004764221938053802,
            "auditor_fp_violation": 0.004179485990218663,
            "ave_precision_score": 0.674757427050173,
            "fpr": 0.03732162458836443,
            "logloss": 0.6986861482604834,
            "mae": 0.4251471616012892,
            "precision": 0.8482142857142857,
            "recall": 0.3917525773195876
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8243963101680688,
            "auditor_fn_violation": 0.02207243855908428,
            "auditor_fp_violation": 0.010118411152033584,
            "ave_precision_score": 0.8247667650944582,
            "fpr": 0.18859649122807018,
            "logloss": 1.1891586515704042,
            "mae": 0.3395200321814282,
            "precision": 0.6928571428571428,
            "recall": 0.8272921108742004
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.845174580965161,
            "auditor_fn_violation": 0.017818869034820693,
            "auditor_fp_violation": 0.01190715459975367,
            "ave_precision_score": 0.8452556817548849,
            "fpr": 0.17672886937431395,
            "logloss": 1.3762449712474467,
            "mae": 0.33094493584342294,
            "precision": 0.7165492957746479,
            "recall": 0.8391752577319588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7284118567921584,
            "auditor_fn_violation": 0.030673699173306406,
            "auditor_fp_violation": 0.06122282285850067,
            "ave_precision_score": 0.7136100244497371,
            "fpr": 0.3925438596491228,
            "logloss": 1.3962759740014217,
            "mae": 0.43084657585999947,
            "precision": 0.5451080050825922,
            "recall": 0.9147121535181236
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7256325875222349,
            "auditor_fn_violation": 0.034119071599126374,
            "auditor_fp_violation": 0.06880949067990084,
            "ave_precision_score": 0.7089551692380676,
            "fpr": 0.3512623490669594,
            "logloss": 1.4741616323716185,
            "mae": 0.42607880168636336,
            "precision": 0.5789473684210527,
            "recall": 0.9072164948453608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6388835039389211,
            "auditor_fn_violation": 0.01575066397336626,
            "auditor_fp_violation": 0.02922161498554513,
            "ave_precision_score": 0.6264395870785876,
            "fpr": 0.11074561403508772,
            "logloss": 0.7126188801587313,
            "mae": 0.4574512578710391,
            "precision": 0.6622073578595318,
            "recall": 0.42217484008528783
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.6918944021564215,
            "auditor_fn_violation": 0.003643894213903376,
            "auditor_fp_violation": 0.01495029452234814,
            "ave_precision_score": 0.6757029117763214,
            "fpr": 0.09549945115257959,
            "logloss": 0.6866178148241647,
            "mae": 0.447102116128485,
            "precision": 0.7119205298013245,
            "recall": 0.44329896907216493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7156859666711258,
            "auditor_fn_violation": 0.011519002730707361,
            "auditor_fp_violation": 0.006460140192467627,
            "ave_precision_score": 0.7029001954908417,
            "fpr": 0.0625,
            "logloss": 1.5437663911773745,
            "mae": 0.41254089263377053,
            "precision": 0.7816091954022989,
            "recall": 0.4349680170575693
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7634243197592138,
            "auditor_fn_violation": 0.022506139169599534,
            "auditor_fp_violation": 0.008492962899975783,
            "ave_precision_score": 0.7502632286264984,
            "fpr": 0.06147091108671789,
            "logloss": 1.4808977269081969,
            "mae": 0.3924956056011924,
            "precision": 0.7956204379562044,
            "recall": 0.44948453608247424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.6716724846603082,
            "auditor_fn_violation": 0.016578292746792376,
            "auditor_fp_violation": 0.01046988238089581,
            "ave_precision_score": 0.6535993230668149,
            "fpr": 0.06030701754385965,
            "logloss": 6.842471900941575,
            "mae": 0.4057594606335324,
            "precision": 0.7566371681415929,
            "recall": 0.3646055437100213
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.6893718582450221,
            "auditor_fn_violation": 0.016524268109135785,
            "auditor_fp_violation": 0.005674000092762946,
            "ave_precision_score": 0.6763071510672316,
            "fpr": 0.0570801317233809,
            "logloss": 6.848374952927796,
            "mae": 0.413710056172955,
            "precision": 0.7688888888888888,
            "recall": 0.35670103092783506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8536445521592582,
            "auditor_fn_violation": 0.015598698238132654,
            "auditor_fp_violation": 0.011657954140430082,
            "ave_precision_score": 0.8538802765247032,
            "fpr": 0.08223684210526316,
            "logloss": 1.0850861201639235,
            "mae": 0.29127158117290375,
            "precision": 0.8129675810473815,
            "recall": 0.6950959488272921
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8650286276385828,
            "auditor_fn_violation": 0.014360564464109903,
            "auditor_fp_violation": 0.007573063702375246,
            "ave_precision_score": 0.8653604696948158,
            "fpr": 0.06476399560922064,
            "logloss": 1.2018323236504174,
            "mae": 0.2814709245177873,
            "precision": 0.855036855036855,
            "recall": 0.7175257731958763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7999005557865876,
            "auditor_fn_violation": 0.023341936931881944,
            "auditor_fp_violation": 0.00917785434240228,
            "ave_precision_score": 0.7645524261287866,
            "fpr": 0.08442982456140351,
            "logloss": 0.5924981163197982,
            "mae": 0.3379081751203589,
            "precision": 0.8005181347150259,
            "recall": 0.6588486140724946
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8324826428879442,
            "auditor_fn_violation": 0.004288931388414236,
            "auditor_fp_violation": 0.007619445174523178,
            "ave_precision_score": 0.801744193356558,
            "fpr": 0.06695938529088913,
            "logloss": 0.5539827688386265,
            "mae": 0.32028369323384226,
            "precision": 0.8443877551020408,
            "recall": 0.6824742268041237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.674102185461369,
            "auditor_fn_violation": 0.005669490891407624,
            "auditor_fp_violation": 0.01625678190962735,
            "ave_precision_score": 0.6550406985198218,
            "fpr": 0.1513157894736842,
            "logloss": 0.6256548132101833,
            "mae": 0.44036112688155027,
            "precision": 0.6658595641646489,
            "recall": 0.5863539445628998
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6654229325335946,
            "auditor_fn_violation": 0.022904477915964106,
            "auditor_fp_violation": 0.019392608854738393,
            "ave_precision_score": 0.6431922581608218,
            "fpr": 0.15587266739846323,
            "logloss": 0.6481307944885827,
            "mae": 0.4508358537987218,
            "precision": 0.6635071090047393,
            "recall": 0.5773195876288659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7295948633637969,
            "auditor_fn_violation": 0.015645456925896837,
            "auditor_fp_violation": 0.009313987564848922,
            "ave_precision_score": 0.6752110989965855,
            "fpr": 0.19407894736842105,
            "logloss": 0.6215872390866337,
            "mae": 0.43652129513129856,
            "precision": 0.6066666666666667,
            "recall": 0.582089552238806
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7411713886672039,
            "auditor_fn_violation": 0.015582740163183086,
            "auditor_fp_violation": 0.004756677643615086,
            "ave_precision_score": 0.6801638029730118,
            "fpr": 0.15587266739846323,
            "logloss": 0.6255431231458627,
            "mae": 0.4396161368989787,
            "precision": 0.6511056511056511,
            "recall": 0.5463917525773195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8005264994398453,
            "auditor_fn_violation": 0.006964706542475597,
            "auditor_fp_violation": 0.005267118133935288,
            "ave_precision_score": 0.800824515815352,
            "fpr": 0.09429824561403509,
            "logloss": 0.5396798009341961,
            "mae": 0.345861409725458,
            "precision": 0.7881773399014779,
            "recall": 0.6823027718550106
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8474083021274949,
            "auditor_fn_violation": 0.012502404743852346,
            "auditor_fp_violation": 0.007181397937570539,
            "ave_precision_score": 0.8472181854127709,
            "fpr": 0.06915477497255763,
            "logloss": 0.5033817550796678,
            "mae": 0.3295789337936793,
            "precision": 0.8448275862068966,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.610302025106569,
            "auditor_fn_violation": 0.008905192084689336,
            "auditor_fp_violation": 0.01668498277295949,
            "ave_precision_score": 0.6826536456150442,
            "fpr": 0.22807017543859648,
            "logloss": 0.5934713777956846,
            "mae": 0.40020235750432076,
            "precision": 0.6606851549755302,
            "recall": 0.8635394456289979
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.6929325265485256,
            "auditor_fn_violation": 0.005130874647775754,
            "auditor_fp_violation": 0.0118427358884371,
            "ave_precision_score": 0.747498609472425,
            "fpr": 0.18660812294182216,
            "logloss": 0.5642970985528749,
            "mae": 0.38282832007703876,
            "precision": 0.708904109589041,
            "recall": 0.8536082474226804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6277088005777248,
            "auditor_fn_violation": 0.01417255826132497,
            "auditor_fp_violation": 0.005234941190447905,
            "ave_precision_score": 0.6293392391907637,
            "fpr": 0.07236842105263158,
            "logloss": 0.7069465925628399,
            "mae": 0.4597536947480158,
            "precision": 0.6683417085427136,
            "recall": 0.2835820895522388
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6786233859196961,
            "auditor_fn_violation": 0.018454853056005097,
            "auditor_fp_violation": 0.007707054621913702,
            "ave_precision_score": 0.6801015328863683,
            "fpr": 0.05817782656421515,
            "logloss": 0.6854731292847281,
            "mae": 0.45339095270267304,
            "precision": 0.75,
            "recall": 0.32783505154639175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 29198,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8266364104018507,
            "auditor_fn_violation": 0.006319436651329821,
            "auditor_fp_violation": 0.0020494237851966255,
            "ave_precision_score": 0.7728054840821417,
            "fpr": 0.08662280701754387,
            "logloss": 0.5447303514316002,
            "mae": 0.36590912934850184,
            "precision": 0.8049382716049382,
            "recall": 0.6950959488272921
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8610730139115045,
            "auditor_fn_violation": 0.012022587617549542,
            "auditor_fp_violation": 0.007446803028194784,
            "ave_precision_score": 0.8049906977164459,
            "fpr": 0.06805708013172337,
            "logloss": 0.5130047322139114,
            "mae": 0.3514139274407166,
            "precision": 0.8469135802469135,
            "recall": 0.7072164948453609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5731110214882806,
            "auditor_fn_violation": 0.07186108929039016,
            "auditor_fp_violation": 0.08752623658468972,
            "ave_precision_score": 0.5751531493896641,
            "fpr": 0.32127192982456143,
            "logloss": 1.1849620981426912,
            "mae": 0.4710477463993224,
            "precision": 0.5540334855403348,
            "recall": 0.7761194029850746
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.5808141283265956,
            "auditor_fn_violation": 0.07041995314993153,
            "auditor_fp_violation": 0.09315718680910932,
            "ave_precision_score": 0.5822099020131867,
            "fpr": 0.27771679473106475,
            "logloss": 1.2721566534958595,
            "mae": 0.4627306180922942,
            "precision": 0.5964912280701754,
            "recall": 0.7711340206185567
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7781593286699335,
            "auditor_fn_violation": 0.0013466502076085783,
            "auditor_fp_violation": 0.011432715536018379,
            "ave_precision_score": 0.6412274467262684,
            "fpr": 0.16885964912280702,
            "logloss": 0.6195376842033752,
            "mae": 0.41934700130501334,
            "precision": 0.6888888888888889,
            "recall": 0.7270788912579957
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.803461638516397,
            "auditor_fn_violation": 0.010245906277230184,
            "auditor_fp_violation": 0.014038125570105591,
            "ave_precision_score": 0.6762115047011684,
            "fpr": 0.15148188803512624,
            "logloss": 0.5985273093327362,
            "mae": 0.4095202507747646,
            "precision": 0.7245508982035929,
            "recall": 0.7484536082474227
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7381458917541232,
            "auditor_fn_violation": 0.0005844835970523378,
            "auditor_fp_violation": 0.005905706704684968,
            "ave_precision_score": 0.7283779123940836,
            "fpr": 0.13157894736842105,
            "logloss": 0.6414653914281973,
            "mae": 0.4043196398568781,
            "precision": 0.7435897435897436,
            "recall": 0.7420042643923241
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7714017246799632,
            "auditor_fn_violation": 0.005545056412461677,
            "auditor_fp_violation": 0.0033317357492926867,
            "ave_precision_score": 0.7654126287556757,
            "fpr": 0.11086717892425905,
            "logloss": 0.6075312614263113,
            "mae": 0.3929896749858668,
            "precision": 0.7809110629067245,
            "recall": 0.7422680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4857456140350877,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.7617172469442,
            "mae": 0.5142543859649122,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.38782277884927,
            "mae": 0.5323819978046103,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6201620464646984,
            "auditor_fn_violation": 0.004163861145400816,
            "auditor_fp_violation": 0.002240010296621928,
            "ave_precision_score": 0.594344459913928,
            "fpr": 0.4440789473684211,
            "logloss": 0.6807070600216989,
            "mae": 0.46696070774857634,
            "precision": 0.5317919075144508,
            "recall": 0.9808102345415778
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6575641223990604,
            "auditor_fn_violation": 0.001023006325890887,
            "auditor_fp_violation": 0.0027777348319702358,
            "ave_precision_score": 0.6255115067694837,
            "fpr": 0.42371020856201974,
            "logloss": 0.6587544967397851,
            "mae": 0.4564215075458491,
            "precision": 0.553757225433526,
            "recall": 0.9876288659793815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8166073631741433,
            "auditor_fn_violation": 0.004304137208693378,
            "auditor_fp_violation": 0.012365846897152592,
            "ave_precision_score": 0.7675105798693442,
            "fpr": 0.08662280701754387,
            "logloss": 0.5422982991263178,
            "mae": 0.3656733852827497,
            "precision": 0.7921052631578948,
            "recall": 0.6417910447761194
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8266613728106535,
            "auditor_fn_violation": 0.005366256634263937,
            "auditor_fp_violation": 0.007879696768242092,
            "ave_precision_score": 0.7823071544937605,
            "fpr": 0.08122941822173436,
            "logloss": 0.549183375375583,
            "mae": 0.3666866511580842,
            "precision": 0.8052631578947368,
            "recall": 0.6309278350515464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.7243098294181397,
            "auditor_fn_violation": 0.016905603561141666,
            "auditor_fp_violation": 0.020603144429923573,
            "ave_precision_score": 0.72486921279038,
            "fpr": 0.2324561403508772,
            "logloss": 1.1751363229058152,
            "mae": 0.3916894682263542,
            "precision": 0.6081330868761553,
            "recall": 0.7014925373134329
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.747065321849093,
            "auditor_fn_violation": 0.022508402457931134,
            "auditor_fp_violation": 0.034041423808125,
            "ave_precision_score": 0.7477188993098451,
            "fpr": 0.20965971459934138,
            "logloss": 1.2372334291202487,
            "mae": 0.3665164803832051,
            "precision": 0.6533575317604355,
            "recall": 0.7422680412371134
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8507708626801582,
            "auditor_fn_violation": 0.028999738151348525,
            "auditor_fp_violation": 0.020375430676012836,
            "ave_precision_score": 0.8491128138072228,
            "fpr": 0.1118421052631579,
            "logloss": 0.495473591024914,
            "mae": 0.32816296148424345,
            "precision": 0.7811158798283262,
            "recall": 0.7761194029850746
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8661488683345508,
            "auditor_fn_violation": 0.01753369470503695,
            "auditor_fp_violation": 0.015517179181933903,
            "ave_precision_score": 0.8667540434609182,
            "fpr": 0.09110867178924259,
            "logloss": 0.46330695628201757,
            "mae": 0.3097829138154714,
            "precision": 0.8191721132897604,
            "recall": 0.7752577319587629
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5843391598104148,
            "auditor_fn_violation": 0.0027073280215464037,
            "auditor_fp_violation": 0.009348639657835358,
            "ave_precision_score": 0.5567450094283743,
            "fpr": 0.4440789473684211,
            "logloss": 0.6913130391294364,
            "mae": 0.4988122952350399,
            "precision": 0.5323325635103926,
            "recall": 0.9829424307036247
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5991501643976623,
            "auditor_fn_violation": 0.0014982968755304586,
            "auditor_fp_violation": 0.003339465994650672,
            "ave_precision_score": 0.5720200021613664,
            "fpr": 0.44127332601536773,
            "logloss": 0.6904696583745555,
            "mae": 0.49839347015358876,
            "precision": 0.5457627118644067,
            "recall": 0.9958762886597938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.771183912600832,
            "auditor_fn_violation": 0.0137330265963416,
            "auditor_fp_violation": 0.02482327432576928,
            "ave_precision_score": 0.6816697885837526,
            "fpr": 0.19736842105263158,
            "logloss": 7.626422812683166,
            "mae": 0.32498215573212275,
            "precision": 0.6635514018691588,
            "recall": 0.7569296375266524
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7791132778057105,
            "auditor_fn_violation": 0.01532925187004199,
            "auditor_fp_violation": 0.02005740995552533,
            "ave_precision_score": 0.6941734557964753,
            "fpr": 0.18221734357848518,
            "logloss": 7.244683139222915,
            "mae": 0.31129772145809054,
            "precision": 0.6914498141263941,
            "recall": 0.7670103092783506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6021561912398393,
            "auditor_fn_violation": 0.00858021920472826,
            "auditor_fp_violation": 0.013702427626628648,
            "ave_precision_score": 0.5847709319456417,
            "fpr": 0.09649122807017543,
            "logloss": 0.6923554971093258,
            "mae": 0.47248155155562255,
            "precision": 0.6053811659192825,
            "recall": 0.2878464818763326
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6489517239145829,
            "auditor_fn_violation": 0.01664195910237985,
            "auditor_fp_violation": 0.004359858381905042,
            "ave_precision_score": 0.6204008582841372,
            "fpr": 0.07574094401756312,
            "logloss": 0.693101099051904,
            "mae": 0.4719169356673138,
            "precision": 0.6805555555555556,
            "recall": 0.3030927835051546
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.6184192296967238,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5363449230790158,
            "fpr": 0.4857456140350877,
            "logloss": 0.6907134776073502,
            "mae": 0.4911906039505674,
            "precision": 0.5142543859649122,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.6569048842586572,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5641818583650648,
            "fpr": 0.4676180021953897,
            "logloss": 0.6823864257096355,
            "mae": 0.4868649665662931,
            "precision": 0.5323819978046103,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8105843871792957,
            "auditor_fn_violation": 0.0020573822616242157,
            "auditor_fp_violation": 0.006306680923527783,
            "ave_precision_score": 0.8021404217243047,
            "fpr": 0.11403508771929824,
            "logloss": 0.5385479010890303,
            "mae": 0.35099765730678645,
            "precision": 0.7688888888888888,
            "recall": 0.7377398720682303
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8520880667763053,
            "auditor_fn_violation": 0.010481288263718363,
            "auditor_fp_violation": 0.0032003215782068924,
            "ave_precision_score": 0.8424580032248521,
            "fpr": 0.0889132821075741,
            "logloss": 0.49890732999255594,
            "mae": 0.3329854626597021,
            "precision": 0.8167420814479638,
            "recall": 0.7443298969072165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7033649405719488,
            "auditor_fn_violation": 0.004589365204054914,
            "auditor_fp_violation": 0.023768860639182605,
            "ave_precision_score": 0.7071779440941719,
            "fpr": 0.2138157894736842,
            "logloss": 0.6799214125629571,
            "mae": 0.3684676636808128,
            "precision": 0.666095890410959,
            "recall": 0.8294243070362474
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7787593580464277,
            "auditor_fn_violation": 0.003861169893738618,
            "auditor_fp_violation": 0.00980968135928635,
            "ave_precision_score": 0.7622515392467859,
            "fpr": 0.2074643249176729,
            "logloss": 0.6018160276348365,
            "mae": 0.3531289902300002,
            "precision": 0.676923076923077,
            "recall": 0.8164948453608247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6879174287570955,
            "auditor_fn_violation": 0.00428777166797592,
            "auditor_fp_violation": 0.0034949110926299964,
            "ave_precision_score": 0.6910310389522545,
            "fpr": 0.03618421052631579,
            "logloss": 0.9443111688015899,
            "mae": 0.44345263986268263,
            "precision": 0.7480916030534351,
            "recall": 0.208955223880597
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7656774988322601,
            "auditor_fn_violation": 0.019536704878518003,
            "auditor_fp_violation": 0.0018552588859170394,
            "ave_precision_score": 0.764617163971946,
            "fpr": 0.021953896816684963,
            "logloss": 0.9275424465932753,
            "mae": 0.43450382381522235,
            "precision": 0.8561151079136691,
            "recall": 0.24536082474226803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8233066936328909,
            "auditor_fn_violation": 0.008154715146074142,
            "auditor_fp_violation": 0.009960001584095681,
            "ave_precision_score": 0.7806787016087741,
            "fpr": 0.13925438596491227,
            "logloss": 0.5327928598500512,
            "mae": 0.33878221734541286,
            "precision": 0.741869918699187,
            "recall": 0.7782515991471215
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8419335625365005,
            "auditor_fn_violation": 0.007009403963017873,
            "auditor_fp_violation": 0.011780893925573204,
            "ave_precision_score": 0.8019730190239633,
            "fpr": 0.1163556531284303,
            "logloss": 0.508425863897557,
            "mae": 0.3267740954764588,
            "precision": 0.7823408624229979,
            "recall": 0.7855670103092783
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5967860024305545,
            "auditor_fn_violation": 0.011229098866569408,
            "auditor_fp_violation": 0.015365728089976636,
            "ave_precision_score": 0.5331345118533263,
            "fpr": 0.4331140350877193,
            "logloss": 0.708786152115108,
            "mae": 0.4894360766599053,
            "precision": 0.5286396181384249,
            "recall": 0.9445628997867804
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6503742095919696,
            "auditor_fn_violation": 0.0131089660167257,
            "auditor_fp_violation": 0.018970022108501725,
            "ave_precision_score": 0.5757292493156819,
            "fpr": 0.3951701427003293,
            "logloss": 0.6836597708425867,
            "mae": 0.47709852208421205,
            "precision": 0.5577395577395577,
            "recall": 0.9360824742268041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.6743347954829894,
            "auditor_fn_violation": 0.01670921707253208,
            "auditor_fp_violation": 0.02375400974218843,
            "ave_precision_score": 0.677876503341841,
            "fpr": 0.15899122807017543,
            "logloss": 0.6273184486030106,
            "mae": 0.44058995092851355,
            "precision": 0.6895074946466809,
            "recall": 0.6865671641791045
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7343874210816254,
            "auditor_fn_violation": 0.01667817171568572,
            "auditor_fp_violation": 0.02858644733383838,
            "ave_precision_score": 0.7361034435396928,
            "fpr": 0.1437980241492865,
            "logloss": 0.615033832574652,
            "mae": 0.4361965683637479,
            "precision": 0.7145969498910676,
            "recall": 0.6762886597938145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7390655332241398,
            "auditor_fn_violation": 0.021256499457599227,
            "auditor_fp_violation": 0.03246901112827215,
            "ave_precision_score": 0.6764096464637521,
            "fpr": 0.12171052631578948,
            "logloss": 0.6422334685455234,
            "mae": 0.40625585516681895,
            "precision": 0.7318840579710145,
            "recall": 0.6460554371002132
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7245749947209887,
            "auditor_fn_violation": 0.030348433238652446,
            "auditor_fp_violation": 0.02141277964162583,
            "ave_precision_score": 0.6989585002875592,
            "fpr": 0.10867178924259056,
            "logloss": 0.6472256381614869,
            "mae": 0.4010531562058466,
            "precision": 0.7591240875912408,
            "recall": 0.643298969072165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 29198,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.5999888436329541,
            "auditor_fn_violation": 0.00048629035274755665,
            "auditor_fp_violation": 0.0016385489683576888,
            "ave_precision_score": 0.601800504536526,
            "fpr": 0.005482456140350877,
            "logloss": 4.000236943163894,
            "mae": 0.4961312451827726,
            "precision": 0.75,
            "recall": 0.031982942430703626
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.667639478768235,
            "auditor_fn_violation": 0.0037208460171783762,
            "auditor_fp_violation": 0.0006648011007869391,
            "ave_precision_score": 0.669199772270999,
            "fpr": 0.003293084522502744,
            "logloss": 4.04611899066832,
            "mae": 0.5009509160042506,
            "precision": 0.8846153846153846,
            "recall": 0.04742268041237113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 29198,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8083945856465642,
            "auditor_fn_violation": 0.004537930647514304,
            "auditor_fp_violation": 0.003930537404459236,
            "ave_precision_score": 0.8020221335059572,
            "fpr": 0.10855263157894737,
            "logloss": 0.5372995111325656,
            "mae": 0.3374172640931711,
            "precision": 0.7744874715261959,
            "recall": 0.7249466950959488
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8543403822346802,
            "auditor_fn_violation": 0.0051444543777654575,
            "auditor_fp_violation": 0.0065475178182155536,
            "ave_precision_score": 0.846085808644754,
            "fpr": 0.08232711306256861,
            "logloss": 0.4964942389278251,
            "mae": 0.32263765803872557,
            "precision": 0.8263888888888888,
            "recall": 0.7360824742268042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7369344424266197,
            "auditor_fn_violation": 0.004142819735906948,
            "auditor_fp_violation": 0.007447724842580492,
            "ave_precision_score": 0.7207462056671167,
            "fpr": 0.020833333333333332,
            "logloss": 0.6859511882419176,
            "mae": 0.4292270437765278,
            "precision": 0.8173076923076923,
            "recall": 0.1812366737739872
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.7746943991833494,
            "auditor_fn_violation": 0.01080493849513961,
            "auditor_fp_violation": 0.0007163360698401898,
            "ave_precision_score": 0.7552379814546496,
            "fpr": 0.014270032930845226,
            "logloss": 0.6705156392038801,
            "mae": 0.4223408169071185,
            "precision": 0.8951612903225806,
            "recall": 0.2288659793814433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.862453741347324,
            "auditor_fn_violation": 0.012559383533460521,
            "auditor_fp_violation": 0.01837055958179875,
            "ave_precision_score": 0.8626644176793802,
            "fpr": 0.24671052631578946,
            "logloss": 0.623981606567637,
            "mae": 0.3103084716001093,
            "precision": 0.652241112828439,
            "recall": 0.8997867803837953
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8756163724753696,
            "auditor_fn_violation": 0.005977344483800513,
            "auditor_fp_violation": 0.021327746942687964,
            "ave_precision_score": 0.8758249783578197,
            "fpr": 0.22063666300768386,
            "logloss": 0.5717752975051565,
            "mae": 0.2922088942927949,
            "precision": 0.6883720930232559,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5253034109552491,
            "auditor_fn_violation": 0.0010333669995885235,
            "auditor_fp_violation": 0.004019642786424301,
            "ave_precision_score": 0.543638672997153,
            "fpr": 0.47478070175438597,
            "logloss": 6.759715155563364,
            "mae": 0.4772340944822021,
            "precision": 0.5188888888888888,
            "recall": 0.9957356076759062
        },
        "train": {
            "accuracy": 0.54006586169045,
            "auc_prc": 0.5576651561561264,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0031230191246270234,
            "ave_precision_score": 0.5780370710810465,
            "fpr": 0.45993413830954993,
            "logloss": 6.479075111008877,
            "mae": 0.4600758612257126,
            "precision": 0.536504424778761,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.7715812486682957,
            "auditor_fn_violation": 0.039340421950398385,
            "auditor_fp_violation": 0.05965357807611581,
            "ave_precision_score": 0.7720851250625111,
            "fpr": 0.3793859649122807,
            "logloss": 1.9159393401279874,
            "mae": 0.4107144658056373,
            "precision": 0.5447368421052632,
            "recall": 0.8827292110874201
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.809792591175043,
            "auditor_fn_violation": 0.03984066450145417,
            "auditor_fp_violation": 0.0647330746277887,
            "ave_precision_score": 0.8098773705125938,
            "fpr": 0.34906695938529086,
            "logloss": 2.016722588867946,
            "mae": 0.3882067572615941,
            "precision": 0.5742971887550201,
            "recall": 0.8845360824742268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8282188460688131,
            "auditor_fn_violation": 0.019110275689223057,
            "auditor_fp_violation": 0.016991901310839174,
            "ave_precision_score": 0.7903756108603068,
            "fpr": 0.11951754385964912,
            "logloss": 0.533268345494284,
            "mae": 0.3539889722392617,
            "precision": 0.7545045045045045,
            "recall": 0.7142857142857143
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8283561725198703,
            "auditor_fn_violation": 0.028404268561793428,
            "auditor_fp_violation": 0.012020531531670825,
            "ave_precision_score": 0.7894636132890053,
            "fpr": 0.10208562019758508,
            "logloss": 0.5455360519882267,
            "mae": 0.35928779345672296,
            "precision": 0.7852193995381063,
            "recall": 0.7010309278350515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 29198,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.5708050469977511,
            "auditor_fn_violation": 0.0655065836232372,
            "auditor_fp_violation": 0.06497267434953072,
            "ave_precision_score": 0.5722353223125534,
            "fpr": 0.29276315789473684,
            "logloss": 1.3518826754243158,
            "mae": 0.45959051355712094,
            "precision": 0.5761904761904761,
            "recall": 0.7739872068230277
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6126398273916803,
            "auditor_fn_violation": 0.06284699039234104,
            "auditor_fp_violation": 0.07727926284380267,
            "ave_precision_score": 0.6141747031165268,
            "fpr": 0.2579582875960483,
            "logloss": 1.3869102434139793,
            "mae": 0.4514800719137046,
            "precision": 0.6109271523178808,
            "recall": 0.7608247422680412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8145516343689108,
            "auditor_fn_violation": 0.010593180712976474,
            "auditor_fp_violation": 0.016927547423864413,
            "ave_precision_score": 0.8149194156646059,
            "fpr": 0.23793859649122806,
            "logloss": 0.583786307137285,
            "mae": 0.33921180725947286,
            "precision": 0.667687595712098,
            "recall": 0.929637526652452
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8341968748843458,
            "auditor_fn_violation": 0.004617108196498694,
            "auditor_fp_violation": 0.023097973129667142,
            "ave_precision_score": 0.8344803923695903,
            "fpr": 0.2283205268935236,
            "logloss": 0.5633841802157845,
            "mae": 0.32956623858501305,
            "precision": 0.6809815950920245,
            "recall": 0.9154639175257732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 29198,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8269452350822856,
            "auditor_fn_violation": 0.02107647850970711,
            "auditor_fp_violation": 0.020533840243950743,
            "ave_precision_score": 0.8273257066611732,
            "fpr": 0.21162280701754385,
            "logloss": 0.5905246455034083,
            "mae": 0.3343676051819042,
            "precision": 0.6750841750841751,
            "recall": 0.8550106609808102
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8492575088011806,
            "auditor_fn_violation": 0.016162141976077044,
            "auditor_fp_violation": 0.021381858660193875,
            "ave_precision_score": 0.8499788367263932,
            "fpr": 0.19209659714599342,
            "logloss": 0.5541621059149506,
            "mae": 0.31908870932326894,
            "precision": 0.7053872053872053,
            "recall": 0.8639175257731959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 29198,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.733375731459029,
            "auditor_fn_violation": 0.007944301051135305,
            "auditor_fp_violation": 0.02613510356025505,
            "ave_precision_score": 0.7207296413460188,
            "fpr": 0.15789473684210525,
            "logloss": 0.6277840522994022,
            "mae": 0.3952622370648386,
            "precision": 0.6742081447963801,
            "recall": 0.6353944562899787
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.727146492080924,
            "auditor_fn_violation": 0.011723833557776103,
            "auditor_fp_violation": 0.0140999675329695,
            "ave_precision_score": 0.7132898085717966,
            "fpr": 0.15367727771679474,
            "logloss": 0.6280194692924409,
            "mae": 0.40103592517101805,
            "precision": 0.6949891067538126,
            "recall": 0.6577319587628866
        }
    }
]