[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 6933,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 6933,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7137630837359099,
            "auditor_fn_violation": 0.09934895833333333,
            "auditor_fp_violation": 0.1023137995451592,
            "ave_precision_score": 0.5497819377348363,
            "fpr": 0.30043859649122806,
            "logloss": 0.689266918426608,
            "mae": 0.497532297219885,
            "precision": 0.5587761674718197,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7244127099213941,
            "auditor_fn_violation": 0.08452481855613761,
            "auditor_fp_violation": 0.10431617630436038,
            "ave_precision_score": 0.5529612308448486,
            "fpr": 0.30735455543358947,
            "logloss": 0.6882908802111137,
            "mae": 0.4970322721745128,
            "precision": 0.5631825273010921,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7245386639908952,
            "auditor_fn_violation": 0.005738304093567264,
            "auditor_fp_violation": 0.003566134665367123,
            "ave_precision_score": 0.6136017126148705,
            "fpr": 0.027412280701754384,
            "logloss": 0.6488038917097729,
            "mae": 0.4564423966956766,
            "precision": 0.84472049689441,
            "recall": 0.2833333333333333
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7313966024101077,
            "auditor_fn_violation": 0.015376991019281467,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6059809004783073,
            "fpr": 0.029637760702524697,
            "logloss": 0.6503342937713146,
            "mae": 0.4601841578106718,
            "precision": 0.8258064516129032,
            "recall": 0.270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.6404519822282979,
            "auditor_fn_violation": 0.009772478070175467,
            "auditor_fp_violation": 0.002604166666666666,
            "ave_precision_score": 0.5460013670539986,
            "fpr": 0.025219298245614034,
            "logloss": 0.6922369724013574,
            "mae": 0.48863346495649274,
            "precision": 0.7012987012987013,
            "recall": 0.1125
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.6722699761934536,
            "auditor_fn_violation": 0.016439948681608293,
            "auditor_fp_violation": 0.0056793776547511094,
            "ave_precision_score": 0.5514756063953462,
            "fpr": 0.020856201975850714,
            "logloss": 0.6824883255336274,
            "mae": 0.48415069188820414,
            "precision": 0.7625,
            "recall": 0.12869198312236288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 6933,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7857611945426143,
            "auditor_fn_violation": 0.019960709064327495,
            "auditor_fp_violation": 0.004111842105263158,
            "ave_precision_score": 0.6737634425699389,
            "fpr": 0.029605263157894735,
            "logloss": 0.6183495488943137,
            "mae": 0.42672386056367767,
            "precision": 0.8708133971291866,
            "recall": 0.37916666666666665
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7708884655989824,
            "auditor_fn_violation": 0.012442857341355308,
            "auditor_fp_violation": 0.00497856104012238,
            "ave_precision_score": 0.6653685343550204,
            "fpr": 0.036223929747530186,
            "logloss": 0.6282338250053165,
            "mae": 0.42737954082918217,
            "precision": 0.8472222222222222,
            "recall": 0.3860759493670886
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7424051505312446,
            "auditor_fn_violation": 0.002204404239766102,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5707319199039905,
            "fpr": 0.005482456140350877,
            "logloss": 0.6726240856412415,
            "mae": 0.4797154467945036,
            "precision": 0.9074074074074074,
            "recall": 0.10208333333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7577348715212956,
            "auditor_fn_violation": 0.0035501396434576096,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.559354538338994,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6723989701805065,
            "mae": 0.480577857512674,
            "precision": 0.9574468085106383,
            "recall": 0.0949367088607595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.650300561591025,
            "auditor_fn_violation": 0.04199561403508773,
            "auditor_fp_violation": 0.03872238466536713,
            "ave_precision_score": 0.5926407556501874,
            "fpr": 0.0712719298245614,
            "logloss": 0.6729680541222396,
            "mae": 0.4766398384644274,
            "precision": 0.6889952153110048,
            "recall": 0.3
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6754132048072444,
            "auditor_fn_violation": 0.04161050822807969,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.5941612032699956,
            "fpr": 0.07793633369923161,
            "logloss": 0.6705733512887073,
            "mae": 0.47538006318780124,
            "precision": 0.6816143497757847,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7039190192627158,
            "auditor_fn_violation": 0.04685444078947369,
            "auditor_fp_violation": 0.061139538661468505,
            "ave_precision_score": 0.7040255634749911,
            "fpr": 0.2675438596491228,
            "logloss": 0.6350658187638211,
            "mae": 0.44299901502304956,
            "precision": 0.607085346215781,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7098274331907395,
            "auditor_fn_violation": 0.04274988768312283,
            "auditor_fp_violation": 0.05193327422024734,
            "ave_precision_score": 0.7033712055211065,
            "fpr": 0.28869374313940727,
            "logloss": 0.6395661551077603,
            "mae": 0.44332590447299175,
            "precision": 0.5922480620155038,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.797422112924792,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6360848693851441,
            "fpr": 0.006578947368421052,
            "logloss": 0.6258784733190822,
            "mae": 0.4430974285085604,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7907223634379447,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.642501184068248,
            "fpr": 0.012074643249176729,
            "logloss": 0.620372784999697,
            "mae": 0.4382901848605645,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6479639202172097,
            "auditor_fn_violation": 0.04199561403508773,
            "auditor_fp_violation": 0.037341617933723203,
            "ave_precision_score": 0.5910557644110276,
            "fpr": 0.07236842105263158,
            "logloss": 0.6738858749208646,
            "mae": 0.4769731504483181,
            "precision": 0.6857142857142857,
            "recall": 0.3
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6754132048072444,
            "auditor_fn_violation": 0.04161050822807969,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.5941612032699956,
            "fpr": 0.07793633369923161,
            "logloss": 0.6705733512887073,
            "mae": 0.47538006318780124,
            "precision": 0.6816143497757847,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6431241380240236,
            "auditor_fn_violation": 0.04098592836257312,
            "auditor_fp_violation": 0.03872238466536713,
            "ave_precision_score": 0.5897624028230435,
            "fpr": 0.0712719298245614,
            "logloss": 0.674364592024871,
            "mae": 0.477815415220041,
            "precision": 0.6859903381642513,
            "recall": 0.29583333333333334
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6724408613967023,
            "auditor_fn_violation": 0.041990301379760744,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.5919998156170886,
            "fpr": 0.07793633369923161,
            "logloss": 0.6717097628749288,
            "mae": 0.4763429274150752,
            "precision": 0.6787330316742082,
            "recall": 0.31645569620253167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.7441550065527912,
            "auditor_fn_violation": 0.0070175438596491325,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5698435265423445,
            "fpr": 0.005482456140350877,
            "logloss": 0.6740709565964281,
            "mae": 0.47897610336280705,
            "precision": 0.9152542372881356,
            "recall": 0.1125
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7648593646850905,
            "auditor_fn_violation": 0.000514110241909715,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5659374204555567,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6699745185380017,
            "mae": 0.4790948015667343,
            "precision": 0.96,
            "recall": 0.10126582278481013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7367672987573819,
            "auditor_fn_violation": 0.002204404239766102,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5645218601033887,
            "fpr": 0.005482456140350877,
            "logloss": 0.6774905814459675,
            "mae": 0.4807295173145177,
            "precision": 0.9074074074074074,
            "recall": 0.10208333333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7537748254625127,
            "auditor_fn_violation": 0.0035501396434576096,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5566748466836714,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6748703986464385,
            "mae": 0.4809800059944555,
            "precision": 0.9574468085106383,
            "recall": 0.0949367088607595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8201749194513228,
            "auditor_fn_violation": 0.0229577850877193,
            "auditor_fp_violation": 0.021206444931773885,
            "ave_precision_score": 0.8205537468748598,
            "fpr": 0.15460526315789475,
            "logloss": 0.545957050907257,
            "mae": 0.32761300325734755,
            "precision": 0.7277992277992278,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8324537761493522,
            "auditor_fn_violation": 0.02539287748891884,
            "auditor_fp_violation": 0.020004672110764198,
            "ave_precision_score": 0.8337742910732944,
            "fpr": 0.14489571899012074,
            "logloss": 0.5235533088544136,
            "mae": 0.3132570845199673,
            "precision": 0.7416829745596869,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6077011033493207,
            "auditor_fn_violation": 0.03859649122807018,
            "auditor_fp_violation": 0.03115862573099416,
            "ave_precision_score": 0.6012112337088449,
            "fpr": 0.3355263157894737,
            "logloss": 0.6931264257532641,
            "mae": 0.4665069512107916,
            "precision": 0.5677966101694916,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6553389484575418,
            "auditor_fn_violation": 0.04952363749206835,
            "auditor_fp_violation": 0.012913613676725114,
            "ave_precision_score": 0.6348837320716745,
            "fpr": 0.34577387486278816,
            "logloss": 0.6847235276195561,
            "mae": 0.46203324061324647,
            "precision": 0.5649171270718232,
            "recall": 0.8628691983122363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.7338008135630666,
            "auditor_fn_violation": 0.009491502192982467,
            "auditor_fp_violation": 0.004355506822612086,
            "ave_precision_score": 0.6226983561871138,
            "fpr": 0.027412280701754384,
            "logloss": 0.6539588435337482,
            "mae": 0.46912657070839614,
            "precision": 0.8076923076923077,
            "recall": 0.21875
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.7378039456523001,
            "auditor_fn_violation": 0.011831482999624854,
            "auditor_fp_violation": 0.006123981743601597,
            "ave_precision_score": 0.6177329822113987,
            "fpr": 0.025246981339187707,
            "logloss": 0.6525154169921626,
            "mae": 0.46748426124764325,
            "precision": 0.8308823529411765,
            "recall": 0.23839662447257384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5455609061313076,
            "auditor_fn_violation": 0.005665204678362583,
            "auditor_fp_violation": 0.027369131741390523,
            "ave_precision_score": 0.5251853861457768,
            "fpr": 0.051535087719298246,
            "logloss": 0.6980220551887825,
            "mae": 0.5001537924338328,
            "precision": 0.5154639175257731,
            "recall": 0.10416666666666667
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5455862152626983,
            "auditor_fn_violation": 0.010731472346890104,
            "auditor_fp_violation": 0.023511267071415477,
            "ave_precision_score": 0.5204075503745753,
            "fpr": 0.04939626783754116,
            "logloss": 0.6972522446863301,
            "mae": 0.4998370720774884,
            "precision": 0.5212765957446809,
            "recall": 0.10337552742616034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7978370937953013,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6360430521239139,
            "fpr": 0.006578947368421052,
            "logloss": 0.627234414927256,
            "mae": 0.44548681724751205,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7878051000319951,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.638387257876415,
            "fpr": 0.012074643249176729,
            "logloss": 0.6232628771286209,
            "mae": 0.4413054566482812,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 6933,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.5724459285803555,
            "auditor_fn_violation": 0.005413925438596503,
            "auditor_fp_violation": 0.010279605263157895,
            "ave_precision_score": 0.5565264080187305,
            "fpr": 0.029605263157894735,
            "logloss": 0.7499010641311115,
            "mae": 0.48782196474310596,
            "precision": 0.5573770491803278,
            "recall": 0.07083333333333333
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5914347556878398,
            "auditor_fn_violation": 0.0022996012171907594,
            "auditor_fp_violation": 0.014975873320489217,
            "ave_precision_score": 0.5565824693169851,
            "fpr": 0.029637760702524697,
            "logloss": 0.7471445419813519,
            "mae": 0.4833280884964406,
            "precision": 0.6029411764705882,
            "recall": 0.08649789029535865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7314895411605937,
            "auditor_fn_violation": 0.0073601973684210556,
            "auditor_fp_violation": 0.0034874512670565313,
            "ave_precision_score": 0.6189085695006747,
            "fpr": 0.02850877192982456,
            "logloss": 0.6460363948783298,
            "mae": 0.45325073521388204,
            "precision": 0.8461538461538461,
            "recall": 0.29791666666666666
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7387175865584491,
            "auditor_fn_violation": 0.010045992024343814,
            "auditor_fp_violation": 0.0034287264479147565,
            "ave_precision_score": 0.6155025350671335,
            "fpr": 0.030735455543358946,
            "logloss": 0.6450843985306891,
            "mae": 0.4554242882979819,
            "precision": 0.8313253012048193,
            "recall": 0.2911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 6933,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5131963940503796,
            "auditor_fn_violation": 0.010060307017543863,
            "auditor_fp_violation": 0.008261756822612083,
            "ave_precision_score": 0.5146928634681098,
            "fpr": 0.29276315789473684,
            "logloss": 1.340722486000843,
            "mae": 0.4590135111965649,
            "precision": 0.5700483091787439,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.519700156238118,
            "auditor_fn_violation": 0.0037238255359946675,
            "auditor_fp_violation": 0.016465422612513728,
            "ave_precision_score": 0.5209162081368963,
            "fpr": 0.29198682766191,
            "logloss": 1.3619772728699162,
            "mae": 0.4483160697081296,
            "precision": 0.5771065182829889,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7325040282680788,
            "auditor_fn_violation": 0.0008954678362573253,
            "auditor_fp_violation": 0.003566134665367123,
            "ave_precision_score": 0.6174439051133933,
            "fpr": 0.027412280701754384,
            "logloss": 0.6473102544560123,
            "mae": 0.45524965618786056,
            "precision": 0.8475609756097561,
            "recall": 0.28958333333333336
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7399567242300311,
            "auditor_fn_violation": 0.007568073290815037,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6126659851287383,
            "fpr": 0.029637760702524697,
            "logloss": 0.6461069552234842,
            "mae": 0.4579990440090192,
            "precision": 0.83125,
            "recall": 0.2805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 6933,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7516173245614034,
            "auditor_fn_violation": 0.002213541666666664,
            "auditor_fp_violation": 0.003477298570500325,
            "ave_precision_score": 0.6088872226522187,
            "fpr": 0.020833333333333332,
            "logloss": 0.6482952722489141,
            "mae": 0.46292970643231746,
            "precision": 0.8602941176470589,
            "recall": 0.24375
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7035530665723874,
            "auditor_fn_violation": 0.012653596224300276,
            "auditor_fp_violation": 0.0008289228775178543,
            "ave_precision_score": 0.5939790820430402,
            "fpr": 0.02854006586169045,
            "logloss": 0.6591935354428176,
            "mae": 0.4650878976257651,
            "precision": 0.8194444444444444,
            "recall": 0.2489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.797422112924792,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6360848693851441,
            "fpr": 0.006578947368421052,
            "logloss": 0.6258933905304198,
            "mae": 0.44293552302150874,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7907223634379447,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.642501184068248,
            "fpr": 0.012074643249176729,
            "logloss": 0.6204410863985618,
            "mae": 0.4381192666442674,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5837327694235589,
            "auditor_fn_violation": 0.011161366959064334,
            "auditor_fp_violation": 0.017442332683560755,
            "ave_precision_score": 0.5332591896407686,
            "fpr": 0.04824561403508772,
            "logloss": 0.6946540242094507,
            "mae": 0.49770801024217354,
            "precision": 0.580952380952381,
            "recall": 0.12708333333333333
        },
        "train": {
            "accuracy": 0.5027442371020856,
            "auc_prc": 0.5935442743234988,
            "auditor_fn_violation": 0.0164376328697078,
            "auditor_fp_violation": 0.020376431461893413,
            "ave_precision_score": 0.5311621965181137,
            "fpr": 0.042810098792535674,
            "logloss": 0.6923625056715131,
            "mae": 0.49674500657488824,
            "precision": 0.6060606060606061,
            "recall": 0.12658227848101267
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7360572948175035,
            "auditor_fn_violation": 0.006857638888888903,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5666577462974166,
            "fpr": 0.005482456140350877,
            "logloss": 0.6755843628484907,
            "mae": 0.4794466477214244,
            "precision": 0.9137931034482759,
            "recall": 0.11041666666666666
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7677304581307725,
            "auditor_fn_violation": 0.0015284358543261733,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5690632410928848,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6676569729934008,
            "mae": 0.4781649589015153,
            "precision": 0.9629629629629629,
            "recall": 0.10970464135021098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.7360572948175035,
            "auditor_fn_violation": 0.006857638888888903,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5666577462974166,
            "fpr": 0.005482456140350877,
            "logloss": 0.6755843628484907,
            "mae": 0.4794466477214244,
            "precision": 0.9137931034482759,
            "recall": 0.11041666666666666
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7677304581307725,
            "auditor_fn_violation": 0.0015284358543261733,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5690632410928848,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6676569729934008,
            "mae": 0.4781649589015153,
            "precision": 0.9629629629629629,
            "recall": 0.10970464135021098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5149391199702302,
            "auditor_fn_violation": 0.009598866959064332,
            "auditor_fp_violation": 0.00667793615984406,
            "ave_precision_score": 0.5164316819192029,
            "fpr": 0.27960526315789475,
            "logloss": 1.3138906918561617,
            "mae": 0.46026334241016004,
            "precision": 0.5692567567567568,
            "recall": 0.7020833333333333
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.5203565514159254,
            "auditor_fn_violation": 0.008420292070196893,
            "auditor_fp_violation": 0.011537099322543962,
            "ave_precision_score": 0.5215581041741539,
            "fpr": 0.27552140504939626,
            "logloss": 1.3306517547372347,
            "mae": 0.4486283885597425,
            "precision": 0.5788590604026845,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6372202274208896,
            "auditor_fn_violation": 0.07600054824561404,
            "auditor_fp_violation": 0.08015553931124107,
            "ave_precision_score": 0.638131392392681,
            "fpr": 0.2850877192982456,
            "logloss": 0.6693162066854481,
            "mae": 0.46685462464627464,
            "precision": 0.584,
            "recall": 0.7604166666666666
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6584837046340135,
            "auditor_fn_violation": 0.06842297841200146,
            "auditor_fp_violation": 0.07697176889630175,
            "ave_precision_score": 0.6575110964213808,
            "fpr": 0.29088913282107576,
            "logloss": 0.6587853792018985,
            "mae": 0.46193531809863353,
            "precision": 0.5885093167701864,
            "recall": 0.79957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.6057690916181149,
            "auditor_fn_violation": 0.05577713815789476,
            "auditor_fp_violation": 0.041747888239116314,
            "ave_precision_score": 0.5968509645274277,
            "fpr": 0.07017543859649122,
            "logloss": 0.6751453119607171,
            "mae": 0.48174072262880047,
            "precision": 0.6464088397790055,
            "recall": 0.24375
        },
        "train": {
            "accuracy": 0.531284302963776,
            "auc_prc": 0.6445861785275994,
            "auditor_fn_violation": 0.05518116596497567,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.6032075091711268,
            "fpr": 0.07793633369923161,
            "logloss": 0.6738601025160443,
            "mae": 0.4810113191081193,
            "precision": 0.6243386243386243,
            "recall": 0.2489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.828705240817833,
            "auditor_fn_violation": 0.0171326754385965,
            "auditor_fp_violation": 0.017584470435347627,
            "ave_precision_score": 0.829110033309391,
            "fpr": 0.08333333333333333,
            "logloss": 0.545177838053616,
            "mae": 0.3273741563770863,
            "precision": 0.8109452736318408,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8270543091768319,
            "auditor_fn_violation": 0.014580351725511453,
            "auditor_fp_violation": 0.011358755309502219,
            "ave_precision_score": 0.828478485692943,
            "fpr": 0.08342480790340286,
            "logloss": 0.5293815392818519,
            "mae": 0.3130537968529664,
            "precision": 0.8137254901960784,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7325040282680788,
            "auditor_fn_violation": 0.0008954678362573253,
            "auditor_fp_violation": 0.003566134665367123,
            "ave_precision_score": 0.6174439051133933,
            "fpr": 0.027412280701754384,
            "logloss": 0.6473102544560123,
            "mae": 0.45524965618786056,
            "precision": 0.8475609756097561,
            "recall": 0.28958333333333336
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7399567242300311,
            "auditor_fn_violation": 0.007568073290815037,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6126659851287383,
            "fpr": 0.029637760702524697,
            "logloss": 0.6461069552234842,
            "mae": 0.4579990440090192,
            "precision": 0.83125,
            "recall": 0.2805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7137630837359099,
            "auditor_fn_violation": 0.09934895833333333,
            "auditor_fp_violation": 0.1023137995451592,
            "ave_precision_score": 0.5497819377348363,
            "fpr": 0.30043859649122806,
            "logloss": 0.689266918426608,
            "mae": 0.497532297219885,
            "precision": 0.5587761674718197,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7244127099213941,
            "auditor_fn_violation": 0.08452481855613761,
            "auditor_fp_violation": 0.10431617630436038,
            "ave_precision_score": 0.5529612308448486,
            "fpr": 0.30735455543358947,
            "logloss": 0.6882908802111137,
            "mae": 0.4970322721745128,
            "precision": 0.5631825273010921,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7367672987573819,
            "auditor_fn_violation": 0.002204404239766102,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5645218601033887,
            "fpr": 0.005482456140350877,
            "logloss": 0.6774905814459675,
            "mae": 0.4807295173145177,
            "precision": 0.9074074074074074,
            "recall": 0.10208333333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7537748254625127,
            "auditor_fn_violation": 0.0035501396434576096,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5566748466836714,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6748703986464385,
            "mae": 0.4809800059944555,
            "precision": 0.9574468085106383,
            "recall": 0.0949367088607595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6936467868897289,
            "auditor_fn_violation": 0.005265442251461991,
            "auditor_fp_violation": 0.0034620695256660184,
            "ave_precision_score": 0.6084988965843748,
            "fpr": 0.04057017543859649,
            "logloss": 0.6543832140043309,
            "mae": 0.45590349456720186,
            "precision": 0.8072916666666666,
            "recall": 0.3229166666666667
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7035223612371858,
            "auditor_fn_violation": 0.021092414789701138,
            "auditor_fp_violation": 0.0018010233429706097,
            "ave_precision_score": 0.6106186131589222,
            "fpr": 0.03951701427003293,
            "logloss": 0.6547050604480122,
            "mae": 0.4538645428635025,
            "precision": 0.8125,
            "recall": 0.3291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.797422112924792,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6360848693851441,
            "fpr": 0.006578947368421052,
            "logloss": 0.6258933906239487,
            "mae": 0.44293552298066124,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.790298234144208,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.6416578429218612,
            "fpr": 0.012074643249176729,
            "logloss": 0.6215366376107486,
            "mae": 0.43893334340676254,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8186858308950401,
            "auditor_fn_violation": 0.02044956140350877,
            "auditor_fp_violation": 0.021206444931773885,
            "ave_precision_score": 0.8189445051058555,
            "fpr": 0.15460526315789475,
            "logloss": 0.5459050545680876,
            "mae": 0.3272753140461231,
            "precision": 0.7283236994219653,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8328688210476551,
            "auditor_fn_violation": 0.02466339674026317,
            "auditor_fp_violation": 0.020004672110764198,
            "ave_precision_score": 0.8342053274987445,
            "fpr": 0.14489571899012074,
            "logloss": 0.5238710035986118,
            "mae": 0.3131980560750636,
            "precision": 0.7421875,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7314895411605937,
            "auditor_fn_violation": 0.0073601973684210556,
            "auditor_fp_violation": 0.0034874512670565313,
            "ave_precision_score": 0.6189085695006747,
            "fpr": 0.02850877192982456,
            "logloss": 0.6460363948783298,
            "mae": 0.45325073521388204,
            "precision": 0.8461538461538461,
            "recall": 0.29791666666666666
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7387175865584491,
            "auditor_fn_violation": 0.010045992024343814,
            "auditor_fp_violation": 0.0034287264479147565,
            "ave_precision_score": 0.6155025350671335,
            "fpr": 0.030735455543358946,
            "logloss": 0.6450843985306891,
            "mae": 0.4554242882979819,
            "precision": 0.8313253012048193,
            "recall": 0.2911392405063291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.7628730455077688,
            "auditor_fn_violation": 0.011433205409356745,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.6383812366039533,
            "fpr": 0.003289473684210526,
            "logloss": 0.6421282070276786,
            "mae": 0.45892280470906643,
            "precision": 0.9659090909090909,
            "recall": 0.17708333333333334
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7443625364729015,
            "auditor_fn_violation": 0.00712575321782063,
            "auditor_fp_violation": 0.0006656501895219125,
            "ave_precision_score": 0.6239862337486365,
            "fpr": 0.003293084522502744,
            "logloss": 0.633617610933068,
            "mae": 0.45334126380743495,
            "precision": 0.9693877551020408,
            "recall": 0.20042194092827004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.7097661585490533,
            "auditor_fn_violation": 0.038304093567251486,
            "auditor_fp_violation": 0.01141163092917479,
            "ave_precision_score": 0.5983721578129474,
            "fpr": 0.03070175438596491,
            "logloss": 0.6592716413767105,
            "mae": 0.47260716675143494,
            "precision": 0.8205128205128205,
            "recall": 0.26666666666666666
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7125063770150091,
            "auditor_fn_violation": 0.04533433376407435,
            "auditor_fp_violation": 0.012421283725229649,
            "ave_precision_score": 0.5955678608812175,
            "fpr": 0.02854006586169045,
            "logloss": 0.6569309637192986,
            "mae": 0.47134308309246237,
            "precision": 0.8311688311688312,
            "recall": 0.270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6431241380240236,
            "auditor_fn_violation": 0.04098592836257312,
            "auditor_fp_violation": 0.03872238466536713,
            "ave_precision_score": 0.5897624028230435,
            "fpr": 0.0712719298245614,
            "logloss": 0.6743645911081304,
            "mae": 0.4778154112986828,
            "precision": 0.6859903381642513,
            "recall": 0.29583333333333334
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6724408613967023,
            "auditor_fn_violation": 0.041990301379760744,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.5919998156170886,
            "fpr": 0.07793633369923161,
            "logloss": 0.6717097624469498,
            "mae": 0.4763429234239848,
            "precision": 0.6787330316742082,
            "recall": 0.31645569620253167
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7061663774821669,
            "auditor_fn_violation": 0.0017543859649122747,
            "auditor_fp_violation": 0.0014467592592592596,
            "ave_precision_score": 0.5610046617612406,
            "fpr": 0.006578947368421052,
            "logloss": 0.6782230323666237,
            "mae": 0.4874969513008469,
            "precision": 0.8888888888888888,
            "recall": 0.1
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.7319195403474745,
            "auditor_fn_violation": 0.003418138365129437,
            "auditor_fp_violation": 0.0009821480154832746,
            "ave_precision_score": 0.5588917073931455,
            "fpr": 0.0043907793633369925,
            "logloss": 0.6753378685345277,
            "mae": 0.48630662512700723,
            "precision": 0.9230769230769231,
            "recall": 0.10126582278481013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 6933,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6764988581906515,
            "auditor_fn_violation": 0.002213541666666664,
            "auditor_fp_violation": 0.003477298570500325,
            "ave_precision_score": 0.6279469485180873,
            "fpr": 0.020833333333333332,
            "logloss": 0.6475808603324744,
            "mae": 0.4619326419605498,
            "precision": 0.8602941176470589,
            "recall": 0.24375
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.6569728270200108,
            "auditor_fn_violation": 0.012653596224300276,
            "auditor_fp_violation": 0.0008289228775178543,
            "ave_precision_score": 0.6199556686734102,
            "fpr": 0.02854006586169045,
            "logloss": 0.6586611108989083,
            "mae": 0.46458303362425546,
            "precision": 0.8194444444444444,
            "recall": 0.2489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7114466591005816,
            "auditor_fn_violation": 0.0393137792397661,
            "auditor_fp_violation": 0.011122279077322939,
            "ave_precision_score": 0.5993200867735375,
            "fpr": 0.03179824561403509,
            "logloss": 0.658795320748497,
            "mae": 0.47147863763466213,
            "precision": 0.8176100628930818,
            "recall": 0.2708333333333333
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7144265066009151,
            "auditor_fn_violation": 0.04668676791396296,
            "auditor_fp_violation": 0.012421283725229649,
            "ave_precision_score": 0.5975302103600398,
            "fpr": 0.02854006586169045,
            "logloss": 0.6557608719126734,
            "mae": 0.4700467602219985,
            "precision": 0.8333333333333334,
            "recall": 0.2742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.6029912999119764,
            "auditor_fn_violation": 0.05325292397660822,
            "auditor_fp_violation": 0.04109557748538012,
            "ave_precision_score": 0.5935054890801525,
            "fpr": 0.06907894736842106,
            "logloss": 0.6765736732179831,
            "mae": 0.4822860864693658,
            "precision": 0.64,
            "recall": 0.23333333333333334
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6402027923174819,
            "auditor_fn_violation": 0.05366662498205246,
            "auditor_fp_violation": 0.03793201325271849,
            "ave_precision_score": 0.5999557484352825,
            "fpr": 0.07793633369923161,
            "logloss": 0.6752916305565746,
            "mae": 0.4812739837575299,
            "precision": 0.6182795698924731,
            "recall": 0.24261603375527427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0.5455609061313076,
            "auditor_fn_violation": 0.005665204678362583,
            "auditor_fp_violation": 0.027369131741390523,
            "ave_precision_score": 0.5251853861457768,
            "fpr": 0.051535087719298246,
            "logloss": 0.6980220551887825,
            "mae": 0.5001537924338328,
            "precision": 0.5154639175257731,
            "recall": 0.10416666666666667
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5455862152626983,
            "auditor_fn_violation": 0.010731472346890104,
            "auditor_fp_violation": 0.023511267071415477,
            "ave_precision_score": 0.5204075503745753,
            "fpr": 0.04939626783754116,
            "logloss": 0.6972522446863301,
            "mae": 0.4998370720774884,
            "precision": 0.5212765957446809,
            "recall": 0.10337552742616034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 6933,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5187599238691454,
            "auditor_fn_violation": 0.009046052631578953,
            "auditor_fp_violation": 0.009939489928525025,
            "ave_precision_score": 0.5202118615679823,
            "fpr": 0.28728070175438597,
            "logloss": 1.296616275033234,
            "mae": 0.4540371268864411,
            "precision": 0.5787781350482315,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5265162598605128,
            "auditor_fn_violation": 0.004261093896909322,
            "auditor_fp_violation": 0.01560635708490433,
            "ave_precision_score": 0.5277295752799702,
            "fpr": 0.29198682766191,
            "logloss": 1.3121433783949275,
            "mae": 0.44369691529839134,
            "precision": 0.580441640378549,
            "recall": 0.7763713080168776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8451863674401925,
            "auditor_fn_violation": 0.02346491228070175,
            "auditor_fp_violation": 0.017828135152696555,
            "ave_precision_score": 0.8454265090346089,
            "fpr": 0.10964912280701754,
            "logloss": 0.5167626525480757,
            "mae": 0.31904545899133635,
            "precision": 0.7797356828193832,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8453475015650562,
            "auditor_fn_violation": 0.023662965999249677,
            "auditor_fp_violation": 0.014747291557294895,
            "ave_precision_score": 0.8457618983366824,
            "fpr": 0.10428100987925357,
            "logloss": 0.5049338463670938,
            "mae": 0.311255063286113,
            "precision": 0.7921225382932167,
            "recall": 0.7637130801687764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7263822458231309,
            "auditor_fn_violation": 0.0007812500000000026,
            "auditor_fp_violation": 0.001093953053931138,
            "ave_precision_score": 0.7033151626773027,
            "fpr": 0.23574561403508773,
            "logloss": 0.6240568433753059,
            "mae": 0.44899110989481733,
            "precision": 0.6221441124780316,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6854315823913842,
            "auditor_fn_violation": 0.006245744695632847,
            "auditor_fp_violation": 0.015633987847488245,
            "ave_precision_score": 0.6634416993668502,
            "fpr": 0.2623490669593853,
            "logloss": 0.6292648362460846,
            "mae": 0.45042453959796874,
            "precision": 0.5716845878136201,
            "recall": 0.6729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7965519939758999,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6362071625109141,
            "fpr": 0.006578947368421052,
            "logloss": 0.6290298327834293,
            "mae": 0.4442862451174541,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7934828837399,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.6466820616231426,
            "fpr": 0.012074643249176729,
            "logloss": 0.6131013675366961,
            "mae": 0.4352171718665326,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8023617877397189,
            "auditor_fn_violation": 0.020586622807017545,
            "auditor_fp_violation": 0.018993157082521125,
            "ave_precision_score": 0.8032400626434006,
            "fpr": 0.17214912280701755,
            "logloss": 0.5598314877921876,
            "mae": 0.34033199341910514,
            "precision": 0.7092592592592593,
            "recall": 0.7979166666666667
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8223864553069389,
            "auditor_fn_violation": 0.014094031226407663,
            "auditor_fp_violation": 0.015541048009705937,
            "ave_precision_score": 0.8229225824026726,
            "fpr": 0.1602634467618002,
            "logloss": 0.5432865053888438,
            "mae": 0.3276118748661838,
            "precision": 0.7296296296296296,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8274311764702703,
            "auditor_fn_violation": 0.016897386695906437,
            "auditor_fp_violation": 0.014894005847953216,
            "ave_precision_score": 0.8276896853560495,
            "fpr": 0.15899122807017543,
            "logloss": 0.5381315850394746,
            "mae": 0.3414045185796057,
            "precision": 0.7200772200772201,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8314899374747518,
            "auditor_fn_violation": 0.015298253414664644,
            "auditor_fp_violation": 0.008377144837945582,
            "ave_precision_score": 0.8319554001629816,
            "fpr": 0.15148188803512624,
            "logloss": 0.5257832441939719,
            "mae": 0.3308648710236151,
            "precision": 0.7325581395348837,
            "recall": 0.7974683544303798
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8424038696632111,
            "auditor_fn_violation": 0.019247989766081868,
            "auditor_fp_violation": 0.02144249512670566,
            "ave_precision_score": 0.8426240256446447,
            "fpr": 0.15679824561403508,
            "logloss": 0.5323487457599766,
            "mae": 0.3257324332534744,
            "precision": 0.7276190476190476,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8447294440232085,
            "auditor_fn_violation": 0.019142501169485016,
            "auditor_fp_violation": 0.018273981618007223,
            "ave_precision_score": 0.845460992061202,
            "fpr": 0.13830954994511527,
            "logloss": 0.5098875662172013,
            "mae": 0.3099451829964534,
            "precision": 0.7519685039370079,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7382717611336033,
            "auditor_fn_violation": 0.0019668311403508924,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5632823043184886,
            "fpr": 0.005482456140350877,
            "logloss": 0.6806221881828124,
            "mae": 0.49167996448905843,
            "precision": 0.9038461538461539,
            "recall": 0.09791666666666667
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7596896657665878,
            "auditor_fn_violation": 0.0007642179271630842,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.559791895996373,
            "fpr": 0.0021953896816684962,
            "logloss": 0.680024481662867,
            "mae": 0.4916445875272531,
            "precision": 0.9555555555555556,
            "recall": 0.09071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7450341113821611,
            "auditor_fn_violation": 0.0008954678362573253,
            "auditor_fp_violation": 0.003566134665367123,
            "ave_precision_score": 0.6247383715006934,
            "fpr": 0.027412280701754384,
            "logloss": 0.6420425269149204,
            "mae": 0.4540486502412118,
            "precision": 0.8475609756097561,
            "recall": 0.28958333333333336
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7402335573846064,
            "auditor_fn_violation": 0.007568073290815037,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6152057601030451,
            "fpr": 0.029637760702524697,
            "logloss": 0.6453180495338364,
            "mae": 0.4581287524506499,
            "precision": 0.83125,
            "recall": 0.2805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 6933,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.7516173245614034,
            "auditor_fn_violation": 0.002213541666666664,
            "auditor_fp_violation": 0.003477298570500325,
            "ave_precision_score": 0.6088872226522187,
            "fpr": 0.020833333333333332,
            "logloss": 0.6482952722489141,
            "mae": 0.46292970643231746,
            "precision": 0.8602941176470589,
            "recall": 0.24375
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7035530665723874,
            "auditor_fn_violation": 0.012653596224300276,
            "auditor_fp_violation": 0.0008289228775178543,
            "ave_precision_score": 0.5939790820430402,
            "fpr": 0.02854006586169045,
            "logloss": 0.6591935354428176,
            "mae": 0.4650878976257651,
            "precision": 0.8194444444444444,
            "recall": 0.2489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7098052330682985,
            "auditor_fn_violation": 0.011376096491228069,
            "auditor_fp_violation": 0.001093953053931138,
            "ave_precision_score": 0.6851092130597104,
            "fpr": 0.23574561403508773,
            "logloss": 0.6349733131876037,
            "mae": 0.45621984896429796,
            "precision": 0.6160714285714286,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6773506398590444,
            "auditor_fn_violation": 0.007795022857063465,
            "auditor_fp_violation": 0.015633987847488245,
            "ave_precision_score": 0.6544478521976639,
            "fpr": 0.2623490669593853,
            "logloss": 0.6363053324349263,
            "mae": 0.45506975342622835,
            "precision": 0.5685920577617328,
            "recall": 0.6645569620253164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6198977396500325,
            "auditor_fn_violation": 0.09279057017543861,
            "auditor_fp_violation": 0.09529067170240416,
            "ave_precision_score": 0.6221714083612282,
            "fpr": 0.26864035087719296,
            "logloss": 0.6734358539296688,
            "mae": 0.4679651091267404,
            "precision": 0.5909849749582637,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.6600746401124868,
            "auditor_fn_violation": 0.07847591787204676,
            "auditor_fp_violation": 0.09172157234110427,
            "ave_precision_score": 0.6562624844965993,
            "fpr": 0.2722283205268935,
            "logloss": 0.6624387455234282,
            "mae": 0.4625101704007315,
            "precision": 0.5993537964458805,
            "recall": 0.7827004219409283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8687924803206964,
            "auditor_fn_violation": 0.009347587719298245,
            "auditor_fp_violation": 0.02010233918128656,
            "ave_precision_score": 0.8690970627575093,
            "fpr": 0.15789473684210525,
            "logloss": 0.5654793250321971,
            "mae": 0.2528477632339969,
            "precision": 0.7410071942446043,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8405038013438746,
            "auditor_fn_violation": 0.010372521502313502,
            "auditor_fp_violation": 0.019296319833612578,
            "ave_precision_score": 0.8408375588391949,
            "fpr": 0.17014270032930845,
            "logloss": 0.6497914667264583,
            "mae": 0.2752668876701562,
            "precision": 0.7192028985507246,
            "recall": 0.8375527426160337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5142543859649122,
            "auc_prc": 0.7389437134502924,
            "auditor_fn_violation": 0.005605811403508793,
            "auditor_fp_violation": 0.0008731319038336584,
            "ave_precision_score": 0.559183723196881,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6828225884778579,
            "mae": 0.49340441600795376,
            "precision": 0.9111111111111111,
            "recall": 0.08541666666666667
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.7554976244853391,
            "auditor_fn_violation": 0.00036126665647709063,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5557621523359143,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6821682092507386,
            "mae": 0.49320521783881077,
            "precision": 0.9512195121951219,
            "recall": 0.08227848101265822
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.779311344621227,
            "auditor_fn_violation": 0.009269919590643291,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.665489910454313,
            "fpr": 0.003289473684210526,
            "logloss": 0.6284504433110629,
            "mae": 0.44799683455443173,
            "precision": 0.97,
            "recall": 0.20208333333333334
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7522700506620563,
            "auditor_fn_violation": 0.008221132246754395,
            "auditor_fp_violation": 0.0006656501895219125,
            "ave_precision_score": 0.6422634709512751,
            "fpr": 0.003293084522502744,
            "logloss": 0.6280994181103063,
            "mae": 0.4466324701954321,
            "precision": 0.9719626168224299,
            "recall": 0.21940928270042195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.5502606361715227,
            "auditor_fn_violation": 0.008287646198830422,
            "auditor_fp_violation": 0.012061403508771938,
            "ave_precision_score": 0.5518063264903847,
            "fpr": 0.23684210526315788,
            "logloss": 1.0683234268083706,
            "mae": 0.4379302871270818,
            "precision": 0.6058394160583942,
            "recall": 0.6916666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.5581601603107927,
            "auditor_fn_violation": 0.011674007790391235,
            "auditor_fp_violation": 0.010645379257335346,
            "ave_precision_score": 0.559456324357556,
            "fpr": 0.24698133918770582,
            "logloss": 1.0760657406810992,
            "mae": 0.4273025953566398,
            "precision": 0.6038732394366197,
            "recall": 0.7236286919831224
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6140350877192983,
            "auc_prc": 0.5942207883317523,
            "auditor_fn_violation": 0.025123355263157898,
            "auditor_fp_violation": 0.05085739522417155,
            "ave_precision_score": 0.597171245036559,
            "fpr": 0.3168859649122807,
            "logloss": 0.8153692920917152,
            "mae": 0.4600162237980648,
            "precision": 0.5906515580736544,
            "recall": 0.86875
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.5897459510116192,
            "auditor_fn_violation": 0.02426044546957718,
            "auditor_fp_violation": 0.04056698324822222,
            "ave_precision_score": 0.5912981260430766,
            "fpr": 0.31284302963776073,
            "logloss": 0.8016348609186257,
            "mae": 0.46323435253879763,
            "precision": 0.592274678111588,
            "recall": 0.8734177215189873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7382717611336033,
            "auditor_fn_violation": 0.0019668311403508924,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5632823043184886,
            "fpr": 0.005482456140350877,
            "logloss": 0.6806066887074785,
            "mae": 0.4916626528689736,
            "precision": 0.9038461538461539,
            "recall": 0.09791666666666667
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7596896657665878,
            "auditor_fn_violation": 0.0007642179271630842,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.559791895996373,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6800057985734728,
            "mae": 0.4916268511216282,
            "precision": 0.9555555555555556,
            "recall": 0.09071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8494965067666109,
            "auditor_fn_violation": 0.010263614766081878,
            "auditor_fp_violation": 0.005482456140350881,
            "ave_precision_score": 0.8497885973280392,
            "fpr": 0.06359649122807018,
            "logloss": 0.5404993732539182,
            "mae": 0.30704929409732457,
            "precision": 0.847769028871391,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8427811169338288,
            "auditor_fn_violation": 0.007702390381043691,
            "auditor_fp_violation": 0.007909933761526426,
            "ave_precision_score": 0.8436918245213255,
            "fpr": 0.07244785949506037,
            "logloss": 0.5324879098582277,
            "mae": 0.29538720192793555,
            "precision": 0.8324873096446701,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.7798584888879645,
            "auditor_fn_violation": 0.011800986842105265,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.6663938090988148,
            "fpr": 0.003289473684210526,
            "logloss": 0.629359469984985,
            "mae": 0.4479678787225694,
            "precision": 0.9702970297029703,
            "recall": 0.20416666666666666
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7408971451509665,
            "auditor_fn_violation": 0.005314788311634186,
            "auditor_fp_violation": 0.0002562125257782456,
            "ave_precision_score": 0.6404541213932605,
            "fpr": 0.0043907793633369925,
            "logloss": 0.630381845387635,
            "mae": 0.4466003595997552,
            "precision": 0.963302752293578,
            "recall": 0.22151898734177214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7879770536780657,
            "auditor_fn_violation": 0.00789930555555556,
            "auditor_fp_violation": 0.004446881091617936,
            "ave_precision_score": 0.7154462817204205,
            "fpr": 0.02631578947368421,
            "logloss": 0.6083620495929337,
            "mae": 0.42578284066627947,
            "precision": 0.8811881188118812,
            "recall": 0.37083333333333335
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7664227216154822,
            "auditor_fn_violation": 0.012079274872977733,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6956365685841669,
            "fpr": 0.029637760702524697,
            "logloss": 0.602576445241076,
            "mae": 0.42231732888226975,
            "precision": 0.8669950738916257,
            "recall": 0.37130801687763715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7962205580713871,
            "auditor_fn_violation": 0.0060786732456140444,
            "auditor_fp_violation": 0.003566134665367123,
            "ave_precision_score": 0.7417965730730806,
            "fpr": 0.027412280701754384,
            "logloss": 0.6008033455550036,
            "mae": 0.420409002439364,
            "precision": 0.8724489795918368,
            "recall": 0.35625
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7932397449959286,
            "auditor_fn_violation": 0.012959283395165526,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.7407722234047196,
            "fpr": 0.029637760702524697,
            "logloss": 0.5851450646286864,
            "mae": 0.4118096199863959,
            "precision": 0.8669950738916257,
            "recall": 0.37130801687763715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.7039190192627158,
            "auditor_fn_violation": 0.04685444078947369,
            "auditor_fp_violation": 0.061139538661468505,
            "ave_precision_score": 0.7040255634749911,
            "fpr": 0.2675438596491228,
            "logloss": 0.6350641435593948,
            "mae": 0.4429970556837425,
            "precision": 0.607085346215781,
            "recall": 0.7854166666666667
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7098251250849491,
            "auditor_fn_violation": 0.04274988768312283,
            "auditor_fp_violation": 0.05193327422024734,
            "ave_precision_score": 0.7033712055211065,
            "fpr": 0.28869374313940727,
            "logloss": 0.6395595587143,
            "mae": 0.44332215505622485,
            "precision": 0.5922480620155038,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5109292450541085,
            "auditor_fn_violation": 0.009285910087719304,
            "auditor_fp_violation": 0.011472547108512036,
            "ave_precision_score": 0.5123843125659348,
            "fpr": 0.2949561403508772,
            "logloss": 1.3588710024969224,
            "mae": 0.4609801182851426,
            "precision": 0.5689102564102564,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.5194959587922784,
            "auditor_fn_violation": 0.004159198173287578,
            "auditor_fp_violation": 0.018118244592534184,
            "ave_precision_score": 0.5207134383475926,
            "fpr": 0.29527991218441274,
            "logloss": 1.3755223307001316,
            "mae": 0.4495502712263867,
            "precision": 0.5770440251572327,
            "recall": 0.7742616033755274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.6577069205860145,
            "auditor_fn_violation": 0.06046235380116959,
            "auditor_fp_violation": 0.037676656920077975,
            "ave_precision_score": 0.593751530197118,
            "fpr": 0.07346491228070176,
            "logloss": 0.669594505203324,
            "mae": 0.47826954585156944,
            "precision": 0.6883720930232559,
            "recall": 0.30833333333333335
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6738322954643219,
            "auditor_fn_violation": 0.07317965605561656,
            "auditor_fp_violation": 0.03674891423662483,
            "ave_precision_score": 0.6003834312246925,
            "fpr": 0.07683863885839737,
            "logloss": 0.6664284659832821,
            "mae": 0.47658483093577864,
            "precision": 0.6929824561403509,
            "recall": 0.3333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.7382717611336033,
            "auditor_fn_violation": 0.0019668311403508924,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5632823043184886,
            "fpr": 0.005482456140350877,
            "logloss": 0.6806221881828124,
            "mae": 0.49167996448905843,
            "precision": 0.9038461538461539,
            "recall": 0.09791666666666667
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.7596896657665878,
            "auditor_fn_violation": 0.0007642179271630842,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.559791895996373,
            "fpr": 0.0021953896816684962,
            "logloss": 0.680024481662867,
            "mae": 0.4916445875272531,
            "precision": 0.9555555555555556,
            "recall": 0.09071729957805907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8496134277288239,
            "auditor_fn_violation": 0.010263614766081878,
            "auditor_fp_violation": 0.005482456140350881,
            "ave_precision_score": 0.8499024708485077,
            "fpr": 0.06359649122807018,
            "logloss": 0.5404683659524722,
            "mae": 0.30704164227905784,
            "precision": 0.847769028871391,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8427842641415402,
            "auditor_fn_violation": 0.007639863459730349,
            "auditor_fp_violation": 0.007909933761526426,
            "ave_precision_score": 0.8436949743034534,
            "fpr": 0.07244785949506037,
            "logloss": 0.5324602325816087,
            "mae": 0.29538209449538694,
            "precision": 0.8329113924050633,
            "recall": 0.6940928270042194
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8293098503572556,
            "auditor_fn_violation": 0.01963404605263158,
            "auditor_fp_violation": 0.015645305393112412,
            "ave_precision_score": 0.8297309031966114,
            "fpr": 0.09758771929824561,
            "logloss": 0.5328825278334354,
            "mae": 0.3177153781631332,
            "precision": 0.7949308755760369,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8303949320252015,
            "auditor_fn_violation": 0.014559509418407007,
            "auditor_fp_violation": 0.012629770388362929,
            "ave_precision_score": 0.8311698942940244,
            "fpr": 0.09110867178924259,
            "logloss": 0.5194677345978556,
            "mae": 0.3047311604677257,
            "precision": 0.8096330275229358,
            "recall": 0.7447257383966245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7965519939758999,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6362071625109141,
            "fpr": 0.006578947368421052,
            "logloss": 0.6294712367104917,
            "mae": 0.4444459308951832,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7934828837399,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.6466820616231426,
            "fpr": 0.012074643249176729,
            "logloss": 0.61329365902304,
            "mae": 0.4353342334751109,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 6933,
        "test": {
            "accuracy": 0.606359649122807,
            "auc_prc": 0.6421718709660295,
            "auditor_fn_violation": 0.08026772660818712,
            "auditor_fp_violation": 0.08158960769980508,
            "ave_precision_score": 0.6398194620070485,
            "fpr": 0.23355263157894737,
            "logloss": 0.6636214201573492,
            "mae": 0.4644341471670359,
            "precision": 0.6106032906764168,
            "recall": 0.6958333333333333
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6547407016756313,
            "auditor_fn_violation": 0.068214555340957,
            "auditor_fp_violation": 0.08207843619931326,
            "ave_precision_score": 0.6467012482248762,
            "fpr": 0.24368825466520308,
            "logloss": 0.6530701374313043,
            "mae": 0.45946452209703487,
            "precision": 0.6118881118881119,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8490688242545046,
            "auditor_fn_violation": 0.00973135964912281,
            "auditor_fp_violation": 0.005482456140350881,
            "ave_precision_score": 0.849358355565698,
            "fpr": 0.06359649122807018,
            "logloss": 0.5378547747265993,
            "mae": 0.3063964629773022,
            "precision": 0.8485639686684073,
            "recall": 0.6770833333333334
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8424138877343497,
            "auditor_fn_violation": 0.0072114382581389205,
            "auditor_fp_violation": 0.007909933761526426,
            "ave_precision_score": 0.8433442234209989,
            "fpr": 0.07244785949506037,
            "logloss": 0.5301201385003553,
            "mae": 0.294960780831107,
            "precision": 0.8333333333333334,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8415733664255137,
            "auditor_fn_violation": 0.0024259868421052625,
            "auditor_fp_violation": 0.02175976689408707,
            "ave_precision_score": 0.8418564044434771,
            "fpr": 0.23574561403508773,
            "logloss": 0.6273746769766223,
            "mae": 0.32063149511502653,
            "precision": 0.6624803767660911,
            "recall": 0.8791666666666667
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8311191264515658,
            "auditor_fn_violation": 0.008466608308206775,
            "auditor_fp_violation": 0.01347125270341894,
            "ave_precision_score": 0.8314765871300968,
            "fpr": 0.2414928649835346,
            "logloss": 0.6643807579724277,
            "mae": 0.3270689712396596,
            "precision": 0.6540880503144654,
            "recall": 0.8776371308016878
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7403589306314096,
            "auditor_fn_violation": 0.011376096491228069,
            "auditor_fp_violation": 0.001093953053931138,
            "ave_precision_score": 0.6856981046986789,
            "fpr": 0.23574561403508773,
            "logloss": 0.6349736163798312,
            "mae": 0.45621756310656403,
            "precision": 0.6160714285714286,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6983202747935928,
            "auditor_fn_violation": 0.007795022857063465,
            "auditor_fp_violation": 0.015633987847488245,
            "ave_precision_score": 0.650241168016833,
            "fpr": 0.2623490669593853,
            "logloss": 0.6363140703402526,
            "mae": 0.4550710068903168,
            "precision": 0.5685920577617328,
            "recall": 0.6645569620253164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.7806697494365319,
            "auditor_fn_violation": 0.007979258040935678,
            "auditor_fp_violation": 0.0034874512670565313,
            "ave_precision_score": 0.7076851834854088,
            "fpr": 0.02850877192982456,
            "logloss": 0.6148516014488367,
            "mae": 0.4294279337484847,
            "precision": 0.8693467336683417,
            "recall": 0.36041666666666666
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7649727173920028,
            "auditor_fn_violation": 0.012959283395165526,
            "auditor_fp_violation": 0.0019894149060428485,
            "ave_precision_score": 0.6935954690262847,
            "fpr": 0.029637760702524697,
            "logloss": 0.6048794886531361,
            "mae": 0.4235739301149984,
            "precision": 0.8669950738916257,
            "recall": 0.37130801687763715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.7419797898321795,
            "auditor_fn_violation": 0.002204404239766102,
            "auditor_fp_violation": 0.0004467186484730344,
            "ave_precision_score": 0.5686086324527794,
            "fpr": 0.005482456140350877,
            "logloss": 0.6745841692745741,
            "mae": 0.47920431791428936,
            "precision": 0.9074074074074074,
            "recall": 0.10208333333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7609437794248823,
            "auditor_fn_violation": 0.0035501396434576096,
            "auditor_fp_violation": 8.289228775178534e-05,
            "ave_precision_score": 0.5620237401117201,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6711425440885012,
            "mae": 0.4792796228772068,
            "precision": 0.9574468085106383,
            "recall": 0.0949367088607595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7425575642845926,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.663804994087506,
            "fpr": 0.006578947368421052,
            "logloss": 0.6287722800649361,
            "mae": 0.44686211145630006,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7415027611288569,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.6642351472880215,
            "fpr": 0.012074643249176729,
            "logloss": 0.6219573581137816,
            "mae": 0.44099045051701374,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6962880073058838,
            "auditor_fn_violation": 0.006332236842105268,
            "auditor_fp_violation": 0.0034620695256660184,
            "ave_precision_score": 0.6099369171544734,
            "fpr": 0.04057017543859649,
            "logloss": 0.652664390578089,
            "mae": 0.4561059754015061,
            "precision": 0.8082901554404145,
            "recall": 0.325
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7015746835271489,
            "auditor_fn_violation": 0.021092414789701138,
            "auditor_fp_violation": 0.002401364457294144,
            "ave_precision_score": 0.6094284988940607,
            "fpr": 0.04061470911086718,
            "logloss": 0.6548206568925758,
            "mae": 0.4548996716377895,
            "precision": 0.8082901554404145,
            "recall": 0.3291139240506329
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6359532081608515,
            "auditor_fn_violation": 0.011549707602339193,
            "auditor_fp_violation": 0.003614359974009096,
            "ave_precision_score": 0.546531884486497,
            "fpr": 0.03070175438596491,
            "logloss": 0.6934024818040968,
            "mae": 0.48822929994448233,
            "precision": 0.6853932584269663,
            "recall": 0.12708333333333333
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.6514609670353845,
            "auditor_fn_violation": 0.02697457701695638,
            "auditor_fp_violation": 0.008238991025025936,
            "ave_precision_score": 0.5493272431527401,
            "fpr": 0.03293084522502744,
            "logloss": 0.6884196575594322,
            "mae": 0.48424217153982585,
            "precision": 0.7087378640776699,
            "recall": 0.1540084388185654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.797422112924792,
            "auditor_fn_violation": 0.012097953216374269,
            "auditor_fp_violation": 0.002330043859649123,
            "ave_precision_score": 0.6360848693851441,
            "fpr": 0.006578947368421052,
            "logloss": 0.6258784733190822,
            "mae": 0.4430974285085604,
            "precision": 0.9508196721311475,
            "recall": 0.24166666666666667
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7907223634379447,
            "auditor_fn_violation": 0.007044699801303352,
            "auditor_fp_violation": 0.002315960282034731,
            "ave_precision_score": 0.642501184068248,
            "fpr": 0.012074643249176729,
            "logloss": 0.620372784999697,
            "mae": 0.4382901848605645,
            "precision": 0.9214285714285714,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8450166168704232,
            "auditor_fn_violation": 0.02894736842105264,
            "auditor_fp_violation": 0.01667580409356725,
            "ave_precision_score": 0.8452570951940941,
            "fpr": 0.10855263157894737,
            "logloss": 0.517092454267782,
            "mae": 0.31870477286180465,
            "precision": 0.7804878048780488,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8453740133819277,
            "auditor_fn_violation": 0.023952442486811453,
            "auditor_fp_violation": 0.016638742850540185,
            "ave_precision_score": 0.8457907170299546,
            "fpr": 0.10208562019758508,
            "logloss": 0.5054214593909487,
            "mae": 0.31100229684916914,
            "precision": 0.7942477876106194,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8177122711429036,
            "auditor_fn_violation": 0.017859100877192984,
            "auditor_fp_violation": 0.018574358349577658,
            "ave_precision_score": 0.818005374829714,
            "fpr": 0.16885964912280702,
            "logloss": 0.5492482612072696,
            "mae": 0.33614852505617593,
            "precision": 0.7148148148148148,
            "recall": 0.8041666666666667
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8334635255268541,
            "auditor_fn_violation": 0.02033746011014001,
            "auditor_fp_violation": 0.016480493937559505,
            "ave_precision_score": 0.8347233034481204,
            "fpr": 0.15587266739846323,
            "logloss": 0.5309345043393382,
            "mae": 0.3234976499017357,
            "precision": 0.7350746268656716,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8411453716634274,
            "auditor_fn_violation": 0.030439053362573104,
            "auditor_fp_violation": 0.01887640107212476,
            "ave_precision_score": 0.8413912318661116,
            "fpr": 0.12171052631578948,
            "logloss": 0.5221366674964883,
            "mae": 0.3218947278454786,
            "precision": 0.7607758620689655,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8424834966989303,
            "auditor_fn_violation": 0.02974891967374842,
            "auditor_fp_violation": 0.020253348974019546,
            "ave_precision_score": 0.8429050089568411,
            "fpr": 0.11525795828759605,
            "logloss": 0.5096056422845244,
            "mae": 0.3129989967291745,
            "precision": 0.7761194029850746,
            "recall": 0.7679324894514767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5983427472592038,
            "auditor_fn_violation": 0.008022660818713473,
            "auditor_fp_violation": 0.005193104288499025,
            "ave_precision_score": 0.5651280017419434,
            "fpr": 0.041666666666666664,
            "logloss": 0.6837392883903987,
            "mae": 0.48353968900546695,
            "precision": 0.5957446808510638,
            "recall": 0.11666666666666667
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.6041920308053796,
            "auditor_fn_violation": 0.004430148165645401,
            "auditor_fp_violation": 0.010235941593591674,
            "ave_precision_score": 0.5647899719063525,
            "fpr": 0.04061470911086718,
            "logloss": 0.6782216642170203,
            "mae": 0.483127871080497,
            "precision": 0.5978260869565217,
            "recall": 0.1160337552742616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8422770522853467,
            "auditor_fn_violation": 0.019247989766081868,
            "auditor_fp_violation": 0.02144249512670566,
            "ave_precision_score": 0.8424975217264434,
            "fpr": 0.15679824561403508,
            "logloss": 0.5322718237748039,
            "mae": 0.3257474809008847,
            "precision": 0.7276190476190476,
            "recall": 0.7958333333333333
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8447101726093698,
            "auditor_fn_violation": 0.019142501169485016,
            "auditor_fp_violation": 0.018273981618007223,
            "ave_precision_score": 0.8454418515740593,
            "fpr": 0.13830954994511527,
            "logloss": 0.5098176147690809,
            "mae": 0.3099710884034781,
            "precision": 0.7519685039370079,
            "recall": 0.8059071729957806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7712206410222364,
            "auditor_fn_violation": 0.009269919590643291,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.6641977637555723,
            "fpr": 0.003289473684210526,
            "logloss": 0.6346252283054682,
            "mae": 0.448486466091453,
            "precision": 0.97,
            "recall": 0.20208333333333334
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.7459593261629421,
            "auditor_fn_violation": 0.008221132246754395,
            "auditor_fp_violation": 0.0006656501895219125,
            "ave_precision_score": 0.643110379463424,
            "fpr": 0.003293084522502744,
            "logloss": 0.6337960753340182,
            "mae": 0.44661199392262196,
            "precision": 0.9719626168224299,
            "recall": 0.21940928270042195
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8291001983906133,
            "auditor_fn_violation": 0.015803179824561406,
            "auditor_fp_violation": 0.015145285087719298,
            "ave_precision_score": 0.8293481196285482,
            "fpr": 0.08881578947368421,
            "logloss": 0.5565850014398471,
            "mae": 0.33411752081807017,
            "precision": 0.7985074626865671,
            "recall": 0.66875
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8301331012395756,
            "auditor_fn_violation": 0.015469623495301218,
            "auditor_fp_violation": 0.012840768939003835,
            "ave_precision_score": 0.8306488832295384,
            "fpr": 0.08232711306256861,
            "logloss": 0.5388487550829726,
            "mae": 0.32002391163684,
            "precision": 0.8138957816377171,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8287094480447912,
            "auditor_fn_violation": 0.0171326754385965,
            "auditor_fp_violation": 0.017584470435347627,
            "ave_precision_score": 0.8291139035920163,
            "fpr": 0.08333333333333333,
            "logloss": 0.5452684677112589,
            "mae": 0.3273996494704318,
            "precision": 0.8109452736318408,
            "recall": 0.6791666666666667
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.827059186836816,
            "auditor_fn_violation": 0.014580351725511453,
            "auditor_fp_violation": 0.01117789940895287,
            "ave_precision_score": 0.8284833345810814,
            "fpr": 0.08232711306256861,
            "logloss": 0.5294622555844534,
            "mae": 0.31306968125771284,
            "precision": 0.8157248157248157,
            "recall": 0.70042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6558234730757144,
            "auditor_fn_violation": 0.003951937134502925,
            "auditor_fp_violation": 0.01506406351526965,
            "ave_precision_score": 0.538921732101652,
            "fpr": 0.3607456140350877,
            "logloss": 8.831043725786813,
            "mae": 0.4078219891409645,
            "precision": 0.5749354005167958,
            "recall": 0.9270833333333334
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6469551040308812,
            "auditor_fn_violation": 0.004870152426739292,
            "auditor_fp_violation": 0.005141833728118327,
            "ave_precision_score": 0.5200347463438945,
            "fpr": 0.3787047200878156,
            "logloss": 9.719137400520484,
            "mae": 0.43078139940831917,
            "precision": 0.5610687022900763,
            "recall": 0.930379746835443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 6933,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6528986289621568,
            "auditor_fn_violation": 0.01844846491228071,
            "auditor_fp_violation": 0.026196495289148813,
            "ave_precision_score": 0.5362194688190429,
            "fpr": 0.28399122807017546,
            "logloss": 9.000405529678487,
            "mae": 0.4437152451350457,
            "precision": 0.5632377740303541,
            "recall": 0.6958333333333333
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.6442858221171373,
            "auditor_fn_violation": 0.003042976837249373,
            "auditor_fp_violation": 0.012067107586653837,
            "ave_precision_score": 0.5179008368808715,
            "fpr": 0.3150384193194292,
            "logloss": 9.84739783183809,
            "mae": 0.45998730719640335,
            "precision": 0.5400641025641025,
            "recall": 0.7109704641350211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7739152458247597,
            "auditor_fn_violation": 0.03475877192982457,
            "auditor_fp_violation": 0.01137609649122807,
            "ave_precision_score": 0.6593034220546065,
            "fpr": 0.029605263157894735,
            "logloss": 0.6201426809606474,
            "mae": 0.43992588966431323,
            "precision": 0.8601036269430051,
            "recall": 0.3458333333333333
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7820115664818331,
            "auditor_fn_violation": 0.044023584228394634,
            "auditor_fp_violation": 0.012737781551191011,
            "ave_precision_score": 0.6652448123993869,
            "fpr": 0.029637760702524697,
            "logloss": 0.6113845416951961,
            "mae": 0.4343079390039036,
            "precision": 0.864321608040201,
            "recall": 0.3628691983122363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5108002690181002,
            "auditor_fn_violation": 0.008847313596491229,
            "auditor_fp_violation": 0.010713633040935682,
            "ave_precision_score": 0.5122552124060985,
            "fpr": 0.2993421052631579,
            "logloss": 1.3648717116011764,
            "mae": 0.46098574471490567,
            "precision": 0.5666666666666667,
            "recall": 0.74375
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.5191652291375473,
            "auditor_fn_violation": 0.00567373915621078,
            "auditor_fp_violation": 0.01937921212136437,
            "ave_precision_score": 0.5203826237150794,
            "fpr": 0.29747530186608123,
            "logloss": 1.3833220806036564,
            "mae": 0.44991428252166693,
            "precision": 0.5772230889235569,
            "recall": 0.7805907172995781
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.6536536696547913,
            "auditor_fn_violation": 0.01771290204678362,
            "auditor_fp_violation": 0.026544225146198846,
            "ave_precision_score": 0.5380287668111935,
            "fpr": 0.2817982456140351,
            "logloss": 8.938926680149677,
            "mae": 0.4492099630859323,
            "precision": 0.5568965517241379,
            "recall": 0.6729166666666667
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6455070549283796,
            "auditor_fn_violation": 0.008698189498256197,
            "auditor_fp_violation": 0.016907514813856588,
            "ave_precision_score": 0.5193774057218283,
            "fpr": 0.305159165751921,
            "logloss": 9.813269366962025,
            "mae": 0.46216580819082503,
            "precision": 0.5427631578947368,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.7069949432078058,
            "auditor_fn_violation": 0.09934895833333333,
            "auditor_fp_violation": 0.1023137995451592,
            "ave_precision_score": 0.5546659180896932,
            "fpr": 0.30043859649122806,
            "logloss": 0.6853864600414831,
            "mae": 0.4947366133462964,
            "precision": 0.5587761674718197,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7173965907886002,
            "auditor_fn_violation": 0.08452481855613761,
            "auditor_fp_violation": 0.10431617630436038,
            "ave_precision_score": 0.5581993909864648,
            "fpr": 0.30735455543358947,
            "logloss": 0.6847095066356411,
            "mae": 0.4945884759810832,
            "precision": 0.5631825273010921,
            "recall": 0.7616033755274262
        }
    }
]