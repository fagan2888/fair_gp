[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6867444933467961,
            "auditor_fn_violation": 0.125789748379299,
            "auditor_fp_violation": 0.10272071634050484,
            "ave_precision_score": 0.5618722138749314,
            "fpr": 0.19298245614035087,
            "logloss": 0.684326064491874,
            "mae": 0.4927679889165519,
            "precision": 0.5935334872979214,
            "recall": 0.5365344467640919
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6751738498276427,
            "auditor_fn_violation": 0.12589057715639262,
            "auditor_fp_violation": 0.10292651486923333,
            "ave_precision_score": 0.5468019932840942,
            "fpr": 0.21624588364434688,
            "logloss": 0.6881902319736773,
            "mae": 0.49463510860072535,
            "precision": 0.5679824561403509,
            "recall": 0.5452631578947369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.6037493681417931,
            "auditor_fn_violation": 0.005471010511665403,
            "auditor_fp_violation": 0.012036080385721813,
            "ave_precision_score": 0.5508887804020471,
            "fpr": 0.12390350877192982,
            "logloss": 4.055519948200183,
            "mae": 0.4849764089377826,
            "precision": 0.5515873015873016,
            "recall": 0.29018789144050106
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5958436549390751,
            "auditor_fn_violation": 0.012247963487203202,
            "auditor_fp_violation": 0.009642594588062313,
            "ave_precision_score": 0.5366043955546433,
            "fpr": 0.150384193194292,
            "logloss": 4.489563266723317,
            "mae": 0.49560642252245796,
            "precision": 0.5159010600706714,
            "recall": 0.30736842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6157774371310386,
            "auditor_fn_violation": 0.010882503754166219,
            "auditor_fp_violation": 0.008625055710870718,
            "ave_precision_score": 0.5810417513179675,
            "fpr": 0.12609649122807018,
            "logloss": 9.602520954997257,
            "mae": 0.46354127259540234,
            "precision": 0.5993031358885017,
            "recall": 0.35908141962421714
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5765765559734377,
            "auditor_fn_violation": 0.006412848806979027,
            "auditor_fp_violation": 0.008721135157453753,
            "ave_precision_score": 0.5407862964525276,
            "fpr": 0.13172338090010977,
            "logloss": 11.29898259402352,
            "mae": 0.49888574382944567,
            "precision": 0.550561797752809,
            "recall": 0.3094736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 8653,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.140431900397168,
            "mae": 0.5252192982456141,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.008692412275053,
            "mae": 0.5214050493962679,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 8653,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5654899556744158,
            "auditor_fn_violation": 0.0680854667985203,
            "auditor_fp_violation": 0.06454104371783964,
            "ave_precision_score": 0.5610414745604028,
            "fpr": 0.3333333333333333,
            "logloss": 0.6922338321718435,
            "mae": 0.49939459627657606,
            "precision": 0.5227629513343799,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5177328762682357,
            "auditor_fn_violation": 0.07619157663643192,
            "auditor_fp_violation": 0.06529773713733272,
            "ave_precision_score": 0.517087741640144,
            "fpr": 0.3260153677277717,
            "logloss": 0.6929568110894195,
            "mae": 0.4997549535937681,
            "precision": 0.5170731707317073,
            "recall": 0.6694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.5779361860198666,
            "auditor_fn_violation": 0.08467933926674726,
            "auditor_fp_violation": 0.024201308698999235,
            "ave_precision_score": 0.5792658766759476,
            "fpr": 0.049342105263157895,
            "logloss": 0.6877864381913223,
            "mae": 0.49700515664983214,
            "precision": 0.7513812154696132,
            "recall": 0.2839248434237996
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.5864461626833641,
            "auditor_fn_violation": 0.08463804956958809,
            "auditor_fp_violation": 0.027301382692675662,
            "ave_precision_score": 0.5875163843796245,
            "fpr": 0.05159165751920966,
            "logloss": 0.6872234486337958,
            "mae": 0.49671477164447503,
            "precision": 0.7486631016042781,
            "recall": 0.29473684210526313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 8653,
        "test": {
            "accuracy": 0.506578947368421,
            "auc_prc": 0.5654899556744158,
            "auditor_fn_violation": 0.0680854667985203,
            "auditor_fp_violation": 0.06454104371783964,
            "ave_precision_score": 0.5610414745604028,
            "fpr": 0.3333333333333333,
            "logloss": 0.6922337396659787,
            "mae": 0.4993943761903466,
            "precision": 0.5227629513343799,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5177328762682357,
            "auditor_fn_violation": 0.07619157663643192,
            "auditor_fp_violation": 0.06529773713733272,
            "ave_precision_score": 0.517087741640144,
            "fpr": 0.3260153677277717,
            "logloss": 0.692957569403309,
            "mae": 0.49975514503525065,
            "precision": 0.5170731707317073,
            "recall": 0.6694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.6125762986873738,
            "auditor_fn_violation": 0.005471010511665403,
            "auditor_fp_violation": 0.012036080385721813,
            "ave_precision_score": 0.5594001542181221,
            "fpr": 0.12390350877192982,
            "logloss": 4.0495662180528536,
            "mae": 0.48496743807928605,
            "precision": 0.5515873015873016,
            "recall": 0.29018789144050106
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.604433530762855,
            "auditor_fn_violation": 0.010399214281587632,
            "auditor_fp_violation": 0.009642594588062313,
            "ave_precision_score": 0.5450071124603465,
            "fpr": 0.150384193194292,
            "logloss": 4.481316251003161,
            "mae": 0.49552502364541773,
            "precision": 0.5141843971631206,
            "recall": 0.30526315789473685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.5516015953419711,
            "auditor_fn_violation": 0.006475936710251628,
            "auditor_fp_violation": 0.006285199141039667,
            "ave_precision_score": 0.5684714050070858,
            "fpr": 0.10635964912280702,
            "logloss": 0.691112893918648,
            "mae": 0.49865536002867056,
            "precision": 0.6008230452674898,
            "recall": 0.3048016701461378
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.52794349464282,
            "auditor_fn_violation": 0.012296493153850601,
            "auditor_fp_violation": 0.012361655202972839,
            "ave_precision_score": 0.5563711766460725,
            "fpr": 0.1251372118551043,
            "logloss": 0.6912252248184241,
            "mae": 0.4986908124712767,
            "precision": 0.5632183908045977,
            "recall": 0.3094736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.4721906721370731,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4833201557434106,
            "fpr": 0.47478070175438597,
            "logloss": 0.6929270280262344,
            "mae": 0.49957995123246257,
            "precision": 0.5252192982456141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.5006242164781383,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5138442014218692,
            "fpr": 0.47859495060373214,
            "logloss": 0.6922026940163463,
            "mae": 0.4992053336683665,
            "precision": 0.5214050493962679,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.6307968559192023,
            "auditor_fn_violation": 0.008146998498333531,
            "auditor_fp_violation": 0.010899072160771446,
            "ave_precision_score": 0.5776186184657959,
            "fpr": 0.13925438596491227,
            "logloss": 4.051555710960168,
            "mae": 0.48320461077648297,
            "precision": 0.5808580858085809,
            "recall": 0.3674321503131524
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6224864839888361,
            "auditor_fn_violation": 0.015229071581258326,
            "auditor_fp_violation": 0.01285007905416973,
            "ave_precision_score": 0.5630460934133265,
            "fpr": 0.1602634467618002,
            "logloss": 4.484828156691884,
            "mae": 0.4938569727438603,
            "precision": 0.5521472392638037,
            "recall": 0.37894736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6601941628853918,
            "auditor_fn_violation": 0.006562923488261379,
            "auditor_fp_violation": 0.012580527531299382,
            "ave_precision_score": 0.6552017402931252,
            "fpr": 0.04057017543859649,
            "logloss": 9.381755501343568,
            "mae": 0.4460836169061224,
            "precision": 0.7672955974842768,
            "recall": 0.2546972860125261
        },
        "train": {
            "accuracy": 0.5422612513721186,
            "auc_prc": 0.6105445610322213,
            "auditor_fn_violation": 0.003965567046045414,
            "auditor_fp_violation": 0.0076536521012296205,
            "ave_precision_score": 0.6066417153522838,
            "fpr": 0.043907793633369926,
            "logloss": 10.782944144675914,
            "mae": 0.4724354339751781,
            "precision": 0.7101449275362319,
            "recall": 0.2063157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.666124851612726,
            "auditor_fn_violation": 0.006450756327143545,
            "auditor_fp_violation": 0.007427271990600057,
            "ave_precision_score": 0.6607689708835446,
            "fpr": 0.03070175438596491,
            "logloss": 9.412887891060747,
            "mae": 0.44633679376936186,
            "precision": 0.8108108108108109,
            "recall": 0.25052192066805845
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.6135662429706887,
            "auditor_fn_violation": 0.002163036570570228,
            "auditor_fp_violation": 0.004934591486319096,
            "ave_precision_score": 0.6094966802906012,
            "fpr": 0.026344676180021953,
            "logloss": 10.814270126564129,
            "mae": 0.4749421027825668,
            "precision": 0.7876106194690266,
            "recall": 0.18736842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8104779516218175,
            "auditor_fn_violation": 0.011608156612826439,
            "auditor_fp_violation": 0.013806166686925173,
            "ave_precision_score": 0.8119151587206586,
            "fpr": 0.09758771929824561,
            "logloss": 1.0197120175432826,
            "mae": 0.2851620011379543,
            "precision": 0.78239608801956,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8706394961025303,
            "auditor_fn_violation": 0.016419203882373334,
            "auditor_fp_violation": 0.0023816956867642168,
            "ave_precision_score": 0.870793413151729,
            "fpr": 0.07574094401756312,
            "logloss": 0.8672556858955784,
            "mae": 0.2587767739542466,
            "precision": 0.8292079207920792,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7290837001096027,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6793194286515688,
            "fpr": 0.015350877192982455,
            "logloss": 0.621157606964559,
            "mae": 0.4325788853722706,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7008989303631912,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6539473849589205,
            "fpr": 0.019758507135016465,
            "logloss": 0.6313594748406618,
            "mae": 0.43933608918629674,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7289800502984647,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.679202740327088,
            "fpr": 0.015350877192982455,
            "logloss": 0.622199872718046,
            "mae": 0.4328350319380039,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7007739371893174,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6537890843595271,
            "fpr": 0.019758507135016465,
            "logloss": 0.6324030984462534,
            "mae": 0.43959258868063583,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7833337667703839,
            "auditor_fn_violation": 0.011088525070505088,
            "auditor_fp_violation": 0.0026715894817876114,
            "ave_precision_score": 0.7567886393890567,
            "fpr": 0.046052631578947366,
            "logloss": 0.6049424362541146,
            "mae": 0.43085478401432437,
            "precision": 0.832,
            "recall": 0.4342379958246347
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7662494284737703,
            "auditor_fn_violation": 0.006264948870529798,
            "auditor_fp_violation": 0.005314756442663069,
            "ave_precision_score": 0.7362826820024021,
            "fpr": 0.042810098792535674,
            "logloss": 0.6213311018169532,
            "mae": 0.4395310167063735,
            "precision": 0.8125,
            "recall": 0.35578947368421054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8104827117459703,
            "auditor_fn_violation": 0.011608156612826439,
            "auditor_fp_violation": 0.013806166686925173,
            "ave_precision_score": 0.8119199136765756,
            "fpr": 0.09758771929824561,
            "logloss": 1.0197101815359446,
            "mae": 0.2851617804302048,
            "precision": 0.78239608801956,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8706394961025303,
            "auditor_fn_violation": 0.016419203882373334,
            "auditor_fp_violation": 0.0023816956867642168,
            "ave_precision_score": 0.870793413151729,
            "fpr": 0.07574094401756312,
            "logloss": 0.8672537704519048,
            "mae": 0.2587766622129793,
            "precision": 0.8292079207920792,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6830380083833784,
            "auditor_fn_violation": 0.017047119364172452,
            "auditor_fp_violation": 0.013350350472023018,
            "ave_precision_score": 0.6665149559634387,
            "fpr": 0.0581140350877193,
            "logloss": 1.0243911378983048,
            "mae": 0.4568068080238606,
            "precision": 0.6826347305389222,
            "recall": 0.23799582463465555
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6839269023802649,
            "auditor_fn_violation": 0.016613322548962976,
            "auditor_fp_violation": 0.016163304766412555,
            "ave_precision_score": 0.6707024099961364,
            "fpr": 0.06037321624588365,
            "logloss": 0.8713959811898908,
            "mae": 0.44902934259954846,
            "precision": 0.6927374301675978,
            "recall": 0.26105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6799573841604301,
            "auditor_fn_violation": 0.006299674028495046,
            "auditor_fp_violation": 0.007414610429074999,
            "ave_precision_score": 0.6593156233214228,
            "fpr": 0.14473684210526316,
            "logloss": 1.0245491482717115,
            "mae": 0.4593652663589047,
            "precision": 0.5643564356435643,
            "recall": 0.3569937369519833
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6797472776241265,
            "auditor_fn_violation": 0.005664105378704719,
            "auditor_fp_violation": 0.010143606682846772,
            "ave_precision_score": 0.6596355172391353,
            "fpr": 0.1525795828759605,
            "logloss": 0.87400352019339,
            "mae": 0.4522504718191145,
            "precision": 0.5516129032258065,
            "recall": 0.36
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6786333527075586,
            "auditor_fn_violation": 0.006299674028495046,
            "auditor_fp_violation": 0.007414610429074999,
            "ave_precision_score": 0.6605499461770669,
            "fpr": 0.14473684210526316,
            "logloss": 1.0246534831710836,
            "mae": 0.45928159565256355,
            "precision": 0.5643564356435643,
            "recall": 0.3569937369519833
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.6784456402033947,
            "auditor_fn_violation": 0.005664105378704719,
            "auditor_fp_violation": 0.010143606682846772,
            "ave_precision_score": 0.6610448532265731,
            "fpr": 0.1525795828759605,
            "logloss": 0.8722818211868386,
            "mae": 0.45211143188104935,
            "precision": 0.5516129032258065,
            "recall": 0.36
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7931841419251874,
            "auditor_fn_violation": 0.007048218144526239,
            "auditor_fp_violation": 0.01064584093027025,
            "ave_precision_score": 0.7946532489046017,
            "fpr": 0.08991228070175439,
            "logloss": 0.9785644310871827,
            "mae": 0.3209372508553649,
            "precision": 0.7807486631016043,
            "recall": 0.6096033402922756
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8420389172945515,
            "auditor_fn_violation": 0.0012571494598186007,
            "auditor_fp_violation": 0.011636572372330036,
            "ave_precision_score": 0.8422339585993105,
            "fpr": 0.08122941822173436,
            "logloss": 0.8077885504906102,
            "mae": 0.29974649244832197,
            "precision": 0.8031914893617021,
            "recall": 0.6357894736842106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.6798770974013468,
            "auditor_fn_violation": 0.006299674028495046,
            "auditor_fp_violation": 0.007414610429074999,
            "ave_precision_score": 0.6591286691856629,
            "fpr": 0.14473684210526316,
            "logloss": 1.024607678977718,
            "mae": 0.4593080288420121,
            "precision": 0.5643564356435643,
            "recall": 0.3569937369519833
        },
        "train": {
            "accuracy": 0.5137211855104281,
            "auc_prc": 0.679937752418368,
            "auditor_fn_violation": 0.005664105378704719,
            "auditor_fp_violation": 0.010143606682846772,
            "ave_precision_score": 0.6596845337854008,
            "fpr": 0.1525795828759605,
            "logloss": 0.8728288834605843,
            "mae": 0.4521562559479024,
            "precision": 0.5516129032258065,
            "recall": 0.36
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7935326967153766,
            "auditor_fn_violation": 0.006471358458777423,
            "auditor_fp_violation": 0.009174567481058306,
            "ave_precision_score": 0.7950041242938397,
            "fpr": 0.09539473684210527,
            "logloss": 0.9535868082337189,
            "mae": 0.31920351577075834,
            "precision": 0.7763496143958869,
            "recall": 0.6304801670146137
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8434265861025277,
            "auditor_fn_violation": 0.00039054826968629505,
            "auditor_fp_violation": 0.011002124895517579,
            "ave_precision_score": 0.8436184672673015,
            "fpr": 0.0867178924259056,
            "logloss": 0.7774759618389129,
            "mae": 0.2979022591754118,
            "precision": 0.7958656330749354,
            "recall": 0.6484210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8079830988532449,
            "auditor_fn_violation": 0.01570340255649563,
            "auditor_fp_violation": 0.015778837972529474,
            "ave_precision_score": 0.8094080928710339,
            "fpr": 0.10416666666666667,
            "logloss": 0.9354852082581386,
            "mae": 0.28445420006779154,
            "precision": 0.7754137115839244,
            "recall": 0.6847599164926931
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8737675503826613,
            "auditor_fn_violation": 0.010383037726038477,
            "auditor_fp_violation": 0.006425039527084865,
            "ave_precision_score": 0.873926634541075,
            "fpr": 0.0801317233809001,
            "logloss": 0.7550729558515417,
            "mae": 0.2530732225476019,
            "precision": 0.8261904761904761,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.730960166688722,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6800001390552834,
            "fpr": 0.015350877192982455,
            "logloss": 0.6174014746623079,
            "mae": 0.4315794041184218,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.696542837545715,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.647607550245642,
            "fpr": 0.019758507135016465,
            "logloss": 0.6368676645977023,
            "mae": 0.4432324720331918,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7292980587403701,
            "auditor_fn_violation": 0.005200893674687782,
            "auditor_fp_violation": 0.004358109476925571,
            "ave_precision_score": 0.6789627283399305,
            "fpr": 0.01425438596491228,
            "logloss": 0.6135048492148701,
            "mae": 0.42362029047012983,
            "precision": 0.9202453987730062,
            "recall": 0.31315240083507306
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7066525455977016,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.003363578686593018,
            "ave_precision_score": 0.656976318343065,
            "fpr": 0.015367727771679473,
            "logloss": 0.6219059275649714,
            "mae": 0.4308544169604353,
            "precision": 0.900709219858156,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7935406712625072,
            "auditor_fn_violation": 0.006471358458777423,
            "auditor_fp_violation": 0.009174567481058306,
            "ave_precision_score": 0.7950120955369109,
            "fpr": 0.09539473684210527,
            "logloss": 0.9536332296109014,
            "mae": 0.3192112814768646,
            "precision": 0.7763496143958869,
            "recall": 0.6304801670146137
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8434592784024451,
            "auditor_fn_violation": 0.00039054826968629505,
            "auditor_fp_violation": 0.011002124895517579,
            "ave_precision_score": 0.8436510631753062,
            "fpr": 0.0867178924259056,
            "logloss": 0.7775450270498351,
            "mae": 0.2979152577067374,
            "precision": 0.7958656330749354,
            "recall": 0.6484210526315789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.6578653139099582,
            "auditor_fn_violation": 0.010335402702999673,
            "auditor_fp_violation": 0.01446456788622828,
            "ave_precision_score": 0.6558127738040276,
            "fpr": 0.19078947368421054,
            "logloss": 9.843699247065771,
            "mae": 0.45886357746775025,
            "precision": 0.5745721271393643,
            "recall": 0.4906054279749478
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.6048267690928228,
            "auditor_fn_violation": 0.005361372696285194,
            "auditor_fp_violation": 0.022286226447396248,
            "ave_precision_score": 0.6059574586435628,
            "fpr": 0.1877058177826564,
            "logloss": 11.220041934654681,
            "mae": 0.49532808962095903,
            "precision": 0.5327868852459017,
            "recall": 0.4105263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6601105531274273,
            "auditor_fn_violation": 0.006386660806504805,
            "auditor_fp_violation": 0.009703820752805802,
            "ave_precision_score": 0.6548202022033196,
            "fpr": 0.04057017543859649,
            "logloss": 9.45181220471318,
            "mae": 0.4462519204824852,
            "precision": 0.7701863354037267,
            "recall": 0.2588726513569937
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6060335391485897,
            "auditor_fn_violation": 0.0064405800450632695,
            "auditor_fp_violation": 0.008016193516551024,
            "ave_precision_score": 0.6024865362953011,
            "fpr": 0.04610318331503842,
            "logloss": 10.874853316980408,
            "mae": 0.4758237223165314,
            "precision": 0.6865671641791045,
            "recall": 0.1936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7921222290452262,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6496595151460802,
            "fpr": 0.015350877192982455,
            "logloss": 0.6193919519368172,
            "mae": 0.434464167672814,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7666112115126004,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6270688176370907,
            "fpr": 0.019758507135016465,
            "logloss": 0.6320240305331593,
            "mae": 0.44149770369317737,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.734555108609855,
            "auditor_fn_violation": 0.0006226422004907885,
            "auditor_fp_violation": 0.0021474008346501518,
            "ave_precision_score": 0.7001302110948371,
            "fpr": 0.47039473684210525,
            "logloss": 0.7557868492936576,
            "mae": 0.44833785620223926,
            "precision": 0.5270121278941565,
            "recall": 0.9979123173277662
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.7015898027020485,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0038167554557447846,
            "ave_precision_score": 0.6688037412155139,
            "fpr": 0.4698133918770582,
            "logloss": 0.7692151614977654,
            "mae": 0.45441464159707207,
            "precision": 0.5260243632336655,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 8653,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7771997260133167,
            "auditor_fn_violation": 0.010589495659817611,
            "auditor_fp_violation": 0.015958632146185325,
            "ave_precision_score": 0.7785961785183935,
            "fpr": 0.14473684210526316,
            "logloss": 0.6064724695430287,
            "mae": 0.35704468604480527,
            "precision": 0.7079646017699115,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7980651352278709,
            "auditor_fn_violation": 0.010318331503841937,
            "auditor_fp_violation": 0.024677992729030505,
            "ave_precision_score": 0.798375946196042,
            "fpr": 0.145993413830955,
            "logloss": 0.584428446771693,
            "mae": 0.3526101080671619,
            "precision": 0.7158119658119658,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8051750068093073,
            "auditor_fn_violation": 0.009515895689118418,
            "auditor_fp_violation": 0.008584538713990522,
            "ave_precision_score": 0.8055899639168895,
            "fpr": 0.09868421052631579,
            "logloss": 0.9354475357715366,
            "mae": 0.30390854087568747,
            "precision": 0.781021897810219,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8552143305787014,
            "auditor_fn_violation": 0.015390837136749679,
            "auditor_fp_violation": 0.012243325713249882,
            "ave_precision_score": 0.8553881137492005,
            "fpr": 0.09330406147091108,
            "logloss": 0.7641607970708751,
            "mae": 0.2835984698472855,
            "precision": 0.7951807228915663,
            "recall": 0.6947368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8105073300846579,
            "auditor_fn_violation": 0.011608156612826439,
            "auditor_fp_violation": 0.013806166686925173,
            "ave_precision_score": 0.8119444872094054,
            "fpr": 0.09758771929824561,
            "logloss": 1.0194958320753646,
            "mae": 0.2851529613335341,
            "precision": 0.78239608801956,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8705941696775981,
            "auditor_fn_violation": 0.016419203882373334,
            "auditor_fp_violation": 0.0023816956867642168,
            "ave_precision_score": 0.8707481762838603,
            "fpr": 0.07574094401756312,
            "logloss": 0.8670948651245515,
            "mae": 0.258801579072406,
            "precision": 0.8292079207920792,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 8653,
        "test": {
            "accuracy": 0.4967105263157895,
            "auc_prc": 0.6360334995746976,
            "auditor_fn_violation": 0.0055877559242574135,
            "auditor_fp_violation": 0.013907459179125647,
            "ave_precision_score": 0.5155249371857269,
            "fpr": 0.34539473684210525,
            "logloss": 9.078704272552937,
            "mae": 0.482967550555865,
            "precision": 0.5153846153846153,
            "recall": 0.6993736951983298
        },
        "train": {
            "accuracy": 0.5203073545554336,
            "auc_prc": 0.6632540353237548,
            "auditor_fn_violation": 0.005474608585129133,
            "auditor_fp_violation": 0.0036757671275642243,
            "ave_precision_score": 0.5440696731540955,
            "fpr": 0.31833150384193193,
            "logloss": 8.272721691121074,
            "mae": 0.4713108553321118,
            "precision": 0.5307443365695793,
            "recall": 0.6905263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6177940872862557,
            "auditor_fn_violation": 0.009291561366882773,
            "auditor_fp_violation": 0.009407540213119408,
            "ave_precision_score": 0.6089179381850662,
            "fpr": 0.04276315789473684,
            "logloss": 1.0395158318141005,
            "mae": 0.45827585407491905,
            "precision": 0.7214285714285714,
            "recall": 0.21085594989561587
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6337460778739347,
            "auditor_fn_violation": 0.007834074758796007,
            "auditor_fp_violation": 0.005770450860532332,
            "ave_precision_score": 0.6272883002358686,
            "fpr": 0.030735455543358946,
            "logloss": 0.8888130549841803,
            "mae": 0.44845013338438633,
            "precision": 0.8041958041958042,
            "recall": 0.24210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7796311690006119,
            "auditor_fn_violation": 0.008037120462952789,
            "auditor_fp_violation": 0.01884040354928893,
            "ave_precision_score": 0.7189381698346532,
            "fpr": 0.125,
            "logloss": 3.8033147054449965,
            "mae": 0.28647801721751703,
            "precision": 0.7516339869281046,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8134536245291272,
            "auditor_fn_violation": 0.012042290138078457,
            "auditor_fp_violation": 0.016284151904853023,
            "ave_precision_score": 0.7581052553810972,
            "fpr": 0.1163556531284303,
            "logloss": 3.2769176982889845,
            "mae": 0.2627440220131051,
            "precision": 0.7690631808278867,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7814578816186898,
            "auditor_fn_violation": 0.0015497381240156829,
            "auditor_fp_violation": 0.01289959888173089,
            "ave_precision_score": 0.7817952915225604,
            "fpr": 0.14035087719298245,
            "logloss": 0.849744758477788,
            "mae": 0.359937711251527,
            "precision": 0.7223427331887202,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.820259263615204,
            "auditor_fn_violation": 0.009985556646831126,
            "auditor_fp_violation": 0.013726220807863124,
            "ave_precision_score": 0.8204879082906853,
            "fpr": 0.13062568605927552,
            "logloss": 0.6371307330154441,
            "mae": 0.34105213709988574,
            "precision": 0.7355555555555555,
            "recall": 0.6968421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8068015102249361,
            "auditor_fn_violation": 0.00992564919605904,
            "auditor_fp_violation": 0.014203739718812046,
            "ave_precision_score": 0.8082370096026712,
            "fpr": 0.11293859649122807,
            "logloss": 0.9485043013598521,
            "mae": 0.28086258888538873,
            "precision": 0.7669683257918553,
            "recall": 0.7077244258872651
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8715982275455478,
            "auditor_fn_violation": 0.013038303772603855,
            "auditor_fp_violation": 0.004156638032608587,
            "ave_precision_score": 0.8717558743406918,
            "fpr": 0.09110867178924259,
            "logloss": 0.7700684814634955,
            "mae": 0.2536446384010732,
            "precision": 0.8096330275229358,
            "recall": 0.7431578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8048115662552069,
            "auditor_fn_violation": 0.009948540453430037,
            "auditor_fp_violation": 0.010119119970827761,
            "ave_precision_score": 0.8052267837823087,
            "fpr": 0.10526315789473684,
            "logloss": 0.9307270161678517,
            "mae": 0.3038136721506217,
            "precision": 0.7730496453900709,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8542246083782684,
            "auditor_fn_violation": 0.018395054595874986,
            "auditor_fp_violation": 0.012356619905537821,
            "ave_precision_score": 0.8543990340096699,
            "fpr": 0.09659714599341383,
            "logloss": 0.7585422611928109,
            "mae": 0.2835163487990628,
            "precision": 0.7919621749408984,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7623236112036119,
            "auditor_fn_violation": 0.005535106032304151,
            "auditor_fp_violation": 0.0002051172967059702,
            "ave_precision_score": 0.7627538218353709,
            "fpr": 0.15789473684210525,
            "logloss": 0.8441425389435563,
            "mae": 0.3749434626226519,
            "precision": 0.6923076923076923,
            "recall": 0.6764091858037579
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.797505877465103,
            "auditor_fn_violation": 0.017320469120110926,
            "auditor_fp_violation": 0.011216125036505906,
            "ave_precision_score": 0.7978113136851153,
            "fpr": 0.132821075740944,
            "logloss": 0.6418203804646692,
            "mae": 0.3543977249727066,
            "precision": 0.737527114967462,
            "recall": 0.7157894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8111450656180583,
            "auditor_fn_violation": 0.0084857891074241,
            "auditor_fp_violation": 0.014282241400267416,
            "ave_precision_score": 0.8125377828614762,
            "fpr": 0.09978070175438597,
            "logloss": 0.8868586495403898,
            "mae": 0.286683865416519,
            "precision": 0.78125,
            "recall": 0.6784968684759917
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8751942374162726,
            "auditor_fn_violation": 0.010214339361026063,
            "auditor_fp_violation": 0.004410920553077074,
            "ave_precision_score": 0.8753473278097772,
            "fpr": 0.07903402854006586,
            "logloss": 0.7134907377190187,
            "mae": 0.25663774383245963,
            "precision": 0.8273381294964028,
            "recall": 0.7263157894736842
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7974526337866132,
            "auditor_fn_violation": 0.0005585466798520365,
            "auditor_fp_violation": 0.011704347473765251,
            "ave_precision_score": 0.7989482099879827,
            "fpr": 0.10197368421052631,
            "logloss": 0.9203673109669795,
            "mae": 0.3091699099572088,
            "precision": 0.7692307692307693,
            "recall": 0.6471816283924844
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8543291626449894,
            "auditor_fn_violation": 0.014831590502050957,
            "auditor_fp_violation": 0.014730762646149509,
            "ave_precision_score": 0.854502673410829,
            "fpr": 0.09769484083424808,
            "logloss": 0.736379623550756,
            "mae": 0.2862103781961148,
            "precision": 0.7834549878345499,
            "recall": 0.6778947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8150755717896643,
            "auditor_fn_violation": 0.008833736219463062,
            "auditor_fp_violation": 0.013471901462663595,
            "ave_precision_score": 0.8164922160687125,
            "fpr": 0.1074561403508772,
            "logloss": 0.9513330312874247,
            "mae": 0.28498321824605516,
            "precision": 0.772093023255814,
            "recall": 0.6931106471816284
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8738943454119799,
            "auditor_fn_violation": 0.01583453694609741,
            "auditor_fp_violation": 0.009144100141995386,
            "ave_precision_score": 0.8740363089365024,
            "fpr": 0.0889132821075741,
            "logloss": 0.7909955402718376,
            "mae": 0.2579946543033502,
            "precision": 0.8089622641509434,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7937464888069329,
            "auditor_fn_violation": 0.005530527780829955,
            "auditor_fp_violation": 0.009174567481058306,
            "ave_precision_score": 0.7952199601556567,
            "fpr": 0.09539473684210527,
            "logloss": 0.9518447969008685,
            "mae": 0.3178606337217012,
            "precision": 0.7757731958762887,
            "recall": 0.6283924843423799
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.84472215576749,
            "auditor_fn_violation": 0.00350800161765556,
            "auditor_fp_violation": 0.011002124895517579,
            "ave_precision_score": 0.8449112284627728,
            "fpr": 0.0867178924259056,
            "logloss": 0.7731095528716989,
            "mae": 0.2956713521104849,
            "precision": 0.7974358974358975,
            "recall": 0.6547368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.816076830480425,
            "auditor_fn_violation": 0.007899772918726889,
            "auditor_fp_violation": 0.011904400145861194,
            "ave_precision_score": 0.8174953435538941,
            "fpr": 0.07236842105263158,
            "logloss": 0.9529352418718208,
            "mae": 0.2932477869807198,
            "precision": 0.8186813186813187,
            "recall": 0.6221294363256785
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.872110856382542,
            "auditor_fn_violation": 0.0186816107227454,
            "auditor_fp_violation": 0.0054330859323860285,
            "ave_precision_score": 0.87225620091501,
            "fpr": 0.054884742041712405,
            "logloss": 0.9045310700689231,
            "mae": 0.26361632077283464,
            "precision": 0.8614958448753463,
            "recall": 0.6547368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7853918075849977,
            "auditor_fn_violation": 0.011887429952752467,
            "auditor_fp_violation": 0.00499118755317856,
            "ave_precision_score": 0.7855766290816186,
            "fpr": 0.041666666666666664,
            "logloss": 0.5988924368349016,
            "mae": 0.4279969275618593,
            "precision": 0.8429752066115702,
            "recall": 0.42588726513569936
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7690311610044763,
            "auditor_fn_violation": 0.006264948870529798,
            "auditor_fp_violation": 0.005332379983685639,
            "ave_precision_score": 0.7692407429304701,
            "fpr": 0.04061470911086718,
            "logloss": 0.617641943679569,
            "mae": 0.4377987909199247,
            "precision": 0.8203883495145631,
            "recall": 0.35578947368421054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8054163264119198,
            "auditor_fn_violation": 0.005150532908471607,
            "auditor_fp_violation": 0.010521757627324662,
            "ave_precision_score": 0.8058218230168506,
            "fpr": 0.10635964912280702,
            "logloss": 0.9140967164592007,
            "mae": 0.30382013055498447,
            "precision": 0.7744186046511627,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8545860956096911,
            "auditor_fn_violation": 0.014618984343405167,
            "auditor_fp_violation": 0.012512714126023427,
            "ave_precision_score": 0.8547584538222793,
            "fpr": 0.09879253567508232,
            "logloss": 0.7424401077547065,
            "mae": 0.28427239311701336,
            "precision": 0.7902097902097902,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7794673221720662,
            "auditor_fn_violation": 0.002852250668424721,
            "auditor_fp_violation": 0.010222944775333248,
            "ave_precision_score": 0.7798847543141967,
            "fpr": 0.15899122807017543,
            "logloss": 0.8505713621674654,
            "mae": 0.36411181470963094,
            "precision": 0.7016460905349794,
            "recall": 0.7118997912317327
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8151757573544789,
            "auditor_fn_violation": 0.006278814489571901,
            "auditor_fp_violation": 0.010171300818739371,
            "ave_precision_score": 0.8154072127554641,
            "fpr": 0.14270032930845225,
            "logloss": 0.6440918575834891,
            "mae": 0.3467964156512652,
            "precision": 0.7222222222222222,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7974493415900875,
            "auditor_fn_violation": 0.0005585466798520365,
            "auditor_fp_violation": 0.011704347473765251,
            "ave_precision_score": 0.7989449329704612,
            "fpr": 0.10197368421052631,
            "logloss": 0.920374761112576,
            "mae": 0.3091716111579301,
            "precision": 0.7692307692307693,
            "recall": 0.6471816283924844
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8543291626449894,
            "auditor_fn_violation": 0.014831590502050957,
            "auditor_fp_violation": 0.014730762646149509,
            "ave_precision_score": 0.854502673410829,
            "fpr": 0.09769484083424808,
            "logloss": 0.7363849296638392,
            "mae": 0.28621152007162187,
            "precision": 0.7834549878345499,
            "recall": 0.6778947368421052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.6772712029767093,
            "auditor_fn_violation": 0.010653591180456369,
            "auditor_fp_violation": 0.003925084072768525,
            "ave_precision_score": 0.674906972769626,
            "fpr": 0.05701754385964912,
            "logloss": 8.915290721616945,
            "mae": 0.4350674841963021,
            "precision": 0.7450980392156863,
            "recall": 0.3173277661795407
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.626402491552042,
            "auditor_fn_violation": 0.007022936044832186,
            "auditor_fp_violation": 0.01061188934430357,
            "ave_precision_score": 0.6269423196640193,
            "fpr": 0.05159165751920966,
            "logloss": 10.293099027500451,
            "mae": 0.469098780618137,
            "precision": 0.7151515151515152,
            "recall": 0.24842105263157896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.5084804407551899,
            "auditor_fn_violation": 0.002833937662527935,
            "auditor_fp_violation": 0.007619727725780971,
            "ave_precision_score": 0.5419162061134899,
            "fpr": 0.36403508771929827,
            "logloss": 0.6909389103980265,
            "mae": 0.4984775931950201,
            "precision": 0.521613832853026,
            "recall": 0.755741127348643
        },
        "train": {
            "accuracy": 0.5049396267837541,
            "auc_prc": 0.5058332954226187,
            "auditor_fn_violation": 0.0028563175226760653,
            "auditor_fp_violation": 0.008106828870381375,
            "ave_precision_score": 0.527157603232347,
            "fpr": 0.3600439077936334,
            "logloss": 0.6914382328394126,
            "mae": 0.49869976072489364,
            "precision": 0.5176470588235295,
            "recall": 0.7410526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8104827117459703,
            "auditor_fn_violation": 0.011608156612826439,
            "auditor_fp_violation": 0.013806166686925173,
            "ave_precision_score": 0.8119199136765756,
            "fpr": 0.09758771929824561,
            "logloss": 1.0197087855844829,
            "mae": 0.2851616171037205,
            "precision": 0.78239608801956,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8706394961025303,
            "auditor_fn_violation": 0.016419203882373334,
            "auditor_fp_violation": 0.0023816956867642168,
            "ave_precision_score": 0.870793413151729,
            "fpr": 0.07574094401756312,
            "logloss": 0.8672521834175174,
            "mae": 0.2587765672751698,
            "precision": 0.8292079207920792,
            "recall": 0.7052631578947368
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6605109728578942,
            "auditor_fn_violation": 0.00648967146467421,
            "auditor_fp_violation": 0.009448057209999595,
            "ave_precision_score": 0.6560348556508919,
            "fpr": 0.039473684210526314,
            "logloss": 9.40080417391048,
            "mae": 0.4446898761962278,
            "precision": 0.7777777777777778,
            "recall": 0.2630480167014614
        },
        "train": {
            "accuracy": 0.5389681668496158,
            "auc_prc": 0.6088953642190199,
            "auditor_fn_violation": 0.00435149344271767,
            "auditor_fp_violation": 0.0062865688476218306,
            "ave_precision_score": 0.6071447328698529,
            "fpr": 0.042810098792535674,
            "logloss": 10.771585516077772,
            "mae": 0.47322890422760366,
            "precision": 0.706766917293233,
            "recall": 0.19789473684210526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7767503081110458,
            "auditor_fn_violation": 0.004065487309086917,
            "auditor_fp_violation": 0.009625319071350438,
            "ave_precision_score": 0.7771642803953445,
            "fpr": 0.11732456140350878,
            "logloss": 0.8532016305934298,
            "mae": 0.36320757120895947,
            "precision": 0.7494145199063232,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8126453087633809,
            "auditor_fn_violation": 0.004168929458663139,
            "auditor_fp_violation": 0.01322269106436118,
            "ave_precision_score": 0.8128836396583301,
            "fpr": 0.12184412733260154,
            "logloss": 0.6412762547509345,
            "mae": 0.3451049024541147,
            "precision": 0.7406542056074766,
            "recall": 0.6673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8149699387498979,
            "auditor_fn_violation": 0.006226422004907897,
            "auditor_fp_violation": 0.012960374377051175,
            "ave_precision_score": 0.8163804285448508,
            "fpr": 0.11074561403508772,
            "logloss": 0.9177199100991402,
            "mae": 0.28402283804284545,
            "precision": 0.769406392694064,
            "recall": 0.7035490605427975
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8744080100421713,
            "auditor_fn_violation": 0.010385348662545504,
            "auditor_fp_violation": 0.007842475755042847,
            "ave_precision_score": 0.8745498509634564,
            "fpr": 0.0889132821075741,
            "logloss": 0.7777631600770339,
            "mae": 0.2570756789973941,
            "precision": 0.810304449648712,
            "recall": 0.728421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.730986304166082,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6800263461974441,
            "fpr": 0.015350877192982455,
            "logloss": 0.6158604217936716,
            "mae": 0.4318017785584456,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6965239673428728,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6475892558671386,
            "fpr": 0.019758507135016465,
            "logloss": 0.635814383831659,
            "mae": 0.44378225490630785,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5554866916546319,
            "auditor_fn_violation": 0.008433139215470842,
            "auditor_fp_violation": 0.005945869292168065,
            "ave_precision_score": 0.554801017717425,
            "fpr": 0.08333333333333333,
            "logloss": 9.00505566422842,
            "mae": 0.4963074510922741,
            "precision": 0.6062176165803109,
            "recall": 0.24425887265135698
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.5189124763403072,
            "auditor_fn_violation": 0.005303599283609688,
            "auditor_fp_violation": 0.010158712575151814,
            "ave_precision_score": 0.5232951140698812,
            "fpr": 0.0889132821075741,
            "logloss": 10.353315139483831,
            "mae": 0.5184841376799211,
            "precision": 0.5120481927710844,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7794759173121535,
            "auditor_fn_violation": 0.002769842141889173,
            "auditor_fp_violation": 0.013494692273408696,
            "ave_precision_score": 0.7809346573734759,
            "fpr": 0.13157894736842105,
            "logloss": 0.846044539726682,
            "mae": 0.3608100261377299,
            "precision": 0.7345132743362832,
            "recall": 0.6931106471816284
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8157402939484635,
            "auditor_fn_violation": 0.0026460223005372973,
            "auditor_fp_violation": 0.009748335834197727,
            "ave_precision_score": 0.8159709471615479,
            "fpr": 0.12294182217343579,
            "logloss": 0.6421053985341344,
            "mae": 0.3447454996646252,
            "precision": 0.7407407407407407,
            "recall": 0.6736842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8110724138174018,
            "auditor_fn_violation": 0.009870710178368684,
            "auditor_fp_violation": 0.014755783801304649,
            "ave_precision_score": 0.8124760325985068,
            "fpr": 0.10307017543859649,
            "logloss": 0.8907127714298677,
            "mae": 0.28353348076046603,
            "precision": 0.7798594847775175,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8760441975748486,
            "auditor_fn_violation": 0.009458663123230697,
            "auditor_fp_violation": 0.003977884973665399,
            "ave_precision_score": 0.876195235570317,
            "fpr": 0.08122941822173436,
            "logloss": 0.7124370705778197,
            "mae": 0.2531171939167472,
            "precision": 0.8246445497630331,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7869591745102763,
            "auditor_fn_violation": 0.011154909716880934,
            "auditor_fp_violation": 0.013932782302175761,
            "ave_precision_score": 0.788461546079102,
            "fpr": 0.12719298245614036,
            "logloss": 0.8319435265242062,
            "mae": 0.3281947001144437,
            "precision": 0.7416481069042317,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8370829564266734,
            "auditor_fn_violation": 0.018395054595874986,
            "auditor_fp_violation": 0.017029375925235905,
            "ave_precision_score": 0.8372973465299655,
            "fpr": 0.1163556531284303,
            "logloss": 0.6385740551674866,
            "mae": 0.30698766096816865,
            "precision": 0.7579908675799086,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 8653,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.7054438660467768,
            "auditor_fn_violation": 0.009101563930703596,
            "auditor_fp_violation": 0.0007343705684534667,
            "ave_precision_score": 0.681900024832119,
            "fpr": 0.023026315789473683,
            "logloss": 1.0220150122802236,
            "mae": 0.45657064683996795,
            "precision": 0.8189655172413793,
            "recall": 0.19832985386221294
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6881086518043575,
            "auditor_fn_violation": 0.005421457045467675,
            "auditor_fp_violation": 0.004894309106838942,
            "ave_precision_score": 0.6669079742693441,
            "fpr": 0.020856201975850714,
            "logloss": 0.8695250840574252,
            "mae": 0.4486347970467891,
            "precision": 0.848,
            "recall": 0.2231578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7792918859036337,
            "auditor_fn_violation": 0.005200893674687782,
            "auditor_fp_violation": 0.004358109476925571,
            "ave_precision_score": 0.7531167135987895,
            "fpr": 0.01425438596491228,
            "logloss": 0.6011715499703204,
            "mae": 0.4165192130338319,
            "precision": 0.9202453987730062,
            "recall": 0.31315240083507306
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7805915790725475,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.003363578686593018,
            "ave_precision_score": 0.7554407717096824,
            "fpr": 0.015367727771679473,
            "logloss": 0.6131870338042259,
            "mae": 0.42700149423241385,
            "precision": 0.900709219858156,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7291424103245181,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6793635114969128,
            "fpr": 0.015350877192982455,
            "logloss": 0.7258384013873851,
            "mae": 0.4326947274078664,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7009069191633515,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6539236794991607,
            "fpr": 0.019758507135016465,
            "logloss": 0.6282122132262027,
            "mae": 0.43870777210668466,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7975704338546988,
            "auditor_fn_violation": 0.0007828810020876905,
            "auditor_fp_violation": 0.011874012398201047,
            "ave_precision_score": 0.7990451601056836,
            "fpr": 0.1074561403508772,
            "logloss": 0.928024445188314,
            "mae": 0.3078747973407588,
            "precision": 0.7627118644067796,
            "recall": 0.6576200417536534
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8514912465518278,
            "auditor_fn_violation": 0.0160818071523485,
            "auditor_fp_violation": 0.01486168037946002,
            "ave_precision_score": 0.8516703039832948,
            "fpr": 0.10208562019758508,
            "logloss": 0.7467161829980178,
            "mae": 0.28586765425138316,
            "precision": 0.7811764705882352,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8138759310721287,
            "auditor_fn_violation": 0.005780042486173681,
            "auditor_fp_violation": 0.013170556298367164,
            "ave_precision_score": 0.8152694204971143,
            "fpr": 0.10855263157894737,
            "logloss": 0.8529803202632943,
            "mae": 0.28667459697847575,
            "precision": 0.7697674418604651,
            "recall": 0.6910229645093946
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8739175270340702,
            "auditor_fn_violation": 0.015418568374833906,
            "auditor_fp_violation": 0.006827863321886424,
            "ave_precision_score": 0.8740595543508926,
            "fpr": 0.08562019758507135,
            "logloss": 0.7920857628990154,
            "mae": 0.2577329237989961,
            "precision": 0.8151658767772512,
            "recall": 0.7242105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5954436494184288,
            "auditor_fn_violation": 0.02746950884518185,
            "auditor_fp_violation": 0.013702341882419686,
            "ave_precision_score": 0.596767305415,
            "fpr": 0.19846491228070176,
            "logloss": 0.7540883094113543,
            "mae": 0.47252194590718083,
            "precision": 0.5914221218961625,
            "recall": 0.5469728601252609
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.5879573209270192,
            "auditor_fn_violation": 0.008192269917384025,
            "auditor_fp_violation": 0.018942788950543313,
            "ave_precision_score": 0.5893668208832786,
            "fpr": 0.20197585071350166,
            "logloss": 0.6751752688813574,
            "mae": 0.4630691288071214,
            "precision": 0.6085106382978723,
            "recall": 0.6021052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7921222290452262,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6496595151460802,
            "fpr": 0.015350877192982455,
            "logloss": 0.61939195195077,
            "mae": 0.434464167623797,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7666112115126004,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6270688176370907,
            "fpr": 0.019758507135016465,
            "logloss": 0.6320240303744874,
            "mae": 0.441497703562322,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7820398245269853,
            "auditor_fn_violation": 0.003838863861114164,
            "auditor_fp_violation": 0.014216401280337103,
            "ave_precision_score": 0.7823746460131795,
            "fpr": 0.13815789473684212,
            "logloss": 0.8503482969025508,
            "mae": 0.3591223270437499,
            "precision": 0.7248908296943232,
            "recall": 0.6931106471816284
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8216672262514493,
            "auditor_fn_violation": 0.00387544052227165,
            "auditor_fp_violation": 0.01421967995649503,
            "ave_precision_score": 0.821895017003819,
            "fpr": 0.12952799121844127,
            "logloss": 0.6329445674761796,
            "mae": 0.33879519830283805,
            "precision": 0.738359201773836,
            "recall": 0.7010526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.780626247259258,
            "auditor_fn_violation": 0.006993279126835884,
            "auditor_fp_violation": 0.012000628013451647,
            "ave_precision_score": 0.7809776917128075,
            "fpr": 0.15350877192982457,
            "logloss": 0.8493925338952178,
            "mae": 0.3601411658982516,
            "precision": 0.7095435684647303,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8167295970616801,
            "auditor_fn_violation": 0.007394996822462301,
            "auditor_fp_violation": 0.014773562674347181,
            "ave_precision_score": 0.8169721341633895,
            "fpr": 0.14050493962678376,
            "logloss": 0.6394025083645369,
            "mae": 0.3423895105933548,
            "precision": 0.7288135593220338,
            "recall": 0.7242105263157895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8102218105738481,
            "auditor_fn_violation": 0.010408654726586825,
            "auditor_fp_violation": 0.014510149507718492,
            "ave_precision_score": 0.8116678958899992,
            "fpr": 0.09868421052631579,
            "logloss": 1.027774153989077,
            "mae": 0.2857152027231053,
            "precision": 0.7820823244552058,
            "recall": 0.6743215031315241
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8675263228508785,
            "auditor_fn_violation": 0.014836212375064996,
            "auditor_fp_violation": 0.0015307304202459265,
            "ave_precision_score": 0.8676857898554987,
            "fpr": 0.07903402854006586,
            "logloss": 0.8582561880070027,
            "mae": 0.26066283230171167,
            "precision": 0.823960880195599,
            "recall": 0.7094736842105264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6763665509388659,
            "auditor_fn_violation": 0.010198055158773771,
            "auditor_fp_violation": 0.0026209432356873717,
            "ave_precision_score": 0.6741390828738894,
            "fpr": 0.05263157894736842,
            "logloss": 8.986388597258559,
            "mae": 0.4352074710324469,
            "precision": 0.7563451776649747,
            "recall": 0.31106471816283926
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6260602829639084,
            "auditor_fn_violation": 0.007741637298515243,
            "auditor_fp_violation": 0.006052427516893426,
            "ave_precision_score": 0.6270164555947865,
            "fpr": 0.04720087815587267,
            "logloss": 10.3700746515197,
            "mae": 0.46883090770725144,
            "precision": 0.7278481012658228,
            "recall": 0.24210526315789474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7841778632366662,
            "auditor_fn_violation": 0.005612936307365497,
            "auditor_fp_violation": 0.012836291074105588,
            "ave_precision_score": 0.7845438503445348,
            "fpr": 0.13706140350877194,
            "logloss": 1.002716586422799,
            "mae": 0.35099121991959753,
            "precision": 0.7311827956989247,
            "recall": 0.7098121085594989
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8290958132174115,
            "auditor_fn_violation": 0.003168293951123691,
            "auditor_fp_violation": 0.01421967995649503,
            "ave_precision_score": 0.8293450889811775,
            "fpr": 0.12952799121844127,
            "logloss": 0.7215913840879854,
            "mae": 0.331445564403307,
            "precision": 0.7400881057268722,
            "recall": 0.7073684210526315
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8150755717896643,
            "auditor_fn_violation": 0.008833736219463062,
            "auditor_fp_violation": 0.013471901462663595,
            "ave_precision_score": 0.8164922160687125,
            "fpr": 0.1074561403508772,
            "logloss": 0.9513344431288653,
            "mae": 0.284983350496579,
            "precision": 0.772093023255814,
            "recall": 0.6931106471816284
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8738943454119799,
            "auditor_fn_violation": 0.01583453694609741,
            "auditor_fp_violation": 0.009144100141995386,
            "ave_precision_score": 0.8740363089365024,
            "fpr": 0.0889132821075741,
            "logloss": 0.7909971085778159,
            "mae": 0.2579947343384064,
            "precision": 0.8089622641509434,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 8653,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7290892342624158,
            "auditor_fn_violation": 0.003761033586052822,
            "auditor_fp_violation": 0.004477128155261132,
            "ave_precision_score": 0.6793118168410265,
            "fpr": 0.015350877192982455,
            "logloss": 0.7263171307657804,
            "mae": 0.4328466892536533,
            "precision": 0.9151515151515152,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7008414766051682,
            "auditor_fn_violation": 0.006466000346640471,
            "auditor_fp_violation": 0.002094683732968107,
            "ave_precision_score": 0.6538569062219686,
            "fpr": 0.019758507135016465,
            "logloss": 0.6286914680416356,
            "mae": 0.43885990143083975,
            "precision": 0.8758620689655172,
            "recall": 0.2673684210526316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8170288190169255,
            "auditor_fn_violation": 0.015730872065340806,
            "auditor_fp_violation": 0.011413131558688871,
            "ave_precision_score": 0.8184000990577048,
            "fpr": 0.07456140350877193,
            "logloss": 0.9261765575970873,
            "mae": 0.2946261957150967,
            "precision": 0.8136986301369863,
            "recall": 0.6200417536534447
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8770313896576395,
            "auditor_fn_violation": 0.01485238893061413,
            "auditor_fp_violation": 0.004400849958207035,
            "ave_precision_score": 0.8771789863893324,
            "fpr": 0.05598243688254665,
            "logloss": 0.7746392580353368,
            "mae": 0.2620402511333673,
            "precision": 0.8617886178861789,
            "recall": 0.6694736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8156488427698105,
            "auditor_fn_violation": 0.00949529355748453,
            "auditor_fp_violation": 0.012160163688667399,
            "ave_precision_score": 0.8170272557609799,
            "fpr": 0.08552631578947369,
            "logloss": 0.9236766409627963,
            "mae": 0.2907741621298861,
            "precision": 0.7958115183246073,
            "recall": 0.6346555323590815
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8768535202034056,
            "auditor_fn_violation": 0.016488531977583917,
            "auditor_fp_violation": 0.007965840542200831,
            "ave_precision_score": 0.8770013137816624,
            "fpr": 0.06366630076838639,
            "logloss": 0.7703666351284016,
            "mae": 0.2569989744152808,
            "precision": 0.8505154639175257,
            "recall": 0.6947368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 8653,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.5762385291518588,
            "auditor_fn_violation": 0.008211094018972276,
            "auditor_fp_violation": 0.005945869292168065,
            "ave_precision_score": 0.5637349285570185,
            "fpr": 0.08333333333333333,
            "logloss": 8.930081829038699,
            "mae": 0.4966628419237444,
            "precision": 0.6041666666666666,
            "recall": 0.24217118997912318
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5234384671587387,
            "auditor_fn_violation": 0.005303599283609688,
            "auditor_fp_violation": 0.007129981167987597,
            "ave_precision_score": 0.5187240382696777,
            "fpr": 0.08781558726673985,
            "logloss": 10.267054668168381,
            "mae": 0.5175597066750647,
            "precision": 0.5151515151515151,
            "recall": 0.17894736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6771642511482634,
            "auditor_fn_violation": 0.009456378419953853,
            "auditor_fp_violation": 0.0070372958956282155,
            "ave_precision_score": 0.6748010364347916,
            "fpr": 0.0581140350877193,
            "logloss": 8.916798776396595,
            "mae": 0.4350317189791293,
            "precision": 0.7439613526570048,
            "recall": 0.32150313152400833
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.626397607370645,
            "auditor_fn_violation": 0.007022936044832186,
            "auditor_fp_violation": 0.01238179639271292,
            "ave_precision_score": 0.6269372128377193,
            "fpr": 0.054884742041712405,
            "logloss": 10.29480846579505,
            "mae": 0.4691480303025289,
            "precision": 0.7023809523809523,
            "recall": 0.24842105263157896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7772515376912352,
            "auditor_fn_violation": 0.005141376405523202,
            "auditor_fp_violation": 0.010103926096997696,
            "ave_precision_score": 0.777665107232127,
            "fpr": 0.12171052631578948,
            "logloss": 0.8511101111559713,
            "mae": 0.3629931535279789,
            "precision": 0.7448275862068966,
            "recall": 0.6764091858037579
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8133766462551152,
            "auditor_fn_violation": 0.013502802010514764,
            "auditor_fp_violation": 0.00973574759061018,
            "ave_precision_score": 0.8136138556103065,
            "fpr": 0.12403951701427003,
            "logloss": 0.638394949996569,
            "mae": 0.344694863054679,
            "precision": 0.7384259259259259,
            "recall": 0.671578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7945528575710741,
            "auditor_fn_violation": 0.008991685895322869,
            "auditor_fp_violation": 0.00923281066407358,
            "ave_precision_score": 0.7960320054721475,
            "fpr": 0.08881578947368421,
            "logloss": 0.982661026005295,
            "mae": 0.32074356242772306,
            "precision": 0.779891304347826,
            "recall": 0.5991649269311065
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8426568206614622,
            "auditor_fn_violation": 0.002442659887919587,
            "auditor_fp_violation": 0.012900432028519928,
            "ave_precision_score": 0.8428512666405719,
            "fpr": 0.08122941822173436,
            "logloss": 0.8146175366723954,
            "mae": 0.3000249729247381,
            "precision": 0.8016085790884718,
            "recall": 0.6294736842105263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6599056121060305,
            "auditor_fn_violation": 0.006876533714243869,
            "auditor_fp_violation": 0.009331570843969045,
            "ave_precision_score": 0.6577599510266283,
            "fpr": 0.03837719298245614,
            "logloss": 9.062925265663125,
            "mae": 0.4441560949113901,
            "precision": 0.7852760736196319,
            "recall": 0.267223382045929
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.6078497417013976,
            "auditor_fn_violation": 0.0036813218556820265,
            "auditor_fp_violation": 0.006253839414294204,
            "ave_precision_score": 0.6089619003094372,
            "fpr": 0.03951701427003293,
            "logloss": 10.432924102805995,
            "mae": 0.47240506563630974,
            "precision": 0.7209302325581395,
            "recall": 0.1957894736842105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6727066059771235,
            "auditor_fn_violation": 0.007991337948210815,
            "auditor_fp_violation": 0.007961589886957577,
            "ave_precision_score": 0.6704917451548913,
            "fpr": 0.05701754385964912,
            "logloss": 9.164732224178666,
            "mae": 0.4359084771046549,
            "precision": 0.7438423645320197,
            "recall": 0.31524008350730687
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6217277796619514,
            "auditor_fn_violation": 0.004855277601247913,
            "auditor_fp_violation": 0.01315723219770592,
            "ave_precision_score": 0.6226978034258006,
            "fpr": 0.06037321624588365,
            "logloss": 10.573224243855147,
            "mae": 0.46946342838475785,
            "precision": 0.6892655367231638,
            "recall": 0.25684210526315787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6601901306219529,
            "auditor_fn_violation": 0.006386660806504805,
            "auditor_fp_violation": 0.009703820752805802,
            "ave_precision_score": 0.6549289371695259,
            "fpr": 0.04057017543859649,
            "logloss": 9.456108516491117,
            "mae": 0.44628979501078336,
            "precision": 0.7701863354037267,
            "recall": 0.2588726513569937
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6058204820177397,
            "auditor_fn_violation": 0.0064405800450632695,
            "auditor_fp_violation": 0.008016193516551024,
            "ave_precision_score": 0.6022743357539745,
            "fpr": 0.04610318331503842,
            "logloss": 10.87995978427856,
            "mae": 0.4758900627986816,
            "precision": 0.6865671641791045,
            "recall": 0.1936842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8104589438530613,
            "auditor_fn_violation": 0.009401439402263491,
            "auditor_fp_violation": 0.014687411369069326,
            "ave_precision_score": 0.8118747881442778,
            "fpr": 0.11403508771929824,
            "logloss": 0.98610594753018,
            "mae": 0.284086183679295,
            "precision": 0.7620137299771167,
            "recall": 0.6951983298538622
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8716112948273296,
            "auditor_fn_violation": 0.018277196834016986,
            "auditor_fp_violation": 0.008988005921509787,
            "ave_precision_score": 0.8717616745314006,
            "fpr": 0.0889132821075741,
            "logloss": 0.8345166412274015,
            "mae": 0.25698593583252877,
            "precision": 0.8107476635514018,
            "recall": 0.7305263157894737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7803684140912291,
            "auditor_fn_violation": 0.013402831190711657,
            "auditor_fp_violation": 0.003383169239495969,
            "ave_precision_score": 0.7806141761995992,
            "fpr": 0.0537280701754386,
            "logloss": 0.5982327029826968,
            "mae": 0.4293113219339335,
            "precision": 0.8157894736842105,
            "recall": 0.453027139874739
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7666403787806763,
            "auditor_fn_violation": 0.012492922756947255,
            "auditor_fp_violation": 0.005337415281120656,
            "ave_precision_score": 0.7668585406083641,
            "fpr": 0.052689352360043906,
            "logloss": 0.6131004825877923,
            "mae": 0.43745473485223285,
            "precision": 0.8048780487804879,
            "recall": 0.4168421052631579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.797381045932558,
            "auditor_fn_violation": 0.008893253488627628,
            "auditor_fp_violation": 0.009898808800291722,
            "ave_precision_score": 0.7988420178511667,
            "fpr": 0.08552631578947369,
            "logloss": 0.9599169068523362,
            "mae": 0.3197218914321661,
            "precision": 0.7845303867403315,
            "recall": 0.592901878914405
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8460584047537061,
            "auditor_fn_violation": 0.005671038188225787,
            "auditor_fp_violation": 0.012749373105469343,
            "ave_precision_score": 0.8462486734260428,
            "fpr": 0.07464324917672886,
            "logloss": 0.7858986860347684,
            "mae": 0.2988237766938876,
            "precision": 0.8131868131868132,
            "recall": 0.6231578947368421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8148267514491974,
            "auditor_fn_violation": 0.008517836867743484,
            "auditor_fp_violation": 0.010807908917791015,
            "ave_precision_score": 0.8162630401343313,
            "fpr": 0.07236842105263158,
            "logloss": 0.9397308097986208,
            "mae": 0.2955332843110285,
            "precision": 0.8181818181818182,
            "recall": 0.6200417536534447
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8707117098238094,
            "auditor_fn_violation": 0.015349240279623326,
            "auditor_fp_violation": 0.005780521455402374,
            "ave_precision_score": 0.8708600369648609,
            "fpr": 0.0570801317233809,
            "logloss": 0.8915378282570475,
            "mae": 0.26552990732922793,
            "precision": 0.8567493112947658,
            "recall": 0.6547368421052632
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8152746815152239,
            "auditor_fn_violation": 0.005548840786726735,
            "auditor_fp_violation": 0.012261456180867877,
            "ave_precision_score": 0.8166718479314083,
            "fpr": 0.10087719298245613,
            "logloss": 0.9249180232291915,
            "mae": 0.28692734226074673,
            "precision": 0.7799043062200957,
            "recall": 0.6805845511482255
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8737287396559938,
            "auditor_fn_violation": 0.015818360390548274,
            "auditor_fp_violation": 0.007512663773049076,
            "ave_precision_score": 0.8738716482350364,
            "fpr": 0.0801317233809001,
            "logloss": 0.7876524956371891,
            "mae": 0.2594612618872738,
            "precision": 0.8223844282238443,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7914060518171562,
            "auditor_fn_violation": 0.010898527634325902,
            "auditor_fp_violation": 0.014208804343422064,
            "ave_precision_score": 0.792862393171007,
            "fpr": 0.11403508771929824,
            "logloss": 0.8354803545793249,
            "mae": 0.32880722800821655,
            "precision": 0.7547169811320755,
            "recall": 0.6680584551148225
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8411605082156224,
            "auditor_fn_violation": 0.01743601594546191,
            "auditor_fp_violation": 0.014572150776946395,
            "ave_precision_score": 0.8413632087266842,
            "fpr": 0.10098792535675083,
            "logloss": 0.6459611353144324,
            "mae": 0.30773319860005793,
            "precision": 0.7788461538461539,
            "recall": 0.6821052631578948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 8653,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6808436524496666,
            "auditor_fn_violation": 0.010674193312090272,
            "auditor_fp_violation": 0.00278554353551315,
            "ave_precision_score": 0.6765179391278995,
            "fpr": 0.043859649122807015,
            "logloss": 8.585651211047715,
            "mae": 0.435757343699215,
            "precision": 0.7727272727272727,
            "recall": 0.2839248434237996
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6306012077393821,
            "auditor_fn_violation": 0.006147091108671781,
            "auditor_fp_violation": 0.006440145419389924,
            "ave_precision_score": 0.6287189172822321,
            "fpr": 0.04500548847420417,
            "logloss": 9.92568217734234,
            "mae": 0.4674054331762413,
            "precision": 0.7354838709677419,
            "recall": 0.24
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8069065619449276,
            "auditor_fn_violation": 0.016165805955389523,
            "auditor_fp_violation": 0.015778837972529474,
            "ave_precision_score": 0.8083312656908499,
            "fpr": 0.10416666666666667,
            "logloss": 0.9436481191339605,
            "mae": 0.28528456345319797,
            "precision": 0.7759433962264151,
            "recall": 0.6868475991649269
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8729200548695132,
            "auditor_fn_violation": 0.013632214454907856,
            "auditor_fp_violation": 0.0082427819011269,
            "ave_precision_score": 0.8730783172746874,
            "fpr": 0.0801317233809001,
            "logloss": 0.76209714941684,
            "mae": 0.2538078815281152,
            "precision": 0.8266033254156769,
            "recall": 0.7326315789473684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 8653,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7804859160138569,
            "auditor_fn_violation": 0.0029026114346408782,
            "auditor_fp_violation": 0.011443519306349013,
            "ave_precision_score": 0.7809021555941197,
            "fpr": 0.16228070175438597,
            "logloss": 0.8486191168277709,
            "mae": 0.36433919518787117,
            "precision": 0.6979591836734694,
            "recall": 0.7139874739039666
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8153217194926112,
            "auditor_fn_violation": 0.005978392743659373,
            "auditor_fp_violation": 0.0031722373840622747,
            "ave_precision_score": 0.8155530217459291,
            "fpr": 0.145993413830955,
            "logloss": 0.6424180912561749,
            "mae": 0.34680277061591225,
            "precision": 0.7182203389830508,
            "recall": 0.7136842105263158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8061369074445877,
            "auditor_fn_violation": 0.00975854301725086,
            "auditor_fp_violation": 0.013137636238402011,
            "ave_precision_score": 0.8065431294855043,
            "fpr": 0.09978070175438597,
            "logloss": 0.9212551491998942,
            "mae": 0.30377405177383915,
            "precision": 0.7807228915662651,
            "recall": 0.6764091858037579
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8556866623323535,
            "auditor_fn_violation": 0.017674042405684903,
            "auditor_fp_violation": 0.011334454526228867,
            "ave_precision_score": 0.8558578911903569,
            "fpr": 0.09440175631174534,
            "logloss": 0.7510037941842037,
            "mae": 0.2841935959197454,
            "precision": 0.7942583732057417,
            "recall": 0.6989473684210527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 8653,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8148950886144137,
            "auditor_fn_violation": 0.006881111965718068,
            "auditor_fp_violation": 0.010511628378104616,
            "ave_precision_score": 0.8162663805106705,
            "fpr": 0.10197368421052631,
            "logloss": 0.872209784264257,
            "mae": 0.2891146093934619,
            "precision": 0.7785714285714286,
            "recall": 0.6826722338204593
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8722337256881001,
            "auditor_fn_violation": 0.010833670344907273,
            "auditor_fp_violation": 0.009174311926605507,
            "ave_precision_score": 0.8723819397803345,
            "fpr": 0.08342480790340286,
            "logloss": 0.7282979239554038,
            "mae": 0.26232763256082403,
            "precision": 0.8186157517899761,
            "recall": 0.7221052631578947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8065858861094857,
            "auditor_fn_violation": 0.0072473720836538184,
            "auditor_fp_violation": 0.013704874194724687,
            "ave_precision_score": 0.8080079939169025,
            "fpr": 0.11513157894736842,
            "logloss": 0.9156190984628634,
            "mae": 0.2825004018745792,
            "precision": 0.7666666666666667,
            "recall": 0.7202505219206681
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8672162182753533,
            "auditor_fn_violation": 0.013851753423074705,
            "auditor_fp_violation": 0.009375723824006286,
            "ave_precision_score": 0.8673791952471428,
            "fpr": 0.09879253567508232,
            "logloss": 0.7444970516186762,
            "mae": 0.2588254646589306,
            "precision": 0.7991071428571429,
            "recall": 0.7536842105263157
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8084999084172224,
            "auditor_fn_violation": 0.014998351829469299,
            "auditor_fp_violation": 0.011316903691098414,
            "ave_precision_score": 0.8099125902939979,
            "fpr": 0.09649122807017543,
            "logloss": 0.9426689607145816,
            "mae": 0.28834869009535974,
            "precision": 0.784841075794621,
            "recall": 0.6701461377870563
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8729766355535036,
            "auditor_fn_violation": 0.008598994742619452,
            "auditor_fp_violation": 0.004461273527427265,
            "ave_precision_score": 0.8731340265663166,
            "fpr": 0.07025246981339188,
            "logloss": 0.7653290719068825,
            "mae": 0.25765743710712846,
            "precision": 0.8407960199004975,
            "recall": 0.7115789473684211
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 8653,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.806210125740732,
            "auditor_fn_violation": 0.009351078636047321,
            "auditor_fp_violation": 0.011562537984684578,
            "ave_precision_score": 0.8075903855105688,
            "fpr": 0.09210526315789473,
            "logloss": 1.7475886877519364,
            "mae": 0.29715783070157675,
            "precision": 0.7857142857142857,
            "recall": 0.6430062630480167
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.865712456268803,
            "auditor_fn_violation": 0.01975850713501646,
            "auditor_fp_violation": 0.008288099578042078,
            "ave_precision_score": 0.8658488407046734,
            "fpr": 0.06805708013172337,
            "logloss": 1.899044652127339,
            "mae": 0.26431409004147227,
            "precision": 0.8397932816537468,
            "recall": 0.6842105263157895
        }
    }
]