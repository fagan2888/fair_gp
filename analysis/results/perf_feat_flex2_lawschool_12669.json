[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7200985886850395,
            "auditor_fn_violation": 0.02815177478580172,
            "auditor_fp_violation": 0.03843963553530751,
            "ave_precision_score": 0.7034240197923195,
            "fpr": 0.18640350877192982,
            "logloss": 3.7201603745077536,
            "mae": 0.3168189527927945,
            "precision": 0.6828358208955224,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7330024172042532,
            "auditor_fn_violation": 0.037898998381984114,
            "auditor_fp_violation": 0.03296658412682205,
            "ave_precision_score": 0.7164233358928356,
            "fpr": 0.1778265642151482,
            "logloss": 4.004546386170608,
            "mae": 0.3133106690437378,
            "precision": 0.6960600375234521,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8107491926102205,
            "auditor_fn_violation": 0.011328863914543226,
            "auditor_fp_violation": 0.032010550293729775,
            "ave_precision_score": 0.811161748202383,
            "fpr": 0.1337719298245614,
            "logloss": 0.8088010823256826,
            "mae": 0.28549781846775213,
            "precision": 0.7442348008385744,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8452911420755453,
            "auditor_fn_violation": 0.0241698254870593,
            "auditor_fp_violation": 0.01629183366093994,
            "ave_precision_score": 0.8455726041044986,
            "fpr": 0.12733260153677278,
            "logloss": 0.6645552801990696,
            "mae": 0.2539554326868898,
            "precision": 0.7693836978131213,
            "recall": 0.8045738045738046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7606189095135021,
            "auditor_fn_violation": 0.008020844924149704,
            "auditor_fp_violation": 0.021497722095671988,
            "ave_precision_score": 0.760477050722171,
            "fpr": 0.13267543859649122,
            "logloss": 1.3446581415770305,
            "mae": 0.3023000571344214,
            "precision": 0.7334801762114538,
            "recall": 0.7040169133192389
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8043594545035618,
            "auditor_fn_violation": 0.01830252104675815,
            "auditor_fp_violation": 0.016067189135373864,
            "ave_precision_score": 0.8045974528169977,
            "fpr": 0.1350164654226125,
            "logloss": 1.1286965518764167,
            "mae": 0.2732471435638907,
            "precision": 0.7489795918367347,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6252567837284635,
            "auditor_fn_violation": 0.01335262045176366,
            "auditor_fp_violation": 0.018280681772769054,
            "ave_precision_score": 0.5277533944595185,
            "fpr": 0.36951754385964913,
            "logloss": 7.951286926892399,
            "mae": 0.43508733663611965,
            "precision": 0.557161629434954,
            "recall": 0.8964059196617337
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6558193019108349,
            "auditor_fn_violation": 0.014263186601276612,
            "auditor_fp_violation": 0.016393944808924532,
            "ave_precision_score": 0.5616572114491525,
            "fpr": 0.3413830954994512,
            "logloss": 7.226760858778375,
            "mae": 0.3979250535937067,
            "precision": 0.5891677675033025,
            "recall": 0.9272349272349273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8029445325241694,
            "auditor_fn_violation": 0.01392057045361819,
            "auditor_fp_violation": 0.021612616392918522,
            "ave_precision_score": 0.7662060629114461,
            "fpr": 0.18201754385964913,
            "logloss": 2.449290331447394,
            "mae": 0.2925617838894763,
            "precision": 0.7067137809187279,
            "recall": 0.8456659619450317
        },
        "train": {
            "accuracy": 0.7804610318331504,
            "auc_prc": 0.8616569345874013,
            "auditor_fn_violation": 0.010552475975088491,
            "auditor_fp_violation": 0.01737931738697573,
            "ave_precision_score": 0.837654891311027,
            "fpr": 0.1712403951701427,
            "logloss": 1.7836552363215015,
            "mae": 0.25638958100163306,
            "precision": 0.7369308600337268,
            "recall": 0.9085239085239085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7310246522579588,
            "auditor_fn_violation": 0.009363061459144692,
            "auditor_fp_violation": 0.016369939655516922,
            "ave_precision_score": 0.7175347806049996,
            "fpr": 0.3432017543859649,
            "logloss": 2.7055202870455584,
            "mae": 0.37545082082548115,
            "precision": 0.5886990801576872,
            "recall": 0.9471458773784355
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.733728079315161,
            "auditor_fn_violation": 0.0014012154517094148,
            "auditor_fp_violation": 0.0074668776963725,
            "ave_precision_score": 0.7162782847619635,
            "fpr": 0.34577387486278816,
            "logloss": 2.888301225967284,
            "mae": 0.36501653610708323,
            "precision": 0.5971867007672634,
            "recall": 0.9708939708939709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7565853230716476,
            "auditor_fn_violation": 0.0021535736805014674,
            "auditor_fp_violation": 0.015548195659992815,
            "ave_precision_score": 0.7581758043789569,
            "fpr": 0.375,
            "logloss": 1.5843693850183558,
            "mae": 0.39672755297441364,
            "precision": 0.565438373570521,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.8145946958877106,
            "auditor_fn_violation": 0.00401423123706329,
            "auditor_fp_violation": 0.008056569575983458,
            "ave_precision_score": 0.8158328847906435,
            "fpr": 0.38529088913282106,
            "logloss": 1.469557770214718,
            "mae": 0.3912945503644694,
            "precision": 0.5666666666666667,
            "recall": 0.9542619542619543
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.7220836732464473,
            "auditor_fn_violation": 0.00034772449093134516,
            "auditor_fp_violation": 0.0224818167286097,
            "ave_precision_score": 0.7214312647657328,
            "fpr": 0.3793859649122807,
            "logloss": 2.0458469791031315,
            "mae": 0.41129564005818237,
            "precision": 0.5569782330345711,
            "recall": 0.919661733615222
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7562374301377517,
            "auditor_fn_violation": 0.003975435369507818,
            "auditor_fp_violation": 0.014844408138258507,
            "ave_precision_score": 0.756225972747103,
            "fpr": 0.38529088913282106,
            "logloss": 1.9509790279450494,
            "mae": 0.40387456666264226,
            "precision": 0.5601503759398496,
            "recall": 0.9293139293139293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7179309480296224,
            "auditor_fn_violation": 0.02800804866288343,
            "auditor_fp_violation": 0.036783659033689006,
            "ave_precision_score": 0.6984999442160114,
            "fpr": 0.15570175438596492,
            "logloss": 3.312476411150498,
            "mae": 0.29956008198894135,
            "precision": 0.7237354085603113,
            "recall": 0.7864693446088795
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7290686693573215,
            "auditor_fn_violation": 0.040187954567756985,
            "auditor_fp_violation": 0.02767722666122074,
            "ave_precision_score": 0.7106520881325484,
            "fpr": 0.15697036223929747,
            "logloss": 3.6170571097124107,
            "mae": 0.29750356964873637,
            "precision": 0.7306967984934086,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 12669,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7841679836459732,
            "auditor_fn_violation": 0.01838535291717666,
            "auditor_fp_violation": 0.04794339207928706,
            "ave_precision_score": 0.7823601404346623,
            "fpr": 0.28289473684210525,
            "logloss": 1.3709053336232118,
            "mae": 0.33655638731290477,
            "precision": 0.6244541484716157,
            "recall": 0.9069767441860465
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.8176125023376866,
            "auditor_fn_violation": 0.013231672946272288,
            "auditor_fp_violation": 0.02974497740790852,
            "ave_precision_score": 0.8157869185430768,
            "fpr": 0.29747530186608123,
            "logloss": 1.2781772099179307,
            "mae": 0.3270763961861446,
            "precision": 0.6267217630853994,
            "recall": 0.9459459459459459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7501764445531833,
            "auditor_fn_violation": 0.005018823485775751,
            "auditor_fp_violation": 0.028656136354553816,
            "ave_precision_score": 0.7458118044438905,
            "fpr": 0.16228070175438597,
            "logloss": 1.8876518898643573,
            "mae": 0.30758582007224666,
            "precision": 0.7004048582995951,
            "recall": 0.7315010570824524
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7587030357276751,
            "auditor_fn_violation": 0.011946845097229293,
            "auditor_fp_violation": 0.01869910397467644,
            "ave_precision_score": 0.7500323567390969,
            "fpr": 0.17014270032930845,
            "logloss": 1.9322123879298314,
            "mae": 0.2905055961863348,
            "precision": 0.7041984732824428,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7865494470980525,
            "auditor_fn_violation": 0.011194410444716448,
            "auditor_fp_violation": 0.024604863525556495,
            "ave_precision_score": 0.7849097803282504,
            "fpr": 0.14583333333333334,
            "logloss": 1.1431333697985417,
            "mae": 0.2884836737686958,
            "precision": 0.7302231237322515,
            "recall": 0.7610993657505285
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8213843474420351,
            "auditor_fn_violation": 0.01976535346458508,
            "auditor_fp_violation": 0.014331299619635984,
            "ave_precision_score": 0.8173961416575414,
            "fpr": 0.13391877058177826,
            "logloss": 1.021249035751486,
            "mae": 0.2536380284769095,
            "precision": 0.7653846153846153,
            "recall": 0.8274428274428275
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7650218250646292,
            "auditor_fn_violation": 0.004283965728274173,
            "auditor_fp_violation": 0.03587199776205891,
            "ave_precision_score": 0.763525648120823,
            "fpr": 0.30043859649122806,
            "logloss": 1.9459689654491026,
            "mae": 0.3630905739288337,
            "precision": 0.6102418207681366,
            "recall": 0.9069767441860465
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.8003258911077575,
            "auditor_fn_violation": 0.0037152748459005334,
            "auditor_fp_violation": 0.021576085569142027,
            "ave_precision_score": 0.7993373117291869,
            "fpr": 0.32711306256860595,
            "logloss": 1.7797651593633552,
            "mae": 0.3518072712108034,
            "precision": 0.6026666666666667,
            "recall": 0.9397089397089398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.6157694914568989,
            "auditor_fn_violation": 0.008994473498757457,
            "auditor_fp_violation": 0.022516784558206455,
            "ave_precision_score": 0.6178766993746713,
            "fpr": 0.12609649122807018,
            "logloss": 3.301790306573509,
            "mae": 0.42785411346886687,
            "precision": 0.649390243902439,
            "recall": 0.4503171247357294
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.6080325248697867,
            "auditor_fn_violation": 0.01639239509711519,
            "auditor_fp_violation": 0.021701171725423126,
            "ave_precision_score": 0.6100632522576283,
            "fpr": 0.12403951701427003,
            "logloss": 3.4856520838758214,
            "mae": 0.4409986853423968,
            "precision": 0.6389776357827476,
            "recall": 0.4158004158004158
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 12669,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.6081669569465282,
            "auditor_fn_violation": 0.023443585178591308,
            "auditor_fp_violation": 0.018897614194940657,
            "ave_precision_score": 0.6090895403515564,
            "fpr": 0.07346491228070176,
            "logloss": 2.1471204906553725,
            "mae": 0.4543406562676072,
            "precision": 0.6683168316831684,
            "recall": 0.2854122621564482
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6175632303878755,
            "auditor_fn_violation": 0.022866740759166667,
            "auditor_fp_violation": 0.02294948050953463,
            "ave_precision_score": 0.6183508849291242,
            "fpr": 0.09879253567508232,
            "logloss": 2.252741116079964,
            "mae": 0.4584901495232455,
            "precision": 0.625,
            "recall": 0.31185031185031187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7543321992737163,
            "auditor_fn_violation": 0.008769611661288527,
            "auditor_fp_violation": 0.012286196699036885,
            "ave_precision_score": 0.7519818281649651,
            "fpr": 0.19736842105263158,
            "logloss": 1.3152833281834928,
            "mae": 0.3299388077023304,
            "precision": 0.6779964221824687,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8059192342999422,
            "auditor_fn_violation": 0.010974666298486278,
            "auditor_fp_violation": 0.01309830750772216,
            "ave_precision_score": 0.8034121497787206,
            "fpr": 0.1877058177826564,
            "logloss": 1.134184140989982,
            "mae": 0.2874622827258202,
            "precision": 0.7101694915254237,
            "recall": 0.8711018711018711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7239632376833806,
            "auditor_fn_violation": 0.012381310040428778,
            "auditor_fp_violation": 0.027369819765815453,
            "ave_precision_score": 0.7245241469828734,
            "fpr": 0.12719298245614036,
            "logloss": 1.4791550808986946,
            "mae": 0.3237444695308312,
            "precision": 0.7231503579952268,
            "recall": 0.6405919661733616
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.751799839059154,
            "auditor_fn_violation": 0.025561912499343902,
            "auditor_fp_violation": 0.018522962244403036,
            "ave_precision_score": 0.7534366555611941,
            "fpr": 0.12843029637760703,
            "logloss": 1.318108515566824,
            "mae": 0.2993727123768465,
            "precision": 0.7439824945295405,
            "recall": 0.7068607068607069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7706570813863963,
            "auditor_fn_violation": 0.012374355550610146,
            "auditor_fp_violation": 0.024385065739519644,
            "ave_precision_score": 0.7688907970459079,
            "fpr": 0.13486842105263158,
            "logloss": 1.7439453015032862,
            "mae": 0.29666421449533387,
            "precision": 0.7296703296703296,
            "recall": 0.7019027484143763
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7999647935250878,
            "auditor_fn_violation": 0.01996161491221865,
            "auditor_fp_violation": 0.015023102647231515,
            "ave_precision_score": 0.7965503832277883,
            "fpr": 0.13721185510428102,
            "logloss": 1.5701287458356787,
            "mae": 0.2748167271330308,
            "precision": 0.7417355371900827,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6758565546743447,
            "auditor_fn_violation": 0.004156466748266014,
            "auditor_fp_violation": 0.015206010470367258,
            "ave_precision_score": 0.6574742550670587,
            "fpr": 0.3607456140350877,
            "logloss": 2.9110985506143985,
            "mae": 0.4019606860101145,
            "precision": 0.5721716514954487,
            "recall": 0.9302325581395349
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.705319138287992,
            "auditor_fn_violation": 0.0016682223048853123,
            "auditor_fp_violation": 0.00542976029408011,
            "ave_precision_score": 0.6853020373732448,
            "fpr": 0.35016465422612514,
            "logloss": 2.8665309086778428,
            "mae": 0.38002771247998907,
            "precision": 0.591025641025641,
            "recall": 0.9584199584199584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7220581680957184,
            "auditor_fn_violation": 0.015489966989354996,
            "auditor_fp_violation": 0.02669544019502059,
            "ave_precision_score": 0.7206836581008251,
            "fpr": 0.14473684210526316,
            "logloss": 1.7718849253971458,
            "mae": 0.3170500729529188,
            "precision": 0.7130434782608696,
            "recall": 0.693446088794926
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7671935756661609,
            "auditor_fn_violation": 0.023720249845387065,
            "auditor_fp_violation": 0.016516478186506013,
            "ave_precision_score": 0.7669892446128065,
            "fpr": 0.15587266739846323,
            "logloss": 1.6155207547524837,
            "mae": 0.29932501061368616,
            "precision": 0.7142857142857143,
            "recall": 0.738045738045738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6859989917598908,
            "auditor_fn_violation": 0.019407662920514827,
            "auditor_fp_violation": 0.019674399552411785,
            "ave_precision_score": 0.6867192967995429,
            "fpr": 0.11074561403508772,
            "logloss": 1.6394343727019653,
            "mae": 0.3489387010276441,
            "precision": 0.7328042328042328,
            "recall": 0.5856236786469344
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7061664260745157,
            "auditor_fn_violation": 0.03719154432656079,
            "auditor_fp_violation": 0.018145150996860086,
            "ave_precision_score": 0.7065945143898344,
            "fpr": 0.12294182217343579,
            "logloss": 1.5475720148860626,
            "mae": 0.34219028342115243,
            "precision": 0.726161369193154,
            "recall": 0.6174636174636174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7643484607466628,
            "auditor_fn_violation": 0.011308000445087348,
            "auditor_fp_violation": 0.02681033449226711,
            "ave_precision_score": 0.7583712828272315,
            "fpr": 0.22039473684210525,
            "logloss": 2.051190913654912,
            "mae": 0.3177947283167844,
            "precision": 0.664440734557596,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8008289803944892,
            "auditor_fn_violation": 0.016298828593010812,
            "auditor_fp_violation": 0.017246572894595774,
            "ave_precision_score": 0.7954787153570883,
            "fpr": 0.21734357848518113,
            "logloss": 1.833441095320991,
            "mae": 0.30056019922898203,
            "precision": 0.6780487804878049,
            "recall": 0.8669438669438669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6280865445117401,
            "auditor_fn_violation": 0.00933756166314306,
            "auditor_fp_violation": 0.019517044319226316,
            "ave_precision_score": 0.5329608115308668,
            "fpr": 0.34649122807017546,
            "logloss": 7.763578086847824,
            "mae": 0.4254467307554988,
            "precision": 0.56353591160221,
            "recall": 0.8625792811839323
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.6555113377435304,
            "auditor_fn_violation": 0.013101592684468645,
            "auditor_fp_violation": 0.01034896484823732,
            "ave_precision_score": 0.5626081713539994,
            "fpr": 0.32711306256860595,
            "logloss": 7.162923077584584,
            "mae": 0.39155928737182466,
            "precision": 0.5962059620596206,
            "recall": 0.9147609147609148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.789845302800177,
            "auditor_fn_violation": 0.004886688179221841,
            "auditor_fp_violation": 0.025988590496743,
            "ave_precision_score": 0.7881186489970573,
            "fpr": 0.20394736842105263,
            "logloss": 1.1970990298365651,
            "mae": 0.3096183648847632,
            "precision": 0.6905158069883528,
            "recall": 0.8773784355179705
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8294451527669446,
            "auditor_fn_violation": 0.008010205595276945,
            "auditor_fp_violation": 0.01625609475914533,
            "ave_precision_score": 0.8268276550055438,
            "fpr": 0.20417124039517015,
            "logloss": 1.0666834371086442,
            "mae": 0.2809576126353245,
            "precision": 0.7070866141732284,
            "recall": 0.9334719334719335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7635242851916787,
            "auditor_fn_violation": 0.006080542264752793,
            "auditor_fp_violation": 0.011659273468409082,
            "ave_precision_score": 0.760371502153331,
            "fpr": 0.2774122807017544,
            "logloss": 1.801654793982302,
            "mae": 0.34148534005778536,
            "precision": 0.6295754026354319,
            "recall": 0.9090909090909091
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7778683561917565,
            "auditor_fn_violation": 0.006456088783201848,
            "auditor_fp_violation": 0.0074643249176728965,
            "ave_precision_score": 0.7738745101700764,
            "fpr": 0.28210757409440174,
            "logloss": 1.795104250942832,
            "mae": 0.3242763793931651,
            "precision": 0.6375176304654443,
            "recall": 0.9397089397089398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6261705406767314,
            "auditor_fn_violation": 0.013412892696858426,
            "auditor_fp_violation": 0.01721166526795349,
            "ave_precision_score": 0.5284164936852482,
            "fpr": 0.3673245614035088,
            "logloss": 7.961485364878896,
            "mae": 0.4341915166737117,
            "precision": 0.5568783068783069,
            "recall": 0.8900634249471459
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6568421266578862,
            "auditor_fn_violation": 0.012998897740939456,
            "auditor_fp_violation": 0.017083195057820452,
            "ave_precision_score": 0.5624780670758838,
            "fpr": 0.3424807903402854,
            "logloss": 7.236658175017073,
            "mae": 0.3966009260020316,
            "precision": 0.5889328063241107,
            "recall": 0.9293139293139293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7141819579200775,
            "auditor_fn_violation": 0.01226540187678499,
            "auditor_fp_violation": 0.006134356392119251,
            "ave_precision_score": 0.7151567148313622,
            "fpr": 0.051535087719298246,
            "logloss": 1.4921469119839594,
            "mae": 0.4028693039036978,
            "precision": 0.7661691542288557,
            "recall": 0.32558139534883723
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7523590579387502,
            "auditor_fn_violation": 0.009231134368346218,
            "auditor_fp_violation": 0.003711740229239527,
            "ave_precision_score": 0.753791728623875,
            "fpr": 0.04061470911086718,
            "logloss": 1.3447326076143893,
            "mae": 0.3827024383234625,
            "precision": 0.821256038647343,
            "recall": 0.35343035343035345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7656603154129591,
            "auditor_fn_violation": 0.02842763621527392,
            "auditor_fp_violation": 0.04939705470966711,
            "ave_precision_score": 0.760565096836803,
            "fpr": 0.1875,
            "logloss": 2.1939012356220995,
            "mae": 0.31684107837831593,
            "precision": 0.6827458256029685,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7878793699115185,
            "auditor_fn_violation": 0.03672599391589513,
            "auditor_fp_violation": 0.04268245985755495,
            "ave_precision_score": 0.7809113777014502,
            "fpr": 0.20417124039517015,
            "logloss": 2.0435586728940067,
            "mae": 0.3070114555581375,
            "precision": 0.6765217391304348,
            "recall": 0.8087318087318087
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.5985250817761723,
            "auditor_fn_violation": 0.05824153406772747,
            "auditor_fp_violation": 0.019661911041841507,
            "ave_precision_score": 0.6020255294453618,
            "fpr": 0.0668859649122807,
            "logloss": 8.68306144001357,
            "mae": 0.43357446287420826,
            "precision": 0.7009803921568627,
            "recall": 0.3023255813953488
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.6117638311222778,
            "auditor_fn_violation": 0.06772617420257378,
            "auditor_fp_violation": 0.01828300104663927,
            "ave_precision_score": 0.6182448631551603,
            "fpr": 0.07793633369923161,
            "logloss": 8.978804418623303,
            "mae": 0.44460542824964727,
            "precision": 0.6830357142857143,
            "recall": 0.3180873180873181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.718281425227712,
            "auditor_fn_violation": 0.01417788657690739,
            "auditor_fp_violation": 0.02883597090676578,
            "ave_precision_score": 0.7188567529356825,
            "fpr": 0.13048245614035087,
            "logloss": 1.518098146627059,
            "mae": 0.32303155794269744,
            "precision": 0.7213114754098361,
            "recall": 0.6511627906976745
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7518860162879647,
            "auditor_fn_violation": 0.026351522509590577,
            "auditor_fp_violation": 0.018941617951139817,
            "ave_precision_score": 0.7526222458163876,
            "fpr": 0.13172338090010977,
            "logloss": 1.35758791467263,
            "mae": 0.3011559928725232,
            "precision": 0.7402597402597403,
            "recall": 0.7110187110187111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7129042925627767,
            "auditor_fn_violation": 0.032071788880234424,
            "auditor_fp_violation": 0.0342934500259761,
            "ave_precision_score": 0.6949624154005951,
            "fpr": 0.14035087719298245,
            "logloss": 3.276373460989682,
            "mae": 0.2998342143924269,
            "precision": 0.7316561844863732,
            "recall": 0.7378435517970402
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7284558461157881,
            "auditor_fn_violation": 0.04101864255541534,
            "auditor_fp_violation": 0.030954994511525804,
            "ave_precision_score": 0.7107792265705448,
            "fpr": 0.141602634467618,
            "logloss": 3.5939157086801243,
            "mae": 0.29283537671155657,
            "precision": 0.7425149700598802,
            "recall": 0.7733887733887734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7486998746449133,
            "auditor_fn_violation": 0.05044323281777382,
            "auditor_fp_violation": 0.0823517364025097,
            "ave_precision_score": 0.7371522755534659,
            "fpr": 0.25548245614035087,
            "logloss": 3.1728861448675985,
            "mae": 0.3583855601762375,
            "precision": 0.619281045751634,
            "recall": 0.8012684989429175
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7637536714755653,
            "auditor_fn_violation": 0.04825749501929524,
            "auditor_fp_violation": 0.07006101141092079,
            "ave_precision_score": 0.7491662690930694,
            "fpr": 0.2491767288693743,
            "logloss": 3.1082510760449624,
            "mae": 0.34889477375885275,
            "precision": 0.6356340288924559,
            "recall": 0.8232848232848233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7722729262975829,
            "auditor_fn_violation": 0.00921238084640778,
            "auditor_fp_violation": 0.020820844822763068,
            "ave_precision_score": 0.770552504507503,
            "fpr": 0.14364035087719298,
            "logloss": 1.7098417033712803,
            "mae": 0.2989820255905419,
            "precision": 0.7188841201716738,
            "recall": 0.7082452431289641
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8066656203671478,
            "auditor_fn_violation": 0.013736019224493431,
            "auditor_fp_violation": 0.015526000051055578,
            "ave_precision_score": 0.8046362119425212,
            "fpr": 0.14709110867178923,
            "logloss": 1.4898054330365182,
            "mae": 0.2739269717892429,
            "precision": 0.7309236947791165,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7169777085822572,
            "auditor_fn_violation": 0.025805793553651573,
            "auditor_fp_violation": 0.03921142548855054,
            "ave_precision_score": 0.70061015530882,
            "fpr": 0.17982456140350878,
            "logloss": 3.7146745994829073,
            "mae": 0.31831123077563767,
            "precision": 0.6852207293666027,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7297440239069459,
            "auditor_fn_violation": 0.03818882633372206,
            "auditor_fp_violation": 0.03379368442549716,
            "ave_precision_score": 0.713250882419342,
            "fpr": 0.1800219538968167,
            "logloss": 4.005103195244244,
            "mae": 0.31634365170771156,
            "precision": 0.6899810964083176,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.716682022854063,
            "auditor_fn_violation": 0.027347372130113866,
            "auditor_fp_violation": 0.03866942412980059,
            "ave_precision_score": 0.7008269934217668,
            "fpr": 0.18859649122807018,
            "logloss": 3.7086060265557506,
            "mae": 0.31938070054764983,
            "precision": 0.6826568265682657,
            "recall": 0.7822410147991543
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.731895467555754,
            "auditor_fn_violation": 0.03775294335118704,
            "auditor_fp_violation": 0.03213693104944732,
            "ave_precision_score": 0.7154941785316721,
            "fpr": 0.18551042810098792,
            "logloss": 3.997869240177197,
            "mae": 0.31624782222169423,
            "precision": 0.692167577413479,
            "recall": 0.7900207900207901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7832782628649038,
            "auditor_fn_violation": 0.014764381884944925,
            "auditor_fp_violation": 0.024267673740159056,
            "ave_precision_score": 0.7841210704587231,
            "fpr": 0.12719298245614036,
            "logloss": 1.4862492886807477,
            "mae": 0.2963512060988773,
            "precision": 0.7381489841986456,
            "recall": 0.6913319238900634
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8197151474227033,
            "auditor_fn_violation": 0.018487371945110697,
            "auditor_fp_violation": 0.01573022234702474,
            "ave_precision_score": 0.8200350691471923,
            "fpr": 0.12843029637760703,
            "logloss": 1.2770587827777848,
            "mae": 0.2733955399414797,
            "precision": 0.7510638297872341,
            "recall": 0.7338877338877339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.8032132842901559,
            "auditor_fn_violation": 0.010179054931196915,
            "auditor_fp_violation": 0.042525876193901614,
            "ave_precision_score": 0.7814349547516382,
            "fpr": 0.30701754385964913,
            "logloss": 4.255322376705669,
            "mae": 0.3504326001828407,
            "precision": 0.6078431372549019,
            "recall": 0.9175475687103594
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8363769272807787,
            "auditor_fn_violation": 0.010732762653728628,
            "auditor_fp_violation": 0.040354325683506505,
            "ave_precision_score": 0.8195178646034837,
            "fpr": 0.29198682766191,
            "logloss": 3.932427309504386,
            "mae": 0.3330449636944088,
            "precision": 0.6248236953455572,
            "recall": 0.920997920997921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7716525109490698,
            "auditor_fn_violation": 0.008822929416564665,
            "auditor_fp_violation": 0.021465251968189273,
            "ave_precision_score": 0.7698371793884726,
            "fpr": 0.14473684210526316,
            "logloss": 1.7432740971107887,
            "mae": 0.2983369697127111,
            "precision": 0.7191489361702128,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8030218441835244,
            "auditor_fn_violation": 0.01427003293084523,
            "auditor_fp_violation": 0.014772930334669294,
            "ave_precision_score": 0.7988013623443495,
            "fpr": 0.145993413830955,
            "logloss": 1.5779929813568878,
            "mae": 0.2742386044870577,
            "precision": 0.7323943661971831,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8025302999604219,
            "auditor_fn_violation": 0.008275842884166018,
            "auditor_fp_violation": 0.011914039084042684,
            "ave_precision_score": 0.8038623945455099,
            "fpr": 0.10635964912280702,
            "logloss": 0.8011930077677654,
            "mae": 0.2972542157697443,
            "precision": 0.7679425837320574,
            "recall": 0.678646934460888
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8419375837019853,
            "auditor_fn_violation": 0.020826534547720058,
            "auditor_fp_violation": 0.011130115130319359,
            "ave_precision_score": 0.8422327477954976,
            "fpr": 0.09330406147091108,
            "logloss": 0.6594839135827463,
            "mae": 0.2665028961550172,
            "precision": 0.805045871559633,
            "recall": 0.7297297297297297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7686756560351874,
            "auditor_fn_violation": 0.005160231445421168,
            "auditor_fp_violation": 0.021320385245574072,
            "ave_precision_score": 0.7172104064086697,
            "fpr": 0.14473684210526316,
            "logloss": 3.7095710564022037,
            "mae": 0.29844475766959067,
            "precision": 0.7197452229299363,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7929786953799206,
            "auditor_fn_violation": 0.015344906673117432,
            "auditor_fp_violation": 0.011707043116432243,
            "ave_precision_score": 0.745535333507759,
            "fpr": 0.1437980241492865,
            "logloss": 3.3332924479277724,
            "mae": 0.27486991627508706,
            "precision": 0.7358870967741935,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 12669,
        "test": {
            "accuracy": 0.48464912280701755,
            "auc_prc": 0.7964968036780566,
            "auditor_fn_violation": 0.0006629946960424284,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.797055127776406,
            "fpr": 0.0,
            "logloss": 7.878374122139755,
            "mae": 0.5143098243905802,
            "precision": 1.0,
            "recall": 0.006342494714587738
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.8298672744804917,
            "auditor_fn_violation": 0.0020379241015904136,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8302156066255176,
            "fpr": 0.0,
            "logloss": 7.752162999480274,
            "mae": 0.5208206475136877,
            "precision": 1.0,
            "recall": 0.012474012474012475
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6603759831531077,
            "auditor_fn_violation": 0.01618773413449056,
            "auditor_fp_violation": 0.02397294489070056,
            "ave_precision_score": 0.6476826013323174,
            "fpr": 0.17324561403508773,
            "logloss": 2.6359259349164694,
            "mae": 0.33197885090728596,
            "precision": 0.6814516129032258,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6758064735318617,
            "auditor_fn_violation": 0.022727532057938208,
            "auditor_fp_violation": 0.01796135093048784,
            "ave_precision_score": 0.6644788063486191,
            "fpr": 0.18331503841931943,
            "logloss": 2.588294497019846,
            "mae": 0.31778767707849237,
            "precision": 0.6866791744840526,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7688578618669849,
            "auditor_fn_violation": 0.02441953191647195,
            "auditor_fp_violation": 0.026982675938136916,
            "ave_precision_score": 0.769430226368965,
            "fpr": 0.1524122807017544,
            "logloss": 0.7909982659331447,
            "mae": 0.34231557522371514,
            "precision": 0.707983193277311,
            "recall": 0.7124735729386892
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.778810918564112,
            "auditor_fn_violation": 0.02627849499419204,
            "auditor_fp_violation": 0.01948025425675849,
            "ave_precision_score": 0.7792025454243283,
            "fpr": 0.145993413830955,
            "logloss": 0.770506586083648,
            "mae": 0.3467525182057577,
            "precision": 0.710239651416122,
            "recall": 0.6777546777546778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7149170599426431,
            "auditor_fn_violation": 0.024493713141203965,
            "auditor_fp_violation": 0.04114714462694321,
            "ave_precision_score": 0.6991809461866973,
            "fpr": 0.18201754385964913,
            "logloss": 3.614300978739869,
            "mae": 0.3188886151251953,
            "precision": 0.6813819577735125,
            "recall": 0.7505285412262156
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7320788125895983,
            "auditor_fn_violation": 0.037515603926141804,
            "auditor_fp_violation": 0.03309422306180278,
            "ave_precision_score": 0.7157193765171814,
            "fpr": 0.17233809001097694,
            "logloss": 3.9802400193496332,
            "mae": 0.3113127163615095,
            "precision": 0.6951456310679611,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.766966646523611,
            "auditor_fn_violation": 0.010524461258855384,
            "auditor_fp_violation": 0.026006074411541385,
            "ave_precision_score": 0.7633465401254045,
            "fpr": 0.19407894736842105,
            "logloss": 1.9301796138439442,
            "mae": 0.3087722973901699,
            "precision": 0.6799276672694394,
            "recall": 0.7949260042283298
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7960655768990441,
            "auditor_fn_violation": 0.013466730261461328,
            "auditor_fp_violation": 0.022479769228805558,
            "ave_precision_score": 0.7916112190298246,
            "fpr": 0.19538968166849616,
            "logloss": 1.7717422248162513,
            "mae": 0.2910044876930918,
            "precision": 0.6920415224913494,
            "recall": 0.8316008316008316
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7637073746202436,
            "auditor_fn_violation": 0.022465320277437785,
            "auditor_fp_violation": 0.019442113255804663,
            "ave_precision_score": 0.761936061938886,
            "fpr": 0.1699561403508772,
            "logloss": 1.2501787365309758,
            "mae": 0.316985177713917,
            "precision": 0.7030651340996169,
            "recall": 0.7758985200845666
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8066211665177067,
            "auditor_fn_violation": 0.018859355851671988,
            "auditor_fp_violation": 0.01364460214943967,
            "ave_precision_score": 0.8035888490269144,
            "fpr": 0.15916575192096596,
            "logloss": 1.095635255427137,
            "mae": 0.2835757106161002,
            "precision": 0.740608228980322,
            "recall": 0.8607068607068608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7097719966402688,
            "auditor_fn_violation": 0.011428544935276883,
            "auditor_fp_violation": 0.03188066978379892,
            "ave_precision_score": 0.7084601613203829,
            "fpr": 0.33114035087719296,
            "logloss": 2.1092257584593987,
            "mae": 0.39510175601072756,
            "precision": 0.5758426966292135,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7305909992266322,
            "auditor_fn_violation": 0.022161568813599552,
            "auditor_fp_violation": 0.024404564368314913,
            "ave_precision_score": 0.7291045794867536,
            "fpr": 0.3468715697036224,
            "logloss": 2.013794428798011,
            "mae": 0.39814286539194105,
            "precision": 0.5653370013755158,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6614457137746288,
            "auditor_fn_violation": 0.009965783910092355,
            "auditor_fp_violation": 0.024127802421771972,
            "ave_precision_score": 0.6485636697004235,
            "fpr": 0.17434210526315788,
            "logloss": 2.621655210114043,
            "mae": 0.3313015242166998,
            "precision": 0.6807228915662651,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.677353804437784,
            "auditor_fn_violation": 0.022001821123665256,
            "auditor_fp_violation": 0.01903351798432594,
            "ave_precision_score": 0.6658389176356387,
            "fpr": 0.18441273326015367,
            "logloss": 2.5677880715974664,
            "mae": 0.31671853626394175,
            "precision": 0.6848030018761726,
            "recall": 0.7588357588357588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7929837880582109,
            "auditor_fn_violation": 0.01834362597826491,
            "auditor_fp_violation": 0.025788774327618592,
            "ave_precision_score": 0.7936949826292329,
            "fpr": 0.13486842105263158,
            "logloss": 0.964663326617232,
            "mae": 0.2887069927091263,
            "precision": 0.734341252699784,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8305861512522961,
            "auditor_fn_violation": 0.02702702702702703,
            "auditor_fp_violation": 0.018068567635871655,
            "ave_precision_score": 0.8308836951192846,
            "fpr": 0.13391877058177826,
            "logloss": 0.8243248832453041,
            "mae": 0.2647704017506848,
            "precision": 0.7515274949083504,
            "recall": 0.7671517671517671
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7644837955103653,
            "auditor_fn_violation": 0.0032662920514817733,
            "auditor_fp_violation": 0.01898253606681853,
            "ave_precision_score": 0.7591573140866704,
            "fpr": 0.34100877192982454,
            "logloss": 2.2916065061441984,
            "mae": 0.3819224232705086,
            "precision": 0.5847797062750334,
            "recall": 0.9260042283298098
        },
        "train": {
            "accuracy": 0.6169045005488474,
            "auc_prc": 0.8011499162691672,
            "auditor_fn_violation": 0.0034984744095611286,
            "auditor_fp_violation": 0.014132182881066043,
            "ave_precision_score": 0.7958663121208136,
            "fpr": 0.3556531284302964,
            "logloss": 2.1258628094106395,
            "mae": 0.3670536350623173,
            "precision": 0.5846153846153846,
            "recall": 0.9480249480249481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7589807818964184,
            "auditor_fn_violation": 0.03170320091984719,
            "auditor_fp_violation": 0.028219038484594172,
            "ave_precision_score": 0.7593731716082156,
            "fpr": 0.10416666666666667,
            "logloss": 1.6504560426222716,
            "mae": 0.2983432705002409,
            "precision": 0.7677261613691931,
            "recall": 0.6638477801268499
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8101290954776643,
            "auditor_fn_violation": 0.04275076393627437,
            "auditor_fp_violation": 0.023643836315829784,
            "ave_precision_score": 0.8105386870810855,
            "fpr": 0.10318331503841932,
            "logloss": 1.6397405416239976,
            "mae": 0.2931803965945827,
            "precision": 0.7783018867924528,
            "recall": 0.6860706860706861
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 12669,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7696238868862713,
            "auditor_fn_violation": 0.008869292682022183,
            "auditor_fp_violation": 0.02816408903808497,
            "ave_precision_score": 0.7673178944575236,
            "fpr": 0.20394736842105263,
            "logloss": 1.8735015495212428,
            "mae": 0.3108470487033684,
            "precision": 0.6776429809358753,
            "recall": 0.8266384778012685
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8015344865806786,
            "auditor_fn_violation": 0.008325136755433135,
            "auditor_fp_violation": 0.02504786460061778,
            "ave_precision_score": 0.7971183012525158,
            "fpr": 0.1986827661909989,
            "logloss": 1.7284200719814644,
            "mae": 0.29012998187148326,
            "precision": 0.6942567567567568,
            "recall": 0.8544698544698545
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7720247168038751,
            "auditor_fn_violation": 0.022959089054560292,
            "auditor_fp_violation": 0.03531501019062463,
            "ave_precision_score": 0.7677485391098282,
            "fpr": 0.15460526315789475,
            "logloss": 1.9565627095427864,
            "mae": 0.3005549674316588,
            "precision": 0.716297786720322,
            "recall": 0.7526427061310782
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7970558442401282,
            "auditor_fn_violation": 0.029895639116275782,
            "auditor_fp_violation": 0.02307456666581574,
            "ave_precision_score": 0.7925716036519268,
            "fpr": 0.150384193194292,
            "logloss": 1.7328469174791297,
            "mae": 0.28366749049559975,
            "precision": 0.7365384615384616,
            "recall": 0.7962577962577962
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7766530805506409,
            "auditor_fn_violation": 0.01789158414005415,
            "auditor_fp_violation": 0.02759960836030852,
            "ave_precision_score": 0.7765544338924018,
            "fpr": 0.11842105263157894,
            "logloss": 1.305376556480029,
            "mae": 0.2937532800484204,
            "precision": 0.7517241379310344,
            "recall": 0.6913319238900634
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8153610812816163,
            "auditor_fn_violation": 0.025908793197486943,
            "auditor_fp_violation": 0.017169989533607335,
            "ave_precision_score": 0.8156912173993158,
            "fpr": 0.11964873765093303,
            "logloss": 1.1029152152760442,
            "mae": 0.2728455392571674,
            "precision": 0.7635574837310195,
            "recall": 0.7318087318087318
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7523229327193344,
            "auditor_fn_violation": 0.00220457327250473,
            "auditor_fp_violation": 0.028331435079726658,
            "ave_precision_score": 0.7481792458732044,
            "fpr": 0.15570175438596492,
            "logloss": 1.8847872148668128,
            "mae": 0.30512786063006486,
            "precision": 0.7053941908713693,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7634690218447728,
            "auditor_fn_violation": 0.011657017145491354,
            "auditor_fp_violation": 0.02131570214178133,
            "ave_precision_score": 0.75577899265065,
            "fpr": 0.15806805708013172,
            "logloss": 1.8903593208271539,
            "mae": 0.2874731742709537,
            "precision": 0.7176470588235294,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.7631231138926451,
            "auditor_fn_violation": 0.011553725752012169,
            "auditor_fp_violation": 0.037537965072133646,
            "ave_precision_score": 0.7613183167586272,
            "fpr": 0.3223684210526316,
            "logloss": 2.1246385164239356,
            "mae": 0.3701303803613232,
            "precision": 0.5922330097087378,
            "recall": 0.9027484143763214
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.793257035306739,
            "auditor_fn_violation": 0.00570755675036685,
            "auditor_fp_violation": 0.019860618283001043,
            "ave_precision_score": 0.790572689706086,
            "fpr": 0.34577387486278816,
            "logloss": 1.9577671811103297,
            "mae": 0.3614155444711373,
            "precision": 0.5871559633027523,
            "recall": 0.9313929313929314
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7558054967971086,
            "auditor_fn_violation": 0.0047522347093950645,
            "auditor_fp_violation": 0.021342864564600578,
            "ave_precision_score": 0.7485149337301553,
            "fpr": 0.14912280701754385,
            "logloss": 2.009994763377694,
            "mae": 0.3013075806856352,
            "precision": 0.7130801687763713,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7835110719701639,
            "auditor_fn_violation": 0.021844355543587157,
            "auditor_fp_violation": 0.016184616955556133,
            "ave_precision_score": 0.7773893771330536,
            "fpr": 0.15367727771679474,
            "logloss": 1.8143107302583725,
            "mae": 0.2845926117415719,
            "precision": 0.7244094488188977,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7898529770100754,
            "auditor_fn_violation": 0.01857312414227959,
            "auditor_fp_violation": 0.024534927866362948,
            "ave_precision_score": 0.7902063424375119,
            "fpr": 0.12719298245614036,
            "logloss": 1.0185719576392331,
            "mae": 0.28806296670269493,
            "precision": 0.7450549450549451,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8290363887812007,
            "auditor_fn_violation": 0.023978128259138143,
            "auditor_fp_violation": 0.016067189135373857,
            "ave_precision_score": 0.8293419509788609,
            "fpr": 0.12733260153677278,
            "logloss": 0.8638915272829678,
            "mae": 0.2647789681273916,
            "precision": 0.7568134171907757,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6096491228070176,
            "auc_prc": 0.764018047650001,
            "auditor_fn_violation": 0.0029232038870961766,
            "auditor_fp_violation": 0.021864884306438095,
            "ave_precision_score": 0.7586085186762475,
            "fpr": 0.35526315789473684,
            "logloss": 2.328781549204983,
            "mae": 0.3841824640071656,
            "precision": 0.5764705882352941,
            "recall": 0.9323467230443975
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8016406552449481,
            "auditor_fn_violation": 0.002183979132387476,
            "auditor_fp_violation": 0.014606999719194335,
            "ave_precision_score": 0.7962683267809699,
            "fpr": 0.36882546652030734,
            "logloss": 2.1714994689453313,
            "mae": 0.37283387177796345,
            "precision": 0.5768261964735516,
            "recall": 0.9521829521829522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7621257998043267,
            "auditor_fn_violation": 0.006405085122955382,
            "auditor_fp_violation": 0.01875024977021141,
            "ave_precision_score": 0.710689510199389,
            "fpr": 0.14035087719298245,
            "logloss": 3.730460090982839,
            "mae": 0.30988069702983956,
            "precision": 0.7259100642398287,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.782338562521461,
            "auditor_fn_violation": 0.015621041965718152,
            "auditor_fp_violation": 0.018926301278942133,
            "ave_precision_score": 0.7348977227694415,
            "fpr": 0.1437980241492865,
            "logloss": 3.4133598200708026,
            "mae": 0.2915226818052275,
            "precision": 0.7321063394683026,
            "recall": 0.7442827442827443
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.5785872338059275,
            "auditor_fn_violation": 0.00985219390972145,
            "auditor_fp_violation": 0.022294489070055545,
            "ave_precision_score": 0.5351078814240161,
            "fpr": 0.34539473684210525,
            "logloss": 4.880119259486988,
            "mae": 0.41329256653770835,
            "precision": 0.58,
            "recall": 0.919661733615222
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6118083890693968,
            "auditor_fn_violation": 0.01824090408064064,
            "auditor_fp_violation": 0.02974753018660813,
            "ave_precision_score": 0.5650947537024175,
            "fpr": 0.33040614709110866,
            "logloss": 4.655081595707384,
            "mae": 0.3953926782569726,
            "precision": 0.5937921727395412,
            "recall": 0.9147609147609148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7766000735478065,
            "auditor_fn_violation": 0.0172888616891065,
            "auditor_fp_violation": 0.026408204451904258,
            "ave_precision_score": 0.776256857754303,
            "fpr": 0.12390350877192982,
            "logloss": 1.3564612893058172,
            "mae": 0.2916233118277433,
            "precision": 0.7454954954954955,
            "recall": 0.6997885835095138
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8153523574077903,
            "auditor_fn_violation": 0.023638093890563712,
            "auditor_fp_violation": 0.014341510734434437,
            "ave_precision_score": 0.8154738052335653,
            "fpr": 0.12733260153677278,
            "logloss": 1.1250593095554846,
            "mae": 0.2698581087009794,
            "precision": 0.7547568710359408,
            "recall": 0.7422037422037422
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7986106218316236,
            "auditor_fn_violation": 0.019240755164867774,
            "auditor_fp_violation": 0.020079027294888706,
            "ave_precision_score": 0.7999536302066952,
            "fpr": 0.09210526315789473,
            "logloss": 1.366432461919909,
            "mae": 0.30926383376367195,
            "precision": 0.7835051546391752,
            "recall": 0.642706131078224
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8242345606486157,
            "auditor_fn_violation": 0.03062363216040494,
            "auditor_fp_violation": 0.01475506088377199,
            "ave_precision_score": 0.8255870985044986,
            "fpr": 0.09879253567508232,
            "logloss": 1.229670425880147,
            "mae": 0.29564159000493223,
            "precision": 0.788235294117647,
            "recall": 0.6964656964656964
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 12669,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7406592995016194,
            "auditor_fn_violation": 0.012082266978227809,
            "auditor_fp_violation": 0.019751828317947483,
            "ave_precision_score": 0.7386483602307515,
            "fpr": 0.1962719298245614,
            "logloss": 1.3960098138636263,
            "mae": 0.3443549054765444,
            "precision": 0.6757246376811594,
            "recall": 0.7885835095137421
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7915959227355286,
            "auditor_fn_violation": 0.012725044558194943,
            "auditor_fp_violation": 0.01910754856661476,
            "ave_precision_score": 0.7885947534713541,
            "fpr": 0.19209659714599342,
            "logloss": 1.2207389160371405,
            "mae": 0.3078145763781353,
            "precision": 0.7058823529411765,
            "recall": 0.8731808731808732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8291935665856399,
            "auditor_fn_violation": 0.00955083268424762,
            "auditor_fp_violation": 0.017923510370459184,
            "ave_precision_score": 0.8119674509463106,
            "fpr": 0.14583333333333334,
            "logloss": 2.943965214282845,
            "mae": 0.2794448065145886,
            "precision": 0.7285714285714285,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8643415640531213,
            "auditor_fn_violation": 0.0038156876795735215,
            "auditor_fp_violation": 0.007663441656242827,
            "ave_precision_score": 0.853626004276201,
            "fpr": 0.13391877058177826,
            "logloss": 2.210112446664461,
            "mae": 0.24769207529353487,
            "precision": 0.758893280632411,
            "recall": 0.7983367983367984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7748604345593203,
            "auditor_fn_violation": 0.015362468009346852,
            "auditor_fp_violation": 0.0276895256364145,
            "ave_precision_score": 0.773080095757299,
            "fpr": 0.12938596491228072,
            "logloss": 1.3119078318082165,
            "mae": 0.2908308266668698,
            "precision": 0.738359201773836,
            "recall": 0.7040169133192389
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8085396283586577,
            "auditor_fn_violation": 0.022065720199638976,
            "auditor_fp_violation": 0.013626732698542367,
            "ave_precision_score": 0.8051600411606625,
            "fpr": 0.12952799121844127,
            "logloss": 1.1743655019737267,
            "mae": 0.26713254679475307,
            "precision": 0.7536534446764092,
            "recall": 0.7505197505197505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7123143182124236,
            "auditor_fn_violation": 0.03391472868217054,
            "auditor_fp_violation": 0.03501528593693803,
            "ave_precision_score": 0.694531256860404,
            "fpr": 0.1425438596491228,
            "logloss": 3.268139688026335,
            "mae": 0.29997991663863555,
            "precision": 0.7308488612836439,
            "recall": 0.7463002114164905
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7274422433446657,
            "auditor_fn_violation": 0.04114872281721898,
            "auditor_fp_violation": 0.030352538738416767,
            "ave_precision_score": 0.710073411166618,
            "fpr": 0.14050493962678376,
            "logloss": 3.5831120882449534,
            "mae": 0.2931462247181187,
            "precision": 0.7455268389662028,
            "recall": 0.7796257796257796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7205552345154046,
            "auditor_fn_violation": 0.023902581506620675,
            "auditor_fp_violation": 0.037857670942732694,
            "ave_precision_score": 0.7059912381397799,
            "fpr": 0.18201754385964913,
            "logloss": 3.615876504905309,
            "mae": 0.3155781436113725,
            "precision": 0.6826003824091779,
            "recall": 0.7547568710359408
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7325181587817986,
            "auditor_fn_violation": 0.03809069560990528,
            "auditor_fp_violation": 0.033645623260919515,
            "ave_precision_score": 0.7162607677861459,
            "fpr": 0.17892425905598244,
            "logloss": 3.9373587490918336,
            "mae": 0.3117732862752453,
            "precision": 0.6930320150659134,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7685553714547918,
            "auditor_fn_violation": 0.006523311449872049,
            "auditor_fp_violation": 0.023196159533229437,
            "ave_precision_score": 0.7170979810161651,
            "fpr": 0.14912280701754385,
            "logloss": 3.698622274630628,
            "mae": 0.2995474620935942,
            "precision": 0.7172557172557172,
            "recall": 0.7293868921775899
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7927984052491146,
            "auditor_fn_violation": 0.014607785189563459,
            "auditor_fp_violation": 0.014920991499246935,
            "ave_precision_score": 0.7453517953642543,
            "fpr": 0.14818880351262348,
            "logloss": 3.326852877771062,
            "mae": 0.27556380162592276,
            "precision": 0.7326732673267327,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7220283162082899,
            "auditor_fn_violation": 0.01385566188197768,
            "auditor_fp_violation": 0.023068776725412618,
            "ave_precision_score": 0.7225825400932413,
            "fpr": 0.12828947368421054,
            "logloss": 1.609473231578926,
            "mae": 0.32486295235302837,
            "precision": 0.7200956937799043,
            "recall": 0.6363636363636364
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7543538139139421,
            "auditor_fn_violation": 0.025751327617408854,
            "auditor_fp_violation": 0.019329640313481226,
            "ave_precision_score": 0.7549174195062932,
            "fpr": 0.12952799121844127,
            "logloss": 1.4524584956767936,
            "mae": 0.3014651503079268,
            "precision": 0.7412280701754386,
            "recall": 0.7027027027027027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5953960279065149,
            "auditor_fn_violation": 0.05590250732539595,
            "auditor_fp_violation": 0.018985033768932583,
            "ave_precision_score": 0.5989640774487652,
            "fpr": 0.06469298245614036,
            "logloss": 8.793207966968653,
            "mae": 0.4378215031682267,
            "precision": 0.6974358974358974,
            "recall": 0.28752642706131076
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6083772391082276,
            "auditor_fn_violation": 0.06749796321695334,
            "auditor_fp_violation": 0.01956194317514615,
            "ave_precision_score": 0.614929369905616,
            "fpr": 0.07574094401756312,
            "logloss": 9.079110590254606,
            "mae": 0.4460505481342435,
            "precision": 0.684931506849315,
            "recall": 0.31185031185031187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7651412884054148,
            "auditor_fn_violation": 0.03073652683505805,
            "auditor_fp_violation": 0.04814570595052552,
            "ave_precision_score": 0.7599128354571929,
            "fpr": 0.18311403508771928,
            "logloss": 2.241369985065675,
            "mae": 0.3171184792139857,
            "precision": 0.6866791744840526,
            "recall": 0.773784355179704
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7856897762307734,
            "auditor_fn_violation": 0.03793551213968339,
            "auditor_fp_violation": 0.03988206162407782,
            "ave_precision_score": 0.7779205025945151,
            "fpr": 0.1942919868276619,
            "logloss": 2.1075804117445562,
            "mae": 0.3050034500625203,
            "precision": 0.6856127886323268,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7500423635458424,
            "auditor_fn_violation": 0.001958847965579913,
            "auditor_fp_violation": 0.012248731167326068,
            "ave_precision_score": 0.75163640594694,
            "fpr": 0.39364035087719296,
            "logloss": 1.6529544672455752,
            "mae": 0.4086026184939113,
            "precision": 0.5534825870646766,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8083965583026251,
            "auditor_fn_violation": 0.004336008726788091,
            "auditor_fp_violation": 0.00879687539887169,
            "ave_precision_score": 0.8097026706908541,
            "fpr": 0.3885839736553238,
            "logloss": 1.5269132338508837,
            "mae": 0.3982177398065445,
            "precision": 0.5640394088669951,
            "recall": 0.9521829521829522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7669634357441318,
            "auditor_fn_violation": 0.024769574570676165,
            "auditor_fp_violation": 0.04314280861607322,
            "ave_precision_score": 0.7618405125749121,
            "fpr": 0.17653508771929824,
            "logloss": 2.1154766822814346,
            "mae": 0.3114080356903512,
            "precision": 0.6933333333333334,
            "recall": 0.7695560253699789
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7897970761215336,
            "auditor_fn_violation": 0.0333895493061245,
            "auditor_fp_violation": 0.03198121154877084,
            "ave_precision_score": 0.7829938656925182,
            "fpr": 0.18221734357848518,
            "logloss": 1.9407592958726219,
            "mae": 0.29702424408480477,
            "precision": 0.7003610108303249,
            "recall": 0.8066528066528067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6425438596491229,
            "auc_prc": 0.7421786294955404,
            "auditor_fn_violation": 0.009972738399910985,
            "auditor_fp_violation": 0.00580715741517803,
            "ave_precision_score": 0.7343916365839909,
            "fpr": 0.3267543859649123,
            "logloss": 2.333526121778007,
            "mae": 0.36889447849360624,
            "precision": 0.5989232839838493,
            "recall": 0.9408033826638478
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7538249121052341,
            "auditor_fn_violation": 0.0056961462010858286,
            "auditor_fp_violation": 0.004365251576340839,
            "ave_precision_score": 0.7446244827221238,
            "fpr": 0.32930845225027444,
            "logloss": 2.3427837855567852,
            "mae": 0.3525553520924595,
            "precision": 0.6057818659658344,
            "recall": 0.9584199584199584
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7640793233844221,
            "auditor_fn_violation": 0.0015809873521011833,
            "auditor_fp_violation": 0.018602885345482153,
            "ave_precision_score": 0.7616446843647291,
            "fpr": 0.37280701754385964,
            "logloss": 2.253601715881381,
            "mae": 0.3920230451799278,
            "precision": 0.565772669220945,
            "recall": 0.9365750528541226
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7965850012203923,
            "auditor_fn_violation": 0.0037609170430246176,
            "auditor_fp_violation": 0.012873662982156083,
            "ave_precision_score": 0.7917732681059857,
            "fpr": 0.38529088913282106,
            "logloss": 2.182978380262946,
            "mae": 0.38183422279913937,
            "precision": 0.5672009864364982,
            "recall": 0.9563409563409564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7183305002458871,
            "auditor_fn_violation": 0.011736860650569343,
            "auditor_fp_violation": 0.023565819446109585,
            "ave_precision_score": 0.7096120021706228,
            "fpr": 0.30153508771929827,
            "logloss": 3.864767908116949,
            "mae": 0.37496608522524516,
            "precision": 0.5955882352941176,
            "recall": 0.8562367864693446
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7294422777245679,
            "auditor_fn_violation": 0.006898818095305475,
            "auditor_fp_violation": 0.010341306512138467,
            "ave_precision_score": 0.7204109320947343,
            "fpr": 0.3172338090010977,
            "logloss": 4.1921840874152005,
            "mae": 0.3919184982300425,
            "precision": 0.5877318116975749,
            "recall": 0.8565488565488566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.780555507287659,
            "auditor_fn_violation": 0.029375764993880053,
            "auditor_fp_violation": 0.03806498021819927,
            "ave_precision_score": 0.7764837259260974,
            "fpr": 0.14583333333333334,
            "logloss": 1.9563405339340174,
            "mae": 0.29175597428081407,
            "precision": 0.7257731958762886,
            "recall": 0.7441860465116279
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8063072368487407,
            "auditor_fn_violation": 0.03623534029681121,
            "auditor_fp_violation": 0.03326270645597733,
            "ave_precision_score": 0.8036684074011137,
            "fpr": 0.14709110867178923,
            "logloss": 1.6955873888892459,
            "mae": 0.277536922574016,
            "precision": 0.7346534653465346,
            "recall": 0.7713097713097713
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6238237164728183,
            "auditor_fn_violation": 0.00814138941433923,
            "auditor_fp_violation": 0.01895755904567798,
            "ave_precision_score": 0.5248227062346495,
            "fpr": 0.37280701754385964,
            "logloss": 8.136188488601015,
            "mae": 0.44019942476107216,
            "precision": 0.5549738219895288,
            "recall": 0.8964059196617337
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6552257785708936,
            "auditor_fn_violation": 0.014096592581773704,
            "auditor_fp_violation": 0.013381665943379377,
            "ave_precision_score": 0.5589080674210007,
            "fpr": 0.34906695938529086,
            "logloss": 7.4228830519018185,
            "mae": 0.4014035783131514,
            "precision": 0.5843137254901961,
            "recall": 0.9293139293139293
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7104651970958867,
            "auditor_fn_violation": 0.013433756166314306,
            "auditor_fp_violation": 0.028703592694720857,
            "ave_precision_score": 0.7110738649243725,
            "fpr": 0.12938596491228072,
            "logloss": 1.4942994404760195,
            "mae": 0.3256622861026373,
            "precision": 0.7223529411764706,
            "recall": 0.6490486257928119
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7401654342878821,
            "auditor_fn_violation": 0.02646334589254458,
            "auditor_fp_violation": 0.020406912924718554,
            "ave_precision_score": 0.7405671250225115,
            "fpr": 0.132821075740944,
            "logloss": 1.362791601692623,
            "mae": 0.30586626402058176,
            "precision": 0.7363834422657952,
            "recall": 0.7027027027027027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7386201172789151,
            "auditor_fn_violation": 0.013211212492118247,
            "auditor_fp_violation": 0.023375994085441405,
            "ave_precision_score": 0.7358243703162308,
            "fpr": 0.14364035087719298,
            "logloss": 2.1046488631282907,
            "mae": 0.3266746384393927,
            "precision": 0.7082405345211581,
            "recall": 0.6723044397463002
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7717619917875901,
            "auditor_fn_violation": 0.015767096996515222,
            "auditor_fp_violation": 0.015076710999923424,
            "ave_precision_score": 0.7672692801877152,
            "fpr": 0.15587266739846323,
            "logloss": 1.9468191000566295,
            "mae": 0.3047790016013457,
            "precision": 0.7215686274509804,
            "recall": 0.7650727650727651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7624056464154961,
            "auditor_fn_violation": 0.005190367567968548,
            "auditor_fp_violation": 0.02503696599128802,
            "ave_precision_score": 0.7109703546587574,
            "fpr": 0.15021929824561403,
            "logloss": 3.7113326936315336,
            "mae": 0.31021851400674405,
            "precision": 0.7145833333333333,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7829334030029159,
            "auditor_fn_violation": 0.01584925295133858,
            "auditor_fp_violation": 0.01974574324151839,
            "ave_precision_score": 0.7354952296305335,
            "fpr": 0.14818880351262348,
            "logloss": 3.3960001155289414,
            "mae": 0.2922180240961695,
            "precision": 0.7267206477732794,
            "recall": 0.7463617463617463
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7688157061042394,
            "auditor_fn_violation": 0.006864081450984757,
            "auditor_fp_violation": 0.027527174999000918,
            "ave_precision_score": 0.7652666542734698,
            "fpr": 0.18421052631578946,
            "logloss": 1.8344480126675164,
            "mae": 0.3062226566668566,
            "precision": 0.6865671641791045,
            "recall": 0.7780126849894292
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8004251880484329,
            "auditor_fn_violation": 0.010499987448395792,
            "auditor_fp_violation": 0.017575881346846036,
            "ave_precision_score": 0.7961021646924514,
            "fpr": 0.17672886937431395,
            "logloss": 1.6745266330362294,
            "mae": 0.2864822438731223,
            "precision": 0.7135231316725978,
            "recall": 0.8336798336798337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7577422957567413,
            "auditor_fn_violation": 0.019474889655428214,
            "auditor_fp_violation": 0.033039603564720466,
            "ave_precision_score": 0.7572615104981921,
            "fpr": 0.15570175438596492,
            "logloss": 1.177109557155116,
            "mae": 0.3105177578992816,
            "precision": 0.7041666666666667,
            "recall": 0.7145877378435518
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7978146364310583,
            "auditor_fn_violation": 0.02566917166258549,
            "auditor_fp_violation": 0.015291144410691036,
            "ave_precision_score": 0.7964885232554774,
            "fpr": 0.14270032930845225,
            "logloss": 1.0149214184033635,
            "mae": 0.28507552737291925,
            "precision": 0.738430583501006,
            "recall": 0.762993762993763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7663572439372858,
            "auditor_fn_violation": 0.00804634472015133,
            "auditor_fp_violation": 0.028199056867681736,
            "ave_precision_score": 0.7610688954320873,
            "fpr": 0.21710526315789475,
            "logloss": 1.987888752893626,
            "mae": 0.3143381800528802,
            "precision": 0.669449081803005,
            "recall": 0.8477801268498943
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8014179947365109,
            "auditor_fn_violation": 0.004082694532749418,
            "auditor_fp_violation": 0.019528757052051163,
            "ave_precision_score": 0.7961811350750714,
            "fpr": 0.20856201975850713,
            "logloss": 1.7934745569717945,
            "mae": 0.29306261192090777,
            "precision": 0.6885245901639344,
            "recall": 0.8731808731808732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7871962776982533,
            "auditor_fn_violation": 0.012499536367345425,
            "auditor_fp_violation": 0.022666646685049755,
            "ave_precision_score": 0.7860679886091622,
            "fpr": 0.12938596491228072,
            "logloss": 1.122982089051675,
            "mae": 0.28711822787147573,
            "precision": 0.7440347071583514,
            "recall": 0.7251585623678647
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.823611076448894,
            "auditor_fn_violation": 0.02079914922944561,
            "auditor_fp_violation": 0.017307839583386518,
            "ave_precision_score": 0.8226371863651293,
            "fpr": 0.13172338090010977,
            "logloss": 0.9383240280558282,
            "mae": 0.2600050413411562,
            "precision": 0.757085020242915,
            "recall": 0.7775467775467776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7394324796033233,
            "auditor_fn_violation": 0.010058510441007383,
            "auditor_fp_violation": 0.027587119849738245,
            "ave_precision_score": 0.7347011327176477,
            "fpr": 0.32785087719298245,
            "logloss": 2.1986450471088235,
            "mae": 0.38302207576813535,
            "precision": 0.5970350404312669,
            "recall": 0.9365750528541226
        },
        "train": {
            "accuracy": 0.6388583973655324,
            "auc_prc": 0.7650006653959438,
            "auditor_fn_violation": 0.0035692198151034598,
            "auditor_fp_violation": 0.014721874760677003,
            "ave_precision_score": 0.7599962757264163,
            "fpr": 0.34357848518111966,
            "logloss": 2.0741763365803965,
            "mae": 0.35991849719506397,
            "precision": 0.5976863753213367,
            "recall": 0.9667359667359667
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7668017565319036,
            "auditor_fn_violation": 0.017212362301101604,
            "auditor_fp_violation": 0.025668884626143952,
            "ave_precision_score": 0.7672033740833848,
            "fpr": 0.14583333333333334,
            "logloss": 1.1105831127695032,
            "mae": 0.29994593127729324,
            "precision": 0.718816067653277,
            "recall": 0.718816067653277
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.807718870787696,
            "auditor_fn_violation": 0.020114516272584336,
            "auditor_fp_violation": 0.020258851760140917,
            "ave_precision_score": 0.8080831074680034,
            "fpr": 0.14709110867178923,
            "logloss": 0.9783946122938637,
            "mae": 0.27844564585019566,
            "precision": 0.7309236947791165,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.752362244624933,
            "auditor_fn_violation": 0.003671970624235013,
            "auditor_fp_violation": 0.028878431842704715,
            "ave_precision_score": 0.7481906104978628,
            "fpr": 0.15679824561403508,
            "logloss": 1.8874849946487757,
            "mae": 0.3058301747723339,
            "precision": 0.7045454545454546,
            "recall": 0.7209302325581395
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7627288396936047,
            "auditor_fn_violation": 0.011657017145491354,
            "auditor_fp_violation": 0.02131570214178133,
            "ave_precision_score": 0.7550197907587534,
            "fpr": 0.15806805708013172,
            "logloss": 1.894629714338295,
            "mae": 0.28810737666046665,
            "precision": 0.7176470588235294,
            "recall": 0.760914760914761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 12669,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7191683784717358,
            "auditor_fn_violation": 0.04610363117095064,
            "auditor_fp_violation": 0.05674779203133117,
            "ave_precision_score": 0.7192402533716451,
            "fpr": 0.19298245614035087,
            "logloss": 1.8875723631511125,
            "mae": 0.33402360995988634,
            "precision": 0.6840215439856373,
            "recall": 0.8054968287526427
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7294803820980371,
            "auditor_fn_violation": 0.052538733109534434,
            "auditor_fp_violation": 0.04730809486125649,
            "ave_precision_score": 0.7284641125541665,
            "fpr": 0.18551042810098792,
            "logloss": 2.0728242408404856,
            "mae": 0.3371002898280648,
            "precision": 0.6949458483754513,
            "recall": 0.8004158004158004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 12669,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7630964936755984,
            "auditor_fn_violation": 0.006254404510218466,
            "auditor_fp_violation": 0.017441453862446565,
            "ave_precision_score": 0.7598527386776466,
            "fpr": 0.2850877192982456,
            "logloss": 1.8573634164365294,
            "mae": 0.3464584788339194,
            "precision": 0.6237337192474675,
            "recall": 0.9112050739957717
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7764871358637204,
            "auditor_fn_violation": 0.005050309111780023,
            "auditor_fp_violation": 0.010290250938146183,
            "ave_precision_score": 0.7725818290258437,
            "fpr": 0.29747530186608123,
            "logloss": 1.8580873737895833,
            "mae": 0.3315809180874499,
            "precision": 0.6256906077348067,
            "recall": 0.9417879417879418
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 12669,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6263192672444309,
            "auditor_fn_violation": 0.014687882496940025,
            "auditor_fp_violation": 0.022062202773448437,
            "ave_precision_score": 0.5293513548269357,
            "fpr": 0.36622807017543857,
            "logloss": 7.882952177717307,
            "mae": 0.4337621518173468,
            "precision": 0.5564409030544488,
            "recall": 0.8858350951374208
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6569170868325311,
            "auditor_fn_violation": 0.014655709496543746,
            "auditor_fp_violation": 0.01738442294437498,
            "ave_precision_score": 0.5630654628356625,
            "fpr": 0.3402854006586169,
            "logloss": 7.1792908521104355,
            "mae": 0.39588095665677797,
            "precision": 0.5894039735099338,
            "recall": 0.9251559251559252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7685608365207223,
            "auditor_fn_violation": 0.00663226512369719,
            "auditor_fp_violation": 0.021005674779203135,
            "ave_precision_score": 0.7691319592024379,
            "fpr": 0.12938596491228072,
            "logloss": 1.3096082201287935,
            "mae": 0.30690059508061907,
            "precision": 0.7318181818181818,
            "recall": 0.6807610993657506
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8052742276771975,
            "auditor_fn_violation": 0.022398908238644797,
            "auditor_fp_violation": 0.01667475046588212,
            "ave_precision_score": 0.8056176104506514,
            "fpr": 0.1251372118551043,
            "logloss": 1.1300138093690912,
            "mae": 0.2777123009157368,
            "precision": 0.759493670886076,
            "recall": 0.7484407484407485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7828269131536036,
            "auditor_fn_violation": 0.004569099810837878,
            "auditor_fp_violation": 0.026550573472405394,
            "ave_precision_score": 0.7804623451269745,
            "fpr": 0.2236842105263158,
            "logloss": 1.821291243632603,
            "mae": 0.3071629357936329,
            "precision": 0.6677524429967426,
            "recall": 0.8668076109936576
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8162408093656113,
            "auditor_fn_violation": 0.0009265366016189307,
            "auditor_fp_violation": 0.016005922446583106,
            "ave_precision_score": 0.8120281958918152,
            "fpr": 0.2030735455543359,
            "logloss": 1.6509424136733952,
            "mae": 0.28006218773157665,
            "precision": 0.6996753246753247,
            "recall": 0.896049896049896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7662940574540562,
            "auditor_fn_violation": 0.003804105930788917,
            "auditor_fp_violation": 0.024132797826000085,
            "ave_precision_score": 0.7610671018435626,
            "fpr": 0.2149122807017544,
            "logloss": 2.0145435957897417,
            "mae": 0.31636169024123445,
            "precision": 0.67003367003367,
            "recall": 0.8414376321353065
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8016166455977813,
            "auditor_fn_violation": 0.004130618839729711,
            "auditor_fp_violation": 0.016480739284711415,
            "ave_precision_score": 0.7964060482992489,
            "fpr": 0.21295279912184412,
            "logloss": 1.8150726744790573,
            "mae": 0.2951192659647647,
            "precision": 0.6855753646677472,
            "recall": 0.8794178794178794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6668857034419864,
            "auditor_fn_violation": 0.011062275138162535,
            "auditor_fp_violation": 0.017086780162250736,
            "ave_precision_score": 0.5791484222080682,
            "fpr": 0.2050438596491228,
            "logloss": 6.859122641878517,
            "mae": 0.3693371958853994,
            "precision": 0.6587591240875912,
            "recall": 0.7632135306553911
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6668134561335667,
            "auditor_fn_violation": 0.012193312961699357,
            "auditor_fp_violation": 0.01021111479845813,
            "ave_precision_score": 0.5838400908633781,
            "fpr": 0.2074643249176729,
            "logloss": 6.574618727558926,
            "mae": 0.3733511721885483,
            "precision": 0.6654867256637168,
            "recall": 0.7817047817047817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.6385231632729168,
            "auditor_fn_violation": 0.00938856125514632,
            "auditor_fp_violation": 0.022451844303241028,
            "ave_precision_score": 0.6399791789497243,
            "fpr": 0.33223684210526316,
            "logloss": 1.6135917309544803,
            "mae": 0.4072223517477051,
            "precision": 0.5768156424581006,
            "recall": 0.8731501057082452
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6375123644711501,
            "auditor_fn_violation": 0.007195492376612027,
            "auditor_fp_violation": 0.012707732366681141,
            "ave_precision_score": 0.6384780655825935,
            "fpr": 0.3380900109769484,
            "logloss": 1.6321750918685887,
            "mae": 0.40533529543640134,
            "precision": 0.5757575757575758,
            "recall": 0.8690228690228691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8158595740182502,
            "auditor_fn_violation": 0.010628778606134787,
            "auditor_fp_violation": 0.027584622147624183,
            "ave_precision_score": 0.8163906281031352,
            "fpr": 0.13267543859649122,
            "logloss": 0.7532725758099638,
            "mae": 0.2850415005643804,
            "precision": 0.7430997876857749,
            "recall": 0.7399577167019028
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8528334422614137,
            "auditor_fn_violation": 0.02666188945003435,
            "auditor_fp_violation": 0.01623567252954842,
            "ave_precision_score": 0.8530959401921158,
            "fpr": 0.12294182217343579,
            "logloss": 0.6145411552528532,
            "mae": 0.253150296746253,
            "precision": 0.7751004016064257,
            "recall": 0.8024948024948025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 12669,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7496993675550498,
            "auditor_fn_violation": 0.0028606134787285404,
            "auditor_fp_violation": 0.027189985213603492,
            "ave_precision_score": 0.7479625073414293,
            "fpr": 0.15350877192982457,
            "logloss": 1.8788326804496618,
            "mae": 0.3040834887668876,
            "precision": 0.7077244258872651,
            "recall": 0.7167019027484144
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7629334012062396,
            "auditor_fn_violation": 0.01685109917821224,
            "auditor_fp_violation": 0.020223112858346312,
            "ave_precision_score": 0.7587589773853409,
            "fpr": 0.15806805708013172,
            "logloss": 1.8082087333757482,
            "mae": 0.2882391871095748,
            "precision": 0.7165354330708661,
            "recall": 0.7567567567567568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 12669,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7190976531237743,
            "auditor_fn_violation": 0.036974704202366385,
            "auditor_fp_violation": 0.04181153338928187,
            "ave_precision_score": 0.6972711389465224,
            "fpr": 0.1962719298245614,
            "logloss": 3.546644538969441,
            "mae": 0.3112137610859843,
            "precision": 0.6797853309481217,
            "recall": 0.8033826638477801
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7314379140988441,
            "auditor_fn_violation": 0.043535809726808636,
            "auditor_fp_violation": 0.03710208562019759,
            "ave_precision_score": 0.710086943471293,
            "fpr": 0.18880351262349068,
            "logloss": 3.8708989971938297,
            "mae": 0.3113065372384699,
            "precision": 0.69009009009009,
            "recall": 0.7962577962577962
        }
    }
]