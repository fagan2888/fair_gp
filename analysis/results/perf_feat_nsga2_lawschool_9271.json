[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8015951142099826,
            "auditor_fn_violation": 0.011698249362723045,
            "auditor_fp_violation": 0.011787280701754386,
            "ave_precision_score": 0.7276073809547945,
            "fpr": 0.12171052631578948,
            "logloss": 0.5842422391346477,
            "mae": 0.40574774391164903,
            "precision": 0.7344497607655502,
            "recall": 0.655982905982906
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8163244368899456,
            "auditor_fn_violation": 0.01224178196979759,
            "auditor_fp_violation": 0.0179634532188287,
            "ave_precision_score": 0.7434648341419849,
            "fpr": 0.1207464324917673,
            "logloss": 0.574781283730817,
            "mae": 0.40396161195868063,
            "precision": 0.7488584474885844,
            "recall": 0.6748971193415638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5120245875568039,
            "auditor_fn_violation": 0.014057579847053536,
            "auditor_fp_violation": 0.009423897581792321,
            "ave_precision_score": 0.5234296178245124,
            "fpr": 0.06578947368421052,
            "logloss": 0.7763348928338693,
            "mae": 0.49911439948176084,
            "precision": 0.5081967213114754,
            "recall": 0.13247863247863248
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5235909348445955,
            "auditor_fn_violation": 0.004219123379996671,
            "auditor_fp_violation": 0.004752372957964747,
            "ave_precision_score": 0.536924090963022,
            "fpr": 0.06147091108671789,
            "logloss": 0.7445706124489565,
            "mae": 0.5000695642799499,
            "precision": 0.5483870967741935,
            "recall": 0.13991769547325103
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8029617427033673,
            "auditor_fn_violation": 0.011698249362723045,
            "auditor_fp_violation": 0.011787280701754386,
            "ave_precision_score": 0.7294060780617366,
            "fpr": 0.12171052631578948,
            "logloss": 0.5825400282671567,
            "mae": 0.4050172524886173,
            "precision": 0.7344497607655502,
            "recall": 0.655982905982906
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8185559688640275,
            "auditor_fn_violation": 0.013499839637173468,
            "auditor_fp_violation": 0.0179634532188287,
            "ave_precision_score": 0.746200723616526,
            "fpr": 0.1207464324917673,
            "logloss": 0.5726422541284188,
            "mae": 0.4029344951020376,
            "precision": 0.7494305239179955,
            "recall": 0.676954732510288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4984052604764272,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5088576937987515,
            "fpr": 0.0581140350877193,
            "logloss": 0.6936474086592163,
            "mae": 0.4996780381586991,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.512205276462731,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5200953960239716,
            "fpr": 0.05378704720087816,
            "logloss": 0.6951725165170946,
            "mae": 0.5004486280660074,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7947362336934459,
            "auditor_fn_violation": 0.008284600389863553,
            "auditor_fp_violation": 0.017237632369211314,
            "ave_precision_score": 0.7556703776924822,
            "fpr": 0.14583333333333334,
            "logloss": 0.5998371557327287,
            "mae": 0.38695856159858777,
            "precision": 0.7096069868995634,
            "recall": 0.6944444444444444
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.816274991390445,
            "auditor_fn_violation": 0.012128850401810526,
            "auditor_fp_violation": 0.022263834183508757,
            "ave_precision_score": 0.7766448700927734,
            "fpr": 0.13172338090010977,
            "logloss": 0.5712244063864375,
            "mae": 0.376866300234062,
            "precision": 0.7468354430379747,
            "recall": 0.7283950617283951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7241138187935037,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.6198877270634886,
            "fpr": 0.008771929824561403,
            "logloss": 0.6390314109247011,
            "mae": 0.45452470871570866,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7402656034717574,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.64032237688719,
            "fpr": 0.005488474204171241,
            "logloss": 0.6339606718698048,
            "mae": 0.45254940003909083,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7724148755504381,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.602384836178897,
            "fpr": 0.008771929824561403,
            "logloss": 0.638971367949023,
            "mae": 0.45454731426740946,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.794817513935812,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.6251412130691673,
            "fpr": 0.005488474204171241,
            "logloss": 0.6348116453969576,
            "mae": 0.4535697186948439,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4992623344948773,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5207467185718173,
            "fpr": 0.0581140350877193,
            "logloss": 0.6938111198091925,
            "mae": 0.4996925704507974,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120323939782954,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5315800549835652,
            "fpr": 0.05378704720087816,
            "logloss": 0.6954387927951367,
            "mae": 0.5005165612004068,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7212302587626315,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5600039545346079,
            "fpr": 0.2949561403508772,
            "logloss": 0.6841295225245866,
            "mae": 0.4922351878986024,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7250594782415739,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5693761236970865,
            "fpr": 0.305159165751921,
            "logloss": 0.6848705458768267,
            "mae": 0.49232415764967774,
            "precision": 0.5635792778649922,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8019600688901339,
            "auditor_fn_violation": 0.008069050832208728,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.7279673489442849,
            "fpr": 0.14692982456140352,
            "logloss": 0.592287459860234,
            "mae": 0.39696916064508914,
            "precision": 0.7093275488069414,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8234801062370469,
            "auditor_fn_violation": 0.013723444141787845,
            "auditor_fp_violation": 0.023330535287660624,
            "ave_precision_score": 0.7514336189266285,
            "fpr": 0.132821075740944,
            "logloss": 0.5688216282688038,
            "mae": 0.3876524570957235,
            "precision": 0.7463312368972747,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995547699264938,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.521230990481604,
            "fpr": 0.0581140350877193,
            "logloss": 0.6937314149651059,
            "mae": 0.4996880673590982,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120418977308379,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322389758335795,
            "fpr": 0.05378704720087816,
            "logloss": 0.6953083988516136,
            "mae": 0.5004857085342596,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7958713107105558,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6493070635510159,
            "fpr": 0.010964912280701754,
            "logloss": 0.6087771141566924,
            "mae": 0.4289880830859929,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8091274730462092,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6598091448356945,
            "fpr": 0.006586169045005488,
            "logloss": 0.6119802055098407,
            "mae": 0.4337132746838319,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7917743195746403,
            "auditor_fn_violation": 0.007000674763832662,
            "auditor_fp_violation": 0.011836672198514307,
            "ave_precision_score": 0.7271845108768926,
            "fpr": 0.13925438596491227,
            "logloss": 0.611327526572909,
            "mae": 0.3954894748218194,
            "precision": 0.7066974595842956,
            "recall": 0.6538461538461539
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8185669543872848,
            "auditor_fn_violation": 0.018303948539343102,
            "auditor_fp_violation": 0.01771550332536967,
            "ave_precision_score": 0.7553188972981526,
            "fpr": 0.12294182217343579,
            "logloss": 0.5876601365514607,
            "mae": 0.384985683696461,
            "precision": 0.7477477477477478,
            "recall": 0.6831275720164609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7870503645695109,
            "auditor_fn_violation": 0.0100558554505923,
            "auditor_fp_violation": 0.027649359886201996,
            "ave_precision_score": 0.7865485486019141,
            "fpr": 0.10964912280701754,
            "logloss": 0.5814940230397239,
            "mae": 0.3705992862018512,
            "precision": 0.7566909975669099,
            "recall": 0.6645299145299145
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8101918452871695,
            "auditor_fn_violation": 0.013852186129293098,
            "auditor_fp_violation": 0.019624200942726155,
            "ave_precision_score": 0.8091974622624609,
            "fpr": 0.09220636663007684,
            "logloss": 0.5591483912292062,
            "mae": 0.3653816135792403,
            "precision": 0.7915632754342432,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7182295067694049,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10291212264896475,
            "ave_precision_score": 0.5489486744155675,
            "fpr": 0.2982456140350877,
            "logloss": 0.6854247878548231,
            "mae": 0.4929520082578324,
            "precision": 0.5612903225806452,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.7212778905814987,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10154322980564344,
            "ave_precision_score": 0.5563683183682671,
            "fpr": 0.3040614709110867,
            "logloss": 0.6865233395482544,
            "mae": 0.49343619905371305,
            "precision": 0.5644654088050315,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.71959406995234,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5509780247901889,
            "fpr": 0.2949561403508772,
            "logloss": 0.685345446607099,
            "mae": 0.49269785526159565,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.720834825111479,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5557137483940404,
            "fpr": 0.305159165751921,
            "logloss": 0.6868641273245168,
            "mae": 0.4933575901451278,
            "precision": 0.5635792778649922,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.71959406995234,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5509780247901889,
            "fpr": 0.2949561403508772,
            "logloss": 0.6855584857144389,
            "mae": 0.49257063630380127,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.720834825111479,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5557137483940404,
            "fpr": 0.305159165751921,
            "logloss": 0.6869524245582372,
            "mae": 0.4931578597567084,
            "precision": 0.5635792778649922,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995398014558606,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5214070205778829,
            "fpr": 0.0581140350877193,
            "logloss": 0.6937253076600107,
            "mae": 0.49968762986623405,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120645295575061,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322687048528438,
            "fpr": 0.05378704720087816,
            "logloss": 0.6952983605098941,
            "mae": 0.5004832284968719,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7905778188563034,
            "auditor_fn_violation": 0.005672233468286098,
            "auditor_fp_violation": 0.0029215070333491397,
            "ave_precision_score": 0.7907759680154995,
            "fpr": 0.0581140350877193,
            "logloss": 0.669532303778426,
            "mae": 0.37226715969409907,
            "precision": 0.78099173553719,
            "recall": 0.40384615384615385
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.7965652263509428,
            "auditor_fn_violation": 0.006821066706418602,
            "auditor_fp_violation": 0.004067927939562214,
            "ave_precision_score": 0.7966972625054687,
            "fpr": 0.04720087815587267,
            "logloss": 0.6870206033734279,
            "mae": 0.3865063037706946,
            "precision": 0.7952380952380952,
            "recall": 0.3436213991769547
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.71959406995234,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5509780247901889,
            "fpr": 0.2949561403508772,
            "logloss": 0.685345446607099,
            "mae": 0.49269785526159565,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.720834825111479,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5557137483940404,
            "fpr": 0.305159165751921,
            "logloss": 0.6868641273245168,
            "mae": 0.4933575901451278,
            "precision": 0.5635792778649922,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7228658485792053,
            "auditor_fn_violation": 0.08375506072874493,
            "auditor_fp_violation": 0.09752844950213373,
            "ave_precision_score": 0.561035046909435,
            "fpr": 0.27631578947368424,
            "logloss": 0.6801567950126272,
            "mae": 0.48640621804811973,
            "precision": 0.5757575757575758,
            "recall": 0.7307692307692307
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7268540450597032,
            "auditor_fn_violation": 0.09424365211656345,
            "auditor_fp_violation": 0.09379996125782916,
            "ave_precision_score": 0.5696630571382032,
            "fpr": 0.283205268935236,
            "logloss": 0.6776843364545316,
            "mae": 0.4858935555171234,
            "precision": 0.5777414075286416,
            "recall": 0.7263374485596708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7637489161996102,
            "auditor_fn_violation": 0.004969354475933423,
            "auditor_fp_violation": 0.02529832464042993,
            "ave_precision_score": 0.5553797426860516,
            "fpr": 0.39364035087719296,
            "logloss": 13.37629932916244,
            "mae": 0.41333810545957184,
            "precision": 0.5578817733990148,
            "recall": 0.967948717948718
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7791669823971752,
            "auditor_fn_violation": 0.004341089473422685,
            "auditor_fp_violation": 0.01600826499644863,
            "ave_precision_score": 0.5779944007271801,
            "fpr": 0.38199780461031835,
            "logloss": 12.894723480014425,
            "mae": 0.4006237823559387,
            "precision": 0.5745721271393643,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 9271,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7871174191389902,
            "auditor_fn_violation": 0.007961276053381322,
            "auditor_fp_violation": 0.01266397976924293,
            "ave_precision_score": 0.7716320254502356,
            "fpr": 0.1337719298245614,
            "logloss": 0.5918947163041557,
            "mae": 0.3784942004845984,
            "precision": 0.7182448036951501,
            "recall": 0.6645299145299145
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8224839642054911,
            "auditor_fn_violation": 0.013321407759753906,
            "auditor_fp_violation": 0.01951055724155744,
            "ave_precision_score": 0.8079797009284774,
            "fpr": 0.11855104281009879,
            "logloss": 0.5483091269707623,
            "mae": 0.36171784692747533,
            "precision": 0.7594654788418709,
            "recall": 0.7016460905349794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7724148755504381,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.602384836178897,
            "fpr": 0.008771929824561403,
            "logloss": 0.638971367949023,
            "mae": 0.45454731426740946,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.794817513935812,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.6251412130691673,
            "fpr": 0.005488474204171241,
            "logloss": 0.6348116453969576,
            "mae": 0.4535697186948439,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.7006166914855663,
            "auditor_fn_violation": 0.002021948568001219,
            "auditor_fp_violation": 0.0008100205468626521,
            "ave_precision_score": 0.5317963066375045,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6868362257438413,
            "mae": 0.49076676603994873,
            "precision": 0.8620689655172413,
            "recall": 0.053418803418803416
        },
        "train": {
            "accuracy": 0.4972557628979144,
            "auc_prc": 0.7494961670052277,
            "auditor_fn_violation": 0.007060481630551158,
            "auditor_fp_violation": 0.0011209401433460325,
            "ave_precision_score": 0.5580600223884887,
            "fpr": 0.0021953896816684962,
            "logloss": 0.6833834556637388,
            "mae": 0.4896906436994492,
            "precision": 0.9375,
            "recall": 0.06172839506172839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7972163898333896,
            "auditor_fn_violation": 0.006663292847503373,
            "auditor_fp_violation": 0.03442093409198674,
            "ave_precision_score": 0.7961525334944466,
            "fpr": 0.2565789473684211,
            "logloss": 0.7763222243605246,
            "mae": 0.36858270614893107,
            "precision": 0.6320754716981132,
            "recall": 0.8589743589743589
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8249607110181325,
            "auditor_fn_violation": 0.0046392288129085335,
            "auditor_fp_violation": 0.020551430231807326,
            "ave_precision_score": 0.8237142557102847,
            "fpr": 0.2261251372118551,
            "logloss": 0.8256693366323632,
            "mae": 0.35469003126749105,
            "precision": 0.6750788643533123,
            "recall": 0.8806584362139918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5311253196833509,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5264316687422659,
            "fpr": 0.0581140350877193,
            "logloss": 0.6937029754090025,
            "mae": 0.49965371698010386,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.515944072613747,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5424397468545165,
            "fpr": 0.05378704720087816,
            "logloss": 0.6952591349290994,
            "mae": 0.5004410452560065,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7239639659022099,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.6199357102693666,
            "fpr": 0.008771929824561403,
            "logloss": 0.6402806299417126,
            "mae": 0.45501903754969436,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7405411727270028,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.6411491669000066,
            "fpr": 0.005488474204171241,
            "logloss": 0.6327718035725947,
            "mae": 0.45194296026857966,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.7635317974281673,
            "auditor_fn_violation": 0.00423836032388664,
            "auditor_fp_violation": 0.016180654338549077,
            "ave_precision_score": 0.5551626453988889,
            "fpr": 0.42105263157894735,
            "logloss": 13.431447086532383,
            "mae": 0.43845897314766963,
            "precision": 0.5444839857651246,
            "recall": 0.9807692307692307
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7789300568469488,
            "auditor_fn_violation": 0.0010163841118835638,
            "auditor_fp_violation": 0.008161683993026417,
            "ave_precision_score": 0.5777575046451946,
            "fpr": 0.41602634467618005,
            "logloss": 12.950979122939895,
            "mae": 0.4268779120426272,
            "precision": 0.5572429906542056,
            "recall": 0.9814814814814815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5723684210526315,
            "auc_prc": 0.7635387720900416,
            "auditor_fn_violation": 0.00423836032388664,
            "auditor_fp_violation": 0.015380512091038401,
            "ave_precision_score": 0.5551696193574011,
            "fpr": 0.41776315789473684,
            "logloss": 13.4222254213085,
            "mae": 0.435569539072563,
            "precision": 0.5464285714285714,
            "recall": 0.9807692307692307
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.7789467506820206,
            "auditor_fn_violation": 0.0021728033680710837,
            "auditor_fp_violation": 0.004199651320462347,
            "ave_precision_score": 0.5777741967750311,
            "fpr": 0.4127332601536773,
            "logloss": 12.939897132488351,
            "mae": 0.42403569261088014,
            "precision": 0.5586854460093896,
            "recall": 0.9794238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7637279583806521,
            "auditor_fn_violation": 0.004610886189833559,
            "auditor_fp_violation": 0.02529832464042993,
            "ave_precision_score": 0.5553587871071063,
            "fpr": 0.39364035087719296,
            "logloss": 13.377703895128693,
            "mae": 0.4130297932138251,
            "precision": 0.5573366214549939,
            "recall": 0.9658119658119658
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7791582948438608,
            "auditor_fn_violation": 0.004341089473422685,
            "auditor_fp_violation": 0.01600826499644863,
            "ave_precision_score": 0.5779857139205498,
            "fpr": 0.38199780461031835,
            "logloss": 12.896037173129614,
            "mae": 0.40044823626269593,
            "precision": 0.5745721271393643,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995250696692716,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5214079615530159,
            "fpr": 0.0581140350877193,
            "logloss": 0.6936293702123871,
            "mae": 0.49967193737495363,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120460778557004,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322491289109084,
            "fpr": 0.05378704720087816,
            "logloss": 0.6951443049567855,
            "mae": 0.5004372313438734,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.837496823394851,
            "auditor_fn_violation": 0.015969410706252813,
            "auditor_fp_violation": 0.015350877192982455,
            "ave_precision_score": 0.837745226373394,
            "fpr": 0.08333333333333333,
            "logloss": 0.9190390177815269,
            "mae": 0.2830085233219541,
            "precision": 0.7978723404255319,
            "recall": 0.6410256410256411
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8399449099804817,
            "auditor_fn_violation": 0.023751767379039012,
            "auditor_fp_violation": 0.017431394072447863,
            "ave_precision_score": 0.8402130905322317,
            "fpr": 0.0845225027442371,
            "logloss": 0.8603891621867558,
            "mae": 0.2889397784046176,
            "precision": 0.8040712468193384,
            "recall": 0.6502057613168725
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7724148755504381,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.602384836178897,
            "fpr": 0.008771929824561403,
            "logloss": 0.6390774812678495,
            "mae": 0.4544674175742425,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.7952320230951772,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.6256844517811303,
            "fpr": 0.005488474204171241,
            "logloss": 0.6337253627541071,
            "mae": 0.4525096022598568,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7182295067694049,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10291212264896475,
            "ave_precision_score": 0.5489486744155675,
            "fpr": 0.2982456140350877,
            "logloss": 0.6854247878548231,
            "mae": 0.4929520082578324,
            "precision": 0.5612903225806452,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.7212778905814987,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10154322980564344,
            "ave_precision_score": 0.5563683183682671,
            "fpr": 0.3040614709110867,
            "logloss": 0.6865233395482544,
            "mae": 0.49343619905371305,
            "precision": 0.5644654088050315,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7216330075743631,
            "auditor_fn_violation": 0.081407444894287,
            "auditor_fp_violation": 0.09632823613086772,
            "ave_precision_score": 0.5614380495615133,
            "fpr": 0.2730263157894737,
            "logloss": 0.6801148452299289,
            "mae": 0.48600567128966776,
            "precision": 0.576530612244898,
            "recall": 0.7243589743589743
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.728038654893946,
            "auditor_fn_violation": 0.0938958228871633,
            "auditor_fp_violation": 0.09226060566927102,
            "ave_precision_score": 0.572224029399716,
            "fpr": 0.278814489571899,
            "logloss": 0.6769751596243154,
            "mae": 0.48515167843824425,
            "precision": 0.5808580858085809,
            "recall": 0.7242798353909465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7634513478931961,
            "auditor_fn_violation": 0.0024038461538461544,
            "auditor_fp_violation": 0.01296279832464044,
            "ave_precision_score": 0.5550822018199273,
            "fpr": 0.42214912280701755,
            "logloss": 13.429360433514663,
            "mae": 0.43791603320311734,
            "precision": 0.5432977461447213,
            "recall": 0.9786324786324786
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7789747533612306,
            "auditor_fn_violation": 0.0028503927759934585,
            "auditor_fp_violation": 0.004592238651772468,
            "ave_precision_score": 0.5778021955657275,
            "fpr": 0.4094401756311745,
            "logloss": 12.939878041698723,
            "mae": 0.4238671391642536,
            "precision": 0.5606595995288575,
            "recall": 0.9794238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8346997494668051,
            "auditor_fn_violation": 0.012321468735942422,
            "auditor_fp_violation": 0.010312944523470844,
            "ave_precision_score": 0.83499106976838,
            "fpr": 0.0800438596491228,
            "logloss": 0.8141742173515666,
            "mae": 0.279587549188235,
            "precision": 0.8089005235602095,
            "recall": 0.6602564102564102
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8452835085151131,
            "auditor_fn_violation": 0.010963396620184028,
            "auditor_fp_violation": 0.013980758055143027,
            "ave_precision_score": 0.8455605637100627,
            "fpr": 0.07793633369923161,
            "logloss": 0.776313682087451,
            "mae": 0.2789851476163269,
            "precision": 0.821608040201005,
            "recall": 0.6728395061728395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7637448821033339,
            "auditor_fn_violation": 0.004969354475933423,
            "auditor_fp_violation": 0.02529832464042993,
            "ave_precision_score": 0.555375708284653,
            "fpr": 0.39364035087719296,
            "logloss": 13.376663589443316,
            "mae": 0.4132852703564423,
            "precision": 0.5578817733990148,
            "recall": 0.967948717948718
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7791645417830236,
            "auditor_fn_violation": 0.004341089473422685,
            "auditor_fp_violation": 0.01600826499644863,
            "ave_precision_score": 0.5779919602978122,
            "fpr": 0.38199780461031835,
            "logloss": 12.894194155555994,
            "mae": 0.40071308634001235,
            "precision": 0.5745721271393643,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.71959406995234,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5509780247901889,
            "fpr": 0.2949561403508772,
            "logloss": 0.6855584857144389,
            "mae": 0.49257063630380127,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.720834825111479,
            "auditor_fn_violation": 0.09408554792138156,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5557137483940404,
            "fpr": 0.305159165751921,
            "logloss": 0.6869524245582372,
            "mae": 0.4931578597567084,
            "precision": 0.5635792778649922,
            "recall": 0.7386831275720165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7216330075743631,
            "auditor_fn_violation": 0.081407444894287,
            "auditor_fp_violation": 0.09632823613086772,
            "ave_precision_score": 0.5614380495615133,
            "fpr": 0.2730263157894737,
            "logloss": 0.6801020910353516,
            "mae": 0.4859234812881863,
            "precision": 0.576530612244898,
            "recall": 0.7243589743589743
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.728038654893946,
            "auditor_fn_violation": 0.0938958228871633,
            "auditor_fp_violation": 0.09226060566927102,
            "ave_precision_score": 0.572224029399716,
            "fpr": 0.278814489571899,
            "logloss": 0.6768685389860468,
            "mae": 0.485018920198361,
            "precision": 0.5808580858085809,
            "recall": 0.7242798353909465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 9271,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.723845781598904,
            "mae": 0.5131578947368421,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.42573581550669,
            "mae": 0.5334796926454446,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7958713107105558,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6493070635510159,
            "fpr": 0.010964912280701754,
            "logloss": 0.6087771139913329,
            "mae": 0.4289880830206369,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8091274730462092,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6598091448356945,
            "fpr": 0.006586169045005488,
            "logloss": 0.6119802055606742,
            "mae": 0.43371327474925964,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.765249235565631,
            "auditor_fn_violation": 0.010252661568451045,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.7398224259149786,
            "fpr": 0.14692982456140352,
            "logloss": 0.5865969032425499,
            "mae": 0.39270480839012745,
            "precision": 0.7086956521739131,
            "recall": 0.6965811965811965
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7989842098783588,
            "auditor_fn_violation": 0.014310688295320572,
            "auditor_fp_violation": 0.02155872667398464,
            "ave_precision_score": 0.7721028389075119,
            "fpr": 0.13062568605927552,
            "logloss": 0.5573749302670807,
            "mae": 0.38085620912480955,
            "precision": 0.7494736842105263,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7426502164879432,
            "auditor_fn_violation": 0.013101664417453895,
            "auditor_fp_violation": 0.014861901375059274,
            "ave_precision_score": 0.7428221367107534,
            "fpr": 0.05592105263157895,
            "logloss": 0.754970040847324,
            "mae": 0.39849075329389927,
            "precision": 0.7829787234042553,
            "recall": 0.39316239316239315
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7645781703691436,
            "auditor_fn_violation": 0.01072398169605146,
            "auditor_fp_violation": 0.011899012074643249,
            "ave_precision_score": 0.7645706460379411,
            "fpr": 0.04610318331503842,
            "logloss": 0.7677943418540589,
            "mae": 0.40827656709016574,
            "precision": 0.7920792079207921,
            "recall": 0.3292181069958848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.8064866331759368,
            "auditor_fn_violation": 0.011934885290148448,
            "auditor_fp_violation": 0.039933025130393575,
            "ave_precision_score": 0.804637671357856,
            "fpr": 0.28289473684210525,
            "logloss": 0.7545340497682888,
            "mae": 0.37492242669572523,
            "precision": 0.6205882352941177,
            "recall": 0.9017094017094017
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.8370574841323153,
            "auditor_fn_violation": 0.007223103088452523,
            "auditor_fp_violation": 0.025595660876864476,
            "ave_precision_score": 0.8330198892608635,
            "fpr": 0.2557628979143798,
            "logloss": 0.787828013007294,
            "mae": 0.3616370272312554,
            "precision": 0.6537890044576523,
            "recall": 0.9053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.793999362794336,
            "auditor_fn_violation": 0.007581721397510871,
            "auditor_fp_violation": 0.038710585585585586,
            "ave_precision_score": 0.7937858397206898,
            "fpr": 0.2532894736842105,
            "logloss": 0.5924253164511672,
            "mae": 0.3661866600588454,
            "precision": 0.6373626373626373,
            "recall": 0.8675213675213675
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8349597088217353,
            "auditor_fn_violation": 0.010389704254809756,
            "auditor_fp_violation": 0.02201071866726933,
            "ave_precision_score": 0.834421488291992,
            "fpr": 0.2217343578485181,
            "logloss": 0.5399392990009722,
            "mae": 0.34702401796333354,
            "precision": 0.6848673946957878,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.7634513478931961,
            "auditor_fn_violation": 0.0024038461538461544,
            "auditor_fp_violation": 0.01296279832464044,
            "ave_precision_score": 0.5550822018199273,
            "fpr": 0.42214912280701755,
            "logloss": 13.429795372825998,
            "mae": 0.4380452286183132,
            "precision": 0.5432977461447213,
            "recall": 0.9786324786324786
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7789734471341845,
            "auditor_fn_violation": 0.0028503927759934585,
            "auditor_fp_violation": 0.004592238651772468,
            "ave_precision_score": 0.5778008894808546,
            "fpr": 0.4094401756311745,
            "logloss": 12.940289264789907,
            "mae": 0.42398156209174226,
            "precision": 0.5606595995288575,
            "recall": 0.9794238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8017621973973544,
            "auditor_fn_violation": 0.00960601289548658,
            "auditor_fp_violation": 0.011587245139876728,
            "ave_precision_score": 0.731536454642515,
            "fpr": 0.13815789473684212,
            "logloss": 0.6051236914157477,
            "mae": 0.3927932900311262,
            "precision": 0.7155756207674944,
            "recall": 0.6773504273504274
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8263735782607544,
            "auditor_fn_violation": 0.012305023647870346,
            "auditor_fp_violation": 0.0207477238974624,
            "ave_precision_score": 0.7591805406821344,
            "fpr": 0.12843029637760703,
            "logloss": 0.5730879014207724,
            "mae": 0.3792455003041729,
            "precision": 0.7483870967741936,
            "recall": 0.7160493827160493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4991451023406431,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5207420739423454,
            "fpr": 0.0581140350877193,
            "logloss": 0.6936384271861589,
            "mae": 0.4996502589957233,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5121016938215348,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322500786786886,
            "fpr": 0.05378704720087816,
            "logloss": 0.6951751422774776,
            "mae": 0.500426342144494,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8019600688901339,
            "auditor_fn_violation": 0.008069050832208728,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.7279673489442849,
            "fpr": 0.14692982456140352,
            "logloss": 0.592287459860234,
            "mae": 0.39696916064508914,
            "precision": 0.7093275488069414,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8234801062370469,
            "auditor_fn_violation": 0.013723444141787845,
            "auditor_fp_violation": 0.023330535287660624,
            "ave_precision_score": 0.7514336189266285,
            "fpr": 0.132821075740944,
            "logloss": 0.5688216282688038,
            "mae": 0.3876524570957235,
            "precision": 0.7463312368972747,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8207643717361396,
            "auditor_fn_violation": 0.007127192982456144,
            "auditor_fp_violation": 0.012671388493756916,
            "ave_precision_score": 0.8202270048252214,
            "fpr": 0.09100877192982457,
            "logloss": 0.5373309471269098,
            "mae": 0.3361556423682997,
            "precision": 0.7945544554455446,
            "recall": 0.6858974358974359
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8500315579472018,
            "auditor_fn_violation": 0.01438748176155177,
            "auditor_fp_violation": 0.014936398269516371,
            "ave_precision_score": 0.8491403253941568,
            "fpr": 0.07574094401756312,
            "logloss": 0.511771257078564,
            "mae": 0.33014559931235243,
            "precision": 0.8248730964467005,
            "recall": 0.668724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7947362336934459,
            "auditor_fn_violation": 0.008284600389863553,
            "auditor_fp_violation": 0.017237632369211314,
            "ave_precision_score": 0.7556703776924822,
            "fpr": 0.14583333333333334,
            "logloss": 0.5998372717382366,
            "mae": 0.38695856173332066,
            "precision": 0.7096069868995634,
            "recall": 0.6944444444444444
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.816274991390445,
            "auditor_fn_violation": 0.012128850401810526,
            "auditor_fp_violation": 0.022263834183508757,
            "ave_precision_score": 0.7766448700927734,
            "fpr": 0.13172338090010977,
            "logloss": 0.5712244837121433,
            "mae": 0.37686630031226853,
            "precision": 0.7468354430379747,
            "recall": 0.7283950617283951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8031214821115085,
            "auditor_fn_violation": 0.009948080671764881,
            "auditor_fp_violation": 0.011574897265686742,
            "ave_precision_score": 0.7348570096276894,
            "fpr": 0.11293859649122807,
            "logloss": 0.5844419176445175,
            "mae": 0.40013378633088187,
            "precision": 0.743142144638404,
            "recall": 0.6367521367521367
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8196070737504013,
            "auditor_fn_violation": 0.007498656114340962,
            "auditor_fp_violation": 0.01601343061922903,
            "ave_precision_score": 0.7530963815485152,
            "fpr": 0.10976948408342481,
            "logloss": 0.5705852275404882,
            "mae": 0.39537105379722254,
            "precision": 0.7647058823529411,
            "recall": 0.668724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8196196655291248,
            "auditor_fn_violation": 0.011794309491677916,
            "auditor_fp_violation": 0.024167259364627793,
            "ave_precision_score": 0.8198940670264914,
            "fpr": 0.1118421052631579,
            "logloss": 0.5474606856371199,
            "mae": 0.34482150660059824,
            "precision": 0.7622377622377622,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8369279349843155,
            "auditor_fn_violation": 0.012964544004914784,
            "auditor_fp_violation": 0.015062956027636082,
            "ave_precision_score": 0.8372507557344884,
            "fpr": 0.10647639956092206,
            "logloss": 0.5247341564678332,
            "mae": 0.33767942691367003,
            "precision": 0.780045351473923,
            "recall": 0.7078189300411523
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7940339410014337,
            "auditor_fn_violation": 0.007581721397510871,
            "auditor_fp_violation": 0.038710585585585586,
            "ave_precision_score": 0.7938205068939946,
            "fpr": 0.2532894736842105,
            "logloss": 0.5924261798559489,
            "mae": 0.3661868123300864,
            "precision": 0.6373626373626373,
            "recall": 0.8675213675213675
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8349552826552198,
            "auditor_fn_violation": 0.010389704254809756,
            "auditor_fp_violation": 0.02201071866726933,
            "ave_precision_score": 0.8344170666126294,
            "fpr": 0.2217343578485181,
            "logloss": 0.5399381336472376,
            "mae": 0.3470232839462001,
            "precision": 0.6848673946957878,
            "recall": 0.9032921810699589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8031862348373149,
            "auditor_fn_violation": 0.010491640425850959,
            "auditor_fp_violation": 0.01403212422949266,
            "ave_precision_score": 0.7289169423759547,
            "fpr": 0.1513157894736842,
            "logloss": 0.58920004162761,
            "mae": 0.39551055153603093,
            "precision": 0.7044967880085653,
            "recall": 0.7029914529914529
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8289201281678018,
            "auditor_fn_violation": 0.015408383136154818,
            "auditor_fp_violation": 0.02055401304319752,
            "ave_precision_score": 0.7548768767147938,
            "fpr": 0.13611416026344675,
            "logloss": 0.6709908724188877,
            "mae": 0.38770768268833306,
            "precision": 0.7416666666666667,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7958713107105558,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6493070635510159,
            "fpr": 0.010964912280701754,
            "logloss": 0.6087771138738056,
            "mae": 0.4289880830859929,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8091274730462092,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6598091448356945,
            "fpr": 0.006586169045005488,
            "logloss": 0.6119802059469083,
            "mae": 0.43371327514182595,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7637553825648886,
            "auditor_fn_violation": 0.004969354475933423,
            "auditor_fp_violation": 0.02529832464042993,
            "ave_precision_score": 0.5553862086233673,
            "fpr": 0.39364035087719296,
            "logloss": 13.376544040508389,
            "mae": 0.41329086122903935,
            "precision": 0.5578817733990148,
            "recall": 0.967948717948718
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7791635468469853,
            "auditor_fn_violation": 0.004341089473422685,
            "auditor_fp_violation": 0.01600826499644863,
            "ave_precision_score": 0.5779909659579987,
            "fpr": 0.38199780461031835,
            "logloss": 12.895329021897236,
            "mae": 0.40066926539919656,
            "precision": 0.5745721271393643,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7958713107105558,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6493070635510159,
            "fpr": 0.010964912280701754,
            "logloss": 0.6087771139913329,
            "mae": 0.4289880830206369,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8091274730462092,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6598091448356945,
            "fpr": 0.006586169045005488,
            "logloss": 0.6119802055606742,
            "mae": 0.43371327474925964,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8052362358395265,
            "auditor_fn_violation": 0.010252661568451045,
            "auditor_fp_violation": 0.011624288762446661,
            "ave_precision_score": 0.7331450848497175,
            "fpr": 0.14583333333333334,
            "logloss": 0.5890068845312655,
            "mae": 0.39006341216072704,
            "precision": 0.710239651416122,
            "recall": 0.6965811965811965
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8311456084162995,
            "auditor_fn_violation": 0.013416270276863032,
            "auditor_fp_violation": 0.02155872667398464,
            "ave_precision_score": 0.760471901388888,
            "fpr": 0.13062568605927552,
            "logloss": 0.6655252803193412,
            "mae": 0.3803859568568014,
            "precision": 0.7484143763213531,
            "recall": 0.7283950617283951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7901870786783272,
            "auditor_fn_violation": 0.001827485380116961,
            "auditor_fp_violation": 0.025278568041725936,
            "ave_precision_score": 0.7901396257224911,
            "fpr": 0.19517543859649122,
            "logloss": 0.5705897366086156,
            "mae": 0.36916224305566986,
            "precision": 0.673992673992674,
            "recall": 0.7863247863247863
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8290171308213097,
            "auditor_fn_violation": 0.006586169045005488,
            "auditor_fp_violation": 0.01643701168722154,
            "ave_precision_score": 0.8285168895838646,
            "fpr": 0.16355653128430298,
            "logloss": 0.5233786648458815,
            "mae": 0.35214446526548276,
            "precision": 0.7214953271028037,
            "recall": 0.7942386831275721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.49916737631595187,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5199401702158111,
            "fpr": 0.0581140350877193,
            "logloss": 0.6936348755898373,
            "mae": 0.4996511860048039,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5119397101427506,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5317792318216167,
            "fpr": 0.05378704720087816,
            "logloss": 0.6951645949136179,
            "mae": 0.50042387800604,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8538377128046121,
            "auditor_fn_violation": 0.014198155645524069,
            "auditor_fp_violation": 0.00692962699541647,
            "ave_precision_score": 0.8541056456461849,
            "fpr": 0.041666666666666664,
            "logloss": 0.8935220841642675,
            "mae": 0.29505460673938655,
            "precision": 0.8793650793650793,
            "recall": 0.5918803418803419
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.8661971028788654,
            "auditor_fn_violation": 0.010123185754360291,
            "auditor_fp_violation": 0.011126751468973978,
            "ave_precision_score": 0.8664050954180651,
            "fpr": 0.04500548847420417,
            "logloss": 0.8690493321486591,
            "mae": 0.30305621612403194,
            "precision": 0.8694267515923567,
            "recall": 0.5617283950617284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.834517064422717,
            "auditor_fn_violation": 0.01327035537561854,
            "auditor_fp_violation": 0.010905642484589858,
            "ave_precision_score": 0.834816255285092,
            "fpr": 0.07894736842105263,
            "logloss": 0.8112320535743784,
            "mae": 0.28023928855931013,
            "precision": 0.8105263157894737,
            "recall": 0.6581196581196581
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8453085330161283,
            "auditor_fn_violation": 0.011004051984659377,
            "auditor_fp_violation": 0.014344934461160974,
            "ave_precision_score": 0.8455820432894363,
            "fpr": 0.07793633369923161,
            "logloss": 0.7743154436841893,
            "mae": 0.28028848863152866,
            "precision": 0.821608040201005,
            "recall": 0.6728395061728395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8009868750742875,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6513357563390235,
            "fpr": 0.010964912280701754,
            "logloss": 0.604805179805162,
            "mae": 0.4280560954490252,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8105546146871665,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6584034850270404,
            "fpr": 0.006586169045005488,
            "logloss": 0.6109627344934022,
            "mae": 0.43389186452824774,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.5199590415046601,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5257763700988072,
            "fpr": 0.0581140350877193,
            "logloss": 0.6937014736495187,
            "mae": 0.49965353087897885,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5240799134216976,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5409508405837431,
            "fpr": 0.05378704720087816,
            "logloss": 0.6952566484607565,
            "mae": 0.5004403497921518,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7842375836079813,
            "auditor_fn_violation": 0.0064805443094916836,
            "auditor_fp_violation": 0.027560455192034147,
            "ave_precision_score": 0.7837827322550507,
            "fpr": 0.10526315789473684,
            "logloss": 0.5959173088562609,
            "mae": 0.37547261362053913,
            "precision": 0.7593984962406015,
            "recall": 0.6474358974358975
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8057410950703041,
            "auditor_fn_violation": 0.004553400821238358,
            "auditor_fp_violation": 0.01962936656550656,
            "ave_precision_score": 0.8048543167052462,
            "fpr": 0.0889132821075741,
            "logloss": 0.579371692986855,
            "mae": 0.37352529156679115,
            "precision": 0.7923076923076923,
            "recall": 0.6358024691358025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7635042720068143,
            "auditor_fn_violation": 0.004135271405008247,
            "auditor_fp_violation": 0.019277501185395923,
            "ave_precision_score": 0.5551351212620725,
            "fpr": 0.41118421052631576,
            "logloss": 13.403904019236048,
            "mae": 0.429394297012526,
            "precision": 0.5492788461538461,
            "recall": 0.9764957264957265
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7790201336944869,
            "auditor_fn_violation": 0.002936220767663627,
            "auditor_fp_violation": 0.00882030089752697,
            "ave_precision_score": 0.5778475704470963,
            "fpr": 0.3951701427003293,
            "logloss": 12.916300507599475,
            "mae": 0.41631851881137016,
            "precision": 0.5673076923076923,
            "recall": 0.9711934156378601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8019600688901339,
            "auditor_fn_violation": 0.008069050832208728,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.7279673489442849,
            "fpr": 0.14692982456140352,
            "logloss": 0.5922874590615392,
            "mae": 0.3969691605143772,
            "precision": 0.7093275488069414,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8234801062370469,
            "auditor_fn_violation": 0.013723444141787845,
            "auditor_fp_violation": 0.023330535287660624,
            "ave_precision_score": 0.7514336189266285,
            "fpr": 0.132821075740944,
            "logloss": 0.5688216280560924,
            "mae": 0.38765245722657893,
            "precision": 0.7463312368972747,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995545684741216,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5213966263028331,
            "fpr": 0.0581140350877193,
            "logloss": 0.693809658741854,
            "mae": 0.49969250032384144,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120579040329692,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322604122092249,
            "fpr": 0.05378704720087816,
            "logloss": 0.6954363977538682,
            "mae": 0.5005160062752754,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8201707664540232,
            "auditor_fn_violation": 0.012942345179187284,
            "auditor_fp_violation": 0.022255808440018975,
            "ave_precision_score": 0.8204419215341563,
            "fpr": 0.1074561403508772,
            "logloss": 0.548944252222771,
            "mae": 0.3456580981626502,
            "precision": 0.7655502392344498,
            "recall": 0.6837606837606838
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8373270939755644,
            "auditor_fn_violation": 0.013389166700546141,
            "auditor_fp_violation": 0.016542906954219675,
            "ave_precision_score": 0.8376607375386598,
            "fpr": 0.09879253567508232,
            "logloss": 0.5281345948658882,
            "mae": 0.33947884278631596,
            "precision": 0.7887323943661971,
            "recall": 0.691358024691358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7985828544255649,
            "auditor_fn_violation": 0.0029403771180086962,
            "auditor_fp_violation": 0.03125000000000001,
            "ave_precision_score": 0.7982603330300938,
            "fpr": 0.22697368421052633,
            "logloss": 0.5764417063147358,
            "mae": 0.365007120952533,
            "precision": 0.6491525423728813,
            "recall": 0.8183760683760684
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8372318501608109,
            "auditor_fn_violation": 0.006717169663870485,
            "auditor_fp_violation": 0.008871957125330933,
            "ave_precision_score": 0.8366692108435299,
            "fpr": 0.18880351262349068,
            "logloss": 0.5290185162922719,
            "mae": 0.34762675970236634,
            "precision": 0.7089678510998308,
            "recall": 0.8621399176954733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995602381559071,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5213770654044827,
            "fpr": 0.0581140350877193,
            "logloss": 0.693656302811811,
            "mae": 0.49964784092286174,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120557903430374,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322397348672379,
            "fpr": 0.05378704720087816,
            "logloss": 0.69519119163936,
            "mae": 0.5004237440428017,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.7635042720068143,
            "auditor_fn_violation": 0.004135271405008247,
            "auditor_fp_violation": 0.019277501185395923,
            "ave_precision_score": 0.5551351212620725,
            "fpr": 0.41118421052631576,
            "logloss": 13.403996574965591,
            "mae": 0.42944499408060055,
            "precision": 0.5492788461538461,
            "recall": 0.9764957264957265
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.7790214942604209,
            "auditor_fn_violation": 0.002936220767663627,
            "auditor_fp_violation": 0.00882030089752697,
            "ave_precision_score": 0.5778489308380915,
            "fpr": 0.3951701427003293,
            "logloss": 12.916304721764954,
            "mae": 0.416346945000666,
            "precision": 0.5673076923076923,
            "recall": 0.9711934156378601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.4995388498236041,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5213974711183246,
            "fpr": 0.0581140350877193,
            "logloss": 0.6937409954472851,
            "mae": 0.4996886723266359,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120603201760211,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322759984511688,
            "fpr": 0.05378704720087816,
            "logloss": 0.6953239132205828,
            "mae": 0.5004894090928832,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7696011496907661,
            "auditor_fn_violation": 0.010903996101364534,
            "auditor_fp_violation": 0.014298838311996211,
            "ave_precision_score": 0.7644789511549629,
            "fpr": 0.14364035087719298,
            "logloss": 0.5865807088453057,
            "mae": 0.3917398058172119,
            "precision": 0.7127192982456141,
            "recall": 0.6944444444444444
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8140283459653807,
            "auditor_fn_violation": 0.014961174126926052,
            "auditor_fp_violation": 0.020796797313876163,
            "ave_precision_score": 0.8041332596866388,
            "fpr": 0.12843029637760703,
            "logloss": 0.5534346431900407,
            "mae": 0.37780469681343837,
            "precision": 0.7521186440677966,
            "recall": 0.7304526748971193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7947799132411061,
            "auditor_fn_violation": 0.005379367221472486,
            "auditor_fp_violation": 0.036739864864864864,
            "ave_precision_score": 0.7945547209658171,
            "fpr": 0.2598684210526316,
            "logloss": 0.5960671898821268,
            "mae": 0.36633928685056927,
            "precision": 0.6348228043143297,
            "recall": 0.8803418803418803
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8336996089000478,
            "auditor_fn_violation": 0.008835765879307778,
            "auditor_fp_violation": 0.022318073222702923,
            "ave_precision_score": 0.8330885185801806,
            "fpr": 0.2283205268935236,
            "logloss": 0.5435786830367674,
            "mae": 0.34715714562851957,
            "precision": 0.6780185758513931,
            "recall": 0.9012345679012346
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8009868750742875,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6513357563390235,
            "fpr": 0.010964912280701754,
            "logloss": 0.6048051798141951,
            "mae": 0.4280560951876013,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8105546146871665,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6584034850270404,
            "fpr": 0.006586169045005488,
            "logloss": 0.6109627345218106,
            "mae": 0.43389186418475223,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7216330075743631,
            "auditor_fn_violation": 0.081407444894287,
            "auditor_fp_violation": 0.09632823613086772,
            "ave_precision_score": 0.5614380495615133,
            "fpr": 0.2730263157894737,
            "logloss": 0.6808117457672208,
            "mae": 0.4862931645393633,
            "precision": 0.576530612244898,
            "recall": 0.7243589743589743
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7276074389328437,
            "auditor_fn_violation": 0.0938958228871633,
            "auditor_fp_violation": 0.09226060566927102,
            "ave_precision_score": 0.5713615974775114,
            "fpr": 0.278814489571899,
            "logloss": 0.6768478039892795,
            "mae": 0.48506598195836,
            "precision": 0.5808580858085809,
            "recall": 0.7242798353909465
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8076947625166019,
            "auditor_fn_violation": 0.008650097465886937,
            "auditor_fp_violation": 0.03678678678678678,
            "ave_precision_score": 0.8040914598614253,
            "fpr": 0.2719298245614035,
            "logloss": 0.7488165580333456,
            "mae": 0.3748185738349197,
            "precision": 0.6265060240963856,
            "recall": 0.8888888888888888
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8399200581736636,
            "auditor_fn_violation": 0.004937368152394376,
            "auditor_fp_violation": 0.023994317814941574,
            "ave_precision_score": 0.8323936734096085,
            "fpr": 0.2491767288693743,
            "logloss": 0.7819966807185067,
            "mae": 0.3614879109697391,
            "precision": 0.6596701649175413,
            "recall": 0.9053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.8012460552459681,
            "auditor_fn_violation": 0.008069050832208728,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.7294680826476636,
            "fpr": 0.14692982456140352,
            "logloss": 0.5921925233926668,
            "mae": 0.3968887906521559,
            "precision": 0.7093275488069414,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8227742133395595,
            "auditor_fn_violation": 0.013723444141787845,
            "auditor_fp_violation": 0.023330535287660624,
            "ave_precision_score": 0.7524076206923423,
            "fpr": 0.132821075740944,
            "logloss": 0.5686862959540888,
            "mae": 0.3875565830164238,
            "precision": 0.7463312368972747,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7228658485792053,
            "auditor_fn_violation": 0.08375506072874493,
            "auditor_fp_violation": 0.09752844950213373,
            "ave_precision_score": 0.561035046909435,
            "fpr": 0.27631578947368424,
            "logloss": 0.6801567950126272,
            "mae": 0.48640621804811973,
            "precision": 0.5757575757575758,
            "recall": 0.7307692307692307
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7268540450597032,
            "auditor_fn_violation": 0.09424365211656345,
            "auditor_fp_violation": 0.09379996125782916,
            "ave_precision_score": 0.5696630571382032,
            "fpr": 0.283205268935236,
            "logloss": 0.6776843364545316,
            "mae": 0.4858935555171234,
            "precision": 0.5777414075286416,
            "recall": 0.7263374485596708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7897263655070164,
            "auditor_fn_violation": 0.008069050832208728,
            "auditor_fp_violation": 0.011503279595384861,
            "ave_precision_score": 0.761629754965309,
            "fpr": 0.14692982456140352,
            "logloss": 0.6069068724632146,
            "mae": 0.3985459672842632,
            "precision": 0.7093275488069414,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8092667123740553,
            "auditor_fn_violation": 0.013723444141787845,
            "auditor_fp_violation": 0.023330535287660624,
            "ave_precision_score": 0.7830414671546195,
            "fpr": 0.132821075740944,
            "logloss": 0.5805733401945011,
            "mae": 0.3882150136253313,
            "precision": 0.7463312368972747,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.7958713107105558,
            "auditor_fn_violation": 0.007844129554655885,
            "auditor_fp_violation": 0.0006420894578789319,
            "ave_precision_score": 0.6493070635510159,
            "fpr": 0.010964912280701754,
            "logloss": 0.6087771140740127,
            "mae": 0.4289880830533149,
            "precision": 0.935064935064935,
            "recall": 0.3076923076923077
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.8091274730462092,
            "auditor_fn_violation": 0.011860073270001317,
            "auditor_fp_violation": 0.0009194808549105703,
            "ave_precision_score": 0.6598091448356945,
            "fpr": 0.006586169045005488,
            "logloss": 0.6119802055352574,
            "mae": 0.4337132747165458,
            "precision": 0.9568345323741008,
            "recall": 0.2736625514403292
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.7114282217320658,
            "auditor_fn_violation": 0.013193038686459739,
            "auditor_fp_violation": 0.0053490990990991,
            "ave_precision_score": 0.7118643664817131,
            "fpr": 0.03618421052631579,
            "logloss": 2.7612269619850194,
            "mae": 0.4155954376094127,
            "precision": 0.8103448275862069,
            "recall": 0.30128205128205127
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7323996752094033,
            "auditor_fn_violation": 0.00937106151156645,
            "auditor_fp_violation": 0.0006766965842319388,
            "ave_precision_score": 0.7329030375765049,
            "fpr": 0.036223929747530186,
            "logloss": 2.862409957517527,
            "mae": 0.42079723997816554,
            "precision": 0.8186813186813187,
            "recall": 0.3065843621399177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.763448516939365,
            "auditor_fn_violation": 0.0024038461538461544,
            "auditor_fp_violation": 0.01296279832464044,
            "ave_precision_score": 0.5550793711619142,
            "fpr": 0.42214912280701755,
            "logloss": 13.426591469336488,
            "mae": 0.4374603181980555,
            "precision": 0.5432977461447213,
            "recall": 0.9786324786324786
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.77899785994049,
            "auditor_fn_violation": 0.0028503927759934585,
            "auditor_fp_violation": 0.004592238651772468,
            "ave_precision_score": 0.5778252991800958,
            "fpr": 0.4094401756311745,
            "logloss": 12.937032691472895,
            "mae": 0.4231629781858841,
            "precision": 0.5606595995288575,
            "recall": 0.9794238683127572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7637369198507402,
            "auditor_fn_violation": 0.004969354475933423,
            "auditor_fp_violation": 0.02529832464042993,
            "ave_precision_score": 0.5553677466744918,
            "fpr": 0.39364035087719296,
            "logloss": 13.376701977006848,
            "mae": 0.4136682550418124,
            "precision": 0.5578817733990148,
            "recall": 0.967948717948718
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7791770408333553,
            "auditor_fn_violation": 0.004341089473422685,
            "auditor_fp_violation": 0.01600826499644863,
            "ave_precision_score": 0.5780044582517208,
            "fpr": 0.38199780461031835,
            "logloss": 12.893962769089445,
            "mae": 0.40144205290759516,
            "precision": 0.5745721271393643,
            "recall": 0.9670781893004116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7724148755504381,
            "auditor_fn_violation": 0.004650715999400224,
            "auditor_fp_violation": 0.0007408724513987672,
            "ave_precision_score": 0.602384836178897,
            "fpr": 0.008771929824561403,
            "logloss": 0.638971367949023,
            "mae": 0.45454731426740946,
            "precision": 0.926605504587156,
            "recall": 0.21581196581196582
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.794817513935812,
            "auditor_fn_violation": 0.009260388574939138,
            "auditor_fp_violation": 0.0006844450184025311,
            "ave_precision_score": 0.6251412130691673,
            "fpr": 0.005488474204171241,
            "logloss": 0.6348116453969576,
            "mae": 0.4535697186948439,
            "precision": 0.954954954954955,
            "recall": 0.21810699588477367
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7851576212489442,
            "auditor_fn_violation": 0.011159375468585999,
            "auditor_fp_violation": 0.02655286865813182,
            "ave_precision_score": 0.7846363179285697,
            "fpr": 0.10964912280701754,
            "logloss": 0.5867523139752567,
            "mae": 0.3719380134246884,
            "precision": 0.7566909975669099,
            "recall": 0.6645299145299145
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8069487396990064,
            "auditor_fn_violation": 0.010163841118835632,
            "auditor_fp_violation": 0.020417124039517016,
            "ave_precision_score": 0.8059490372896422,
            "fpr": 0.09330406147091108,
            "logloss": 0.5664951672476684,
            "mae": 0.36801163080270055,
            "precision": 0.7890818858560794,
            "recall": 0.654320987654321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.71959406995234,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5509780247901889,
            "fpr": 0.2949561403508772,
            "logloss": 0.6844218444455904,
            "mae": 0.49257028890414195,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.7189922990188569,
            "auditor_fn_violation": 0.09301269802550448,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5543119509376127,
            "fpr": 0.305159165751921,
            "logloss": 0.720655378923677,
            "mae": 0.49487167200224064,
            "precision": 0.5622047244094488,
            "recall": 0.7345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7633371091571326,
            "auditor_fn_violation": 0.003251986804618384,
            "auditor_fp_violation": 0.009675794215267906,
            "ave_precision_score": 0.5549679764260717,
            "fpr": 0.4331140350877193,
            "logloss": 13.398697982754536,
            "mae": 0.4449925230011311,
            "precision": 0.5380116959064327,
            "recall": 0.9829059829059829
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.779135252020811,
            "auditor_fn_violation": 0.0015900764772578408,
            "auditor_fp_violation": 0.009517659972880493,
            "ave_precision_score": 0.5779626706804756,
            "fpr": 0.424807903402854,
            "logloss": 12.916004414111612,
            "mae": 0.42944468066647584,
            "precision": 0.554147465437788,
            "recall": 0.9897119341563786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7212302587626315,
            "auditor_fn_violation": 0.08715699505173191,
            "auditor_fp_violation": 0.10632260550023709,
            "ave_precision_score": 0.5600039545346079,
            "fpr": 0.2949561403508772,
            "logloss": 0.6842462638947228,
            "mae": 0.4921788312494755,
            "precision": 0.5640194489465153,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7209280711450448,
            "auditor_fn_violation": 0.09272133458009785,
            "auditor_fp_violation": 0.10082004261638794,
            "ave_precision_score": 0.5645679423199016,
            "fpr": 0.305159165751921,
            "logloss": 0.68771543363449,
            "mae": 0.49374864970944193,
            "precision": 0.5615141955835962,
            "recall": 0.7325102880658436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7228658485792053,
            "auditor_fn_violation": 0.08375506072874493,
            "auditor_fp_violation": 0.09752844950213373,
            "ave_precision_score": 0.561035046909435,
            "fpr": 0.27631578947368424,
            "logloss": 0.6801567950126272,
            "mae": 0.48640621804811973,
            "precision": 0.5757575757575758,
            "recall": 0.7307692307692307
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.7268540450597032,
            "auditor_fn_violation": 0.09424365211656345,
            "auditor_fp_violation": 0.09379996125782916,
            "ave_precision_score": 0.5696630571382032,
            "fpr": 0.283205268935236,
            "logloss": 0.6776843364545316,
            "mae": 0.4858935555171234,
            "precision": 0.5777414075286416,
            "recall": 0.7263374485596708
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.7426467898466791,
            "auditor_fn_violation": 0.013101664417453895,
            "auditor_fp_violation": 0.014861901375059274,
            "ave_precision_score": 0.7428187455326215,
            "fpr": 0.05592105263157895,
            "logloss": 0.7549774538489678,
            "mae": 0.39849170951709856,
            "precision": 0.7829787234042553,
            "recall": 0.39316239316239315
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7646094123260392,
            "auditor_fn_violation": 0.01072398169605146,
            "auditor_fp_violation": 0.011899012074643249,
            "ave_precision_score": 0.7646369127047505,
            "fpr": 0.04610318331503842,
            "logloss": 0.7677989291604755,
            "mae": 0.40827562258595196,
            "precision": 0.7920792079207921,
            "recall": 0.3292181069958848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 9271,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.49951906078527686,
            "auditor_fn_violation": 0.013774085320137965,
            "auditor_fp_violation": 0.006522147147147147,
            "ave_precision_score": 0.5213980107413766,
            "fpr": 0.0581140350877193,
            "logloss": 0.6936638907091527,
            "mae": 0.49968131808073896,
            "precision": 0.5092592592592593,
            "recall": 0.11752136752136752
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5120544410511887,
            "auditor_fn_violation": 0.003690603641817212,
            "auditor_fp_violation": 0.006480273778007361,
            "ave_precision_score": 0.5322526991823321,
            "fpr": 0.05378704720087816,
            "logloss": 0.6951990896501313,
            "mae": 0.5004571657607375,
            "precision": 0.5545454545454546,
            "recall": 0.12551440329218108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7032624191900678,
            "auditor_fn_violation": 0.004877980206927589,
            "auditor_fp_violation": 0.007971787577050735,
            "ave_precision_score": 0.6988602535061222,
            "fpr": 0.02631578947368421,
            "logloss": 0.6130543048149909,
            "mae": 0.42522637563218413,
            "precision": 0.8588235294117647,
            "recall": 0.31196581196581197
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7484921954231636,
            "auditor_fn_violation": 0.01845753547180551,
            "auditor_fp_violation": 0.0014902821721443794,
            "ave_precision_score": 0.7345050256209749,
            "fpr": 0.012074643249176729,
            "logloss": 0.6110243501936993,
            "mae": 0.42679726295622983,
            "precision": 0.9266666666666666,
            "recall": 0.28600823045267487
        }
    }
]