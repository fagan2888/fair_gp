[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 14289,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.59488948454073,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5131183103398681,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005026670000416735,
            "ave_precision_score": 0.5454660843593018,
            "fpr": 0.4605263157894737,
            "logloss": 0.6976470401691965,
            "mae": 0.4943861520783812,
            "precision": 0.5389681668496158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5843310931382699,
            "auditor_fn_violation": 0.0005950786286164066,
            "auditor_fp_violation": 0.0006223537713658593,
            "ave_precision_score": 0.5284612948513896,
            "fpr": 0.49066959385290887,
            "logloss": 0.6926384312151133,
            "mae": 0.4927344094965971,
            "precision": 0.5082508250825083,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7045352395105569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7057241947522681,
            "fpr": 0.4616228070175439,
            "logloss": 0.698929189117905,
            "mae": 0.4824847179677403,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6766936662934144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6775760666153883,
            "fpr": 0.49176728869374314,
            "logloss": 0.7148671595185159,
            "mae": 0.4882597867665254,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7045352395105569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7057241947522681,
            "fpr": 0.4616228070175439,
            "logloss": 0.7099917858506039,
            "mae": 0.4878855447627996,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6766936662934144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6775760666153883,
            "fpr": 0.49176728869374314,
            "logloss": 0.7262545950015958,
            "mae": 0.49381144902577906,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7621441272549437,
            "auditor_fn_violation": 0.00609658055525781,
            "auditor_fp_violation": 0.00361243072050673,
            "ave_precision_score": 0.6717357439567866,
            "fpr": 0.008771929824561403,
            "logloss": 0.6971164862292767,
            "mae": 0.48022742417544995,
            "precision": 0.8805970149253731,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.768307847605534,
            "auditor_fn_violation": 0.008508913139857717,
            "auditor_fp_violation": 0.002984357848518112,
            "ave_precision_score": 0.6803378486703008,
            "fpr": 0.006586169045005488,
            "logloss": 0.716911499723657,
            "mae": 0.48681799623436417,
            "precision": 0.9142857142857143,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5405701754385965,
            "auc_prc": 0.7129923012932654,
            "auditor_fn_violation": 0.0007994783292242828,
            "auditor_fp_violation": 0.0025524023836312956,
            "ave_precision_score": 0.7149278417372027,
            "fpr": 0.45614035087719296,
            "logloss": 0.6935191384179056,
            "mae": 0.4819502720380561,
            "precision": 0.5398230088495575,
            "recall": 0.9938900203665988
        },
        "train": {
            "accuracy": 0.5060373216245884,
            "auc_prc": 0.6640025573844885,
            "auditor_fn_violation": 0.001346632115753462,
            "auditor_fp_violation": 0.0012153050023522229,
            "ave_precision_score": 0.6666379346122359,
            "fpr": 0.48737650933040616,
            "logloss": 0.7165682279270909,
            "mae": 0.49155708221651195,
            "precision": 0.5072142064372919,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 14289,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6849639538750701,
            "auditor_fn_violation": 0.0021192875263515215,
            "auditor_fp_violation": 0.019247197566362464,
            "ave_precision_score": 0.6817802116864969,
            "fpr": 0.3607456140350877,
            "logloss": 1.9916216726987943,
            "mae": 0.38406600297827953,
            "precision": 0.5892634207240949,
            "recall": 0.9613034623217923
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6508311253172734,
            "auditor_fn_violation": 0.004412116844044355,
            "auditor_fp_violation": 0.0022541947624274907,
            "ave_precision_score": 0.6454707710860164,
            "fpr": 0.41931942919868276,
            "logloss": 2.3487358752677223,
            "mae": 0.41707879746752935,
            "precision": 0.5392038600723763,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.5131183103398681,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005026670000416735,
            "ave_precision_score": 0.5454660843593018,
            "fpr": 0.4605263157894737,
            "logloss": 0.6976274768354269,
            "mae": 0.4943819905073676,
            "precision": 0.5389681668496158,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5843310931382699,
            "auditor_fn_violation": 0.0005950786286164066,
            "auditor_fp_violation": 0.0006223537713658593,
            "ave_precision_score": 0.5284612948513896,
            "fpr": 0.49066959385290887,
            "logloss": 0.6926320456957287,
            "mae": 0.4927289853164871,
            "precision": 0.5082508250825083,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6665407701484011,
            "auditor_fn_violation": 0.004363633115374996,
            "auditor_fp_violation": 0.0185283577113806,
            "ave_precision_score": 0.6539375016181888,
            "fpr": 0.34210526315789475,
            "logloss": 2.5510216105831325,
            "mae": 0.37942139104294864,
            "precision": 0.6015325670498084,
            "recall": 0.9592668024439919
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6293036936109974,
            "auditor_fn_violation": 0.004094425464623643,
            "auditor_fp_violation": 0.0033102360043907814,
            "ave_precision_score": 0.6152911629559867,
            "fpr": 0.407244785949506,
            "logloss": 2.910038443464773,
            "mae": 0.4156751733104076,
            "precision": 0.5458996328029376,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8058873779785003,
            "auditor_fn_violation": 0.011956444063315114,
            "auditor_fp_violation": 0.020515585281493526,
            "ave_precision_score": 0.7839075053674616,
            "fpr": 0.15460526315789475,
            "logloss": 3.2169534245455096,
            "mae": 0.29085355835567905,
            "precision": 0.7277992277992278,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7729922099476275,
            "auditor_fn_violation": 0.013670212639849407,
            "auditor_fp_violation": 0.0233995217186765,
            "ave_precision_score": 0.7403580723704761,
            "fpr": 0.16465422612513722,
            "logloss": 3.2901752681593184,
            "mae": 0.2812495908472077,
            "precision": 0.7104247104247104,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.670561344076721,
            "auditor_fn_violation": 0.0034055990281201994,
            "auditor_fp_violation": 0.01446014085093971,
            "ave_precision_score": 0.6564895034385838,
            "fpr": 0.38377192982456143,
            "logloss": 2.7507362531652784,
            "mae": 0.3935037937197577,
            "precision": 0.5798319327731093,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.6326314009979479,
            "auditor_fn_violation": 0.002057881472665502,
            "auditor_fp_violation": 0.004537792065234437,
            "ave_precision_score": 0.6169564455361162,
            "fpr": 0.43578485181119647,
            "logloss": 3.122044983499077,
            "mae": 0.4323196770719423,
            "precision": 0.5329411764705883,
            "recall": 0.978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6861432406376504,
            "auditor_fn_violation": 0.0021192875263515215,
            "auditor_fp_violation": 0.018379901654373466,
            "ave_precision_score": 0.6821676286645846,
            "fpr": 0.35964912280701755,
            "logloss": 2.0286783020966697,
            "mae": 0.3845361562913208,
            "precision": 0.59,
            "recall": 0.9613034623217923
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6522107938645475,
            "auditor_fn_violation": 0.004412116844044355,
            "auditor_fp_violation": 0.010364395483769794,
            "ave_precision_score": 0.6467087050017241,
            "fpr": 0.41931942919868276,
            "logloss": 2.359912991414373,
            "mae": 0.41836539815020424,
            "precision": 0.5392038600723763,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7045352395105569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7057241947522681,
            "fpr": 0.4616228070175439,
            "logloss": 0.699760442100099,
            "mae": 0.48260845636066635,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6766936662934144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6775760666153883,
            "fpr": 0.49176728869374314,
            "logloss": 0.7158793650875587,
            "mae": 0.4884856968758266,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7177130607097123,
            "auditor_fn_violation": 0.009930950083967561,
            "auditor_fp_violation": 0.017252156519564955,
            "ave_precision_score": 0.7124704371546462,
            "fpr": 0.23574561403508773,
            "logloss": 1.7927907390332503,
            "mae": 0.3169815749750565,
            "precision": 0.6624803767660911,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6823108508163656,
            "auditor_fn_violation": 0.005789569765264006,
            "auditor_fp_violation": 0.017092676807276164,
            "ave_precision_score": 0.6762259800812974,
            "fpr": 0.25466520307354557,
            "logloss": 1.9831708024416668,
            "mae": 0.3254996563100995,
            "precision": 0.6380655226209049,
            "recall": 0.8833693304535637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7924389314178797,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7397776007363759,
            "fpr": 0.03508771929824561,
            "logloss": 1.086511487254253,
            "mae": 0.40246852593092647,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7819697117255625,
            "auditor_fn_violation": 0.0157565440867914,
            "auditor_fp_violation": 0.009930708013172338,
            "ave_precision_score": 0.7326771295856684,
            "fpr": 0.036223929747530186,
            "logloss": 0.9737640694898322,
            "mae": 0.3983960985319844,
            "precision": 0.88,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6838422290762692,
            "auditor_fn_violation": 0.0021192875263515215,
            "auditor_fp_violation": 0.016496853773388356,
            "ave_precision_score": 0.680560776274508,
            "fpr": 0.36293859649122806,
            "logloss": 2.0011264892835885,
            "mae": 0.38457052667932623,
            "precision": 0.5877957658779577,
            "recall": 0.9613034623217923
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6497845856323656,
            "auditor_fn_violation": 0.0046373458070665,
            "auditor_fp_violation": 0.009408812921436421,
            "ave_precision_score": 0.6443073949091555,
            "fpr": 0.42151481888035125,
            "logloss": 2.361912093864944,
            "mae": 0.418128639144228,
            "precision": 0.5379061371841155,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8054754555810806,
            "auditor_fn_violation": 0.01229365419659128,
            "auditor_fp_violation": 0.020476517898070597,
            "ave_precision_score": 0.7835171213109806,
            "fpr": 0.1699561403508772,
            "logloss": 3.19983688765077,
            "mae": 0.2925675532470258,
            "precision": 0.7102803738317757,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7726187333344495,
            "auditor_fn_violation": 0.01318656307714922,
            "auditor_fp_violation": 0.026202563901521096,
            "ave_precision_score": 0.7399143429344891,
            "fpr": 0.18111964873765093,
            "logloss": 3.29009107532767,
            "mae": 0.2841332657448017,
            "precision": 0.6961325966850829,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.7721647587464768,
            "auditor_fn_violation": 0.002961196269696666,
            "auditor_fp_violation": 0.00026565820727590965,
            "ave_precision_score": 0.6208515254519316,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6858796149123504,
            "mae": 0.48950982252299263,
            "precision": 0.9090909090909091,
            "recall": 0.0814663951120163
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7639492216206742,
            "auditor_fn_violation": 0.0021550855514434844,
            "auditor_fp_violation": 0.001492178924259056,
            "ave_precision_score": 0.6087820759532593,
            "fpr": 0.003293084522502744,
            "logloss": 0.7020417764325567,
            "mae": 0.4935084838301565,
            "precision": 0.9333333333333333,
            "recall": 0.09071274298056156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8280276236653482,
            "auditor_fn_violation": 0.005804034015793052,
            "auditor_fp_violation": 0.005802808684418887,
            "ave_precision_score": 0.8131777134504798,
            "fpr": 0.03837719298245614,
            "logloss": 1.9382917174225962,
            "mae": 0.30341354999730946,
            "precision": 0.8888888888888888,
            "recall": 0.570264765784114
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8371207902454126,
            "auditor_fn_violation": 0.0035728426028881514,
            "auditor_fp_violation": 0.006620472008781558,
            "ave_precision_score": 0.8215862897762691,
            "fpr": 0.038419319429198684,
            "logloss": 1.5599238763307817,
            "mae": 0.2837969080092861,
            "precision": 0.8888888888888888,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8511403191629019,
            "auditor_fn_violation": 0.034562922070961524,
            "auditor_fp_violation": 0.031089823727965996,
            "ave_precision_score": 0.8513874376118657,
            "fpr": 0.09758771929824561,
            "logloss": 0.5100064439457036,
            "mae": 0.3254564037003244,
            "precision": 0.802660753880266,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7859495060373216,
            "auc_prc": 0.8522793315615778,
            "auditor_fn_violation": 0.021432313954949475,
            "auditor_fp_violation": 0.026121706915477497,
            "ave_precision_score": 0.8525410684646684,
            "fpr": 0.09989023051591657,
            "logloss": 0.4777249180776132,
            "mae": 0.3166820497464687,
            "precision": 0.7977777777777778,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8279401310757032,
            "auditor_fn_violation": 0.006641476399757038,
            "auditor_fp_violation": 0.005802808684418887,
            "ave_precision_score": 0.8130906848541142,
            "fpr": 0.03837719298245614,
            "logloss": 1.9248209175826791,
            "mae": 0.3032892995673048,
            "precision": 0.8885350318471338,
            "recall": 0.5682281059063137
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8370663204291626,
            "auditor_fn_violation": 0.0035728426028881514,
            "auditor_fp_violation": 0.006620472008781558,
            "ave_precision_score": 0.8215475346923493,
            "fpr": 0.038419319429198684,
            "logloss": 1.5507615982884453,
            "mae": 0.28378705772800444,
            "precision": 0.8888888888888888,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.7675893443991001,
            "auditor_fn_violation": 0.003785239575517199,
            "auditor_fp_violation": 0.00026565820727590965,
            "ave_precision_score": 0.624701489267244,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6855936905907475,
            "mae": 0.4896699025483573,
            "precision": 0.9111111111111111,
            "recall": 0.0835030549898167
        },
        "train": {
            "accuracy": 0.5345773874862788,
            "auc_prc": 0.7619776725298202,
            "auditor_fn_violation": 0.0021550855514434844,
            "auditor_fp_violation": 0.001492178924259056,
            "ave_precision_score": 0.6105599612508892,
            "fpr": 0.003293084522502744,
            "logloss": 0.7011815470602043,
            "mae": 0.49370640928475706,
            "precision": 0.9333333333333333,
            "recall": 0.09071274298056156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.786912119102329,
            "auditor_fn_violation": 0.007443187908671886,
            "auditor_fp_violation": 0.003914551818977372,
            "ave_precision_score": 0.7393865842561111,
            "fpr": 0.03508771929824561,
            "logloss": 0.9985467013774714,
            "mae": 0.39286601699468826,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7837093076499524,
            "auditor_fn_violation": 0.012544067824738676,
            "auditor_fp_violation": 0.009487219695781719,
            "ave_precision_score": 0.7364371253252193,
            "fpr": 0.03512623490669594,
            "logloss": 0.9015033961184916,
            "mae": 0.3870421743829693,
            "precision": 0.8853046594982079,
            "recall": 0.5334773218142549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8475064659502423,
            "auditor_fn_violation": 0.030315414299496198,
            "auditor_fp_violation": 0.031907634287619294,
            "ave_precision_score": 0.8477823107514244,
            "fpr": 0.09868421052631579,
            "logloss": 0.5128817619211037,
            "mae": 0.3255291181929689,
            "precision": 0.8013245033112583,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8610820796661984,
            "auditor_fn_violation": 0.023080041631795695,
            "auditor_fp_violation": 0.026121706915477497,
            "ave_precision_score": 0.8613056655787854,
            "fpr": 0.09989023051591657,
            "logloss": 0.4681118969996994,
            "mae": 0.31200662938012197,
            "precision": 0.7991169977924945,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8055469361568507,
            "auditor_fn_violation": 0.012503573087504922,
            "auditor_fp_violation": 0.02331020544234696,
            "ave_precision_score": 0.7837584662097747,
            "fpr": 0.1524122807017544,
            "logloss": 3.1440155571193227,
            "mae": 0.29111414063132357,
            "precision": 0.7258382642998028,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7740307040948545,
            "auditor_fn_violation": 0.013622796016055268,
            "auditor_fp_violation": 0.025295985573153518,
            "ave_precision_score": 0.7414367972398104,
            "fpr": 0.1602634467618002,
            "logloss": 3.2463578415411383,
            "mae": 0.2827950319083854,
            "precision": 0.7153996101364523,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7598631443566256,
            "auditor_fn_violation": 0.0016659520491656898,
            "auditor_fp_violation": 0.003156644580572574,
            "ave_precision_score": 0.7160385750604511,
            "fpr": 0.03179824561403509,
            "logloss": 0.7409385801607344,
            "mae": 0.48567635107343315,
            "precision": 0.8897338403041825,
            "recall": 0.47657841140529533
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7833359971290914,
            "auditor_fn_violation": 0.007231035128605742,
            "auditor_fp_violation": 0.00568204092833621,
            "ave_precision_score": 0.7316603026824653,
            "fpr": 0.031833150384193196,
            "logloss": 0.6783246491640228,
            "mae": 0.4802555852107054,
            "precision": 0.8901515151515151,
            "recall": 0.5075593952483801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7923804119252763,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7397318288525533,
            "fpr": 0.03508771929824561,
            "logloss": 1.0880639749593017,
            "mae": 0.40229986473888235,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.78200607665424,
            "auditor_fn_violation": 0.015635631696116346,
            "auditor_fp_violation": 0.009930708013172338,
            "ave_precision_score": 0.7327807564751693,
            "fpr": 0.036223929747530186,
            "logloss": 0.9749687286617255,
            "mae": 0.39814277656617847,
            "precision": 0.8804347826086957,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7886259732013823,
            "auditor_fn_violation": 0.0063556293993639905,
            "auditor_fp_violation": 0.0031852939950827185,
            "ave_precision_score": 0.7408255498175333,
            "fpr": 0.03399122807017544,
            "logloss": 1.0030366708331928,
            "mae": 0.38893958948832574,
            "precision": 0.8904593639575972,
            "recall": 0.5132382892057027
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7873188900099233,
            "auditor_fn_violation": 0.011441631321525014,
            "auditor_fp_violation": 0.00755645287752862,
            "ave_precision_score": 0.7400980661004802,
            "fpr": 0.03402854006586169,
            "logloss": 0.9035029547452302,
            "mae": 0.38264185194023803,
            "precision": 0.8876811594202898,
            "recall": 0.5291576673866091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 14289,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.7131144819413971,
            "auditor_fn_violation": 0.0007994783292242828,
            "auditor_fp_violation": 0.0014533066633329354,
            "ave_precision_score": 0.7150492512672225,
            "fpr": 0.45285087719298245,
            "logloss": 0.6829454903666173,
            "mae": 0.4733179951446098,
            "precision": 0.5416204217536071,
            "recall": 0.9938900203665988
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6641896621728736,
            "auditor_fn_violation": 0.001346632115753462,
            "auditor_fp_violation": 0.001465226595577863,
            "ave_precision_score": 0.6668157222517327,
            "fpr": 0.48518111964873767,
            "logloss": 0.7066776065625742,
            "mae": 0.4834210748173926,
            "precision": 0.5083426028921023,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 14289,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7888495357358722,
            "auditor_fn_violation": 0.005815199914245895,
            "auditor_fp_violation": 0.0018387715131058069,
            "ave_precision_score": 0.7403623772085746,
            "fpr": 0.03289473684210526,
            "logloss": 1.0009386142712244,
            "mae": 0.38833675117732314,
            "precision": 0.8939929328621908,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7970008933733935,
            "auditor_fn_violation": 0.01173798522023837,
            "auditor_fp_violation": 0.008418927395326957,
            "ave_precision_score": 0.7470870168500676,
            "fpr": 0.03293084522502744,
            "logloss": 0.8975687200335762,
            "mae": 0.38079587926368985,
            "precision": 0.8916967509025271,
            "recall": 0.5334773218142549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7876207798682704,
            "auditor_fn_violation": 0.010598670811448175,
            "auditor_fp_violation": 0.0052272159019877504,
            "ave_precision_score": 0.7360369716304809,
            "fpr": 0.03728070175438596,
            "logloss": 1.1004891159330203,
            "mae": 0.3944998997918731,
            "precision": 0.8807017543859649,
            "recall": 0.5112016293279023
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7900678133636656,
            "auditor_fn_violation": 0.011266189813486718,
            "auditor_fp_violation": 0.00842627803042183,
            "ave_precision_score": 0.7383375590006371,
            "fpr": 0.03402854006586169,
            "logloss": 0.9693043615865825,
            "mae": 0.38837594666894626,
            "precision": 0.8880866425992779,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7173268979495948,
            "auditor_fn_violation": 0.013544234823310826,
            "auditor_fp_violation": 0.02298724840605076,
            "ave_precision_score": 0.7088063654252781,
            "fpr": 0.21052631578947367,
            "logloss": 3.0436949350539844,
            "mae": 0.31544519548231365,
            "precision": 0.6740237691001698,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6962352187946346,
            "auditor_fn_violation": 0.006538752421211351,
            "auditor_fp_violation": 0.030465932256546965,
            "ave_precision_score": 0.6861230178938073,
            "fpr": 0.20856201975850713,
            "logloss": 2.8238726495955473,
            "mae": 0.3016052818678229,
            "precision": 0.6718480138169257,
            "recall": 0.8401727861771058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7147688145696033,
            "auditor_fn_violation": 0.006813431235930969,
            "auditor_fp_violation": 0.017259969996249534,
            "ave_precision_score": 0.7105724971620098,
            "fpr": 0.23355263157894737,
            "logloss": 1.6762472281189649,
            "mae": 0.3155370085031863,
            "precision": 0.6640378548895899,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6802439685988038,
            "auditor_fn_violation": 0.002951684831184965,
            "auditor_fp_violation": 0.01388289948251529,
            "ave_precision_score": 0.6738565146585931,
            "fpr": 0.24807903402854006,
            "logloss": 1.8827722313285993,
            "mae": 0.3242922678546405,
            "precision": 0.6429699842022117,
            "recall": 0.8790496760259179
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7095340572029134,
            "auditor_fn_violation": 0.009437417372351452,
            "auditor_fp_violation": 0.017259969996249545,
            "ave_precision_score": 0.7033392294323945,
            "fpr": 0.23903508771929824,
            "logloss": 1.903115855584777,
            "mae": 0.3188740941502163,
            "precision": 0.6599063962558502,
            "recall": 0.8615071283095723
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.6762927286500999,
            "auditor_fn_violation": 0.0024040228263626957,
            "auditor_fp_violation": 0.017719931002038572,
            "ave_precision_score": 0.6666384604938703,
            "fpr": 0.2557628979143798,
            "logloss": 2.1680830251201577,
            "mae": 0.32780822982164637,
            "precision": 0.6381987577639752,
            "recall": 0.8876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7598631443566256,
            "auditor_fn_violation": 0.0016659520491656898,
            "auditor_fp_violation": 0.003156644580572574,
            "ave_precision_score": 0.7160385750604511,
            "fpr": 0.03179824561403509,
            "logloss": 0.7420818877034113,
            "mae": 0.48546229499689114,
            "precision": 0.8897338403041825,
            "recall": 0.47657841140529533
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7833359971290914,
            "auditor_fn_violation": 0.007231035128605742,
            "auditor_fp_violation": 0.00568204092833621,
            "ave_precision_score": 0.7316603026824653,
            "fpr": 0.031833150384193196,
            "logloss": 0.6780835938814699,
            "mae": 0.4799897343405585,
            "precision": 0.8901515151515151,
            "recall": 0.5075593952483801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7870752879001308,
            "auditor_fn_violation": 0.005815199914245895,
            "auditor_fp_violation": 0.0031852939950827185,
            "ave_precision_score": 0.7396036032686819,
            "fpr": 0.03399122807017544,
            "logloss": 1.0064500547423798,
            "mae": 0.3892057720790381,
            "precision": 0.8908450704225352,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7861176890768331,
            "auditor_fn_violation": 0.013494771131811101,
            "auditor_fp_violation": 0.009487219695781719,
            "ave_precision_score": 0.7388125827111058,
            "fpr": 0.03512623490669594,
            "logloss": 0.9060328416252706,
            "mae": 0.38284157770917265,
            "precision": 0.8848920863309353,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5021929824561403,
            "auc_prc": 0.7707145187123218,
            "auditor_fn_violation": 0.003785239575517199,
            "auditor_fp_violation": 0.00026565820727590965,
            "ave_precision_score": 0.6311665147525232,
            "fpr": 0.0043859649122807015,
            "logloss": 0.6867908689364703,
            "mae": 0.4903670691051765,
            "precision": 0.9111111111111111,
            "recall": 0.0835030549898167
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.7589403259526478,
            "auditor_fn_violation": 0.0021527147202537755,
            "auditor_fp_violation": 0.0016073388740787207,
            "ave_precision_score": 0.6136964820264371,
            "fpr": 0.0043907793633369925,
            "logloss": 0.7002473027930399,
            "mae": 0.4940535995033779,
            "precision": 0.9166666666666666,
            "recall": 0.09503239740820735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7045352395105569,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.7057241947522681,
            "fpr": 0.4616228070175439,
            "logloss": 0.698929955679191,
            "mae": 0.4824846576441798,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.6766936662934144,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.6775760666153883,
            "fpr": 0.49176728869374314,
            "logloss": 0.7148681520949154,
            "mae": 0.48825979278587484,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8277655146183033,
            "auditor_fn_violation": 0.006641476399757038,
            "auditor_fp_violation": 0.005802808684418887,
            "ave_precision_score": 0.8129291292777103,
            "fpr": 0.03837719298245614,
            "logloss": 2.025478766183676,
            "mae": 0.3032948375613737,
            "precision": 0.8885350318471338,
            "recall": 0.5682281059063137
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8366435176242446,
            "auditor_fn_violation": 0.0035728426028881514,
            "auditor_fp_violation": 0.006620472008781558,
            "ave_precision_score": 0.8211068318935217,
            "fpr": 0.038419319429198684,
            "logloss": 1.624964577140449,
            "mae": 0.28375903340403597,
            "precision": 0.8888888888888888,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7908361628508475,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7384454711809381,
            "fpr": 0.03508771929824561,
            "logloss": 1.092554384762029,
            "mae": 0.4017325118097777,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7835124718712361,
            "auditor_fn_violation": 0.01493149483277343,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7334712573517619,
            "fpr": 0.03512623490669594,
            "logloss": 0.9784216060800063,
            "mae": 0.39726005388631785,
            "precision": 0.8840579710144928,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8256347293743553,
            "auditor_fn_violation": 0.006661575016972169,
            "auditor_fp_violation": 0.005800204192190691,
            "ave_precision_score": 0.8108514719392066,
            "fpr": 0.03837719298245614,
            "logloss": 1.9891774173329448,
            "mae": 0.3092797442901227,
            "precision": 0.8856209150326797,
            "recall": 0.5519348268839104
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8366965286236859,
            "auditor_fn_violation": 0.003525425979094012,
            "auditor_fp_violation": 0.007032107574094402,
            "ave_precision_score": 0.8221305219664885,
            "fpr": 0.038419319429198684,
            "logloss": 1.5675009566733977,
            "mae": 0.28703525016445985,
            "precision": 0.8852459016393442,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8292120498496279,
            "auditor_fn_violation": 0.004613749240718907,
            "auditor_fp_violation": 0.0018387715131058069,
            "ave_precision_score": 0.8149430153598964,
            "fpr": 0.041666666666666664,
            "logloss": 1.9992180837043763,
            "mae": 0.3003353601242541,
            "precision": 0.8808777429467085,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8425379320498203,
            "auditor_fn_violation": 0.006043248702562631,
            "auditor_fp_violation": 0.00531205896189431,
            "ave_precision_score": 0.8274180658455406,
            "fpr": 0.03951701427003293,
            "logloss": 1.5891198168462937,
            "mae": 0.27922299075587304,
            "precision": 0.8878504672897196,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7908952039221584,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7385701980789123,
            "fpr": 0.03508771929824561,
            "logloss": 1.085709035325326,
            "mae": 0.40211948608712483,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7825192471770508,
            "auditor_fn_violation": 0.01493149483277343,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7323049439620457,
            "fpr": 0.03512623490669594,
            "logloss": 0.9726775922585079,
            "mae": 0.39771605536409677,
            "precision": 0.8840579710144928,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8259062389463019,
            "auditor_fn_violation": 0.008937185121663634,
            "auditor_fp_violation": 0.007451452264866443,
            "ave_precision_score": 0.8135258394244254,
            "fpr": 0.044956140350877194,
            "logloss": 1.8741321108900544,
            "mae": 0.301708882728393,
            "precision": 0.8714733542319749,
            "recall": 0.5661914460285132
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8365006535937263,
            "auditor_fn_violation": 0.004445308480700253,
            "auditor_fp_violation": 0.01532117374941195,
            "ave_precision_score": 0.8234053765890966,
            "fpr": 0.04500548847420417,
            "logloss": 1.510273517261842,
            "mae": 0.28176048897469,
            "precision": 0.8706624605678234,
            "recall": 0.5961123110151187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7554508562982243,
            "auditor_fn_violation": 0.023673937899739175,
            "auditor_fp_violation": 0.006940971788140185,
            "ave_precision_score": 0.7408074109284126,
            "fpr": 0.09539473684210527,
            "logloss": 1.262942250552013,
            "mae": 0.36853852117018493,
            "precision": 0.7751937984496124,
            "recall": 0.6109979633401222
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7528004619233426,
            "auditor_fn_violation": 0.015886939802225265,
            "auditor_fp_violation": 0.0021684373529873005,
            "ave_precision_score": 0.7376482237618125,
            "fpr": 0.09549945115257959,
            "logloss": 1.162417882534316,
            "mae": 0.3438672486225092,
            "precision": 0.7746113989637305,
            "recall": 0.6457883369330454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7509635084368765,
            "auditor_fn_violation": 0.010487011826919648,
            "auditor_fp_violation": 0.016595824478059757,
            "ave_precision_score": 0.7469443094523808,
            "fpr": 0.19298245614035087,
            "logloss": 0.6523828315324528,
            "mae": 0.46769144990595807,
            "precision": 0.6817359855334539,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.7307692107955938,
            "auditor_fn_violation": 0.00944539145979189,
            "auditor_fp_violation": 0.03013760388897601,
            "ave_precision_score": 0.7265429220685414,
            "fpr": 0.2052689352360044,
            "logloss": 0.6431999197277775,
            "mae": 0.4685053223116338,
            "precision": 0.6630630630630631,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7667148900869512,
            "auditor_fn_violation": 0.003146550184014008,
            "auditor_fp_violation": 0.022086094095095224,
            "ave_precision_score": 0.7667041015992551,
            "fpr": 0.2894736842105263,
            "logloss": 0.6627166733972016,
            "mae": 0.48211481343758733,
            "precision": 0.6265912305516266,
            "recall": 0.9022403258655805
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7249792558187937,
            "auditor_fn_violation": 0.009824724450144979,
            "auditor_fp_violation": 0.02546259996863729,
            "ave_precision_score": 0.7255579722288292,
            "fpr": 0.28869374313940727,
            "logloss": 0.6690290076569442,
            "mae": 0.4842387981851852,
            "precision": 0.6154970760233918,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 14289,
        "test": {
            "accuracy": 0.43640350877192985,
            "auc_prc": 0.487500012341613,
            "auditor_fn_violation": 0.008347625683352984,
            "auditor_fp_violation": 0.0062690127932658254,
            "ave_precision_score": 0.5051426251880472,
            "fpr": 0.07785087719298246,
            "logloss": 0.6993064508457312,
            "mae": 0.5020927508737434,
            "precision": 0.40336134453781514,
            "recall": 0.09775967413441955
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.49473370730071964,
            "auditor_fn_violation": 0.01671673071862266,
            "auditor_fp_violation": 0.0061500313627097375,
            "ave_precision_score": 0.5074196503113219,
            "fpr": 0.059275521405049394,
            "logloss": 0.6937380343580045,
            "mae": 0.49927800955939894,
            "precision": 0.46,
            "recall": 0.09935205183585313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7178277517177322,
            "auditor_fn_violation": 0.009930950083967561,
            "auditor_fp_violation": 0.01672865358169772,
            "ave_precision_score": 0.7122632586816532,
            "fpr": 0.23684210526315788,
            "logloss": 1.7987543490529778,
            "mae": 0.31704758492319424,
            "precision": 0.6614420062695925,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6819310982136749,
            "auditor_fn_violation": 0.0069062312556159074,
            "auditor_fp_violation": 0.017092676807276164,
            "ave_precision_score": 0.6755600814231366,
            "fpr": 0.25466520307354557,
            "logloss": 1.9909938662419404,
            "mae": 0.32545590650202444,
            "precision": 0.6375,
            "recall": 0.8812095032397408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.638513643991488,
            "auditor_fn_violation": 0.005326133562010934,
            "auditor_fp_violation": 0.01808298954035923,
            "ave_precision_score": 0.6259924868533351,
            "fpr": 0.2565789473684211,
            "logloss": 2.352411623823011,
            "mae": 0.4065218459449202,
            "precision": 0.6151315789473685,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.5999681069355498,
            "auditor_fn_violation": 0.006112002807064129,
            "auditor_fp_violation": 0.02221116904500548,
            "ave_precision_score": 0.5869658703310406,
            "fpr": 0.2843029637760702,
            "logloss": 2.528669425397342,
            "mae": 0.42134905863823174,
            "precision": 0.5747126436781609,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7909937520550656,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7387492092320608,
            "fpr": 0.03508771929824561,
            "logloss": 1.0895477082077227,
            "mae": 0.4019355516049862,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7846607929000795,
            "auditor_fn_violation": 0.01493149483277343,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7324344646545258,
            "fpr": 0.03512623490669594,
            "logloss": 0.9754727553428987,
            "mae": 0.3975306390474177,
            "precision": 0.8840579710144928,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.7636466431606898,
            "auditor_fn_violation": 0.00609658055525781,
            "auditor_fp_violation": 0.00361243072050673,
            "ave_precision_score": 0.6733304004272627,
            "fpr": 0.008771929824561403,
            "logloss": 0.694877838241122,
            "mae": 0.4804901234517609,
            "precision": 0.8805970149253731,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7681192533966996,
            "auditor_fn_violation": 0.008508913139857717,
            "auditor_fp_violation": 0.002984357848518112,
            "ave_precision_score": 0.679971993153474,
            "fpr": 0.006586169045005488,
            "logloss": 0.713254379139543,
            "mae": 0.4866585406872447,
            "precision": 0.9142857142857143,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7924078838798739,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7398088194015802,
            "fpr": 0.03508771929824561,
            "logloss": 1.0885223759485596,
            "mae": 0.40226315554227454,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7820406863659004,
            "auditor_fn_violation": 0.015635631696116346,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7328154778305072,
            "fpr": 0.03512623490669594,
            "logloss": 0.9753341710910239,
            "mae": 0.3980835889173918,
            "precision": 0.8836363636363637,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7812549002608381,
            "auditor_fn_violation": 0.018274109407939398,
            "auditor_fp_violation": 0.0026774180105846555,
            "ave_precision_score": 0.7781227630366079,
            "fpr": 0.0537280701754386,
            "logloss": 0.9987715974797008,
            "mae": 0.3422868063113649,
            "precision": 0.8338983050847457,
            "recall": 0.5010183299389002
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7853546338343347,
            "auditor_fn_violation": 0.010687707003198252,
            "auditor_fp_violation": 0.01159930217970833,
            "ave_precision_score": 0.7825283767493331,
            "fpr": 0.059275521405049394,
            "logloss": 0.8880288846909185,
            "mae": 0.3188004944390776,
            "precision": 0.8211920529801324,
            "recall": 0.5356371490280778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.847302491362615,
            "auditor_fn_violation": 0.03557008611140887,
            "auditor_fp_violation": 0.031907634287619294,
            "ave_precision_score": 0.8475787282290147,
            "fpr": 0.09868421052631579,
            "logloss": 0.5136826076465056,
            "mae": 0.32481362486188464,
            "precision": 0.801762114537445,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7903402854006586,
            "auc_prc": 0.8602014758686896,
            "auditor_fn_violation": 0.02354709537616793,
            "auditor_fp_violation": 0.026121706915477497,
            "ave_precision_score": 0.8604276252524892,
            "fpr": 0.09989023051591657,
            "logloss": 0.4695731354139621,
            "mae": 0.3117530697558718,
            "precision": 0.7995594713656388,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7054765230089788,
            "auditor_fn_violation": 0.01111676849966056,
            "auditor_fp_violation": 0.011491019710797194,
            "ave_precision_score": 0.7004823767264762,
            "fpr": 0.25,
            "logloss": 1.9056290271085727,
            "mae": 0.3227549081220587,
            "precision": 0.6529680365296804,
            "recall": 0.8737270875763747
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6711753611582282,
            "auditor_fn_violation": 0.0016192777025697447,
            "auditor_fp_violation": 0.022914379802414928,
            "ave_precision_score": 0.6651950933984235,
            "fpr": 0.2722283205268935,
            "logloss": 2.096472913975941,
            "mae": 0.33656118132078366,
            "precision": 0.6287425149700598,
            "recall": 0.9071274298056156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8070454632904918,
            "auditor_fn_violation": 0.008903687426305066,
            "auditor_fp_violation": 0.025076051173063302,
            "ave_precision_score": 0.78516175324156,
            "fpr": 0.15021929824561403,
            "logloss": 3.176834810408746,
            "mae": 0.28923271395953337,
            "precision": 0.7303149606299213,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7749074029723078,
            "auditor_fn_violation": 0.014137266384221648,
            "auditor_fp_violation": 0.024744687941038106,
            "ave_precision_score": 0.742211583325521,
            "fpr": 0.15697036223929747,
            "logloss": 3.2868604811282394,
            "mae": 0.28079237462810835,
            "precision": 0.7190569744597249,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7910572181665259,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7387090949299258,
            "fpr": 0.03508771929824561,
            "logloss": 1.0894044421168756,
            "mae": 0.40209176946499114,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.782502570684787,
            "auditor_fn_violation": 0.01493149483277343,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7324331589654491,
            "fpr": 0.03512623490669594,
            "logloss": 0.9761072495323759,
            "mae": 0.3978098599179363,
            "precision": 0.8840579710144928,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6682238287158959,
            "auditor_fn_violation": 0.008999714152999608,
            "auditor_fp_violation": 0.012329666208276038,
            "ave_precision_score": 0.6659170152172407,
            "fpr": 0.2576754385964912,
            "logloss": 1.5432157109788587,
            "mae": 0.3397104962282914,
            "precision": 0.6508172362555721,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6383565726943432,
            "auditor_fn_violation": 0.009642170448537555,
            "auditor_fp_violation": 0.005924611886466999,
            "ave_precision_score": 0.6329293388435405,
            "fpr": 0.300768386388584,
            "logloss": 1.8643480816887636,
            "mae": 0.3601545294082001,
            "precision": 0.6068866571018652,
            "recall": 0.9136069114470843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.6816804889425585,
            "auditor_fn_violation": 0.0028651695430021084,
            "auditor_fp_violation": 0.017132349877067972,
            "ave_precision_score": 0.6735855031161658,
            "fpr": 0.3651315789473684,
            "logloss": 2.2449329933846993,
            "mae": 0.3861067598618479,
            "precision": 0.5888888888888889,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6485822494020879,
            "auditor_fn_violation": 0.0029706514807026204,
            "auditor_fp_violation": 0.0035234044221420834,
            "ave_precision_score": 0.6383841952152406,
            "fpr": 0.42041712403951703,
            "logloss": 2.5859019646025443,
            "mae": 0.42082954135224526,
            "precision": 0.5391095066185319,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7556966476652958,
            "auditor_fn_violation": 0.02515676921427807,
            "auditor_fp_violation": 0.005399112389048632,
            "ave_precision_score": 0.7409517641939967,
            "fpr": 0.09649122807017543,
            "logloss": 1.2634091493315185,
            "mae": 0.3681586481991772,
            "precision": 0.7743589743589744,
            "recall": 0.615071283095723
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.752862900770239,
            "auditor_fn_violation": 0.017309438516049342,
            "auditor_fp_violation": 0.003258781558726678,
            "ave_precision_score": 0.7378786254801644,
            "fpr": 0.09879253567508232,
            "logloss": 1.1637829013502567,
            "mae": 0.3436704752342863,
            "precision": 0.7692307692307693,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.827756476705223,
            "auditor_fn_violation": 0.007068013720656022,
            "auditor_fp_violation": 0.003211338917364671,
            "ave_precision_score": 0.8216070114477357,
            "fpr": 0.03728070175438596,
            "logloss": 1.7191455823494188,
            "mae": 0.29817719235811463,
            "precision": 0.8906752411575563,
            "recall": 0.5641547861507128
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8396573525303841,
            "auditor_fn_violation": 0.007700459704167688,
            "auditor_fp_violation": 0.009016779049709897,
            "ave_precision_score": 0.8326631404447136,
            "fpr": 0.03512623490669594,
            "logloss": 1.387193066270844,
            "mae": 0.2770567636672458,
            "precision": 0.8957654723127035,
            "recall": 0.593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7667148900869512,
            "auditor_fn_violation": 0.003146550184014008,
            "auditor_fp_violation": 0.022086094095095224,
            "ave_precision_score": 0.7667041015992551,
            "fpr": 0.2894736842105263,
            "logloss": 0.6627166726244965,
            "mae": 0.4821148209862019,
            "precision": 0.6265912305516266,
            "recall": 0.9022403258655805
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7249792558187937,
            "auditor_fn_violation": 0.009824724450144979,
            "auditor_fp_violation": 0.02546259996863729,
            "ave_precision_score": 0.7255579722288292,
            "fpr": 0.28869374313940727,
            "logloss": 0.6690289623482047,
            "mae": 0.4842387925911159,
            "precision": 0.6154970760233918,
            "recall": 0.9092872570194385
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7669544449033953,
            "auditor_fn_violation": 0.012825150962947082,
            "auditor_fp_violation": 0.012949535358586495,
            "ave_precision_score": 0.766940000821045,
            "fpr": 0.14364035087719298,
            "logloss": 0.6622509010617181,
            "mae": 0.48203176782842266,
            "precision": 0.7120879120879121,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7272206138826935,
            "auditor_fn_violation": 0.012098351561073795,
            "auditor_fp_violation": 0.0209150070566097,
            "ave_precision_score": 0.7277845984786624,
            "fpr": 0.14709110867178923,
            "logloss": 0.665696685738499,
            "mae": 0.4827770312060116,
            "precision": 0.7002237136465325,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.786000516073977,
            "auditor_fn_violation": 0.012838550041090512,
            "auditor_fp_violation": 0.005750718839854982,
            "ave_precision_score": 0.7324603931726614,
            "fpr": 0.03618421052631579,
            "logloss": 1.0965386876153687,
            "mae": 0.40389430611635335,
            "precision": 0.8833922261484098,
            "recall": 0.5091649694501018
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7818575355622623,
            "auditor_fn_violation": 0.015472044344026575,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7315045009375285,
            "fpr": 0.03512623490669594,
            "logloss": 0.9806691034649435,
            "mae": 0.39936641266779566,
            "precision": 0.8836363636363637,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8290534126427618,
            "auditor_fn_violation": 0.004613749240718907,
            "auditor_fp_violation": 0.0005235029378672343,
            "ave_precision_score": 0.8161972819837834,
            "fpr": 0.04057017543859649,
            "logloss": 1.9945592313597624,
            "mae": 0.2999757175873849,
            "precision": 0.8836477987421384,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8403777606037718,
            "auditor_fn_violation": 0.0054173492684800335,
            "auditor_fp_violation": 0.006003018660812295,
            "ave_precision_score": 0.8280233456562553,
            "fpr": 0.03732162458836443,
            "logloss": 1.5898641232380513,
            "mae": 0.2798472751914489,
            "precision": 0.8930817610062893,
            "recall": 0.6133909287257019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.6854862687487282,
            "auditor_fn_violation": 0.002603887519205346,
            "auditor_fp_violation": 0.019247197566362464,
            "ave_precision_score": 0.6780081632754662,
            "fpr": 0.3607456140350877,
            "logloss": 2.1885178514507286,
            "mae": 0.38503150088996463,
            "precision": 0.5902864259028643,
            "recall": 0.9653767820773931
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6543433858857362,
            "auditor_fn_violation": 0.002211985499996444,
            "auditor_fp_violation": 0.005018033558099422,
            "ave_precision_score": 0.6451079786326348,
            "fpr": 0.42151481888035125,
            "logloss": 2.4990400849841037,
            "mae": 0.41909493061455233,
            "precision": 0.5379061371841155,
            "recall": 0.9654427645788337
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7136848898789903,
            "auditor_fn_violation": 0.006813431235930969,
            "auditor_fp_violation": 0.018361670208776104,
            "ave_precision_score": 0.709479666060643,
            "fpr": 0.23026315789473684,
            "logloss": 1.6762696102872496,
            "mae": 0.3155238343865556,
            "precision": 0.6671949286846276,
            "recall": 0.8574338085539714
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.6789401314659184,
            "auditor_fn_violation": 0.004061233827967752,
            "auditor_fp_violation": 0.020726340755841306,
            "ave_precision_score": 0.67253313067491,
            "fpr": 0.24478594950603733,
            "logloss": 1.8830766785860995,
            "mae": 0.3237796424520986,
            "precision": 0.6449044585987261,
            "recall": 0.8747300215982722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7556770358719807,
            "auditor_fn_violation": 0.02515676921427807,
            "auditor_fp_violation": 0.005399112389048632,
            "ave_precision_score": 0.7409131024103808,
            "fpr": 0.09649122807017543,
            "logloss": 1.263763831004329,
            "mae": 0.3681792875473058,
            "precision": 0.7743589743589744,
            "recall": 0.615071283095723
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7528686650148559,
            "auditor_fn_violation": 0.017309438516049342,
            "auditor_fp_violation": 0.003258781558726678,
            "ave_precision_score": 0.7378504868446722,
            "fpr": 0.09879253567508232,
            "logloss": 1.164027679043229,
            "mae": 0.34367833127681,
            "precision": 0.7692307692307693,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7220568450648559,
            "auditor_fn_violation": 0.011259691999857078,
            "auditor_fp_violation": 0.02591730216277035,
            "ave_precision_score": 0.720840680352421,
            "fpr": 0.24780701754385964,
            "logloss": 0.6620675473052974,
            "mae": 0.48166587922656745,
            "precision": 0.64576802507837,
            "recall": 0.8391038696537678
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.6942602674466678,
            "auditor_fn_violation": 0.007795292951755958,
            "auditor_fp_violation": 0.023583287596048306,
            "ave_precision_score": 0.6942935281471596,
            "fpr": 0.2689352360043908,
            "logloss": 0.6689405302104906,
            "mae": 0.4843240104509368,
            "precision": 0.6171875,
            "recall": 0.8531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7806827378516634,
            "auditor_fn_violation": 0.017860971165183842,
            "auditor_fp_violation": 0.00437554694336792,
            "ave_precision_score": 0.7707071426787387,
            "fpr": 0.05482456140350877,
            "logloss": 0.8625451682552231,
            "mae": 0.34388755128275317,
            "precision": 0.8381877022653722,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7740864401135067,
            "auditor_fn_violation": 0.011017252538567503,
            "auditor_fp_violation": 0.009629331974282578,
            "ave_precision_score": 0.7656232130523867,
            "fpr": 0.06256860592755215,
            "logloss": 0.7882679336225423,
            "mae": 0.3215601327960246,
            "precision": 0.8246153846153846,
            "recall": 0.5788336933045356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.662678281460487,
            "auditor_fn_violation": 0.0061457105084503525,
            "auditor_fp_violation": 0.022112139017377196,
            "ave_precision_score": 0.652969679568314,
            "fpr": 0.37609649122807015,
            "logloss": 3.063999597323817,
            "mae": 0.3861729510812905,
            "precision": 0.5796568627450981,
            "recall": 0.9633401221995926
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.633932923454629,
            "auditor_fn_violation": 0.005478990879412413,
            "auditor_fp_violation": 0.017259291202759937,
            "ave_precision_score": 0.6241952013520333,
            "fpr": 0.39626783754116357,
            "logloss": 3.221705863394836,
            "mae": 0.4026454920202112,
            "precision": 0.5548705302096177,
            "recall": 0.9719222462203023
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8265491663562534,
            "auditor_fn_violation": 0.0070948118769428754,
            "auditor_fp_violation": 0.005800204192190691,
            "ave_precision_score": 0.8117819634450933,
            "fpr": 0.03837719298245614,
            "logloss": 1.7163281482410588,
            "mae": 0.3087065288087238,
            "precision": 0.8859934853420195,
            "recall": 0.5539714867617108
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8372306113744211,
            "auditor_fn_violation": 0.00202468983600961,
            "auditor_fp_violation": 0.008281715540222676,
            "ave_precision_score": 0.8226919144294738,
            "fpr": 0.03732162458836443,
            "logloss": 1.3747730735758183,
            "mae": 0.28612976057773887,
            "precision": 0.8888888888888888,
            "recall": 0.5874730021598272
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6972392234839483,
            "auditor_fn_violation": 0.009993479115303534,
            "auditor_fp_violation": 0.008818810684668924,
            "ave_precision_score": 0.6891298750383568,
            "fpr": 0.24671052631578946,
            "logloss": 2.0883609113776966,
            "mae": 0.32523159089703113,
            "precision": 0.6506211180124224,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6625975164716195,
            "auditor_fn_violation": 0.0026434767765230838,
            "auditor_fp_violation": 0.015470636663007693,
            "ave_precision_score": 0.6523803288486072,
            "fpr": 0.2689352360043908,
            "logloss": 2.352519924328002,
            "mae": 0.3409028039926998,
            "precision": 0.6236559139784946,
            "recall": 0.8768898488120951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.4493189953738644,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.44681648978797917,
            "fpr": 0.4616228070175439,
            "logloss": 0.7182773856502598,
            "mae": 0.4941794925875831,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.4380597230413612,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4136881271072965,
            "fpr": 0.49176728869374314,
            "logloss": 0.7345509005666683,
            "mae": 0.5001350262424163,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7065040912874608,
            "auditor_fn_violation": 0.01041331689713081,
            "auditor_fp_violation": 0.013907988498562323,
            "ave_precision_score": 0.7016296272100155,
            "fpr": 0.25109649122807015,
            "logloss": 1.8856430492666054,
            "mae": 0.32354096483690975,
            "precision": 0.6546003016591252,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6726551617273486,
            "auditor_fn_violation": 0.00018018317041771877,
            "auditor_fp_violation": 0.019832013485965194,
            "ave_precision_score": 0.6666379850018078,
            "fpr": 0.27552140504939626,
            "logloss": 2.095913230286803,
            "mae": 0.3386663611250281,
            "precision": 0.6270430906389302,
            "recall": 0.9114470842332614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7915481516300901,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7388183580099604,
            "fpr": 0.03508771929824561,
            "logloss": 1.0907625392230134,
            "mae": 0.4020949807187845,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7820538792978964,
            "auditor_fn_violation": 0.015635631696116346,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.73275369279863,
            "fpr": 0.03512623490669594,
            "logloss": 0.9770141752246813,
            "mae": 0.39785473381586506,
            "precision": 0.8836363636363637,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7924289360777461,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.002461245155644456,
            "ave_precision_score": 0.7397864298030561,
            "fpr": 0.03618421052631579,
            "logloss": 1.1000571579250156,
            "mae": 0.4001112955264035,
            "precision": 0.8846153846153846,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7846762943369798,
            "auditor_fn_violation": 0.013907295758820094,
            "auditor_fp_violation": 0.009930708013172338,
            "ave_precision_score": 0.7324298077682503,
            "fpr": 0.036223929747530186,
            "logloss": 0.9832906124686672,
            "mae": 0.39548155321833406,
            "precision": 0.8804347826086957,
            "recall": 0.5248380129589633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7887993355271489,
            "auditor_fn_violation": 0.0063556293993639905,
            "auditor_fp_violation": 0.0031852939950827185,
            "ave_precision_score": 0.7409835504923886,
            "fpr": 0.03399122807017544,
            "logloss": 1.0034468497664673,
            "mae": 0.3890934539241954,
            "precision": 0.8904593639575972,
            "recall": 0.5132382892057027
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7864643363254826,
            "auditor_fn_violation": 0.011882605922810477,
            "auditor_fp_violation": 0.00755645287752862,
            "ave_precision_score": 0.7389534906801156,
            "fpr": 0.03402854006586169,
            "logloss": 0.9040159687394262,
            "mae": 0.3828291347464147,
            "precision": 0.8880866425992779,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8080213713812405,
            "auditor_fn_violation": 0.012559402579769185,
            "auditor_fp_violation": 0.02568550235446098,
            "ave_precision_score": 0.7861395940866343,
            "fpr": 0.1513157894736842,
            "logloss": 3.1603119309416603,
            "mae": 0.2873050890125274,
            "precision": 0.7299412915851272,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7769635862079445,
            "auditor_fn_violation": 0.012375738810269498,
            "auditor_fp_violation": 0.024744687941038106,
            "ave_precision_score": 0.7441971793292037,
            "fpr": 0.15697036223929747,
            "logloss": 3.227960473438728,
            "mae": 0.2770945312279286,
            "precision": 0.7201565557729941,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7214524628867167,
            "auditor_fn_violation": 0.010471379569085651,
            "auditor_fp_violation": 0.017434470975538605,
            "ave_precision_score": 0.7146680726515182,
            "fpr": 0.2138157894736842,
            "logloss": 2.957651854035291,
            "mae": 0.30926810830187285,
            "precision": 0.674457429048414,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6927842281795591,
            "auditor_fn_violation": 0.005720815660762508,
            "auditor_fp_violation": 0.029934236318017872,
            "ave_precision_score": 0.6838878092534038,
            "fpr": 0.23380900109769484,
            "logloss": 2.813886632047006,
            "mae": 0.30652438493389805,
            "precision": 0.6508196721311476,
            "recall": 0.857451403887689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7834800067876327,
            "auditor_fn_violation": 0.04541394218744416,
            "auditor_fp_violation": 0.09482435304413052,
            "ave_precision_score": 0.7549840593316128,
            "fpr": 0.23793859649122806,
            "logloss": 1.0929636103449396,
            "mae": 0.4103570147406212,
            "precision": 0.6104129263913824,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7727077868488139,
            "auditor_fn_violation": 0.035967879979041856,
            "auditor_fp_violation": 0.10141426219225341,
            "ave_precision_score": 0.7477707635122129,
            "fpr": 0.2513721185510428,
            "logloss": 0.9846299552788077,
            "mae": 0.4085447676232295,
            "precision": 0.5836363636363636,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7923624281141396,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7396499029810452,
            "fpr": 0.03508771929824561,
            "logloss": 1.0840015975238155,
            "mae": 0.40220500914208973,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7839409038353377,
            "auditor_fn_violation": 0.0157565440867914,
            "auditor_fp_violation": 0.009930708013172338,
            "ave_precision_score": 0.7320941198198613,
            "fpr": 0.036223929747530186,
            "logloss": 0.9712625757234121,
            "mae": 0.3979888268168709,
            "precision": 0.88,
            "recall": 0.5226781857451404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7662806871987105,
            "auditor_fn_violation": 0.02808670096830672,
            "auditor_fp_violation": 0.005875734466808349,
            "ave_precision_score": 0.7499969781378953,
            "fpr": 0.09649122807017543,
            "logloss": 1.390625302271884,
            "mae": 0.36417485597843885,
            "precision": 0.7783375314861462,
            "recall": 0.6293279022403259
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7513760313400055,
            "auditor_fn_violation": 0.023447520466200255,
            "auditor_fp_violation": 0.0061818841147875175,
            "ave_precision_score": 0.7357220980168163,
            "fpr": 0.10208562019758508,
            "logloss": 1.329738731577065,
            "mae": 0.34350227232229064,
            "precision": 0.7645569620253164,
            "recall": 0.652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.787372735395866,
            "auditor_fn_violation": 0.0063556293993639905,
            "auditor_fp_violation": 0.0031852939950827185,
            "ave_precision_score": 0.7398709438850026,
            "fpr": 0.03399122807017544,
            "logloss": 0.9970557070561273,
            "mae": 0.38898178245686543,
            "precision": 0.8904593639575972,
            "recall": 0.5132382892057027
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.78698288168705,
            "auditor_fn_violation": 0.011441631321525014,
            "auditor_fp_violation": 0.00755645287752862,
            "ave_precision_score": 0.7398059979499683,
            "fpr": 0.03402854006586169,
            "logloss": 0.8984148830985228,
            "mae": 0.3826014125159535,
            "precision": 0.8876811594202898,
            "recall": 0.5291576673866091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8293073499704093,
            "auditor_fn_violation": 0.004613749240718907,
            "auditor_fp_violation": 0.0018387715131058069,
            "ave_precision_score": 0.8150890937301405,
            "fpr": 0.041666666666666664,
            "logloss": 1.9951341496258423,
            "mae": 0.3003998084756836,
            "precision": 0.8808777429467085,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8426910279951846,
            "auditor_fn_violation": 0.006043248702562631,
            "auditor_fp_violation": 0.00531205896189431,
            "ave_precision_score": 0.8275703256427768,
            "fpr": 0.03951701427003293,
            "logloss": 1.5858514305139644,
            "mae": 0.2792694848883616,
            "precision": 0.8878504672897196,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5799501954676601,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4554085700582288,
            "fpr": 0.4616228070175439,
            "logloss": 1.086855313548968,
            "mae": 0.4689760983251689,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.5145330724903856,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.4183220238774345,
            "fpr": 0.49176728869374314,
            "logloss": 1.1511535672141726,
            "mae": 0.49316470251386957,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.4674068124118311,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.543774928285984,
            "fpr": 0.4616228070175439,
            "logloss": 0.7196019770190669,
            "mae": 0.4920547349672568,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.49887958561252455,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5148686861847827,
            "fpr": 0.49176728869374314,
            "logloss": 0.7361187051589007,
            "mae": 0.498105490639495,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.764746182341329,
            "auditor_fn_violation": 0.00609658055525781,
            "auditor_fp_violation": 0.00361243072050673,
            "ave_precision_score": 0.677669158861228,
            "fpr": 0.008771929824561403,
            "logloss": 0.6930042798764255,
            "mae": 0.4790807926609679,
            "precision": 0.8805970149253731,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.7665348827560712,
            "auditor_fn_violation": 0.007418330792592588,
            "auditor_fp_violation": 0.002984357848518112,
            "ave_precision_score": 0.6835830863132607,
            "fpr": 0.006586169045005488,
            "logloss": 0.7142443756473307,
            "mae": 0.4865719961165016,
            "precision": 0.9130434782608695,
            "recall": 0.13606911447084233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8509855939413149,
            "auditor_fn_violation": 0.006717404509236438,
            "auditor_fp_violation": 0.007594699337417179,
            "ave_precision_score": 0.8512622187673853,
            "fpr": 0.06798245614035088,
            "logloss": 0.5125992372148032,
            "mae": 0.3393621715296289,
            "precision": 0.845,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8494562512900984,
            "auditor_fn_violation": 0.0011451114646283895,
            "auditor_fp_violation": 0.011927630547279286,
            "ave_precision_score": 0.8496770329260706,
            "fpr": 0.08342480790340286,
            "logloss": 0.4945454161844569,
            "mae": 0.33593014526128784,
            "precision": 0.8123456790123457,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.77306553526652,
            "auditor_fn_violation": 0.013265087361989501,
            "auditor_fp_violation": 0.003664520565070635,
            "ave_precision_score": 0.7657439186843308,
            "fpr": 0.03508771929824561,
            "logloss": 1.0784862903524357,
            "mae": 0.3582794799698295,
            "precision": 0.8827838827838828,
            "recall": 0.4908350305498982
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7795639334458171,
            "auditor_fn_violation": 0.009533112213811042,
            "auditor_fp_violation": 0.011043104124196332,
            "ave_precision_score": 0.7738494175432895,
            "fpr": 0.04061470911086718,
            "logloss": 0.9527256734479581,
            "mae": 0.33775852375699467,
            "precision": 0.8683274021352313,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.7651011841355624,
            "auditor_fn_violation": 0.003611051559652696,
            "auditor_fp_violation": 0.005169917072967462,
            "ave_precision_score": 0.6834136751373278,
            "fpr": 0.40899122807017546,
            "logloss": 0.6845440390038414,
            "mae": 0.4760044349220647,
            "precision": 0.5532934131736527,
            "recall": 0.9409368635437881
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.7653561226657402,
            "auditor_fn_violation": 0.0061285986253920765,
            "auditor_fp_violation": 0.004503489101458361,
            "ave_precision_score": 0.683662675127081,
            "fpr": 0.4489571899012075,
            "logloss": 0.7069058131695221,
            "mae": 0.48492575721134373,
            "precision": 0.513095238095238,
            "recall": 0.9308855291576674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8259147657347241,
            "auditor_fn_violation": 0.008937185121663634,
            "auditor_fp_violation": 0.007451452264866443,
            "ave_precision_score": 0.8135345751878754,
            "fpr": 0.044956140350877194,
            "logloss": 1.8758281221666588,
            "mae": 0.30166365072199075,
            "precision": 0.8714733542319749,
            "recall": 0.5661914460285132
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8365637358349023,
            "auditor_fn_violation": 0.004445308480700253,
            "auditor_fp_violation": 0.01532117374941195,
            "ave_precision_score": 0.8234683428155898,
            "fpr": 0.04500548847420417,
            "logloss": 1.5114687341135407,
            "mae": 0.2817087315682897,
            "precision": 0.8706624605678234,
            "recall": 0.5961123110151187
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.766039043497573,
            "auditor_fn_violation": 0.00609658055525781,
            "auditor_fp_violation": 0.00361243072050673,
            "ave_precision_score": 0.6821170579678815,
            "fpr": 0.008771929824561403,
            "logloss": 0.6970152403386897,
            "mae": 0.4802292101166881,
            "precision": 0.8805970149253731,
            "recall": 0.12016293279022404
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.7683605077507413,
            "auditor_fn_violation": 0.008508913139857717,
            "auditor_fp_violation": 0.002984357848518112,
            "ave_precision_score": 0.6827331917582699,
            "fpr": 0.006586169045005488,
            "logloss": 0.7167698831890433,
            "mae": 0.48679698342058714,
            "precision": 0.9142857142857143,
            "recall": 0.13822894168466524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.6844153648902738,
            "auditor_fn_violation": 0.004298870904348448,
            "auditor_fp_violation": 0.012767220902612836,
            "ave_precision_score": 0.6789497262434168,
            "fpr": 0.32894736842105265,
            "logloss": 2.212587927602372,
            "mae": 0.3525621923361605,
            "precision": 0.6108949416342413,
            "recall": 0.9592668024439919
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.6494325355228983,
            "auditor_fn_violation": 0.0029991014549791014,
            "auditor_fp_violation": 0.016323310334012863,
            "ave_precision_score": 0.6418291180868922,
            "fpr": 0.37980241492864986,
            "logloss": 2.5524230898152234,
            "mae": 0.3910733804141982,
            "precision": 0.5675,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7908555735643191,
            "auditor_fn_violation": 0.007275699431879079,
            "auditor_fp_violation": 0.005190753010793017,
            "ave_precision_score": 0.7384459847641407,
            "fpr": 0.03508771929824561,
            "logloss": 1.0919011362160653,
            "mae": 0.4019210720787302,
            "precision": 0.887719298245614,
            "recall": 0.515274949083503
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7834893521806983,
            "auditor_fn_violation": 0.01493149483277343,
            "auditor_fp_violation": 0.010820134859651876,
            "ave_precision_score": 0.7334912732051135,
            "fpr": 0.03512623490669594,
            "logloss": 0.9778805090127117,
            "mae": 0.39753624182926317,
            "precision": 0.8840579710144928,
            "recall": 0.5269978401727862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8067588782913179,
            "auditor_fn_violation": 0.012612998892342872,
            "auditor_fp_violation": 0.027943597116306205,
            "ave_precision_score": 0.7839914932965091,
            "fpr": 0.15350877192982457,
            "logloss": 3.2282305585092663,
            "mae": 0.287704304635906,
            "precision": 0.7297297297297297,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7760325662153778,
            "auditor_fn_violation": 0.012375738810269498,
            "auditor_fp_violation": 0.024531519523286815,
            "ave_precision_score": 0.7431833250735437,
            "fpr": 0.1602634467618002,
            "logloss": 3.254954198774423,
            "mae": 0.27667536500126155,
            "precision": 0.7159533073929961,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8278272773891275,
            "auditor_fn_violation": 0.004613749240718907,
            "auditor_fp_violation": 0.002406550818852356,
            "ave_precision_score": 0.8123637271681677,
            "fpr": 0.04276315789473684,
            "logloss": 2.0031657420086995,
            "mae": 0.3006442848915603,
            "precision": 0.878125,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8424069774389903,
            "auditor_fn_violation": 0.004881541419606307,
            "auditor_fp_violation": 0.007154618159008939,
            "ave_precision_score": 0.826890198167644,
            "fpr": 0.03951701427003293,
            "logloss": 1.5921656993371212,
            "mae": 0.2795125346845487,
            "precision": 0.8885448916408669,
            "recall": 0.6198704103671706
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7802567036013043,
            "auditor_fn_violation": 0.01740316932861686,
            "auditor_fp_violation": 0.00437554694336792,
            "ave_precision_score": 0.7702830045505251,
            "fpr": 0.05482456140350877,
            "logloss": 0.8634692441158353,
            "mae": 0.3439320394456137,
            "precision": 0.8381877022653722,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7739755560050399,
            "auditor_fn_violation": 0.011017252538567503,
            "auditor_fp_violation": 0.009629331974282578,
            "ave_precision_score": 0.7655128281594553,
            "fpr": 0.06256860592755215,
            "logloss": 0.7889477973268573,
            "mae": 0.32156301856623476,
            "precision": 0.8246153846153846,
            "recall": 0.5788336933045356
        }
    }
]