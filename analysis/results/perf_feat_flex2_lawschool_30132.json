[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.8218838943767847,
            "auditor_fn_violation": 0.002867393378844601,
            "auditor_fp_violation": 0.01936292343762633,
            "ave_precision_score": 0.8211230182024707,
            "fpr": 0.3958333333333333,
            "logloss": 2.467851592891322,
            "mae": 0.39675036882500425,
            "precision": 0.5666266506602641,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8303794662083887,
            "auditor_fn_violation": 0.002402937025523711,
            "auditor_fp_violation": 0.012281565035265027,
            "ave_precision_score": 0.829631186678107,
            "fpr": 0.407244785949506,
            "logloss": 2.6562506446954406,
            "mae": 0.4109270493162034,
            "precision": 0.558858501783591,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.8282582767804814,
            "auditor_fn_violation": 0.0005138368934889527,
            "auditor_fp_violation": 0.016442315466084576,
            "ave_precision_score": 0.8279902937224255,
            "fpr": 0.41228070175438597,
            "logloss": 2.3340715947545627,
            "mae": 0.4051719534809787,
            "precision": 0.5581668625146886,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.8308039892416674,
            "auditor_fn_violation": 0.002416773515114059,
            "auditor_fp_violation": 0.012655033624790254,
            "ave_precision_score": 0.8309085769062677,
            "fpr": 0.41602634467618005,
            "logloss": 2.5018785512354507,
            "mae": 0.41704003565291964,
            "precision": 0.5535924617196702,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 30132,
        "test": {
            "accuracy": 0.4934210526315789,
            "auc_prc": 0.5413568716515587,
            "auditor_fn_violation": 0.006436724656830361,
            "auditor_fp_violation": 0.0017887460586951394,
            "ave_precision_score": 0.5385253045511365,
            "fpr": 0.4583333333333333,
            "logloss": 4.576908234563459,
            "mae": 0.49617702408248876,
            "precision": 0.5093896713615024,
            "recall": 0.9079497907949791
        },
        "train": {
            "accuracy": 0.47310647639956094,
            "auc_prc": 0.5466327344716607,
            "auditor_fn_violation": 0.009856192751524323,
            "auditor_fp_violation": 0.004463959019392616,
            "ave_precision_score": 0.5438420836324203,
            "fpr": 0.4632272228320527,
            "logloss": 4.606467059781613,
            "mae": 0.5170707000398839,
            "precision": 0.4976190476190476,
            "recall": 0.8781512605042017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6841498986160865,
            "auditor_fn_violation": 0.005704965866549219,
            "auditor_fp_violation": 0.015270029913493416,
            "ave_precision_score": 0.6630742056944158,
            "fpr": 0.23684210526315788,
            "logloss": 2.4681354124542234,
            "mae": 0.31317062752387165,
            "precision": 0.6598425196850394,
            "recall": 0.8765690376569037
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6535256469301167,
            "auditor_fn_violation": 0.009929987362672844,
            "auditor_fp_violation": 0.019745889952937926,
            "ave_precision_score": 0.63478980405546,
            "fpr": 0.2689352360043908,
            "logloss": 2.772013509402526,
            "mae": 0.3278747880382983,
            "precision": 0.6348733233979136,
            "recall": 0.8949579831932774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.6564761755108698,
            "auditor_fn_violation": 0.04132716729061146,
            "auditor_fp_violation": 0.05815698520494786,
            "ave_precision_score": 0.6557580345572485,
            "fpr": 0.13486842105263158,
            "logloss": 1.4634538338442038,
            "mae": 0.36059285021713405,
            "precision": 0.6977886977886978,
            "recall": 0.5941422594142259
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6427866748384915,
            "auditor_fn_violation": 0.05000737946111486,
            "auditor_fp_violation": 0.06684583065218215,
            "ave_precision_score": 0.6416763939027469,
            "fpr": 0.14818880351262348,
            "logloss": 1.48747702364291,
            "mae": 0.35236353381642044,
            "precision": 0.6931818181818182,
            "recall": 0.6407563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7431792124892529,
            "auditor_fn_violation": 0.03310118916538208,
            "auditor_fp_violation": 0.018109790605546124,
            "ave_precision_score": 0.7272393209718768,
            "fpr": 0.14583333333333334,
            "logloss": 2.906918449492043,
            "mae": 0.31654202060959374,
            "precision": 0.7089715536105032,
            "recall": 0.6778242677824268
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7522351159619166,
            "auditor_fn_violation": 0.007280299606121263,
            "auditor_fp_violation": 0.01674300061824193,
            "ave_precision_score": 0.739413580128235,
            "fpr": 0.16575192096597147,
            "logloss": 2.8129915325838093,
            "mae": 0.3125165417080008,
            "precision": 0.694331983805668,
            "recall": 0.7205882352941176
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8088203238262952,
            "auditor_fn_violation": 0.009753725317477792,
            "auditor_fp_violation": 0.022803985770878818,
            "ave_precision_score": 0.8090924924166387,
            "fpr": 0.16228070175438597,
            "logloss": 0.8819255441576758,
            "mae": 0.2859301100414966,
            "precision": 0.7180952380952381,
            "recall": 0.7887029288702929
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8196376848643208,
            "auditor_fn_violation": 0.008428728242120122,
            "auditor_fp_violation": 0.025966160717665325,
            "ave_precision_score": 0.8198919173371171,
            "fpr": 0.1778265642151482,
            "logloss": 0.8920670096716763,
            "mae": 0.2929023560553133,
            "precision": 0.7070524412296564,
            "recall": 0.8214285714285714
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7516488979828133,
            "auditor_fn_violation": 0.01020333259928063,
            "auditor_fp_violation": 0.012308998302207141,
            "ave_precision_score": 0.7525429131897768,
            "fpr": 0.1425438596491228,
            "logloss": 0.9899705647244241,
            "mae": 0.3259762502138476,
            "precision": 0.7123893805309734,
            "recall": 0.6736401673640168
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7699845932364109,
            "auditor_fn_violation": 0.013522862492966447,
            "auditor_fp_violation": 0.021138826854410337,
            "ave_precision_score": 0.7706070946495014,
            "fpr": 0.1525795828759605,
            "logloss": 0.9417111482158937,
            "mae": 0.3185160512420223,
            "precision": 0.7110187110187111,
            "recall": 0.7184873949579832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.6636233389925369,
            "auditor_fn_violation": 0.011208067239227777,
            "auditor_fp_violation": 0.012442901608860866,
            "ave_precision_score": 0.6439030727126381,
            "fpr": 0.1962719298245614,
            "logloss": 2.3348601111685356,
            "mae": 0.35363795958191824,
            "precision": 0.6865148861646234,
            "recall": 0.8200836820083682
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6312484938468902,
            "auditor_fn_violation": 0.0066092298609894025,
            "auditor_fp_violation": 0.027502933494833265,
            "ave_precision_score": 0.6135372201567117,
            "fpr": 0.2074643249176729,
            "logloss": 2.5617903448594217,
            "mae": 0.3696685559806362,
            "precision": 0.6796610169491526,
            "recall": 0.842436974789916
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6738781735840638,
            "auditor_fn_violation": 0.0018167804448359392,
            "auditor_fp_violation": 0.003951410785027095,
            "ave_precision_score": 0.6504461111870052,
            "fpr": 0.40131578947368424,
            "logloss": 2.7290236180310656,
            "mae": 0.39230775824960384,
            "precision": 0.5648038049940547,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6411503751423577,
            "auditor_fn_violation": 0.002001678827403629,
            "auditor_fp_violation": 0.009500738105151597,
            "ave_precision_score": 0.6191784367574803,
            "fpr": 0.4061470911086718,
            "logloss": 3.018915650668043,
            "mae": 0.4027419769451529,
            "precision": 0.5584725536992841,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.755606564761385,
            "auditor_fn_violation": 0.0052393011818248555,
            "auditor_fp_violation": 0.022172366399870656,
            "ave_precision_score": 0.7575570496366099,
            "fpr": 0.3925438596491228,
            "logloss": 2.4581445338177286,
            "mae": 0.40088340311079884,
            "precision": 0.5665859564164649,
            "recall": 0.9790794979079498
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.7677729622215763,
            "auditor_fn_violation": 0.003403776439225526,
            "auditor_fp_violation": 0.020704795790908077,
            "ave_precision_score": 0.7677868892948,
            "fpr": 0.411635565312843,
            "logloss": 2.663026392445932,
            "mae": 0.41312647250468937,
            "precision": 0.5551601423487544,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6815994176406402,
            "auditor_fn_violation": 0.008102106731263306,
            "auditor_fp_violation": 0.01417353868542324,
            "ave_precision_score": 0.6591835926680767,
            "fpr": 0.23684210526315788,
            "logloss": 2.5468781369788065,
            "mae": 0.3155101771163301,
            "precision": 0.6625,
            "recall": 0.8870292887029289
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6510591229105389,
            "auditor_fn_violation": 0.00844256473171047,
            "auditor_fp_violation": 0.01864567167568796,
            "ave_precision_score": 0.6315232153921768,
            "fpr": 0.2678375411635565,
            "logloss": 2.8208371854992182,
            "mae": 0.3298950562735101,
            "precision": 0.6363636363636364,
            "recall": 0.8970588235294118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.83281136560329,
            "auditor_fn_violation": 0.0015828011451222198,
            "auditor_fp_violation": 0.01663938070983911,
            "ave_precision_score": 0.8323834806057111,
            "fpr": 0.3925438596491228,
            "logloss": 2.41645834005583,
            "mae": 0.39354900413392196,
            "precision": 0.5697115384615384,
            "recall": 0.9916317991631799
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.8397813275428012,
            "auditor_fn_violation": 0.0018310287891226747,
            "auditor_fp_violation": 0.011317612324463457,
            "ave_precision_score": 0.8388306317685652,
            "fpr": 0.40504939626783754,
            "logloss": 2.6104033237673883,
            "mae": 0.4081892613953976,
            "precision": 0.5607142857142857,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.7812662189844278,
            "auditor_fn_violation": 0.005466398737429348,
            "auditor_fp_violation": 0.028480980677500205,
            "ave_precision_score": 0.7814099579132743,
            "fpr": 0.3256578947368421,
            "logloss": 1.6309646598148508,
            "mae": 0.3513867454295524,
            "precision": 0.6029411764705882,
            "recall": 0.9435146443514645
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7991177434461219,
            "auditor_fn_violation": 0.005377782287448459,
            "auditor_fp_violation": 0.018749132568732105,
            "ave_precision_score": 0.7994028819949541,
            "fpr": 0.34357848518111966,
            "logloss": 1.7482144113899503,
            "mae": 0.3640389017244512,
            "precision": 0.5935064935064935,
            "recall": 0.9600840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7886440765843279,
            "auditor_fn_violation": 0.02217297951992953,
            "auditor_fp_violation": 0.03938273102110115,
            "ave_precision_score": 0.7886771840296317,
            "fpr": 0.22807017543859648,
            "logloss": 1.9807480737309315,
            "mae": 0.30205473264331045,
            "precision": 0.6623376623376623,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.805610400010571,
            "auditor_fn_violation": 0.02504865832172606,
            "auditor_fp_violation": 0.03826791324425604,
            "ave_precision_score": 0.8057917128544403,
            "fpr": 0.24698133918770582,
            "logloss": 2.1916341246361584,
            "mae": 0.32131559339149224,
            "precision": 0.6439873417721519,
            "recall": 0.8550420168067226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8331484234349777,
            "auditor_fn_violation": 0.009313293694487267,
            "auditor_fp_violation": 0.010805744199207703,
            "ave_precision_score": 0.8334537942517457,
            "fpr": 0.12390350877192982,
            "logloss": 0.7571512945615758,
            "mae": 0.26818251565554246,
            "precision": 0.7616033755274262,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8424399960009512,
            "auditor_fn_violation": 0.014290787665230743,
            "auditor_fp_violation": 0.023922177220939478,
            "ave_precision_score": 0.8426683442421379,
            "fpr": 0.14489571899012074,
            "logloss": 0.760986521359444,
            "mae": 0.2704219796261348,
            "precision": 0.7396449704142012,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.823000585277676,
            "auditor_fn_violation": 0.00461076855318212,
            "auditor_fp_violation": 0.013142735871937913,
            "ave_precision_score": 0.8233690612841207,
            "fpr": 0.15789473684210525,
            "logloss": 0.8265631413422161,
            "mae": 0.2744425300103882,
            "precision": 0.7251908396946565,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8361037984191897,
            "auditor_fn_violation": 0.006440885904306842,
            "auditor_fp_violation": 0.023707685125604058,
            "ave_precision_score": 0.8363422869906518,
            "fpr": 0.17233809001097694,
            "logloss": 0.8410082205675589,
            "mae": 0.2774854376625162,
            "precision": 0.7176258992805755,
            "recall": 0.8382352941176471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 30132,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8328696879538464,
            "auditor_fn_violation": 0.008437018277912357,
            "auditor_fp_violation": 0.008779509257013506,
            "ave_precision_score": 0.8331733766739828,
            "fpr": 0.11951754385964912,
            "logloss": 0.7522464432684184,
            "mae": 0.2690335213044523,
            "precision": 0.7670940170940171,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8422106887069122,
            "auditor_fn_violation": 0.012694979199143988,
            "auditor_fp_violation": 0.020666944244672403,
            "ave_precision_score": 0.8424401045744788,
            "fpr": 0.13721185510428102,
            "logloss": 0.7536202850397113,
            "mae": 0.2704932266563779,
            "precision": 0.748995983935743,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.8280439313620203,
            "auditor_fn_violation": 0.0006468839462673419,
            "auditor_fp_violation": 0.013137682916969852,
            "ave_precision_score": 0.8251641863711754,
            "fpr": 0.43859649122807015,
            "logloss": 3.4374743848881737,
            "mae": 0.436668153629095,
            "precision": 0.5438996579247435,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.8321705889682639,
            "auditor_fn_violation": 0.0009777785977179018,
            "auditor_fp_violation": 0.007699004504334016,
            "ave_precision_score": 0.8292522747863829,
            "fpr": 0.45115257958287597,
            "logloss": 3.643877505017683,
            "mae": 0.449541310628928,
            "precision": 0.535593220338983,
            "recall": 0.9957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6740624824487288,
            "auditor_fn_violation": 0.005246182925934085,
            "auditor_fp_violation": 0.019079957959414667,
            "ave_precision_score": 0.6536880608249318,
            "fpr": 0.18859649122807018,
            "logloss": 2.337976250824609,
            "mae": 0.31771832302400616,
            "precision": 0.6923076923076923,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6400662059524407,
            "auditor_fn_violation": 0.01267422446475846,
            "auditor_fp_violation": 0.029524206063817705,
            "ave_precision_score": 0.6219045070090948,
            "fpr": 0.21734357848518113,
            "logloss": 2.5727358528451703,
            "mae": 0.3312679537373639,
            "precision": 0.6710963455149501,
            "recall": 0.8487394957983193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8225891427738403,
            "auditor_fn_violation": 0.014369081700066072,
            "auditor_fp_violation": 0.014926428975664976,
            "ave_precision_score": 0.8228497942794614,
            "fpr": 0.11074561403508772,
            "logloss": 0.8813073863203716,
            "mae": 0.2705071011382698,
            "precision": 0.7755555555555556,
            "recall": 0.7301255230125523
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8277643463122347,
            "auditor_fn_violation": 0.011624957337490431,
            "auditor_fp_violation": 0.028590534590004674,
            "ave_precision_score": 0.8280883860068946,
            "fpr": 0.13721185510428102,
            "logloss": 0.8996638929302949,
            "mae": 0.27407881274086054,
            "precision": 0.7448979591836735,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 30132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8151660929475039,
            "auditor_fn_violation": 0.006170630551273583,
            "auditor_fp_violation": 0.022495755517826826,
            "ave_precision_score": 0.8155948498334884,
            "fpr": 0.15350877192982457,
            "logloss": 0.9120050957331268,
            "mae": 0.27436214555853533,
            "precision": 0.7270955165692008,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8303980097972723,
            "auditor_fn_violation": 0.009637114999677149,
            "auditor_fp_violation": 0.024050872478140736,
            "ave_precision_score": 0.8306644586174696,
            "fpr": 0.1668496158068057,
            "logloss": 0.9214728477790287,
            "mae": 0.28118231227708473,
            "precision": 0.7190388170055453,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.678084677602121,
            "auditor_fn_violation": 0.0053677604051970956,
            "auditor_fp_violation": 0.023728676530034774,
            "ave_precision_score": 0.6564658710937984,
            "fpr": 0.19736842105263158,
            "logloss": 2.597818317807753,
            "mae": 0.3102317524588894,
            "precision": 0.6785714285714286,
            "recall": 0.7949790794979079
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6519257284454006,
            "auditor_fn_violation": 0.008689315462738335,
            "auditor_fp_violation": 0.02348057584819007,
            "ave_precision_score": 0.6328255849747546,
            "fpr": 0.2261251372118551,
            "logloss": 2.844190664060714,
            "mae": 0.3188950966514182,
            "precision": 0.6600660066006601,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8146059952337024,
            "auditor_fn_violation": 0.007858951772737285,
            "auditor_fp_violation": 0.007907874525022233,
            "ave_precision_score": 0.814934251712663,
            "fpr": 0.11732456140350878,
            "logloss": 0.8608239934995953,
            "mae": 0.2725351707929542,
            "precision": 0.7688984881209503,
            "recall": 0.7447698744769874
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8293942012117121,
            "auditor_fn_violation": 0.011507347175972479,
            "auditor_fp_violation": 0.02258980279344412,
            "ave_precision_score": 0.8296971095828564,
            "fpr": 0.13391877058177826,
            "logloss": 0.8563085925721052,
            "mae": 0.2716268261063335,
            "precision": 0.75,
            "recall": 0.7689075630252101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8690507715914688,
            "auditor_fn_violation": 0.011850363356088972,
            "auditor_fp_violation": 0.012890088123534647,
            "ave_precision_score": 0.8692262457763769,
            "fpr": 0.13706140350877194,
            "logloss": 0.50266397616817,
            "mae": 0.2777643412728937,
            "precision": 0.7572815533980582,
            "recall": 0.8158995815899581
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8542314527679354,
            "auditor_fn_violation": 0.014237747788467751,
            "auditor_fp_violation": 0.021307897094262968,
            "ave_precision_score": 0.8546151076406432,
            "fpr": 0.1437980241492865,
            "logloss": 0.5278343717578592,
            "mae": 0.2842607028330252,
            "precision": 0.747104247104247,
            "recall": 0.8130252100840336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.8196627173634745,
            "auditor_fn_violation": 0.0006468839462673419,
            "auditor_fp_violation": 0.014153326865550975,
            "ave_precision_score": 0.8179966464736991,
            "fpr": 0.43201754385964913,
            "logloss": 3.1338667104832476,
            "mae": 0.4274005364190599,
            "precision": 0.547646383467279,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.8257428712314896,
            "auditor_fn_violation": 0.0018310287891226747,
            "auditor_fp_violation": 0.010245151847786318,
            "ave_precision_score": 0.8242276742103612,
            "fpr": 0.4456641053787047,
            "logloss": 3.3323947721455056,
            "mae": 0.4409629153591062,
            "precision": 0.5370581527936146,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8233738266386501,
            "auditor_fn_violation": 0.00830626513983704,
            "auditor_fp_violation": 0.014486821893443297,
            "ave_precision_score": 0.8237314617527388,
            "fpr": 0.125,
            "logloss": 0.8385044147526209,
            "mae": 0.27476261579598593,
            "precision": 0.7558886509635975,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.836026431970269,
            "auditor_fn_violation": 0.009039839865693814,
            "auditor_fp_violation": 0.02324084938869753,
            "ave_precision_score": 0.8362654501113589,
            "fpr": 0.1394072447859495,
            "logloss": 0.8249019871939202,
            "mae": 0.2725677535398004,
            "precision": 0.744466800804829,
            "recall": 0.7773109243697479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8278230035695469,
            "auditor_fn_violation": 0.0074781619320267185,
            "auditor_fp_violation": 0.021922245128951422,
            "ave_precision_score": 0.8281882965604277,
            "fpr": 0.19846491228070176,
            "logloss": 0.8952227129177761,
            "mae": 0.2781053518470482,
            "precision": 0.6988352745424293,
            "recall": 0.8786610878661087
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8389695340676337,
            "auditor_fn_violation": 0.008002103146417734,
            "auditor_fp_violation": 0.024467239486733034,
            "ave_precision_score": 0.8391846404968268,
            "fpr": 0.22063666300768386,
            "logloss": 0.9443144696040624,
            "mae": 0.28665164413785693,
            "precision": 0.6758064516129032,
            "recall": 0.8802521008403361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.667413380743881,
            "auditor_fn_violation": 0.007886478749174192,
            "auditor_fp_violation": 0.02075753900881236,
            "ave_precision_score": 0.6453830404955576,
            "fpr": 0.18092105263157895,
            "logloss": 2.411130219299984,
            "mae": 0.3584593519560274,
            "precision": 0.6983546617915904,
            "recall": 0.799163179916318
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.6298293315514439,
            "auditor_fn_violation": 0.009524117001355976,
            "auditor_fp_violation": 0.028522401806780485,
            "ave_precision_score": 0.6078433128448906,
            "fpr": 0.19538968166849616,
            "logloss": 2.814273140051486,
            "mae": 0.37873682638264283,
            "precision": 0.6798561151079137,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8317876011345104,
            "auditor_fn_violation": 0.00872834544520297,
            "auditor_fp_violation": 0.019168384671355815,
            "ave_precision_score": 0.8321964695764108,
            "fpr": 0.13267543859649122,
            "logloss": 0.7745309651213398,
            "mae": 0.2672207879911312,
            "precision": 0.7479166666666667,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.844075313660297,
            "auditor_fn_violation": 0.00931426357590237,
            "auditor_fp_violation": 0.023884325674703815,
            "ave_precision_score": 0.8442907502857518,
            "fpr": 0.14818880351262348,
            "logloss": 0.7839609966853139,
            "mae": 0.2688314382674233,
            "precision": 0.7383720930232558,
            "recall": 0.8004201680672269
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6714374266170422,
            "auditor_fn_violation": 0.006285326286427366,
            "auditor_fp_violation": 0.020378567386207462,
            "ave_precision_score": 0.6471705487888649,
            "fpr": 0.23903508771929824,
            "logloss": 2.5398797332844594,
            "mae": 0.33380036128826823,
            "precision": 0.655608214849921,
            "recall": 0.8682008368200836
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.6393612131115348,
            "auditor_fn_violation": 0.007845289597727127,
            "auditor_fp_violation": 0.02204726396406627,
            "ave_precision_score": 0.6160039266797739,
            "fpr": 0.2513721185510428,
            "logloss": 2.967597918831848,
            "mae": 0.34218519664309205,
            "precision": 0.6466049382716049,
            "recall": 0.8802521008403361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.833978488847997,
            "auditor_fn_violation": 0.0008235153784041695,
            "auditor_fp_violation": 0.017932937181663843,
            "ave_precision_score": 0.8333903909199607,
            "fpr": 0.4067982456140351,
            "logloss": 2.4947955383454845,
            "mae": 0.40245133498479335,
            "precision": 0.5614657210401891,
            "recall": 0.9937238493723849
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.8380403163925165,
            "auditor_fn_violation": 0.0018310287891226747,
            "auditor_fp_violation": 0.01606419622241569,
            "ave_precision_score": 0.8372331551288653,
            "fpr": 0.4149286498353458,
            "logloss": 2.688455041789438,
            "mae": 0.4163978614631502,
            "precision": 0.5547703180212014,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 30132,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.8397690170538471,
            "auditor_fn_violation": 0.005175071570138737,
            "auditor_fp_violation": 0.026507801762470702,
            "ave_precision_score": 0.8405599866723618,
            "fpr": 0.3026315789473684,
            "logloss": 1.4417940352116185,
            "mae": 0.33570474802297867,
            "precision": 0.6208791208791209,
            "recall": 0.9456066945606695
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.8492109798500214,
            "auditor_fn_violation": 0.007879880821702998,
            "auditor_fp_violation": 0.024542942579204363,
            "ave_precision_score": 0.8494181718082122,
            "fpr": 0.3227222832052689,
            "logloss": 1.5785883329459005,
            "mae": 0.3513302578579054,
            "precision": 0.6085219707057257,
            "recall": 0.9600840336134454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.8309385995720197,
            "auditor_fn_violation": 0.0006468839462673419,
            "auditor_fp_violation": 0.013476230899830225,
            "ave_precision_score": 0.8276417562182559,
            "fpr": 0.4375,
            "logloss": 3.4039662070838395,
            "mae": 0.43543286130992337,
            "precision": 0.5445205479452054,
            "recall": 0.997907949790795
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.8349319565288186,
            "auditor_fn_violation": 0.0009777785977179018,
            "auditor_fp_violation": 0.009046519550323628,
            "ave_precision_score": 0.8321731259839673,
            "fpr": 0.4489571899012075,
            "logloss": 3.6092301730303027,
            "mae": 0.44741366997817517,
            "precision": 0.5368063420158551,
            "recall": 0.9957983193277311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6740992475052846,
            "auditor_fn_violation": 0.0014451662629376791,
            "auditor_fp_violation": 0.00646525588163961,
            "ave_precision_score": 0.6506355025691593,
            "fpr": 0.4024122807017544,
            "logloss": 2.729851062580793,
            "mae": 0.3943231291006924,
            "precision": 0.564650059311981,
            "recall": 0.99581589958159
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6413668494877451,
            "auditor_fn_violation": 0.0016142571188738945,
            "auditor_fp_violation": 0.010250198720617743,
            "ave_precision_score": 0.6199461792514023,
            "fpr": 0.4105378704720088,
            "logloss": 3.000272213631695,
            "mae": 0.4047045693022294,
            "precision": 0.5563463819691578,
            "recall": 0.9852941176470589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8211914520505292,
            "auditor_fn_violation": 0.007872715260955745,
            "auditor_fp_violation": 0.009393443285633445,
            "ave_precision_score": 0.8216321846132856,
            "fpr": 0.1162280701754386,
            "logloss": 0.8355703130138296,
            "mae": 0.27407576168239517,
            "precision": 0.7685589519650655,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8298411465465666,
            "auditor_fn_violation": 0.014094770729367491,
            "auditor_fp_violation": 0.017088711407194312,
            "ave_precision_score": 0.8301158763125647,
            "fpr": 0.13611416026344675,
            "logloss": 0.8286691223559872,
            "mae": 0.27743638110643054,
            "precision": 0.743801652892562,
            "recall": 0.7563025210084033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8221636248841979,
            "auditor_fn_violation": 0.00884992292446598,
            "auditor_fp_violation": 0.016225038402457762,
            "ave_precision_score": 0.8224886866118152,
            "fpr": 0.14692982456140352,
            "logloss": 0.7827309203632167,
            "mae": 0.28032747581288636,
            "precision": 0.7341269841269841,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8283873254949272,
            "auditor_fn_violation": 0.010896235552398787,
            "auditor_fp_violation": 0.022536810628714186,
            "ave_precision_score": 0.8286905597815529,
            "fpr": 0.15806805708013172,
            "logloss": 0.7920749571945109,
            "mae": 0.2791951866301666,
            "precision": 0.7277882797731569,
            "recall": 0.8088235294117647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5241228070175439,
            "auc_prc": 0.8283580809888633,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8286009508438043,
            "fpr": 0.4758771929824561,
            "logloss": 3.5488714841376434,
            "mae": 0.4723461604954904,
            "precision": 0.5241228070175439,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.824716972359169,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8248951958420165,
            "fpr": 0.4774972557628979,
            "logloss": 3.5869140853726296,
            "mae": 0.4746805858664403,
            "precision": 0.5225027442371021,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 30132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7971461489605226,
            "auditor_fn_violation": 0.009042611759524337,
            "auditor_fp_violation": 0.011288301398657942,
            "ave_precision_score": 0.7716053410254446,
            "fpr": 0.12609649122807018,
            "logloss": 1.844264673508072,
            "mae": 0.2730204213815485,
            "precision": 0.7573839662447257,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7901448982816688,
            "auditor_fn_violation": 0.008092040328754999,
            "auditor_fp_violation": 0.01744956281464098,
            "ave_precision_score": 0.763881186269133,
            "fpr": 0.14489571899012074,
            "logloss": 2.044478347357851,
            "mae": 0.27796696122696063,
            "precision": 0.7406679764243614,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8222167218940587,
            "auditor_fn_violation": 0.011623265800484485,
            "auditor_fp_violation": 0.01069205271242623,
            "ave_precision_score": 0.8225997832548032,
            "fpr": 0.11951754385964912,
            "logloss": 0.8052872278094356,
            "mae": 0.2725130275936268,
            "precision": 0.7660944206008584,
            "recall": 0.7468619246861925
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8338574389865767,
            "auditor_fn_violation": 0.01373732808161684,
            "auditor_fp_violation": 0.020331327201382844,
            "ave_precision_score": 0.8341321686475098,
            "fpr": 0.1394072447859495,
            "logloss": 0.805329118287832,
            "mae": 0.27469487486983607,
            "precision": 0.7439516129032258,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7252985704465857,
            "auditor_fn_violation": 0.004734639947148205,
            "auditor_fp_violation": 0.009042262915352907,
            "ave_precision_score": 0.7250570854038171,
            "fpr": 0.16337719298245615,
            "logloss": 1.5363461905052207,
            "mae": 0.358501490586685,
            "precision": 0.6746724890829694,
            "recall": 0.6464435146443515
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7368544093740165,
            "auditor_fn_violation": 0.008680091136344768,
            "auditor_fp_violation": 0.01877436693288921,
            "ave_precision_score": 0.7370128145232323,
            "fpr": 0.17453347969264543,
            "logloss": 1.5273565868778864,
            "mae": 0.34309794578303054,
            "precision": 0.6735112936344969,
            "recall": 0.6890756302521008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.8243732517890312,
            "auditor_fn_violation": 0.003720729648388755,
            "auditor_fp_violation": 0.024284501576521966,
            "ave_precision_score": 0.8247683610046961,
            "fpr": 0.3442982456140351,
            "logloss": 1.664732684850827,
            "mae": 0.3721860760747324,
            "precision": 0.5916775032509753,
            "recall": 0.9518828451882845
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.8329070067277272,
            "auditor_fn_violation": 0.0016626848324401118,
            "auditor_fp_violation": 0.026458230818728945,
            "ave_precision_score": 0.8331799324700251,
            "fpr": 0.3512623490669594,
            "logloss": 1.689093074960106,
            "mae": 0.38551917236756317,
            "precision": 0.5860284605433377,
            "recall": 0.9516806722689075
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8118573511738301,
            "auditor_fn_violation": 0.008053934522498722,
            "auditor_fp_violation": 0.019120381599159197,
            "ave_precision_score": 0.8125824213671762,
            "fpr": 0.15570175438596492,
            "logloss": 1.1179781475865238,
            "mae": 0.26974211218023525,
            "precision": 0.7295238095238096,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8214633251595592,
            "auditor_fn_violation": 0.015326218302908437,
            "auditor_fp_violation": 0.022647841831005468,
            "ave_precision_score": 0.8217228610700387,
            "fpr": 0.1756311745334797,
            "logloss": 1.192326596356626,
            "mae": 0.27949840366334666,
            "precision": 0.7085610200364298,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 30132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8286609223810635,
            "auditor_fn_violation": 0.009001321294868974,
            "auditor_fp_violation": 0.013395383620341178,
            "ave_precision_score": 0.8292712526595676,
            "fpr": 0.13157894736842105,
            "logloss": 0.792719771113849,
            "mae": 0.2663604450118677,
            "precision": 0.7520661157024794,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8420335082766568,
            "auditor_fn_violation": 0.013725797673624881,
            "auditor_fp_violation": 0.020843584793772164,
            "ave_precision_score": 0.8422748552498814,
            "fpr": 0.150384193194292,
            "logloss": 0.7905085611290749,
            "mae": 0.27203414868566567,
            "precision": 0.7344961240310077,
            "recall": 0.7962184873949579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.6563132169015327,
            "auditor_fn_violation": 0.04579112530279675,
            "auditor_fp_violation": 0.05833889158379821,
            "ave_precision_score": 0.6556355767000375,
            "fpr": 0.13486842105263158,
            "logloss": 1.4973122249484656,
            "mae": 0.3618313417901047,
            "precision": 0.6947890818858561,
            "recall": 0.5857740585774058
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6442647396995418,
            "auditor_fn_violation": 0.05155706629523379,
            "auditor_fp_violation": 0.06375462104293628,
            "ave_precision_score": 0.6420729377015444,
            "fpr": 0.145993413830955,
            "logloss": 1.5563986880121752,
            "mae": 0.3526938319180431,
            "precision": 0.694954128440367,
            "recall": 0.6365546218487395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8158987017177944,
            "auditor_fn_violation": 0.006858804962196285,
            "auditor_fp_violation": 0.012399951491632312,
            "ave_precision_score": 0.8163852805032443,
            "fpr": 0.1206140350877193,
            "logloss": 0.8524690416342326,
            "mae": 0.27311783526531686,
            "precision": 0.7664543524416136,
            "recall": 0.7552301255230126
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8342993255066156,
            "auditor_fn_violation": 0.01165032423507274,
            "auditor_fp_violation": 0.015529227702284971,
            "ave_precision_score": 0.8345493265249112,
            "fpr": 0.14050493962678376,
            "logloss": 0.8271480956273949,
            "mae": 0.27767825974145943,
            "precision": 0.7414141414141414,
            "recall": 0.7710084033613446
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6787096582915113,
            "auditor_fn_violation": 0.008095224987154079,
            "auditor_fp_violation": 0.009497028862478787,
            "ave_precision_score": 0.654417620621224,
            "fpr": 0.25109649122807015,
            "logloss": 2.584225921995072,
            "mae": 0.32863626023346004,
            "precision": 0.6582089552238806,
            "recall": 0.9225941422594143
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.6457461530178672,
            "auditor_fn_violation": 0.008062061267975906,
            "auditor_fp_violation": 0.02117415496423029,
            "ave_precision_score": 0.6220267341638073,
            "fpr": 0.27552140504939626,
            "logloss": 2.983438557664797,
            "mae": 0.3410916138332006,
            "precision": 0.6367583212735166,
            "recall": 0.9243697478991597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.5399566649930245,
            "auditor_fn_violation": 0.012616530866916244,
            "auditor_fp_violation": 0.010020009701673547,
            "ave_precision_score": 0.5399725432397269,
            "fpr": 0.21710526315789475,
            "logloss": 2.8613043688547184,
            "mae": 0.4238792287557643,
            "precision": 0.61328125,
            "recall": 0.6569037656903766
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.5522389312531537,
            "auditor_fn_violation": 0.017784501286793535,
            "auditor_fp_violation": 0.001450975939033783,
            "ave_precision_score": 0.5504303168012902,
            "fpr": 0.2052689352360044,
            "logloss": 2.90603435063419,
            "mae": 0.4266636762543364,
            "precision": 0.6191446028513238,
            "recall": 0.6386554621848739
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.6750365467373866,
            "auditor_fn_violation": 0.004000587242163989,
            "auditor_fp_violation": 0.020075390088123535,
            "ave_precision_score": 0.6496677264914358,
            "fpr": 0.24780701754385964,
            "logloss": 2.7381977789802763,
            "mae": 0.320050424330826,
            "precision": 0.6580937972768532,
            "recall": 0.9100418410041841
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.6483603325589118,
            "auditor_fn_violation": 0.010010700218616537,
            "auditor_fp_violation": 0.019483452565703975,
            "ave_precision_score": 0.6233528538866718,
            "fpr": 0.28210757409440174,
            "logloss": 3.148732094207449,
            "mae": 0.33425527686264944,
            "precision": 0.6275362318840579,
            "recall": 0.9096638655462185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.6757172265756926,
            "auditor_fn_violation": 0.0004450194523966887,
            "auditor_fp_violation": 0.019878324844368998,
            "ave_precision_score": 0.6561661650278735,
            "fpr": 0.19956140350877194,
            "logloss": 2.299073626490902,
            "mae": 0.31829155155910965,
            "precision": 0.6840277777777778,
            "recall": 0.8242677824267782
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6423061933504461,
            "auditor_fn_violation": 0.014173177503712792,
            "auditor_fp_violation": 0.02685693377241127,
            "ave_precision_score": 0.6245583257470537,
            "fpr": 0.22283205268935236,
            "logloss": 2.546955452705362,
            "mae": 0.3318245430458051,
            "precision": 0.6666666666666666,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8016956729271594,
            "auditor_fn_violation": 0.007092784261910007,
            "auditor_fp_violation": 0.01830180289433261,
            "ave_precision_score": 0.7736742887796026,
            "fpr": 0.14692982456140352,
            "logloss": 1.9248238860069702,
            "mae": 0.27951304665577736,
            "precision": 0.7408123791102514,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7898840746948386,
            "auditor_fn_violation": 0.0040171941443976076,
            "auditor_fp_violation": 0.0020692178608829556,
            "ave_precision_score": 0.7613231870461132,
            "fpr": 0.1668496158068057,
            "logloss": 2.2366792885537032,
            "mae": 0.2920177551198538,
            "precision": 0.7195571955719557,
            "recall": 0.819327731092437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.677375785833649,
            "auditor_fn_violation": 0.008882037730309036,
            "auditor_fp_violation": 0.018857627940819802,
            "ave_precision_score": 0.6533775674293871,
            "fpr": 0.21052631578947367,
            "logloss": 2.4692352565471727,
            "mae": 0.3146765369775382,
            "precision": 0.6826446280991736,
            "recall": 0.8640167364016736
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.6428300892485717,
            "auditor_fn_violation": 0.01000147589222297,
            "auditor_fp_violation": 0.021746975030596673,
            "ave_precision_score": 0.619468039370755,
            "fpr": 0.2261251372118551,
            "logloss": 2.871896938471475,
            "mae": 0.32814825599467223,
            "precision": 0.6693418940609952,
            "recall": 0.8760504201680672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8188164564541313,
            "auditor_fn_violation": 0.010366200543199004,
            "auditor_fp_violation": 0.012763764249333016,
            "ave_precision_score": 0.8192544659672727,
            "fpr": 0.12171052631578948,
            "logloss": 0.8147032096472581,
            "mae": 0.27475466012891947,
            "precision": 0.7638297872340426,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8268283941794508,
            "auditor_fn_violation": 0.012307557490614254,
            "auditor_fp_violation": 0.027957152049661236,
            "ave_precision_score": 0.8271827036391306,
            "fpr": 0.14928649835345773,
            "logloss": 0.827430166804381,
            "mae": 0.27995649302079695,
            "precision": 0.7306930693069307,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8142866088923335,
            "auditor_fn_violation": 0.006927622403288558,
            "auditor_fp_violation": 0.023354757862397945,
            "ave_precision_score": 0.8145408433619377,
            "fpr": 0.22697368421052633,
            "logloss": 1.2274395406867449,
            "mae": 0.28507719524941744,
            "precision": 0.6750392464678179,
            "recall": 0.899581589958159
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8275219276978178,
            "auditor_fn_violation": 0.012093091901963861,
            "auditor_fp_violation": 0.029069987508989745,
            "ave_precision_score": 0.8277457147754144,
            "fpr": 0.24698133918770582,
            "logloss": 1.3269387370706411,
            "mae": 0.301361229833703,
            "precision": 0.6575342465753424,
            "recall": 0.907563025210084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.818249663545391,
            "auditor_fn_violation": 0.007673144681788157,
            "auditor_fp_violation": 0.011303460263562133,
            "ave_precision_score": 0.8188119799549698,
            "fpr": 0.1206140350877193,
            "logloss": 0.8515147062413956,
            "mae": 0.27219925730153965,
            "precision": 0.7654584221748401,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8335141672210254,
            "auditor_fn_violation": 0.007856820005719087,
            "auditor_fp_violation": 0.018713804458912152,
            "ave_precision_score": 0.8338041307689295,
            "fpr": 0.1437980241492865,
            "logloss": 0.8423022562604977,
            "mae": 0.2767731399871391,
            "precision": 0.738,
            "recall": 0.7752100840336135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8254872044490067,
            "auditor_fn_violation": 0.006634001321294872,
            "auditor_fp_violation": 0.02174791818255316,
            "ave_precision_score": 0.825937304487586,
            "fpr": 0.2050438596491228,
            "logloss": 0.9494489040680343,
            "mae": 0.27708901468840724,
            "precision": 0.6924342105263158,
            "recall": 0.8807531380753139
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.8379055167013466,
            "auditor_fn_violation": 0.011530407991956388,
            "auditor_fp_violation": 0.028767175139104446,
            "ave_precision_score": 0.8381509977705796,
            "fpr": 0.2305159165751921,
            "logloss": 1.0122642926655585,
            "mae": 0.29414686216753966,
            "precision": 0.6671949286846276,
            "recall": 0.884453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.811493791229469,
            "auditor_fn_violation": 0.004528187623871394,
            "auditor_fp_violation": 0.029850331473845915,
            "ave_precision_score": 0.8115821399844882,
            "fpr": 0.2598684210526316,
            "logloss": 1.4748628154738939,
            "mae": 0.2992024029907649,
            "precision": 0.6509572901325479,
            "recall": 0.9246861924686193
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8268476130614596,
            "auditor_fn_violation": 0.007840677434530343,
            "auditor_fp_violation": 0.03007683863885841,
            "ave_precision_score": 0.82702457798143,
            "fpr": 0.27661909989023054,
            "logloss": 1.6002050872357862,
            "mae": 0.3164506464746261,
            "precision": 0.6368876080691642,
            "recall": 0.9285714285714286
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.8214196465849095,
            "auditor_fn_violation": 0.00035326286427365483,
            "auditor_fp_violation": 0.018443285633438437,
            "ave_precision_score": 0.8206915535027679,
            "fpr": 0.4057017543859649,
            "logloss": 2.5991699698426896,
            "mae": 0.40319573443731205,
            "precision": 0.5626477541371159,
            "recall": 0.99581589958159
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.8281645118092675,
            "auditor_fn_violation": 0.002402937025523711,
            "auditor_fp_violation": 0.015102766948029846,
            "ave_precision_score": 0.827373566342111,
            "fpr": 0.41712403951701427,
            "logloss": 2.797988621051943,
            "mae": 0.4169608735815842,
            "precision": 0.5529411764705883,
            "recall": 0.9873949579831933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8383665993347225,
            "auditor_fn_violation": 0.00665694046832563,
            "auditor_fp_violation": 0.009913897647344171,
            "ave_precision_score": 0.8374491194999336,
            "fpr": 0.11403508771929824,
            "logloss": 1.2572485281163865,
            "mae": 0.24476897044963278,
            "precision": 0.7773019271948608,
            "recall": 0.7594142259414226
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8505941848150719,
            "auditor_fn_violation": 0.008680091136344768,
            "auditor_fp_violation": 0.015655399523070525,
            "ave_precision_score": 0.8499367048716859,
            "fpr": 0.132821075740944,
            "logloss": 1.226232371055645,
            "mae": 0.2491760842715684,
            "precision": 0.7570281124497992,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8122033548179386,
            "auditor_fn_violation": 0.008053934522498722,
            "auditor_fp_violation": 0.019188596491228078,
            "ave_precision_score": 0.8128977877384231,
            "fpr": 0.15460526315789475,
            "logloss": 1.106598352782164,
            "mae": 0.2695786051860202,
            "precision": 0.7309160305343512,
            "recall": 0.801255230125523
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8217474996436527,
            "auditor_fn_violation": 0.015326218302908437,
            "auditor_fp_violation": 0.022647841831005468,
            "ave_precision_score": 0.82200691903233,
            "fpr": 0.1756311745334797,
            "logloss": 1.1785079558964742,
            "mae": 0.2792599131635104,
            "precision": 0.7085610200364298,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.8237450618896963,
            "auditor_fn_violation": 0.00035326286427365483,
            "auditor_fp_violation": 0.018827310211011403,
            "ave_precision_score": 0.8230412491677794,
            "fpr": 0.40899122807017546,
            "logloss": 2.609442951079411,
            "mae": 0.4068311617674976,
            "precision": 0.5606595995288575,
            "recall": 0.99581589958159
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.8330345258540915,
            "auditor_fn_violation": 0.0018310287891226747,
            "auditor_fp_violation": 0.013263181800976576,
            "ave_precision_score": 0.8325053321775179,
            "fpr": 0.42151481888035125,
            "logloss": 2.783103668387864,
            "mae": 0.4206889452289952,
            "precision": 0.5508771929824562,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 30132,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8250678833822218,
            "auditor_fn_violation": 0.006996439844380829,
            "auditor_fp_violation": 0.02169233567790444,
            "ave_precision_score": 0.8255676756059442,
            "fpr": 0.19078947368421054,
            "logloss": 0.9176889874163962,
            "mae": 0.27285937072367317,
            "precision": 0.706081081081081,
            "recall": 0.8744769874476988
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8364235624955958,
            "auditor_fn_violation": 0.013640472654484408,
            "auditor_fp_violation": 0.028365948749006404,
            "ave_precision_score": 0.8367183302306498,
            "fpr": 0.21514818880351264,
            "logloss": 0.9799635693177009,
            "mae": 0.28881552064070687,
            "precision": 0.6781609195402298,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6731320782598602,
            "auditor_fn_violation": 0.0005551273581443142,
            "auditor_fp_violation": 0.019949066213921906,
            "ave_precision_score": 0.6527787275957807,
            "fpr": 0.18859649122807018,
            "logloss": 2.3479253373222955,
            "mae": 0.3174768151248715,
            "precision": 0.6928571428571428,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6409751793364428,
            "auditor_fn_violation": 0.013047809683697852,
            "auditor_fp_violation": 0.02374806010825543,
            "ave_precision_score": 0.6223982997192606,
            "fpr": 0.21844127332601537,
            "logloss": 2.5878641979967676,
            "mae": 0.3311507734329502,
            "precision": 0.6694352159468439,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8293543607666898,
            "auditor_fn_violation": 0.006333498495191956,
            "auditor_fp_violation": 0.02990591397849464,
            "ave_precision_score": 0.829887370660793,
            "fpr": 0.26864035087719296,
            "logloss": 1.2108620464083335,
            "mae": 0.3079072438215068,
            "precision": 0.6469740634005764,
            "recall": 0.9393305439330544
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.8361645883686271,
            "auditor_fn_violation": 0.009865417077917887,
            "auditor_fp_violation": 0.022382881007355825,
            "ave_precision_score": 0.8363799206211352,
            "fpr": 0.29088913282107576,
            "logloss": 1.3235187491856555,
            "mae": 0.3251779102012009,
            "precision": 0.6278089887640449,
            "recall": 0.9390756302521008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8285943554362576,
            "auditor_fn_violation": 0.007331351391029878,
            "auditor_fp_violation": 0.016275567952138418,
            "ave_precision_score": 0.8289528180513579,
            "fpr": 0.12938596491228072,
            "logloss": 0.8030463404282224,
            "mae": 0.268895729907626,
            "precision": 0.7551867219917012,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8388884497261531,
            "auditor_fn_violation": 0.013746552408010404,
            "auditor_fp_violation": 0.024838184639842546,
            "ave_precision_score": 0.8391200205445524,
            "fpr": 0.14709110867178923,
            "logloss": 0.8090416850568285,
            "mae": 0.2713837573743625,
            "precision": 0.7387914230019493,
            "recall": 0.7962184873949579
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8006998522974252,
            "auditor_fn_violation": 0.00548704396975703,
            "auditor_fp_violation": 0.025605849300671037,
            "ave_precision_score": 0.7973744809327568,
            "fpr": 0.24671052631578946,
            "logloss": 1.4638772930474198,
            "mae": 0.29846587339760355,
            "precision": 0.6606334841628959,
            "recall": 0.9163179916317992
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.8183888806597789,
            "auditor_fn_violation": 0.010750952411700137,
            "auditor_fp_violation": 0.027540785041068938,
            "ave_precision_score": 0.8175718052789711,
            "fpr": 0.2711306256860593,
            "logloss": 1.472971180860197,
            "mae": 0.31576202515132545,
            "precision": 0.6372980910425844,
            "recall": 0.9117647058823529
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7405464687549556,
            "auditor_fn_violation": 0.02290932613961683,
            "auditor_fp_violation": 0.034804753820033965,
            "ave_precision_score": 0.7064709122955005,
            "fpr": 0.22587719298245615,
            "logloss": 3.117771979414135,
            "mae": 0.3080775850043582,
            "precision": 0.6650406504065041,
            "recall": 0.8556485355648535
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7347639654630286,
            "auditor_fn_violation": 0.021179053399625492,
            "auditor_fp_violation": 0.04504334002043984,
            "ave_precision_score": 0.6967378650945903,
            "fpr": 0.22722283205268934,
            "logloss": 3.2888523253995467,
            "mae": 0.30000243222697753,
            "precision": 0.6661290322580645,
            "recall": 0.8676470588235294
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8193187367499523,
            "auditor_fn_violation": 0.0028352785730015417,
            "auditor_fp_violation": 0.024362822378526966,
            "ave_precision_score": 0.8198232538077561,
            "fpr": 0.18092105263157895,
            "logloss": 0.8793278197182564,
            "mae": 0.2746344915942208,
            "precision": 0.7064056939501779,
            "recall": 0.8305439330543933
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.836106856111769,
            "auditor_fn_violation": 0.011438164728020738,
            "auditor_fp_violation": 0.026458230818728955,
            "ave_precision_score": 0.836345631508543,
            "fpr": 0.19758507135016465,
            "logloss": 0.9072905706810622,
            "mae": 0.2851812686673552,
            "precision": 0.6912521440823327,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6735647636330777,
            "auditor_fn_violation": 0.0005551273581443142,
            "auditor_fp_violation": 0.019757053925135423,
            "ave_precision_score": 0.6528806683440793,
            "fpr": 0.18969298245614036,
            "logloss": 2.3515736036848005,
            "mae": 0.3174829050850556,
            "precision": 0.6916221033868093,
            "recall": 0.8117154811715481
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6407379522953427,
            "auditor_fn_violation": 0.013047809683697852,
            "auditor_fp_violation": 0.02374806010825543,
            "ave_precision_score": 0.6221822342326395,
            "fpr": 0.21844127332601537,
            "logloss": 2.59276053067372,
            "mae": 0.331180827887923,
            "precision": 0.6694352159468439,
            "recall": 0.8466386554621849
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.6746345567393097,
            "auditor_fn_violation": 0.0014084636276884691,
            "auditor_fp_violation": 0.02143463497453312,
            "ave_precision_score": 0.6539807125060195,
            "fpr": 0.19956140350877194,
            "logloss": 2.358963486832689,
            "mae": 0.31707587656707975,
            "precision": 0.6851211072664359,
            "recall": 0.8284518828451883
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6415880979476616,
            "auditor_fn_violation": 0.011447389054414305,
            "auditor_fp_violation": 0.02337459151873021,
            "ave_precision_score": 0.6230060392964522,
            "fpr": 0.23161361141602635,
            "logloss": 2.6019396485499313,
            "mae": 0.33089674521226364,
            "precision": 0.6591276252019386,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6819927808530148,
            "auditor_fn_violation": 0.0065261873302503125,
            "auditor_fp_violation": 0.017084040747028878,
            "ave_precision_score": 0.660709752146941,
            "fpr": 0.23903508771929824,
            "logloss": 2.5854514058408955,
            "mae": 0.3122156473421838,
            "precision": 0.6599063962558502,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6545671670180183,
            "auditor_fn_violation": 0.009823907609146846,
            "auditor_fp_violation": 0.024262841137060443,
            "ave_precision_score": 0.6358842802763585,
            "fpr": 0.2689352360043908,
            "logloss": 2.8744451932741097,
            "mae": 0.32629027030001834,
            "precision": 0.6337817638266069,
            "recall": 0.8907563025210085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8124439209298786,
            "auditor_fn_violation": 0.0102813256991852,
            "auditor_fp_violation": 0.02140937019969279,
            "ave_precision_score": 0.8127473647546382,
            "fpr": 0.15570175438596492,
            "logloss": 0.8723905696605745,
            "mae": 0.2832684044174788,
            "precision": 0.7258687258687259,
            "recall": 0.7866108786610879
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8225442196461848,
            "auditor_fn_violation": 0.007185750260587226,
            "auditor_fp_violation": 0.02388684911111953,
            "ave_precision_score": 0.8227909537992449,
            "fpr": 0.1800219538968167,
            "logloss": 0.8836432283433793,
            "mae": 0.2913258332738178,
            "precision": 0.7028985507246377,
            "recall": 0.8151260504201681
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7300140947454583,
            "auditor_fn_violation": 0.0031701901196505918,
            "auditor_fp_violation": 0.03260671840892556,
            "ave_precision_score": 0.7266601548331459,
            "fpr": 0.36293859649122806,
            "logloss": 2.3954169653487276,
            "mae": 0.3842702137017592,
            "precision": 0.5810126582278481,
            "recall": 0.9602510460251046
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.740620665776396,
            "auditor_fn_violation": 0.0040679279395622134,
            "auditor_fp_violation": 0.022057357709729115,
            "ave_precision_score": 0.7397369188282422,
            "fpr": 0.38748627881448955,
            "logloss": 2.5783239697007474,
            "mae": 0.40241058550096465,
            "precision": 0.5679314565483476,
            "recall": 0.9747899159663865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8640319632629074,
            "auditor_fn_violation": 0.010086342949423774,
            "auditor_fp_violation": 0.009019524617996603,
            "ave_precision_score": 0.8640258652836121,
            "fpr": 0.11732456140350878,
            "logloss": 0.84046958815328,
            "mae": 0.23465143586160714,
            "precision": 0.779835390946502,
            "recall": 0.7928870292887029
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8709368284721873,
            "auditor_fn_violation": 0.00658616904500549,
            "auditor_fp_violation": 0.006248028565300229,
            "ave_precision_score": 0.8711023009907108,
            "fpr": 0.12294182217343579,
            "logloss": 0.8124330323156023,
            "mae": 0.23968324220167325,
            "precision": 0.7714285714285715,
            "recall": 0.7941176470588235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.8408209265669453,
            "auditor_fn_violation": 0.003190835351978272,
            "auditor_fp_violation": 0.026406742663109398,
            "ave_precision_score": 0.8405170448418242,
            "fpr": 0.36622807017543857,
            "logloss": 2.0326958924501053,
            "mae": 0.37558581234707,
            "precision": 0.5850931677018634,
            "recall": 0.9853556485355649
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.8479179577045515,
            "auditor_fn_violation": 0.003514468355948307,
            "auditor_fp_violation": 0.017108898898520002,
            "ave_precision_score": 0.8480585916625121,
            "fpr": 0.3885839736553238,
            "logloss": 2.1897273379655116,
            "mae": 0.39219589777924074,
            "precision": 0.5693430656934306,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8170195611752136,
            "auditor_fn_violation": 0.008950855171401305,
            "auditor_fp_violation": 0.022515967337699092,
            "ave_precision_score": 0.8175688583990804,
            "fpr": 0.17763157894736842,
            "logloss": 0.9260794896149093,
            "mae": 0.2770040609983379,
            "precision": 0.7049180327868853,
            "recall": 0.8096234309623431
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8293814163582023,
            "auditor_fn_violation": 0.01145661338080787,
            "auditor_fp_violation": 0.027714902153752982,
            "ave_precision_score": 0.8296639587788424,
            "fpr": 0.19319429198682767,
            "logloss": 0.9673327314328191,
            "mae": 0.28541526870086253,
            "precision": 0.6944444444444444,
            "recall": 0.8403361344537815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.669016934428342,
            "auditor_fn_violation": 0.006631707406591795,
            "auditor_fp_violation": 0.020957130730050937,
            "ave_precision_score": 0.6540221429273703,
            "fpr": 0.20065789473684212,
            "logloss": 2.0384265611518364,
            "mae": 0.33645026181546744,
            "precision": 0.698019801980198,
            "recall": 0.8849372384937239
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6408603523763636,
            "auditor_fn_violation": 0.007810698373751259,
            "auditor_fp_violation": 0.02872932359286878,
            "ave_precision_score": 0.6245463744895396,
            "fpr": 0.22502744237102085,
            "logloss": 2.3581562914690277,
            "mae": 0.3525654084389594,
            "precision": 0.6693548387096774,
            "recall": 0.8718487394957983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.8401738743771621,
            "auditor_fn_violation": 0.0026196505909124278,
            "auditor_fp_violation": 0.02419860134206486,
            "ave_precision_score": 0.8401622716225624,
            "fpr": 0.37280701754385964,
            "logloss": 2.087289039205331,
            "mae": 0.3797322293070657,
            "precision": 0.5812807881773399,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.8476870006898893,
            "auditor_fn_violation": 0.003514468355948307,
            "auditor_fp_violation": 0.015784094780271783,
            "ave_precision_score": 0.8477702823503155,
            "fpr": 0.3918770581778266,
            "logloss": 2.2433279060903057,
            "mae": 0.39659539270396194,
            "precision": 0.5672727272727273,
            "recall": 0.9831932773109243
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8278832912308285,
            "auditor_fn_violation": 0.005239301181824862,
            "auditor_fp_violation": 0.015803116662624305,
            "ave_precision_score": 0.8282166116269641,
            "fpr": 0.12828947368421054,
            "logloss": 0.7937279787706061,
            "mae": 0.2686353685501403,
            "precision": 0.7567567567567568,
            "recall": 0.7615062761506276
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8377565223686136,
            "auditor_fn_violation": 0.01246437103930486,
            "auditor_fp_violation": 0.023503286775931467,
            "ave_precision_score": 0.8379942352439093,
            "fpr": 0.14928649835345773,
            "logloss": 0.8030514164852418,
            "mae": 0.27195273856108027,
            "precision": 0.7348927875243665,
            "recall": 0.792016806722689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 30132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8238028481373779,
            "auditor_fn_violation": 0.006620237833076416,
            "auditor_fp_violation": 0.023981324278438035,
            "ave_precision_score": 0.8241911390645762,
            "fpr": 0.2149122807017544,
            "logloss": 0.985640960016252,
            "mae": 0.28344743100018127,
            "precision": 0.6864,
            "recall": 0.897489539748954
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.8335922052353097,
            "auditor_fn_violation": 0.011862483742124733,
            "auditor_fp_violation": 0.02440920044917169,
            "ave_precision_score": 0.8338579097722336,
            "fpr": 0.24478594950603733,
            "logloss": 1.0613210688830075,
            "mae": 0.2999529337058457,
            "precision": 0.6574500768049155,
            "recall": 0.8991596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8338181199551571,
            "auditor_fn_violation": 0.008363613007413935,
            "auditor_fp_violation": 0.010805744199207703,
            "ave_precision_score": 0.8341207139183545,
            "fpr": 0.12390350877192982,
            "logloss": 0.7481926323745144,
            "mae": 0.2685205263076814,
            "precision": 0.7610993657505285,
            "recall": 0.7531380753138075
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8430279850950874,
            "auditor_fn_violation": 0.01309393131566568,
            "auditor_fp_violation": 0.022698310559319687,
            "ave_precision_score": 0.8432530098028413,
            "fpr": 0.14050493962678376,
            "logloss": 0.7507248320909176,
            "mae": 0.27033038242776136,
            "precision": 0.7450199203187251,
            "recall": 0.7857142857142857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 30132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7834267764479761,
            "auditor_fn_violation": 0.007668556852382002,
            "auditor_fp_violation": 0.018392756083757785,
            "ave_precision_score": 0.7826758552561659,
            "fpr": 0.13815789473684212,
            "logloss": 1.1380541794177008,
            "mae": 0.284963238644731,
            "precision": 0.7402061855670103,
            "recall": 0.7510460251046025
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8017078387028522,
            "auditor_fn_violation": 0.013253050945954675,
            "auditor_fp_violation": 0.021587998536406885,
            "ave_precision_score": 0.801057211785318,
            "fpr": 0.15916575192096596,
            "logloss": 1.1155362055331322,
            "mae": 0.28512998978170645,
            "precision": 0.7200772200772201,
            "recall": 0.7836134453781513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.5703557732514384,
            "auditor_fn_violation": 0.006959737209131616,
            "auditor_fp_violation": 0.008385378769504412,
            "ave_precision_score": 0.5706273420972685,
            "fpr": 0.43530701754385964,
            "logloss": 2.3910767227367664,
            "mae": 0.45540194584931704,
            "precision": 0.5323910482921084,
            "recall": 0.9456066945606695
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.5694887527501254,
            "auditor_fn_violation": 0.003449898071193351,
            "auditor_fp_violation": 0.007658629521682636,
            "ave_precision_score": 0.5698682497077604,
            "fpr": 0.43907793633369924,
            "logloss": 2.378840416052009,
            "mae": 0.4696192080609862,
            "precision": 0.5271867612293144,
            "recall": 0.9369747899159664
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7802516917618069,
            "auditor_fn_violation": 0.01018039345224988,
            "auditor_fp_violation": 0.017407429864985047,
            "ave_precision_score": 0.7600258737934513,
            "fpr": 0.1337719298245614,
            "logloss": 1.7340800823136808,
            "mae": 0.28937456180918575,
            "precision": 0.7370689655172413,
            "recall": 0.7154811715481172
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7868975268463173,
            "auditor_fn_violation": 0.01201468512761856,
            "auditor_fp_violation": 0.019405226036816943,
            "ave_precision_score": 0.7725879939918489,
            "fpr": 0.15367727771679474,
            "logloss": 1.627314669649498,
            "mae": 0.29120877137442724,
            "precision": 0.7216699801192843,
            "recall": 0.7626050420168067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8105553900491874,
            "auditor_fn_violation": 0.005675144975409236,
            "auditor_fp_violation": 0.022965680329856904,
            "ave_precision_score": 0.8113820330099848,
            "fpr": 0.15570175438596492,
            "logloss": 0.8529407455886919,
            "mae": 0.2846497566948881,
            "precision": 0.7248062015503876,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8195448795341111,
            "auditor_fn_violation": 0.008963739172946895,
            "auditor_fp_violation": 0.025095575154245053,
            "ave_precision_score": 0.8198041912115022,
            "fpr": 0.1756311745334797,
            "logloss": 0.8873673564983598,
            "mae": 0.2913161093306809,
            "precision": 0.7085610200364298,
            "recall": 0.8172268907563025
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6725373223347636,
            "auditor_fn_violation": 0.03047236291565735,
            "auditor_fp_violation": 0.01470915191203816,
            "ave_precision_score": 0.6702246378294034,
            "fpr": 0.14692982456140352,
            "logloss": 2.6191012270730893,
            "mae": 0.3476671001330947,
            "precision": 0.7035398230088495,
            "recall": 0.6652719665271967
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6528551886476783,
            "auditor_fn_violation": 0.02205997657021096,
            "auditor_fp_violation": 0.013921798705477122,
            "ave_precision_score": 0.651081952731015,
            "fpr": 0.16355653128430298,
            "logloss": 2.4923459478944148,
            "mae": 0.3438654660872347,
            "precision": 0.6995967741935484,
            "recall": 0.7289915966386554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7123036593264565,
            "auditor_fn_violation": 0.02904554797034427,
            "auditor_fp_violation": 0.017187626323874203,
            "ave_precision_score": 0.7040766055635831,
            "fpr": 0.16557017543859648,
            "logloss": 2.7907087710994842,
            "mae": 0.3134931958848907,
            "precision": 0.7118320610687023,
            "recall": 0.7803347280334728
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6713136058547594,
            "auditor_fn_violation": 0.01349518951378576,
            "auditor_fp_violation": 0.0223071779148845,
            "ave_precision_score": 0.6599142568514075,
            "fpr": 0.19978046103183314,
            "logloss": 3.119201794894674,
            "mae": 0.3213907388531676,
            "precision": 0.6829268292682927,
            "recall": 0.8235294117647058
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.8477924314379411,
            "auditor_fn_violation": 0.0005734786757689204,
            "auditor_fp_violation": 0.013718772738297373,
            "ave_precision_score": 0.8480409733396904,
            "fpr": 0.3815789473684211,
            "logloss": 0.8725883440634109,
            "mae": 0.37311280578713896,
            "precision": 0.5756097560975609,
            "recall": 0.9874476987447699
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.8375121820144906,
            "auditor_fn_violation": 0.0022299809056443663,
            "auditor_fp_violation": 0.005185661834285929,
            "ave_precision_score": 0.8379326924769382,
            "fpr": 0.3973655323819978,
            "logloss": 0.8830660231371701,
            "mae": 0.3820643987303189,
            "precision": 0.562273276904474,
            "recall": 0.976890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.6946174171949842,
            "auditor_fn_violation": 0.00556044924025545,
            "auditor_fp_violation": 0.034776962567709596,
            "ave_precision_score": 0.6838618642449923,
            "fpr": 0.16776315789473684,
            "logloss": 1.9179238121549818,
            "mae": 0.30848940758989485,
            "precision": 0.6976284584980237,
            "recall": 0.7384937238493724
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.6858101676543547,
            "auditor_fn_violation": 0.020261232923465763,
            "auditor_fp_violation": 0.0370818981288719,
            "ave_precision_score": 0.6737776553494816,
            "fpr": 0.18660812294182216,
            "logloss": 2.1587577187525984,
            "mae": 0.3076447928645363,
            "precision": 0.6920289855072463,
            "recall": 0.8025210084033614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 30132,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.8242688160155969,
            "auditor_fn_violation": 0.00035326286427365483,
            "auditor_fp_violation": 0.017349320882852313,
            "ave_precision_score": 0.8237853127719559,
            "fpr": 0.4155701754385965,
            "logloss": 2.614510067388896,
            "mae": 0.4106479917646906,
            "precision": 0.5567251461988304,
            "recall": 0.99581589958159
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.8307152138548197,
            "auditor_fn_violation": 0.0018310287891226747,
            "auditor_fp_violation": 0.011279760778227793,
            "ave_precision_score": 0.8301793014188857,
            "fpr": 0.42371020856201974,
            "logloss": 2.8039063623752147,
            "mae": 0.4240676541353238,
            "precision": 0.5495915985997666,
            "recall": 0.9894957983193278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8264120797612969,
            "auditor_fn_violation": 0.007854363943331133,
            "auditor_fp_violation": 0.01209677419354839,
            "ave_precision_score": 0.8267527659578195,
            "fpr": 0.12719298245614036,
            "logloss": 0.7840269019795398,
            "mae": 0.27319235886921633,
            "precision": 0.7613168724279835,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8389700251404644,
            "auditor_fn_violation": 0.006540047413037665,
            "auditor_fp_violation": 0.02234502946112016,
            "ave_precision_score": 0.8392199934259787,
            "fpr": 0.14270032930845225,
            "logloss": 0.7977914713663222,
            "mae": 0.27177781755158065,
            "precision": 0.7425742574257426,
            "recall": 0.7878151260504201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8274640769698087,
            "auditor_fn_violation": 0.009345408500330325,
            "auditor_fp_violation": 0.025732173174872683,
            "ave_precision_score": 0.8278755738139156,
            "fpr": 0.19188596491228072,
            "logloss": 0.8582144706285871,
            "mae": 0.2739943159425628,
            "precision": 0.7018739352640545,
            "recall": 0.8619246861924686
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8365388387379471,
            "auditor_fn_violation": 0.008290363346216648,
            "auditor_fp_violation": 0.025297450067501923,
            "ave_precision_score": 0.8368033940127455,
            "fpr": 0.20636663007683864,
            "logloss": 0.9071115270113764,
            "mae": 0.28465096267217715,
            "precision": 0.6861435726210351,
            "recall": 0.8634453781512605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 30132,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8239933531388095,
            "auditor_fn_violation": 0.004466251926888353,
            "auditor_fp_violation": 0.02439061363085133,
            "ave_precision_score": 0.8242665530288533,
            "fpr": 0.21710526315789475,
            "logloss": 1.031665726437142,
            "mae": 0.28633782841911437,
            "precision": 0.685214626391097,
            "recall": 0.9016736401673641
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8331007047788517,
            "auditor_fn_violation": 0.009464158879797804,
            "auditor_fp_violation": 0.025554840581904447,
            "ave_precision_score": 0.8333983104091638,
            "fpr": 0.24588364434687157,
            "logloss": 1.1142850152875334,
            "mae": 0.3029448809018586,
            "precision": 0.656441717791411,
            "recall": 0.8991596638655462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.794362189560501,
            "auditor_fn_violation": 0.012914739778316088,
            "auditor_fp_violation": 0.014820316921335603,
            "ave_precision_score": 0.7630156549623095,
            "fpr": 0.13815789473684212,
            "logloss": 3.729899057532561,
            "mae": 0.2834744585557606,
            "precision": 0.7375,
            "recall": 0.7405857740585774
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7810228309446863,
            "auditor_fn_violation": 0.015183241243808177,
            "auditor_fp_violation": 0.028668761118891706,
            "ave_precision_score": 0.7396288796866107,
            "fpr": 0.15477497255762898,
            "logloss": 4.116844534745658,
            "mae": 0.2854862120914583,
            "precision": 0.7213438735177866,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8187118145766963,
            "auditor_fn_violation": 0.0034408720546135244,
            "auditor_fp_violation": 0.013476230899830232,
            "ave_precision_score": 0.8190851087934597,
            "fpr": 0.15570175438596492,
            "logloss": 0.8424396596548812,
            "mae": 0.27745841961931034,
            "precision": 0.7248062015503876,
            "recall": 0.7824267782426778
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8310436804912824,
            "auditor_fn_violation": 0.008813843869051464,
            "auditor_fp_violation": 0.0252217469750306,
            "ave_precision_score": 0.831309686888055,
            "fpr": 0.17014270032930845,
            "logloss": 0.8527781810129917,
            "mae": 0.27953114725713524,
            "precision": 0.7176684881602914,
            "recall": 0.8277310924369747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8820900235971324,
            "auditor_fn_violation": 0.008813220289216767,
            "auditor_fp_violation": 0.004537553561322664,
            "ave_precision_score": 0.8822573457337288,
            "fpr": 0.09320175438596491,
            "logloss": 0.4529229028942439,
            "mae": 0.2993919960214969,
            "precision": 0.8131868131868132,
            "recall": 0.7740585774058577
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8660314007489485,
            "auditor_fn_violation": 0.011525795828759608,
            "auditor_fp_violation": 0.01430788447708089,
            "ave_precision_score": 0.866358523143095,
            "fpr": 0.08232711306256861,
            "logloss": 0.4622503944713234,
            "mae": 0.3045872050939633,
            "precision": 0.8263888888888888,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8083239630880268,
            "auditor_fn_violation": 0.009010496953681278,
            "auditor_fp_violation": 0.021606435443447335,
            "ave_precision_score": 0.8087383425354517,
            "fpr": 0.12609649122807018,
            "logloss": 0.9156096422440576,
            "mae": 0.2764441414087223,
            "precision": 0.7537473233404711,
            "recall": 0.7364016736401674
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8140669653553627,
            "auditor_fn_violation": 0.01320462323238846,
            "auditor_fp_violation": 0.02049030369557264,
            "ave_precision_score": 0.8143261415408628,
            "fpr": 0.15916575192096596,
            "logloss": 0.9296722477346548,
            "mae": 0.2889717950542679,
            "precision": 0.7156862745098039,
            "recall": 0.7668067226890757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 30132,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8179813473786368,
            "auditor_fn_violation": 0.0075745063495559015,
            "auditor_fp_violation": 0.0247291616137117,
            "ave_precision_score": 0.818497347671137,
            "fpr": 0.18530701754385964,
            "logloss": 0.8987941379145277,
            "mae": 0.2760660303498048,
            "precision": 0.707105719237435,
            "recall": 0.8535564853556485
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8354604620839094,
            "auditor_fn_violation": 0.011332084974494741,
            "auditor_fp_violation": 0.024512661342215827,
            "ave_precision_score": 0.8356986790466736,
            "fpr": 0.20965971459934138,
            "logloss": 0.9398059177941673,
            "mae": 0.28768461779311855,
            "precision": 0.6800670016750419,
            "recall": 0.8529411764705882
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.6746959938933795,
            "auditor_fn_violation": 0.009951001981942304,
            "auditor_fp_violation": 0.012864823348694321,
            "ave_precision_score": 0.6749227933234714,
            "fpr": 0.17324561403508773,
            "logloss": 1.1986045104531478,
            "mae": 0.3492898283332922,
            "precision": 0.682092555331992,
            "recall": 0.7092050209205021
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.6774247515355156,
            "auditor_fn_violation": 0.002306081598391282,
            "auditor_fp_violation": 0.0022761396469712526,
            "ave_precision_score": 0.6787794570132106,
            "fpr": 0.1800219538968167,
            "logloss": 1.2291409327217782,
            "mae": 0.3530057379814063,
            "precision": 0.6784313725490196,
            "recall": 0.726890756302521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 30132,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.664872263761531,
            "auditor_fn_violation": 0.003745962710122586,
            "auditor_fp_violation": 0.02041646454846795,
            "ave_precision_score": 0.6533097544252648,
            "fpr": 0.22478070175438597,
            "logloss": 2.025559083452914,
            "mae": 0.34336050954124514,
            "precision": 0.6583333333333333,
            "recall": 0.8263598326359832
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.6398957872579291,
            "auditor_fn_violation": 0.008380300528553906,
            "auditor_fp_violation": 0.020962186305310566,
            "ave_precision_score": 0.6280733397902847,
            "fpr": 0.2601536772777168,
            "logloss": 2.3634259004653124,
            "mae": 0.35200616929099465,
            "precision": 0.6381679389312978,
            "recall": 0.8781512605042017
        }
    }
]