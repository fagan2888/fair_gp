[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8236180126568747,
            "auditor_fn_violation": 0.010743421052631581,
            "auditor_fp_violation": 0.018693578606710958,
            "ave_precision_score": 0.8097886767543727,
            "fpr": 0.14692982456140352,
            "logloss": 1.877823909558488,
            "mae": 0.25982834797957144,
            "precision": 0.750465549348231,
            "recall": 0.806
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8520124487817888,
            "auditor_fn_violation": 0.007064899394091793,
            "auditor_fp_violation": 0.01602826624264101,
            "ave_precision_score": 0.8431483473361583,
            "fpr": 0.15587266739846323,
            "logloss": 1.3921210255683312,
            "mae": 0.2301002582882131,
            "precision": 0.7315689981096408,
            "recall": 0.8524229074889867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8034067035322632,
            "auditor_fn_violation": 0.01831578947368421,
            "auditor_fp_violation": 0.022611139499233532,
            "ave_precision_score": 0.8054130100219952,
            "fpr": 0.19736842105263158,
            "logloss": 1.1395429367496117,
            "mae": 0.30042207691774503,
            "precision": 0.6938775510204082,
            "recall": 0.816
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8151227310727933,
            "auditor_fn_violation": 0.008392288089285629,
            "auditor_fp_violation": 0.02207399472049616,
            "ave_precision_score": 0.816231227212779,
            "fpr": 0.1942919868276619,
            "logloss": 1.0037769154579363,
            "mae": 0.2735776712177442,
            "precision": 0.6872791519434629,
            "recall": 0.8568281938325991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7867011607393267,
            "auditor_fn_violation": 0.015489035087719304,
            "auditor_fp_violation": 0.01697964571623233,
            "ave_precision_score": 0.7883085667732245,
            "fpr": 0.17105263157894737,
            "logloss": 1.1643236302822362,
            "mae": 0.2947811554546264,
            "precision": 0.7189189189189189,
            "recall": 0.798
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7888526373216885,
            "auditor_fn_violation": 0.007896632929878094,
            "auditor_fp_violation": 0.02450477629363457,
            "ave_precision_score": 0.789009096982948,
            "fpr": 0.17672886937431395,
            "logloss": 1.0253366767980867,
            "mae": 0.2700995961221281,
            "precision": 0.7024029574861368,
            "recall": 0.8370044052863436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.848411612748636,
            "auditor_fn_violation": 0.010508771929824566,
            "auditor_fp_violation": 0.011933656957928801,
            "ave_precision_score": 0.8282241286360531,
            "fpr": 0.11842105263157894,
            "logloss": 2.3533959708550487,
            "mae": 0.24118833310614216,
            "precision": 0.782258064516129,
            "recall": 0.776
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8820172474325506,
            "auditor_fn_violation": 0.005691571928026035,
            "auditor_fp_violation": 0.006787933523408283,
            "ave_precision_score": 0.8717867884374694,
            "fpr": 0.10757409440175632,
            "logloss": 1.5863417849068318,
            "mae": 0.2035238907767829,
            "precision": 0.7883369330453563,
            "recall": 0.8039647577092511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7770731783563383,
            "auditor_fn_violation": 0.030684210526315786,
            "auditor_fp_violation": 0.02837836399250554,
            "ave_precision_score": 0.7764835412002761,
            "fpr": 0.2138157894736842,
            "logloss": 1.493645456375318,
            "mae": 0.3117989276878191,
            "precision": 0.6760797342192691,
            "recall": 0.814
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7879712531349417,
            "auditor_fn_violation": 0.0182618703366103,
            "auditor_fp_violation": 0.04025441539943362,
            "ave_precision_score": 0.7885602193185197,
            "fpr": 0.2239297475301866,
            "logloss": 1.310134878321508,
            "mae": 0.29499214404298324,
            "precision": 0.659432387312187,
            "recall": 0.8700440528634361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7980823331532527,
            "auditor_fn_violation": 0.0052982456140350884,
            "auditor_fp_violation": 0.02375021291091807,
            "ave_precision_score": 0.7985232973511935,
            "fpr": 0.25,
            "logloss": 1.21611551617164,
            "mae": 0.3187403175434056,
            "precision": 0.6602086438152012,
            "recall": 0.886
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.8156866701448053,
            "auditor_fn_violation": 0.009934863658563711,
            "auditor_fp_violation": 0.02057757483900877,
            "ave_precision_score": 0.816285535615369,
            "fpr": 0.25466520307354557,
            "logloss": 1.1260393753879856,
            "mae": 0.30617304854972854,
            "precision": 0.6380655226209049,
            "recall": 0.9008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8150201718868864,
            "auditor_fn_violation": 0.017385964912280706,
            "auditor_fp_violation": 0.018470022142735482,
            "ave_precision_score": 0.8156153219641744,
            "fpr": 0.13157894736842105,
            "logloss": 1.2016493737558303,
            "mae": 0.2853109117119182,
            "precision": 0.7540983606557377,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.838407744264569,
            "auditor_fn_violation": 0.016663684676276738,
            "auditor_fp_violation": 0.024439923425576535,
            "ave_precision_score": 0.8386528592845719,
            "fpr": 0.11855104281009879,
            "logloss": 0.9645692318261448,
            "mae": 0.24958044121219977,
            "precision": 0.7641921397379913,
            "recall": 0.7709251101321586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8149894289844367,
            "auditor_fn_violation": 0.024048245614035086,
            "auditor_fp_violation": 0.031619932720149894,
            "ave_precision_score": 0.8150997449272298,
            "fpr": 0.1699561403508772,
            "logloss": 1.1819815858809197,
            "mae": 0.2882457971441614,
            "precision": 0.7176684881602914,
            "recall": 0.788
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8300254622977667,
            "auditor_fn_violation": 0.0192217488648288,
            "auditor_fp_violation": 0.030202220850437278,
            "ave_precision_score": 0.8306698491327356,
            "fpr": 0.16136114160263446,
            "logloss": 0.9738487730300917,
            "mae": 0.25784508292830965,
            "precision": 0.7178502879078695,
            "recall": 0.8237885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7851348823623052,
            "auditor_fn_violation": 0.012618421052631579,
            "auditor_fp_violation": 0.0017006259580991325,
            "ave_precision_score": 0.781108153880519,
            "fpr": 0.023026315789473683,
            "logloss": 5.025938271482184,
            "mae": 0.4562298596594166,
            "precision": 0.8359375,
            "recall": 0.214
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.7933795513246156,
            "auditor_fn_violation": 0.008368109788826723,
            "auditor_fp_violation": 0.0040929365618852485,
            "ave_precision_score": 0.7891068178982421,
            "fpr": 0.012074643249176729,
            "logloss": 4.347219839228746,
            "mae": 0.41842552253625037,
            "precision": 0.8854166666666666,
            "recall": 0.18722466960352424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.816277731936519,
            "auditor_fn_violation": 0.014780701754385969,
            "auditor_fp_violation": 0.020588485777550677,
            "ave_precision_score": 0.8167056459760444,
            "fpr": 0.17982456140350878,
            "logloss": 1.1046424860806021,
            "mae": 0.2975382842872432,
            "precision": 0.7050359712230215,
            "recall": 0.784
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.829898516596922,
            "auditor_fn_violation": 0.007466259181709601,
            "auditor_fp_violation": 0.01887458656296614,
            "ave_precision_score": 0.8305021501821976,
            "fpr": 0.17453347969264543,
            "logloss": 0.9073812972675532,
            "mae": 0.26773521454728033,
            "precision": 0.7,
            "recall": 0.8171806167400881
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8014490119111943,
            "auditor_fn_violation": 0.018217105263157896,
            "auditor_fp_violation": 0.025017032873445755,
            "ave_precision_score": 0.801050219870137,
            "fpr": 0.19517543859649122,
            "logloss": 1.289432798333095,
            "mae": 0.2948665374288804,
            "precision": 0.6957264957264957,
            "recall": 0.814
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8167109790292234,
            "auditor_fn_violation": 0.01223905569229728,
            "auditor_fp_violation": 0.02286664088564998,
            "ave_precision_score": 0.8163322082216258,
            "fpr": 0.18441273326015367,
            "logloss": 1.0666304227714196,
            "mae": 0.2660080219291488,
            "precision": 0.6989247311827957,
            "recall": 0.8590308370044053
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8148119712809212,
            "auditor_fn_violation": 0.024048245614035086,
            "auditor_fp_violation": 0.030989184125361956,
            "ave_precision_score": 0.8148817199732594,
            "fpr": 0.17105263157894737,
            "logloss": 1.1840883692741726,
            "mae": 0.28828979151941386,
            "precision": 0.7163636363636363,
            "recall": 0.788
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8300815401707186,
            "auditor_fn_violation": 0.018844567377669888,
            "auditor_fp_violation": 0.030202220850437278,
            "ave_precision_score": 0.8307057400250788,
            "fpr": 0.16136114160263446,
            "logloss": 0.9756902083169563,
            "mae": 0.25795793259724226,
            "precision": 0.7173076923076923,
            "recall": 0.8215859030837004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8563924029576523,
            "auditor_fn_violation": 0.009155701754385976,
            "auditor_fp_violation": 0.006142479986373699,
            "ave_precision_score": 0.8411342909454215,
            "fpr": 0.08771929824561403,
            "logloss": 2.6221166072144215,
            "mae": 0.2419054692018035,
            "precision": 0.8194130925507901,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.8013172338090011,
            "auc_prc": 0.8843787718728802,
            "auditor_fn_violation": 0.001421684066983566,
            "auditor_fp_violation": 0.009240332719232719,
            "ave_precision_score": 0.8751209120403746,
            "fpr": 0.08232711306256861,
            "logloss": 1.8064134375189114,
            "mae": 0.20002230983433664,
            "precision": 0.8226950354609929,
            "recall": 0.7665198237885462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 16695,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8174267748030479,
            "auditor_fn_violation": 0.013298245614035094,
            "auditor_fp_violation": 0.024612502129109183,
            "ave_precision_score": 0.8174724430467428,
            "fpr": 0.21052631578947367,
            "logloss": 1.3102408665925822,
            "mae": 0.2929130663306583,
            "precision": 0.6883116883116883,
            "recall": 0.848
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8375526818298038,
            "auditor_fn_violation": 0.008965313810161657,
            "auditor_fp_violation": 0.025708157289822668,
            "ave_precision_score": 0.8376999021325359,
            "fpr": 0.21185510428100987,
            "logloss": 1.09028771760071,
            "mae": 0.2691969458913887,
            "precision": 0.6794019933554817,
            "recall": 0.9008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7745167466730148,
            "auditor_fn_violation": 0.013513157894736842,
            "auditor_fp_violation": 0.02342286237438257,
            "ave_precision_score": 0.7443373034420653,
            "fpr": 0.1962719298245614,
            "logloss": 3.622553314639622,
            "mae": 0.3090611431705932,
            "precision": 0.6897746967071057,
            "recall": 0.796
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7877836620440347,
            "auditor_fn_violation": 0.009647141883102754,
            "auditor_fp_violation": 0.021084387993091976,
            "ave_precision_score": 0.7629640081618762,
            "fpr": 0.1942919868276619,
            "logloss": 2.889079463237064,
            "mae": 0.2796251287264722,
            "precision": 0.6839285714285714,
            "recall": 0.8436123348017621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8042472043188148,
            "auditor_fn_violation": 0.009699561403508772,
            "auditor_fp_violation": 0.020897206608754906,
            "ave_precision_score": 0.8047054178103775,
            "fpr": 0.20614035087719298,
            "logloss": 1.1420487244563535,
            "mae": 0.3043627107229452,
            "precision": 0.6902800658978583,
            "recall": 0.838
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8208021536475005,
            "auditor_fn_violation": 0.009944534978747276,
            "auditor_fp_violation": 0.022186886750078683,
            "ave_precision_score": 0.8212578885775912,
            "fpr": 0.21295279912184412,
            "logloss": 0.9912222571741882,
            "mae": 0.27863146211291556,
            "precision": 0.6706281833616299,
            "recall": 0.8700440528634361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.817102287095083,
            "auditor_fn_violation": 0.018421052631578953,
            "auditor_fp_violation": 0.018320984500085177,
            "ave_precision_score": 0.8173583116677022,
            "fpr": 0.1337719298245614,
            "logloss": 1.1878467342203043,
            "mae": 0.28484532549818437,
            "precision": 0.7510204081632653,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8385403328742452,
            "auditor_fn_violation": 0.014961532323969887,
            "auditor_fp_violation": 0.023286983548989133,
            "ave_precision_score": 0.8387900064977787,
            "fpr": 0.1207464324917673,
            "logloss": 0.9531371942622608,
            "mae": 0.2485508840114492,
            "precision": 0.7624190064794817,
            "recall": 0.7775330396475771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7842293804134279,
            "auditor_fn_violation": 0.017043859649122813,
            "auditor_fp_violation": 0.01634091296201669,
            "ave_precision_score": 0.7890761169659108,
            "fpr": 0.16228070175438597,
            "logloss": 1.1502077564016504,
            "mae": 0.29654183828114616,
            "precision": 0.7269372693726938,
            "recall": 0.788
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.7865260630355645,
            "auditor_fn_violation": 0.010186317983336317,
            "auditor_fp_violation": 0.014077876284747331,
            "ave_precision_score": 0.786560858391315,
            "fpr": 0.17233809001097694,
            "logloss": 1.0123962598843905,
            "mae": 0.27278301573454616,
            "precision": 0.7037735849056603,
            "recall": 0.8215859030837004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8465391057704683,
            "auditor_fn_violation": 0.009622807017543871,
            "auditor_fp_violation": 0.01288377192982456,
            "ave_precision_score": 0.8288777937289538,
            "fpr": 0.11293859649122807,
            "logloss": 2.2443564730876293,
            "mae": 0.242981005377721,
            "precision": 0.7876288659793814,
            "recall": 0.764
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8798718979345597,
            "auditor_fn_violation": 0.00681828072941097,
            "auditor_fp_violation": 0.007847197035022957,
            "ave_precision_score": 0.8706600949415502,
            "fpr": 0.10208562019758508,
            "logloss": 1.5106604078644972,
            "mae": 0.20469936504572214,
            "precision": 0.7947019867549668,
            "recall": 0.7929515418502202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8164287452649797,
            "auditor_fn_violation": 0.012131578947368429,
            "auditor_fp_violation": 0.018142671606199968,
            "ave_precision_score": 0.8167867627871725,
            "fpr": 0.12609649122807018,
            "logloss": 1.248158329554008,
            "mae": 0.290387878387079,
            "precision": 0.7599164926931107,
            "recall": 0.728
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8468314400853284,
            "auditor_fn_violation": 0.0076596855853808396,
            "auditor_fp_violation": 0.01191131009999352,
            "ave_precision_score": 0.847033884924605,
            "fpr": 0.11306256860592755,
            "logloss": 0.9379276294364123,
            "mae": 0.24807455340136586,
            "precision": 0.7716186252771619,
            "recall": 0.7665198237885462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8070140812521944,
            "auditor_fn_violation": 0.01666666666666667,
            "auditor_fp_violation": 0.024341040708567546,
            "ave_precision_score": 0.8083523249761644,
            "fpr": 0.19188596491228072,
            "logloss": 1.1025999504240338,
            "mae": 0.2978397416611632,
            "precision": 0.6982758620689655,
            "recall": 0.81
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8224073053612295,
            "auditor_fn_violation": 0.00899916343080412,
            "auditor_fp_violation": 0.020985907711966796,
            "ave_precision_score": 0.8231398429428602,
            "fpr": 0.18990120746432493,
            "logloss": 0.9594675964579382,
            "mae": 0.26946039055957827,
            "precision": 0.6905187835420393,
            "recall": 0.8502202643171806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 16695,
        "test": {
            "accuracy": 0.28399122807017546,
            "auc_prc": 0.4324327465130221,
            "auditor_fn_violation": 0.012765350877192983,
            "auditor_fp_violation": 0.00958099131323455,
            "ave_precision_score": 0.39337535335257745,
            "fpr": 0.34210526315789475,
            "logloss": 15.123770197242699,
            "mae": 0.7185967540734604,
            "precision": 0.3375796178343949,
            "recall": 0.318
        },
        "train": {
            "accuracy": 0.24368825466520308,
            "auc_prc": 0.36901653468241463,
            "auditor_fn_violation": 0.006924665251430163,
            "auditor_fp_violation": 0.008755137187835525,
            "ave_precision_score": 0.33559507770966174,
            "fpr": 0.4061470911086718,
            "logloss": 17.01669914412324,
            "mae": 0.7560397608692789,
            "precision": 0.26732673267326734,
            "recall": 0.2973568281938326
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7886360828622916,
            "auditor_fn_violation": 0.010307017543859652,
            "auditor_fp_violation": 0.02451136944302504,
            "ave_precision_score": 0.7844915814626388,
            "fpr": 0.2225877192982456,
            "logloss": 1.4134592714738747,
            "mae": 0.3172454115328468,
            "precision": 0.6842923794712286,
            "recall": 0.88
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7922912256944328,
            "auditor_fn_violation": 0.007297011078497271,
            "auditor_fp_violation": 0.02230698465388985,
            "ave_precision_score": 0.7878531410423344,
            "fpr": 0.20856201975850713,
            "logloss": 1.292683329573263,
            "mae": 0.29092049786395985,
            "precision": 0.6854304635761589,
            "recall": 0.9118942731277533
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7977801312967291,
            "auditor_fn_violation": 0.016657894736842104,
            "auditor_fp_violation": 0.04240919349344234,
            "ave_precision_score": 0.7893368351192614,
            "fpr": 0.26206140350877194,
            "logloss": 1.7644388922988137,
            "mae": 0.32480999345573447,
            "precision": 0.6516034985422741,
            "recall": 0.894
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8199843352136056,
            "auditor_fn_violation": 0.01837792617881304,
            "auditor_fp_violation": 0.04558676232865033,
            "ave_precision_score": 0.8133299184933865,
            "fpr": 0.2711306256860593,
            "logloss": 1.5854638009352402,
            "mae": 0.3143885578665194,
            "precision": 0.6291291291291291,
            "recall": 0.9229074889867841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7586109896815116,
            "auditor_fn_violation": 0.0038377192982456186,
            "auditor_fp_violation": 0.017788707204905475,
            "ave_precision_score": 0.759262146869195,
            "fpr": 0.17653508771929824,
            "logloss": 1.153028073401137,
            "mae": 0.30350466227688633,
            "precision": 0.7078039927404719,
            "recall": 0.78
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7286801142198654,
            "auditor_fn_violation": 0.0031746108502541137,
            "auditor_fp_violation": 0.019431840836650036,
            "ave_precision_score": 0.7302476974231,
            "fpr": 0.1690450054884742,
            "logloss": 1.0802621177110232,
            "mae": 0.2714387447323149,
            "precision": 0.7088846880907372,
            "recall": 0.8259911894273128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7960741870752551,
            "auditor_fn_violation": 0.008938596491228072,
            "auditor_fp_violation": 0.02521929824561405,
            "ave_precision_score": 0.796710672305084,
            "fpr": 0.25219298245614036,
            "logloss": 1.2415601665619649,
            "mae": 0.3206179798912133,
            "precision": 0.658753709198813,
            "recall": 0.888
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.8094252774581316,
            "auditor_fn_violation": 0.00775639878721645,
            "auditor_fp_violation": 0.022201298498536002,
            "ave_precision_score": 0.8101197194108021,
            "fpr": 0.25905598243688255,
            "logloss": 1.1568919210303619,
            "mae": 0.31003060231540464,
            "precision": 0.6346749226006192,
            "recall": 0.9030837004405287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8200143883479575,
            "auditor_fn_violation": 0.01580043859649124,
            "auditor_fp_violation": 0.005269545222278998,
            "ave_precision_score": 0.8204403442345285,
            "fpr": 0.06798245614035088,
            "logloss": 1.7035968886389616,
            "mae": 0.29494886697602996,
            "precision": 0.8253521126760563,
            "recall": 0.586
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8434291362084037,
            "auditor_fn_violation": 0.00944887981933974,
            "auditor_fp_violation": 0.006024110855169134,
            "ave_precision_score": 0.8436817671209849,
            "fpr": 0.0570801317233809,
            "logloss": 1.4061389580376449,
            "mae": 0.2573989182758648,
            "precision": 0.844311377245509,
            "recall": 0.6211453744493393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 16695,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8474052017203142,
            "auditor_fn_violation": 0.010445175438596493,
            "auditor_fp_violation": 0.007430591040708569,
            "ave_precision_score": 0.847126266888153,
            "fpr": 0.0625,
            "logloss": 2.0801122683959634,
            "mae": 0.25823259178957825,
            "precision": 0.8523316062176166,
            "recall": 0.658
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8461094988818693,
            "auditor_fn_violation": 0.0026281812598828885,
            "auditor_fp_violation": 0.010131459165511723,
            "ave_precision_score": 0.8457465518507268,
            "fpr": 0.05598243688254665,
            "logloss": 2.0653237749280304,
            "mae": 0.23906144838382695,
            "precision": 0.8551136363636364,
            "recall": 0.6629955947136564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7882912707812444,
            "auditor_fn_violation": 0.006809210526315791,
            "auditor_fp_violation": 0.028639179867143597,
            "ave_precision_score": 0.788623634928128,
            "fpr": 0.27960526315789475,
            "logloss": 1.512142461332811,
            "mae": 0.33460212584331556,
            "precision": 0.6408450704225352,
            "recall": 0.91
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7950352202882238,
            "auditor_fn_violation": 0.006636943475969188,
            "auditor_fp_violation": 0.025297422458788424,
            "ave_precision_score": 0.7957299312788749,
            "fpr": 0.305159165751921,
            "logloss": 1.4771524770780202,
            "mae": 0.33952965143134173,
            "precision": 0.6034236804564908,
            "recall": 0.9317180616740088
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7834785199532773,
            "auditor_fn_violation": 0.002039473684210528,
            "auditor_fp_violation": 0.007241632600919783,
            "ave_precision_score": 0.7628817505574463,
            "fpr": 0.3541666666666667,
            "logloss": 2.346807689880974,
            "mae": 0.3725790607415164,
            "precision": 0.5972568578553616,
            "recall": 0.958
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8038487054014046,
            "auditor_fn_violation": 0.0017722694236376737,
            "auditor_fp_violation": 0.0059328364482726425,
            "ave_precision_score": 0.7878968300836424,
            "fpr": 0.40175631174533477,
            "logloss": 2.0966824615967723,
            "mae": 0.3946323526819246,
            "precision": 0.5475896168108776,
            "recall": 0.9757709251101322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 16695,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7243205436488735,
            "auditor_fn_violation": 0.0014627192982456265,
            "auditor_fp_violation": 0.010613609265883155,
            "ave_precision_score": 0.7241482392761971,
            "fpr": 0.15350877192982457,
            "logloss": 2.860263805460064,
            "mae": 0.3374330929287415,
            "precision": 0.720558882235529,
            "recall": 0.722
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7219614611259579,
            "auditor_fn_violation": 0.018467385890510994,
            "auditor_fp_violation": 0.009869645735203337,
            "ave_precision_score": 0.7220912298667036,
            "fpr": 0.17014270032930845,
            "logloss": 2.542631504981223,
            "mae": 0.34359685304386917,
            "precision": 0.6736842105263158,
            "recall": 0.7048458149779736
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8173268108317098,
            "auditor_fn_violation": 0.01770833333333334,
            "auditor_fp_violation": 0.019236501447794253,
            "ave_precision_score": 0.8177497812083779,
            "fpr": 0.13486842105263158,
            "logloss": 1.1868708015723208,
            "mae": 0.2847987928171449,
            "precision": 0.75,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8385412777025345,
            "auditor_fn_violation": 0.015324206830853452,
            "auditor_fp_violation": 0.02315247389672061,
            "ave_precision_score": 0.8387909165322729,
            "fpr": 0.12184412733260154,
            "logloss": 0.9533058284847251,
            "mae": 0.24861258313798612,
            "precision": 0.7612903225806451,
            "recall": 0.7797356828193832
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8663533626019138,
            "auditor_fn_violation": 0.012543859649122812,
            "auditor_fp_violation": 0.01789516266394141,
            "ave_precision_score": 0.8551554338550466,
            "fpr": 0.14364035087719298,
            "logloss": 1.7405283215264502,
            "mae": 0.23845403840901197,
            "precision": 0.7648114901256733,
            "recall": 0.852
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8952519688767421,
            "auditor_fn_violation": 0.005539248635134943,
            "auditor_fp_violation": 0.014851306785291377,
            "ave_precision_score": 0.8898718944255937,
            "fpr": 0.14270032930845225,
            "logloss": 1.2575815587117385,
            "mae": 0.2077198982601915,
            "precision": 0.7542533081285444,
            "recall": 0.8788546255506607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8131898993148045,
            "auditor_fn_violation": 0.01800877192982457,
            "auditor_fp_violation": 0.01906351132686085,
            "ave_precision_score": 0.8135449908752657,
            "fpr": 0.12390350877192982,
            "logloss": 1.2130180926915277,
            "mae": 0.2939017906562728,
            "precision": 0.7580299785867237,
            "recall": 0.708
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.826934610322694,
            "auditor_fn_violation": 0.0038008288321397365,
            "auditor_fp_violation": 0.01718360807730462,
            "ave_precision_score": 0.8273197601034155,
            "fpr": 0.11306256860592755,
            "logloss": 0.9376318054857943,
            "mae": 0.2556037731610466,
            "precision": 0.7664399092970522,
            "recall": 0.7444933920704846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8483096398497452,
            "auditor_fn_violation": 0.008815789473684206,
            "auditor_fp_violation": 0.00796819110884006,
            "ave_precision_score": 0.8357985797223101,
            "fpr": 0.10416666666666667,
            "logloss": 1.9585221738735357,
            "mae": 0.24190457420735922,
            "precision": 0.8,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8788326585733756,
            "auditor_fn_violation": 0.006707060547300013,
            "auditor_fp_violation": 0.007410040665150233,
            "ave_precision_score": 0.8708964231740524,
            "fpr": 0.09440175631174534,
            "logloss": 1.3585717212755217,
            "mae": 0.2041848673898993,
            "precision": 0.8054298642533937,
            "recall": 0.7841409691629956
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7843673234748441,
            "auditor_fn_violation": 0.016899122807017546,
            "auditor_fp_violation": 0.020167986714358713,
            "ave_precision_score": 0.784916733460289,
            "fpr": 0.15460526315789475,
            "logloss": 1.9066607822405508,
            "mae": 0.31765628242924676,
            "precision": 0.7235294117647059,
            "recall": 0.738
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8195444379880055,
            "auditor_fn_violation": 0.012144760320507555,
            "auditor_fp_violation": 0.019525517201622763,
            "ave_precision_score": 0.8201048513611077,
            "fpr": 0.145993413830955,
            "logloss": 1.4399427783394532,
            "mae": 0.2739175288233726,
            "precision": 0.734,
            "recall": 0.8083700440528634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8013810411756934,
            "auditor_fn_violation": 0.010848684210526316,
            "auditor_fp_violation": 0.020436786748424467,
            "ave_precision_score": 0.8018233689659058,
            "fpr": 0.20723684210526316,
            "logloss": 1.1356929910801143,
            "mae": 0.30436584229877395,
            "precision": 0.686046511627907,
            "recall": 0.826
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8230383708037621,
            "auditor_fn_violation": 0.008989492110620561,
            "auditor_fp_violation": 0.02235262185733812,
            "ave_precision_score": 0.8234096323851366,
            "fpr": 0.21295279912184412,
            "logloss": 0.9769110126327553,
            "mae": 0.2786957054805633,
            "precision": 0.6706281833616299,
            "recall": 0.8700440528634361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8621394824747057,
            "auditor_fn_violation": 0.012938596491228076,
            "auditor_fp_violation": 0.010629577584738554,
            "ave_precision_score": 0.8547586380591271,
            "fpr": 0.12390350877192982,
            "logloss": 1.457293476511894,
            "mae": 0.2383528288391938,
            "precision": 0.7797270955165692,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.8100987925356751,
            "auc_prc": 0.894285387763861,
            "auditor_fn_violation": 0.002850621624104799,
            "auditor_fp_violation": 0.015161159377124233,
            "ave_precision_score": 0.8910990662556416,
            "fpr": 0.1163556531284303,
            "logloss": 1.017019430787692,
            "mae": 0.19998489535328975,
            "precision": 0.7849898580121704,
            "recall": 0.8524229074889867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7800760565767835,
            "auditor_fn_violation": 0.017142543859649122,
            "auditor_fp_violation": 0.01875745188213252,
            "ave_precision_score": 0.7449954017246447,
            "fpr": 0.17543859649122806,
            "logloss": 3.930041758684497,
            "mae": 0.3091840162998693,
            "precision": 0.702048417132216,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7845938120382836,
            "auditor_fn_violation": 0.009226439455117827,
            "auditor_fp_violation": 0.02100512337657659,
            "ave_precision_score": 0.7504043315482132,
            "fpr": 0.16575192096597147,
            "logloss": 3.2834481778733124,
            "mae": 0.27425534767084897,
            "precision": 0.705078125,
            "recall": 0.7951541850220264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7973497812323922,
            "auditor_fn_violation": 0.0052982456140350884,
            "auditor_fp_violation": 0.025152763583716577,
            "ave_precision_score": 0.7979262961591238,
            "fpr": 0.2532894736842105,
            "logloss": 1.27743980390638,
            "mae": 0.32094652836293425,
            "precision": 0.6572700296735905,
            "recall": 0.886
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.8109775438978895,
            "auditor_fn_violation": 0.007928064720474668,
            "auditor_fp_violation": 0.021120417364235335,
            "ave_precision_score": 0.811690231412087,
            "fpr": 0.2601536772777168,
            "logloss": 1.192563489622655,
            "mae": 0.3116458482893244,
            "precision": 0.6353846153846154,
            "recall": 0.9096916299559471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7320705304800474,
            "auditor_fn_violation": 0.02093201754385966,
            "auditor_fp_violation": 0.021738204735138825,
            "ave_precision_score": 0.7338031234145577,
            "fpr": 0.17543859649122806,
            "logloss": 1.507010925292579,
            "mae": 0.33861735321163017,
            "precision": 0.6893203883495146,
            "recall": 0.71
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.6985744174459876,
            "auditor_fn_violation": 0.02263330705958018,
            "auditor_fp_violation": 0.023483944111239483,
            "ave_precision_score": 0.7001942250717361,
            "fpr": 0.19209659714599342,
            "logloss": 1.3286536425575926,
            "mae": 0.3166826540138516,
            "precision": 0.6595330739299611,
            "recall": 0.7466960352422908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7916752659313258,
            "auditor_fn_violation": 0.0052982456140350884,
            "auditor_fp_violation": 0.025767543859649137,
            "ave_precision_score": 0.7922100502564586,
            "fpr": 0.25109649122807015,
            "logloss": 1.233902224555399,
            "mae": 0.31968019357612665,
            "precision": 0.6592261904761905,
            "recall": 0.886
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7824193505630844,
            "auditor_fn_violation": 0.009934863658563711,
            "auditor_fp_violation": 0.022220514163145803,
            "ave_precision_score": 0.7829167278614714,
            "fpr": 0.2579582875960483,
            "logloss": 1.2424813267418011,
            "mae": 0.30873572504567737,
            "precision": 0.6350931677018633,
            "recall": 0.9008810572687225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7815509282289204,
            "auditor_fn_violation": 0.02403508771929825,
            "auditor_fp_violation": 0.025506727985011076,
            "ave_precision_score": 0.7681284161961583,
            "fpr": 0.1206140350877193,
            "logloss": 2.0874402267547643,
            "mae": 0.29626309086525365,
            "precision": 0.7634408602150538,
            "recall": 0.71
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8041679872271271,
            "auditor_fn_violation": 0.012495345677161665,
            "auditor_fp_violation": 0.02147110324336399,
            "ave_precision_score": 0.7947845145846465,
            "fpr": 0.11525795828759605,
            "logloss": 1.5998111955665422,
            "mae": 0.2519951930115165,
            "precision": 0.7661469933184856,
            "recall": 0.7577092511013216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7356732399183066,
            "auditor_fn_violation": 0.009539473684210528,
            "auditor_fp_violation": 0.014887795946176136,
            "ave_precision_score": 0.7362974166131828,
            "fpr": 0.3048245614035088,
            "logloss": 0.8959889738342559,
            "mae": 0.37211458926146423,
            "precision": 0.6181318681318682,
            "recall": 0.9
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7095882754921888,
            "auditor_fn_violation": 0.004961387254167134,
            "auditor_fp_violation": 0.018670420126487116,
            "ave_precision_score": 0.7109889320746234,
            "fpr": 0.33150384193194293,
            "logloss": 0.9430472880218133,
            "mae": 0.3849751344134645,
            "precision": 0.5776223776223777,
            "recall": 0.9096916299559471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7958936646450744,
            "auditor_fn_violation": 0.011741228070175443,
            "auditor_fp_violation": 0.023036961335377283,
            "ave_precision_score": 0.7956232292969347,
            "fpr": 0.17763157894736842,
            "logloss": 1.3673633382342418,
            "mae": 0.2945105369593852,
            "precision": 0.7147887323943662,
            "recall": 0.812
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8136988448758642,
            "auditor_fn_violation": 0.0035493745073671306,
            "auditor_fp_violation": 0.02163924030869965,
            "ave_precision_score": 0.8137216538182128,
            "fpr": 0.18441273326015367,
            "logloss": 1.1089024665343474,
            "mae": 0.26998875389965976,
            "precision": 0.697841726618705,
            "recall": 0.8546255506607929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8254740114254668,
            "auditor_fn_violation": 0.013436403508771934,
            "auditor_fp_violation": 0.012790623403168116,
            "ave_precision_score": 0.825763320824192,
            "fpr": 0.1206140350877193,
            "logloss": 0.9149066356400279,
            "mae": 0.290287748811782,
            "precision": 0.7674418604651163,
            "recall": 0.726
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8434107628304983,
            "auditor_fn_violation": 0.010498218059256187,
            "auditor_fp_violation": 0.01378723935752426,
            "ave_precision_score": 0.8437406341162775,
            "fpr": 0.11086717892425905,
            "logloss": 0.6879353046412026,
            "mae": 0.2522337417997766,
            "precision": 0.7740492170022372,
            "recall": 0.762114537444934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6663857752906376,
            "auditor_fn_violation": 0.015774122807017562,
            "auditor_fp_violation": 0.017160619996593428,
            "ave_precision_score": 0.6579988763245006,
            "fpr": 0.1513157894736842,
            "logloss": 10.550920210419084,
            "mae": 0.46180320884971143,
            "precision": 0.6112676056338028,
            "recall": 0.434
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.6491917625873875,
            "auditor_fn_violation": 0.01127192367394113,
            "auditor_fp_violation": 0.018029097320135384,
            "ave_precision_score": 0.6448694545152507,
            "fpr": 0.17014270032930845,
            "logloss": 9.924874756776557,
            "mae": 0.4449181883676646,
            "precision": 0.5584045584045584,
            "recall": 0.43171806167400884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 16695,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7754089883066732,
            "auditor_fn_violation": 0.01402631578947369,
            "auditor_fp_violation": 0.02125117101004941,
            "ave_precision_score": 0.7451224315717471,
            "fpr": 0.19407894736842105,
            "logloss": 3.6397900018417375,
            "mae": 0.308893207003003,
            "precision": 0.6921739130434783,
            "recall": 0.796
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7885124805142386,
            "auditor_fn_violation": 0.008302828377587688,
            "auditor_fp_violation": 0.021084387993091976,
            "ave_precision_score": 0.7636363495629861,
            "fpr": 0.1942919868276619,
            "logloss": 2.907344594670373,
            "mae": 0.2793638758834259,
            "precision": 0.6833631484794276,
            "recall": 0.8414096916299559
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7918825685993665,
            "auditor_fn_violation": 0.011859649122807018,
            "auditor_fp_violation": 0.02166368591381366,
            "ave_precision_score": 0.7894564779458401,
            "fpr": 0.20723684210526316,
            "logloss": 1.6029870560636201,
            "mae": 0.29996426757643796,
            "precision": 0.6881188118811881,
            "recall": 0.834
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8071234436335721,
            "auditor_fn_violation": 0.008621981943645218,
            "auditor_fp_violation": 0.02605163729472266,
            "ave_precision_score": 0.8049453761712585,
            "fpr": 0.22283205268935236,
            "logloss": 1.3895871982547863,
            "mae": 0.28272472062201126,
            "precision": 0.6633499170812603,
            "recall": 0.8810572687224669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8569913861596221,
            "auditor_fn_violation": 0.009385964912280706,
            "auditor_fp_violation": 0.00972736756940896,
            "ave_precision_score": 0.8434005771008234,
            "fpr": 0.11513157894736842,
            "logloss": 2.09751502646223,
            "mae": 0.23884201580608025,
            "precision": 0.7861507128309573,
            "recall": 0.772
        },
        "train": {
            "accuracy": 0.7969264544456641,
            "auc_prc": 0.8876922023729368,
            "auditor_fn_violation": 0.005399014492473297,
            "auditor_fp_violation": 0.00736920737785443,
            "ave_precision_score": 0.8813287472268461,
            "fpr": 0.10318331503841932,
            "logloss": 1.4372452031204213,
            "mae": 0.20341349021235022,
            "precision": 0.7943107221006565,
            "recall": 0.7995594713656388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8184303657582209,
            "auditor_fn_violation": 0.01592105263157895,
            "auditor_fp_violation": 0.023907234712996092,
            "ave_precision_score": 0.8189342476156946,
            "fpr": 0.19407894736842105,
            "logloss": 0.9857966846890219,
            "mae": 0.2968512662955917,
            "precision": 0.6958762886597938,
            "recall": 0.81
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8335780531162371,
            "auditor_fn_violation": 0.010309627315676726,
            "auditor_fp_violation": 0.020603996377847225,
            "ave_precision_score": 0.8341671996454934,
            "fpr": 0.18660812294182216,
            "logloss": 0.8468403423454897,
            "mae": 0.2660180727958449,
            "precision": 0.6942446043165468,
            "recall": 0.8502202643171806
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6480263157894737,
            "auc_prc": 0.691926937868564,
            "auditor_fn_violation": 0.007000000000000008,
            "auditor_fp_violation": 0.015691534661897467,
            "ave_precision_score": 0.6528037337119963,
            "fpr": 0.18092105263157895,
            "logloss": 4.618495783664517,
            "mae": 0.3545310478314519,
            "precision": 0.6758349705304518,
            "recall": 0.688
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.6831591820591343,
            "auditor_fn_violation": 0.014463459334516458,
            "auditor_fp_violation": 0.020839388269317152,
            "ave_precision_score": 0.6451673379996278,
            "fpr": 0.18111964873765093,
            "logloss": 4.255835059992946,
            "mae": 0.3400315185868261,
            "precision": 0.6540880503144654,
            "recall": 0.6872246696035242
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7918231101213528,
            "auditor_fn_violation": 0.015657894736842103,
            "auditor_fp_violation": 0.0186190597853858,
            "ave_precision_score": 0.7923307662120695,
            "fpr": 0.12828947368421054,
            "logloss": 1.9988296831350427,
            "mae": 0.31135372411407236,
            "precision": 0.7439824945295405,
            "recall": 0.68
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.815231110887209,
            "auditor_fn_violation": 0.016586314114808244,
            "auditor_fp_violation": 0.025676931834831756,
            "ave_precision_score": 0.8159666967536421,
            "fpr": 0.1251372118551043,
            "logloss": 1.505460147320753,
            "mae": 0.26902010527134806,
            "precision": 0.7461024498886414,
            "recall": 0.737885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.8122877135738105,
            "auditor_fn_violation": 0.009429824561403514,
            "auditor_fp_violation": 0.026004407256004093,
            "ave_precision_score": 0.8129373279226132,
            "fpr": 0.21600877192982457,
            "logloss": 0.9720662874266441,
            "mae": 0.3075149577515005,
            "precision": 0.6807131280388979,
            "recall": 0.84
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8277468767856775,
            "auditor_fn_violation": 0.007630671624830147,
            "auditor_fp_violation": 0.01978252671577871,
            "ave_precision_score": 0.8284394952548361,
            "fpr": 0.21185510428100987,
            "logloss": 0.8790614905497011,
            "mae": 0.2843358843071929,
            "precision": 0.6745362563237775,
            "recall": 0.8810572687224669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 16695,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7801996176952402,
            "auditor_fn_violation": 0.018842105263157903,
            "auditor_fp_violation": 0.008388690172032023,
            "ave_precision_score": 0.7705664179884524,
            "fpr": 0.05263157894736842,
            "logloss": 2.500190662034703,
            "mae": 0.3746943473606644,
            "precision": 0.8110236220472441,
            "recall": 0.412
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7944543241997644,
            "auditor_fn_violation": 0.014168484068917846,
            "auditor_fp_violation": 0.005685434766421589,
            "ave_precision_score": 0.7872300376322888,
            "fpr": 0.05159165751920966,
            "logloss": 1.965008269745095,
            "mae": 0.3311057374297861,
            "precision": 0.8049792531120332,
            "recall": 0.42731277533039647
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7964506546863865,
            "auditor_fn_violation": 0.016061403508771936,
            "auditor_fp_violation": 0.017684913132345426,
            "ave_precision_score": 0.7969293055857771,
            "fpr": 0.12828947368421054,
            "logloss": 1.9468883567570696,
            "mae": 0.30996417210437205,
            "precision": 0.7462039045553145,
            "recall": 0.688
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8209418085997022,
            "auditor_fn_violation": 0.016010870563886326,
            "auditor_fp_violation": 0.028100507533741513,
            "ave_precision_score": 0.8216534696659863,
            "fpr": 0.12623490669593854,
            "logloss": 1.4670935947430257,
            "mae": 0.2686151918620836,
            "precision": 0.7472527472527473,
            "recall": 0.748898678414097
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.6498820103743854,
            "auditor_fn_violation": 0.013109649122807026,
            "auditor_fp_violation": 0.016239780275932557,
            "ave_precision_score": 0.6413865182589733,
            "fpr": 0.13048245614035087,
            "logloss": 10.57819481813544,
            "mae": 0.46309743706507633,
            "precision": 0.6198083067092651,
            "recall": 0.388
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6337440398538208,
            "auditor_fn_violation": 0.011001126708801408,
            "auditor_fp_violation": 0.018384587115416497,
            "ave_precision_score": 0.6295353048810524,
            "fpr": 0.132821075740944,
            "logloss": 9.889480387968199,
            "mae": 0.43041565527569026,
            "precision": 0.6032786885245902,
            "recall": 0.4052863436123348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.808024603458014,
            "auditor_fn_violation": 0.01831578947368421,
            "auditor_fp_violation": 0.022611139499233532,
            "ave_precision_score": 0.8084592794903394,
            "fpr": 0.19736842105263158,
            "logloss": 1.1447504066774652,
            "mae": 0.30036000281225933,
            "precision": 0.6938775510204082,
            "recall": 0.816
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8199724404157129,
            "auditor_fn_violation": 0.008392288089285629,
            "auditor_fp_violation": 0.02156477960833672,
            "ave_precision_score": 0.8207715877937515,
            "fpr": 0.19319429198682767,
            "logloss": 1.007297943679617,
            "mae": 0.2736226177995859,
            "precision": 0.6884955752212389,
            "recall": 0.8568281938325991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8040671332276639,
            "auditor_fn_violation": 0.011304824561403515,
            "auditor_fp_violation": 0.020301056038153645,
            "ave_precision_score": 0.8045118656528469,
            "fpr": 0.20614035087719298,
            "logloss": 1.1354210439216086,
            "mae": 0.30434710348766036,
            "precision": 0.6892561983471074,
            "recall": 0.834
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8207949331637452,
            "auditor_fn_violation": 0.009944534978747276,
            "auditor_fp_violation": 0.020294143786014365,
            "ave_precision_score": 0.8212402730445294,
            "fpr": 0.21185510428100987,
            "logloss": 0.9826328092570792,
            "mae": 0.2778607025482639,
            "precision": 0.6717687074829932,
            "recall": 0.8700440528634361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6894047314938518,
            "auditor_fn_violation": 0.007324561403508771,
            "auditor_fp_violation": 0.014350195878044631,
            "ave_precision_score": 0.6494646435095605,
            "fpr": 0.18201754385964913,
            "logloss": 4.700456591408663,
            "mae": 0.35705657266640806,
            "precision": 0.6732283464566929,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.680798243515403,
            "auditor_fn_violation": 0.013815480882217828,
            "auditor_fp_violation": 0.019427036920497593,
            "ave_precision_score": 0.6406415151651315,
            "fpr": 0.18441273326015367,
            "logloss": 4.387099686868779,
            "mae": 0.3420061350794817,
            "precision": 0.6492693110647182,
            "recall": 0.6850220264317181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8496114797566718,
            "auditor_fn_violation": 0.010692982456140358,
            "auditor_fp_violation": 0.01195494804973599,
            "ave_precision_score": 0.8312172576821424,
            "fpr": 0.13486842105263158,
            "logloss": 2.0635156897454907,
            "mae": 0.2457408189864374,
            "precision": 0.764367816091954,
            "recall": 0.798
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8852057966429336,
            "auditor_fn_violation": 0.004393197193382884,
            "auditor_fp_violation": 0.0070185214987257575,
            "ave_precision_score": 0.8757955321765161,
            "fpr": 0.12184412733260154,
            "logloss": 1.4094452773383985,
            "mae": 0.20492057518281875,
            "precision": 0.774390243902439,
            "recall": 0.8392070484581498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.738951446666372,
            "auditor_fn_violation": 0.015657894736842114,
            "auditor_fp_violation": 0.021099471980923195,
            "ave_precision_score": 0.7400465127541157,
            "fpr": 0.14035087719298245,
            "logloss": 2.0159387796572714,
            "mae": 0.3340679907429528,
            "precision": 0.7276595744680852,
            "recall": 0.684
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7634846112756003,
            "auditor_fn_violation": 0.01889534180863359,
            "auditor_fp_violation": 0.01934537034590598,
            "ave_precision_score": 0.7644130558121518,
            "fpr": 0.1437980241492865,
            "logloss": 1.5358836451576316,
            "mae": 0.2937140053508596,
            "precision": 0.7164502164502164,
            "recall": 0.7290748898678414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7819199527209528,
            "auditor_fn_violation": 0.019166666666666672,
            "auditor_fp_violation": 0.01562233861352411,
            "ave_precision_score": 0.7834307077090487,
            "fpr": 0.1524122807017544,
            "logloss": 1.1033120776076766,
            "mae": 0.29781202893843517,
            "precision": 0.734225621414914,
            "recall": 0.768
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.78360074244384,
            "auditor_fn_violation": 0.009511743400532893,
            "auditor_fp_violation": 0.01363111208256971,
            "ave_precision_score": 0.783676578108387,
            "fpr": 0.15916575192096596,
            "logloss": 0.9543115723006924,
            "mae": 0.2684644266178591,
            "precision": 0.7184466019417476,
            "recall": 0.8149779735682819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7739316824029242,
            "auditor_fn_violation": 0.019359649122807018,
            "auditor_fp_violation": 0.025525357690342372,
            "ave_precision_score": 0.7622355419063067,
            "fpr": 0.1962719298245614,
            "logloss": 1.640080467830825,
            "mae": 0.3022768452700964,
            "precision": 0.694017094017094,
            "recall": 0.812
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.795312526316494,
            "auditor_fn_violation": 0.012708114721200018,
            "auditor_fp_violation": 0.020757721694725544,
            "ave_precision_score": 0.7872421422155181,
            "fpr": 0.18660812294182216,
            "logloss": 1.3069400460333314,
            "mae": 0.26753330768513084,
            "precision": 0.6980461811722913,
            "recall": 0.8656387665198237
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.8100811520951353,
            "auditor_fn_violation": 0.019958333333333335,
            "auditor_fp_violation": 0.028072304547777212,
            "ave_precision_score": 0.8100955144302661,
            "fpr": 0.20175438596491227,
            "logloss": 1.33028388897993,
            "mae": 0.295680227329046,
            "precision": 0.6917922948073701,
            "recall": 0.826
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.830395511394406,
            "auditor_fn_violation": 0.015135616087273998,
            "auditor_fp_violation": 0.03669471353047004,
            "ave_precision_score": 0.8305368765004495,
            "fpr": 0.19978046103183314,
            "logloss": 1.1339132222035737,
            "mae": 0.2709952678185607,
            "precision": 0.6829268292682927,
            "recall": 0.8634361233480177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7886283328721786,
            "auditor_fn_violation": 0.0036688596491228176,
            "auditor_fp_violation": 0.008559018906489534,
            "ave_precision_score": 0.7547724429680985,
            "fpr": 0.14473684210526316,
            "logloss": 3.9511169444676235,
            "mae": 0.29490045774288887,
            "precision": 0.7311608961303462,
            "recall": 0.718
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.80401150169709,
            "auditor_fn_violation": 0.006963350532164394,
            "auditor_fp_violation": 0.007323570174406181,
            "ave_precision_score": 0.7739707300529644,
            "fpr": 0.13391877058177826,
            "logloss": 3.387323854691744,
            "mae": 0.2682396542368874,
            "precision": 0.7300884955752213,
            "recall": 0.7268722466960352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7835970125399351,
            "auditor_fn_violation": 0.010482456140350883,
            "auditor_fp_violation": 0.011018140010219727,
            "ave_precision_score": 0.7841627553585244,
            "fpr": 0.16666666666666666,
            "logloss": 1.848793265805291,
            "mae": 0.3214624619059143,
            "precision": 0.7142857142857143,
            "recall": 0.76
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8137299746133955,
            "auditor_fn_violation": 0.0037186226105794594,
            "auditor_fp_violation": 0.012266799895274634,
            "ave_precision_score": 0.8142821544279363,
            "fpr": 0.15477497255762898,
            "logloss": 1.380281953381756,
            "mae": 0.2812190573951868,
            "precision": 0.7272727272727273,
            "recall": 0.8281938325991189
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8351627005672034,
            "auditor_fn_violation": 0.009673245614035094,
            "auditor_fp_violation": 0.0045988758303525815,
            "ave_precision_score": 0.8306394440283162,
            "fpr": 0.08771929824561403,
            "logloss": 1.8246417852726453,
            "mae": 0.256833978810869,
            "precision": 0.8126463700234192,
            "recall": 0.694
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.861798595053286,
            "auditor_fn_violation": 0.010171811003060974,
            "auditor_fp_violation": 0.011385281281300515,
            "ave_precision_score": 0.8569757732754107,
            "fpr": 0.07464324917672886,
            "logloss": 1.3425202233420528,
            "mae": 0.21819185579629982,
            "precision": 0.8312655086848635,
            "recall": 0.737885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8079103304264829,
            "auditor_fn_violation": 0.012991228070175439,
            "auditor_fp_violation": 0.020556549139839897,
            "ave_precision_score": 0.8073743099903595,
            "fpr": 0.13157894736842105,
            "logloss": 1.3234595908045401,
            "mae": 0.2816207934753924,
            "precision": 0.7585513078470825,
            "recall": 0.754
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8200204810215942,
            "auditor_fn_violation": 0.00826414309685344,
            "auditor_fp_violation": 0.02141345624953463,
            "ave_precision_score": 0.8197422430405567,
            "fpr": 0.12843029637760703,
            "logloss": 1.0376703981279056,
            "mae": 0.2483170787840463,
            "precision": 0.7547169811320755,
            "recall": 0.7929515418502202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.794651464608068,
            "auditor_fn_violation": 0.016668859649122805,
            "auditor_fp_violation": 0.020812042241526146,
            "ave_precision_score": 0.7945565556613359,
            "fpr": 0.19298245614035087,
            "logloss": 1.4158982870248402,
            "mae": 0.300687794055759,
            "precision": 0.6949740034662045,
            "recall": 0.802
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8034360457476151,
            "auditor_fn_violation": 0.007940153870704122,
            "auditor_fp_violation": 0.017764881931750767,
            "ave_precision_score": 0.8058335796133493,
            "fpr": 0.1877058177826564,
            "logloss": 1.2043628908782238,
            "mae": 0.27329598587725434,
            "precision": 0.6918918918918919,
            "recall": 0.8458149779735683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.781917908366655,
            "auditor_fn_violation": 0.021589912280701756,
            "auditor_fp_violation": 0.01562233861352411,
            "ave_precision_score": 0.7834266252684832,
            "fpr": 0.1524122807017544,
            "logloss": 1.1093938120447806,
            "mae": 0.29767419676818274,
            "precision": 0.7337164750957854,
            "recall": 0.766
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7836810652784093,
            "auditor_fn_violation": 0.009511743400532893,
            "auditor_fp_violation": 0.01363111208256971,
            "ave_precision_score": 0.7838091076798577,
            "fpr": 0.15916575192096596,
            "logloss": 0.9596366297606606,
            "mae": 0.26830259119469935,
            "precision": 0.7184466019417476,
            "recall": 0.8149779735682819
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.8140671524974723,
            "auditor_fn_violation": 0.02212280701754386,
            "auditor_fp_violation": 0.025251234883324817,
            "ave_precision_score": 0.81419930894428,
            "fpr": 0.17982456140350878,
            "logloss": 1.1746660384894771,
            "mae": 0.2930175233188774,
            "precision": 0.7050359712230215,
            "recall": 0.784
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8280753971813438,
            "auditor_fn_violation": 0.0165718071345329,
            "auditor_fp_violation": 0.02749521409853313,
            "ave_precision_score": 0.8286704571192129,
            "fpr": 0.16575192096597147,
            "logloss": 0.9635788684081468,
            "mae": 0.25963431372527235,
            "precision": 0.7123809523809523,
            "recall": 0.8237885462555066
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 16695,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8114020436972041,
            "auditor_fn_violation": 0.017646929824561407,
            "auditor_fp_violation": 0.024713634815193335,
            "ave_precision_score": 0.8114136422083172,
            "fpr": 0.1699561403508772,
            "logloss": 1.2067403391151732,
            "mae": 0.2922969295671143,
            "precision": 0.7140221402214022,
            "recall": 0.774
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8257324018380467,
            "auditor_fn_violation": 0.011475021397795908,
            "auditor_fp_violation": 0.02415889433065836,
            "ave_precision_score": 0.826163871600615,
            "fpr": 0.15587266739846323,
            "logloss": 0.9666016546084417,
            "mae": 0.2571949831309426,
            "precision": 0.7242718446601941,
            "recall": 0.8215859030837004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8578709141213823,
            "auditor_fn_violation": 0.005557017543859654,
            "auditor_fp_violation": 0.007941577244081077,
            "ave_precision_score": 0.8339399862810944,
            "fpr": 0.11403508771929824,
            "logloss": 2.9723664641849834,
            "mae": 0.23874616616191935,
            "precision": 0.7877551020408163,
            "recall": 0.772
        },
        "train": {
            "accuracy": 0.7925356750823271,
            "auc_prc": 0.872983249060787,
            "auditor_fn_violation": 0.00418042814934453,
            "auditor_fp_violation": 0.008514941380213154,
            "ave_precision_score": 0.8519258360821482,
            "fpr": 0.10098792535675083,
            "logloss": 2.489149178926115,
            "mae": 0.21088083236566307,
            "precision": 0.7951002227171492,
            "recall": 0.7863436123348018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7575028935738058,
            "auditor_fn_violation": 0.02009868421052632,
            "auditor_fp_violation": 0.02779019758133197,
            "ave_precision_score": 0.7443564614391569,
            "fpr": 0.12171052631578948,
            "logloss": 2.882961773696307,
            "mae": 0.31897507038405937,
            "precision": 0.756578947368421,
            "recall": 0.69
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7827125788083301,
            "auditor_fn_violation": 0.018128889684086328,
            "auditor_fp_violation": 0.018341351870044462,
            "ave_precision_score": 0.7735577193329299,
            "fpr": 0.1163556531284303,
            "logloss": 2.2438477559892673,
            "mae": 0.2674741196802785,
            "precision": 0.7633928571428571,
            "recall": 0.7533039647577092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7990630161269131,
            "auditor_fn_violation": 0.012780701754385972,
            "auditor_fp_violation": 0.02326051779935276,
            "ave_precision_score": 0.7959982580540592,
            "fpr": 0.13048245614035087,
            "logloss": 1.1372898901258548,
            "mae": 0.29003457546018024,
            "precision": 0.75564681724846,
            "recall": 0.736
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8147458212080427,
            "auditor_fn_violation": 0.008459987330570561,
            "auditor_fp_violation": 0.016275667924492046,
            "ave_precision_score": 0.8122111443242616,
            "fpr": 0.12843029637760703,
            "logloss": 0.888516773329332,
            "mae": 0.2528839672374262,
            "precision": 0.7542016806722689,
            "recall": 0.7907488986784141
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8114605796806073,
            "auditor_fn_violation": 0.02610087719298246,
            "auditor_fp_violation": 0.029658490887412712,
            "ave_precision_score": 0.811472606154894,
            "fpr": 0.14802631578947367,
            "logloss": 1.2901972096942815,
            "mae": 0.2916823799662159,
            "precision": 0.734251968503937,
            "recall": 0.746
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8265729138737998,
            "auditor_fn_violation": 0.019052500761616468,
            "auditor_fp_violation": 0.031213445200527476,
            "ave_precision_score": 0.8270079568536369,
            "fpr": 0.14489571899012074,
            "logloss": 1.0480717820656447,
            "mae": 0.2538047210217555,
            "precision": 0.7317073170731707,
            "recall": 0.7929515418502202
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.782213176435014,
            "auditor_fn_violation": 0.017298245614035094,
            "auditor_fp_violation": 0.02215071963890309,
            "ave_precision_score": 0.7825263769755197,
            "fpr": 0.14583333333333334,
            "logloss": 2.1473587384404396,
            "mae": 0.3149054302666124,
            "precision": 0.7211740041928721,
            "recall": 0.688
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8045123022675745,
            "auditor_fn_violation": 0.016639506375817834,
            "auditor_fp_violation": 0.024365462725213595,
            "ave_precision_score": 0.8051939160181418,
            "fpr": 0.13611416026344675,
            "logloss": 1.6425049374288323,
            "mae": 0.2707948689904858,
            "precision": 0.7333333333333333,
            "recall": 0.751101321585903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 16695,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8611085096456865,
            "auditor_fn_violation": 0.008771929824561406,
            "auditor_fp_violation": 0.006411280020439448,
            "ave_precision_score": 0.8412114803081271,
            "fpr": 0.10635964912280702,
            "logloss": 2.714381750865789,
            "mae": 0.2438067109335916,
            "precision": 0.7944915254237288,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8839212257400028,
            "auditor_fn_violation": 0.005191081108526719,
            "auditor_fp_violation": 0.004203426633391544,
            "ave_precision_score": 0.870355827848271,
            "fpr": 0.09769484083424808,
            "logloss": 1.964435753400549,
            "mae": 0.19852926844044202,
            "precision": 0.8022222222222222,
            "recall": 0.7951541850220264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5032894736842105,
            "auc_prc": 0.795637001553092,
            "auditor_fn_violation": 0.009763157894736849,
            "auditor_fp_violation": 0.0018736160790325334,
            "ave_precision_score": 0.7952013362427441,
            "fpr": 0.013157894736842105,
            "logloss": 4.4973483077365675,
            "mae": 0.491424498925656,
            "precision": 0.8309859154929577,
            "recall": 0.118
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.8044805327960476,
            "auditor_fn_violation": 0.005256362519765769,
            "auditor_fp_violation": 0.0026853891292181386,
            "ave_precision_score": 0.8041541994361874,
            "fpr": 0.007683863885839737,
            "logloss": 4.001099811137141,
            "mae": 0.4496268667634477,
            "precision": 0.875,
            "recall": 0.10792951541850221
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7866211136451322,
            "auditor_fn_violation": 0.04952850877192983,
            "auditor_fp_violation": 0.04840529722364163,
            "ave_precision_score": 0.7837533895337885,
            "fpr": 0.16228070175438597,
            "logloss": 1.94329347686133,
            "mae": 0.30790843551810665,
            "precision": 0.7159309021113244,
            "recall": 0.746
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7906633559386262,
            "auditor_fn_violation": 0.041620526409957594,
            "auditor_fp_violation": 0.048610827546616,
            "ave_precision_score": 0.7904973097202762,
            "fpr": 0.17014270032930845,
            "logloss": 1.6054673039884264,
            "mae": 0.28151972656139945,
            "precision": 0.6978557504873294,
            "recall": 0.788546255506608
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 16695,
        "test": {
            "accuracy": 0.2993421052631579,
            "auc_prc": 0.4008754097811822,
            "auditor_fn_violation": 0.010600877192982458,
            "auditor_fp_violation": 0.011646227218531778,
            "ave_precision_score": 0.4018678775455171,
            "fpr": 0.29385964912280704,
            "logloss": 6.165378308946323,
            "mae": 0.6944092775431585,
            "precision": 0.3249370277078086,
            "recall": 0.258
        },
        "train": {
            "accuracy": 0.283205268935236,
            "auc_prc": 0.3473729404807932,
            "auditor_fn_violation": 0.007531540592948653,
            "auditor_fp_violation": 0.01897066488601508,
            "ave_precision_score": 0.3473965484481868,
            "fpr": 0.3446761800219539,
            "logloss": 6.68499730127948,
            "mae": 0.7123622933251469,
            "precision": 0.2680652680652681,
            "recall": 0.2533039647577093
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8040142420455455,
            "auditor_fn_violation": 0.015978070175438595,
            "auditor_fp_violation": 0.027071623232839386,
            "ave_precision_score": 0.8044203620697639,
            "fpr": 0.18311403508771928,
            "logloss": 1.1536849698498204,
            "mae": 0.3001975521719038,
            "precision": 0.7023172905525846,
            "recall": 0.788
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8080814428717064,
            "auditor_fn_violation": 0.005860820031238366,
            "auditor_fp_violation": 0.017702431021768945,
            "ave_precision_score": 0.8086359090300115,
            "fpr": 0.1800219538968167,
            "logloss": 0.9753211324594097,
            "mae": 0.2735540594363568,
            "precision": 0.6974169741697417,
            "recall": 0.8325991189427313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8375895046778805,
            "auditor_fn_violation": 0.011217105263157902,
            "auditor_fp_violation": 0.010810551865099641,
            "ave_precision_score": 0.8238442828138048,
            "fpr": 0.12938596491228072,
            "logloss": 1.7423398021924426,
            "mae": 0.24870267948433072,
            "precision": 0.7699805068226121,
            "recall": 0.79
        },
        "train": {
            "accuracy": 0.7947310647639956,
            "auc_prc": 0.8717303198220409,
            "auditor_fn_violation": 0.006242837178489048,
            "auditor_fp_violation": 0.008538960960975388,
            "ave_precision_score": 0.8637663426200638,
            "fpr": 0.12184412733260154,
            "logloss": 1.1953429398065492,
            "mae": 0.21151971376317966,
            "precision": 0.7730061349693251,
            "recall": 0.8325991189427313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7718323172208429,
            "auditor_fn_violation": 0.010471491228070179,
            "auditor_fp_violation": 0.020902529381706704,
            "ave_precision_score": 0.7594060029912977,
            "fpr": 0.1611842105263158,
            "logloss": 2.068191129786863,
            "mae": 0.3028501134441874,
            "precision": 0.7236842105263158,
            "recall": 0.77
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.795580030650549,
            "auditor_fn_violation": 0.006849712520007545,
            "auditor_fp_violation": 0.025021197280022684,
            "ave_precision_score": 0.7864147751998101,
            "fpr": 0.15916575192096596,
            "logloss": 1.483141549091599,
            "mae": 0.26572512751401084,
            "precision": 0.7178988326848249,
            "recall": 0.8127753303964758
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6644736842105263,
            "auc_prc": 0.736152002054024,
            "auditor_fn_violation": 0.021517543859649133,
            "auditor_fp_violation": 0.02345479901209334,
            "ave_precision_score": 0.7378594627829913,
            "fpr": 0.18311403508771928,
            "logloss": 1.443764375035443,
            "mae": 0.3337447401466683,
            "precision": 0.6837121212121212,
            "recall": 0.722
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7020159393200803,
            "auditor_fn_violation": 0.021847512294665788,
            "auditor_fp_violation": 0.02121409372920805,
            "ave_precision_score": 0.7042028537271392,
            "fpr": 0.18660812294182216,
            "logloss": 1.2804973971327858,
            "mae": 0.31154096619071203,
            "precision": 0.6699029126213593,
            "recall": 0.7599118942731278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8127939333370379,
            "auditor_fn_violation": 0.011565789473684212,
            "auditor_fp_violation": 0.01998168966104582,
            "ave_precision_score": 0.8130551793775933,
            "fpr": 0.17653508771929824,
            "logloss": 1.2456069838939452,
            "mae": 0.2944518193117791,
            "precision": 0.7140319715808171,
            "recall": 0.804
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8244324017506561,
            "auditor_fn_violation": 0.0030488836878678166,
            "auditor_fp_violation": 0.023548796979297525,
            "ave_precision_score": 0.8243375154040076,
            "fpr": 0.1778265642151482,
            "logloss": 0.9847820072781506,
            "mae": 0.26552200150992583,
            "precision": 0.7005545286506469,
            "recall": 0.8348017621145375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5263157894736842,
            "auc_prc": 0.6212841103277431,
            "auditor_fn_violation": 0.006394736842105284,
            "auditor_fp_violation": 0.00714582268778743,
            "ave_precision_score": 0.6231790154133613,
            "fpr": 0.047149122807017545,
            "logloss": 7.694462504902621,
            "mae": 0.48005121962139274,
            "precision": 0.7207792207792207,
            "recall": 0.222
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5875188403967708,
            "auditor_fn_violation": 0.008520433081717826,
            "auditor_fp_violation": 0.003701417395460781,
            "ave_precision_score": 0.5899344247961572,
            "fpr": 0.05598243688254665,
            "logloss": 7.421352417554984,
            "mae": 0.4432233514178398,
            "precision": 0.6666666666666666,
            "recall": 0.22466960352422907
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8206247804312743,
            "auditor_fn_violation": 0.009539473684210532,
            "auditor_fp_violation": 0.016436722875149037,
            "ave_precision_score": 0.8209770903696681,
            "fpr": 0.12280701754385964,
            "logloss": 1.7102587176500115,
            "mae": 0.3109742790178603,
            "precision": 0.7575757575757576,
            "recall": 0.7
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8382602219991394,
            "auditor_fn_violation": 0.005884998331697271,
            "auditor_fp_violation": 0.013996209710155723,
            "ave_precision_score": 0.8396601241247659,
            "fpr": 0.1163556531284303,
            "logloss": 1.274086275366766,
            "mae": 0.2690030198806014,
            "precision": 0.7633928571428571,
            "recall": 0.7533039647577092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 16695,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6812184449761496,
            "auditor_fn_violation": 0.026589912280701764,
            "auditor_fp_violation": 0.007483818770226539,
            "ave_precision_score": 0.6819978171173011,
            "fpr": 0.08881578947368421,
            "logloss": 2.2208576016732153,
            "mae": 0.42908930466148926,
            "precision": 0.7065217391304348,
            "recall": 0.39
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.6411603077353327,
            "auditor_fn_violation": 0.01920240622446168,
            "auditor_fp_violation": 0.001686174569509071,
            "ave_precision_score": 0.6427498507585617,
            "fpr": 0.0845225027442371,
            "logloss": 1.8653614972980188,
            "mae": 0.3899782870906918,
            "precision": 0.7137546468401487,
            "recall": 0.42290748898678415
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7932116105318423,
            "auditor_fn_violation": 0.010219298245614038,
            "auditor_fp_violation": 0.022161365184806683,
            "ave_precision_score": 0.7912131222237477,
            "fpr": 0.21162280701754385,
            "logloss": 1.535509053471054,
            "mae": 0.2995020894033193,
            "precision": 0.6851549755301795,
            "recall": 0.84
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8104694223702008,
            "auditor_fn_violation": 0.00898465645052878,
            "auditor_fp_violation": 0.02275134689799124,
            "ave_precision_score": 0.8091227889706186,
            "fpr": 0.22283205268935236,
            "logloss": 1.294281742860833,
            "mae": 0.2829376049117316,
            "precision": 0.6639072847682119,
            "recall": 0.8832599118942731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7555550634504592,
            "auditor_fn_violation": 0.012719298245614036,
            "auditor_fp_violation": 0.02166900868676546,
            "ave_precision_score": 0.7553349193003001,
            "fpr": 0.23574561403508773,
            "logloss": 1.5404656487707509,
            "mae": 0.3220457923599196,
            "precision": 0.6640625,
            "recall": 0.85
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7468340040575989,
            "auditor_fn_violation": 0.012521941807666456,
            "auditor_fp_violation": 0.02333021879436117,
            "ave_precision_score": 0.7459601762382069,
            "fpr": 0.24698133918770582,
            "logloss": 1.4829833596546753,
            "mae": 0.313892366190754,
            "precision": 0.6394230769230769,
            "recall": 0.8788546255506607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8537596321096497,
            "auditor_fn_violation": 0.011842105263157897,
            "auditor_fp_violation": 0.013605007664793051,
            "ave_precision_score": 0.8350960475357982,
            "fpr": 0.12719298245614036,
            "logloss": 2.0909133182645423,
            "mae": 0.24336264957407192,
            "precision": 0.7729941291585127,
            "recall": 0.79
        },
        "train": {
            "accuracy": 0.8002195389681669,
            "auc_prc": 0.8860515883798767,
            "auditor_fn_violation": 0.00029497526559863385,
            "auditor_fp_violation": 0.006761511984569824,
            "ave_precision_score": 0.875652654450845,
            "fpr": 0.11964873765093303,
            "logloss": 1.4547586956867637,
            "mae": 0.2027344527912269,
            "precision": 0.7775510204081633,
            "recall": 0.8392070484581498
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.79758497956134,
            "auditor_fn_violation": 0.00635964912280702,
            "auditor_fp_violation": 0.021535939362970543,
            "ave_precision_score": 0.7956814615912882,
            "fpr": 0.26096491228070173,
            "logloss": 1.5249084446190226,
            "mae": 0.32147609552862877,
            "precision": 0.6540697674418605,
            "recall": 0.9
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.817017457044934,
            "auditor_fn_violation": 0.010885070866598645,
            "auditor_fp_violation": 0.017536695914509515,
            "ave_precision_score": 0.8149066287645058,
            "fpr": 0.27661909989023054,
            "logloss": 1.404347961839259,
            "mae": 0.31355195289273996,
            "precision": 0.6272189349112426,
            "recall": 0.933920704845815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7867043016997898,
            "auditor_fn_violation": 0.015489035087719304,
            "auditor_fp_violation": 0.01697964571623233,
            "ave_precision_score": 0.7883117041772738,
            "fpr": 0.17105263157894737,
            "logloss": 1.1643349309732556,
            "mae": 0.29477998484279244,
            "precision": 0.7189189189189189,
            "recall": 0.798
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7888525537530784,
            "auditor_fn_violation": 0.007896632929878094,
            "auditor_fp_violation": 0.02450477629363457,
            "ave_precision_score": 0.7890122284195693,
            "fpr": 0.17672886937431395,
            "logloss": 1.0253359243151985,
            "mae": 0.2700969723438503,
            "precision": 0.7024029574861368,
            "recall": 0.8370044052863436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7729373948436722,
            "auditor_fn_violation": 0.01814912280701755,
            "auditor_fp_violation": 0.014169221597683527,
            "ave_precision_score": 0.7595875676205612,
            "fpr": 0.13048245614035087,
            "logloss": 1.885128641211172,
            "mae": 0.3137692231867792,
            "precision": 0.7451820128479657,
            "recall": 0.696
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7812994766888058,
            "auditor_fn_violation": 0.01711823672490414,
            "auditor_fp_violation": 0.01661674597131582,
            "ave_precision_score": 0.7720475371510375,
            "fpr": 0.13830954994511527,
            "logloss": 1.4567149933566488,
            "mae": 0.282402298543719,
            "precision": 0.7272727272727273,
            "recall": 0.7400881057268722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8022600160365169,
            "auditor_fn_violation": 0.02278947368421053,
            "auditor_fp_violation": 0.02936839976153978,
            "ave_precision_score": 0.8016723575526903,
            "fpr": 0.20285087719298245,
            "logloss": 1.3953189512444664,
            "mae": 0.29806001698549456,
            "precision": 0.6921797004991681,
            "recall": 0.832
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.823664856702658,
            "auditor_fn_violation": 0.018547174282025368,
            "auditor_fp_violation": 0.03997338630451544,
            "ave_precision_score": 0.823149304400203,
            "fpr": 0.2030735455543359,
            "logloss": 1.1954073195601989,
            "mae": 0.2749652283799791,
            "precision": 0.6810344827586207,
            "recall": 0.8700440528634361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 16695,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8033035760881866,
            "auditor_fn_violation": 0.018460526315789472,
            "auditor_fp_violation": 0.022611139499233532,
            "ave_precision_score": 0.8053954928408805,
            "fpr": 0.19736842105263158,
            "logloss": 1.1406608978058388,
            "mae": 0.3001579479394895,
            "precision": 0.6928327645051194,
            "recall": 0.812
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8151282688697219,
            "auditor_fn_violation": 0.008430973370019875,
            "auditor_fp_violation": 0.01952791915969899,
            "ave_precision_score": 0.8160728026037887,
            "fpr": 0.18880351262349068,
            "logloss": 1.0035265271356433,
            "mae": 0.2728725721089083,
            "precision": 0.6923076923076923,
            "recall": 0.8524229074889867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 16695,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8527200872631535,
            "auditor_fn_violation": 0.01058333333333334,
            "auditor_fp_violation": 0.005897632430591043,
            "ave_precision_score": 0.8527351437674895,
            "fpr": 0.07017543859649122,
            "logloss": 1.876216053976924,
            "mae": 0.25469649620331103,
            "precision": 0.8411910669975186,
            "recall": 0.678
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8477462649453804,
            "auditor_fn_violation": 0.005399014492473304,
            "auditor_fp_violation": 0.007938471441919455,
            "ave_precision_score": 0.8478424729066707,
            "fpr": 0.059275521405049394,
            "logloss": 1.889333066247184,
            "mae": 0.23468543324696978,
            "precision": 0.8512396694214877,
            "recall": 0.6806167400881057
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 16695,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.854196914561141,
            "auditor_fn_violation": 0.011842105263157897,
            "auditor_fp_violation": 0.013232413558167266,
            "ave_precision_score": 0.8355385618165487,
            "fpr": 0.12828947368421054,
            "logloss": 2.1082091126099973,
            "mae": 0.2434441702088702,
            "precision": 0.771484375,
            "recall": 0.79
        },
        "train": {
            "accuracy": 0.7991218441273326,
            "auc_prc": 0.8861210711752872,
            "auditor_fn_violation": 0.0020213059183643886,
            "auditor_fp_violation": 0.008317980817962799,
            "ave_precision_score": 0.8757304894535608,
            "fpr": 0.11745334796926454,
            "logloss": 1.4639515593544903,
            "mae": 0.20253550864598724,
            "precision": 0.7793814432989691,
            "recall": 0.8325991189427313
        }
    }
]