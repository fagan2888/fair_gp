[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 6933,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 6933,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5840252938170669,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5333418497700562,
            "fpr": 0.047149122807017545,
            "logloss": 0.6942260719671753,
            "mae": 0.49750936619545283,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5834470818033185,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5286126139326823,
            "fpr": 0.050493962678375415,
            "logloss": 0.693915509948276,
            "mae": 0.4971561728926574,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5575891641345219,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5549014969955189,
            "fpr": 0.047149122807017545,
            "logloss": 0.6944354913431804,
            "mae": 0.49772157797818645,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5447762798791508,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5432198215292282,
            "fpr": 0.050493962678375415,
            "logloss": 0.6939833407710954,
            "mae": 0.4973515722283155,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7640721736116047,
            "auditor_fn_violation": 0.07590460526315791,
            "auditor_fp_violation": 0.01397011046133853,
            "ave_precision_score": 0.6408655330152478,
            "fpr": 0.03508771929824561,
            "logloss": 0.63692860161822,
            "mae": 0.4427182295670112,
            "precision": 0.8350515463917526,
            "recall": 0.3375
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7558403622547838,
            "auditor_fn_violation": 0.08148415753078872,
            "auditor_fp_violation": 0.02042666921204601,
            "ave_precision_score": 0.6351980121403836,
            "fpr": 0.04500548847420417,
            "logloss": 0.6381075009195967,
            "mae": 0.4386166931180085,
            "precision": 0.8127853881278538,
            "recall": 0.3755274261603376
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7461108127461511,
            "auditor_fn_violation": 0.059521198830409364,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.608264709392529,
            "fpr": 0.025219298245614034,
            "logloss": 0.6501069355081471,
            "mae": 0.4574890856614761,
            "precision": 0.8435374149659864,
            "recall": 0.25833333333333336
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7686879422998769,
            "auditor_fn_violation": 0.06785097287257941,
            "auditor_fp_violation": 0.012190190074527704,
            "ave_precision_score": 0.629062176425875,
            "fpr": 0.025246981339187707,
            "logloss": 0.632967844289869,
            "mae": 0.4463360034477305,
            "precision": 0.8662790697674418,
            "recall": 0.3143459915611814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5575891641345219,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5549014969955189,
            "fpr": 0.047149122807017545,
            "logloss": 0.6944354890702257,
            "mae": 0.49772157392611627,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5447762798791508,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5432198215292282,
            "fpr": 0.050493962678375415,
            "logloss": 0.6939833386737385,
            "mae": 0.4973515693494962,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5575891641345219,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5549014969955189,
            "fpr": 0.047149122807017545,
            "logloss": 0.6944354890364378,
            "mae": 0.4977215749391338,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5447762798791508,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5432198215292282,
            "fpr": 0.050493962678375415,
            "logloss": 0.6939833380600197,
            "mae": 0.4973515695130655,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7461108127461511,
            "auditor_fn_violation": 0.059521198830409364,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.608264709392529,
            "fpr": 0.025219298245614034,
            "logloss": 0.6501069355081471,
            "mae": 0.4574890856614761,
            "precision": 0.8435374149659864,
            "recall": 0.25833333333333336
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7686879422998769,
            "auditor_fn_violation": 0.06785097287257941,
            "auditor_fp_violation": 0.012190190074527704,
            "ave_precision_score": 0.629062176425875,
            "fpr": 0.025246981339187707,
            "logloss": 0.632967844289869,
            "mae": 0.4463360034477305,
            "precision": 0.8662790697674418,
            "recall": 0.3143459915611814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.7887694888196347,
            "auditor_fn_violation": 0.012148209064327502,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.6158700106473174,
            "fpr": 0.003289473684210526,
            "logloss": 0.6384774740859844,
            "mae": 0.4569617680094221,
            "precision": 0.9662921348314607,
            "recall": 0.17916666666666667
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.7864163102294381,
            "auditor_fn_violation": 0.0018457020846938885,
            "auditor_fp_violation": 0.0007560781397965873,
            "ave_precision_score": 0.6214250757381483,
            "fpr": 0.005488474204171241,
            "logloss": 0.6311107779115281,
            "mae": 0.45080827714713817,
            "precision": 0.9509803921568627,
            "recall": 0.20464135021097046
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5575891641345219,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5549014969955189,
            "fpr": 0.047149122807017545,
            "logloss": 0.6944354893287139,
            "mae": 0.4977215752005577,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.5447762798791508,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5432198215292282,
            "fpr": 0.050493962678375415,
            "logloss": 0.6939833382660775,
            "mae": 0.49735156954577936,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7472947042437174,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6095246562351825,
            "fpr": 0.025219298245614034,
            "logloss": 0.6496357926441332,
            "mae": 0.4558981877277818,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7292317462442796,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6296852032672318,
            "fpr": 0.026344676180021953,
            "logloss": 0.632123666005868,
            "mae": 0.4438870234167537,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 6933,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7845473019506293,
            "mae": 0.5071763975643798,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.778250316126259,
            "mae": 0.5046802539660562,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 6933,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5575891641345219,
            "auditor_fn_violation": 0.00810261330409358,
            "auditor_fp_violation": 0.010873538011695908,
            "ave_precision_score": 0.5549014969955189,
            "fpr": 0.06578947368421052,
            "logloss": 0.6941566067641427,
            "mae": 0.49739413662699233,
            "precision": 0.5488721804511278,
            "recall": 0.15208333333333332
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5447762798791508,
            "auditor_fn_violation": 0.007920076699690148,
            "auditor_fp_violation": 0.005267428103499815,
            "ave_precision_score": 0.5432198215292282,
            "fpr": 0.07135016465422613,
            "logloss": 0.6938534259445093,
            "mae": 0.497079749629474,
            "precision": 0.5255474452554745,
            "recall": 0.1518987341772152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6479321143261849,
            "auditor_fn_violation": 0.005957602339181292,
            "auditor_fp_violation": 0.0017361111111111112,
            "ave_precision_score": 0.6012348524407151,
            "fpr": 0.003289473684210526,
            "logloss": 0.6501918621208714,
            "mae": 0.46678158150691734,
            "precision": 0.9620253164556962,
            "recall": 0.15833333333333333
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6620801617606322,
            "auditor_fn_violation": 0.0001250538426266913,
            "auditor_fp_violation": 0.0007560781397965873,
            "ave_precision_score": 0.6039390366409407,
            "fpr": 0.005488474204171241,
            "logloss": 0.6473090284800709,
            "mae": 0.4633048202936526,
            "precision": 0.9438202247191011,
            "recall": 0.17721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7461108127461511,
            "auditor_fn_violation": 0.059521198830409364,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.608264709392529,
            "fpr": 0.025219298245614034,
            "logloss": 0.6501069355081471,
            "mae": 0.4574890856614761,
            "precision": 0.8435374149659864,
            "recall": 0.25833333333333336
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7686879422998769,
            "auditor_fn_violation": 0.06785097287257941,
            "auditor_fp_violation": 0.012190190074527704,
            "ave_precision_score": 0.629062176425875,
            "fpr": 0.025246981339187707,
            "logloss": 0.632967844289869,
            "mae": 0.4463360034477305,
            "precision": 0.8662790697674418,
            "recall": 0.3143459915611814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.566744967473534,
            "auditor_fn_violation": 0.006962719298245613,
            "auditor_fp_violation": 0.022148107537361926,
            "ave_precision_score": 0.5641026250689509,
            "fpr": 0.0581140350877193,
            "logloss": 0.719456941622601,
            "mae": 0.4922685100321184,
            "precision": 0.5954198473282443,
            "recall": 0.1625
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5572311931346687,
            "auditor_fn_violation": 0.00472888790080915,
            "auditor_fp_violation": 0.017804258654080436,
            "ave_precision_score": 0.5557707338992932,
            "fpr": 0.059275521405049394,
            "logloss": 0.7137032603572869,
            "mae": 0.49397798188431463,
            "precision": 0.578125,
            "recall": 0.15611814345991562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.5961350517443458,
            "auditor_fn_violation": 0.014473684210526323,
            "auditor_fp_violation": 0.0001421377517868749,
            "ave_precision_score": 0.48892358581826234,
            "fpr": 0.008771929824561403,
            "logloss": 0.8368391594255029,
            "mae": 0.5212646964937449,
            "precision": 0.8,
            "recall": 0.06666666666666667
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.6336219574510056,
            "auditor_fn_violation": 0.02027724900072718,
            "auditor_fp_violation": 0.0020999379563785615,
            "ave_precision_score": 0.5038320210698322,
            "fpr": 0.0043907793633369925,
            "logloss": 0.8105382990583208,
            "mae": 0.5106164018422136,
            "precision": 0.9166666666666666,
            "recall": 0.09282700421940929
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8557661197079415,
            "auditor_fn_violation": 0.00705409356725147,
            "auditor_fp_violation": 0.017500710688758934,
            "ave_precision_score": 0.8560383371720196,
            "fpr": 0.10416666666666667,
            "logloss": 0.891215659261906,
            "mae": 0.26543849638289646,
            "precision": 0.7907488986784141,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8419575939582822,
            "auditor_fn_violation": 0.006407851528667435,
            "auditor_fp_violation": 0.01065793869487349,
            "ave_precision_score": 0.842757002686498,
            "fpr": 0.09330406147091108,
            "logloss": 0.8762987590916009,
            "mae": 0.2563879046246748,
            "precision": 0.8094170403587444,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7536787032033531,
            "auditor_fn_violation": 0.049255299707602354,
            "auditor_fp_violation": 0.0035306002274204037,
            "ave_precision_score": 0.6059776422852448,
            "fpr": 0.01206140350877193,
            "logloss": 0.6648696617680646,
            "mae": 0.4566496586909093,
            "precision": 0.9035087719298246,
            "recall": 0.21458333333333332
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7722913773189379,
            "auditor_fn_violation": 0.05813614195000625,
            "auditor_fp_violation": 0.004679646426714426,
            "ave_precision_score": 0.6261191806740471,
            "fpr": 0.010976948408342482,
            "logloss": 0.648971840238444,
            "mae": 0.4453273696986433,
            "precision": 0.9264705882352942,
            "recall": 0.26582278481012656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7290788198804045,
            "auditor_fn_violation": 0.050913742690058494,
            "auditor_fp_violation": 0.012914230019493177,
            "ave_precision_score": 0.7190393818367639,
            "fpr": 0.05263157894736842,
            "logloss": 0.762381851515049,
            "mae": 0.4089251329998018,
            "precision": 0.8285714285714286,
            "recall": 0.48333333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.73393149912587,
            "auditor_fn_violation": 0.051355444705359264,
            "auditor_fp_violation": 0.013350682103052697,
            "ave_precision_score": 0.7170723789476041,
            "fpr": 0.06476399560922064,
            "logloss": 0.7399355160361178,
            "mae": 0.41079148696200013,
            "precision": 0.802675585284281,
            "recall": 0.5063291139240507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7630903705731087,
            "auditor_fn_violation": 0.007798793859649121,
            "auditor_fp_violation": 0.015685916179337234,
            "ave_precision_score": 0.7603237134818192,
            "fpr": 0.10307017543859649,
            "logloss": 0.6379997787270455,
            "mae": 0.43044624110454793,
            "precision": 0.7352112676056338,
            "recall": 0.54375
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7395276500039237,
            "auditor_fn_violation": 0.03429254262251803,
            "auditor_fp_violation": 0.01767866427869895,
            "ave_precision_score": 0.7358852619117796,
            "fpr": 0.10098792535675083,
            "logloss": 0.6073244523108791,
            "mae": 0.42879635422579787,
            "precision": 0.7325581395348837,
            "recall": 0.5316455696202531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.739170146603636,
            "auditor_fn_violation": 0.050913742690058494,
            "auditor_fp_violation": 0.011365943794671866,
            "ave_precision_score": 0.7201962019582633,
            "fpr": 0.0537280701754386,
            "logloss": 0.7633167366042837,
            "mae": 0.4097056051120436,
            "precision": 0.8256227758007118,
            "recall": 0.48333333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7342591703560775,
            "auditor_fn_violation": 0.051355444705359264,
            "auditor_fp_violation": 0.013350682103052697,
            "ave_precision_score": 0.7165530222195622,
            "fpr": 0.06476399560922064,
            "logloss": 0.7412311780577557,
            "mae": 0.4114474679908587,
            "precision": 0.802675585284281,
            "recall": 0.5063291139240507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.7341301776739911,
            "auditor_fn_violation": 0.010265899122807025,
            "auditor_fp_violation": 0.0022107496751137103,
            "ave_precision_score": 0.6216293711491133,
            "fpr": 0.020833333333333332,
            "logloss": 0.6485443908965669,
            "mae": 0.465638890699075,
            "precision": 0.8272727272727273,
            "recall": 0.18958333333333333
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7505475350251791,
            "auditor_fn_violation": 0.004749730207913598,
            "auditor_fp_violation": 0.0026374818830113512,
            "ave_precision_score": 0.6261850995319579,
            "fpr": 0.018660812294182216,
            "logloss": 0.6439608899273265,
            "mae": 0.4613241146673355,
            "precision": 0.8583333333333333,
            "recall": 0.21729957805907174
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7630903705731087,
            "auditor_fn_violation": 0.007798793859649121,
            "auditor_fp_violation": 0.015685916179337234,
            "ave_precision_score": 0.7603237134818192,
            "fpr": 0.10307017543859649,
            "logloss": 0.637999589800002,
            "mae": 0.43044620937422484,
            "precision": 0.7352112676056338,
            "recall": 0.54375
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7395276500039237,
            "auditor_fn_violation": 0.03429254262251803,
            "auditor_fp_violation": 0.01767866427869895,
            "ave_precision_score": 0.7358852619117796,
            "fpr": 0.10098792535675083,
            "logloss": 0.6073244334520177,
            "mae": 0.4287963237037718,
            "precision": 0.7325581395348837,
            "recall": 0.5316455696202531
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7209678627441504,
            "auditor_fn_violation": 0.0042397660818713585,
            "auditor_fp_violation": 0.0003654970760233918,
            "ave_precision_score": 0.7173328861431935,
            "fpr": 0.02631578947368421,
            "logloss": 0.6771382947677793,
            "mae": 0.44969285721874863,
            "precision": 0.8235294117647058,
            "recall": 0.23333333333333334
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7559348711523558,
            "auditor_fn_violation": 0.004008670399755462,
            "auditor_fp_violation": 0.0050463820028283845,
            "ave_precision_score": 0.746658949186138,
            "fpr": 0.019758507135016465,
            "logloss": 0.6194199278132315,
            "mae": 0.43806435262937843,
            "precision": 0.8625954198473282,
            "recall": 0.23839662447257384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 6933,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.5840252938170669,
            "auditor_fn_violation": 0.006853070175438604,
            "auditor_fp_violation": 0.0255289554905783,
            "ave_precision_score": 0.5333418497700562,
            "fpr": 0.047149122807017545,
            "logloss": 0.6941709703833021,
            "mae": 0.49746234822822244,
            "precision": 0.5825242718446602,
            "recall": 0.125
        },
        "train": {
            "accuracy": 0.4994511525795829,
            "auc_prc": 0.583694364707023,
            "auditor_fn_violation": 0.007234596377143863,
            "auditor_fp_violation": 0.02357155237159859,
            "ave_precision_score": 0.5291071797400911,
            "fpr": 0.050493962678375415,
            "logloss": 0.6938467540019464,
            "mae": 0.49709862771594304,
            "precision": 0.5818181818181818,
            "recall": 0.1350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7472947042437174,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6095246562351825,
            "fpr": 0.025219298245614034,
            "logloss": 0.649593519299062,
            "mae": 0.4558803020862111,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7292317462442796,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6296852032672318,
            "fpr": 0.026344676180021953,
            "logloss": 0.6320067048769075,
            "mae": 0.44383975624645583,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7472947042437174,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6095246562351825,
            "fpr": 0.025219298245614034,
            "logloss": 0.649593519299062,
            "mae": 0.4558803020862111,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7292317462442796,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6296852032672318,
            "fpr": 0.026344676180021953,
            "logloss": 0.6320067048769075,
            "mae": 0.44383975624645583,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.7416848413663183,
            "auditor_fn_violation": 0.061846673976608195,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.614423033724368,
            "fpr": 0.025219298245614034,
            "logloss": 0.6687657391830063,
            "mae": 0.47490216772023003,
            "precision": 0.8506493506493507,
            "recall": 0.27291666666666664
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7704713527985574,
            "auditor_fn_violation": 0.07067163176738132,
            "auditor_fp_violation": 0.013250206602747503,
            "ave_precision_score": 0.6452469247081292,
            "fpr": 0.027442371020856202,
            "logloss": 0.6426072063514289,
            "mae": 0.46011204662621347,
            "precision": 0.8611111111111112,
            "recall": 0.3270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7457760543449911,
            "auditor_fn_violation": 0.0019188596491228071,
            "auditor_fp_violation": 0.004721003898635477,
            "ave_precision_score": 0.7182610088745321,
            "fpr": 0.4418859649122807,
            "logloss": 0.6934634516976999,
            "mae": 0.4232606091854952,
            "precision": 0.5383734249713631,
            "recall": 0.9791666666666666
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7566546839154841,
            "auditor_fn_violation": 0.0011162213360382017,
            "auditor_fp_violation": 0.0012936220664293892,
            "ave_precision_score": 0.7132739027247113,
            "fpr": 0.44127332601536773,
            "logloss": 0.6685646952048191,
            "mae": 0.4209239397188871,
            "precision": 0.5373993095512083,
            "recall": 0.9852320675105485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.7209678627441504,
            "auditor_fn_violation": 0.0042397660818713585,
            "auditor_fp_violation": 0.0003654970760233918,
            "ave_precision_score": 0.7173328861431935,
            "fpr": 0.02631578947368421,
            "logloss": 0.6771372366926445,
            "mae": 0.449693722188672,
            "precision": 0.8235294117647058,
            "recall": 0.23333333333333334
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.7559348711523558,
            "auditor_fn_violation": 0.004008670399755462,
            "auditor_fp_violation": 0.0050463820028283845,
            "ave_precision_score": 0.746658949186138,
            "fpr": 0.019758507135016465,
            "logloss": 0.6194200599131339,
            "mae": 0.4380654979496264,
            "precision": 0.8625954198473282,
            "recall": 0.23839662447257384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5010964912280702,
            "auc_prc": 0.566744967473534,
            "auditor_fn_violation": 0.006962719298245613,
            "auditor_fp_violation": 0.022148107537361926,
            "ave_precision_score": 0.5641026250689509,
            "fpr": 0.0581140350877193,
            "logloss": 0.7194569144230757,
            "mae": 0.4922685129077811,
            "precision": 0.5954198473282443,
            "recall": 0.1625
        },
        "train": {
            "accuracy": 0.5016465422612514,
            "auc_prc": 0.5572311931346687,
            "auditor_fn_violation": 0.00472888790080915,
            "auditor_fp_violation": 0.017804258654080436,
            "ave_precision_score": 0.5557707338992932,
            "fpr": 0.059275521405049394,
            "logloss": 0.7137032467919189,
            "mae": 0.49397798554826644,
            "precision": 0.578125,
            "recall": 0.15611814345991562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.758938225691907,
            "auditor_fn_violation": 0.04232456140350878,
            "auditor_fp_violation": 0.007634827810266411,
            "ave_precision_score": 0.7447570793974091,
            "fpr": 0.06140350877192982,
            "logloss": 0.5911517099239996,
            "mae": 0.4063023332048926,
            "precision": 0.8205128205128205,
            "recall": 0.5333333333333333
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7549715271388137,
            "auditor_fn_violation": 0.04059386680376274,
            "auditor_fp_violation": 0.017851984516725403,
            "ave_precision_score": 0.7414870863387288,
            "fpr": 0.07244785949506037,
            "logloss": 0.5948566242295523,
            "mae": 0.4040879280389206,
            "precision": 0.7981651376146789,
            "recall": 0.5506329113924051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7447636823957062,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6087657475671179,
            "fpr": 0.025219298245614034,
            "logloss": 0.6540576465088871,
            "mae": 0.4547288427129388,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.769240565380813,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6329819178604874,
            "fpr": 0.026344676180021953,
            "logloss": 0.631155521995765,
            "mae": 0.4410191138410935,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7571026668770687,
            "auditor_fn_violation": 0.040501644736842105,
            "auditor_fp_violation": 0.003946860786224825,
            "ave_precision_score": 0.7537846220730862,
            "fpr": 0.08442982456140351,
            "logloss": 0.6037579769312419,
            "mae": 0.4121372297308163,
            "precision": 0.7748538011695907,
            "recall": 0.5520833333333334
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.749036175331181,
            "auditor_fn_violation": 0.04083934286521512,
            "auditor_fp_violation": 0.017673640503683682,
            "ave_precision_score": 0.744825502402281,
            "fpr": 0.09879253567508232,
            "logloss": 0.6132633326054799,
            "mae": 0.41198551945968986,
            "precision": 0.7493036211699164,
            "recall": 0.5675105485232067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7290788198804045,
            "auditor_fn_violation": 0.050913742690058494,
            "auditor_fp_violation": 0.012914230019493177,
            "ave_precision_score": 0.7190393818367639,
            "fpr": 0.05263157894736842,
            "logloss": 0.7621646578602453,
            "mae": 0.40891334961246956,
            "precision": 0.8285714285714286,
            "recall": 0.48333333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.73393149912587,
            "auditor_fn_violation": 0.051355444705359264,
            "auditor_fp_violation": 0.013350682103052697,
            "ave_precision_score": 0.7170723789476041,
            "fpr": 0.06476399560922064,
            "logloss": 0.7396876626563362,
            "mae": 0.41077420033917855,
            "precision": 0.802675585284281,
            "recall": 0.5063291139240507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8608312230117379,
            "auditor_fn_violation": 0.01019736842105263,
            "auditor_fp_violation": 0.011452241715399615,
            "ave_precision_score": 0.8612201335578502,
            "fpr": 0.1074561403508772,
            "logloss": 0.9517385745724556,
            "mae": 0.25356416748197064,
            "precision": 0.7896995708154506,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8570640894002592,
            "auditor_fn_violation": 0.007118805782119157,
            "auditor_fp_violation": 0.0113989455096243,
            "ave_precision_score": 0.8572802029255169,
            "fpr": 0.10976948408342481,
            "logloss": 0.9070069139945278,
            "mae": 0.2536963141834741,
            "precision": 0.7807017543859649,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.729449946820387,
            "auditor_fn_violation": 0.050913742690058494,
            "auditor_fp_violation": 0.012914230019493177,
            "ave_precision_score": 0.7194069041332553,
            "fpr": 0.05263157894736842,
            "logloss": 0.7622652824632714,
            "mae": 0.408819095029628,
            "precision": 0.8285714285714286,
            "recall": 0.48333333333333334
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7344293078530172,
            "auditor_fn_violation": 0.051355444705359264,
            "auditor_fp_violation": 0.013350682103052697,
            "ave_precision_score": 0.7175215698154414,
            "fpr": 0.06476399560922064,
            "logloss": 0.739818412838799,
            "mae": 0.41068497503205287,
            "precision": 0.802675585284281,
            "recall": 0.5063291139240507
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7490499872579464,
            "auditor_fn_violation": 0.05189144736842107,
            "auditor_fp_violation": 0.010812621832358676,
            "ave_precision_score": 0.7491276235357945,
            "fpr": 0.0625,
            "logloss": 0.6446312225270696,
            "mae": 0.4125190472659888,
            "precision": 0.8041237113402062,
            "recall": 0.4875
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.7525620132656221,
            "auditor_fn_violation": 0.048217519580189626,
            "auditor_fp_violation": 0.008666011901323014,
            "ave_precision_score": 0.7523072279042609,
            "fpr": 0.07574094401756312,
            "logloss": 0.6037960311544699,
            "mae": 0.4065012289808849,
            "precision": 0.7802547770700637,
            "recall": 0.5168776371308017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 6933,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.6560184324112989,
            "auditor_fn_violation": 0.012383497807017562,
            "auditor_fp_violation": 0.012061403508771931,
            "ave_precision_score": 0.6126508516766381,
            "fpr": 0.07675438596491228,
            "logloss": 0.6419276675744844,
            "mae": 0.4612334646415292,
            "precision": 0.6132596685082873,
            "recall": 0.23125
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6687018676266699,
            "auditor_fn_violation": 0.004626992177187419,
            "auditor_fp_violation": 0.007578364610519286,
            "ave_precision_score": 0.6111707523534349,
            "fpr": 0.07244785949506037,
            "logloss": 0.6449436140119178,
            "mae": 0.46081468057292224,
            "precision": 0.6432432432432432,
            "recall": 0.2510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6652344094038148,
            "auditor_fn_violation": 0.003166118421052634,
            "auditor_fp_violation": 0.013487857374918786,
            "ave_precision_score": 0.6659250507414045,
            "fpr": 0.21600877192982457,
            "logloss": 0.7320263114764889,
            "mae": 0.43661706462356475,
            "precision": 0.6083499005964215,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7155542488763578,
            "auditor_fn_violation": 0.013311286804040638,
            "auditor_fp_violation": 0.013848035829563413,
            "ave_precision_score": 0.7161205137445269,
            "fpr": 0.18990120746432493,
            "logloss": 0.6814360463965833,
            "mae": 0.4049415241996465,
            "precision": 0.6490872210953347,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7438537204014211,
            "auditor_fn_violation": 0.004941063596491245,
            "auditor_fp_violation": 0.011289798570500324,
            "ave_precision_score": 0.7437034065986832,
            "fpr": 0.05043859649122807,
            "logloss": 0.7034035382481856,
            "mae": 0.42851237607891335,
            "precision": 0.7937219730941704,
            "recall": 0.36875
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7370459536966532,
            "auditor_fn_violation": 0.008408713010694437,
            "auditor_fp_violation": 0.008422358813082917,
            "ave_precision_score": 0.737064114711129,
            "fpr": 0.043907793633369926,
            "logloss": 0.6555839909564457,
            "mae": 0.4186400992758316,
            "precision": 0.812206572769953,
            "recall": 0.3649789029535865
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8607781269366104,
            "auditor_fn_violation": 0.01019736842105263,
            "auditor_fp_violation": 0.011452241715399615,
            "ave_precision_score": 0.8611662064018727,
            "fpr": 0.1074561403508772,
            "logloss": 0.9489085903038147,
            "mae": 0.25355428905146826,
            "precision": 0.7896995708154506,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8567532912008703,
            "auditor_fn_violation": 0.007118805782119157,
            "auditor_fp_violation": 0.0113989455096243,
            "ave_precision_score": 0.8569684922767753,
            "fpr": 0.10976948408342481,
            "logloss": 0.907068703348985,
            "mae": 0.2538933849322927,
            "precision": 0.7807017543859649,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5460526315789473,
            "auc_prc": 0.7024660325816519,
            "auditor_fn_violation": 0.0019188596491228071,
            "auditor_fp_violation": 0.0024061890838206674,
            "ave_precision_score": 0.6952960526016861,
            "fpr": 0.44298245614035087,
            "logloss": 0.7130336023699348,
            "mae": 0.43315016593616806,
            "precision": 0.5377574370709383,
            "recall": 0.9791666666666666
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.7399184720086479,
            "auditor_fn_violation": 0.0011162213360382017,
            "auditor_fp_violation": 0.0019090345057987002,
            "ave_precision_score": 0.7010900815897154,
            "fpr": 0.442371020856202,
            "logloss": 0.6876093016511517,
            "mae": 0.42975866616312813,
            "precision": 0.5367816091954023,
            "recall": 0.9852320675105485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7577718183544531,
            "auditor_fn_violation": 0.040501644736842105,
            "auditor_fp_violation": 0.003946860786224825,
            "ave_precision_score": 0.753609996900378,
            "fpr": 0.08442982456140351,
            "logloss": 0.6037412569871048,
            "mae": 0.41213387657741185,
            "precision": 0.7748538011695907,
            "recall": 0.5520833333333334
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7492940432827514,
            "auditor_fn_violation": 0.04083934286521512,
            "auditor_fp_violation": 0.017673640503683682,
            "ave_precision_score": 0.7444923578634359,
            "fpr": 0.09879253567508232,
            "logloss": 0.613246777752934,
            "mae": 0.41197586586263385,
            "precision": 0.7493036211699164,
            "recall": 0.5675105485232067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.7379232682605945,
            "auditor_fn_violation": 0.008669133771929826,
            "auditor_fp_violation": 0.0016447368421052637,
            "ave_precision_score": 0.7379291017323613,
            "fpr": 0.03399122807017544,
            "logloss": 0.7169073545260446,
            "mae": 0.4312163062313186,
            "precision": 0.8315217391304348,
            "recall": 0.31875
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7278497249436753,
            "auditor_fn_violation": 0.004696466534202245,
            "auditor_fp_violation": 0.00461182546400842,
            "ave_precision_score": 0.7280039230714901,
            "fpr": 0.03402854006586169,
            "logloss": 0.6704340113655287,
            "mae": 0.4221940469637257,
            "precision": 0.8418367346938775,
            "recall": 0.34810126582278483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8563461042294165,
            "auditor_fn_violation": 0.011252741228070172,
            "auditor_fp_violation": 0.01660981156595192,
            "ave_precision_score": 0.856629794918652,
            "fpr": 0.10087719298245613,
            "logloss": 0.8381944539413518,
            "mae": 0.2677763970521499,
            "precision": 0.7995642701525054,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8435103671214951,
            "auditor_fn_violation": 0.007628284400227879,
            "auditor_fp_violation": 0.01272271022614523,
            "ave_precision_score": 0.8443153684921476,
            "fpr": 0.09549945115257959,
            "logloss": 0.8251121653599605,
            "mae": 0.2599198213651972,
            "precision": 0.8066666666666666,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7534477723329872,
            "auditor_fn_violation": 0.042811129385964916,
            "auditor_fp_violation": 0.00827190951916829,
            "ave_precision_score": 0.7387864473967831,
            "fpr": 0.06469298245614036,
            "logloss": 0.5974402096852149,
            "mae": 0.41120116660992306,
            "precision": 0.8132911392405063,
            "recall": 0.5354166666666667
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.7492691681062952,
            "auditor_fn_violation": 0.04059386680376274,
            "auditor_fp_violation": 0.01668144493816989,
            "ave_precision_score": 0.7351236570236501,
            "fpr": 0.07354555433589462,
            "logloss": 0.6022169261756967,
            "mae": 0.4087145428298988,
            "precision": 0.7957317073170732,
            "recall": 0.5506329113924051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8552614277158159,
            "auditor_fn_violation": 0.003803453947368426,
            "auditor_fp_violation": 0.01640168128654971,
            "ave_precision_score": 0.8555453801980427,
            "fpr": 0.09868421052631579,
            "logloss": 0.930371664085522,
            "mae": 0.2645519179163703,
            "precision": 0.797752808988764,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8422132842715429,
            "auditor_fn_violation": 0.005395841728151474,
            "auditor_fp_violation": 0.0071965577093595435,
            "ave_precision_score": 0.8428441713940094,
            "fpr": 0.08781558726673985,
            "logloss": 0.8955611647861148,
            "mae": 0.2553977066830158,
            "precision": 0.817351598173516,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8447226850311036,
            "auditor_fn_violation": 0.006853070175438598,
            "auditor_fp_violation": 0.016193551007147502,
            "ave_precision_score": 0.8450420799437931,
            "fpr": 0.13596491228070176,
            "logloss": 0.5123784423997548,
            "mae": 0.3367049481095947,
            "precision": 0.7615384615384615,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.858772420227141,
            "auditor_fn_violation": 0.005970163079474037,
            "auditor_fp_violation": 0.0017181310552188316,
            "ave_precision_score": 0.8590674356541448,
            "fpr": 0.12952799121844127,
            "logloss": 0.5009463801913251,
            "mae": 0.3188004752403833,
            "precision": 0.76953125,
            "recall": 0.8312236286919831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8555966562572822,
            "auditor_fn_violation": 0.00705409356725147,
            "auditor_fp_violation": 0.017500710688758934,
            "ave_precision_score": 0.8558708065979129,
            "fpr": 0.10416666666666667,
            "logloss": 0.890373426605318,
            "mae": 0.265346377604639,
            "precision": 0.7907488986784141,
            "recall": 0.7479166666666667
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8419337149633179,
            "auditor_fn_violation": 0.006407851528667435,
            "auditor_fp_violation": 0.011630039160326245,
            "ave_precision_score": 0.842733215891704,
            "fpr": 0.09220636663007684,
            "logloss": 0.8759164883042152,
            "mae": 0.25632173153698334,
            "precision": 0.8112359550561797,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7447636823957062,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6087657475671179,
            "fpr": 0.025219298245614034,
            "logloss": 0.6541736826464294,
            "mae": 0.4547199374228193,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.769240565380813,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6329819178604874,
            "fpr": 0.026344676180021953,
            "logloss": 0.6312943855691233,
            "mae": 0.44102126884996956,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8447972634679315,
            "auditor_fn_violation": 0.004682931286549711,
            "auditor_fp_violation": 0.005264173164392474,
            "ave_precision_score": 0.8451191706693906,
            "fpr": 0.13925438596491227,
            "logloss": 0.5119479920683087,
            "mae": 0.33678043611758507,
            "precision": 0.758095238095238,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8583018461053045,
            "auditor_fn_violation": 0.003476033662641786,
            "auditor_fp_violation": 0.000899255727731491,
            "ave_precision_score": 0.8586006071347412,
            "fpr": 0.13062568605927552,
            "logloss": 0.50143015306005,
            "mae": 0.3191871024926439,
            "precision": 0.7684824902723736,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8609673053713465,
            "auditor_fn_violation": 0.008155153508771936,
            "auditor_fp_violation": 0.011360867446393766,
            "ave_precision_score": 0.8613549690427575,
            "fpr": 0.1074561403508772,
            "logloss": 0.9480664385965694,
            "mae": 0.2532582019922329,
            "precision": 0.7901498929336188,
            "recall": 0.76875
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8572650325870399,
            "auditor_fn_violation": 0.007906181828287182,
            "auditor_fp_violation": 0.012496640350458547,
            "ave_precision_score": 0.857479635973225,
            "fpr": 0.10976948408342481,
            "logloss": 0.9040175565799192,
            "mae": 0.2534123020260307,
            "precision": 0.7811816192560175,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8608808522533956,
            "auditor_fn_violation": 0.00860288742690059,
            "auditor_fp_violation": 0.01202079272254711,
            "ave_precision_score": 0.8613785141036729,
            "fpr": 0.11403508771929824,
            "logloss": 0.8256598648523268,
            "mae": 0.25319083622788,
            "precision": 0.7824267782426778,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8530263428295352,
            "auditor_fn_violation": 0.008392502327390958,
            "auditor_fp_violation": 0.012227868387142151,
            "ave_precision_score": 0.8533152989015449,
            "fpr": 0.11306256860592755,
            "logloss": 0.8354651174133544,
            "mae": 0.25674797576175407,
            "precision": 0.7775377969762419,
            "recall": 0.759493670886076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.7198737373737373,
            "auditor_fn_violation": 0.0652686403508772,
            "auditor_fp_violation": 0.009799890350877192,
            "ave_precision_score": 0.6137457912457912,
            "fpr": 0.029605263157894735,
            "logloss": 0.6465227585020129,
            "mae": 0.4522244710998054,
            "precision": 0.8363636363636363,
            "recall": 0.2875
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.6934075733004091,
            "auditor_fn_violation": 0.07584283974118487,
            "auditor_fp_violation": 0.016495565262605278,
            "ave_precision_score": 0.6207723497352365,
            "fpr": 0.03732162458836443,
            "logloss": 0.6374439511631756,
            "mae": 0.44235447716503584,
            "precision": 0.83,
            "recall": 0.350210970464135
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8667189604113513,
            "auditor_fn_violation": 0.018119517543859653,
            "auditor_fp_violation": 0.014894005847953216,
            "ave_precision_score": 0.8668852843488495,
            "fpr": 0.09868421052631579,
            "logloss": 0.9444502163446518,
            "mae": 0.2500026690379904,
            "precision": 0.8056155507559395,
            "recall": 0.7770833333333333
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8585129722685545,
            "auditor_fn_violation": 0.011234003529297338,
            "auditor_fp_violation": 0.016055984948770058,
            "ave_precision_score": 0.8589525753294684,
            "fpr": 0.10757409440175632,
            "logloss": 0.9022992438495255,
            "mae": 0.24921637922952974,
            "precision": 0.7874186550976139,
            "recall": 0.7658227848101266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8572784351893268,
            "auditor_fn_violation": 0.01098775584795322,
            "auditor_fp_violation": 0.016051413255360625,
            "ave_precision_score": 0.8578458016658019,
            "fpr": 0.09210526315789473,
            "logloss": 0.9712103203892418,
            "mae": 0.255648122686714,
            "precision": 0.8064516129032258,
            "recall": 0.7291666666666666
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8544098151307365,
            "auditor_fn_violation": 0.008010393363809423,
            "auditor_fp_violation": 0.006573609607467341,
            "ave_precision_score": 0.854628486902168,
            "fpr": 0.09549945115257959,
            "logloss": 0.9322072323719847,
            "mae": 0.2559958259636926,
            "precision": 0.7986111111111112,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 6933,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.6978498193831524,
            "auditor_fn_violation": 0.02665844298245615,
            "auditor_fp_violation": 0.027869152046783634,
            "ave_precision_score": 0.697079608246085,
            "fpr": 0.11513157894736842,
            "logloss": 0.6639478680234157,
            "mae": 0.43361554247246437,
            "precision": 0.6982758620689655,
            "recall": 0.50625
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.7048257799751249,
            "auditor_fn_violation": 0.033778432380608334,
            "auditor_fp_violation": 0.02427488087373495,
            "ave_precision_score": 0.7004165534025748,
            "fpr": 0.12733260153677278,
            "logloss": 0.631183473632198,
            "mae": 0.4291982054825095,
            "precision": 0.6898395721925134,
            "recall": 0.5443037974683544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.7257626068440078,
            "auditor_fn_violation": 0.0429733187134503,
            "auditor_fp_violation": 0.007599293372319689,
            "ave_precision_score": 0.7241503037631134,
            "fpr": 0.044956140350877194,
            "logloss": 0.7685148537991464,
            "mae": 0.41096847436234446,
            "precision": 0.8416988416988417,
            "recall": 0.45416666666666666
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7391833951436136,
            "auditor_fn_violation": 0.04853478581055733,
            "auditor_fp_violation": 0.013805333741933703,
            "ave_precision_score": 0.7219956156496619,
            "fpr": 0.06147091108671789,
            "logloss": 0.7499188604669257,
            "mae": 0.41150139756078236,
            "precision": 0.8068965517241379,
            "recall": 0.4936708860759494
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6621998099765193,
            "auditor_fn_violation": 0.0037691885964912302,
            "auditor_fp_violation": 0.013320337881741392,
            "ave_precision_score": 0.662899965331724,
            "fpr": 0.21929824561403508,
            "logloss": 0.7407058586017236,
            "mae": 0.43752494220449245,
            "precision": 0.6047430830039525,
            "recall": 0.6375
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7127428210026462,
            "auditor_fn_violation": 0.013311286804040638,
            "auditor_fp_violation": 0.019027547870296178,
            "ave_precision_score": 0.7133259723085897,
            "fpr": 0.1986827661909989,
            "logloss": 0.6882870140761929,
            "mae": 0.40523568568766327,
            "precision": 0.6387225548902196,
            "recall": 0.6751054852320675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.7472947042437174,
            "auditor_fn_violation": 0.06001005116959065,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.6095246562351825,
            "fpr": 0.025219298245614034,
            "logloss": 0.649593519299062,
            "mae": 0.4558803020862111,
            "precision": 0.8445945945945946,
            "recall": 0.2604166666666667
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.7292317462442796,
            "auditor_fn_violation": 0.06926130231998037,
            "auditor_fp_violation": 0.012720198338637603,
            "ave_precision_score": 0.6296852032672318,
            "fpr": 0.026344676180021953,
            "logloss": 0.6320067048769075,
            "mae": 0.44383975624645583,
            "precision": 0.8636363636363636,
            "recall": 0.3206751054852321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.825142548595271,
            "auditor_fn_violation": 0.010055738304093568,
            "auditor_fp_violation": 0.015221430311890837,
            "ave_precision_score": 0.8253380877993497,
            "fpr": 0.09758771929824561,
            "logloss": 1.1640362848693846,
            "mae": 0.2781575637753236,
            "precision": 0.7915690866510539,
            "recall": 0.7041666666666667
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8250784458034955,
            "auditor_fn_violation": 0.011653165483286784,
            "auditor_fp_violation": 0.010899079895605967,
            "ave_precision_score": 0.8252980648156116,
            "fpr": 0.10537870472008781,
            "logloss": 1.071079066385166,
            "mae": 0.2783435169612599,
            "precision": 0.7735849056603774,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 6933,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8608141479731701,
            "auditor_fn_violation": 0.00860288742690059,
            "auditor_fp_violation": 0.01622654727095517,
            "ave_precision_score": 0.861312021428911,
            "fpr": 0.11513157894736842,
            "logloss": 0.8263812020063823,
            "mae": 0.25322716745417784,
            "precision": 0.7807933194154488,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8528523389968348,
            "auditor_fn_violation": 0.009531881782434108,
            "auditor_fp_violation": 0.012227868387142151,
            "ave_precision_score": 0.8531425973949824,
            "fpr": 0.11306256860592755,
            "logloss": 0.8364913708690849,
            "mae": 0.2568475413152788,
            "precision": 0.7770562770562771,
            "recall": 0.7573839662447257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8597586388895119,
            "auditor_fn_violation": 0.013267543859649124,
            "auditor_fp_violation": 0.016297616146848607,
            "ave_precision_score": 0.8602571627475546,
            "fpr": 0.11074561403508772,
            "logloss": 0.859835727964445,
            "mae": 0.25406007558870447,
            "precision": 0.7864693446088795,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8514162877838165,
            "auditor_fn_violation": 0.0073457553483675855,
            "auditor_fp_violation": 0.00957782706659265,
            "ave_precision_score": 0.8517607704550445,
            "fpr": 0.11306256860592755,
            "logloss": 0.8540756871391296,
            "mae": 0.2571529165614552,
            "precision": 0.7765726681127982,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8285986024363929,
            "auditor_fn_violation": 0.008854166666666666,
            "auditor_fp_violation": 0.006533260233918133,
            "ave_precision_score": 0.8289655024563578,
            "fpr": 0.125,
            "logloss": 0.5329313942330939,
            "mae": 0.33641553232583493,
            "precision": 0.7682926829268293,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8540634307883366,
            "auditor_fn_violation": 0.005743213513225605,
            "auditor_fp_violation": 0.006731858520448018,
            "ave_precision_score": 0.8543851811675021,
            "fpr": 0.11306256860592755,
            "logloss": 0.5001275226439821,
            "mae": 0.3155237238099983,
            "precision": 0.7849686847599165,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8603485633457926,
            "auditor_fn_violation": 0.012006578947368429,
            "auditor_fp_violation": 0.01139132553606238,
            "ave_precision_score": 0.8608464996098575,
            "fpr": 0.10964912280701754,
            "logloss": 0.853169196912683,
            "mae": 0.2539399392498077,
            "precision": 0.7890295358649789,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8524255725131578,
            "auditor_fn_violation": 0.007053963048905318,
            "auditor_fp_violation": 0.011057328808586639,
            "ave_precision_score": 0.8527693091835247,
            "fpr": 0.1141602634467618,
            "logloss": 0.8430206314908034,
            "mae": 0.2564599466306696,
            "precision": 0.7748917748917749,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.847175748942425,
            "auditor_fn_violation": 0.007229989035087724,
            "auditor_fp_violation": 0.011048672027290448,
            "ave_precision_score": 0.8478868580381274,
            "fpr": 0.0668859649122807,
            "logloss": 0.778249102449167,
            "mae": 0.2751946749529825,
            "precision": 0.8377659574468085,
            "recall": 0.65625
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8405144343693419,
            "auditor_fn_violation": 0.012963915018966505,
            "auditor_fp_violation": 0.010743342870132906,
            "ave_precision_score": 0.8408286479596158,
            "fpr": 0.07464324917672886,
            "logloss": 0.7629186986193957,
            "mae": 0.2754140741271352,
            "precision": 0.8210526315789474,
            "recall": 0.6582278481012658
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8215422138039854,
            "auditor_fn_violation": 0.008045504385964913,
            "auditor_fp_violation": 0.009959795321637429,
            "ave_precision_score": 0.8219151778378782,
            "fpr": 0.16447368421052633,
            "logloss": 0.5324783480487484,
            "mae": 0.34502361814152654,
            "precision": 0.7262773722627737,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8462666286448992,
            "auditor_fn_violation": 0.0031819255512790232,
            "auditor_fp_violation": 0.012717686451129976,
            "ave_precision_score": 0.8465973871147328,
            "fpr": 0.1394072447859495,
            "logloss": 0.5212366370650745,
            "mae": 0.32824090939929496,
            "precision": 0.7509803921568627,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8459224409778162,
            "auditor_fn_violation": 0.0001713267543859643,
            "auditor_fp_violation": 0.010812621832358675,
            "ave_precision_score": 0.8466495701959675,
            "fpr": 0.06798245614035088,
            "logloss": 0.8177769896854596,
            "mae": 0.2756222574917118,
            "precision": 0.8355437665782494,
            "recall": 0.65625
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8398867702328711,
            "auditor_fn_violation": 0.01169948172129668,
            "auditor_fp_violation": 0.009846599029909045,
            "ave_precision_score": 0.8401992301725931,
            "fpr": 0.07793633369923161,
            "logloss": 0.7783683008279629,
            "mae": 0.27541433613725175,
            "precision": 0.8141361256544503,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8603465321687198,
            "auditor_fn_violation": 0.012006578947368429,
            "auditor_fp_violation": 0.01139132553606238,
            "ave_precision_score": 0.8608444899231102,
            "fpr": 0.10964912280701754,
            "logloss": 0.8535605667350876,
            "mae": 0.253950681924978,
            "precision": 0.7890295358649789,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8523562506885226,
            "auditor_fn_violation": 0.007053963048905318,
            "auditor_fp_violation": 0.011057328808586639,
            "ave_precision_score": 0.8527010728140512,
            "fpr": 0.1141602634467618,
            "logloss": 0.84349555952738,
            "mae": 0.25649973185764957,
            "precision": 0.7748917748917749,
            "recall": 0.7552742616033755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.6743811177036667,
            "auditor_fn_violation": 0.002741228070175451,
            "auditor_fp_violation": 0.012558885640025996,
            "ave_precision_score": 0.6750533868389854,
            "fpr": 0.21271929824561403,
            "logloss": 0.7171989099331024,
            "mae": 0.4319076373141411,
            "precision": 0.616600790513834,
            "recall": 0.65
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7242644712248013,
            "auditor_fn_violation": 0.011020948834451875,
            "auditor_fp_violation": 0.012750340988729158,
            "ave_precision_score": 0.724811151749791,
            "fpr": 0.18990120746432493,
            "logloss": 0.6704263415892848,
            "mae": 0.40087503914952377,
            "precision": 0.6512096774193549,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8282156722357986,
            "auditor_fn_violation": 0.007074652777777777,
            "auditor_fp_violation": 0.003474760396361281,
            "ave_precision_score": 0.8285828096803334,
            "fpr": 0.12609649122807018,
            "logloss": 0.5332847516674001,
            "mae": 0.3366473677861199,
            "precision": 0.7672064777327935,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8542102719364053,
            "auditor_fn_violation": 0.008698189498256194,
            "auditor_fp_violation": 0.006731858520448018,
            "ave_precision_score": 0.8545328574228224,
            "fpr": 0.11306256860592755,
            "logloss": 0.49978383598920284,
            "mae": 0.31547552839661747,
            "precision": 0.7849686847599165,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8258862644345961,
            "auditor_fn_violation": 0.008299067982456143,
            "auditor_fp_violation": 0.010543575373619234,
            "ave_precision_score": 0.82621703058413,
            "fpr": 0.18201754385964913,
            "logloss": 0.5354668590275733,
            "mae": 0.3483875755536424,
            "precision": 0.7102966841186736,
            "recall": 0.8479166666666667
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8466040098925025,
            "auditor_fn_violation": 0.011435479164640336,
            "auditor_fp_violation": 0.005511081191739909,
            "ave_precision_score": 0.8469242668569031,
            "fpr": 0.15916575192096596,
            "logloss": 0.5253076786318714,
            "mae": 0.33192328316356584,
            "precision": 0.7319778188539742,
            "recall": 0.8354430379746836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8505809023793499,
            "auditor_fn_violation": 0.010423519736842113,
            "auditor_fp_violation": 0.013584307992202728,
            "ave_precision_score": 0.8512835319709459,
            "fpr": 0.06140350877192982,
            "logloss": 0.7720533622279006,
            "mae": 0.27441958032148056,
            "precision": 0.8440111420612814,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8422062385997187,
            "auditor_fn_violation": 0.009802831774791928,
            "auditor_fp_violation": 0.007997849824293475,
            "ave_precision_score": 0.8425001724804361,
            "fpr": 0.07135016465422613,
            "logloss": 0.7695855230489828,
            "mae": 0.276345677054254,
            "precision": 0.8233695652173914,
            "recall": 0.6392405063291139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.7731936664210246,
            "auditor_fn_violation": 0.00471491228070176,
            "auditor_fp_violation": 0.0019493177387914257,
            "ave_precision_score": 0.6673742511020941,
            "fpr": 0.044956140350877194,
            "logloss": 0.6187501107462765,
            "mae": 0.4315491618033041,
            "precision": 0.8404669260700389,
            "recall": 0.45
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7882898932077405,
            "auditor_fn_violation": 0.023046960033718235,
            "auditor_fp_violation": 0.009042795027467491,
            "ave_precision_score": 0.6857526752937491,
            "fpr": 0.048298572996706916,
            "logloss": 0.6053499368398958,
            "mae": 0.4228225990262958,
            "precision": 0.8422939068100358,
            "recall": 0.4957805907172996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6548156885338713,
            "auditor_fn_violation": 0.049255299707602354,
            "auditor_fp_violation": 0.0035306002274204037,
            "ave_precision_score": 0.656205292412126,
            "fpr": 0.01206140350877193,
            "logloss": 0.6647379560750101,
            "mae": 0.4565865780439293,
            "precision": 0.9035087719298246,
            "recall": 0.21458333333333332
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6973441590051035,
            "auditor_fn_violation": 0.05813614195000625,
            "auditor_fp_violation": 0.004679646426714426,
            "ave_precision_score": 0.699104839560678,
            "fpr": 0.010976948408342482,
            "logloss": 0.6517126213177737,
            "mae": 0.4452039423397651,
            "precision": 0.9264705882352942,
            "recall": 0.26582278481012656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8448588254998419,
            "auditor_fn_violation": 0.004682931286549711,
            "auditor_fp_violation": 0.005264173164392474,
            "ave_precision_score": 0.8451811824497742,
            "fpr": 0.13925438596491227,
            "logloss": 0.5117340385792251,
            "mae": 0.33666056381235876,
            "precision": 0.758095238095238,
            "recall": 0.8291666666666667
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8584702873895402,
            "auditor_fn_violation": 0.003476033662641786,
            "auditor_fp_violation": 0.000899255727731491,
            "ave_precision_score": 0.8587664862096824,
            "fpr": 0.13062568605927552,
            "logloss": 0.5013856208224862,
            "mae": 0.31909497080880317,
            "precision": 0.7684824902723736,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8626798047249158,
            "auditor_fn_violation": 0.01308479532163743,
            "auditor_fp_violation": 0.015899122807017548,
            "ave_precision_score": 0.8630022178917905,
            "fpr": 0.10635964912280702,
            "logloss": 0.8849923185353997,
            "mae": 0.2536045170864167,
            "precision": 0.7913978494623656,
            "recall": 0.7666666666666667
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8520111325011527,
            "auditor_fn_violation": 0.008837138212285845,
            "auditor_fp_violation": 0.01247654525039751,
            "ave_precision_score": 0.8524163519369905,
            "fpr": 0.11086717892425905,
            "logloss": 0.8552829580398711,
            "mae": 0.25369054814901604,
            "precision": 0.7837259100642399,
            "recall": 0.7721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8225929028811236,
            "auditor_fn_violation": 0.01040981359649123,
            "auditor_fp_violation": 0.0071500365497076095,
            "ave_precision_score": 0.8229114456290394,
            "fpr": 0.1611842105263158,
            "logloss": 0.5317605397665092,
            "mae": 0.3440632829362486,
            "precision": 0.7267657992565055,
            "recall": 0.8145833333333333
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8384561339729734,
            "auditor_fn_violation": 0.013552131241692028,
            "auditor_fp_violation": 0.006312373306673841,
            "ave_precision_score": 0.8387850976827176,
            "fpr": 0.1437980241492865,
            "logloss": 0.5326113355842931,
            "mae": 0.33126672108147126,
            "precision": 0.7436399217221135,
            "recall": 0.8016877637130801
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.828096361181999,
            "auditor_fn_violation": 0.007074652777777777,
            "auditor_fp_violation": 0.003474760396361281,
            "ave_precision_score": 0.8284639726307351,
            "fpr": 0.12609649122807018,
            "logloss": 0.5335788059171029,
            "mae": 0.3368739363012185,
            "precision": 0.7672064777327935,
            "recall": 0.7895833333333333
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8539094275424656,
            "auditor_fn_violation": 0.008698189498256194,
            "auditor_fp_violation": 0.006731858520448018,
            "ave_precision_score": 0.8542368526332281,
            "fpr": 0.11306256860592755,
            "logloss": 0.49989959651570076,
            "mae": 0.31567187411176956,
            "precision": 0.7849686847599165,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.846299891670243,
            "auditor_fn_violation": 0.0004682931286549691,
            "auditor_fp_violation": 0.013188352826510723,
            "ave_precision_score": 0.8469939836317685,
            "fpr": 0.05592105263157895,
            "logloss": 0.7333926301279043,
            "mae": 0.2912834485873692,
            "precision": 0.8567415730337079,
            "recall": 0.6354166666666666
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8456834918119982,
            "auditor_fn_violation": 0.012352540677236037,
            "auditor_fp_violation": 0.010833770820407578,
            "ave_precision_score": 0.8460299492908856,
            "fpr": 0.06695938529088913,
            "logloss": 0.6691655001414889,
            "mae": 0.28285466589127267,
            "precision": 0.8346883468834688,
            "recall": 0.6497890295358649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8551358602136742,
            "auditor_fn_violation": 0.003803453947368426,
            "auditor_fp_violation": 0.01722658788174139,
            "ave_precision_score": 0.8554211306246903,
            "fpr": 0.09978070175438597,
            "logloss": 0.9306849257878138,
            "mae": 0.2645116805095631,
            "precision": 0.7959641255605381,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8425024449576244,
            "auditor_fn_violation": 0.004884047298142256,
            "auditor_fp_violation": 0.0071965577093595435,
            "ave_precision_score": 0.8431290420986692,
            "fpr": 0.08781558726673985,
            "logloss": 0.895961547358888,
            "mae": 0.25538812934850863,
            "precision": 0.816933638443936,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8505791476264977,
            "auditor_fn_violation": 0.010423519736842113,
            "auditor_fp_violation": 0.013584307992202728,
            "ave_precision_score": 0.8512817776828917,
            "fpr": 0.06140350877192982,
            "logloss": 0.7720621117275599,
            "mae": 0.274421892612029,
            "precision": 0.8440111420612814,
            "recall": 0.63125
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8422144310711486,
            "auditor_fn_violation": 0.009802831774791928,
            "auditor_fp_violation": 0.007997849824293475,
            "ave_precision_score": 0.8425083544093452,
            "fpr": 0.07135016465422613,
            "logloss": 0.7695772716616149,
            "mae": 0.276347294568387,
            "precision": 0.8233695652173914,
            "recall": 0.6392405063291139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 6933,
        "test": {
            "accuracy": 0.48793859649122806,
            "auc_prc": 0.5577638797697638,
            "auditor_fn_violation": 0.00810261330409358,
            "auditor_fp_violation": 0.010873538011695908,
            "ave_precision_score": 0.5552509282660029,
            "fpr": 0.06578947368421052,
            "logloss": 0.6930715548032053,
            "mae": 0.4967770106894405,
            "precision": 0.5488721804511278,
            "recall": 0.15208333333333332
        },
        "train": {
            "accuracy": 0.4884742041712404,
            "auc_prc": 0.5473375448748747,
            "auditor_fn_violation": 0.007920076699690148,
            "auditor_fp_violation": 0.00320768034724333,
            "ave_precision_score": 0.5455293636972025,
            "fpr": 0.07025246981339188,
            "logloss": 0.692372526174711,
            "mae": 0.4963602075756054,
            "precision": 0.5294117647058824,
            "recall": 0.1518987341772152
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.6006511675739453,
            "auditor_fn_violation": 0.02762701023391813,
            "auditor_fp_violation": 0.0011726364522417158,
            "ave_precision_score": 0.5101674493596996,
            "fpr": 0.010964912280701754,
            "logloss": 0.80719246262611,
            "mae": 0.5161660268183863,
            "precision": 0.8591549295774648,
            "recall": 0.12708333333333333
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6576301864921392,
            "auditor_fn_violation": 0.041369663790428314,
            "auditor_fp_violation": 0.003569392148342029,
            "ave_precision_score": 0.5614793149854114,
            "fpr": 0.007683863885839737,
            "logloss": 0.7591052636908663,
            "mae": 0.4941788273081429,
            "precision": 0.9263157894736842,
            "recall": 0.18565400843881857
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 6933,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.675065401513615,
            "auditor_fn_violation": 0.002741228070175451,
            "auditor_fp_violation": 0.012980222547108516,
            "ave_precision_score": 0.675736694427272,
            "fpr": 0.21162280701754385,
            "logloss": 0.7162805719845022,
            "mae": 0.4315718630503186,
            "precision": 0.6178217821782178,
            "recall": 0.65
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7247530192441475,
            "auditor_fn_violation": 0.011020948834451875,
            "auditor_fp_violation": 0.012750340988729158,
            "ave_precision_score": 0.725299167775801,
            "fpr": 0.18990120746432493,
            "logloss": 0.6696812799368156,
            "mae": 0.40057612959864586,
            "precision": 0.6512096774193549,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8610375896329899,
            "auditor_fn_violation": 0.00860288742690059,
            "auditor_fp_violation": 0.01099029402209227,
            "ave_precision_score": 0.8615351724365371,
            "fpr": 0.11293859649122807,
            "logloss": 0.8238284742579688,
            "mae": 0.25321623815706,
            "precision": 0.7840670859538784,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8535409103619301,
            "auditor_fn_violation": 0.008603241210335934,
            "auditor_fp_violation": 0.012227868387142151,
            "ave_precision_score": 0.853828198966835,
            "fpr": 0.11306256860592755,
            "logloss": 0.8325738279180116,
            "mae": 0.25656044968054986,
            "precision": 0.7780172413793104,
            "recall": 0.7616033755274262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8569042181961344,
            "auditor_fn_violation": 0.011451480263157897,
            "auditor_fp_violation": 0.016581891650422356,
            "ave_precision_score": 0.85748031293215,
            "fpr": 0.09320175438596491,
            "logloss": 0.9672644624451741,
            "mae": 0.25602606718455656,
            "precision": 0.805045871559633,
            "recall": 0.73125
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8549099928353384,
            "auditor_fn_violation": 0.008010393363809423,
            "auditor_fp_violation": 0.006636406795158084,
            "ave_precision_score": 0.8551175420773094,
            "fpr": 0.09769484083424808,
            "logloss": 0.9254875338095458,
            "mae": 0.2562013715187101,
            "precision": 0.7949308755760369,
            "recall": 0.7278481012658228
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.822175924924019,
            "auditor_fn_violation": 0.007483552631578948,
            "auditor_fp_violation": 0.007472384665367124,
            "ave_precision_score": 0.8225408700839356,
            "fpr": 0.16666666666666666,
            "logloss": 0.5328513032056532,
            "mae": 0.3450891987946823,
            "precision": 0.7256317689530686,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8461258850574228,
            "auditor_fn_violation": 0.0031819255512790232,
            "auditor_fp_violation": 0.010170632518393298,
            "ave_precision_score": 0.8464558973535917,
            "fpr": 0.14489571899012074,
            "logloss": 0.522194313368349,
            "mae": 0.3287494918233091,
            "precision": 0.7436893203883496,
            "recall": 0.8080168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8600649258316014,
            "auditor_fn_violation": 0.010923793859649119,
            "auditor_fp_violation": 0.017056530214424954,
            "ave_precision_score": 0.860478369590894,
            "fpr": 0.11403508771929824,
            "logloss": 0.8874869759682866,
            "mae": 0.25360538221216283,
            "precision": 0.7824267782426778,
            "recall": 0.7791666666666667
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8518712971075677,
            "auditor_fn_violation": 0.005724687018021653,
            "auditor_fp_violation": 0.01081116383283891,
            "ave_precision_score": 0.8521584867600808,
            "fpr": 0.1119648737650933,
            "logloss": 0.877344377173186,
            "mae": 0.257544414249102,
            "precision": 0.7777777777777778,
            "recall": 0.7531645569620253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8285895742670266,
            "auditor_fn_violation": 0.006167763157894739,
            "auditor_fp_violation": 0.006716008771929826,
            "ave_precision_score": 0.828954505855255,
            "fpr": 0.12828947368421054,
            "logloss": 0.5328426952597349,
            "mae": 0.3367443005381838,
            "precision": 0.7645875251509054,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8537541001622942,
            "auditor_fn_violation": 0.009152088630753057,
            "auditor_fp_violation": 0.010647891144842972,
            "ave_precision_score": 0.8540765568144704,
            "fpr": 0.1163556531284303,
            "logloss": 0.5005494642222291,
            "mae": 0.3159442143363832,
            "precision": 0.7800829875518672,
            "recall": 0.7932489451476793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8642410006970601,
            "auditor_fn_violation": 0.011773574561403514,
            "auditor_fp_violation": 0.016792560103963617,
            "ave_precision_score": 0.8645610719881018,
            "fpr": 0.11403508771929824,
            "logloss": 0.8387749020533927,
            "mae": 0.2518507943841449,
            "precision": 0.7842323651452282,
            "recall": 0.7875
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8541089151541672,
            "auditor_fn_violation": 0.008225763870555385,
            "auditor_fp_violation": 0.012936220664293776,
            "ave_precision_score": 0.8544331389845086,
            "fpr": 0.1163556531284303,
            "logloss": 0.83806476804641,
            "mae": 0.25337619987333276,
            "precision": 0.7768421052631579,
            "recall": 0.7784810126582279
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8595823307486896,
            "auditor_fn_violation": 0.010937500000000001,
            "auditor_fp_violation": 0.012140086907082525,
            "ave_precision_score": 0.8600820880759946,
            "fpr": 0.11074561403508772,
            "logloss": 0.8586190149871349,
            "mae": 0.25339456682918626,
            "precision": 0.7864693446088795,
            "recall": 0.775
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.852131023007188,
            "auditor_fn_violation": 0.005747845137026592,
            "auditor_fp_violation": 0.010472059019308881,
            "ave_precision_score": 0.8524288722656767,
            "fpr": 0.11306256860592755,
            "logloss": 0.8548495645157365,
            "mae": 0.2571529855157458,
            "precision": 0.775599128540305,
            "recall": 0.7510548523206751
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8271921807951517,
            "auditor_fn_violation": 0.008580043859649123,
            "auditor_fp_violation": 0.007523148148148154,
            "ave_precision_score": 0.827544412811327,
            "fpr": 0.17214912280701755,
            "logloss": 0.530193337263724,
            "mae": 0.34706594616834274,
            "precision": 0.7191413237924866,
            "recall": 0.8375
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8453031447430966,
            "auditor_fn_violation": 0.010064518519547767,
            "auditor_fp_violation": 0.00010298738781282879,
            "ave_precision_score": 0.8456305763211107,
            "fpr": 0.14818880351262348,
            "logloss": 0.5239830978979153,
            "mae": 0.33215146794713263,
            "precision": 0.7423664122137404,
            "recall": 0.820675105485232
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8220165116419282,
            "auditor_fn_violation": 0.008954678362573099,
            "auditor_fp_violation": 0.00810946637426901,
            "ave_precision_score": 0.8223863029424943,
            "fpr": 0.16776315789473684,
            "logloss": 0.5338706840073466,
            "mae": 0.3456309354554089,
            "precision": 0.7233273056057866,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8459923772188747,
            "auditor_fn_violation": 0.006206375893324447,
            "auditor_fp_violation": 0.009758682967142005,
            "ave_precision_score": 0.8463259868535522,
            "fpr": 0.14489571899012074,
            "logloss": 0.5221170717857105,
            "mae": 0.32927926849054207,
            "precision": 0.7451737451737451,
            "recall": 0.8143459915611815
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 6933,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.7461108127461511,
            "auditor_fn_violation": 0.059521198830409364,
            "auditor_fp_violation": 0.007919103313840156,
            "ave_precision_score": 0.608264709392529,
            "fpr": 0.025219298245614034,
            "logloss": 0.6501069355081471,
            "mae": 0.4574890856614761,
            "precision": 0.8435374149659864,
            "recall": 0.25833333333333336
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7686879422998769,
            "auditor_fn_violation": 0.06785097287257941,
            "auditor_fp_violation": 0.012190190074527704,
            "ave_precision_score": 0.629062176425875,
            "fpr": 0.025246981339187707,
            "logloss": 0.632967844289869,
            "mae": 0.4463360034477305,
            "precision": 0.8662790697674418,
            "recall": 0.3143459915611814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8473234382220798,
            "auditor_fn_violation": 0.0013020833333333343,
            "auditor_fp_violation": 0.012030945419103316,
            "ave_precision_score": 0.8480354487840545,
            "fpr": 0.06030701754385965,
            "logloss": 0.73961321766498,
            "mae": 0.28220247472445964,
            "precision": 0.8493150684931506,
            "recall": 0.6458333333333334
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8460871378314274,
            "auditor_fn_violation": 0.008371660020286515,
            "auditor_fp_violation": 0.011692836348016992,
            "ave_precision_score": 0.846384227093379,
            "fpr": 0.06915477497255763,
            "logloss": 0.6980444644290951,
            "mae": 0.2784061222002919,
            "precision": 0.8315508021390374,
            "recall": 0.6561181434599156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 6933,
        "test": {
            "accuracy": 0.7883771929824561,
            "auc_prc": 0.8675501552160599,
            "auditor_fn_violation": 0.018708881578947366,
            "auditor_fp_violation": 0.01701591942820013,
            "ave_precision_score": 0.867673831667654,
            "fpr": 0.09649122807017543,
            "logloss": 0.949126190664047,
            "mae": 0.24976363609691385,
            "precision": 0.8099352051835853,
            "recall": 0.78125
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8581621067959113,
            "auditor_fn_violation": 0.011961168466052512,
            "auditor_fp_violation": 0.01521450263371405,
            "ave_precision_score": 0.8587751999610718,
            "fpr": 0.10537870472008781,
            "logloss": 0.9061083106463285,
            "mae": 0.24883674608344064,
            "precision": 0.7917570498915402,
            "recall": 0.770042194092827
        }
    }
]