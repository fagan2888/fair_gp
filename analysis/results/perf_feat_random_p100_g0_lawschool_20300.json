[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8360154665103409,
            "auditor_fn_violation": 0.02208838031943403,
            "auditor_fp_violation": 0.02225538608992791,
            "ave_precision_score": 0.8363885494532233,
            "fpr": 0.13157894736842105,
            "logloss": 0.8153369646070975,
            "mae": 0.27498727681599194,
            "precision": 0.7575757575757576,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8289254551465471,
            "auditor_fn_violation": 0.014172828852067247,
            "auditor_fp_violation": 0.026521091422298883,
            "ave_precision_score": 0.8292892300010092,
            "fpr": 0.13172338090010977,
            "logloss": 0.818041590456301,
            "mae": 0.2651950325487476,
            "precision": 0.7484276729559748,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7049557459752296,
            "auditor_fn_violation": 0.09474041519276807,
            "auditor_fp_violation": 0.0811325374005084,
            "ave_precision_score": 0.5634771405495308,
            "fpr": 0.26206140350877194,
            "logloss": 0.6972359892210875,
            "mae": 0.4860542310532509,
            "precision": 0.5716845878136201,
            "recall": 0.6496945010183299
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.709435571904304,
            "auditor_fn_violation": 0.07733177174585638,
            "auditor_fp_violation": 0.085237964560138,
            "ave_precision_score": 0.563848103014571,
            "fpr": 0.24478594950603733,
            "logloss": 0.6852609836930145,
            "mae": 0.4785911623229049,
            "precision": 0.5831775700934579,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 20300,
        "test": {
            "accuracy": 0.44298245614035087,
            "auc_prc": 0.6014687846412538,
            "auditor_fn_violation": 0.005413227569943194,
            "auditor_fp_violation": 0.007089427845147311,
            "ave_precision_score": 0.7017935485508066,
            "fpr": 0.03289473684210526,
            "logloss": 0.7339369541518305,
            "mae": 0.47392478898951884,
            "precision": 0.3023255813953488,
            "recall": 0.026476578411405296
        },
        "train": {
            "accuracy": 0.47859495060373214,
            "auc_prc": 0.5765088092359436,
            "auditor_fn_violation": 0.0012020114131813754,
            "auditor_fp_violation": 0.004662752861847265,
            "ave_precision_score": 0.6900245870333849,
            "fpr": 0.018660812294182216,
            "logloss": 0.710022395802589,
            "mae": 0.46052887819862787,
            "precision": 0.22727272727272727,
            "recall": 0.01079913606911447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8415633857140337,
            "auditor_fn_violation": 0.012695626540893987,
            "auditor_fp_violation": 0.008209359503271242,
            "ave_precision_score": 0.8420814851813418,
            "fpr": 0.1118421052631579,
            "logloss": 0.538296479134222,
            "mae": 0.3851610090289461,
            "precision": 0.7834394904458599,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8198752241639781,
            "auditor_fn_violation": 0.01679022648550355,
            "auditor_fp_violation": 0.015350576289791444,
            "ave_precision_score": 0.8205400410588166,
            "fpr": 0.13062568605927552,
            "logloss": 0.5405158968958064,
            "mae": 0.3851769736688891,
            "precision": 0.75,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5964912280701754,
            "auc_prc": 0.7287218682515937,
            "auditor_fn_violation": 0.008921552863829646,
            "auditor_fp_violation": 0.01691617702212777,
            "ave_precision_score": 0.7289751048113664,
            "fpr": 0.14692982456140352,
            "logloss": 1.9702990980136514,
            "mae": 0.4050376049477815,
            "precision": 0.6572890025575447,
            "recall": 0.5234215885947047
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.6559000166968281,
            "auditor_fn_violation": 0.009959861827958277,
            "auditor_fp_violation": 0.029280029794574253,
            "ave_precision_score": 0.6562780612677344,
            "fpr": 0.15148188803512624,
            "logloss": 2.160159976993682,
            "mae": 0.43017958606281637,
            "precision": 0.603448275862069,
            "recall": 0.4535637149028078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.800342490398356,
            "auditor_fn_violation": 0.0038767999428306024,
            "auditor_fp_violation": 0.005138663166229115,
            "ave_precision_score": 0.7691581529367502,
            "fpr": 0.0712719298245614,
            "logloss": 0.5468762290909465,
            "mae": 0.35532604369514603,
            "precision": 0.8350253807106599,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.799539112309812,
            "auditor_fn_violation": 0.013293250480686029,
            "auditor_fp_violation": 0.00840422612513721,
            "ave_precision_score": 0.7649022525018953,
            "fpr": 0.06915477497255763,
            "logloss": 0.5301561914980978,
            "mae": 0.3468565575034244,
            "precision": 0.8328912466843501,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8607083324139827,
            "auditor_fn_violation": 0.006402526172865971,
            "auditor_fp_violation": 0.005604867275076052,
            "ave_precision_score": 0.808893018926388,
            "fpr": 0.06907894736842106,
            "logloss": 0.5064324779689575,
            "mae": 0.3345364624993843,
            "precision": 0.8372093023255814,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8499239836138917,
            "auditor_fn_violation": 0.01275270096943288,
            "auditor_fp_violation": 0.003342088756468563,
            "ave_precision_score": 0.7927648880142543,
            "fpr": 0.06805708013172337,
            "logloss": 0.5064280048482727,
            "mae": 0.3317916646158133,
            "precision": 0.8342245989304813,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.844917159293567,
            "auditor_fn_violation": 0.006806731696859257,
            "auditor_fp_violation": 0.009264178855690298,
            "ave_precision_score": 0.8372659751345709,
            "fpr": 0.06469298245614036,
            "logloss": 0.5009461557849214,
            "mae": 0.32628698678883283,
            "precision": 0.855036855036855,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8170858045103622,
            "auditor_fn_violation": 0.009905332710595006,
            "auditor_fp_violation": 0.015416732005645292,
            "ave_precision_score": 0.8066309350368717,
            "fpr": 0.08562019758507135,
            "logloss": 0.5089113316624997,
            "mae": 0.3293117465273478,
            "precision": 0.8078817733990148,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.40156519673937546,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.403336764878068,
            "fpr": 0.4616228070175439,
            "logloss": 0.6924615897402722,
            "mae": 0.49962714072643666,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.39466280181246705,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.396398250989004,
            "fpr": 0.49176728869374314,
            "logloss": 0.6929595209863086,
            "mae": 0.49987585948929436,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.761014916509836,
            "auditor_fn_violation": 0.012128398899489048,
            "auditor_fp_violation": 0.01683283327082553,
            "ave_precision_score": 0.5539623895326595,
            "fpr": 0.4144736842105263,
            "logloss": 13.975474412152897,
            "mae": 0.4393088500388618,
            "precision": 0.5558166862514688,
            "recall": 0.9633401221995926
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.7562351949657371,
            "auditor_fn_violation": 0.010846552692908608,
            "auditor_fp_violation": 0.021561862944958456,
            "ave_precision_score": 0.5426931599873963,
            "fpr": 0.4138309549945115,
            "logloss": 13.911453524850206,
            "mae": 0.444506353950871,
            "precision": 0.5430303030303031,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.6850827767409523,
            "auditor_fn_violation": 0.021706506592346457,
            "auditor_fp_violation": 0.022286639996666253,
            "ave_precision_score": 0.658181943655356,
            "fpr": 0.10526315789473684,
            "logloss": 0.8282737530609522,
            "mae": 0.4414136055550587,
            "precision": 0.7225433526011561,
            "recall": 0.5091649694501018
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.660000659330582,
            "auditor_fn_violation": 0.014106445578755473,
            "auditor_fp_violation": 0.023595538654539755,
            "ave_precision_score": 0.6268118028186139,
            "fpr": 0.1119648737650933,
            "logloss": 0.8202684055589505,
            "mae": 0.4346559205972697,
            "precision": 0.6861538461538461,
            "recall": 0.4816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7975113483995087,
            "auditor_fn_violation": 0.004104584271268803,
            "auditor_fp_violation": 0.009925719881651876,
            "ave_precision_score": 0.7844391626597643,
            "fpr": 0.10197368421052631,
            "logloss": 0.6250697228590417,
            "mae": 0.3692353607776775,
            "precision": 0.7924107142857143,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7273062122273575,
            "auditor_fn_violation": 0.005358078488737368,
            "auditor_fp_violation": 0.02185098792535676,
            "ave_precision_score": 0.72552421445344,
            "fpr": 0.13062568605927552,
            "logloss": 0.6284736310097657,
            "mae": 0.3747904602081426,
            "precision": 0.7446351931330472,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.8394664284601921,
            "auditor_fn_violation": 0.01820488083753171,
            "auditor_fp_violation": 0.02327374255115223,
            "ave_precision_score": 0.8395839738350386,
            "fpr": 0.22587719298245615,
            "logloss": 1.9824800963002893,
            "mae": 0.3413723618581109,
            "precision": 0.6583747927031509,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.8219307999888577,
            "auditor_fn_violation": 0.012050934937279666,
            "auditor_fp_violation": 0.041673200564528785,
            "ave_precision_score": 0.8219509198115673,
            "fpr": 0.23710208562019758,
            "logloss": 1.9344205281541782,
            "mae": 0.34148246743895894,
            "precision": 0.6345177664974619,
            "recall": 0.8099352051835853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8544227199363937,
            "auditor_fn_violation": 0.03291260227962983,
            "auditor_fp_violation": 0.019609221986081594,
            "ave_precision_score": 0.8494521922868802,
            "fpr": 0.11513157894736842,
            "logloss": 0.5199628947467755,
            "mae": 0.3557489785333082,
            "precision": 0.777542372881356,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8120673072140032,
            "auditor_fn_violation": 0.026245101270054274,
            "auditor_fp_violation": 0.03214187705817783,
            "ave_precision_score": 0.803425101546104,
            "fpr": 0.13391877058177826,
            "logloss": 0.5370521638341879,
            "mae": 0.35792930272911827,
            "precision": 0.7463617463617463,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.876354684844806,
            "auditor_fn_violation": 0.0032649087076142527,
            "auditor_fp_violation": 0.007813476684585574,
            "ave_precision_score": 0.8714535806702124,
            "fpr": 0.06140350877192982,
            "logloss": 0.4829047097586861,
            "mae": 0.29768171631363466,
            "precision": 0.8556701030927835,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.866515664785039,
            "auditor_fn_violation": 0.007103010244361578,
            "auditor_fp_violation": 0.013341402697193036,
            "ave_precision_score": 0.862970448353724,
            "fpr": 0.07354555433589462,
            "logloss": 0.4686773739202198,
            "mae": 0.2892582873076724,
            "precision": 0.8277634961439588,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7774122807017544,
            "auc_prc": 0.8720980267117966,
            "auditor_fn_violation": 0.000940168649730234,
            "auditor_fp_violation": 0.0009167812643247094,
            "ave_precision_score": 0.8722875251646993,
            "fpr": 0.08771929824561403,
            "logloss": 0.4829190794108113,
            "mae": 0.3110102011072613,
            "precision": 0.8214285714285714,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8550302678742626,
            "auditor_fn_violation": 0.013015863231490333,
            "auditor_fp_violation": 0.013838795671946062,
            "ave_precision_score": 0.8554186014283243,
            "fpr": 0.09879253567508232,
            "logloss": 0.47493059133460236,
            "mae": 0.3076053720476713,
            "precision": 0.8004434589800443,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5449561403508771,
            "auc_prc": 0.8531903132510442,
            "auditor_fn_violation": 0.014848411762604066,
            "auditor_fp_violation": 0.0018127265908238531,
            "ave_precision_score": 0.8535672263964273,
            "fpr": 0.0043859649122807015,
            "logloss": 2.9925042136275533,
            "mae": 0.42080671925992774,
            "precision": 0.9523809523809523,
            "recall": 0.1629327902240326
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8431248801850901,
            "auditor_fn_violation": 0.007349576688091077,
            "auditor_fp_violation": 0.0009237298102556062,
            "ave_precision_score": 0.8433814530178819,
            "fpr": 0.005488474204171241,
            "logloss": 2.6667175262466554,
            "mae": 0.3908341449383047,
            "precision": 0.9479166666666666,
            "recall": 0.19654427645788336
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4583333333333333,
            "auc_prc": 0.4926589873127551,
            "auditor_fn_violation": 0.0002456497659627817,
            "auditor_fp_violation": 8.07392590740507e-05,
            "ave_precision_score": 0.5260379471173767,
            "fpr": 0.007675438596491228,
            "logloss": 0.7327794551688759,
            "mae": 0.5087786512612774,
            "precision": 0.36363636363636365,
            "recall": 0.008146639511201629
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5274318769176215,
            "auditor_fn_violation": 0.0028165474533716865,
            "auditor_fp_violation": 0.002866747687000157,
            "ave_precision_score": 0.5154022029671045,
            "fpr": 0.005488474204171241,
            "logloss": 0.7175727966125208,
            "mae": 0.501361658328451,
            "precision": 0.5454545454545454,
            "recall": 0.012958963282937365
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.6511639078328162,
            "auditor_fn_violation": 0.005893361203415871,
            "auditor_fp_violation": 0.010457036296203712,
            "ave_precision_score": 0.5350445400211324,
            "fpr": 0.3432017543859649,
            "logloss": 8.99656810929712,
            "mae": 0.43066676596112974,
            "precision": 0.5826666666666667,
            "recall": 0.890020366598778
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.66709414359431,
            "auditor_fn_violation": 0.006469998316709856,
            "auditor_fp_violation": 0.004599047357691723,
            "ave_precision_score": 0.5412582853190451,
            "fpr": 0.36553238199780463,
            "logloss": 8.819815905123217,
            "mae": 0.4368095734569102,
            "precision": 0.5536193029490617,
            "recall": 0.8920086393088553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6960245832121605,
            "mae": 0.5011955678724406,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6941457881853503,
            "mae": 0.5002564743373842,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6127044976089471,
            "auditor_fn_violation": 0.010265927037553151,
            "auditor_fp_violation": 0.011798349793724221,
            "ave_precision_score": 0.5623062712513158,
            "fpr": 0.41228070175438597,
            "logloss": 0.9726549093938395,
            "mae": 0.4648852711216661,
            "precision": 0.5502392344497608,
            "recall": 0.9368635437881874
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.5979412821651894,
            "auditor_fn_violation": 0.011967955845639923,
            "auditor_fp_violation": 0.02006478359730281,
            "ave_precision_score": 0.5444063589319872,
            "fpr": 0.41602634467618005,
            "logloss": 0.9774641673173732,
            "mae": 0.46892784763246154,
            "precision": 0.5355392156862745,
            "recall": 0.9438444924406048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4780701754385965,
            "auc_prc": 0.5825876927415141,
            "auditor_fn_violation": 0.006717404509236438,
            "auditor_fp_violation": 0.0008126015751968992,
            "ave_precision_score": 0.5421225974607902,
            "fpr": 0.05263157894736842,
            "logloss": 0.6971358163270693,
            "mae": 0.5004530750345766,
            "precision": 0.5675675675675675,
            "recall": 0.12830957230142567
        },
        "train": {
            "accuracy": 0.5104281009879253,
            "auc_prc": 0.5775284685770856,
            "auditor_fn_violation": 0.0033310178215380684,
            "auditor_fp_violation": 0.004871020856201977,
            "ave_precision_score": 0.5179079090764174,
            "fpr": 0.04610318331503842,
            "logloss": 0.6929802056871321,
            "mae": 0.49844010437620984,
            "precision": 0.5841584158415841,
            "recall": 0.12742980561555076
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8638093213170979,
            "auditor_fn_violation": 0.0365102547611391,
            "auditor_fp_violation": 0.02256011168062675,
            "ave_precision_score": 0.8522252087637396,
            "fpr": 0.125,
            "logloss": 0.5034030103316746,
            "mae": 0.33857437407826646,
            "precision": 0.7678207739307535,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8460954197561491,
            "auditor_fn_violation": 0.032610783014417034,
            "auditor_fp_violation": 0.03643464795358319,
            "ave_precision_score": 0.8294181730269186,
            "fpr": 0.1394072447859495,
            "logloss": 0.4984946689089449,
            "mae": 0.331007929283688,
            "precision": 0.742393509127789,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.800361374894484,
            "auditor_fn_violation": 0.008425786972522959,
            "auditor_fp_violation": 0.011886902529482851,
            "ave_precision_score": 0.788263711874362,
            "fpr": 0.20285087719298245,
            "logloss": 1.541703611989505,
            "mae": 0.32802540186400475,
            "precision": 0.7030497592295345,
            "recall": 0.8920570264765784
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7995327944541564,
            "auditor_fn_violation": 0.005497957528930068,
            "auditor_fp_violation": 0.018190371648110392,
            "ave_precision_score": 0.7838108866409946,
            "fpr": 0.21075740944017562,
            "logloss": 1.6936550686955314,
            "mae": 0.3388053543546721,
            "precision": 0.6836902800658978,
            "recall": 0.896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7961272377376961,
            "auditor_fn_violation": 0.004828134491013687,
            "auditor_fp_violation": 0.009196462057757222,
            "ave_precision_score": 0.7971447122743663,
            "fpr": 0.10087719298245613,
            "logloss": 0.6159417331345753,
            "mae": 0.4540324709133098,
            "precision": 0.7909090909090909,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7589343611772275,
            "auditor_fn_violation": 0.016650347445310854,
            "auditor_fp_violation": 0.018621608907009563,
            "ave_precision_score": 0.7604684371692637,
            "fpr": 0.11745334796926454,
            "logloss": 0.6208111103241548,
            "mae": 0.45662485342779485,
            "precision": 0.7528868360277137,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8551238430098217,
            "auditor_fn_violation": 0.008881355629399366,
            "auditor_fp_violation": 0.002578447305913242,
            "ave_precision_score": 0.855357844517523,
            "fpr": 0.08552631578947369,
            "logloss": 0.6216624024179632,
            "mae": 0.2790393517883658,
            "precision": 0.821917808219178,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8279811608657319,
            "auditor_fn_violation": 0.007351947519280786,
            "auditor_fp_violation": 0.012547534106946838,
            "ave_precision_score": 0.8284045075371208,
            "fpr": 0.11306256860592755,
            "logloss": 0.7022218421810578,
            "mae": 0.2936321339211156,
            "precision": 0.7700892857142857,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8258341830140354,
            "auditor_fn_violation": 0.002125987065423232,
            "auditor_fp_violation": 0.013363649622869527,
            "ave_precision_score": 0.7795019146565166,
            "fpr": 0.08442982456140351,
            "logloss": 0.5417429587528069,
            "mae": 0.3518807875245744,
            "precision": 0.8192488262910798,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8195158170098065,
            "auditor_fn_violation": 0.011410810516058825,
            "auditor_fp_violation": 0.00976164340599028,
            "ave_precision_score": 0.770450481238229,
            "fpr": 0.08781558726673985,
            "logloss": 0.5175423404457369,
            "mae": 0.34150389958230287,
            "precision": 0.8067632850241546,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.4386757691070854,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5358715653696359,
            "fpr": 0.4616228070175439,
            "logloss": 1.3960288952992363,
            "mae": 0.473970982066372,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.42471308596080704,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5046025578107429,
            "fpr": 0.49176728869374314,
            "logloss": 1.6279587113714455,
            "mae": 0.4956709927706504,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.7691885964912281,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383771929824561,
            "fpr": 0.4616228070175439,
            "logloss": 0.6927689733034449,
            "mae": 0.4998044039596591,
            "precision": 0.5383771929824561,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5082327113062569,
            "auc_prc": 0.7541163556531285,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5082327113062569,
            "fpr": 0.49176728869374314,
            "logloss": 0.6930762491539937,
            "mae": 0.4999580405546203,
            "precision": 0.5082327113062569,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.733215353102602,
            "mae": 0.4921014322654197,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.7161770086242119,
            "mae": 0.48388177342917343,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8191977018207248,
            "auditor_fn_violation": 0.019446528745488984,
            "auditor_fp_violation": 0.009027170062924535,
            "ave_precision_score": 0.8129851092366774,
            "fpr": 0.05263157894736842,
            "logloss": 1.2365406439559452,
            "mae": 0.3436566285582705,
            "precision": 0.8410596026490066,
            "recall": 0.5173116089613035
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7785507748888657,
            "auditor_fn_violation": 0.025439018665553956,
            "auditor_fp_violation": 0.013451662223616122,
            "ave_precision_score": 0.7789386974233454,
            "fpr": 0.06037321624588365,
            "logloss": 1.1475394850450258,
            "mae": 0.3296170912348312,
            "precision": 0.8259493670886076,
            "recall": 0.5637149028077754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.709510831442366,
            "auditor_fn_violation": 0.012720191517490272,
            "auditor_fp_violation": 0.02038536067008376,
            "ave_precision_score": 0.7101054891340459,
            "fpr": 0.07675438596491228,
            "logloss": 1.1821685322355358,
            "mae": 0.4273405494938798,
            "precision": 0.7297297297297297,
            "recall": 0.384928716904277
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7167656706173559,
            "auditor_fn_violation": 0.025474581133399555,
            "auditor_fp_violation": 0.021574114003449902,
            "ave_precision_score": 0.7172257299060341,
            "fpr": 0.08232711306256861,
            "logloss": 1.041220305478766,
            "mae": 0.40258000785367876,
            "precision": 0.7201492537313433,
            "recall": 0.4168466522678186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.7327371266933471,
            "auditor_fn_violation": 0.0026463179333261876,
            "auditor_fp_violation": 0.0038598574821852747,
            "ave_precision_score": 0.7328301188702339,
            "fpr": 0.40021929824561403,
            "logloss": 0.7283487196668864,
            "mae": 0.45358658308832644,
            "precision": 0.5618247298919568,
            "recall": 0.9531568228105907
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6696377558828674,
            "auditor_fn_violation": 0.004765370691310668,
            "auditor_fp_violation": 0.007767171083581635,
            "ave_precision_score": 0.6692290984450094,
            "fpr": 0.42371020856201974,
            "logloss": 0.8649142676578193,
            "mae": 0.46466181085674496,
            "precision": 0.5309842041312273,
            "recall": 0.9438444924406048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7875967413610605,
            "auditor_fn_violation": 0.007257833994354524,
            "auditor_fp_violation": 0.01627547193399175,
            "ave_precision_score": 0.7881317396019438,
            "fpr": 0.18421052631578946,
            "logloss": 0.578962269857785,
            "mae": 0.39498768498500186,
            "precision": 0.6945454545454546,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.77328981322122,
            "auditor_fn_violation": 0.005045128771696073,
            "auditor_fp_violation": 0.01786694370393602,
            "ave_precision_score": 0.7737119266557215,
            "fpr": 0.1942919868276619,
            "logloss": 0.5799381585135884,
            "mae": 0.39520793929123593,
            "precision": 0.6856127886323268,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.820432801547877,
            "auditor_fn_violation": 0.0026597170114696037,
            "auditor_fp_violation": 0.007961932741592702,
            "ave_precision_score": 0.7819214440454427,
            "fpr": 0.08442982456140351,
            "logloss": 0.5447708471730089,
            "mae": 0.36131598424623934,
            "precision": 0.815347721822542,
            "recall": 0.6924643584521385
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.7858632848267371,
            "auditor_fn_violation": 0.01100539838261897,
            "auditor_fp_violation": 0.007647110710365379,
            "ave_precision_score": 0.7484685116984477,
            "fpr": 0.0867178924259056,
            "logloss": 0.5394266664296614,
            "mae": 0.35666595849195243,
            "precision": 0.8068459657701712,
            "recall": 0.712742980561555
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8709386191574174,
            "auditor_fn_violation": 0.003925929896023157,
            "auditor_fp_violation": 0.003786931699795809,
            "ave_precision_score": 0.8513614784792846,
            "fpr": 0.10635964912280702,
            "logloss": 0.4905861086302416,
            "mae": 0.3345930300032099,
            "precision": 0.7949260042283298,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.7690846817913766,
            "auditor_fn_violation": 0.01232595135528565,
            "auditor_fp_violation": 0.012032989650305786,
            "ave_precision_score": 0.8195206373468954,
            "fpr": 0.11086717892425905,
            "logloss": 0.4972276284639404,
            "mae": 0.3320477709386796,
            "precision": 0.7804347826086957,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 20300,
        "test": {
            "accuracy": 0.42105263157894735,
            "auc_prc": 0.44310561411006955,
            "auditor_fn_violation": 0.014287883660270843,
            "auditor_fp_violation": 0.00853231653956745,
            "ave_precision_score": 0.4579644080921233,
            "fpr": 0.34978070175438597,
            "logloss": 10.3587491407612,
            "mae": 0.5839216098058642,
            "precision": 0.46921797004991683,
            "recall": 0.5743380855397149
        },
        "train": {
            "accuracy": 0.3633369923161361,
            "auc_prc": 0.4032131059990487,
            "auditor_fn_violation": 0.008795783713812223,
            "auditor_fp_violation": 0.012358867806178469,
            "ave_precision_score": 0.42486358984275424,
            "fpr": 0.39846322722283206,
            "logloss": 10.666062490882148,
            "mae": 0.6219080405720764,
            "precision": 0.4039408866995074,
            "recall": 0.531317494600432
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8365913052741669,
            "auditor_fn_violation": 0.010114070818594344,
            "auditor_fp_violation": 0.01842417802225279,
            "ave_precision_score": 0.8370021595812382,
            "fpr": 0.1425438596491228,
            "logloss": 0.7215169206113423,
            "mae": 0.2955413702629653,
            "precision": 0.7410358565737052,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8179949526766969,
            "auditor_fn_violation": 0.009530741382621338,
            "auditor_fp_violation": 0.019116551670064298,
            "ave_precision_score": 0.8183236558327805,
            "fpr": 0.14270032930845225,
            "logloss": 0.7172721165203068,
            "mae": 0.29195759204918115,
            "precision": 0.7308488612836439,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7502720095714407,
            "auditor_fn_violation": 0.01223782470432701,
            "auditor_fp_violation": 0.021164103846314127,
            "ave_precision_score": 0.7508734585265376,
            "fpr": 0.16228070175438597,
            "logloss": 0.8079778489431461,
            "mae": 0.33342817088582943,
            "precision": 0.7063492063492064,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7611567857343418,
            "auditor_fn_violation": 0.013696291782936184,
            "auditor_fp_violation": 0.025952642308295446,
            "ave_precision_score": 0.7618478403414354,
            "fpr": 0.1734357848518112,
            "logloss": 0.7984102510465022,
            "mae": 0.3301902836059352,
            "precision": 0.6748971193415638,
            "recall": 0.7084233261339092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.6338840151614182,
            "auditor_fn_violation": 0.013148962018079828,
            "auditor_fp_violation": 0.014681522690336292,
            "ave_precision_score": 0.6344227180423112,
            "fpr": 0.09320175438596491,
            "logloss": 0.6895134947200839,
            "mae": 0.4924897405854018,
            "precision": 0.6473029045643154,
            "recall": 0.31771894093686354
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5833610031305796,
            "auditor_fn_violation": 0.012494280369754838,
            "auditor_fp_violation": 0.009629331974282576,
            "ave_precision_score": 0.5841816853765145,
            "fpr": 0.11086717892425905,
            "logloss": 0.6951318943651669,
            "mae": 0.49143197704874336,
            "precision": 0.5943775100401606,
            "recall": 0.31965442764578833
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5877192982456141,
            "auc_prc": 0.7772231044768022,
            "auditor_fn_violation": 0.00416488012291421,
            "auditor_fp_violation": 0.007980164187190074,
            "ave_precision_score": 0.6600405245463273,
            "fpr": 0.3980263157894737,
            "logloss": 0.7644422799178919,
            "mae": 0.41681839716865826,
            "precision": 0.5683709869203329,
            "recall": 0.9735234215885947
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.7696499348290784,
            "auditor_fn_violation": 0.004900508069123955,
            "auditor_fp_violation": 0.013468813705504169,
            "ave_precision_score": 0.6448995410879911,
            "fpr": 0.424807903402854,
            "logloss": 0.793584577529104,
            "mae": 0.4311832515062799,
            "precision": 0.5387365911799762,
            "recall": 0.9762419006479481
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.7455078281873401,
            "auditor_fn_violation": 0.0038767999428306024,
            "auditor_fp_violation": 0.00725871983998,
            "ave_precision_score": 0.7362942645999396,
            "fpr": 0.07236842105263158,
            "logloss": 0.5533644893125568,
            "mae": 0.3606683826564174,
            "precision": 0.8329113924050633,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.7949250127600365,
            "auditor_fn_violation": 0.012439751252391574,
            "auditor_fp_violation": 0.00799749098322095,
            "ave_precision_score": 0.7305981683289319,
            "fpr": 0.07025246981339188,
            "logloss": 0.5355586868554366,
            "mae": 0.3531195673146965,
            "precision": 0.8311345646437994,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 20300,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6492038362348725,
            "auditor_fn_violation": 0.010830921499267518,
            "auditor_fp_violation": 0.005524128016002001,
            "ave_precision_score": 0.7165480405544793,
            "fpr": 0.05043859649122807,
            "logloss": 0.7547817969403444,
            "mae": 0.4598548010628867,
            "precision": 0.7711442786069652,
            "recall": 0.31568228105906315
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.692684412472966,
            "auditor_fn_violation": 0.005450540905135929,
            "auditor_fp_violation": 0.005490924415869531,
            "ave_precision_score": 0.7099312308539971,
            "fpr": 0.04939626783754116,
            "logloss": 0.7211459439918847,
            "mae": 0.4425175602370965,
            "precision": 0.7704081632653061,
            "recall": 0.326133909287257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7428541226164467,
            "auditor_fn_violation": 0.010554007217636765,
            "auditor_fp_violation": 0.0160853440013335,
            "ave_precision_score": 0.7431197399018863,
            "fpr": 0.17543859649122806,
            "logloss": 1.1938547243112843,
            "mae": 0.3606907081595507,
            "precision": 0.6806387225548902,
            "recall": 0.6945010183299389
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.748298341284656,
            "auditor_fn_violation": 0.011636039479080979,
            "auditor_fp_violation": 0.014510153677277723,
            "ave_precision_score": 0.7486913965770923,
            "fpr": 0.16575192096597147,
            "logloss": 1.2372190770122318,
            "mae": 0.34765352955502815,
            "precision": 0.6827731092436975,
            "recall": 0.7019438444924406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.789747633224023,
            "auditor_fn_violation": 0.03911414228034445,
            "auditor_fp_violation": 0.03394695170229613,
            "ave_precision_score": 0.7783493423971721,
            "fpr": 0.16776315789473684,
            "logloss": 0.5732810283948713,
            "mae": 0.3887466436840202,
            "precision": 0.7113207547169811,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8206602230377096,
            "auditor_fn_violation": 0.024127949017646096,
            "auditor_fp_violation": 0.035971557942606244,
            "ave_precision_score": 0.8002577290821896,
            "fpr": 0.16575192096597147,
            "logloss": 0.5409797801401058,
            "mae": 0.3753012750792582,
            "precision": 0.7118320610687023,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8318578588909481,
            "auditor_fn_violation": 0.0038767999428306024,
            "auditor_fp_violation": 0.00725871983998,
            "ave_precision_score": 0.8128985688848522,
            "fpr": 0.07236842105263158,
            "logloss": 0.5197890654575189,
            "mae": 0.34151116078882887,
            "precision": 0.8329113924050633,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8235602941428534,
            "auditor_fn_violation": 0.012439751252391574,
            "auditor_fp_violation": 0.00799749098322095,
            "ave_precision_score": 0.798959847795916,
            "fpr": 0.07025246981339188,
            "logloss": 0.5120017101918447,
            "mae": 0.3335625462389411,
            "precision": 0.8311345646437994,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.778571401895595,
            "auditor_fn_violation": 0.00014738985957766157,
            "auditor_fp_violation": 0.00028388965287328495,
            "ave_precision_score": 0.7801719046187463,
            "fpr": 0.4298245614035088,
            "logloss": 3.6047660001605313,
            "mae": 0.44150761968053215,
            "precision": 0.5499425947187141,
            "recall": 0.9755600814663951
        },
        "train": {
            "accuracy": 0.5268935236004391,
            "auc_prc": 0.7662033890353661,
            "auditor_fn_violation": 0.00321484709324242,
            "auditor_fp_violation": 0.0068213893680414105,
            "ave_precision_score": 0.7680531686817034,
            "fpr": 0.4566410537870472,
            "logloss": 3.8074414148169007,
            "mae": 0.4710786535780303,
            "precision": 0.5185185185185185,
            "recall": 0.9676025917926566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5975877192982456,
            "auc_prc": 0.737757164536754,
            "auditor_fn_violation": 0.08761210562046666,
            "auditor_fp_violation": 0.08718537733883402,
            "ave_precision_score": 0.7385975034233226,
            "fpr": 0.24451754385964913,
            "logloss": 0.6510649727029549,
            "mae": 0.4601604117840332,
            "precision": 0.6087719298245614,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7360496930713173,
            "auditor_fn_violation": 0.08163245952398451,
            "auditor_fp_violation": 0.09052062098165284,
            "ave_precision_score": 0.7366652714361537,
            "fpr": 0.2502744237102086,
            "logloss": 0.6293904974886372,
            "mae": 0.4490420316539206,
            "precision": 0.5992970123022847,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7695700470323624,
            "auditor_fn_violation": 0.014247686425840572,
            "auditor_fp_violation": 0.020739571613118308,
            "ave_precision_score": 0.7689779830756427,
            "fpr": 0.1611842105263158,
            "logloss": 0.6041170122373012,
            "mae": 0.4245570576504657,
            "precision": 0.703030303030303,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7427785267974834,
            "auditor_fn_violation": 0.014319820385829076,
            "auditor_fp_violation": 0.026930276775913437,
            "ave_precision_score": 0.7424178860734539,
            "fpr": 0.17014270032930845,
            "logloss": 0.5993337911091561,
            "mae": 0.4218683083972083,
            "precision": 0.6777546777546778,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7010339314781142,
            "auditor_fn_violation": 0.02777405581162683,
            "auditor_fp_violation": 0.012467704296370384,
            "ave_precision_score": 0.6443100967459778,
            "fpr": 0.17543859649122806,
            "logloss": 0.6506504514624153,
            "mae": 0.45530601773051577,
            "precision": 0.6694214876033058,
            "recall": 0.659877800407332
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6779174484633327,
            "auditor_fn_violation": 0.018034912860099624,
            "auditor_fp_violation": 0.01129547592912029,
            "ave_precision_score": 0.6315162697115678,
            "fpr": 0.1734357848518112,
            "logloss": 0.637718166273423,
            "mae": 0.4496717390192327,
            "precision": 0.6715176715176715,
            "recall": 0.6976241900647948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7876950492860486,
            "auditor_fn_violation": 0.0017173151820488125,
            "auditor_fp_violation": 0.013858503146226619,
            "ave_precision_score": 0.7888960049492971,
            "fpr": 0.20614035087719298,
            "logloss": 0.5493943216531577,
            "mae": 0.3555060655844659,
            "precision": 0.6982343499197432,
            "recall": 0.8859470468431772
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7645665916970823,
            "auditor_fn_violation": 0.006026652884234684,
            "auditor_fp_violation": 0.019562490199153213,
            "ave_precision_score": 0.7664420120057305,
            "fpr": 0.2283205268935236,
            "logloss": 0.5688981319240561,
            "mae": 0.3626002628365419,
            "precision": 0.6666666666666666,
            "recall": 0.8984881209503239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7148718719155611,
            "auditor_fn_violation": 0.008691535355700865,
            "auditor_fp_violation": 0.004794870192107347,
            "ave_precision_score": 0.7018936744605284,
            "fpr": 0.03837719298245614,
            "logloss": 8.191102278072497,
            "mae": 0.4333423827305077,
            "precision": 0.8205128205128205,
            "recall": 0.3258655804480652
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6362402658216502,
            "auditor_fn_violation": 0.005275099397097629,
            "auditor_fp_violation": 0.007708366002822646,
            "ave_precision_score": 0.6342448679515771,
            "fpr": 0.042810098792535674,
            "logloss": 9.36471937643326,
            "mae": 0.4450398722966002,
            "precision": 0.7621951219512195,
            "recall": 0.26997840172786175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7903146615853744,
            "auditor_fn_violation": 0.022675706578054098,
            "auditor_fp_violation": 0.009123536275367758,
            "ave_precision_score": 0.7897236930144951,
            "fpr": 0.10416666666666667,
            "logloss": 0.8085796368340294,
            "mae": 0.38434269538623067,
            "precision": 0.782608695652174,
            "recall": 0.6965376782077393
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.724267923831257,
            "auditor_fn_violation": 0.01721460526846107,
            "auditor_fp_violation": 0.007580954994511528,
            "ave_precision_score": 0.7228864337368687,
            "fpr": 0.12623490669593854,
            "logloss": 0.9340228427645422,
            "mae": 0.39134574831595276,
            "precision": 0.7350230414746544,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7557449811064065,
            "auditor_fn_violation": 0.012052470790009654,
            "auditor_fp_violation": 0.014793515856148685,
            "ave_precision_score": 0.7770911752019282,
            "fpr": 0.047149122807017545,
            "logloss": 0.6786149463661154,
            "mae": 0.36839272976309684,
            "precision": 0.8401486988847584,
            "recall": 0.46028513238289204
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.766994143768354,
            "auditor_fn_violation": 0.011142906591621956,
            "auditor_fp_violation": 0.009798396581464641,
            "ave_precision_score": 0.7631721478276309,
            "fpr": 0.05159165751920966,
            "logloss": 0.6451311399869585,
            "mae": 0.35569517171106474,
            "precision": 0.8246268656716418,
            "recall": 0.4773218142548596
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7575746805967027,
            "auditor_fn_violation": 0.013148962018079824,
            "auditor_fp_violation": 0.01723913405842398,
            "ave_precision_score": 0.7592074678066526,
            "fpr": 0.15789473684210525,
            "logloss": 0.5906176957216848,
            "mae": 0.3937629883324629,
            "precision": 0.7246653919694073,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7271937991636941,
            "auditor_fn_violation": 0.003110530520895321,
            "auditor_fp_violation": 0.03036792378861534,
            "ave_precision_score": 0.7282901250918492,
            "fpr": 0.18221734357848518,
            "logloss": 0.5895574191771867,
            "mae": 0.3998132908285384,
            "precision": 0.6867924528301886,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.7225750107683686,
            "auditor_fn_violation": 0.01948672597991927,
            "auditor_fp_violation": 0.012884423052881611,
            "ave_precision_score": 0.6985312221101454,
            "fpr": 0.029605263157894735,
            "logloss": 0.8903952536731691,
            "mae": 0.4518896217682097,
            "precision": 0.8291139240506329,
            "recall": 0.2668024439918534
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7008496315362502,
            "auditor_fn_violation": 0.02289037513661915,
            "auditor_fp_violation": 0.013309549945115257,
            "ave_precision_score": 0.6762705167539559,
            "fpr": 0.030735455543358946,
            "logloss": 0.8518929658841696,
            "mae": 0.4405702055761044,
            "precision": 0.8145695364238411,
            "recall": 0.265658747300216
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4692982456140351,
            "auc_prc": 0.5268062929522049,
            "auditor_fn_violation": 0.009732197091506788,
            "auditor_fp_violation": 0.005946055756969621,
            "ave_precision_score": 0.5536250051735043,
            "fpr": 0.023026315789473683,
            "logloss": 1.1056533145584597,
            "mae": 0.5131059371082014,
            "precision": 0.5714285714285714,
            "recall": 0.05702647657841141
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0.49661468845630635,
            "auditor_fn_violation": 0.009307883250788896,
            "auditor_fp_violation": 0.00535126234906696,
            "ave_precision_score": 0.5274208449677282,
            "fpr": 0.019758507135016465,
            "logloss": 1.0536549936952064,
            "mae": 0.49589412452695986,
            "precision": 0.5,
            "recall": 0.038876889848812095
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 20300,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8249081764806329,
            "auditor_fn_violation": 0.004140315146317934,
            "auditor_fp_violation": 0.006162228611909829,
            "ave_precision_score": 0.8251404500252834,
            "fpr": 0.10635964912280702,
            "logloss": 0.8241646201658407,
            "mae": 0.3374428161975713,
            "precision": 0.7849223946784922,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7880252690372388,
            "auditor_fn_violation": 0.005367561813496195,
            "auditor_fp_violation": 0.015769562490199153,
            "ave_precision_score": 0.7885973611370398,
            "fpr": 0.14489571899012074,
            "logloss": 0.8405313586763883,
            "mae": 0.3415938696750691,
            "precision": 0.7232704402515723,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8008548827757682,
            "auditor_fn_violation": 0.0028852681602172512,
            "auditor_fp_violation": 0.014033004125515693,
            "ave_precision_score": 0.7946945565582187,
            "fpr": 0.08442982456140351,
            "logloss": 0.5379791929968664,
            "mae": 0.33455535579930273,
            "precision": 0.8171021377672208,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.797649267242747,
            "auditor_fn_violation": 0.009395604004808053,
            "auditor_fp_violation": 0.011221969578171556,
            "ave_precision_score": 0.7899443750055037,
            "fpr": 0.08342480790340286,
            "logloss": 0.5097580373296339,
            "mae": 0.3266498843467622,
            "precision": 0.8146341463414634,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.556212614662027,
            "auditor_fn_violation": 0.001945099510487012,
            "auditor_fp_violation": 0.007745759886652511,
            "ave_precision_score": 0.5579553425833658,
            "fpr": 0.44298245614035087,
            "logloss": 1.1480952758406433,
            "mae": 0.45637898822812867,
            "precision": 0.5445321307779031,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5132697664903019,
            "auditor_fn_violation": 0.001088211516075421,
            "auditor_fp_violation": 0.009820448486749277,
            "ave_precision_score": 0.5148982278643213,
            "fpr": 0.4676180021953897,
            "logloss": 1.2325095070113032,
            "mae": 0.4737145027961545,
            "precision": 0.5175537938844847,
            "recall": 0.9870410367170627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5645408334351151,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002125265658207283,
            "ave_precision_score": 0.5660654558589384,
            "fpr": 0.45723684210526316,
            "logloss": 0.7828610384954638,
            "mae": 0.4786108817186272,
            "precision": 0.5407488986784141,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.5338412744408756,
            "auditor_fn_violation": 0.0006211577717031814,
            "auditor_fp_violation": 0.0026854320213266585,
            "ave_precision_score": 0.5355081098182175,
            "fpr": 0.4829857299670692,
            "logloss": 0.8102922158955743,
            "mae": 0.4914883084341671,
            "precision": 0.5121951219512195,
            "recall": 0.9978401727861771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.8076792551548688,
            "auditor_fn_violation": 0.012340550970093258,
            "auditor_fp_violation": 0.031746155769471186,
            "ave_precision_score": 0.6747928528398032,
            "fpr": 0.2807017543859649,
            "logloss": 0.6105636201602279,
            "mae": 0.4228606630574193,
            "precision": 0.6305916305916306,
            "recall": 0.890020366598778
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7728069644362786,
            "auditor_fn_violation": 0.00441685850642377,
            "auditor_fp_violation": 0.04041134153990905,
            "ave_precision_score": 0.6344889596943755,
            "fpr": 0.3106476399560922,
            "logloss": 0.6165057207785306,
            "mae": 0.4272122638940026,
            "precision": 0.5910404624277457,
            "recall": 0.8833693304535637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8452755710496177,
            "auditor_fn_violation": 0.004269839568371029,
            "auditor_fp_violation": 0.010084593907571788,
            "ave_precision_score": 0.8456804620940017,
            "fpr": 0.11732456140350878,
            "logloss": 0.5165739056229847,
            "mae": 0.3536496606365402,
            "precision": 0.7847082494969819,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8379180183307949,
            "auditor_fn_violation": 0.007631705599666187,
            "auditor_fp_violation": 0.01606603810569234,
            "ave_precision_score": 0.8381942216088316,
            "fpr": 0.141602634467618,
            "logloss": 0.5101224174398764,
            "mae": 0.3531257234269428,
            "precision": 0.742,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8528207020305074,
            "auditor_fn_violation": 0.01772028084467788,
            "auditor_fp_violation": 0.009235529441180147,
            "ave_precision_score": 0.8525631778052476,
            "fpr": 0.06798245614035088,
            "logloss": 0.5167682645646845,
            "mae": 0.34348231198683815,
            "precision": 0.8342245989304813,
            "recall": 0.6354378818737271
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8321586710723023,
            "auditor_fn_violation": 0.002370831189706799,
            "auditor_fp_violation": 0.006826289791437983,
            "ave_precision_score": 0.8322472668062479,
            "fpr": 0.06915477497255763,
            "logloss": 0.5084874091728491,
            "mae": 0.33967949814213244,
            "precision": 0.8306451612903226,
            "recall": 0.6673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.6792091935187945,
            "auditor_fn_violation": 0.024873155393575597,
            "auditor_fp_violation": 0.03400945951577281,
            "ave_precision_score": 0.6662582456818046,
            "fpr": 0.16557017543859648,
            "logloss": 0.6636267938854531,
            "mae": 0.452515079786903,
            "precision": 0.6834381551362684,
            "recall": 0.6639511201629328
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.6829446887516955,
            "auditor_fn_violation": 0.024495427852050656,
            "auditor_fp_violation": 0.03321506978202917,
            "ave_precision_score": 0.662870359518212,
            "fpr": 0.1712403951701427,
            "logloss": 0.6363379841615294,
            "mae": 0.4431192268802489,
            "precision": 0.6687898089171974,
            "recall": 0.6803455723542117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 20300,
        "test": {
            "accuracy": 0.48135964912280704,
            "auc_prc": 0.6404339833800388,
            "auditor_fn_violation": 0.001013863579519071,
            "auditor_fp_violation": 0.0018309580364212197,
            "ave_precision_score": 0.5491251678075025,
            "fpr": 0.013157894736842105,
            "logloss": 0.6899502274736415,
            "mae": 0.49482573411966624,
            "precision": 0.7142857142857143,
            "recall": 0.06109979633401222
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.6126810537540542,
            "auditor_fn_violation": 0.004919474718641617,
            "auditor_fp_violation": 0.0020214246510898547,
            "ave_precision_score": 0.5215462513717798,
            "fpr": 0.018660812294182216,
            "logloss": 0.6909862298022054,
            "mae": 0.4941847325025615,
            "precision": 0.6792452830188679,
            "recall": 0.07775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.535336510770487,
            "auditor_fn_violation": 0.06746882481151964,
            "auditor_fp_violation": 0.07497291328082677,
            "ave_precision_score": 0.5365966518821226,
            "fpr": 0.34100877192982454,
            "logloss": 1.873790267782854,
            "mae": 0.47784645320402847,
            "precision": 0.5625879043600562,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5440372333146649,
            "auditor_fn_violation": 0.06111291557707217,
            "auditor_fp_violation": 0.09831719460561393,
            "ave_precision_score": 0.5455319796431464,
            "fpr": 0.33479692645444564,
            "logloss": 1.6586318617051734,
            "mae": 0.4628996609547465,
            "precision": 0.5553935860058309,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7659727963773485,
            "auditor_fn_violation": 0.003568621145531861,
            "auditor_fp_violation": 0.0066779180730924745,
            "ave_precision_score": 0.7657816516644125,
            "fpr": 0.07785087719298246,
            "logloss": 1.2258914120205093,
            "mae": 0.3832754098497391,
            "precision": 0.7746031746031746,
            "recall": 0.4969450101832994
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7276033520457893,
            "auditor_fn_violation": 0.011543577062682425,
            "auditor_fp_violation": 0.011761016151795516,
            "ave_precision_score": 0.7266978024194377,
            "fpr": 0.10537870472008781,
            "logloss": 1.2814360964596077,
            "mae": 0.37952081542222216,
            "precision": 0.6903225806451613,
            "recall": 0.46220302375809935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7333280441822806,
            "auditor_fn_violation": 0.01465859148890557,
            "auditor_fp_violation": 0.016192128182689506,
            "ave_precision_score": 0.7020434472382495,
            "fpr": 0.14035087719298245,
            "logloss": 0.6184849826808585,
            "mae": 0.43343630223943475,
            "precision": 0.717439293598234,
            "recall": 0.6619144602851323
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.697223092652011,
            "auditor_fn_violation": 0.014654107583577736,
            "auditor_fp_violation": 0.020843950917359265,
            "ave_precision_score": 0.6739590640369365,
            "fpr": 0.132821075740944,
            "logloss": 0.6176198833674482,
            "mae": 0.43018758774588844,
            "precision": 0.7125890736342043,
            "recall": 0.6479481641468683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.7828771471152914,
            "auditor_fn_violation": 0.005629845999928549,
            "auditor_fp_violation": 0.013600658415635288,
            "ave_precision_score": 0.7444297878289274,
            "fpr": 0.2225877192982456,
            "logloss": 0.6527696415343143,
            "mae": 0.38637749062699933,
            "precision": 0.6288848263254113,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8102507218791161,
            "auditor_fn_violation": 0.006595652369764325,
            "auditor_fp_violation": 0.004518190371648119,
            "ave_precision_score": 0.7630537824869335,
            "fpr": 0.2414928649835346,
            "logloss": 0.6021598508553038,
            "mae": 0.3708127543225917,
            "precision": 0.6140350877192983,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7938507083306952,
            "auditor_fn_violation": 0.05292412548683317,
            "auditor_fp_violation": 0.05179293244988957,
            "ave_precision_score": 0.7951774666570371,
            "fpr": 0.20614035087719298,
            "logloss": 0.6797038967001126,
            "mae": 0.3599160853251194,
            "precision": 0.6813559322033899,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.8037504917984621,
            "auditor_fn_violation": 0.054659513078690256,
            "auditor_fp_violation": 0.05544584052062098,
            "ave_precision_score": 0.8040557681863998,
            "fpr": 0.1986827661909989,
            "logloss": 0.6505139213390738,
            "mae": 0.3478145128446808,
            "precision": 0.6709090909090909,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.7700584302246489,
            "auditor_fn_violation": 0.00039750598492157104,
            "auditor_fp_violation": 0.00028388965287328495,
            "ave_precision_score": 0.5501880501202557,
            "fpr": 0.4298245614035088,
            "logloss": 0.6845408535544021,
            "mae": 0.49343061878492955,
            "precision": 0.5504587155963303,
            "recall": 0.9775967413441955
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7561399445514361,
            "auditor_fn_violation": 0.0022854812668773546,
            "auditor_fp_violation": 0.0068213893680414105,
            "ave_precision_score": 0.5215745938023584,
            "fpr": 0.4566410537870472,
            "logloss": 0.6863173693327954,
            "mae": 0.4943210336039278,
            "precision": 0.5218390804597701,
            "recall": 0.980561555075594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6107456140350878,
            "auc_prc": 0.6522202360874136,
            "auditor_fn_violation": 0.004991156608425346,
            "auditor_fp_violation": 0.022291848981122648,
            "ave_precision_score": 0.6540752712958086,
            "fpr": 0.1875,
            "logloss": 1.3828048462752862,
            "mae": 0.399415170817167,
            "precision": 0.6422594142259415,
            "recall": 0.6252545824847251
        },
        "train": {
            "accuracy": 0.6366630076838639,
            "auc_prc": 0.6676049118075277,
            "auditor_fn_violation": 0.0204318231928932,
            "auditor_fp_violation": 0.02265710757409441,
            "ave_precision_score": 0.6686746531137865,
            "fpr": 0.19209659714599342,
            "logloss": 1.249558678484263,
            "mae": 0.377769520537283,
            "precision": 0.6369294605809128,
            "recall": 0.6630669546436285
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7313620259682486,
            "auditor_fn_violation": 0.013026137135098443,
            "auditor_fp_violation": 0.024802579489102815,
            "ave_precision_score": 0.6707929964547501,
            "fpr": 0.15789473684210525,
            "logloss": 0.678693590766478,
            "mae": 0.4153532654439148,
            "precision": 0.7079107505070994,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7690983895144592,
            "auditor_fn_violation": 0.009165633379406493,
            "auditor_fp_violation": 0.02346812764622863,
            "ave_precision_score": 0.6453297058611417,
            "fpr": 0.16465422612513722,
            "logloss": 0.6640056710531194,
            "mae": 0.40941315457535626,
            "precision": 0.6767241379310345,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6151315789473685,
            "auc_prc": 0.6872783056998505,
            "auditor_fn_violation": 0.0484599992853825,
            "auditor_fp_violation": 0.08679991248906113,
            "ave_precision_score": 0.5647028035110057,
            "fpr": 0.2894736842105263,
            "logloss": 8.959973733047082,
            "mae": 0.4004812054670619,
            "precision": 0.6047904191616766,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6725679124457958,
            "auditor_fn_violation": 0.05733143982948983,
            "auditor_fp_violation": 0.08718343264858085,
            "ave_precision_score": 0.5393660555873613,
            "fpr": 0.31394072447859495,
            "logloss": 9.525180436561387,
            "mae": 0.42612570802680555,
            "precision": 0.5640243902439024,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4516695280369039,
            "auditor_fn_violation": 0.0005292635866652459,
            "auditor_fp_violation": 2.864941451014721e-05,
            "ave_precision_score": 0.5386596757121465,
            "fpr": 0.0021929824561403508,
            "logloss": 18.46215087446126,
            "mae": 0.5400021245380434,
            "precision": 0.3333333333333333,
            "recall": 0.002036659877800407
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.2991398624443744,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0012447075427316921,
            "ave_precision_score": 0.5075669819081873,
            "fpr": 0.0021953896816684962,
            "logloss": 17.520451425456628,
            "mae": 0.5104541211558821,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6484502856724069,
            "auditor_fn_violation": 0.002380569550148283,
            "auditor_fp_violation": 0.00621692294870194,
            "ave_precision_score": 0.558539756216626,
            "fpr": 0.43640350877192985,
            "logloss": 0.6846991449593992,
            "mae": 0.4891408737258692,
            "precision": 0.5482406356413166,
            "recall": 0.9837067209775967
        },
        "train": {
            "accuracy": 0.5279912184412733,
            "auc_prc": 0.6295325015872533,
            "auditor_fn_violation": 0.00039118714630162184,
            "auditor_fp_violation": 0.008906519523286825,
            "ave_precision_score": 0.5331605890483688,
            "fpr": 0.4643249176728869,
            "logloss": 0.6845570482336935,
            "mae": 0.487856857274157,
            "precision": 0.5187713310580204,
            "recall": 0.9848812095032398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8581916241977199,
            "auditor_fn_violation": 0.00017642119555507816,
            "auditor_fp_violation": 0.012170792182356128,
            "ave_precision_score": 0.8583351455539086,
            "fpr": 0.08662280701754387,
            "logloss": 0.5138989329317938,
            "mae": 0.3284627709439711,
            "precision": 0.8145539906103286,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8404692995004354,
            "auditor_fn_violation": 0.009701441228280224,
            "auditor_fp_violation": 0.0071472675239140655,
            "ave_precision_score": 0.8407503962943398,
            "fpr": 0.0889132821075741,
            "logloss": 0.5023401719465127,
            "mae": 0.32641016788020094,
            "precision": 0.8048192771084337,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6124749305372592,
            "auditor_fn_violation": 0.005596348304569991,
            "auditor_fp_violation": 0.014113743384589738,
            "ave_precision_score": 0.6126903814030167,
            "fpr": 0.14583333333333334,
            "logloss": 0.6885383734783124,
            "mae": 0.49736234088215914,
            "precision": 0.6305555555555555,
            "recall": 0.4623217922606925
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5304927244381128,
            "auditor_fn_violation": 0.002347122877809742,
            "auditor_fp_violation": 0.011709561706131412,
            "ave_precision_score": 0.5327330036619585,
            "fpr": 0.18551042810098792,
            "logloss": 0.6921767558135445,
            "mae": 0.49912422915059834,
            "precision": 0.5655526992287918,
            "recall": 0.47516198704103674
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7127534193278515,
            "auditor_fn_violation": 0.01687390574195163,
            "auditor_fp_violation": 0.017510001250156275,
            "ave_precision_score": 0.6807574738793832,
            "fpr": 0.09868421052631579,
            "logloss": 6.681288277274861,
            "mae": 0.35946123159808363,
            "precision": 0.76,
            "recall": 0.5804480651731161
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7197699044329818,
            "auditor_fn_violation": 0.01902117863501766,
            "auditor_fp_violation": 0.022818821546181593,
            "ave_precision_score": 0.6842410281432894,
            "fpr": 0.0889132821075741,
            "logloss": 6.035497315843969,
            "mae": 0.3194472461960393,
            "precision": 0.7804878048780488,
            "recall": 0.6220302375809935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7811386203614521,
            "auditor_fn_violation": 0.011217261585736235,
            "auditor_fp_violation": 0.02445097303829646,
            "ave_precision_score": 0.7814857138583755,
            "fpr": 0.19517543859649122,
            "logloss": 0.7650862880844829,
            "mae": 0.3339835179749092,
            "precision": 0.6920415224913494,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7712497412562785,
            "auditor_fn_violation": 0.00671893559162907,
            "auditor_fp_violation": 0.02764818880351262,
            "ave_precision_score": 0.7719401820385885,
            "fpr": 0.19978046103183314,
            "logloss": 0.7699014713453302,
            "mae": 0.3393963321626317,
            "precision": 0.6744186046511628,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.594889484540733,
            "mae": 0.5383771929824561,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.553735972386,
            "mae": 0.5082327113062569,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.667146550946742,
            "auditor_fn_violation": 0.0015654589630900132,
            "auditor_fp_violation": 0.009352731591448933,
            "ave_precision_score": 0.746948500921321,
            "fpr": 0.08442982456140351,
            "logloss": 0.5337535840859514,
            "mae": 0.36211621849552583,
            "precision": 0.8229885057471265,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.7376312072496823,
            "auditor_fn_violation": 0.007679122223460324,
            "auditor_fp_violation": 0.00771081621452094,
            "ave_precision_score": 0.7180666094151081,
            "fpr": 0.09549945115257959,
            "logloss": 0.543163993971774,
            "mae": 0.36638522085976,
            "precision": 0.7952941176470588,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8572785509376547,
            "auditor_fn_violation": 0.0017709114946225088,
            "auditor_fp_violation": 0.009732987456765428,
            "ave_precision_score": 0.8361867083099398,
            "fpr": 0.09978070175438597,
            "logloss": 0.5185654045366405,
            "mae": 0.34157021746464206,
            "precision": 0.7991169977924945,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8243402450651123,
            "auditor_fn_violation": 0.007992071940501626,
            "auditor_fp_violation": 0.010543260937745021,
            "ave_precision_score": 0.8064544446475371,
            "fpr": 0.10867178924259056,
            "logloss": 0.5266488521388113,
            "mae": 0.34170152830076533,
            "precision": 0.775,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 20300,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8385936010252271,
            "auditor_fn_violation": 0.00114338800157216,
            "auditor_fp_violation": 0.0053548360211693145,
            "ave_precision_score": 0.8164762679340023,
            "fpr": 0.07236842105263158,
            "logloss": 0.528079821370085,
            "mae": 0.32860747846088517,
            "precision": 0.8329113924050633,
            "recall": 0.670061099796334
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8421512255176216,
            "auditor_fn_violation": 0.008938033585194632,
            "auditor_fp_violation": 0.008075897757566255,
            "ave_precision_score": 0.819627511134073,
            "fpr": 0.07244785949506037,
            "logloss": 0.5015077829629073,
            "mae": 0.3193869858276831,
            "precision": 0.8307692307692308,
            "recall": 0.6997840172786177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.80457918835819,
            "auditor_fn_violation": 0.0041492478650802175,
            "auditor_fp_violation": 0.010420573405008965,
            "ave_precision_score": 0.7952140315356603,
            "fpr": 0.05921052631578947,
            "logloss": 0.5993524116608794,
            "mae": 0.3657414111089326,
            "precision": 0.8457142857142858,
            "recall": 0.6028513238289206
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7971144412228027,
            "auditor_fn_violation": 0.011700051921203054,
            "auditor_fp_violation": 0.00786027912811667,
            "ave_precision_score": 0.7852066333973101,
            "fpr": 0.0570801317233809,
            "logloss": 0.5867286413713783,
            "mae": 0.35819025643371755,
            "precision": 0.8456973293768546,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8165951252041486,
            "auditor_fn_violation": 0.012771554650373398,
            "auditor_fp_violation": 0.0027425303162895384,
            "ave_precision_score": 0.7913743329983314,
            "fpr": 0.11074561403508772,
            "logloss": 0.5601823807096836,
            "mae": 0.3606237482704353,
            "precision": 0.7740492170022372,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.78992682674208,
            "auditor_fn_violation": 0.011600477011235372,
            "auditor_fp_violation": 0.01548043750980085,
            "ave_precision_score": 0.7621450009158517,
            "fpr": 0.1207464324917673,
            "logloss": 0.5634426265989967,
            "mae": 0.3608412616502833,
            "precision": 0.7494305239179955,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 20300,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8498846191610588,
            "auditor_fn_violation": 0.0001518562189588099,
            "auditor_fp_violation": 0.011300891778138932,
            "ave_precision_score": 0.7770043783952187,
            "fpr": 0.08771929824561403,
            "logloss": 0.5302804591940763,
            "mae": 0.34670204188870757,
            "precision": 0.816933638443936,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8409444924431382,
            "auditor_fn_violation": 0.010939015109307181,
            "auditor_fp_violation": 0.008213109612670536,
            "ave_precision_score": 0.7636976639866395,
            "fpr": 0.09659714599341383,
            "logloss": 0.5238972734643369,
            "mae": 0.34448278656906145,
            "precision": 0.7934272300469484,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6936977135307705,
            "auditor_fn_violation": 0.07404777217994069,
            "auditor_fp_violation": 0.044773825894903536,
            "ave_precision_score": 0.692366437477643,
            "fpr": 0.18421052631578946,
            "logloss": 1.627219673275038,
            "mae": 0.45864038898975545,
            "precision": 0.672514619883041,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7113481744797789,
            "auditor_fn_violation": 0.0641926252925013,
            "auditor_fp_violation": 0.05937107966128274,
            "ave_precision_score": 0.7111596635776711,
            "fpr": 0.1877058177826564,
            "logloss": 1.419112851989699,
            "mae": 0.4423302798008687,
            "precision": 0.6607142857142857,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.767407850057335,
            "auditor_fn_violation": 0.006500786079251093,
            "auditor_fp_violation": 0.002958703171229738,
            "ave_precision_score": 0.7677239767243541,
            "fpr": 0.02850877192982456,
            "logloss": 1.9105246937964806,
            "mae": 0.3979611881730298,
            "precision": 0.8834080717488789,
            "recall": 0.40122199592668023
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.712894496838327,
            "auditor_fn_violation": 0.01075883193888946,
            "auditor_fp_violation": 0.005032734828289165,
            "ave_precision_score": 0.7134662801749754,
            "fpr": 0.036223929747530186,
            "logloss": 1.7931655167111755,
            "mae": 0.4023599719964367,
            "precision": 0.8263157894736842,
            "recall": 0.3390928725701944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 20300,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.766282883456978,
            "auditor_fn_violation": 0.003742809161396363,
            "auditor_fp_violation": 0.003951014710172111,
            "ave_precision_score": 0.5456086563006317,
            "fpr": 0.43530701754385964,
            "logloss": 15.350434943013937,
            "mae": 0.4524213413201406,
            "precision": 0.545766590389016,
            "recall": 0.9714867617107943
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.7487165335950743,
            "auditor_fn_violation": 0.0033286469903483465,
            "auditor_fp_violation": 0.005753097067586655,
            "ave_precision_score": 0.515390946478246,
            "fpr": 0.45993413830954993,
            "logloss": 16.280592463920538,
            "mae": 0.48177268783818483,
            "precision": 0.5156069364161849,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7737882688237955,
            "auditor_fn_violation": 0.0035998856611998476,
            "auditor_fp_violation": 0.00330249614535152,
            "ave_precision_score": 0.7559430727121695,
            "fpr": 0.26535087719298245,
            "logloss": 0.7223150571815531,
            "mae": 0.40844642389192976,
            "precision": 0.6310975609756098,
            "recall": 0.8431771894093686
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7572573902871023,
            "auditor_fn_violation": 0.012081755742745852,
            "auditor_fp_violation": 0.010310490826407403,
            "ave_precision_score": 0.7414838981899499,
            "fpr": 0.27991218441273324,
            "logloss": 0.76525347847375,
            "mae": 0.41355616733729306,
            "precision": 0.6046511627906976,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 20300,
        "test": {
            "accuracy": 0.45723684210526316,
            "auc_prc": 0.8248788940455337,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.002125265658207276,
            "ave_precision_score": 0.8261034955926859,
            "fpr": 0.0043859649122807015,
            "logloss": 2.4583023840021045,
            "mae": 0.5293328890562016,
            "precision": 0.0,
            "recall": 0.0
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.7805064058167951,
            "auditor_fn_violation": 0.0006211577717031851,
            "auditor_fp_violation": 0.0026854320213266425,
            "ave_precision_score": 0.7819356569836848,
            "fpr": 0.008781558726673985,
            "logloss": 2.309935633637309,
            "mae": 0.5025123739867944,
            "precision": 0.1111111111111111,
            "recall": 0.0021598272138228943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 20300,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6943578744395913,
            "mae": 0.500553331746344,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.49176728869374314,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6934885531904731,
            "mae": 0.5001187012433744,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7671355448366494,
            "auditor_fn_violation": 0.049100921856576274,
            "auditor_fp_violation": 0.02623244572238197,
            "ave_precision_score": 0.7613132999388198,
            "fpr": 0.11403508771929824,
            "logloss": 0.6111168185891005,
            "mae": 0.39617619321992,
            "precision": 0.7419354838709677,
            "recall": 0.6089613034623218
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7477600143906324,
            "auditor_fn_violation": 0.046733824411500424,
            "auditor_fp_violation": 0.03110788772149914,
            "ave_precision_score": 0.7438847302551674,
            "fpr": 0.13172338090010977,
            "logloss": 0.604023131298336,
            "mae": 0.3898601083720816,
            "precision": 0.7022332506203474,
            "recall": 0.6112311015118791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 20300,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7210620214339222,
            "auditor_fn_violation": 0.03301309536570552,
            "auditor_fp_violation": 0.03982789515356086,
            "ave_precision_score": 0.6999953114681601,
            "fpr": 0.11732456140350878,
            "logloss": 0.6184795323682867,
            "mae": 0.42544055341236425,
            "precision": 0.7409200968523002,
            "recall": 0.6232179226069247
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7433891355184452,
            "auditor_fn_violation": 0.027722129101241604,
            "auditor_fp_violation": 0.03737552924572683,
            "ave_precision_score": 0.7079111336136581,
            "fpr": 0.12952799121844127,
            "logloss": 0.614610032148641,
            "mae": 0.4230157871179602,
            "precision": 0.7223529411764706,
            "recall": 0.6630669546436285
        }
    }
]