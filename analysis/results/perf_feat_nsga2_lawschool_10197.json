[
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(0)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.780121095534165,
            "auditor_fn_violation": 0.017817982456140354,
            "auditor_fp_violation": 0.012959917153996102,
            "ave_precision_score": 0.7806264500517957,
            "fpr": 0.07236842105263158,
            "logloss": 0.692404889124048,
            "mae": 0.38846274939885067,
            "precision": 0.7573529411764706,
            "recall": 0.42916666666666664
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7462879338730721,
            "auditor_fn_violation": 0.013401603468159906,
            "auditor_fp_violation": 0.003524178173204693,
            "ave_precision_score": 0.7466820144399335,
            "fpr": 0.07244785949506037,
            "logloss": 0.8533559642354699,
            "mae": 0.4075553751466979,
            "precision": 0.7215189873417721,
            "recall": 0.36075949367088606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(1)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5636856133670154,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5656001283954686,
            "fpr": 0.29605263157894735,
            "logloss": 0.6881285717328446,
            "mae": 0.496512803494146,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5666058660084902,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5686834363172641,
            "fpr": 0.287596048298573,
            "logloss": 0.6883851894730881,
            "mae": 0.4966554982602007,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(2)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.609893056209196,
            "auditor_fn_violation": 0.0005322551169590643,
            "auditor_fp_violation": 0.0018046418128654994,
            "ave_precision_score": 0.6111952372903422,
            "fpr": 0.46381578947368424,
            "logloss": 0.6919942898849958,
            "mae": 0.4867133941305311,
            "precision": 0.5310421286031042,
            "recall": 0.9979166666666667
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5429570113363147,
            "auditor_fn_violation": 0.001908229006007216,
            "auditor_fp_violation": 0.001971831693489455,
            "ave_precision_score": 0.5440904599276466,
            "fpr": 0.47200878155872666,
            "logloss": 0.6961615738785871,
            "mae": 0.49185476037464076,
            "precision": 0.5222222222222223,
            "recall": 0.9915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(3)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5838721900694862,
            "auditor_fn_violation": 0.08374680190058481,
            "auditor_fp_violation": 0.0862293900259909,
            "ave_precision_score": 0.5847939289453328,
            "fpr": 0.2817982456140351,
            "logloss": 0.6877625391395707,
            "mae": 0.4962388966559318,
            "precision": 0.5702341137123745,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5912680750788724,
            "auditor_fn_violation": 0.08580777834901138,
            "auditor_fp_violation": 0.08943324282165348,
            "ave_precision_score": 0.5927668851606667,
            "fpr": 0.27771679473106475,
            "logloss": 0.686412490939493,
            "mae": 0.4955813462726371,
            "precision": 0.5607638888888888,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(4)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7754629005813325,
            "auditor_fn_violation": 0.010444078947368427,
            "auditor_fp_violation": 0.028524000974658868,
            "ave_precision_score": 0.7662443372005867,
            "fpr": 0.22039473684210525,
            "logloss": 1.7101514886850855,
            "mae": 0.313208039642852,
            "precision": 0.6715686274509803,
            "recall": 0.85625
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7966329781252062,
            "auditor_fn_violation": 0.012327066746330599,
            "auditor_fp_violation": 0.02427236898622733,
            "ave_precision_score": 0.7901594685790293,
            "fpr": 0.22283205268935236,
            "logloss": 1.5487839782106525,
            "mae": 0.3023931751805691,
            "precision": 0.6715210355987055,
            "recall": 0.8755274261603375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(5)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6166062528845703,
            "auditor_fn_violation": 0.014978527046783631,
            "auditor_fp_violation": 0.012883771929824562,
            "ave_precision_score": 0.6240498923406935,
            "fpr": 0.05921052631578947,
            "logloss": 11.711969020888189,
            "mae": 0.4366784501025835,
            "precision": 0.7172774869109948,
            "recall": 0.28541666666666665
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.589302832264546,
            "auditor_fn_violation": 0.0060952169221007236,
            "auditor_fp_violation": 0.0087237853139985,
            "ave_precision_score": 0.5973279326338928,
            "fpr": 0.06037321624588365,
            "logloss": 11.734277150604976,
            "mae": 0.44156224980340836,
            "precision": 0.6978021978021978,
            "recall": 0.2679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(6)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7844156270893486,
            "auditor_fn_violation": 0.01049205043859649,
            "auditor_fp_violation": 0.027767625081221575,
            "ave_precision_score": 0.7718637259149985,
            "fpr": 0.2324561403508772,
            "logloss": 1.9368427101874308,
            "mae": 0.31343472566791125,
            "precision": 0.6661417322834645,
            "recall": 0.88125
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.803644901989202,
            "auditor_fn_violation": 0.016027734163320317,
            "auditor_fp_violation": 0.025103803751252807,
            "ave_precision_score": 0.7952553464147555,
            "fpr": 0.22941822173435786,
            "logloss": 1.7245113434562096,
            "mae": 0.3028134422626067,
            "precision": 0.6703470031545742,
            "recall": 0.8966244725738397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(7)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5827524385929316,
            "auditor_fn_violation": 0.0006304824561403512,
            "auditor_fp_violation": 0.011728902696556218,
            "ave_precision_score": 0.5832316593934095,
            "fpr": 0.43969298245614036,
            "logloss": 2.1358448198290385,
            "mae": 0.4474208074707093,
            "precision": 0.5417142857142857,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5430876053883069,
            "auditor_fn_violation": 0.003089293075259255,
            "auditor_fp_violation": 0.003077062196846602,
            "ave_precision_score": 0.543355462665188,
            "fpr": 0.45554335894621295,
            "logloss": 2.4395640313969356,
            "mae": 0.4652268801172905,
            "precision": 0.52894438138479,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(8)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7742964278169961,
            "auditor_fn_violation": 0.009320175438596496,
            "auditor_fp_violation": 0.02535635964912281,
            "ave_precision_score": 0.7548519602195054,
            "fpr": 0.20723684210526316,
            "logloss": 2.2454045844999455,
            "mae": 0.3047297418739865,
            "precision": 0.6791171477079796,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7938761389191551,
            "auditor_fn_violation": 0.00787839208548125,
            "auditor_fp_violation": 0.02322491189554568,
            "ave_precision_score": 0.7808618817155497,
            "fpr": 0.21075740944017562,
            "logloss": 1.9853771464382748,
            "mae": 0.2927457751691159,
            "precision": 0.678391959798995,
            "recall": 0.8544303797468354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(9)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6626230651410596,
            "auditor_fn_violation": 0.003686951754385965,
            "auditor_fp_violation": 0.004682931286549716,
            "ave_precision_score": 0.5782161430964478,
            "fpr": 0.4331140350877193,
            "logloss": 0.7494621358074971,
            "mae": 0.4746067427556243,
            "precision": 0.5417633410672854,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.643720350716241,
            "auditor_fn_violation": 0.0017021217468632332,
            "auditor_fp_violation": 0.008000361711801105,
            "ave_precision_score": 0.5635017851267865,
            "fpr": 0.44017563117453345,
            "logloss": 0.75588989473647,
            "mae": 0.47851797715892647,
            "precision": 0.5337209302325582,
            "recall": 0.9683544303797469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(10)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7798985871462086,
            "auditor_fn_violation": 0.016059027777777814,
            "auditor_fp_violation": 0.013462475633528264,
            "ave_precision_score": 0.7804078241298711,
            "fpr": 0.0712719298245614,
            "logloss": 0.6985063783320812,
            "mae": 0.3892291660450648,
            "precision": 0.7565543071161048,
            "recall": 0.42083333333333334
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7470833516591272,
            "auditor_fn_violation": 0.011826851375823856,
            "auditor_fp_violation": 0.004609313576500793,
            "ave_precision_score": 0.7474765105929586,
            "fpr": 0.07025246981339188,
            "logloss": 0.8585057129959901,
            "mae": 0.4080420298157843,
            "precision": 0.7229437229437229,
            "recall": 0.35232067510548526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(11)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5568931730762281,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5588668423339618,
            "fpr": 0.29605263157894735,
            "logloss": 0.687973428897035,
            "mae": 0.49648715748467986,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5880843419168941,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5900223914108793,
            "fpr": 0.287596048298573,
            "logloss": 0.688490269664342,
            "mae": 0.49676897140418136,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(12)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5826341624631443,
            "auditor_fn_violation": 0.0006304824561403512,
            "auditor_fp_violation": 0.011391325536062397,
            "ave_precision_score": 0.5824016186442572,
            "fpr": 0.4407894736842105,
            "logloss": 2.1765750513730944,
            "mae": 0.44778665805807905,
            "precision": 0.541095890410959,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.545518346919355,
            "auditor_fn_violation": 0.003089293075259255,
            "auditor_fp_violation": 0.003077062196846602,
            "ave_precision_score": 0.5438477537799242,
            "fpr": 0.45554335894621295,
            "logloss": 2.4864898339361403,
            "mae": 0.4653268705380948,
            "precision": 0.52894438138479,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(13)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5857813987242747,
            "auditor_fn_violation": 0.0010416666666666667,
            "auditor_fp_violation": 0.007101811241065625,
            "ave_precision_score": 0.5851763203295764,
            "fpr": 0.4550438596491228,
            "logloss": 2.102521582107594,
            "mae": 0.45651408594188214,
            "precision": 0.5352743561030235,
            "recall": 0.9958333333333333
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.5440278229813632,
            "auditor_fn_violation": 0.0020842307104447745,
            "auditor_fp_violation": 0.003953710937009409,
            "ave_precision_score": 0.5422796006669686,
            "fpr": 0.4665203073545554,
            "logloss": 2.4015768923178564,
            "mae": 0.47184204053579454,
            "precision": 0.5251396648044693,
            "recall": 0.9915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(14)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7746271651586727,
            "auditor_fn_violation": 0.010444078947368427,
            "auditor_fp_violation": 0.023886756822612088,
            "ave_precision_score": 0.7653883539347007,
            "fpr": 0.22039473684210525,
            "logloss": 1.718707374816339,
            "mae": 0.31253205626700536,
            "precision": 0.6715686274509803,
            "recall": 0.85625
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.798110300000523,
            "auditor_fn_violation": 0.010073781767149749,
            "auditor_fp_violation": 0.023222400008038057,
            "ave_precision_score": 0.7920133760951701,
            "fpr": 0.21844127332601537,
            "logloss": 1.5246458025282397,
            "mae": 0.3013592102916545,
            "precision": 0.6753670473083198,
            "recall": 0.8734177215189873
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(15)",
        "seed": 10197,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7784794523166414,
            "auditor_fn_violation": 0.016059027777777814,
            "auditor_fp_violation": 0.012548732943469787,
            "ave_precision_score": 0.7789928558522705,
            "fpr": 0.07017543859649122,
            "logloss": 0.6996276521586807,
            "mae": 0.3901912722948875,
            "precision": 0.7593984962406015,
            "recall": 0.42083333333333334
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.7455044724436103,
            "auditor_fn_violation": 0.011810640692520398,
            "auditor_fp_violation": 0.004609313576500793,
            "ave_precision_score": 0.7459017718142196,
            "fpr": 0.07025246981339188,
            "logloss": 0.8585230792408598,
            "mae": 0.4088122045007764,
            "precision": 0.7241379310344828,
            "recall": 0.35443037974683544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(16)",
        "seed": 10197,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7791266483704152,
            "auditor_fn_violation": 0.01729714912280702,
            "auditor_fp_violation": 0.012959917153996102,
            "ave_precision_score": 0.7796346903832175,
            "fpr": 0.07236842105263158,
            "logloss": 0.6934198553263703,
            "mae": 0.38910890292895406,
            "precision": 0.7555555555555555,
            "recall": 0.425
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.74549523513239,
            "auditor_fn_violation": 0.013401603468159906,
            "auditor_fp_violation": 0.003524178173204693,
            "ave_precision_score": 0.7458917152551272,
            "fpr": 0.07244785949506037,
            "logloss": 0.853658760075917,
            "mae": 0.40807278635421584,
            "precision": 0.7215189873417721,
            "recall": 0.36075949367088606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(17)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8287159956213975,
            "auditor_fn_violation": 0.01422697368421054,
            "auditor_fp_violation": 0.013767056530214424,
            "ave_precision_score": 0.8290825044274254,
            "fpr": 0.11732456140350878,
            "logloss": 0.7244730383734954,
            "mae": 0.2806794766470295,
            "precision": 0.7611607142857143,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8538264659587258,
            "auditor_fn_violation": 0.008332291217978122,
            "auditor_fp_violation": 0.01164762237287966,
            "ave_precision_score": 0.8540437113525434,
            "fpr": 0.11306256860592755,
            "logloss": 0.6424582340357858,
            "mae": 0.26063537230597966,
            "precision": 0.7706013363028953,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(18)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5845824906026962,
            "auditor_fn_violation": 0.08374680190058481,
            "auditor_fp_violation": 0.08845029239766082,
            "ave_precision_score": 0.5854854830540178,
            "fpr": 0.2807017543859649,
            "logloss": 0.6877193442757367,
            "mae": 0.49621017084440644,
            "precision": 0.5711892797319933,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5929904412688258,
            "auditor_fn_violation": 0.08580777834901138,
            "auditor_fp_violation": 0.08943324282165348,
            "ave_precision_score": 0.5944875221372751,
            "fpr": 0.27771679473106475,
            "logloss": 0.6863289650778668,
            "mae": 0.49553307203901065,
            "precision": 0.5607638888888888,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(19)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.7789402975313394,
            "auditor_fn_violation": 0.01647021198830411,
            "auditor_fp_violation": 0.012959917153996102,
            "ave_precision_score": 0.7794516615997787,
            "fpr": 0.07236842105263158,
            "logloss": 0.6912602200328418,
            "mae": 0.3889212205708509,
            "precision": 0.7564575645756457,
            "recall": 0.4270833333333333
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.7452631136279895,
            "auditor_fn_violation": 0.014038451740795797,
            "auditor_fp_violation": 0.003524178173204693,
            "ave_precision_score": 0.7456604441541999,
            "fpr": 0.07244785949506037,
            "logloss": 0.8524062281993384,
            "mae": 0.407851438147023,
            "precision": 0.7226890756302521,
            "recall": 0.3628691983122363
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(20)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.5885050806508231,
            "auditor_fn_violation": 0.08301123903508772,
            "auditor_fp_violation": 0.08547301413255362,
            "ave_precision_score": 0.5894099720323045,
            "fpr": 0.27960526315789475,
            "logloss": 0.6875418814633615,
            "mae": 0.4960794479243065,
            "precision": 0.5707070707070707,
            "recall": 0.70625
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6012736081565813,
            "auditor_fn_violation": 0.08580777834901138,
            "auditor_fp_violation": 0.08903636459544796,
            "ave_precision_score": 0.6025635106130698,
            "fpr": 0.27661909989023054,
            "logloss": 0.6858903677576231,
            "mae": 0.4952748289288857,
            "precision": 0.5617391304347826,
            "recall": 0.6814345991561181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(21)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5619201128173613,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5638464147862442,
            "fpr": 0.29605263157894735,
            "logloss": 0.6881080155403345,
            "mae": 0.4965048799650711,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5620452453979442,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5641431118637088,
            "fpr": 0.287596048298573,
            "logloss": 0.6885084398468532,
            "mae": 0.4967204846613493,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(22)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6622807017543859,
            "auc_prc": 0.7848005363303759,
            "auditor_fn_violation": 0.017326845760233918,
            "auditor_fp_violation": 0.00811708089668617,
            "ave_precision_score": 0.7852315509166186,
            "fpr": 0.13486842105263158,
            "logloss": 0.7219158394165937,
            "mae": 0.4023374185933245,
            "precision": 0.7057416267942583,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7717056919597417,
            "auditor_fn_violation": 0.019244396893106752,
            "auditor_fp_violation": 0.008266621787609866,
            "ave_precision_score": 0.7720456678695707,
            "fpr": 0.11086717892425905,
            "logloss": 0.7426263757921066,
            "mae": 0.41152138488104545,
            "precision": 0.7277628032345014,
            "recall": 0.569620253164557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(23)",
        "seed": 10197,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.619667100348631,
            "auditor_fn_violation": 0.013596491228070192,
            "auditor_fp_violation": 0.01145224171539961,
            "ave_precision_score": 0.6256608995888453,
            "fpr": 0.0625,
            "logloss": 11.776383680159597,
            "mae": 0.43279481046160606,
            "precision": 0.7164179104477612,
            "recall": 0.3
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5916017105325895,
            "auditor_fn_violation": 0.006836276730258873,
            "auditor_fp_violation": 0.007837089023805161,
            "ave_precision_score": 0.5988005772644311,
            "fpr": 0.06147091108671789,
            "logloss": 11.812041501110965,
            "mae": 0.439676652051204,
            "precision": 0.6972972972972973,
            "recall": 0.2721518987341772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(24)",
        "seed": 10197,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6222561499748949,
            "auditor_fn_violation": 0.01544225146198832,
            "auditor_fp_violation": 0.012185774041585445,
            "ave_precision_score": 0.6298361449286003,
            "fpr": 0.0581140350877193,
            "logloss": 11.673308517373565,
            "mae": 0.431550552166017,
            "precision": 0.7253886010362695,
            "recall": 0.2916666666666667
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5930960739522194,
            "auditor_fn_violation": 0.0060952169221007236,
            "auditor_fp_violation": 0.008271645562625126,
            "ave_precision_score": 0.6010921021475047,
            "fpr": 0.0570801317233809,
            "logloss": 11.7204275937022,
            "mae": 0.4390769504685701,
            "precision": 0.7094972067039106,
            "recall": 0.2679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(25)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6414473684210527,
            "auc_prc": 0.7762116063376233,
            "auditor_fn_violation": 0.013904879385964922,
            "auditor_fp_violation": 0.014274691358024692,
            "ave_precision_score": 0.7767099283019928,
            "fpr": 0.07456140350877193,
            "logloss": 0.7098117340733838,
            "mae": 0.3874728523621519,
            "precision": 0.7647058823529411,
            "recall": 0.46041666666666664
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.7392225370909394,
            "auditor_fn_violation": 0.014839722658366812,
            "auditor_fp_violation": 0.0011931465661241876,
            "ave_precision_score": 0.7396182629898216,
            "fpr": 0.0801317233809001,
            "logloss": 0.8909554754313059,
            "mae": 0.4062158237467629,
            "precision": 0.7192307692307692,
            "recall": 0.39451476793248946
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(26)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8269274398281292,
            "auditor_fn_violation": 0.013020833333333343,
            "auditor_fp_violation": 0.02063281757634828,
            "ave_precision_score": 0.8273641484838713,
            "fpr": 0.13048245614035087,
            "logloss": 0.6990772219371605,
            "mae": 0.2828213041809415,
            "precision": 0.7494736842105263,
            "recall": 0.7416666666666667
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8538621391683996,
            "auditor_fn_violation": 0.0017507537967736179,
            "auditor_fp_violation": 0.014259985380814707,
            "ave_precision_score": 0.8540872081036373,
            "fpr": 0.11855104281009879,
            "logloss": 0.6198083983163283,
            "mae": 0.26232912721059104,
            "precision": 0.7662337662337663,
            "recall": 0.7468354430379747
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(27)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6021744686908508,
            "auditor_fn_violation": 0.05595531798245615,
            "auditor_fp_violation": 0.056469298245614044,
            "ave_precision_score": 0.6032750685881614,
            "fpr": 0.35526315789473684,
            "logloss": 0.6872170328689717,
            "mae": 0.49490478497586754,
            "precision": 0.5443037974683544,
            "recall": 0.80625
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.5903921590805367,
            "auditor_fn_violation": 0.051700500678532886,
            "auditor_fp_violation": 0.06618572393853914,
            "ave_precision_score": 0.5914981968117801,
            "fpr": 0.33699231613611413,
            "logloss": 0.6851236549825295,
            "mae": 0.493900184181205,
            "precision": 0.5511695906432749,
            "recall": 0.7953586497890295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(28)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.582969021068985,
            "auditor_fn_violation": 0.0006304824561403512,
            "auditor_fp_violation": 0.011728902696556218,
            "ave_precision_score": 0.5838169235946324,
            "fpr": 0.43969298245614036,
            "logloss": 2.146947481882742,
            "mae": 0.44687542339358094,
            "precision": 0.5417142857142857,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5434215633161799,
            "auditor_fn_violation": 0.003089293075259255,
            "auditor_fp_violation": 0.003077062196846602,
            "ave_precision_score": 0.5438017541752156,
            "fpr": 0.45554335894621295,
            "logloss": 2.4533453950813753,
            "mae": 0.46467126158817823,
            "precision": 0.52894438138479,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(29)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8279606008463176,
            "auditor_fn_violation": 0.01576206140350878,
            "auditor_fp_violation": 0.017787524366471734,
            "ave_precision_score": 0.8284089033614348,
            "fpr": 0.1162280701754386,
            "logloss": 0.7175450720479531,
            "mae": 0.2806081385995584,
            "precision": 0.7623318385650224,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8553144668554167,
            "auditor_fn_violation": 0.006785328868447999,
            "auditor_fp_violation": 0.010997043508403522,
            "ave_precision_score": 0.8555242252308077,
            "fpr": 0.11306256860592755,
            "logloss": 0.6375025651307273,
            "mae": 0.2607170694963256,
            "precision": 0.7706013363028953,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(30)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8602448827200049,
            "auditor_fn_violation": 0.021262792397660824,
            "auditor_fp_violation": 0.015416869720597791,
            "ave_precision_score": 0.8604819568181136,
            "fpr": 0.08662280701754387,
            "logloss": 0.5222978888781532,
            "mae": 0.28661927300313356,
            "precision": 0.8119047619047619,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.86187288018902,
            "auditor_fn_violation": 0.026182569346987365,
            "auditor_fp_violation": 0.01649807715011291,
            "ave_precision_score": 0.8621538441601699,
            "fpr": 0.06586169045005488,
            "logloss": 0.5226091154411477,
            "mae": 0.2929939441393108,
            "precision": 0.8378378378378378,
            "recall": 0.6540084388185654
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(31)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5818938459847176,
            "auditor_fn_violation": 0.0006304824561403512,
            "auditor_fp_violation": 0.011728902696556218,
            "ave_precision_score": 0.5828234129302476,
            "fpr": 0.43969298245614036,
            "logloss": 2.1203639484002847,
            "mae": 0.44659905481859863,
            "precision": 0.5417142857142857,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5438824492035373,
            "auditor_fn_violation": 0.003089293075259255,
            "auditor_fp_violation": 0.003077062196846602,
            "ave_precision_score": 0.5436041010122861,
            "fpr": 0.45554335894621295,
            "logloss": 2.423068866654679,
            "mae": 0.4645484191837038,
            "precision": 0.52894438138479,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(32)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5568560884715694,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5588814467739485,
            "fpr": 0.29605263157894735,
            "logloss": 0.6879688604391605,
            "mae": 0.4964853173546624,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5849788401501552,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5869805810066635,
            "fpr": 0.287596048298573,
            "logloss": 0.6885311679587303,
            "mae": 0.4967899738630008,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(33)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8275471586440706,
            "auditor_fn_violation": 0.015316611842105268,
            "auditor_fp_violation": 0.010211074561403511,
            "ave_precision_score": 0.8279648660183108,
            "fpr": 0.12828947368421054,
            "logloss": 0.7041064969587529,
            "mae": 0.282991092222769,
            "precision": 0.7521186440677966,
            "recall": 0.7395833333333334
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8524770655030056,
            "auditor_fn_violation": 0.0007920076699690172,
            "auditor_fp_violation": 0.014159509880509518,
            "ave_precision_score": 0.8527069614875363,
            "fpr": 0.11964873765093303,
            "logloss": 0.6275722780482401,
            "mae": 0.2633057231849855,
            "precision": 0.7635574837310195,
            "recall": 0.7426160337552743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(34)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5622704972057813,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5641839591677624,
            "fpr": 0.29605263157894735,
            "logloss": 0.688117574468641,
            "mae": 0.496509160356302,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5636695895252061,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5657446884576245,
            "fpr": 0.287596048298573,
            "logloss": 0.6884756039920696,
            "mae": 0.4967032466185996,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(35)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(36)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5569996126704773,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5590722719484252,
            "fpr": 0.29605263157894735,
            "logloss": 0.6879731612359326,
            "mae": 0.49648704948393924,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5879225435437352,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5899032122459484,
            "fpr": 0.287596048298573,
            "logloss": 0.6884922535549033,
            "mae": 0.49676999387573595,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(37)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(38)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(39)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(40)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(41)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.5245371987352129,
            "auditor_fn_violation": 0.08491182383040935,
            "auditor_fp_violation": 0.08394249512670567,
            "ave_precision_score": 0.5427013690553952,
            "fpr": 0.26973684210526316,
            "logloss": 0.6788066515458043,
            "mae": 0.4885564328588978,
            "precision": 0.5780445969125214,
            "recall": 0.7020833333333333
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5194340714477771,
            "auditor_fn_violation": 0.0822090066556434,
            "auditor_fp_violation": 0.08077225469534574,
            "ave_precision_score": 0.5344908403778902,
            "fpr": 0.2623490669593853,
            "logloss": 0.6833470857091617,
            "mae": 0.4903003597298778,
            "precision": 0.5716845878136201,
            "recall": 0.6729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(42)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.860773218984144,
            "auditor_fn_violation": 0.01731085526315791,
            "auditor_fp_violation": 0.014833089668615984,
            "ave_precision_score": 0.8610051404039737,
            "fpr": 0.08552631578947369,
            "logloss": 0.5214848988669983,
            "mae": 0.2866945452263105,
            "precision": 0.8142857142857143,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8622160259531455,
            "auditor_fn_violation": 0.023885283941697123,
            "auditor_fp_violation": 0.014938195007874768,
            "ave_precision_score": 0.8624884289782897,
            "fpr": 0.06256860592755215,
            "logloss": 0.5223871734249531,
            "mae": 0.2931217306511299,
            "precision": 0.8434065934065934,
            "recall": 0.6476793248945147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(43)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(44)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(45)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(46)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(47)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(48)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(49)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.863674163396755,
            "auditor_fn_violation": 0.01898300438596492,
            "auditor_fp_violation": 0.014193469785575051,
            "ave_precision_score": 0.8638998956087636,
            "fpr": 0.09210526315789473,
            "logloss": 0.5142353188715793,
            "mae": 0.2826917590992117,
            "precision": 0.8064516129032258,
            "recall": 0.7291666666666666
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8705538351232178,
            "auditor_fn_violation": 0.020962729323273453,
            "auditor_fp_violation": 0.01418714064309344,
            "ave_precision_score": 0.8707059910275688,
            "fpr": 0.06366630076838639,
            "logloss": 0.5050769587988853,
            "mae": 0.28597247898047046,
            "precision": 0.8473684210526315,
            "recall": 0.679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(50)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.43485620599013575,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09145041423001951,
            "ave_precision_score": 0.4360515730379777,
            "fpr": 0.2949561403508772,
            "logloss": 0.6879211763462392,
            "mae": 0.49646786021951,
            "precision": 0.5633116883116883,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.424517612080085,
            "auditor_fn_violation": 0.08489766427211716,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.42599232567251627,
            "fpr": 0.287596048298573,
            "logloss": 0.6885211059481255,
            "mae": 0.49679101694428435,
            "precision": 0.5574324324324325,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(51)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6217783381890604,
            "auditor_fn_violation": 0.01544225146198832,
            "auditor_fp_violation": 0.01272132878492528,
            "ave_precision_score": 0.6292191498424322,
            "fpr": 0.05701754385964912,
            "logloss": 11.680345499566055,
            "mae": 0.43191933363116025,
            "precision": 0.7291666666666666,
            "recall": 0.2916666666666667
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.5926356291880185,
            "auditor_fn_violation": 0.0060952169221007236,
            "auditor_fp_violation": 0.008271645562625126,
            "ave_precision_score": 0.6006530474033057,
            "fpr": 0.0570801317233809,
            "logloss": 11.727180321852536,
            "mae": 0.43930701723754184,
            "precision": 0.7094972067039106,
            "recall": 0.2679324894514768
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(52)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.7341335998199497,
            "auditor_fn_violation": 0.0026133040935672524,
            "auditor_fp_violation": 0.012365984405458087,
            "ave_precision_score": 0.7347231067912388,
            "fpr": 0.24013157894736842,
            "logloss": 0.8083859489206661,
            "mae": 0.397205243893256,
            "precision": 0.6262798634812287,
            "recall": 0.7645833333333333
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7100098148008032,
            "auditor_fn_violation": 0.01028220483819422,
            "auditor_fp_violation": 0.012524271113042476,
            "ave_precision_score": 0.7107307380912342,
            "fpr": 0.24259055982436883,
            "logloss": 0.8546732923341804,
            "mae": 0.4066949558867047,
            "precision": 0.6228668941979523,
            "recall": 0.770042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(53)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5888157894736842,
            "auc_prc": 0.7198395757118489,
            "auditor_fn_violation": 0.029422514619883045,
            "auditor_fp_violation": 0.015277270142949969,
            "ave_precision_score": 0.7204420915383518,
            "fpr": 0.03837719298245614,
            "logloss": 1.0564835548935587,
            "mae": 0.4187399387047505,
            "precision": 0.8,
            "recall": 0.2916666666666667
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7030189504176746,
            "auditor_fn_violation": 0.014890670520177684,
            "auditor_fp_violation": 0.014307711243459675,
            "ave_precision_score": 0.7039547545971241,
            "fpr": 0.04061470911086718,
            "logloss": 1.0832865319400222,
            "mae": 0.4248460636380409,
            "precision": 0.7672955974842768,
            "recall": 0.25738396624472576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(54)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6626608398354401,
            "auditor_fn_violation": 0.003686951754385965,
            "auditor_fp_violation": 0.004682931286549716,
            "ave_precision_score": 0.5782529078930067,
            "fpr": 0.4331140350877193,
            "logloss": 0.7492124587347524,
            "mae": 0.47501651776072223,
            "precision": 0.5417633410672854,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.6437140171365561,
            "auditor_fn_violation": 0.0017021217468632332,
            "auditor_fp_violation": 0.008000361711801105,
            "ave_precision_score": 0.5634949874958577,
            "fpr": 0.44017563117453345,
            "logloss": 0.7555798242047834,
            "mae": 0.47892455444246956,
            "precision": 0.5337209302325582,
            "recall": 0.9683544303797469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(55)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7846503294711266,
            "auditor_fn_violation": 0.017326845760233918,
            "auditor_fp_violation": 0.007208414554905794,
            "ave_precision_score": 0.7850574835655914,
            "fpr": 0.1337719298245614,
            "logloss": 0.7223107091633981,
            "mae": 0.4027364959038674,
            "precision": 0.7074340527577938,
            "recall": 0.6145833333333334
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7712573064351335,
            "auditor_fn_violation": 0.01601383929191735,
            "auditor_fp_violation": 0.008266621787609866,
            "ave_precision_score": 0.7715985408284728,
            "fpr": 0.11086717892425905,
            "logloss": 0.7431034591687817,
            "mae": 0.41186180089385027,
            "precision": 0.7255434782608695,
            "recall": 0.5632911392405063
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(56)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5818613075697554,
            "auditor_fn_violation": 0.0006304824561403512,
            "auditor_fp_violation": 0.011391325536062397,
            "ave_precision_score": 0.582360619338407,
            "fpr": 0.4407894736842105,
            "logloss": 2.1648114271873307,
            "mae": 0.44782518746678146,
            "precision": 0.541095890410959,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.5454829138789247,
            "auditor_fn_violation": 0.003089293075259255,
            "auditor_fp_violation": 0.003077062196846602,
            "ave_precision_score": 0.5438736691052524,
            "fpr": 0.45554335894621295,
            "logloss": 2.471561688807394,
            "mae": 0.46541852708579473,
            "precision": 0.52894438138479,
            "recall": 0.9831223628691983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(57)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7748301361144337,
            "auditor_fn_violation": 0.011305281432748537,
            "auditor_fp_violation": 0.023566946881091618,
            "ave_precision_score": 0.7550890686943605,
            "fpr": 0.2138157894736842,
            "logloss": 2.2677439581076237,
            "mae": 0.3092185751346887,
            "precision": 0.6728187919463087,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7922957748965707,
            "auditor_fn_violation": 0.005187418657106997,
            "auditor_fp_violation": 0.023604206909197782,
            "ave_precision_score": 0.7777021439188685,
            "fpr": 0.21185510428100987,
            "logloss": 2.045420831788797,
            "mae": 0.2968798959155997,
            "precision": 0.6767169179229481,
            "recall": 0.8523206751054853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(58)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5569032391699932,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5588708345305409,
            "fpr": 0.29605263157894735,
            "logloss": 0.6879678200591364,
            "mae": 0.4964848388836049,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5845186536466139,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5864954062469242,
            "fpr": 0.287596048298573,
            "logloss": 0.6885362168203562,
            "mae": 0.49679255672003647,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(59)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5725768205165682,
            "auditor_fn_violation": 0.08311175073099417,
            "auditor_fp_violation": 0.09176007147498377,
            "ave_precision_score": 0.5733531058194652,
            "fpr": 0.2850877192982456,
            "logloss": 0.688080067952078,
            "mae": 0.4964275499969198,
            "precision": 0.56738768718802,
            "recall": 0.7104166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6156572082750962,
            "auditor_fn_violation": 0.08614820269838404,
            "auditor_fp_violation": 0.09271376790661807,
            "ave_precision_score": 0.6166672001718287,
            "fpr": 0.283205268935236,
            "logloss": 0.6867725252197947,
            "mae": 0.4958030272655508,
            "precision": 0.5567010309278351,
            "recall": 0.6835443037974683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(60)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.7824591820569213,
            "auditor_fn_violation": 0.01340232090643275,
            "auditor_fp_violation": 0.013531006335282652,
            "ave_precision_score": 0.782943575868114,
            "fpr": 0.0712719298245614,
            "logloss": 0.6949919967831615,
            "mae": 0.386365073116817,
            "precision": 0.7743055555555556,
            "recall": 0.46458333333333335
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.7470923121375215,
            "auditor_fn_violation": 0.012829597928737854,
            "auditor_fp_violation": 0.003519154398189432,
            "ave_precision_score": 0.7474723450262143,
            "fpr": 0.07793633369923161,
            "logloss": 0.8756901340096699,
            "mae": 0.40479250354260565,
            "precision": 0.7193675889328063,
            "recall": 0.38396624472573837
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(61)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6777712300172423,
            "auditor_fn_violation": 0.002638432017543861,
            "auditor_fp_violation": 0.008284600389863563,
            "ave_precision_score": 0.5994721216239192,
            "fpr": 0.40350877192982454,
            "logloss": 0.6834042018143299,
            "mae": 0.4741928495728133,
            "precision": 0.5550181378476421,
            "recall": 0.95625
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6518918185656924,
            "auditor_fn_violation": 0.0033208742653086753,
            "auditor_fp_violation": 0.012838257051496212,
            "ave_precision_score": 0.5761699913653603,
            "fpr": 0.41712403951701427,
            "logloss": 0.6908718567115494,
            "mae": 0.47806452186911086,
            "precision": 0.5432692307692307,
            "recall": 0.9535864978902954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(62)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8278708467142143,
            "auditor_fn_violation": 0.009080317982456143,
            "auditor_fp_violation": 0.022797880116959063,
            "ave_precision_score": 0.8285013840228739,
            "fpr": 0.12390350877192982,
            "logloss": 0.7169324797235134,
            "mae": 0.2820602720769689,
            "precision": 0.7532751091703057,
            "recall": 0.71875
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.858691525121174,
            "auditor_fn_violation": 0.010018202281537887,
            "auditor_fp_violation": 0.01441321051878013,
            "ave_precision_score": 0.8588912423925859,
            "fpr": 0.10976948408342481,
            "logloss": 0.6396168095105572,
            "mae": 0.26279611764291927,
            "precision": 0.7762863534675615,
            "recall": 0.7320675105485233
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(63)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7749078158239207,
            "auditor_fn_violation": 0.007483552631578948,
            "auditor_fp_violation": 0.024328399122807015,
            "ave_precision_score": 0.7584620496190047,
            "fpr": 0.2050438596491228,
            "logloss": 2.1206345340815003,
            "mae": 0.30403030056969915,
            "precision": 0.6792452830188679,
            "recall": 0.825
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7924876308047111,
            "auditor_fn_violation": 0.007730180123849621,
            "auditor_fp_violation": 0.022207597454955583,
            "ave_precision_score": 0.780420880377364,
            "fpr": 0.2074643249176729,
            "logloss": 1.9150821985651318,
            "mae": 0.29153180831422926,
            "precision": 0.6807432432432432,
            "recall": 0.8502109704641351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(64)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5127740822649542,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5301093588210507,
            "fpr": 0.29605263157894735,
            "logloss": 0.6878851523817692,
            "mae": 0.4964419852680804,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.49744922050862417,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5175167758879938,
            "fpr": 0.287596048298573,
            "logloss": 0.6886865085335908,
            "mae": 0.4968673158621029,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(65)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8259500179818717,
            "auditor_fn_violation": 0.012349232456140351,
            "auditor_fp_violation": 0.019188596491228074,
            "ave_precision_score": 0.8263588547928341,
            "fpr": 0.13157894736842105,
            "logloss": 0.7050231253721726,
            "mae": 0.283872556440254,
            "precision": 0.7463002114164905,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8544216203989696,
            "auditor_fn_violation": 0.003327821701010163,
            "auditor_fp_violation": 0.01327532547782381,
            "ave_precision_score": 0.8546444185021116,
            "fpr": 0.11745334796926454,
            "logloss": 0.626148526005582,
            "mae": 0.2637268095914328,
            "precision": 0.7683982683982684,
            "recall": 0.7489451476793249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(66)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.796863620384491,
            "auditor_fn_violation": 0.015323464912280711,
            "auditor_fp_violation": 0.003426535087719301,
            "ave_precision_score": 0.7971738959485897,
            "fpr": 0.08881578947368421,
            "logloss": 0.6222910007031899,
            "mae": 0.40578478960268116,
            "precision": 0.773109243697479,
            "recall": 0.575
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7868230987385225,
            "auditor_fn_violation": 0.0217014733195311,
            "auditor_fp_violation": 0.002745493045839436,
            "ave_precision_score": 0.7871169199810879,
            "fpr": 0.06586169045005488,
            "logloss": 0.6641596414173491,
            "mae": 0.4159797502756297,
            "precision": 0.7966101694915254,
            "recall": 0.4957805907172996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(67)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5350877192982456,
            "auc_prc": 0.6101749128328011,
            "auditor_fn_violation": 0.0005322551169590643,
            "auditor_fp_violation": 0.0018046418128654994,
            "ave_precision_score": 0.6114104337717985,
            "fpr": 0.46381578947368424,
            "logloss": 0.6917860185354445,
            "mae": 0.4867667503524245,
            "precision": 0.5310421286031042,
            "recall": 0.9979166666666667
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5428135755764354,
            "auditor_fn_violation": 0.001908229006007216,
            "auditor_fp_violation": 0.001971831693489455,
            "ave_precision_score": 0.5439536095113624,
            "fpr": 0.47200878155872666,
            "logloss": 0.6959158085221545,
            "mae": 0.49190641440753746,
            "precision": 0.5222222222222223,
            "recall": 0.9915611814345991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(68)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.796225490292426,
            "auditor_fn_violation": 0.017178362573099418,
            "auditor_fp_violation": 0.014010721247563359,
            "ave_precision_score": 0.7966751685547727,
            "fpr": 0.22807017543859648,
            "logloss": 0.7153746793685357,
            "mae": 0.39762588269287324,
            "precision": 0.6682615629984051,
            "recall": 0.8729166666666667
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7929508283354618,
            "auditor_fn_violation": 0.017873436248014192,
            "auditor_fp_violation": 0.014955778220428184,
            "ave_precision_score": 0.7932505737759513,
            "fpr": 0.19099890230515917,
            "logloss": 0.7277327736454318,
            "mae": 0.4043211692409023,
            "precision": 0.6925795053003534,
            "recall": 0.8270042194092827
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(69)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5565268057424794,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5584856810991629,
            "fpr": 0.29605263157894735,
            "logloss": 0.6879473212788231,
            "mae": 0.4964746959638177,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.5803466386376149,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5823115977002764,
            "fpr": 0.287596048298573,
            "logloss": 0.6885725859243282,
            "mae": 0.49681103671159754,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(70)",
        "seed": 10197,
        "test": {
            "accuracy": 0.625,
            "auc_prc": 0.7795807845769958,
            "auditor_fn_violation": 0.016059027777777814,
            "auditor_fp_violation": 0.013198505523066926,
            "ave_precision_score": 0.78008753747448,
            "fpr": 0.07017543859649122,
            "logloss": 0.6978410600338084,
            "mae": 0.3896670268054404,
            "precision": 0.7593984962406015,
            "recall": 0.42083333333333334
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.7452542802818054,
            "auditor_fn_violation": 0.013373813725353975,
            "auditor_fp_violation": 0.004149638162604526,
            "ave_precision_score": 0.7456518286506667,
            "fpr": 0.07135016465422613,
            "logloss": 0.8592550650972703,
            "mae": 0.40882354814432853,
            "precision": 0.7198275862068966,
            "recall": 0.35232067510548526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(71)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.585592062948387,
            "auditor_fn_violation": 0.0006441885964912283,
            "auditor_fp_violation": 0.011391325536062381,
            "ave_precision_score": 0.5859271989239087,
            "fpr": 0.4331140350877193,
            "logloss": 2.154056642082736,
            "mae": 0.4379385816113357,
            "precision": 0.5454545454545454,
            "recall": 0.9875
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.5418371796607717,
            "auditor_fn_violation": 0.0014844354282167785,
            "auditor_fp_violation": 0.007050868233917023,
            "ave_precision_score": 0.5411778469784394,
            "fpr": 0.4445664105378705,
            "logloss": 2.478251163757074,
            "mae": 0.4489490641597924,
            "precision": 0.5355504587155964,
            "recall": 0.9852320675105485
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(72)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6777712300172423,
            "auditor_fn_violation": 0.002638432017543861,
            "auditor_fp_violation": 0.008284600389863563,
            "ave_precision_score": 0.5994721216239192,
            "fpr": 0.40350877192982454,
            "logloss": 0.6834020267157047,
            "mae": 0.4741933635975185,
            "precision": 0.5550181378476421,
            "recall": 0.95625
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6518918185656924,
            "auditor_fn_violation": 0.0033208742653086753,
            "auditor_fp_violation": 0.012838257051496212,
            "ave_precision_score": 0.5761699913653603,
            "fpr": 0.41712403951701427,
            "logloss": 0.6908695362856287,
            "mae": 0.47806492521459265,
            "precision": 0.5432692307692307,
            "recall": 0.9535864978902954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(73)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8298313579301121,
            "auditor_fn_violation": 0.015204678362573104,
            "auditor_fp_violation": 0.007726202079272258,
            "ave_precision_score": 0.8301796030956811,
            "fpr": 0.12719298245614036,
            "logloss": 0.6954046216231717,
            "mae": 0.2824754637605692,
            "precision": 0.7521367521367521,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.852755499450991,
            "auditor_fn_violation": 0.004932679348052644,
            "auditor_fp_violation": 0.01351646667855627,
            "ave_precision_score": 0.8529818485510745,
            "fpr": 0.1119648737650933,
            "logloss": 0.6253187337703028,
            "mae": 0.26431978332860195,
            "precision": 0.7743362831858407,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(74)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8272915801041963,
            "auditor_fn_violation": 0.013569078947368429,
            "auditor_fp_violation": 0.01974445662768031,
            "ave_precision_score": 0.8278428455956681,
            "fpr": 0.12390350877192982,
            "logloss": 0.7105118124534401,
            "mae": 0.2838324749665182,
            "precision": 0.7505518763796909,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8584818842924666,
            "auditor_fn_violation": 0.008508292922415672,
            "auditor_fp_violation": 0.013307980015422988,
            "ave_precision_score": 0.8586817511799035,
            "fpr": 0.10757409440175632,
            "logloss": 0.6253105950595336,
            "mae": 0.2640357218014288,
            "precision": 0.7792792792792793,
            "recall": 0.729957805907173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(75)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6868685693337121,
            "auditor_fn_violation": 0.012294407894736846,
            "auditor_fp_violation": 0.00035026803118908255,
            "ave_precision_score": 0.6874372822141395,
            "fpr": 0.08223684210526316,
            "logloss": 0.7962721506755365,
            "mae": 0.46073153370409364,
            "precision": 0.6987951807228916,
            "recall": 0.3625
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6223093976289571,
            "auditor_fn_violation": 0.0073225972293626445,
            "auditor_fp_violation": 0.00919350827792528,
            "ave_precision_score": 0.6235836726951605,
            "fpr": 0.10537870472008781,
            "logloss": 0.8514782718865015,
            "mae": 0.47125235585962816,
            "precision": 0.6363636363636364,
            "recall": 0.35443037974683544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(76)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7924843122456455,
            "auditor_fn_violation": 0.019449013157894737,
            "auditor_fp_violation": 0.005482456140350881,
            "ave_precision_score": 0.7928850457303837,
            "fpr": 0.09649122807017543,
            "logloss": 0.6189396128440704,
            "mae": 0.40445649703814535,
            "precision": 0.7696335078534031,
            "recall": 0.6125
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7900224368503683,
            "auditor_fn_violation": 0.017391747372711392,
            "auditor_fp_violation": 0.0004873061764801975,
            "ave_precision_score": 0.7903103652594721,
            "fpr": 0.07683863885839737,
            "logloss": 0.6579288987015197,
            "mae": 0.41344870637963754,
            "precision": 0.7839506172839507,
            "recall": 0.5358649789029536
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(77)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8609670669350418,
            "auditor_fn_violation": 0.01731085526315791,
            "auditor_fp_violation": 0.014833089668615984,
            "ave_precision_score": 0.8611951930829644,
            "fpr": 0.08552631578947369,
            "logloss": 0.5220651951404855,
            "mae": 0.28669135818429486,
            "precision": 0.8142857142857143,
            "recall": 0.7125
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8618241291287456,
            "auditor_fn_violation": 0.022292005354157114,
            "auditor_fp_violation": 0.014938195007874768,
            "ave_precision_score": 0.8620978862318824,
            "fpr": 0.06256860592755215,
            "logloss": 0.5232254968953926,
            "mae": 0.29317158178971214,
            "precision": 0.8425414364640884,
            "recall": 0.6434599156118144
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(78)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7830554664123621,
            "auditor_fn_violation": 0.011300712719298249,
            "auditor_fp_violation": 0.02727521929824562,
            "ave_precision_score": 0.774537575274007,
            "fpr": 0.22587719298245615,
            "logloss": 1.6754048037361708,
            "mae": 0.3105898749981223,
            "precision": 0.6693418940609952,
            "recall": 0.86875
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8028202280786197,
            "auditor_fn_violation": 0.015650256823539765,
            "auditor_fp_violation": 0.023591647471659642,
            "ave_precision_score": 0.796683896356275,
            "fpr": 0.2239297475301866,
            "logloss": 1.4970998919775163,
            "mae": 0.2990044789916159,
            "precision": 0.6725521669341894,
            "recall": 0.8839662447257384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(79)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8597521180151702,
            "auditor_fn_violation": 0.02033991228070176,
            "auditor_fp_violation": 0.01832054093567251,
            "ave_precision_score": 0.8599815042468169,
            "fpr": 0.09868421052631579,
            "logloss": 0.517212293020021,
            "mae": 0.2843466622595626,
            "precision": 0.7972972972972973,
            "recall": 0.7375
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.862643939106623,
            "auditor_fn_violation": 0.02770637357751254,
            "auditor_fp_violation": 0.02293102105715298,
            "ave_precision_score": 0.8629046748665825,
            "fpr": 0.0889132821075741,
            "logloss": 0.5124630265386273,
            "mae": 0.2898636907962704,
            "precision": 0.8029197080291971,
            "recall": 0.6962025316455697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(80)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6666666666666666,
            "auc_prc": 0.7841004854597358,
            "auditor_fn_violation": 0.015864857456140354,
            "auditor_fp_violation": 0.007127192982456145,
            "ave_precision_score": 0.7845088230799304,
            "fpr": 0.13706140350877194,
            "logloss": 0.7221132509616714,
            "mae": 0.4030219825676755,
            "precision": 0.7065727699530516,
            "recall": 0.6270833333333333
        },
        "train": {
            "accuracy": 0.6663007683863886,
            "auc_prc": 0.770494936402153,
            "auditor_fn_violation": 0.015886469637390176,
            "auditor_fp_violation": 0.003016776896663461,
            "ave_precision_score": 0.7708375921532998,
            "fpr": 0.1119648737650933,
            "logloss": 0.7424054861239401,
            "mae": 0.4120970017744219,
            "precision": 0.7272727272727273,
            "recall": 0.5738396624472574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(81)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5127740822649542,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5301093588210507,
            "fpr": 0.29605263157894735,
            "logloss": 0.6878851523817692,
            "mae": 0.4964419852680804,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.49744922050862417,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5175167758879938,
            "fpr": 0.287596048298573,
            "logloss": 0.6886865085335908,
            "mae": 0.4968673158621029,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(82)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7821400855983869,
            "auditor_fn_violation": 0.011567982456140352,
            "auditor_fp_violation": 0.027655945419103326,
            "ave_precision_score": 0.7727791517473611,
            "fpr": 0.2236842105263158,
            "logloss": 1.720078136104319,
            "mae": 0.3112669895746334,
            "precision": 0.6714975845410628,
            "recall": 0.86875
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8031175113436764,
            "auditor_fn_violation": 0.014626667963521332,
            "auditor_fp_violation": 0.02427236898622733,
            "ave_precision_score": 0.7969453853178298,
            "fpr": 0.22283205268935236,
            "logloss": 1.5207946803211099,
            "mae": 0.29968689118889463,
            "precision": 0.6762360446570973,
            "recall": 0.8945147679324894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(83)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6689886413239539,
            "auditor_fn_violation": 0.002638432017543861,
            "auditor_fp_violation": 0.008284600389863563,
            "ave_precision_score": 0.5929263048798358,
            "fpr": 0.40350877192982454,
            "logloss": 0.6846572296331161,
            "mae": 0.47376776398404646,
            "precision": 0.5550181378476421,
            "recall": 0.95625
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.648624011804962,
            "auditor_fn_violation": 0.0033208742653086753,
            "auditor_fp_violation": 0.012838257051496212,
            "ave_precision_score": 0.573731305927056,
            "fpr": 0.41712403951701427,
            "logloss": 0.6921403913785849,
            "mae": 0.4776871302027079,
            "precision": 0.5432692307692307,
            "recall": 0.9535864978902954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(84)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7837941262047867,
            "auditor_fn_violation": 0.018023574561403508,
            "auditor_fp_violation": 0.007127192982456145,
            "ave_precision_score": 0.7842033182332866,
            "fpr": 0.13706140350877194,
            "logloss": 0.7223820409702618,
            "mae": 0.40331454608663936,
            "precision": 0.7044917257683215,
            "recall": 0.6208333333333333
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7700772064656674,
            "auditor_fn_violation": 0.01734079951090053,
            "auditor_fp_violation": 0.003016776896663461,
            "ave_precision_score": 0.7704209002170772,
            "fpr": 0.1119648737650933,
            "logloss": 0.7426609169214233,
            "mae": 0.41234936493683855,
            "precision": 0.7258064516129032,
            "recall": 0.569620253164557
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(85)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8315642966723803,
            "auditor_fn_violation": 0.015122441520467838,
            "auditor_fp_violation": 0.010244070825211182,
            "ave_precision_score": 0.8318795317752614,
            "fpr": 0.12719298245614036,
            "logloss": 0.6904355827164945,
            "mae": 0.282612498356038,
            "precision": 0.7526652452025586,
            "recall": 0.7354166666666667
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8516949583045856,
            "auditor_fn_violation": 0.0018480178965943732,
            "auditor_fp_violation": 0.008909664989563111,
            "ave_precision_score": 0.8519225145881058,
            "fpr": 0.1141602634467618,
            "logloss": 0.6239089793832059,
            "mae": 0.2649339432173981,
            "precision": 0.7714285714285715,
            "recall": 0.740506329113924
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(86)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.5127740822649542,
            "auditor_fn_violation": 0.08534585160818714,
            "auditor_fp_violation": 0.09183114035087721,
            "ave_precision_score": 0.5301093588210507,
            "fpr": 0.29605263157894735,
            "logloss": 0.6878851523817692,
            "mae": 0.4964419852680804,
            "precision": 0.5623987034035657,
            "recall": 0.7229166666666667
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.49744922050862417,
            "auditor_fn_violation": 0.08641220525504037,
            "auditor_fp_violation": 0.0943213759115012,
            "ave_precision_score": 0.5175167758879938,
            "fpr": 0.287596048298573,
            "logloss": 0.6886865085335908,
            "mae": 0.4968673158621029,
            "precision": 0.5559322033898305,
            "recall": 0.6919831223628692
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(87)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(88)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7754829941151984,
            "auditor_fn_violation": 0.010928362573099419,
            "auditor_fp_violation": 0.02490710282651073,
            "ave_precision_score": 0.7663970601614931,
            "fpr": 0.22039473684210525,
            "logloss": 1.7081200732302766,
            "mae": 0.3138871015597893,
            "precision": 0.6721044045676998,
            "recall": 0.8583333333333333
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7982318611379086,
            "auditor_fn_violation": 0.011507269333555654,
            "auditor_fp_violation": 0.024882757650581386,
            "ave_precision_score": 0.7921186109921974,
            "fpr": 0.21953896816684962,
            "logloss": 1.5171327719186751,
            "mae": 0.3031628090278966,
            "precision": 0.6747967479674797,
            "recall": 0.8755274261603375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(89)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7831850932854868,
            "auditor_fn_violation": 0.012239583333333338,
            "auditor_fp_violation": 0.02509746588693958,
            "ave_precision_score": 0.7738318263643951,
            "fpr": 0.22807017543859648,
            "logloss": 1.7153496417508478,
            "mae": 0.3113486584025579,
            "precision": 0.6677316293929713,
            "recall": 0.8708333333333333
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8038208042171286,
            "auditor_fn_violation": 0.015534466228515056,
            "auditor_fp_violation": 0.024689342312493878,
            "ave_precision_score": 0.7976412400834123,
            "fpr": 0.2239297475301866,
            "logloss": 1.52114403581327,
            "mae": 0.3006987473514681,
            "precision": 0.6761904761904762,
            "recall": 0.8987341772151899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(90)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7831497620984805,
            "auditor_fn_violation": 0.011951754385964916,
            "auditor_fp_violation": 0.023026315789473683,
            "ave_precision_score": 0.7746164962068225,
            "fpr": 0.23684210526315788,
            "logloss": 1.6983384649774704,
            "mae": 0.31738465141170785,
            "precision": 0.6635514018691588,
            "recall": 0.8875
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8036266793034043,
            "auditor_fn_violation": 0.0164746858601157,
            "auditor_fp_violation": 0.02499579258842472,
            "ave_precision_score": 0.7974917317974597,
            "fpr": 0.2283205268935236,
            "logloss": 1.535696979848323,
            "mae": 0.30662261873011354,
            "precision": 0.6708860759493671,
            "recall": 0.8945147679324894
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(91)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.7181094615080146,
            "auditor_fn_violation": 0.008333333333333342,
            "auditor_fp_violation": 0.009421702404158547,
            "ave_precision_score": 0.7100826499534796,
            "fpr": 0.1600877192982456,
            "logloss": 2.584098006509299,
            "mae": 0.37824479267686223,
            "precision": 0.663594470046083,
            "recall": 0.6
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7062575375426953,
            "auditor_fn_violation": 0.0012019063763564915,
            "auditor_fp_violation": 0.010499689781892817,
            "ave_precision_score": 0.7012656863786457,
            "fpr": 0.1668496158068057,
            "logloss": 2.6142815968183357,
            "mae": 0.38484813957441466,
            "precision": 0.6440281030444965,
            "recall": 0.580168776371308
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(92)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7760934361892979,
            "auditor_fn_violation": 0.010279605263157897,
            "auditor_fp_violation": 0.028183885640025996,
            "ave_precision_score": 0.7684754862029486,
            "fpr": 0.20614035087719298,
            "logloss": 1.5639992689476376,
            "mae": 0.3076313258038669,
            "precision": 0.6829679595278246,
            "recall": 0.84375
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7954050496664135,
            "auditor_fn_violation": 0.010323889452403121,
            "auditor_fp_violation": 0.021722803165983018,
            "ave_precision_score": 0.7894548812151368,
            "fpr": 0.1964873765093304,
            "logloss": 1.4249939405888281,
            "mae": 0.2939310688766265,
            "precision": 0.6903114186851211,
            "recall": 0.8417721518987342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(93)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7744232209422256,
            "auditor_fn_violation": 0.010862116228070179,
            "auditor_fp_violation": 0.02535635964912281,
            "ave_precision_score": 0.75499876257596,
            "fpr": 0.20723684210526316,
            "logloss": 2.2450161038651535,
            "mae": 0.304625178114715,
            "precision": 0.6796610169491526,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7939786323333073,
            "auditor_fn_violation": 0.00787839208548125,
            "auditor_fp_violation": 0.02322491189554568,
            "ave_precision_score": 0.7809785695268626,
            "fpr": 0.21075740944017562,
            "logloss": 1.9849859490479749,
            "mae": 0.29262334153744585,
            "precision": 0.678391959798995,
            "recall": 0.8544303797468354
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(94)",
        "seed": 10197,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7748475921748609,
            "auditor_fn_violation": 0.011305281432748537,
            "auditor_fp_violation": 0.023566946881091618,
            "ave_precision_score": 0.7551073166489803,
            "fpr": 0.2138157894736842,
            "logloss": 2.267721713128993,
            "mae": 0.30922665120902937,
            "precision": 0.6728187919463087,
            "recall": 0.8354166666666667
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.792322270398308,
            "auditor_fn_violation": 0.005187418657106997,
            "auditor_fp_violation": 0.023604206909197782,
            "ave_precision_score": 0.7777277126673002,
            "fpr": 0.21185510428100987,
            "logloss": 2.0455219152356285,
            "mae": 0.2968590506204651,
            "precision": 0.6767169179229481,
            "recall": 0.8523206751054853
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(95)",
        "seed": 10197,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8292935852478863,
            "auditor_fn_violation": 0.015204678362573104,
            "auditor_fp_violation": 0.007726202079272258,
            "ave_precision_score": 0.8296468859151472,
            "fpr": 0.12719298245614036,
            "logloss": 0.6948190349371154,
            "mae": 0.2827897414320576,
            "precision": 0.7521367521367521,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8525695607545247,
            "auditor_fn_violation": 0.004932679348052644,
            "auditor_fp_violation": 0.012298201237355784,
            "ave_precision_score": 0.8527971304542883,
            "fpr": 0.11306256860592755,
            "logloss": 0.6240710750813542,
            "mae": 0.26449746857545275,
            "precision": 0.7726269315673289,
            "recall": 0.7383966244725738
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(96)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6626230651410596,
            "auditor_fn_violation": 0.003686951754385965,
            "auditor_fp_violation": 0.004682931286549716,
            "ave_precision_score": 0.5782161430964478,
            "fpr": 0.4331140350877193,
            "logloss": 0.7517944626872445,
            "mae": 0.4743769995606782,
            "precision": 0.5417633410672854,
            "recall": 0.9729166666666667
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.643720350716241,
            "auditor_fn_violation": 0.0017021217468632332,
            "auditor_fp_violation": 0.008000361711801105,
            "ave_precision_score": 0.5635017851267865,
            "fpr": 0.44017563117453345,
            "logloss": 0.7581084877663102,
            "mae": 0.4783035533422958,
            "precision": 0.5337209302325582,
            "recall": 0.9683544303797469
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(97)",
        "seed": 10197,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.6876072668499792,
            "auditor_fn_violation": 0.012294407894736846,
            "auditor_fp_violation": 0.0011675601039636177,
            "ave_precision_score": 0.6881737091367739,
            "fpr": 0.08442982456140351,
            "logloss": 0.7953016415009158,
            "mae": 0.46051596099457665,
            "precision": 0.6932270916334662,
            "recall": 0.3625
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6229777855601281,
            "auditor_fn_violation": 0.005863635732051297,
            "auditor_fp_violation": 0.00919350827792528,
            "ave_precision_score": 0.6242508372315856,
            "fpr": 0.10537870472008781,
            "logloss": 0.8505403162425653,
            "mae": 0.47103245241484243,
            "precision": 0.6363636363636364,
            "recall": 0.35443037974683544
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(98)",
        "seed": 10197,
        "test": {
            "accuracy": 0.47368421052631576,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.178303365742465,
            "mae": 0.5263157894736842,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.97077937561763,
            "mae": 0.5203073545554336,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_nsga2",
        "model": "feat_nsga2:archive(99)",
        "seed": 10197,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7825884144941929,
            "auditor_fn_violation": 0.011769005847953215,
            "auditor_fp_violation": 0.027655945419103326,
            "ave_precision_score": 0.7732092251731604,
            "fpr": 0.2236842105263158,
            "logloss": 1.6912456031550878,
            "mae": 0.31028227984218876,
            "precision": 0.6709677419354839,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8031609204038634,
            "auditor_fn_violation": 0.01350349919178165,
            "auditor_fp_violation": 0.02427236898622733,
            "ave_precision_score": 0.7969651575773489,
            "fpr": 0.22283205268935236,
            "logloss": 1.494168255117451,
            "mae": 0.2988168784260288,
            "precision": 0.6746794871794872,
            "recall": 0.8881856540084389
        }
    }
]