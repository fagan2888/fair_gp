[
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(0)",
        "seed": 871,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8306243501359619,
            "auditor_fn_violation": 0.010811639313337111,
            "auditor_fp_violation": 0.02416450802621767,
            "ave_precision_score": 0.8310133563678896,
            "fpr": 0.13925438596491227,
            "logloss": 0.781391554383393,
            "mae": 0.2723329203270702,
            "precision": 0.7397540983606558,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8278228273474963,
            "auditor_fn_violation": 0.013484361776873887,
            "auditor_fp_violation": 0.015815129460360733,
            "ave_precision_score": 0.8281473811449837,
            "fpr": 0.12294182217343579,
            "logloss": 0.84523821058743,
            "mae": 0.2742008076625062,
            "precision": 0.7651991614255765,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(1)",
        "seed": 871,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8008568624562096,
            "auditor_fn_violation": 0.0076589322769288785,
            "auditor_fp_violation": 0.024954374190509835,
            "ave_precision_score": 0.7936383364196031,
            "fpr": 0.15789473684210525,
            "logloss": 1.6374897443807368,
            "mae": 0.274777288245019,
            "precision": 0.7203883495145631,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7944109171784102,
            "auditor_fn_violation": 0.012337281892075721,
            "auditor_fp_violation": 0.011517992310933773,
            "ave_precision_score": 0.7819459703190947,
            "fpr": 0.132821075740944,
            "logloss": 1.8930037965717508,
            "mae": 0.2697387499217674,
            "precision": 0.7613412228796844,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(2)",
        "seed": 871,
        "test": {
            "accuracy": 0.631578947368421,
            "auc_prc": 0.8239621242190218,
            "auditor_fn_violation": 0.009543010752688182,
            "auditor_fp_violation": 0.0015969033321558935,
            "ave_precision_score": 0.8221805615436026,
            "fpr": 0.013157894736842105,
            "logloss": 0.6422497972055612,
            "mae": 0.4260400515866646,
            "precision": 0.9215686274509803,
            "recall": 0.3032258064516129
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.8496350330605114,
            "auditor_fn_violation": 0.005497453303073783,
            "auditor_fp_violation": 0.002830075798169816,
            "ave_precision_score": 0.8485527404921627,
            "fpr": 0.012074643249176729,
            "logloss": 0.6206442372356675,
            "mae": 0.43118779907569404,
            "precision": 0.9333333333333333,
            "recall": 0.3149284253578732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(3)",
        "seed": 871,
        "test": {
            "accuracy": 0.518640350877193,
            "auc_prc": 0.7195055176662597,
            "auditor_fn_violation": 0.0005847953216374269,
            "auditor_fp_violation": 0.0036279877546214674,
            "ave_precision_score": 0.720628132336203,
            "fpr": 0.48026315789473684,
            "logloss": 0.6973355482732351,
            "mae": 0.4952683090477398,
            "precision": 0.5144124168514412,
            "recall": 0.9978494623655914
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.7803709166261157,
            "auditor_fn_violation": 0.0004287519725957903,
            "auditor_fp_violation": 0.0024763163233986044,
            "ave_precision_score": 0.7811189159436656,
            "fpr": 0.4500548847420417,
            "logloss": 0.6871329725006848,
            "mae": 0.48989638316513545,
            "precision": 0.5429208472686734,
            "recall": 0.9959100204498977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(4)",
        "seed": 871,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7549879373681683,
            "auditor_fn_violation": 0.01056876061120544,
            "auditor_fp_violation": 0.02184887554456611,
            "ave_precision_score": 0.6441820225407104,
            "fpr": 0.17434210526315788,
            "logloss": 0.6306361475177416,
            "mae": 0.41780329727682103,
            "precision": 0.6807228915662651,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.6073167974009177,
            "auditor_fn_violation": 0.018223081222683898,
            "auditor_fp_violation": 0.0165902788977271,
            "ave_precision_score": 0.6508619972367342,
            "fpr": 0.16465422612513722,
            "logloss": 0.6455919279389964,
            "mae": 0.4241622967561697,
            "precision": 0.6987951807228916,
            "recall": 0.7116564417177914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(5)",
        "seed": 871,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7468399680842255,
            "auditor_fn_violation": 0.00909734012450481,
            "auditor_fp_violation": 0.025847266376231404,
            "ave_precision_score": 0.640419239823764,
            "fpr": 0.17324561403508773,
            "logloss": 0.622652402024571,
            "mae": 0.4343905280948731,
            "precision": 0.680161943319838,
            "recall": 0.7225806451612903
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7531353851653165,
            "auditor_fn_violation": 0.01683581044224308,
            "auditor_fp_violation": 0.015679868484712915,
            "ave_precision_score": 0.6647205501216702,
            "fpr": 0.16245883644346873,
            "logloss": 0.6267369997141192,
            "mae": 0.43642982421800675,
            "precision": 0.6997971602434077,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(6)",
        "seed": 871,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8160182487451,
            "auditor_fn_violation": 0.0015115072627806113,
            "auditor_fp_violation": 0.007790729620471764,
            "ave_precision_score": 0.8138179615042386,
            "fpr": 0.08333333333333333,
            "logloss": 0.5178210946640807,
            "mae": 0.3312492500531095,
            "precision": 0.8061224489795918,
            "recall": 0.6795698924731183
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8752721146463612,
            "auditor_fn_violation": 0.005207877363467197,
            "auditor_fp_violation": 0.004146269138127469,
            "ave_precision_score": 0.867483946771071,
            "fpr": 0.05378704720087816,
            "logloss": 0.49642564309133647,
            "mae": 0.3204288172876027,
            "precision": 0.8668478260869565,
            "recall": 0.6523517382413088
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(7)",
        "seed": 871,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.5985632962448822,
            "auditor_fn_violation": 0.06041312959818902,
            "auditor_fp_violation": 0.068706091290867,
            "ave_precision_score": 0.5942148110565364,
            "fpr": 0.19956140350877194,
            "logloss": 0.6816456361709785,
            "mae": 0.4043994323889676,
            "precision": 0.6660550458715596,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6053193857007743,
            "auditor_fn_violation": 0.06870357525270551,
            "auditor_fp_violation": 0.0674275963604393,
            "ave_precision_score": 0.5937178974617124,
            "fpr": 0.19538968166849616,
            "logloss": 0.6960695455720912,
            "mae": 0.41116305330255026,
            "precision": 0.6715867158671587,
            "recall": 0.7443762781186094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(8)",
        "seed": 871,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.6919208838856508,
            "auditor_fn_violation": 0.004093567251461989,
            "auditor_fp_violation": 0.0029656776168609394,
            "ave_precision_score": 0.6923436586064298,
            "fpr": 0.44298245614035087,
            "logloss": 1.5669576117379096,
            "mae": 0.46823607264249995,
            "precision": 0.5178997613365155,
            "recall": 0.9333333333333333
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.6686827628212412,
            "auditor_fn_violation": 0.009454991144363706,
            "auditor_fp_violation": 0.0030277649164243406,
            "ave_precision_score": 0.6693773821281964,
            "fpr": 0.42590559824368823,
            "logloss": 1.6196628256922,
            "mae": 0.4597404892305904,
            "precision": 0.5380952380952381,
            "recall": 0.9243353783231084
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(9)",
        "seed": 871,
        "test": {
            "accuracy": 0.3892543859649123,
            "auc_prc": 0.5128374525035297,
            "auditor_fn_violation": 0.011509620826259209,
            "auditor_fp_violation": 0.0064391263393382865,
            "ave_precision_score": 0.4293339648683318,
            "fpr": 0.3651315789473684,
            "logloss": 17.613195892970484,
            "mae": 0.6089868631726385,
            "precision": 0.41986062717770034,
            "recall": 0.5182795698924731
        },
        "train": {
            "accuracy": 0.4039517014270033,
            "auc_prc": 0.5473353977749518,
            "auditor_fn_violation": 0.013583131864801716,
            "auditor_fp_violation": 0.01590877167427076,
            "ave_precision_score": 0.4609621541143698,
            "fpr": 0.3468715697036224,
            "logloss": 17.243226322765388,
            "mae": 0.5969912418826028,
            "precision": 0.4532871972318339,
            "recall": 0.5357873210633947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(10)",
        "seed": 871,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.5740496347885922,
            "auditor_fn_violation": 0.017117053386153557,
            "auditor_fp_violation": 0.042966756937085446,
            "ave_precision_score": 0.5745520080613097,
            "fpr": 0.09649122807017543,
            "logloss": 6.236356246942249,
            "mae": 0.4868094608985076,
            "precision": 0.6286919831223629,
            "recall": 0.3204301075268817
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.617261979901847,
            "auditor_fn_violation": 0.013540481145014695,
            "auditor_fp_violation": 0.03747769494488116,
            "ave_precision_score": 0.6172055427467766,
            "fpr": 0.07903402854006586,
            "logloss": 6.3684591795277194,
            "mae": 0.4925201894116629,
            "precision": 0.6727272727272727,
            "recall": 0.30265848670756645
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(11)",
        "seed": 871,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6457931600405211,
            "auditor_fn_violation": 0.009394453876627056,
            "auditor_fp_violation": 0.025849719376741628,
            "ave_precision_score": 0.6466122482959855,
            "fpr": 0.18859649122807018,
            "logloss": 0.6868226499721769,
            "mae": 0.43775176313216324,
            "precision": 0.655310621242485,
            "recall": 0.7032258064516129
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6845186289677212,
            "auditor_fn_violation": 0.02363298831145801,
            "auditor_fp_violation": 0.009926074674463247,
            "ave_precision_score": 0.68515526424929,
            "fpr": 0.1712403951701427,
            "logloss": 0.6863508669797092,
            "mae": 0.4317373112430335,
            "precision": 0.6816326530612244,
            "recall": 0.6830265848670757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(12)",
        "seed": 871,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8082961225614693,
            "auditor_fn_violation": 0.004810413129598193,
            "auditor_fp_violation": 0.027588896738490527,
            "ave_precision_score": 0.8086782114175475,
            "fpr": 0.16447368421052633,
            "logloss": 0.5527378644102129,
            "mae": 0.33823483256549625,
            "precision": 0.7064579256360078,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8088517071034422,
            "auditor_fn_violation": 0.01183220757880843,
            "auditor_fp_violation": 0.02165736313930321,
            "ave_precision_score": 0.8091964799994935,
            "fpr": 0.15367727771679474,
            "logloss": 0.5611501597634411,
            "mae": 0.33496970208065274,
            "precision": 0.7244094488188977,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(13)",
        "seed": 871,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7512634023901472,
            "auditor_fn_violation": 0.00909734012450481,
            "auditor_fp_violation": 0.025847266376231404,
            "ave_precision_score": 0.7284740350319037,
            "fpr": 0.17324561403508773,
            "logloss": 0.6195438800440644,
            "mae": 0.4455432927137927,
            "precision": 0.680161943319838,
            "recall": 0.7225806451612903
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7637469349790394,
            "auditor_fn_violation": 0.01683581044224308,
            "auditor_fp_violation": 0.015679868484712915,
            "ave_precision_score": 0.7402508486863735,
            "fpr": 0.16245883644346873,
            "logloss": 0.6194229264426712,
            "mae": 0.44535798416702993,
            "precision": 0.6997971602434077,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(14)",
        "seed": 871,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7893766207750701,
            "auditor_fn_violation": 0.00426570458404076,
            "auditor_fp_violation": 0.007420326543427925,
            "ave_precision_score": 0.7736520171655197,
            "fpr": 0.09758771929824561,
            "logloss": 0.5406676271931253,
            "mae": 0.3582670014972488,
            "precision": 0.7807881773399015,
            "recall": 0.6817204301075269
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8224294569455204,
            "auditor_fn_violation": 0.0009450501594912434,
            "auditor_fp_violation": 0.01224632064134512,
            "ave_precision_score": 0.812256938437447,
            "fpr": 0.06476399560922064,
            "logloss": 0.5488227922850888,
            "mae": 0.3600466366362493,
            "precision": 0.8392370572207084,
            "recall": 0.6298568507157464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(15)",
        "seed": 871,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.6190213545438068,
            "auditor_fn_violation": 0.03494623655913978,
            "auditor_fp_violation": 0.08598012088386515,
            "ave_precision_score": 0.5530345931854539,
            "fpr": 0.2741228070175439,
            "logloss": 0.6863707429693118,
            "mae": 0.4799929189642793,
            "precision": 0.5798319327731093,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6377382514001024,
            "auditor_fn_violation": 0.03420363249446102,
            "auditor_fp_violation": 0.07906524261136921,
            "ave_precision_score": 0.5830609172444433,
            "fpr": 0.24807903402854006,
            "logloss": 0.6872124822009652,
            "mae": 0.48037333979499325,
            "precision": 0.6162988115449916,
            "recall": 0.7423312883435583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(16)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8453980559835409,
            "auditor_fn_violation": 0.006479909451046976,
            "auditor_fp_violation": 0.018493170846579535,
            "ave_precision_score": 0.8461683352661402,
            "fpr": 0.13157894736842105,
            "logloss": 0.5187204007246572,
            "mae": 0.28101876217733024,
            "precision": 0.7530864197530864,
            "recall": 0.7870967741935484
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.869009825457345,
            "auditor_fn_violation": 0.011006130479775705,
            "auditor_fp_violation": 0.006619984288917448,
            "ave_precision_score": 0.8691934036709368,
            "fpr": 0.10867178924259056,
            "logloss": 0.5324096017052099,
            "mae": 0.2772232090574347,
            "precision": 0.7906976744186046,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(17)",
        "seed": 871,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8006164171668548,
            "auditor_fn_violation": 0.005086304470854564,
            "auditor_fp_violation": 0.002877369598492876,
            "ave_precision_score": 0.7039075961534386,
            "fpr": 0.11293859649122807,
            "logloss": 0.5832595937544754,
            "mae": 0.38655199989545763,
            "precision": 0.7518072289156627,
            "recall": 0.6709677419354839
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8218754344101956,
            "auditor_fn_violation": 0.00393957964348488,
            "auditor_fp_violation": 0.011908168202225566,
            "ave_precision_score": 0.7333188385022478,
            "fpr": 0.06805708013172337,
            "logloss": 0.5666415367304632,
            "mae": 0.3828891118258467,
            "precision": 0.8287292817679558,
            "recall": 0.6134969325153374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(18)",
        "seed": 871,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.714673038527676,
            "auditor_fn_violation": 0.00909734012450481,
            "auditor_fp_violation": 0.025847266376231404,
            "ave_precision_score": 0.6686419082392153,
            "fpr": 0.17324561403508773,
            "logloss": 0.6284250975351399,
            "mae": 0.44978383624632107,
            "precision": 0.680161943319838,
            "recall": 0.7225806451612903
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7254880535045616,
            "auditor_fn_violation": 0.017145589354380354,
            "auditor_fp_violation": 0.015679868484712915,
            "ave_precision_score": 0.6881204177250949,
            "fpr": 0.16245883644346873,
            "logloss": 0.6363714241054241,
            "mae": 0.4548390696129867,
            "precision": 0.6991869918699187,
            "recall": 0.7034764826175869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(19)",
        "seed": 871,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.42432245790804574,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5073592889849257,
            "fpr": 0.4901315789473684,
            "logloss": 0.6937607946692841,
            "mae": 0.4992918658413385,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.47814316590597433,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.537001586185092,
            "fpr": 0.4632272228320527,
            "logloss": 0.6902444496307797,
            "mae": 0.4975353265436761,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(20)",
        "seed": 871,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.7307992269994007,
            "auditor_fn_violation": 0.003862478777589135,
            "auditor_fp_violation": 0.02256760469406177,
            "ave_precision_score": 0.734036509643937,
            "fpr": 0.35964912280701755,
            "logloss": 0.6996387495781126,
            "mae": 0.4245465694714272,
            "precision": 0.5609103078982597,
            "recall": 0.9010752688172043
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7222886619798559,
            "auditor_fn_violation": 0.013663943754924477,
            "auditor_fp_violation": 0.016512243719468744,
            "ave_precision_score": 0.7429016818379509,
            "fpr": 0.3545554335894621,
            "logloss": 0.6890975942853826,
            "mae": 0.42084030321217525,
            "precision": 0.5783289817232375,
            "recall": 0.9059304703476483
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(21)",
        "seed": 871,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7830131114499039,
            "auditor_fn_violation": 0.0023792680626296896,
            "auditor_fp_violation": 0.008874955845990816,
            "ave_precision_score": 0.7836631745282288,
            "fpr": 0.09868421052631579,
            "logloss": 0.5861106025174787,
            "mae": 0.3746064988111979,
            "precision": 0.7554347826086957,
            "recall": 0.5978494623655914
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.8277029005714703,
            "auditor_fn_violation": 0.008150777028771282,
            "auditor_fp_violation": 0.011814525988315533,
            "ave_precision_score": 0.8280684129915971,
            "fpr": 0.054884742041712405,
            "logloss": 0.58052979138251,
            "mae": 0.3692887225510342,
            "precision": 0.8417721518987342,
            "recall": 0.5439672801635992
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(22)",
        "seed": 871,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.7773918996686742,
            "auditor_fn_violation": 0.002412280701754386,
            "auditor_fp_violation": 0.01843184583382395,
            "ave_precision_score": 0.7777133063985243,
            "fpr": 0.3793859649122807,
            "logloss": 0.7506699855554373,
            "mae": 0.4004450101536094,
            "precision": 0.5586734693877551,
            "recall": 0.9419354838709677
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.779807018831748,
            "auditor_fn_violation": 0.00902848394649355,
            "auditor_fp_violation": 0.01990417280109874,
            "ave_precision_score": 0.7801634908737257,
            "fpr": 0.34906695938529086,
            "logloss": 0.7131780758610831,
            "mae": 0.3907242345365028,
            "precision": 0.5848563968668408,
            "recall": 0.9161554192229039
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(23)",
        "seed": 871,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.8107525328033292,
            "auditor_fn_violation": 0.003324844368987002,
            "auditor_fp_violation": 0.00022077004592016986,
            "ave_precision_score": 0.8102125184728609,
            "fpr": 0.03618421052631579,
            "logloss": 0.6124019130860402,
            "mae": 0.4012174561145928,
            "precision": 0.8619246861924686,
            "recall": 0.443010752688172
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.8335217351042964,
            "auditor_fn_violation": 0.004249358555622144,
            "auditor_fp_violation": 0.0007959588182352619,
            "ave_precision_score": 0.8337681888686199,
            "fpr": 0.019758507135016465,
            "logloss": 0.5769212207074604,
            "mae": 0.39844480756788825,
            "precision": 0.9240506329113924,
            "recall": 0.44785276073619634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(24)",
        "seed": 871,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7803221090360309,
            "auditor_fn_violation": 0.01594038860592341,
            "auditor_fp_violation": 0.008825895835786331,
            "ave_precision_score": 0.6590910520027669,
            "fpr": 0.08114035087719298,
            "logloss": 0.6442999323883448,
            "mae": 0.4183721661633044,
            "precision": 0.7777777777777778,
            "recall": 0.556989247311828
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.7815606163052463,
            "auditor_fn_violation": 0.005454802583286765,
            "auditor_fp_violation": 0.003449154879019465,
            "ave_precision_score": 0.6661154639079927,
            "fpr": 0.08122941822173436,
            "logloss": 0.6448786046152589,
            "mae": 0.41838009258002273,
            "precision": 0.7791044776119403,
            "recall": 0.5337423312883436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(25)",
        "seed": 871,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7934677621965872,
            "auditor_fn_violation": 0.013193265421618562,
            "auditor_fp_violation": 0.028241394874210138,
            "ave_precision_score": 0.7821500010445803,
            "fpr": 0.1600877192982456,
            "logloss": 2.5022831181418876,
            "mae": 0.288590211928894,
            "precision": 0.7120315581854043,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7821589935033325,
            "auditor_fn_violation": 0.01517467714527509,
            "auditor_fp_violation": 0.019061392875908457,
            "ave_precision_score": 0.7625013424914053,
            "fpr": 0.15148188803512624,
            "logloss": 3.0907330555382724,
            "mae": 0.29826764520474736,
            "precision": 0.724,
            "recall": 0.7402862985685071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(26)",
        "seed": 871,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7309855563931132,
            "auditor_fn_violation": 0.0029711375212224185,
            "auditor_fp_violation": 0.008879861847011268,
            "ave_precision_score": 0.7212127204817431,
            "fpr": 0.08442982456140351,
            "logloss": 0.6351834218711389,
            "mae": 0.3846228329481136,
            "precision": 0.7433333333333333,
            "recall": 0.47956989247311826
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7848757861763686,
            "auditor_fn_violation": 0.010741247062151087,
            "auditor_fp_violation": 0.0035584041285811677,
            "ave_precision_score": 0.7739272293599532,
            "fpr": 0.059275521405049394,
            "logloss": 0.6772756398735955,
            "mae": 0.3754022595984812,
            "precision": 0.8181818181818182,
            "recall": 0.49693251533742333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(27)",
        "seed": 871,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7245162688882092,
            "auditor_fn_violation": 0.018392756083757785,
            "auditor_fp_violation": 0.03196750264924055,
            "ave_precision_score": 0.7104317346034703,
            "fpr": 0.15021929824561403,
            "logloss": 0.588884259294696,
            "mae": 0.4034228118283576,
            "precision": 0.7034632034632035,
            "recall": 0.6989247311827957
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.7433977323952304,
            "auditor_fn_violation": 0.024676808558877078,
            "auditor_fp_violation": 0.0256579666113484,
            "ave_precision_score": 0.7313163375978188,
            "fpr": 0.14489571899012074,
            "logloss": 0.6014066285362784,
            "mae": 0.40612024279836767,
            "precision": 0.7185501066098081,
            "recall": 0.689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(28)",
        "seed": 871,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5893268291783486,
            "auditor_fn_violation": 0.006541218637992833,
            "auditor_fp_violation": 0.031241414498214222,
            "ave_precision_score": 0.5904344005340886,
            "fpr": 0.37609649122807015,
            "logloss": 0.7144416214873348,
            "mae": 0.46735935288955244,
            "precision": 0.5438829787234043,
            "recall": 0.8795698924731182
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.5758276076331481,
            "auditor_fn_violation": 0.006545763099944105,
            "auditor_fp_violation": 0.014915123737781,
            "ave_precision_score": 0.5770747310316787,
            "fpr": 0.36443468715697036,
            "logloss": 0.728289973454293,
            "mae": 0.4697322597242606,
            "precision": 0.5654450261780105,
            "recall": 0.8834355828220859
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(29)",
        "seed": 871,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7149248698867046,
            "auditor_fn_violation": 0.0035630069798151484,
            "auditor_fp_violation": 0.00522489108677735,
            "ave_precision_score": 0.6912492668543062,
            "fpr": 0.0581140350877193,
            "logloss": 0.6583316078604157,
            "mae": 0.38476248467627,
            "precision": 0.8146853146853147,
            "recall": 0.5010752688172043
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7746370694761883,
            "auditor_fn_violation": 0.009598656726804183,
            "auditor_fp_violation": 0.004937025611145505,
            "ave_precision_score": 0.7542916548091001,
            "fpr": 0.03293084522502744,
            "logloss": 0.6290260011925357,
            "mae": 0.3736216493817833,
            "precision": 0.8909090909090909,
            "recall": 0.5010224948875256
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(30)",
        "seed": 871,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.642010172321286,
            "auditor_fn_violation": 0.009564233163554056,
            "auditor_fp_violation": 0.011379469366929634,
            "ave_precision_score": 0.6415846596723763,
            "fpr": 0.06359649122807018,
            "logloss": 8.910315702848736,
            "mae": 0.4374307255162338,
            "precision": 0.7040816326530612,
            "recall": 0.2967741935483871
        },
        "train": {
            "accuracy": 0.5477497255762898,
            "auc_prc": 0.6717066793088442,
            "auditor_fn_violation": 0.013845770507700712,
            "auditor_fp_violation": 0.011242268014420905,
            "ave_precision_score": 0.6653602687657086,
            "fpr": 0.059275521405049394,
            "logloss": 9.356846888072424,
            "mae": 0.4576396319545849,
            "precision": 0.7081081081081081,
            "recall": 0.26789366053169733
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(31)",
        "seed": 871,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.7516062667862882,
            "auditor_fn_violation": 0.00020279192605168853,
            "auditor_fp_violation": 0.003537226735743168,
            "ave_precision_score": 0.5105799830157622,
            "fpr": 0.48135964912280704,
            "logloss": 0.6937649345587157,
            "mae": 0.4993394808680342,
            "precision": 0.5105908584169454,
            "recall": 0.9849462365591398
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.7665206515533468,
            "auditor_fn_violation": 0.0026263864289899188,
            "auditor_fp_violation": 0.003116204785117156,
            "ave_precision_score": 0.5377675016979226,
            "fpr": 0.4566410537870472,
            "logloss": 0.6910240302837788,
            "mae": 0.4980847838812157,
            "precision": 0.5377777777777778,
            "recall": 0.9897750511247444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(32)",
        "seed": 871,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.4221279003961516,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5094887757026976,
            "fpr": 0.4901315789473684,
            "logloss": 0.6938423249431827,
            "mae": 0.499663161538672,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6045616067199575,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5383665672231464,
            "fpr": 0.4632272228320527,
            "logloss": 0.690339267538217,
            "mae": 0.4977706484292132,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(33)",
        "seed": 871,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8449647888548965,
            "auditor_fn_violation": 0.0026669496321448777,
            "auditor_fp_violation": 0.004898642018917541,
            "ave_precision_score": 0.8441459086786087,
            "fpr": 0.041666666666666664,
            "logloss": 0.5629867460189854,
            "mae": 0.34183004421688484,
            "precision": 0.88125,
            "recall": 0.6064516129032258
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8594217749631905,
            "auditor_fn_violation": 0.0033761411873511407,
            "auditor_fp_violation": 0.0009624338651864278,
            "ave_precision_score": 0.8560830636532186,
            "fpr": 0.02854006586169045,
            "logloss": 0.5977881903519529,
            "mae": 0.34880631390047123,
            "precision": 0.9150326797385621,
            "recall": 0.5725971370143149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(34)",
        "seed": 871,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7801082977734956,
            "auditor_fn_violation": 0.0034309564233163574,
            "auditor_fp_violation": 0.0039149888143176935,
            "ave_precision_score": 0.6807392187492622,
            "fpr": 0.28728070175438597,
            "logloss": 0.6033450988491038,
            "mae": 0.4221928885304614,
            "precision": 0.6106983655274889,
            "recall": 0.8838709677419355
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.7480980927566954,
            "auditor_fn_violation": 0.0024692521981956525,
            "auditor_fp_violation": 0.019019774114170662,
            "ave_precision_score": 0.7196736200671454,
            "fpr": 0.270032930845225,
            "logloss": 0.5915008788507128,
            "mae": 0.41728962550571536,
            "precision": 0.641399416909621,
            "recall": 0.8997955010224948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(35)",
        "seed": 871,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.777075205034268,
            "auditor_fn_violation": 0.012172231654404835,
            "auditor_fp_violation": 0.028783507986969662,
            "ave_precision_score": 0.6663686121030508,
            "fpr": 0.14692982456140352,
            "logloss": 0.5993693332942822,
            "mae": 0.4139368254269156,
            "precision": 0.698876404494382,
            "recall": 0.6688172043010753
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7231398463084396,
            "auditor_fn_violation": 0.01712089683239839,
            "auditor_fp_violation": 0.019415152350679688,
            "ave_precision_score": 0.6857143076288387,
            "fpr": 0.14050493962678376,
            "logloss": 0.6077235875235665,
            "mae": 0.4154672438071059,
            "precision": 0.7199124726477024,
            "recall": 0.6728016359918201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(36)",
        "seed": 871,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.6924037512769965,
            "auditor_fn_violation": 0.00975759290699868,
            "auditor_fp_violation": 0.014040974920522805,
            "ave_precision_score": 0.5551609075697178,
            "fpr": 0.4309210526315789,
            "logloss": 0.6847768768086202,
            "mae": 0.4869599862252934,
            "precision": 0.5293413173652695,
            "recall": 0.9505376344086022
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6947961428038307,
            "auditor_fn_violation": 0.014256564282491432,
            "auditor_fp_violation": 0.02410246539139846,
            "ave_precision_score": 0.5692057972891743,
            "fpr": 0.3973655323819978,
            "logloss": 0.6836364491326917,
            "mae": 0.4859662329129932,
            "precision": 0.5569155446756426,
            "recall": 0.9304703476482618
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(37)",
        "seed": 871,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6622696754656047,
            "auditor_fn_violation": 0.002072722127900398,
            "auditor_fp_violation": 0.036277424545704304,
            "ave_precision_score": 0.6636309690160926,
            "fpr": 0.2675438596491228,
            "logloss": 0.6506385261825736,
            "mae": 0.4701839996207702,
            "precision": 0.6032520325203252,
            "recall": 0.7978494623655914
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.6844982212814745,
            "auditor_fn_violation": 0.011145306512764908,
            "auditor_fp_violation": 0.03294645226067913,
            "ave_precision_score": 0.6860234085590762,
            "fpr": 0.23380900109769484,
            "logloss": 0.6488329172026046,
            "mae": 0.46933140179590127,
            "precision": 0.6395939086294417,
            "recall": 0.7730061349693251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(38)",
        "seed": 871,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7875040670552718,
            "auditor_fn_violation": 0.0017567440105640455,
            "auditor_fp_violation": 0.026735252560932538,
            "ave_precision_score": 0.7538765950307571,
            "fpr": 0.20394736842105263,
            "logloss": 2.2209645685725965,
            "mae": 0.3224050164536222,
            "precision": 0.6831345826235093,
            "recall": 0.8623655913978494
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7927246084140641,
            "auditor_fn_violation": 0.011253055699595267,
            "auditor_fp_violation": 0.02017469475239438,
            "ave_precision_score": 0.7589531932707125,
            "fpr": 0.16465422612513722,
            "logloss": 2.278218744306863,
            "mae": 0.3110438389839087,
            "precision": 0.7311827956989247,
            "recall": 0.8343558282208589
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(39)",
        "seed": 871,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.7492924828792369,
            "auditor_fn_violation": 0.001874646293152251,
            "auditor_fp_violation": 0.001913340397974803,
            "ave_precision_score": 0.708315169442257,
            "fpr": 0.003289473684210526,
            "logloss": 7.058203954001761,
            "mae": 0.44309975753253017,
            "precision": 0.9375,
            "recall": 0.0967741935483871
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.797211015684,
            "auditor_fn_violation": 6.734324176897189e-05,
            "auditor_fp_violation": 0.0006502931521529909,
            "ave_precision_score": 0.7487112112418495,
            "fpr": 0.003293084522502744,
            "logloss": 7.672355284537729,
            "mae": 0.4522556677933424,
            "precision": 0.9473684210526315,
            "recall": 0.11042944785276074
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(40)",
        "seed": 871,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8121763162500584,
            "auditor_fn_violation": 0.0008488964346349785,
            "auditor_fp_violation": 0.005651713175556341,
            "ave_precision_score": 0.78442247045117,
            "fpr": 0.08771929824561403,
            "logloss": 0.5452986365352398,
            "mae": 0.35717451605096195,
            "precision": 0.800498753117207,
            "recall": 0.6903225806451613
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8298633911938517,
            "auditor_fn_violation": 0.009612125375157978,
            "auditor_fp_violation": 0.00303296726164155,
            "ave_precision_score": 0.8053999313862006,
            "fpr": 0.054884742041712405,
            "logloss": 0.5223171862181918,
            "mae": 0.3509295349357942,
            "precision": 0.8659517426273459,
            "recall": 0.6605316973415133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(41)",
        "seed": 871,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7109686658874257,
            "auditor_fn_violation": 0.009436898698358813,
            "auditor_fp_violation": 0.008897032850582838,
            "ave_precision_score": 0.7139626814696095,
            "fpr": 0.08881578947368421,
            "logloss": 1.6000234368426334,
            "mae": 0.3794146184095592,
            "precision": 0.7672413793103449,
            "recall": 0.5741935483870968
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7739367328852031,
            "auditor_fn_violation": 0.013017448633942339,
            "auditor_fp_violation": 0.009728385556208741,
            "ave_precision_score": 0.7639553966338842,
            "fpr": 0.0889132821075741,
            "logloss": 1.7174977875277089,
            "mae": 0.38574910410952773,
            "precision": 0.7828418230563002,
            "recall": 0.5971370143149284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(42)",
        "seed": 871,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.728386892662734,
            "auditor_fn_violation": 0.007623561592152432,
            "auditor_fp_violation": 0.013054868715412699,
            "ave_precision_score": 0.7443793736278927,
            "fpr": 0.11513157894736842,
            "logloss": 0.5666901908419615,
            "mae": 0.371145536686016,
            "precision": 0.7624434389140271,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.7650118532843938,
            "auditor_fn_violation": 0.012485437023967462,
            "auditor_fp_violation": 0.012147476082217862,
            "ave_precision_score": 0.7738808695504047,
            "fpr": 0.08562019758507135,
            "logloss": 0.5761583396981486,
            "mae": 0.37078250109593247,
            "precision": 0.8156028368794326,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(43)",
        "seed": 871,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7635981262560012,
            "auditor_fn_violation": 0.007291077155253724,
            "auditor_fp_violation": 0.029590545154833395,
            "ave_precision_score": 0.6884750904886912,
            "fpr": 0.17543859649122806,
            "logloss": 0.598776453610035,
            "mae": 0.40874045169013634,
            "precision": 0.6780684104627767,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7669040344579304,
            "auditor_fn_violation": 0.01634420477732957,
            "auditor_fp_violation": 0.015055587058646042,
            "ave_precision_score": 0.7005534907526291,
            "fpr": 0.1668496158068057,
            "logloss": 0.6056450356265337,
            "mae": 0.4132074616219681,
            "precision": 0.6953907815631263,
            "recall": 0.7096114519427403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(44)",
        "seed": 871,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8439316407158625,
            "auditor_fn_violation": 0.004624127523108856,
            "auditor_fp_violation": 0.006230621295969234,
            "ave_precision_score": 0.8393907220901712,
            "fpr": 0.10416666666666667,
            "logloss": 0.48695580901421126,
            "mae": 0.32479706427017063,
            "precision": 0.7850678733031674,
            "recall": 0.7462365591397849
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8678825247208337,
            "auditor_fn_violation": 0.005733154649265176,
            "auditor_fp_violation": 0.00937982842665474,
            "ave_precision_score": 0.8631107815002674,
            "fpr": 0.07025246981339188,
            "logloss": 0.4881041973310185,
            "mae": 0.3238098059916863,
            "precision": 0.8415841584158416,
            "recall": 0.6952965235173824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(45)",
        "seed": 871,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.6706467782359123,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5251993424421268,
            "fpr": 0.4901315789473684,
            "logloss": 0.693053730219031,
            "mae": 0.4996071282708854,
            "precision": 0.5098684210526315,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.659682334256561,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5385064630995074,
            "fpr": 0.4632272228320527,
            "logloss": 0.6911003557057536,
            "mae": 0.49863268122584053,
            "precision": 0.5367727771679474,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(46)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8206751332592432,
            "auditor_fn_violation": 0.0017449537823052306,
            "auditor_fp_violation": 0.0034808077240080066,
            "ave_precision_score": 0.8135520539118484,
            "fpr": 0.08552631578947369,
            "logloss": 0.5152432310286393,
            "mae": 0.3304033198255,
            "precision": 0.8040201005025126,
            "recall": 0.6881720430107527
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8634679045590018,
            "auditor_fn_violation": 0.009612125375157978,
            "auditor_fp_violation": 0.00425291721508056,
            "ave_precision_score": 0.8573959746557802,
            "fpr": 0.05378704720087816,
            "logloss": 0.5029116475505281,
            "mae": 0.3232224005040366,
            "precision": 0.8682795698924731,
            "recall": 0.6605316973415133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(47)",
        "seed": 871,
        "test": {
            "accuracy": 0.543859649122807,
            "auc_prc": 0.5375878540207017,
            "auditor_fn_violation": 0.010024052065647993,
            "auditor_fp_violation": 0.0127899446603085,
            "ave_precision_score": 0.5383399088118185,
            "fpr": 0.4331140350877193,
            "logloss": 0.7077660550823784,
            "mae": 0.4860981640062834,
            "precision": 0.5292014302741359,
            "recall": 0.9548387096774194
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.5455832442781872,
            "auditor_fn_violation": 0.01282215323281232,
            "auditor_fp_violation": 0.022718641563616887,
            "ave_precision_score": 0.5473141087192277,
            "fpr": 0.3995609220636663,
            "logloss": 0.70336754447431,
            "mae": 0.4850262714269787,
            "precision": 0.5571776155717761,
            "recall": 0.9366053169734151
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(48)",
        "seed": 871,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7602747808081485,
            "auditor_fn_violation": 0.011247877758913416,
            "auditor_fp_violation": 0.01844165783586484,
            "ave_precision_score": 0.7430112537747158,
            "fpr": 0.26535087719298245,
            "logloss": 1.4624193133579926,
            "mae": 0.399773267457229,
            "precision": 0.6230529595015576,
            "recall": 0.8602150537634409
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7646294083681691,
            "auditor_fn_violation": 0.009360710605887147,
            "auditor_fp_violation": 0.007741089683229212,
            "ave_precision_score": 0.7479791007865494,
            "fpr": 0.23380900109769484,
            "logloss": 1.4767111459278022,
            "mae": 0.3979404582084861,
            "precision": 0.6666666666666666,
            "recall": 0.8711656441717791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(49)",
        "seed": 871,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.6184577901959812,
            "auditor_fn_violation": 0.03563242784380306,
            "auditor_fp_violation": 0.05100278660857962,
            "ave_precision_score": 0.6210969511036601,
            "fpr": 0.23903508771929824,
            "logloss": 0.669621340332483,
            "mae": 0.46042113042060745,
            "precision": 0.5962962962962963,
            "recall": 0.6924731182795699
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.6731282541447909,
            "auditor_fn_violation": 0.05342788324477697,
            "auditor_fp_violation": 0.03337564574110009,
            "ave_precision_score": 0.6727165703562952,
            "fpr": 0.1942919868276619,
            "logloss": 0.6417449961416385,
            "mae": 0.44977435512155395,
            "precision": 0.6438631790744467,
            "recall": 0.65439672801636
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(50)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8274963844254741,
            "auditor_fn_violation": 0.010377758913412563,
            "auditor_fp_violation": 0.021287138427724794,
            "ave_precision_score": 0.8089110751139026,
            "fpr": 0.18201754385964913,
            "logloss": 0.9369927083244936,
            "mae": 0.3028137991355322,
            "precision": 0.6879699248120301,
            "recall": 0.7870967741935484
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8524221319749704,
            "auditor_fn_violation": 0.008714215484905013,
            "auditor_fp_violation": 0.013900666420422337,
            "ave_precision_score": 0.8412319409055748,
            "fpr": 0.15587266739846323,
            "logloss": 1.047858828009575,
            "mae": 0.30024764521334146,
            "precision": 0.7269230769230769,
            "recall": 0.7730061349693251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(51)",
        "seed": 871,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8193257682752867,
            "auditor_fn_violation": 0.008503112620260333,
            "auditor_fp_violation": 0.005217532085246674,
            "ave_precision_score": 0.8151253876452698,
            "fpr": 0.08223684210526316,
            "logloss": 0.5218261960472804,
            "mae": 0.34177652559357513,
            "precision": 0.8152709359605911,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8495755515394641,
            "auditor_fn_violation": 0.005394193665694681,
            "auditor_fp_violation": 0.008347162901035791,
            "ave_precision_score": 0.8456664185134173,
            "fpr": 0.06915477497255763,
            "logloss": 0.5321734446442101,
            "mae": 0.3468223526525903,
            "precision": 0.8417085427135679,
            "recall": 0.6850715746421268
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(52)",
        "seed": 871,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5507800528184237,
            "auditor_fn_violation": 0.006939728353140935,
            "auditor_fp_violation": 0.011850445464892657,
            "ave_precision_score": 0.551534661172566,
            "fpr": 0.06030701754385965,
            "logloss": 0.6916692007142407,
            "mae": 0.49527381086035777,
            "precision": 0.6126760563380281,
            "recall": 0.1870967741935484
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5843281839111313,
            "auditor_fn_violation": 0.0032279860554594113,
            "auditor_fp_violation": 0.011525795828759608,
            "ave_precision_score": 0.5844417405197135,
            "fpr": 0.06037321624588365,
            "logloss": 0.686202158784815,
            "mae": 0.49278285572740826,
            "precision": 0.5985401459854015,
            "recall": 0.16768916155419222
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(53)",
        "seed": 871,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.7642770519230337,
            "auditor_fn_violation": 0.009969817015657426,
            "auditor_fp_violation": 0.025847266376231404,
            "ave_precision_score": 0.6738344142042179,
            "fpr": 0.17324561403508773,
            "logloss": 0.6197635075627991,
            "mae": 0.43220252821450694,
            "precision": 0.6788617886178862,
            "recall": 0.7182795698924731
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7615239737982281,
            "auditor_fn_violation": 0.01683581044224308,
            "auditor_fp_violation": 0.015679868484712915,
            "ave_precision_score": 0.6724914756948066,
            "fpr": 0.16245883644346873,
            "logloss": 0.6249276508611933,
            "mae": 0.43332202964831396,
            "precision": 0.6997971602434077,
            "recall": 0.7055214723926381
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(54)",
        "seed": 871,
        "test": {
            "accuracy": 0.5175438596491229,
            "auc_prc": 0.5395128417700655,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0014472703010322268,
            "ave_precision_score": 0.5541745534074101,
            "fpr": 0.4824561403508772,
            "logloss": 0.6923867254628966,
            "mae": 0.49939616759748834,
            "precision": 0.5138121546961326,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5327564111630426,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0011601229834409502,
            "ave_precision_score": 0.5551660743960951,
            "fpr": 0.4566410537870472,
            "logloss": 0.6910069982086741,
            "mae": 0.49871028810903084,
            "precision": 0.5403314917127072,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(55)",
        "seed": 871,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8068536220498321,
            "auditor_fn_violation": 0.02456376155442369,
            "auditor_fp_violation": 0.02154715648180855,
            "ave_precision_score": 0.8010303949805968,
            "fpr": 0.14473684210526316,
            "logloss": 0.5145623328137546,
            "mae": 0.3544215930772847,
            "precision": 0.736,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8233045146535021,
            "auditor_fn_violation": 0.02086742584947888,
            "auditor_fp_violation": 0.02104608757627939,
            "ave_precision_score": 0.8225052342638585,
            "fpr": 0.1350164654226125,
            "logloss": 0.5275726679882717,
            "mae": 0.3559828939143278,
            "precision": 0.7549800796812749,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(56)",
        "seed": 871,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6527195118867866,
            "auditor_fn_violation": 0.01120543293718167,
            "auditor_fp_violation": 0.021525079477216533,
            "ave_precision_score": 0.6531708758678199,
            "fpr": 0.07894736842105263,
            "logloss": 1.8255459442401458,
            "mae": 0.4477410888915248,
            "precision": 0.6666666666666666,
            "recall": 0.3096774193548387
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6846944057054438,
            "auditor_fn_violation": 0.022048177355161527,
            "auditor_fp_violation": 0.013804423033903685,
            "ave_precision_score": 0.685253324711933,
            "fpr": 0.07135016465422613,
            "logloss": 1.897825597536765,
            "mae": 0.4514300867302322,
            "precision": 0.6976744186046512,
            "recall": 0.3067484662576687
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(57)",
        "seed": 871,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8237373061178395,
            "auditor_fn_violation": 0.008852103376721373,
            "auditor_fp_violation": 0.011310785352643354,
            "ave_precision_score": 0.8251911559806189,
            "fpr": 0.16557017543859648,
            "logloss": 0.5275052374497143,
            "mae": 0.33200086142639057,
            "precision": 0.7229357798165138,
            "recall": 0.8473118279569892
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8730734083734308,
            "auditor_fn_violation": 0.010902870842396613,
            "auditor_fp_violation": 0.026552769988710916,
            "ave_precision_score": 0.873258592213191,
            "fpr": 0.14050493962678376,
            "logloss": 0.4870346106705601,
            "mae": 0.3184031033735113,
            "precision": 0.7571157495256167,
            "recall": 0.8159509202453987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(58)",
        "seed": 871,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8398731883708224,
            "auditor_fn_violation": 0.008463025844180341,
            "auditor_fp_violation": 0.021341104438949727,
            "ave_precision_score": 0.8402523354821598,
            "fpr": 0.09210526315789473,
            "logloss": 0.7448450452370663,
            "mae": 0.28761557965798096,
            "precision": 0.7961165048543689,
            "recall": 0.7053763440860215
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8674469900153188,
            "auditor_fn_violation": 0.007733248929803656,
            "auditor_fp_violation": 0.005816221952856353,
            "ave_precision_score": 0.8676213765668339,
            "fpr": 0.06805708013172337,
            "logloss": 0.7893437699136463,
            "mae": 0.2914040048470898,
            "precision": 0.8426395939086294,
            "recall": 0.6789366053169734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(59)",
        "seed": 871,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5675204270753553,
            "auditor_fn_violation": 0.007227409922656114,
            "auditor_fp_violation": 0.0006549511362298396,
            "ave_precision_score": 0.5641075884277249,
            "fpr": 0.14802631578947367,
            "logloss": 6.488814986974054,
            "mae": 0.49402962495229746,
            "precision": 0.555921052631579,
            "recall": 0.3634408602150538
        },
        "train": {
            "accuracy": 0.4950603732162459,
            "auc_prc": 0.5831743439690137,
            "auditor_fn_violation": 0.013904134650567144,
            "auditor_fp_violation": 0.0025959702633947435,
            "ave_precision_score": 0.5841997264021214,
            "fpr": 0.14709110867178923,
            "logloss": 7.042886429152459,
            "mae": 0.5220041833227629,
            "precision": 0.5488215488215489,
            "recall": 0.3333333333333333
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(60)",
        "seed": 871,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.4511041224857014,
            "auditor_fn_violation": 0.0013440860215053736,
            "auditor_fp_violation": 0.0029803956199222895,
            "ave_precision_score": 0.5462489712701938,
            "fpr": 0.005482456140350877,
            "logloss": 0.7221539165838969,
            "mae": 0.4928654298317014,
            "precision": 0.2857142857142857,
            "recall": 0.004301075268817204
        },
        "train": {
            "accuracy": 0.4621295279912184,
            "auc_prc": 0.3584572718318818,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0006502931521529906,
            "ave_precision_score": 0.5607666085125886,
            "fpr": 0.0010976948408342481,
            "logloss": 0.743046192822791,
            "mae": 0.502662759057515,
            "precision": 0.0,
            "recall": 0.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(61)",
        "seed": 871,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7743772180423731,
            "auditor_fn_violation": 0.009825976230899834,
            "auditor_fp_violation": 0.02153734447976766,
            "ave_precision_score": 0.7062312003054136,
            "fpr": 0.17324561403508773,
            "logloss": 6.771466012403721,
            "mae": 0.31081640812270306,
            "precision": 0.680161943319838,
            "recall": 0.7225806451612903
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.7966872356283139,
            "auditor_fn_violation": 0.01697723124995791,
            "auditor_fp_violation": 0.01670993283772325,
            "ave_precision_score": 0.7376807286811685,
            "fpr": 0.15916575192096596,
            "logloss": 6.760193811262934,
            "mae": 0.3153253436025065,
            "precision": 0.7046843177189409,
            "recall": 0.7075664621676891
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(62)",
        "seed": 871,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7163779625975378,
            "auditor_fn_violation": 0.010231560083003207,
            "auditor_fp_violation": 0.013052415714902467,
            "ave_precision_score": 0.714895018453558,
            "fpr": 0.1162280701754386,
            "logloss": 1.0999667987361494,
            "mae": 0.3406104500891505,
            "precision": 0.7574370709382151,
            "recall": 0.7118279569892473
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7433225278040352,
            "auditor_fn_violation": 0.008545857380482582,
            "auditor_fp_violation": 0.004895406849407713,
            "ave_precision_score": 0.7427536759518654,
            "fpr": 0.1119648737650933,
            "logloss": 1.0343280287768584,
            "mae": 0.34314536198793383,
            "precision": 0.7702702702702703,
            "recall": 0.6993865030674846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(63)",
        "seed": 871,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.833176971858322,
            "auditor_fn_violation": 0.0017543859649122868,
            "auditor_fp_violation": 0.008899485851093061,
            "ave_precision_score": 0.7571176187434068,
            "fpr": 0.09978070175438597,
            "logloss": 3.910583111529934,
            "mae": 0.2650777141510989,
            "precision": 0.7893518518518519,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.852148170161281,
            "auditor_fn_violation": 0.010449426347818867,
            "auditor_fp_violation": 0.0076396439514933336,
            "ave_precision_score": 0.79527972639802,
            "fpr": 0.07574094401756312,
            "logloss": 3.1138795417014165,
            "mae": 0.25821007982332655,
            "precision": 0.8317073170731707,
            "recall": 0.6973415132924335
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(64)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.7433586440128539,
            "auditor_fn_violation": 0.008465383889832118,
            "auditor_fp_violation": 0.007847148632206917,
            "ave_precision_score": 0.7371394646784907,
            "fpr": 0.07785087719298246,
            "logloss": 2.0800453351958206,
            "mae": 0.33956019709441676,
            "precision": 0.8151041666666666,
            "recall": 0.6731182795698925
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.779434221959228,
            "auditor_fn_violation": 0.001919282390415712,
            "auditor_fp_violation": 0.008765951691022315,
            "ave_precision_score": 0.7624157790674813,
            "fpr": 0.06586169045005488,
            "logloss": 2.188948714732008,
            "mae": 0.34594735890854694,
            "precision": 0.8387096774193549,
            "recall": 0.6380368098159509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(65)",
        "seed": 871,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7379852795598767,
            "auditor_fn_violation": 0.008276740237691009,
            "auditor_fp_violation": 0.006750657404136741,
            "ave_precision_score": 0.7395951523357418,
            "fpr": 0.10307017543859649,
            "logloss": 0.6275157274830818,
            "mae": 0.3885710843891853,
            "precision": 0.7577319587628866,
            "recall": 0.632258064516129
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7452635121723474,
            "auditor_fn_violation": 0.008586263325543976,
            "auditor_fp_violation": 0.00026531960607841865,
            "ave_precision_score": 0.7463854114992794,
            "fpr": 0.09440175631174534,
            "logloss": 0.6341691312702483,
            "mae": 0.40007911983194516,
            "precision": 0.7643835616438356,
            "recall": 0.5705521472392638
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(66)",
        "seed": 871,
        "test": {
            "accuracy": 0.34978070175438597,
            "auc_prc": 0.5135634462869503,
            "auditor_fn_violation": 0.016081871345029246,
            "auditor_fp_violation": 0.027360767691039692,
            "ave_precision_score": 0.4578727068813586,
            "fpr": 0.31030701754385964,
            "logloss": 0.7187743187993182,
            "mae": 0.5110727007451811,
            "precision": 0.3538812785388128,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.3534577387486279,
            "auc_prc": 0.5435474466203187,
            "auditor_fn_violation": 0.018869576343666053,
            "auditor_fp_violation": 0.015955592781225783,
            "ave_precision_score": 0.48422822288930456,
            "fpr": 0.29857299670691545,
            "logloss": 0.7163585315535282,
            "mae": 0.5098525188887812,
            "precision": 0.38738738738738737,
            "recall": 0.35173824130879344
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(67)",
        "seed": 871,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6411575304940567,
            "auditor_fn_violation": 0.001131861912846637,
            "auditor_fp_violation": 0.020818615330272,
            "ave_precision_score": 0.6429531844642777,
            "fpr": 0.20614035087719298,
            "logloss": 0.6338323022442585,
            "mae": 0.4365152825290958,
            "precision": 0.656934306569343,
            "recall": 0.7741935483870968
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.6952241549740075,
            "auditor_fn_violation": 0.012166679012927659,
            "auditor_fp_violation": 0.008604678989288378,
            "ave_precision_score": 0.6961910742430988,
            "fpr": 0.16575192096597147,
            "logloss": 0.6417018393890594,
            "mae": 0.43620501767790804,
            "precision": 0.7073643410852714,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(68)",
        "seed": 871,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.6196944406298466,
            "auditor_fn_violation": 0.02234719864176572,
            "auditor_fp_violation": 0.023033674791004356,
            "ave_precision_score": 0.6109389791284967,
            "fpr": 0.17214912280701755,
            "logloss": 0.645192342825227,
            "mae": 0.4534390302407637,
            "precision": 0.6623655913978495,
            "recall": 0.6623655913978495
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.6279462770010791,
            "auditor_fn_violation": 0.02744012624613057,
            "auditor_fp_violation": 0.02936723875122906,
            "ave_precision_score": 0.6188172481506174,
            "fpr": 0.1690450054884742,
            "logloss": 0.6576552294420868,
            "mae": 0.45945061669653253,
            "precision": 0.6666666666666666,
            "recall": 0.6298568507157464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(69)",
        "seed": 871,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.81821347942982,
            "auditor_fn_violation": 0.004499151103565366,
            "auditor_fp_violation": 0.02458151811295577,
            "ave_precision_score": 0.8186190562999809,
            "fpr": 0.15679824561403508,
            "logloss": 1.0886040765835052,
            "mae": 0.2951577993156593,
            "precision": 0.717391304347826,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8382757653947652,
            "auditor_fn_violation": 0.00944601204546118,
            "auditor_fp_violation": 0.017237970877271473,
            "ave_precision_score": 0.8385320273796717,
            "fpr": 0.1437980241492865,
            "logloss": 0.9848341983872132,
            "mae": 0.29816370103573697,
            "precision": 0.7369477911646586,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(70)",
        "seed": 871,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7495668293880955,
            "auditor_fn_violation": 0.006555366911903419,
            "auditor_fp_violation": 0.009721241022018143,
            "ave_precision_score": 0.7501642732054339,
            "fpr": 0.19188596491228072,
            "logloss": 0.6027492750301928,
            "mae": 0.36700715652356547,
            "precision": 0.6823956442831216,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8214847867762365,
            "auditor_fn_violation": 0.013767203392303567,
            "auditor_fp_violation": 0.0027260288938253403,
            "ave_precision_score": 0.8095412403545766,
            "fpr": 0.15148188803512624,
            "logloss": 0.5499140327695263,
            "mae": 0.3535977204858799,
            "precision": 0.7351247600767754,
            "recall": 0.7832310838445807
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(71)",
        "seed": 871,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7862774281391977,
            "auditor_fn_violation": 0.003013582342954161,
            "auditor_fp_violation": 0.005651713175556341,
            "ave_precision_score": 0.7802133181145395,
            "fpr": 0.08771929824561403,
            "logloss": 0.5453155149027679,
            "mae": 0.3503948739983076,
            "precision": 0.801980198019802,
            "recall": 0.6967741935483871
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8254668099677703,
            "auditor_fn_violation": 0.008415660446395905,
            "auditor_fp_violation": 0.004635289588546518,
            "ave_precision_score": 0.8170016597063045,
            "fpr": 0.05378704720087816,
            "logloss": 0.5468465607421904,
            "mae": 0.34811683641143476,
            "precision": 0.8693333333333333,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(72)",
        "seed": 871,
        "test": {
            "accuracy": 0.5098684210526315,
            "auc_prc": 0.25828947368421057,
            "auditor_fn_violation": 0.0017260894170911148,
            "auditor_fp_violation": 0.001648416342870607,
            "ave_precision_score": 0.5099983022071307,
            "fpr": 0.48355263157894735,
            "logloss": 0.6975908083429828,
            "mae": 0.4991062989360408,
            "precision": 0.51,
            "recall": 0.9870967741935484
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.271939549859644,
            "auditor_fn_violation": 0.002181921033314702,
            "auditor_fp_violation": 0.000681507223456352,
            "ave_precision_score": 0.5394661073237383,
            "fpr": 0.4544456641053787,
            "logloss": 0.689679393599416,
            "mae": 0.4952527380146651,
            "precision": 0.5394883203559511,
            "recall": 0.9918200408997955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(73)",
        "seed": 871,
        "test": {
            "accuracy": 0.4901315789473684,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6855693001208266,
            "mae": 0.4866181562834403,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4632272228320527,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6960328374066387,
            "mae": 0.4916688123989838,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(74)",
        "seed": 871,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.6815900444198825,
            "auditor_fn_violation": 0.008562063761554429,
            "auditor_fp_violation": 0.003350798696966129,
            "ave_precision_score": 0.6813159145567361,
            "fpr": 0.05701754385964912,
            "logloss": 0.6698164700663174,
            "mae": 0.4810892330940094,
            "precision": 0.7373737373737373,
            "recall": 0.3139784946236559
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6818363981381736,
            "auditor_fn_violation": 0.020384799283467925,
            "auditor_fp_violation": 0.006112755630238113,
            "ave_precision_score": 0.683059059097197,
            "fpr": 0.07135016465422613,
            "logloss": 0.6744912342548168,
            "mae": 0.48370637650612813,
            "precision": 0.717391304347826,
            "recall": 0.3374233128834356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(75)",
        "seed": 871,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.834137089316439,
            "auditor_fn_violation": 0.0036431805319751026,
            "auditor_fp_violation": 0.012809568664390283,
            "ave_precision_score": 0.8343668636723905,
            "fpr": 0.1337719298245614,
            "logloss": 0.5028067477444847,
            "mae": 0.3302362039315069,
            "precision": 0.7510204081632653,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8517856259792819,
            "auditor_fn_violation": 0.009919659512569616,
            "auditor_fp_violation": 0.009884455912725462,
            "ave_precision_score": 0.8528969883170008,
            "fpr": 0.10318331503841932,
            "logloss": 0.4988975436221436,
            "mae": 0.3259340544478123,
            "precision": 0.7943107221006565,
            "recall": 0.7423312883435583
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(76)",
        "seed": 871,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7143012522300937,
            "auditor_fn_violation": 0.004395397094887759,
            "auditor_fp_violation": 0.006578947368421052,
            "ave_precision_score": 0.700968402323976,
            "fpr": 0.09210526315789473,
            "logloss": 0.5726098334039444,
            "mae": 0.3793459124863148,
            "precision": 0.7936117936117936,
            "recall": 0.6946236559139785
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7522141987259978,
            "auditor_fn_violation": 0.009612125375157978,
            "auditor_fp_violation": 0.00489020450419049,
            "ave_precision_score": 0.743393789613758,
            "fpr": 0.0570801317233809,
            "logloss": 0.5426415886848782,
            "mae": 0.3716271516798487,
            "precision": 0.8613333333333333,
            "recall": 0.6605316973415133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(77)",
        "seed": 871,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8347802180954684,
            "auditor_fn_violation": 0.01140350877192983,
            "auditor_fp_violation": 0.01767632167667491,
            "ave_precision_score": 0.8306268087952242,
            "fpr": 0.12280701754385964,
            "logloss": 0.5088997917606938,
            "mae": 0.3133942208644983,
            "precision": 0.768595041322314,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8708767462884828,
            "auditor_fn_violation": 0.008866860166248016,
            "auditor_fp_violation": 0.02115273565323248,
            "ave_precision_score": 0.8669315944193328,
            "fpr": 0.10098792535675083,
            "logloss": 0.48479833276426887,
            "mae": 0.30711865653289006,
            "precision": 0.8008658008658008,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(78)",
        "seed": 871,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6099843733359492,
            "auditor_fn_violation": 0.04814186002641011,
            "auditor_fp_violation": 0.08863426743592763,
            "ave_precision_score": 0.6110907763481217,
            "fpr": 0.3541666666666667,
            "logloss": 0.7613629618500285,
            "mae": 0.45235601756416655,
            "precision": 0.5538674033149171,
            "recall": 0.8623655913978494
        },
        "train": {
            "accuracy": 0.570801317233809,
            "auc_prc": 0.5998958075510765,
            "auditor_fn_violation": 0.06141703649330272,
            "auditor_fp_violation": 0.07691667403665574,
            "ave_precision_score": 0.6016771155555884,
            "fpr": 0.3413830954994512,
            "logloss": 0.7890808194965335,
            "mae": 0.45882905722342987,
            "precision": 0.5680555555555555,
            "recall": 0.83640081799591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(79)",
        "seed": 871,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7596367664093182,
            "auditor_fn_violation": 0.0047891907187323215,
            "auditor_fp_violation": 0.004471819930138552,
            "ave_precision_score": 0.6796178116577039,
            "fpr": 0.16228070175438597,
            "logloss": 0.6032552087552125,
            "mae": 0.4217144907207081,
            "precision": 0.6960985626283368,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7892140763739562,
            "auditor_fn_violation": 0.001147079884798161,
            "auditor_fp_violation": 0.01603622913209275,
            "ave_precision_score": 0.7182019110905298,
            "fpr": 0.12843029637760703,
            "logloss": 0.5936819968451993,
            "mae": 0.4168376813016006,
            "precision": 0.7422907488986784,
            "recall": 0.689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(80)",
        "seed": 871,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7119936220209977,
            "auditor_fn_violation": 0.023217317487266555,
            "auditor_fp_violation": 0.012257643549589862,
            "ave_precision_score": 0.7134417840914576,
            "fpr": 0.13048245614035087,
            "logloss": 0.6140068796633165,
            "mae": 0.40252174188489126,
            "precision": 0.715311004784689,
            "recall": 0.6430107526881721
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7358921074193255,
            "auditor_fn_violation": 0.0253435066523899,
            "auditor_fp_violation": 0.007689066231056968,
            "ave_precision_score": 0.7374908336663417,
            "fpr": 0.1207464324917673,
            "logloss": 0.6402244601568601,
            "mae": 0.40691931514962937,
            "precision": 0.7368421052631579,
            "recall": 0.6298568507157464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(81)",
        "seed": 871,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8482415181078877,
            "auditor_fn_violation": 0.007130730050933787,
            "auditor_fp_violation": 0.02861915695278465,
            "ave_precision_score": 0.8485420999533684,
            "fpr": 0.1611842105263158,
            "logloss": 0.5369099457881236,
            "mae": 0.28362140069989356,
            "precision": 0.7194656488549618,
            "recall": 0.810752688172043
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8612227677347908,
            "auditor_fn_violation": 0.008310156034291184,
            "auditor_fp_violation": 0.017381035370745132,
            "ave_precision_score": 0.8614709375897305,
            "fpr": 0.14270032930845225,
            "logloss": 0.5534806739023741,
            "mae": 0.2807002946955247,
            "precision": 0.749034749034749,
            "recall": 0.7934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(82)",
        "seed": 871,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8062087172361962,
            "auditor_fn_violation": 0.017194868892661766,
            "auditor_fp_violation": 0.012444071588366891,
            "ave_precision_score": 0.7992544222678053,
            "fpr": 0.09539473684210527,
            "logloss": 0.994451391334921,
            "mae": 0.28276595892027234,
            "precision": 0.7825,
            "recall": 0.6731182795698925
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7951058420518335,
            "auditor_fn_violation": 0.013919848073646572,
            "auditor_fp_violation": 0.008625488370157267,
            "ave_precision_score": 0.7855002732034544,
            "fpr": 0.08342480790340286,
            "logloss": 1.2585551997550266,
            "mae": 0.28764282315511985,
            "precision": 0.81,
            "recall": 0.6625766871165644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(83)",
        "seed": 871,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8335253071807458,
            "auditor_fn_violation": 0.011830315034899083,
            "auditor_fp_violation": 0.013908512892970694,
            "ave_precision_score": 0.8339614227724503,
            "fpr": 0.13815789473684212,
            "logloss": 0.5754534803291448,
            "mae": 0.33337162709455503,
            "precision": 0.7449392712550608,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8350884814045128,
            "auditor_fn_violation": 0.020393778382370442,
            "auditor_fp_violation": 0.016416000332950105,
            "ave_precision_score": 0.8353410838089581,
            "fpr": 0.12843029637760703,
            "logloss": 0.642535671855484,
            "mae": 0.3422410161869226,
            "precision": 0.7526427061310782,
            "recall": 0.7280163599182005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(84)",
        "seed": 871,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7693225944904953,
            "auditor_fn_violation": 0.010448500282965486,
            "auditor_fp_violation": 0.007314847521488285,
            "ave_precision_score": 0.7902976672297474,
            "fpr": 0.08881578947368421,
            "logloss": 0.5209147363119986,
            "mae": 0.33721227835242945,
            "precision": 0.8048192771084337,
            "recall": 0.7182795698924731
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8182937828554747,
            "auditor_fn_violation": 0.006750037599976652,
            "auditor_fp_violation": 0.005041072515489985,
            "ave_precision_score": 0.8267660367129152,
            "fpr": 0.06147091108671789,
            "logloss": 0.5094833311879687,
            "mae": 0.33199963596793614,
            "precision": 0.8564102564102564,
            "recall": 0.6830265848670757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(85)",
        "seed": 871,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.630485354240456,
            "auditor_fn_violation": 0.004958970005659313,
            "auditor_fp_violation": 0.014874995093998984,
            "ave_precision_score": 0.6317059798885722,
            "fpr": 0.18969298245614036,
            "logloss": 0.6642423175464605,
            "mae": 0.4528931488789487,
            "precision": 0.5938967136150235,
            "recall": 0.5440860215053763
        },
        "train": {
            "accuracy": 0.5817782656421515,
            "auc_prc": 0.6763561193169809,
            "auditor_fn_violation": 0.007944257754013105,
            "auditor_fp_violation": 0.014358472799538039,
            "ave_precision_score": 0.6780816909509956,
            "fpr": 0.18880351262349068,
            "logloss": 0.6502796215557746,
            "mae": 0.44859473592101806,
            "precision": 0.6194690265486725,
            "recall": 0.5725971370143149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(86)",
        "seed": 871,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8373121399488808,
            "auditor_fn_violation": 0.0124151103565365,
            "auditor_fp_violation": 0.01049638918324895,
            "ave_precision_score": 0.8336159656868105,
            "fpr": 0.06140350877192982,
            "logloss": 0.5344199686737706,
            "mae": 0.3290187032615537,
            "precision": 0.84,
            "recall": 0.632258064516129
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8629120737058571,
            "auditor_fn_violation": 0.00646270643509572,
            "auditor_fp_violation": 0.01210065497526285,
            "ave_precision_score": 0.8600871160213172,
            "fpr": 0.059275521405049394,
            "logloss": 0.5417836218751819,
            "mae": 0.32886759697180545,
            "precision": 0.8452722063037249,
            "recall": 0.6032719836400818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(87)",
        "seed": 871,
        "test": {
            "accuracy": 0.5942982456140351,
            "auc_prc": 0.7021818653136485,
            "auditor_fn_violation": 0.005586210149028488,
            "auditor_fp_violation": 0.004893736017897093,
            "ave_precision_score": 0.7057389433959709,
            "fpr": 0.03508771929824561,
            "logloss": 0.9985844117084163,
            "mae": 0.40812827366906473,
            "precision": 0.7987421383647799,
            "recall": 0.2731182795698925
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7772792920721506,
            "auditor_fn_violation": 0.005650097984416773,
            "auditor_fp_violation": 0.0017271786121183434,
            "ave_precision_score": 0.7767920137804054,
            "fpr": 0.018660812294182216,
            "logloss": 1.1491323013421741,
            "mae": 0.4107839496652016,
            "precision": 0.89171974522293,
            "recall": 0.28629856850715746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(88)",
        "seed": 871,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.699148219003669,
            "auditor_fn_violation": 0.010476796830786648,
            "auditor_fp_violation": 0.025744240354802,
            "ave_precision_score": 0.7003705808815756,
            "fpr": 0.1962719298245614,
            "logloss": 0.691160497973585,
            "mae": 0.3949851185704271,
            "precision": 0.6544401544401545,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.716155414744416,
            "auditor_fn_violation": 0.01820287825015321,
            "auditor_fp_violation": 0.01525327617690055,
            "ave_precision_score": 0.7170275158781859,
            "fpr": 0.18551042810098792,
            "logloss": 0.6827508827967264,
            "mae": 0.3943690690002379,
            "precision": 0.675,
            "recall": 0.7177914110429447
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(89)",
        "seed": 871,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8147792420334479,
            "auditor_fn_violation": 0.003989813242784388,
            "auditor_fp_violation": 0.016300188390439195,
            "ave_precision_score": 0.8151179815990031,
            "fpr": 0.15350877192982457,
            "logloss": 0.814142595544627,
            "mae": 0.2882148684260309,
            "precision": 0.7343453510436433,
            "recall": 0.832258064516129
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8045525980240367,
            "auditor_fn_violation": 0.003742039467629229,
            "auditor_fp_violation": 0.013689971439124761,
            "ave_precision_score": 0.8046109772412391,
            "fpr": 0.132821075740944,
            "logloss": 0.8776743406550311,
            "mae": 0.28430925359291104,
            "precision": 0.766859344894027,
            "recall": 0.8139059304703476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(90)",
        "seed": 871,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7954256990691064,
            "auditor_fn_violation": 0.0075598943595548045,
            "auditor_fp_violation": 0.018726205895050835,
            "ave_precision_score": 0.7714247920253171,
            "fpr": 0.18640350877192982,
            "logloss": 1.8840201334654285,
            "mae": 0.28102873604822426,
            "precision": 0.6953405017921147,
            "recall": 0.8344086021505376
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7917623240700781,
            "auditor_fn_violation": 0.0066265749900668745,
            "auditor_fp_violation": 0.01591397401948798,
            "ave_precision_score": 0.7638480054461836,
            "fpr": 0.1734357848518112,
            "logloss": 2.1030507406054486,
            "mae": 0.2771374863632575,
            "precision": 0.7158273381294964,
            "recall": 0.8139059304703476
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(91)",
        "seed": 871,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7381134209918414,
            "auditor_fn_violation": 0.008014997170345218,
            "auditor_fp_violation": 0.01291014168530947,
            "ave_precision_score": 0.7387651853608309,
            "fpr": 0.42653508771929827,
            "logloss": 0.7970502394248486,
            "mae": 0.4315220875493986,
            "precision": 0.5244498777506112,
            "recall": 0.9225806451612903
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7852686478679733,
            "auditor_fn_violation": 0.010983682732519382,
            "auditor_fp_violation": 0.026568377024362586,
            "ave_precision_score": 0.7858089467187828,
            "fpr": 0.3918770581778266,
            "logloss": 0.7205221318075016,
            "mae": 0.4080208336809726,
            "precision": 0.5614250614250614,
            "recall": 0.934560327198364
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(92)",
        "seed": 871,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6795477851883636,
            "auditor_fn_violation": 0.004385964912280705,
            "auditor_fp_violation": 0.01479649907767182,
            "ave_precision_score": 0.6825973904671805,
            "fpr": 0.2807017543859649,
            "logloss": 0.6330328585335352,
            "mae": 0.40436398198321594,
            "precision": 0.6115326251896813,
            "recall": 0.8666666666666667
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7816791908096316,
            "auditor_fn_violation": 0.007221440292359466,
            "auditor_fp_violation": 0.025158541470494903,
            "ave_precision_score": 0.7676097442377764,
            "fpr": 0.2239297475301866,
            "logloss": 0.5863631000739818,
            "mae": 0.38419316753614224,
            "precision": 0.6688311688311688,
            "recall": 0.8425357873210634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(93)",
        "seed": 871,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6273546894997879,
            "auditor_fn_violation": 0.02037351443123939,
            "auditor_fp_violation": 0.0389217590957259,
            "ave_precision_score": 0.6293334176681271,
            "fpr": 0.41885964912280704,
            "logloss": 0.9339580099003919,
            "mae": 0.4527108026470258,
            "precision": 0.5341463414634147,
            "recall": 0.9419354838709677
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6132765408111932,
            "auditor_fn_violation": 0.02841660325178067,
            "auditor_fp_violation": 0.03743087383792614,
            "ave_precision_score": 0.6149934237404537,
            "fpr": 0.3973655323819978,
            "logloss": 1.0438173045547539,
            "mae": 0.45028430554110993,
            "precision": 0.5547355473554736,
            "recall": 0.9222903885480572
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(94)",
        "seed": 871,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.7483914611698204,
            "auditor_fn_violation": 0.06326636483682324,
            "auditor_fp_violation": 0.08032350170728836,
            "ave_precision_score": 0.6097673231009875,
            "fpr": 0.2730263157894737,
            "logloss": 8.785757233828752,
            "mae": 0.3779743078172849,
            "precision": 0.5977382875605816,
            "recall": 0.7956989247311828
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7431213475747018,
            "auditor_fn_violation": 0.07441652692944,
            "auditor_fp_violation": 0.0807143860452292,
            "ave_precision_score": 0.6115310671945784,
            "fpr": 0.25905598243688255,
            "logloss": 8.859652466783022,
            "mae": 0.38958489321573797,
            "precision": 0.6105610561056105,
            "recall": 0.7566462167689162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(95)",
        "seed": 871,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8532505656043148,
            "auditor_fn_violation": 0.017388228636106395,
            "auditor_fp_violation": 0.004839770006672164,
            "ave_precision_score": 0.8473279367553481,
            "fpr": 0.11403508771929824,
            "logloss": 0.4655829028473228,
            "mae": 0.31117611438068643,
            "precision": 0.7791932059447984,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8679200840590804,
            "auditor_fn_violation": 0.021217610706677534,
            "auditor_fp_violation": 0.013848642968250089,
            "ave_precision_score": 0.8652875933190994,
            "fpr": 0.09110867178924259,
            "logloss": 0.49043537372097545,
            "mae": 0.3194256095966052,
            "precision": 0.8134831460674158,
            "recall": 0.7402862985685071
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(96)",
        "seed": 871,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.850886454885173,
            "auditor_fn_violation": 0.008675249952839092,
            "auditor_fp_violation": 0.00542849012912595,
            "ave_precision_score": 0.8446607993750879,
            "fpr": 0.08662280701754387,
            "logloss": 0.48561175824625097,
            "mae": 0.31898922142531855,
            "precision": 0.8141176470588235,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8413001920808962,
            "auditor_fn_violation": 0.010027408699399982,
            "auditor_fp_violation": 0.0013968296908246224,
            "ave_precision_score": 0.8387139841465072,
            "fpr": 0.07135016465422613,
            "logloss": 0.518544507909008,
            "mae": 0.32753201615797306,
            "precision": 0.8402948402948403,
            "recall": 0.6993865030674846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(97)",
        "seed": 871,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6391762283891977,
            "auditor_fn_violation": 0.003324844368986989,
            "auditor_fp_violation": 0.004501255936261234,
            "ave_precision_score": 0.6112568379707798,
            "fpr": 0.05701754385964912,
            "logloss": 0.9470723696213496,
            "mae": 0.4622163796740571,
            "precision": 0.688622754491018,
            "recall": 0.24731182795698925
        },
        "train": {
            "accuracy": 0.535675082327113,
            "auc_prc": 0.6698026516650446,
            "auditor_fn_violation": 0.004040594506138348,
            "auditor_fp_violation": 0.007122010602379554,
            "ave_precision_score": 0.6441791620059667,
            "fpr": 0.05598243688254665,
            "logloss": 0.8086290333128626,
            "mae": 0.46645822365088263,
            "precision": 0.6964285714285714,
            "recall": 0.2392638036809816
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(98)",
        "seed": 871,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8287207045648567,
            "auditor_fn_violation": 0.007538671948688934,
            "auditor_fp_violation": 0.022501373680285725,
            "ave_precision_score": 0.8290614578785676,
            "fpr": 0.13706140350877194,
            "logloss": 0.6683888084276461,
            "mae": 0.29241164947712894,
            "precision": 0.7334754797441365,
            "recall": 0.7397849462365591
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8313418772932897,
            "auditor_fn_violation": 0.013167848540559714,
            "auditor_fp_violation": 0.01573189193688515,
            "ave_precision_score": 0.8315748554163896,
            "fpr": 0.13172338090010977,
            "logloss": 0.7132251830403482,
            "mae": 0.2969288055822826,
            "precision": 0.7478991596638656,
            "recall": 0.7280163599182005
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_random_p100_g0",
        "model": "feat_random_p100_g0:archive(99)",
        "seed": 871,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.8019619980685753,
            "auditor_fn_violation": 0.009361441237502358,
            "auditor_fp_violation": 0.02675978256603479,
            "ave_precision_score": 0.802561524941789,
            "fpr": 0.30043859649122806,
            "logloss": 0.6462067406384024,
            "mae": 0.36502633448445093,
            "precision": 0.6178521617852162,
            "recall": 0.9526881720430107
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8185570150488499,
            "auditor_fn_violation": 0.0048554477315429015,
            "auditor_fp_violation": 0.024895823037025103,
            "ave_precision_score": 0.8188975997288601,
            "fpr": 0.27332601536772777,
            "logloss": 0.6027181079449835,
            "mae": 0.35507790923310784,
            "precision": 0.6468085106382979,
            "recall": 0.9325153374233128
        }
    }
]