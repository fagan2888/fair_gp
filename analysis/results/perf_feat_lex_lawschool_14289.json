[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8363568754951791,
            "auditor_fn_violation": 0.021487654982670527,
            "auditor_fp_violation": 0.014767470933866737,
            "ave_precision_score": 0.8366676521216511,
            "fpr": 0.11951754385964912,
            "logloss": 0.832118146890575,
            "mae": 0.2745093833472801,
            "precision": 0.770042194092827,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8319013443539075,
            "auditor_fn_violation": 0.005927077974266999,
            "auditor_fp_violation": 0.023845460247765408,
            "ave_precision_score": 0.8321961398374049,
            "fpr": 0.11745334796926454,
            "logloss": 0.7631566889048446,
            "mae": 0.2567140916208189,
            "precision": 0.7708779443254818,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5131578947368421,
            "auc_prc": 0.48458205496579265,
            "auditor_fn_violation": 0.01472112052024155,
            "auditor_fp_violation": 0.011332145684877278,
            "ave_precision_score": 0.476564712131253,
            "fpr": 0.22478070175438597,
            "logloss": 5.870543636476165,
            "mae": 0.5167869586113084,
            "precision": 0.5514223194748359,
            "recall": 0.5132382892057027
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.47143788852953805,
            "auditor_fn_violation": 0.016861351421194763,
            "auditor_fp_violation": 0.009095185824055208,
            "ave_precision_score": 0.4644693488564131,
            "fpr": 0.2283205268935236,
            "logloss": 5.838753292719807,
            "mae": 0.4820748475227564,
            "precision": 0.5675675675675675,
            "recall": 0.5896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8015686218899304,
            "auditor_fn_violation": 0.019721209847429175,
            "auditor_fp_violation": 0.016525503187898492,
            "ave_precision_score": 0.7885432098391245,
            "fpr": 0.14144736842105263,
            "logloss": 2.2342079411587634,
            "mae": 0.28658214246440084,
            "precision": 0.7388663967611336,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.77861390643028,
            "auditor_fn_violation": 0.014611432622163007,
            "auditor_fp_violation": 0.01785469264544457,
            "ave_precision_score": 0.7658170968300746,
            "fpr": 0.1437980241492865,
            "logloss": 2.109433158558318,
            "mae": 0.2728914040097162,
            "precision": 0.733739837398374,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 14289,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7150993249858484,
            "auditor_fn_violation": 0.01078179154607496,
            "auditor_fp_violation": 0.013975705296495401,
            "ave_precision_score": 0.7111585771918167,
            "fpr": 0.16228070175438597,
            "logloss": 1.587757188380024,
            "mae": 0.32694164248473057,
            "precision": 0.7148362235067437,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.6985228710403026,
            "auditor_fn_violation": 0.0037127216430808485,
            "auditor_fp_violation": 0.015438783910929912,
            "ave_precision_score": 0.6957952728054848,
            "fpr": 0.16794731064763996,
            "logloss": 1.553579463305839,
            "mae": 0.308880289873115,
            "precision": 0.7129455909943715,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.821117278137323,
            "auditor_fn_violation": 0.015404473505556154,
            "auditor_fp_violation": 0.01977851398091428,
            "ave_precision_score": 0.8211700603885922,
            "fpr": 0.15789473684210525,
            "logloss": 0.7427201794281403,
            "mae": 0.2988502278691817,
            "precision": 0.7262357414448669,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8340288386567746,
            "auditor_fn_violation": 0.00529643687780499,
            "auditor_fp_violation": 0.013819193978359743,
            "ave_precision_score": 0.8344208284280163,
            "fpr": 0.14928649835345773,
            "logloss": 0.6072604836240378,
            "mae": 0.27413923093416365,
            "precision": 0.7379576107899807,
            "recall": 0.8272138228941684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.794349874369254,
            "auditor_fn_violation": 0.017709114946225034,
            "auditor_fp_violation": 0.01742405300662583,
            "ave_precision_score": 0.7757467024593803,
            "fpr": 0.13157894736842105,
            "logloss": 2.8330733241321147,
            "mae": 0.29358660606996556,
            "precision": 0.7446808510638298,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7759651096120204,
            "auditor_fn_violation": 0.00839985490513119,
            "auditor_fp_violation": 0.019822212639172027,
            "ave_precision_score": 0.7549454058925149,
            "fpr": 0.12184412733260154,
            "logloss": 2.609961812890581,
            "mae": 0.2686135411046121,
            "precision": 0.7648305084745762,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7752192982456141,
            "auc_prc": 0.8360587591989416,
            "auditor_fn_violation": 0.007003251509629469,
            "auditor_fp_violation": 0.007691065549860401,
            "ave_precision_score": 0.8357666803280455,
            "fpr": 0.10307017543859649,
            "logloss": 0.6108627392047836,
            "mae": 0.2838441724477185,
            "precision": 0.8016877637130801,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8602110743044566,
            "auditor_fn_violation": 0.007472859909955834,
            "auditor_fp_violation": 0.014828681198055516,
            "ave_precision_score": 0.860433352750738,
            "fpr": 0.1251372118551043,
            "logloss": 0.5734679206083281,
            "mae": 0.27485526650077635,
            "precision": 0.7634854771784232,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7996602679471307,
            "auditor_fn_violation": 0.014252152785221715,
            "auditor_fp_violation": 0.01786421219319082,
            "ave_precision_score": 0.7773741575139551,
            "fpr": 0.1337719298245614,
            "logloss": 3.036328991411761,
            "mae": 0.28762369300593116,
            "precision": 0.7484536082474227,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.7736135444929906,
            "auditor_fn_violation": 0.008233896721851718,
            "auditor_fp_violation": 0.019008742355339503,
            "ave_precision_score": 0.7431891078786078,
            "fpr": 0.132821075740944,
            "logloss": 2.993163086239817,
            "mae": 0.2664184110797658,
            "precision": 0.7484407484407485,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6195895465441128,
            "auditor_fn_violation": 0.02070380891128024,
            "auditor_fp_violation": 0.01328030587156728,
            "ave_precision_score": 0.6178248957430783,
            "fpr": 0.20833333333333334,
            "logloss": 2.3704563507417613,
            "mae": 0.37803585139304646,
            "precision": 0.6435272045028143,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.595033428150693,
            "auditor_fn_violation": 0.017266763554634624,
            "auditor_fp_violation": 0.016671240395170144,
            "ave_precision_score": 0.5950717612569225,
            "fpr": 0.21514818880351264,
            "logloss": 2.3264949158667476,
            "mae": 0.3595182220668221,
            "precision": 0.6397058823529411,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6454085471034383,
            "auditor_fn_violation": 0.014095830206881774,
            "auditor_fp_violation": 0.001396007834312636,
            "ave_precision_score": 0.6448319041341765,
            "fpr": 0.22916666666666666,
            "logloss": 1.6646199296018616,
            "mae": 0.38007713649559405,
            "precision": 0.6371527777777778,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.6273829071245958,
            "auditor_fn_violation": 0.011588622855286838,
            "auditor_fp_violation": 0.010829935706445042,
            "ave_precision_score": 0.6275855719144642,
            "fpr": 0.23929747530186607,
            "logloss": 1.7493051623320415,
            "mae": 0.37040447258542136,
            "precision": 0.6273504273504273,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8343975528297777,
            "auditor_fn_violation": 0.011918480008575417,
            "auditor_fp_violation": 0.02521408926115765,
            "ave_precision_score": 0.8347868057288389,
            "fpr": 0.1524122807017544,
            "logloss": 0.7012368298812972,
            "mae": 0.3000470151485131,
            "precision": 0.7316602316602316,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8453042781906248,
            "auditor_fn_violation": 0.005858323869765504,
            "auditor_fp_violation": 0.011251372118551048,
            "ave_precision_score": 0.8455502782832236,
            "fpr": 0.15806805708013172,
            "logloss": 0.592223259587619,
            "mae": 0.27770027738782344,
            "precision": 0.7262357414448669,
            "recall": 0.8250539956803455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8303028313256194,
            "auditor_fn_violation": 0.02067254439561226,
            "auditor_fp_violation": 0.02340396716256199,
            "ave_precision_score": 0.8306353748759426,
            "fpr": 0.12938596491228072,
            "logloss": 0.9386996102833883,
            "mae": 0.27974548900240276,
            "precision": 0.7556935817805382,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8193419644463092,
            "auditor_fn_violation": 0.008267088358507606,
            "auditor_fp_violation": 0.017778736082797557,
            "ave_precision_score": 0.8198875921900255,
            "fpr": 0.12952799121844127,
            "logloss": 0.8448420797802734,
            "mae": 0.2620066177189851,
            "precision": 0.7546777546777547,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8029922987049534,
            "auditor_fn_violation": 0.013521903026405118,
            "auditor_fp_violation": 0.01961703546276618,
            "ave_precision_score": 0.7738080706493639,
            "fpr": 0.1524122807017544,
            "logloss": 3.7543630404019934,
            "mae": 0.2842765954497477,
            "precision": 0.7306201550387597,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7789054587973187,
            "auditor_fn_violation": 0.0028971557138217133,
            "auditor_fp_violation": 0.0263863297788929,
            "ave_precision_score": 0.7385701438932787,
            "fpr": 0.150384193194292,
            "logloss": 3.625036337615791,
            "mae": 0.2632259980205612,
            "precision": 0.730844793713163,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8352579066202475,
            "auditor_fn_violation": 0.014395076285418237,
            "auditor_fp_violation": 0.01277503437929741,
            "ave_precision_score": 0.8310203115311185,
            "fpr": 0.12171052631578948,
            "logloss": 0.9312919494492646,
            "mae": 0.26499055242549446,
            "precision": 0.778,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8256270084022399,
            "auditor_fn_violation": 0.005995832078768499,
            "auditor_fp_violation": 0.01955268935236005,
            "ave_precision_score": 0.820991988713993,
            "fpr": 0.1350164654226125,
            "logloss": 0.9446123222583562,
            "mae": 0.2496803655221281,
            "precision": 0.757396449704142,
            "recall": 0.8293736501079914
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8149838867889031,
            "auditor_fn_violation": 0.02634258762997106,
            "auditor_fp_violation": 0.013215193565862404,
            "ave_precision_score": 0.8155167468012894,
            "fpr": 0.10197368421052631,
            "logloss": 0.9285963856939343,
            "mae": 0.28891848056144304,
            "precision": 0.7801418439716312,
            "recall": 0.6720977596741344
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.798899703556242,
            "auditor_fn_violation": 0.013345408766859577,
            "auditor_fp_violation": 0.018996491296848054,
            "ave_precision_score": 0.7992691802546941,
            "fpr": 0.11745334796926454,
            "logloss": 0.8690688633065254,
            "mae": 0.2803295323486527,
            "precision": 0.7584650112866818,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8480862781311249,
            "auditor_fn_violation": 0.01514319148175939,
            "auditor_fp_violation": 0.01712714089261158,
            "ave_precision_score": 0.8485367211547604,
            "fpr": 0.11951754385964912,
            "logloss": 0.6621064814749875,
            "mae": 0.27401770281966575,
            "precision": 0.7738589211618258,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7771679473106476,
            "auc_prc": 0.8443870640090911,
            "auditor_fn_violation": 0.004070717152726575,
            "auditor_fp_violation": 0.02047886937431395,
            "ave_precision_score": 0.8456651403204849,
            "fpr": 0.1251372118551043,
            "logloss": 0.6064822631205836,
            "mae": 0.2577232335009452,
            "precision": 0.7663934426229508,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7951079744621156,
            "auditor_fn_violation": 0.014616161074784728,
            "auditor_fp_violation": 0.014652873275826147,
            "ave_precision_score": 0.7735955128981465,
            "fpr": 0.12280701754385964,
            "logloss": 3.181087003423735,
            "mae": 0.30027740694924976,
            "precision": 0.7511111111111111,
            "recall": 0.6883910386965377
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7689893837904058,
            "auditor_fn_violation": 0.010332082324742234,
            "auditor_fp_violation": 0.0210448682766191,
            "ave_precision_score": 0.7386446019583917,
            "fpr": 0.11525795828759605,
            "logloss": 3.1265664537198155,
            "mae": 0.2789850257849967,
            "precision": 0.7597254004576659,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.5920684832289327,
            "auditor_fn_violation": 0.02658377103655269,
            "auditor_fp_violation": 0.017791286410801355,
            "ave_precision_score": 0.5902832865782838,
            "fpr": 0.19517543859649122,
            "logloss": 2.838763084888191,
            "mae": 0.3989502166958846,
            "precision": 0.6359918200408998,
            "recall": 0.6334012219959266
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.5672361945878487,
            "auditor_fn_violation": 0.02886724056586998,
            "auditor_fp_violation": 0.019209659714599345,
            "ave_precision_score": 0.5672473549355743,
            "fpr": 0.18441273326015367,
            "logloss": 2.8414639614759354,
            "mae": 0.3787610268786494,
            "precision": 0.65,
            "recall": 0.673866090712743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8213655104976421,
            "auditor_fn_violation": 0.019084753635616538,
            "auditor_fp_violation": 0.01797099637454682,
            "ave_precision_score": 0.8214221388559975,
            "fpr": 0.14364035087719298,
            "logloss": 1.0693131146403887,
            "mae": 0.27776192068066785,
            "precision": 0.7395626242544732,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8310261804293144,
            "auditor_fn_violation": 0.013606200197727325,
            "auditor_fp_violation": 0.029948937588207627,
            "ave_precision_score": 0.8313035699498215,
            "fpr": 0.1350164654226125,
            "logloss": 0.904217457240048,
            "mae": 0.256843077276097,
            "precision": 0.75,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5076754385964912,
            "auc_prc": 0.4795503190091043,
            "auditor_fn_violation": 0.01969441169114232,
            "auditor_fp_violation": 0.011230570487977674,
            "ave_precision_score": 0.4714789792864051,
            "fpr": 0.23793859649122806,
            "logloss": 6.082244389616571,
            "mae": 0.5214371370835946,
            "precision": 0.5441176470588235,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.46645311029162717,
            "auditor_fn_violation": 0.01890974956910143,
            "auditor_fp_violation": 0.009036380743296223,
            "ave_precision_score": 0.45855436213100015,
            "fpr": 0.23710208562019758,
            "logloss": 6.059612429078821,
            "mae": 0.48889248605163804,
            "precision": 0.5618661257606491,
            "recall": 0.5982721382289417
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8408490510354237,
            "auditor_fn_violation": 0.00841908743345125,
            "auditor_fp_violation": 0.026677813893403346,
            "ave_precision_score": 0.8406839868253597,
            "fpr": 0.17543859649122806,
            "logloss": 0.6008500965640045,
            "mae": 0.3021964201434497,
            "precision": 0.7227036395147314,
            "recall": 0.8492871690427699
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8585319285678533,
            "auditor_fn_violation": 0.00580853641478166,
            "auditor_fp_violation": 0.021576564215148197,
            "ave_precision_score": 0.8587761988044497,
            "fpr": 0.18111964873765093,
            "logloss": 0.5895908320417275,
            "mae": 0.2961504261815022,
            "precision": 0.7125435540069687,
            "recall": 0.8833693304535637
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.726652780159437,
            "auditor_fn_violation": 0.018466162861328475,
            "auditor_fp_violation": 0.024940617577197156,
            "ave_precision_score": 0.7193016247303491,
            "fpr": 0.15679824561403508,
            "logloss": 1.824546567995122,
            "mae": 0.3110037877762624,
            "precision": 0.709349593495935,
            "recall": 0.7107942973523421
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7057830848417419,
            "auditor_fn_violation": 0.012349659667182723,
            "auditor_fp_violation": 0.017033871726517172,
            "ave_precision_score": 0.6958574254272686,
            "fpr": 0.1602634467618002,
            "logloss": 1.8439645595725795,
            "mae": 0.3103310185728848,
            "precision": 0.6964656964656964,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7924997990260696,
            "auditor_fn_violation": 0.007286865330331946,
            "auditor_fp_violation": 0.017603762970371306,
            "ave_precision_score": 0.7937734068585192,
            "fpr": 0.18201754385964913,
            "logloss": 0.9232600554903678,
            "mae": 0.3049284763319811,
            "precision": 0.6992753623188406,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7644934354068359,
            "auditor_fn_violation": 0.014597207635024766,
            "auditor_fp_violation": 0.010197781088286034,
            "ave_precision_score": 0.7660205852512011,
            "fpr": 0.19099890230515917,
            "logloss": 0.9111177347861352,
            "mae": 0.29676109667670963,
            "precision": 0.6847826086956522,
            "recall": 0.816414686825054
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8228435597891604,
            "auditor_fn_violation": 0.016815843069996783,
            "auditor_fp_violation": 0.026477267991832313,
            "ave_precision_score": 0.8231386987392223,
            "fpr": 0.1513157894736842,
            "logloss": 0.6529727651501839,
            "mae": 0.30982027163414033,
            "precision": 0.727810650887574,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8137993774296683,
            "auditor_fn_violation": 0.004675279106101808,
            "auditor_fp_violation": 0.007752469813391874,
            "ave_precision_score": 0.8151674193872688,
            "fpr": 0.145993413830955,
            "logloss": 0.5899233463056495,
            "mae": 0.28503368091346537,
            "precision": 0.7361111111111112,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7956756068670622,
            "auditor_fn_violation": 0.004966591631829069,
            "auditor_fp_violation": 0.006724798933199991,
            "ave_precision_score": 0.7947863177311427,
            "fpr": 0.1337719298245614,
            "logloss": 0.8760220330304196,
            "mae": 0.29929101523085216,
            "precision": 0.7555110220440882,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8022645135577451,
            "auditor_fn_violation": 0.009860286917990579,
            "auditor_fp_violation": 0.004684804767131891,
            "ave_precision_score": 0.8017368380453598,
            "fpr": 0.16465422612513722,
            "logloss": 0.8039433058172091,
            "mae": 0.29280386937731984,
            "precision": 0.7137404580152672,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8363839448013315,
            "auditor_fn_violation": 0.03783229713795691,
            "auditor_fp_violation": 0.01920552569071134,
            "ave_precision_score": 0.8369455163296369,
            "fpr": 0.09758771929824561,
            "logloss": 0.5717134416477888,
            "mae": 0.33509572217461253,
            "precision": 0.7958715596330275,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8386208127856083,
            "auditor_fn_violation": 0.03111241770252233,
            "auditor_fp_violation": 0.024533969734985103,
            "ave_precision_score": 0.8388851497332388,
            "fpr": 0.12184412733260154,
            "logloss": 0.509233436717482,
            "mae": 0.3199267075720379,
            "precision": 0.758695652173913,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5267575639388711,
            "auditor_fn_violation": 0.010116303998284927,
            "auditor_fp_violation": 0.015048756094511815,
            "ave_precision_score": 0.5240099434010254,
            "fpr": 0.17763157894736842,
            "logloss": 3.9268065557748,
            "mae": 0.4653841502205999,
            "precision": 0.6152019002375297,
            "recall": 0.5274949083503055
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.5212819238597113,
            "auditor_fn_violation": 0.011633668647891263,
            "auditor_fp_violation": 0.008546338403638077,
            "ave_precision_score": 0.5174356380675391,
            "fpr": 0.1756311745334797,
            "logloss": 3.6849014972744283,
            "mae": 0.42924080114810537,
            "precision": 0.62877030162413,
            "recall": 0.5853131749460043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 14289,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.80602087779416,
            "auditor_fn_violation": 0.006038517883302964,
            "auditor_fp_violation": 0.02040098762345293,
            "ave_precision_score": 0.7971039641580413,
            "fpr": 0.14473684210526316,
            "logloss": 1.5444979191881378,
            "mae": 0.2865793301319217,
            "precision": 0.7523452157598499,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8032832552142832,
            "auditor_fn_violation": 0.002264143786169997,
            "auditor_fp_violation": 0.005606084365689205,
            "ave_precision_score": 0.7941527203588685,
            "fpr": 0.14928649835345773,
            "logloss": 1.3498190765232356,
            "mae": 0.27203474711245873,
            "precision": 0.7448405253283302,
            "recall": 0.857451403887689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 14289,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5217121427252648,
            "auditor_fn_violation": 0.028135830921499266,
            "auditor_fp_violation": 0.012696899612451563,
            "ave_precision_score": 0.5189287525391352,
            "fpr": 0.20833333333333334,
            "logloss": 4.0828929400584375,
            "mae": 0.4681711832542708,
            "precision": 0.592274678111588,
            "recall": 0.5621181262729125
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.5130501212140544,
            "auditor_fn_violation": 0.017328405165567,
            "auditor_fp_violation": 0.011312627411008315,
            "ave_precision_score": 0.5099958922940887,
            "fpr": 0.1964873765093304,
            "logloss": 4.022884802282103,
            "mae": 0.4296191000786641,
            "precision": 0.6191489361702127,
            "recall": 0.6285097192224622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8564961397959382,
            "auditor_fn_violation": 0.012150730696394755,
            "auditor_fp_violation": 0.01693180397549694,
            "ave_precision_score": 0.8568876521529752,
            "fpr": 0.11951754385964912,
            "logloss": 0.6058181646701736,
            "mae": 0.27247272855508226,
            "precision": 0.7757201646090535,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8617790884314641,
            "auditor_fn_violation": 0.0027880974790951947,
            "auditor_fp_violation": 0.017457758350321474,
            "ave_precision_score": 0.862008934126733,
            "fpr": 0.11964873765093303,
            "logloss": 0.5442150461699343,
            "mae": 0.25726799146534385,
            "precision": 0.7738589211618258,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8034236220515248,
            "auditor_fn_violation": 0.01608559331118019,
            "auditor_fp_violation": 0.01686929616202025,
            "ave_precision_score": 0.7742294379390285,
            "fpr": 0.14473684210526316,
            "logloss": 3.7178260893165156,
            "mae": 0.2840015070181453,
            "precision": 0.7370517928286853,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.7789840297714861,
            "auditor_fn_violation": 0.013086988167181535,
            "auditor_fp_violation": 0.02342402383565941,
            "ave_precision_score": 0.7394315141166583,
            "fpr": 0.12733260153677278,
            "logloss": 3.5694078375063905,
            "mae": 0.26045112453583386,
            "precision": 0.7588357588357588,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.837438753185825,
            "auditor_fn_violation": 0.007626308643298678,
            "auditor_fp_violation": 0.009477747218402301,
            "ave_precision_score": 0.8372512487482423,
            "fpr": 0.10964912280701754,
            "logloss": 0.6052782246387888,
            "mae": 0.28625638888943966,
            "precision": 0.7933884297520661,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.857946911741589,
            "auditor_fn_violation": 0.006344344263655397,
            "auditor_fp_violation": 0.014039713031205901,
            "ave_precision_score": 0.8581819579267771,
            "fpr": 0.12952799121844127,
            "logloss": 0.5741114669334724,
            "mae": 0.2779318124228423,
            "precision": 0.7616161616161616,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7898979212079389,
            "auditor_fn_violation": 0.022626576624861547,
            "auditor_fp_violation": 0.02643559611618119,
            "ave_precision_score": 0.7694943942056992,
            "fpr": 0.1600877192982456,
            "logloss": 2.5139045770096353,
            "mae": 0.28499006715815406,
            "precision": 0.7208413001912046,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7745985563017843,
            "auditor_fn_violation": 0.015050036392258765,
            "auditor_fp_violation": 0.03806648894464482,
            "ave_precision_score": 0.7561045664617276,
            "fpr": 0.16245883644346873,
            "logloss": 2.296001742092454,
            "mae": 0.26977063259579676,
            "precision": 0.7191650853889943,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8090343925746327,
            "auditor_fn_violation": 0.005830832172079897,
            "auditor_fp_violation": 0.006357565529024461,
            "ave_precision_score": 0.8082174631709544,
            "fpr": 0.049342105263157895,
            "logloss": 0.8410750849156416,
            "mae": 0.35607183125675373,
            "precision": 0.8615384615384616,
            "recall": 0.570264765784114
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8449333341581383,
            "auditor_fn_violation": 0.005298807708994699,
            "auditor_fp_violation": 0.010489356280382625,
            "ave_precision_score": 0.8451583288001473,
            "fpr": 0.05159165751920966,
            "logloss": 0.6979591509710549,
            "mae": 0.3325186892450715,
            "precision": 0.8558282208588958,
            "recall": 0.6025917926565875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 14289,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8023191076271117,
            "auditor_fn_violation": 0.010924715046271483,
            "auditor_fp_violation": 0.009196462057757222,
            "ave_precision_score": 0.7800942448370637,
            "fpr": 0.12390350877192982,
            "logloss": 3.0226630681114184,
            "mae": 0.2813851039073691,
            "precision": 0.760593220338983,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7776471893396105,
            "auditor_fn_violation": 0.002885301557873175,
            "auditor_fp_violation": 0.014598361298416183,
            "ave_precision_score": 0.7485147927910062,
            "fpr": 0.1207464324917673,
            "logloss": 2.9755041909690783,
            "mae": 0.2643035051302559,
            "precision": 0.7639484978540773,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8229782397791245,
            "auditor_fn_violation": 0.020333101082645518,
            "auditor_fp_violation": 0.01836948368546069,
            "ave_precision_score": 0.8239779577281349,
            "fpr": 0.1337719298245614,
            "logloss": 0.8259121215426266,
            "mae": 0.27715031596757483,
            "precision": 0.7550200803212851,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7595771381778956,
            "auditor_fn_violation": 0.020612006363310918,
            "auditor_fp_violation": 0.010094872196957821,
            "ave_precision_score": 0.7597985902696741,
            "fpr": 0.141602634467618,
            "logloss": 1.1632208835928572,
            "mae": 0.27294704351276217,
            "precision": 0.742,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 14289,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8018951278840565,
            "auditor_fn_violation": 0.017550559188194516,
            "auditor_fp_violation": 0.01607492603242072,
            "ave_precision_score": 0.7880959521381488,
            "fpr": 0.12390350877192982,
            "logloss": 2.308105150670356,
            "mae": 0.284379996832796,
            "precision": 0.760593220338983,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.7890557979747516,
            "auditor_fn_violation": 0.00447612928616644,
            "auditor_fp_violation": 0.01848929747530187,
            "ave_precision_score": 0.7761778309633939,
            "fpr": 0.1207464324917673,
            "logloss": 2.0688899591998595,
            "mae": 0.26153936750631035,
            "precision": 0.7639484978540773,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8510737157687128,
            "auditor_fn_violation": 0.014035534355236367,
            "auditor_fp_violation": 0.014553902571154733,
            "ave_precision_score": 0.8514578207634373,
            "fpr": 0.15021929824561403,
            "logloss": 0.5513219367337386,
            "mae": 0.3309760036211523,
            "precision": 0.7439252336448599,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8436297030990607,
            "auditor_fn_violation": 0.012020114131813472,
            "auditor_fp_violation": 0.017200486122000945,
            "ave_precision_score": 0.8438783564064938,
            "fpr": 0.17892425905598244,
            "logloss": 0.5084555450371018,
            "mae": 0.3236361191020441,
            "precision": 0.7115044247787611,
            "recall": 0.8682505399568035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8018744285620012,
            "auditor_fn_violation": 0.01907805409654483,
            "auditor_fp_violation": 0.017220902612826605,
            "ave_precision_score": 0.7880667818667426,
            "fpr": 0.14035087719298245,
            "logloss": 2.3108040561671546,
            "mae": 0.2830342369703815,
            "precision": 0.7419354838709677,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7881385425950831,
            "auditor_fn_violation": 0.0051850078118887725,
            "auditor_fp_violation": 0.017401403481260794,
            "ave_precision_score": 0.7752570185069043,
            "fpr": 0.12623490669593854,
            "logloss": 2.076328091702679,
            "mae": 0.26036379250310693,
            "precision": 0.7578947368421053,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8017757527047926,
            "auditor_fn_violation": 0.016789044913709937,
            "auditor_fp_violation": 0.017556882110263784,
            "ave_precision_score": 0.7879808756848882,
            "fpr": 0.13048245614035087,
            "logloss": 2.2995709029882265,
            "mae": 0.28416913432167484,
            "precision": 0.7520833333333333,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.7886589960282712,
            "auditor_fn_violation": 0.005882032181662573,
            "auditor_fp_violation": 0.01925866394856516,
            "ave_precision_score": 0.7757842464667727,
            "fpr": 0.12184412733260154,
            "logloss": 2.066008114097501,
            "mae": 0.2615127001200461,
            "precision": 0.7638297872340426,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7104374007835079,
            "auditor_fn_violation": 0.016342408975595815,
            "auditor_fp_violation": 0.03351981497687212,
            "ave_precision_score": 0.702914285901977,
            "fpr": 0.17324561403508773,
            "logloss": 1.6397216726067954,
            "mae": 0.31783177607810914,
            "precision": 0.7030075187969925,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6678720840620439,
            "auditor_fn_violation": 0.004196371205781034,
            "auditor_fp_violation": 0.03730202289477811,
            "ave_precision_score": 0.6549649873465646,
            "fpr": 0.1877058177826564,
            "logloss": 1.8488671253367843,
            "mae": 0.31725971126062924,
            "precision": 0.6856617647058824,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8054973100390914,
            "auditor_fn_violation": 0.011844785078786583,
            "auditor_fp_violation": 0.010641955244405551,
            "ave_precision_score": 0.8044390173454068,
            "fpr": 0.13048245614035087,
            "logloss": 1.2439184100096856,
            "mae": 0.2827021405791931,
            "precision": 0.750524109014675,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8178564700919362,
            "auditor_fn_violation": 0.008793412882622526,
            "auditor_fp_violation": 0.01736465030578642,
            "ave_precision_score": 0.8181555149793884,
            "fpr": 0.12184412733260154,
            "logloss": 1.0186512927681934,
            "mae": 0.26224987000068456,
            "precision": 0.7638297872340426,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.828283745233392,
            "auditor_fn_violation": 0.0094642155286383,
            "auditor_fp_violation": 0.02959484518898196,
            "ave_precision_score": 0.8279503150292727,
            "fpr": 0.22039473684210525,
            "logloss": 0.8398896431206868,
            "mae": 0.32768504915659497,
            "precision": 0.6758064516129032,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8487198290116422,
            "auditor_fn_violation": 0.00466816661253269,
            "auditor_fp_violation": 0.004846518739219072,
            "ave_precision_score": 0.8489797953536635,
            "fpr": 0.2349066959385291,
            "logloss": 0.7577415133368725,
            "mae": 0.3263919029088838,
            "precision": 0.6597774244833068,
            "recall": 0.896328293736501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7990734844295774,
            "auditor_fn_violation": 0.02088246328652589,
            "auditor_fp_violation": 0.01950764678918199,
            "ave_precision_score": 0.7776438940421414,
            "fpr": 0.13596491228070176,
            "logloss": 2.965498700809131,
            "mae": 0.28929396277099906,
            "precision": 0.7459016393442623,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.7727311410288176,
            "auditor_fn_violation": 0.005158928668801999,
            "auditor_fp_violation": 0.020758193507919083,
            "ave_precision_score": 0.7431284363343074,
            "fpr": 0.13172338090010977,
            "logloss": 2.929099262121147,
            "mae": 0.26672401287548425,
            "precision": 0.7510373443983402,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8058605375877392,
            "auditor_fn_violation": 0.013586665237431666,
            "auditor_fp_violation": 0.014887277576363715,
            "ave_precision_score": 0.7776542197447893,
            "fpr": 0.1600877192982456,
            "logloss": 3.5250427347052993,
            "mae": 0.2799797354185582,
            "precision": 0.7276119402985075,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7803426549777003,
            "auditor_fn_violation": 0.002299706254015599,
            "auditor_fp_violation": 0.022304277089540546,
            "ave_precision_score": 0.7429963732221142,
            "fpr": 0.16575192096597147,
            "logloss": 3.398521928322161,
            "mae": 0.26534954634132024,
            "precision": 0.7182835820895522,
            "recall": 0.8315334773218143
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5109649122807017,
            "auc_prc": 0.4887191533128573,
            "auditor_fn_violation": 0.015482634794726127,
            "auditor_fp_violation": 0.016379651623119554,
            "ave_precision_score": 0.48076294798628816,
            "fpr": 0.2225877192982456,
            "logloss": 5.667380730206601,
            "mae": 0.5115213575365769,
            "precision": 0.549889135254989,
            "recall": 0.505091649694501
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.4772333719854307,
            "auditor_fn_violation": 0.014371978672002619,
            "auditor_fp_violation": 0.012812156970362245,
            "ave_precision_score": 0.4693834939362634,
            "fpr": 0.22722283205268934,
            "logloss": 5.663580982865639,
            "mae": 0.47541682177760314,
            "precision": 0.5696465696465697,
            "recall": 0.591792656587473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7023477417790771,
            "auditor_fn_violation": 0.011943044985171685,
            "auditor_fp_violation": 0.016132224861441023,
            "ave_precision_score": 0.6977720132961797,
            "fpr": 0.2050438596491228,
            "logloss": 1.6497074642577356,
            "mae": 0.32690650611780636,
            "precision": 0.6770293609671848,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6861036962832417,
            "auditor_fn_violation": 0.01139658552892059,
            "auditor_fp_violation": 0.01228291124353144,
            "ave_precision_score": 0.6825466478567903,
            "fpr": 0.20087815587266739,
            "logloss": 1.6604029186076958,
            "mae": 0.3068108716634893,
            "precision": 0.6783831282952548,
            "recall": 0.8336933045356372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7970151252088478,
            "auditor_fn_violation": 0.007903222924929437,
            "auditor_fp_violation": 0.022703358753177475,
            "ave_precision_score": 0.798622380948727,
            "fpr": 0.18969298245614036,
            "logloss": 0.7180019231408205,
            "mae": 0.30988283176881387,
            "precision": 0.6970227670753065,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8052317183470583,
            "auditor_fn_violation": 0.002968280649512917,
            "auditor_fp_violation": 0.016994668339344522,
            "ave_precision_score": 0.8061825332560173,
            "fpr": 0.19758507135016465,
            "logloss": 0.6884021919959934,
            "mae": 0.2995716467122182,
            "precision": 0.686411149825784,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.6328551694019754,
            "auditor_fn_violation": 0.02320273698502876,
            "auditor_fp_violation": 0.04490925949076968,
            "ave_precision_score": 0.5993081130423896,
            "fpr": 0.19846491228070176,
            "logloss": 3.475986303004704,
            "mae": 0.36356181040733004,
            "precision": 0.6884681583476764,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.5894185897711621,
            "auditor_fn_violation": 0.011659747790978043,
            "auditor_fp_violation": 0.04822016622236162,
            "ave_precision_score": 0.5532614186711539,
            "fpr": 0.2327113062568606,
            "logloss": 4.071270038583017,
            "mae": 0.3682263299305186,
            "precision": 0.6535947712418301,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8009624203306849,
            "auditor_fn_violation": 0.013441508557544576,
            "auditor_fp_violation": 0.019851439763303752,
            "ave_precision_score": 0.7794200598696654,
            "fpr": 0.1337719298245614,
            "logloss": 3.0007689785594565,
            "mae": 0.28783997930968885,
            "precision": 0.7479338842975206,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7741069400345214,
            "auditor_fn_violation": 0.0050712079147828435,
            "auditor_fp_violation": 0.018405990277559982,
            "ave_precision_score": 0.7436873563569762,
            "fpr": 0.13172338090010977,
            "logloss": 2.9768461533207957,
            "mae": 0.2664025064579028,
            "precision": 0.7515527950310559,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7047653307006122,
            "auditor_fn_violation": 0.008608907707149753,
            "auditor_fp_violation": 0.006618014751843981,
            "ave_precision_score": 0.7009409821357657,
            "fpr": 0.08662280701754387,
            "logloss": 1.5694345153085154,
            "mae": 0.3643262065909509,
            "precision": 0.7859078590785907,
            "recall": 0.5906313645621182
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6907063276828385,
            "auditor_fn_violation": 0.005097287057869618,
            "auditor_fp_violation": 0.01116561470911087,
            "ave_precision_score": 0.6871753123406246,
            "fpr": 0.09989023051591657,
            "logloss": 1.570966730330068,
            "mae": 0.347660599748591,
            "precision": 0.7579787234042553,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8039824977959883,
            "auditor_fn_violation": 0.019839568371029407,
            "auditor_fp_violation": 0.016879714130933032,
            "ave_precision_score": 0.804376857946001,
            "fpr": 0.15460526315789475,
            "logloss": 0.664944921700103,
            "mae": 0.3197726947206607,
            "precision": 0.7272727272727273,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.800005884790884,
            "auditor_fn_violation": 0.017224088593219895,
            "auditor_fp_violation": 0.016220401442684655,
            "ave_precision_score": 0.8004134226778327,
            "fpr": 0.14270032930845225,
            "logloss": 0.5987207931166959,
            "mae": 0.2992695379100329,
            "precision": 0.738430583501006,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8048370824110436,
            "auditor_fn_violation": 0.013731821917318759,
            "auditor_fp_violation": 0.019533691711463932,
            "ave_precision_score": 0.7767905299957587,
            "fpr": 0.17763157894736842,
            "logloss": 3.4760796610300577,
            "mae": 0.2849032535736201,
            "precision": 0.7112299465240641,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7836864376738301,
            "auditor_fn_violation": 0.0074041058054543345,
            "auditor_fp_violation": 0.02758203308765878,
            "ave_precision_score": 0.7469810929733297,
            "fpr": 0.18111964873765093,
            "logloss": 3.3442596090350625,
            "mae": 0.2653036948035104,
            "precision": 0.7079646017699115,
            "recall": 0.8639308855291576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7944255528977987,
            "auditor_fn_violation": 0.017709114946225034,
            "auditor_fp_violation": 0.01959619952494062,
            "ave_precision_score": 0.7765052838038242,
            "fpr": 0.13157894736842105,
            "logloss": 2.7966610670277006,
            "mae": 0.29414810217512033,
            "precision": 0.7446808510638298,
            "recall": 0.7128309572301426
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7723278628088035,
            "auditor_fn_violation": 0.009601866318312542,
            "auditor_fp_violation": 0.019160655480633535,
            "ave_precision_score": 0.7514595615218742,
            "fpr": 0.12403951701427003,
            "logloss": 2.6337702814941464,
            "mae": 0.2728486045314644,
            "precision": 0.7600849256900213,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.5913776195050667,
            "auditor_fn_violation": 0.02919435809482975,
            "auditor_fp_violation": 0.022286639996666257,
            "ave_precision_score": 0.5914592406682518,
            "fpr": 0.16228070175438597,
            "logloss": 3.3658061614394965,
            "mae": 0.41975933643659263,
            "precision": 0.6484560570071259,
            "recall": 0.5560081466395111
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.587790274618879,
            "auditor_fn_violation": 0.03451218962856188,
            "auditor_fp_violation": 0.021336443468715695,
            "ave_precision_score": 0.5878870771022036,
            "fpr": 0.15367727771679474,
            "logloss": 2.976062411032599,
            "mae": 0.3845732040967006,
            "precision": 0.665871121718377,
            "recall": 0.6025917926565875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6030701754385965,
            "auc_prc": 0.5645231951414118,
            "auditor_fn_violation": 0.01604762925644049,
            "auditor_fp_violation": 0.010602887860982632,
            "ave_precision_score": 0.5637037187408299,
            "fpr": 0.15679824561403508,
            "logloss": 2.757849078433719,
            "mae": 0.43302795508526737,
            "precision": 0.655421686746988,
            "recall": 0.5539714867617108
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.5653068700351234,
            "auditor_fn_violation": 0.012503763694513661,
            "auditor_fp_violation": 0.013721185510428106,
            "ave_precision_score": 0.5635173663484019,
            "fpr": 0.15916575192096596,
            "logloss": 2.5117566439868972,
            "mae": 0.39735575424687075,
            "precision": 0.6547619047619048,
            "recall": 0.593952483801296
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7747002860967702,
            "auditor_fn_violation": 0.009917551005824133,
            "auditor_fp_violation": 0.01772617410509647,
            "ave_precision_score": 0.7749852467026839,
            "fpr": 0.1699561403508772,
            "logloss": 0.822167099602485,
            "mae": 0.3063078014513264,
            "precision": 0.716636197440585,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7918382978018771,
            "auditor_fn_violation": 0.0030465180787732416,
            "auditor_fp_violation": 0.015169260624117931,
            "ave_precision_score": 0.7924302127955025,
            "fpr": 0.15477497255762898,
            "logloss": 0.6955012824243523,
            "mae": 0.28319205339688064,
            "precision": 0.7298850574712644,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8200504866625428,
            "auditor_fn_violation": 0.013483938971665428,
            "auditor_fp_violation": 0.01875755302746178,
            "ave_precision_score": 0.8201141689172851,
            "fpr": 0.12719298245614036,
            "logloss": 0.7356986073251031,
            "mae": 0.302005761217265,
            "precision": 0.7578288100208769,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8354002236847737,
            "auditor_fn_violation": 0.008383259086803247,
            "auditor_fp_violation": 0.011545397522345933,
            "ave_precision_score": 0.8357997919877429,
            "fpr": 0.12184412733260154,
            "logloss": 0.587259992225862,
            "mae": 0.27579834995483155,
            "precision": 0.7663157894736842,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8340607769523373,
            "auditor_fn_violation": 0.012077035766605924,
            "auditor_fp_violation": 0.019132599908321883,
            "ave_precision_score": 0.834434695656994,
            "fpr": 0.17324561403508773,
            "logloss": 0.8894105399924253,
            "mae": 0.283197309273538,
            "precision": 0.7148014440433214,
            "recall": 0.8065173116089613
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.828053805264097,
            "auditor_fn_violation": 0.0037174633054602615,
            "auditor_fp_violation": 0.022573800376352513,
            "ave_precision_score": 0.828322706670843,
            "fpr": 0.18331503841931943,
            "logloss": 0.81387172687589,
            "mae": 0.26832290426657407,
            "precision": 0.7023172905525846,
            "recall": 0.8509719222462203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.822180248034339,
            "auditor_fn_violation": 0.013274020080751785,
            "auditor_fp_violation": 0.02301850231278911,
            "ave_precision_score": 0.8224824604821686,
            "fpr": 0.18421052631578946,
            "logloss": 0.6862197257021869,
            "mae": 0.3167603337093616,
            "precision": 0.701067615658363,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8162250287214978,
            "auditor_fn_violation": 0.005500328360119776,
            "auditor_fp_violation": 0.01952818723537714,
            "ave_precision_score": 0.8175430079969601,
            "fpr": 0.1877058177826564,
            "logloss": 0.6390097684596938,
            "mae": 0.30034235452868413,
            "precision": 0.6940966010733453,
            "recall": 0.838012958963283
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.801059352469734,
            "auditor_fn_violation": 0.010274859756315435,
            "auditor_fp_violation": 0.02261220152519066,
            "ave_precision_score": 0.8013912469689252,
            "fpr": 0.20723684210526316,
            "logloss": 0.733866824307289,
            "mae": 0.32424363612077095,
            "precision": 0.6774744027303754,
            "recall": 0.8085539714867617
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7763171022139583,
            "auditor_fn_violation": 0.006178386080375921,
            "auditor_fp_violation": 0.014407244785949506,
            "ave_precision_score": 0.7780425892166731,
            "fpr": 0.2074643249176729,
            "logloss": 0.6886788843072756,
            "mae": 0.3084488141047717,
            "precision": 0.6735751295336787,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7751770172985187,
            "auditor_fn_violation": 0.02936854611069425,
            "auditor_fp_violation": 0.017236529566195778,
            "ave_precision_score": 0.7678610792226146,
            "fpr": 0.14035087719298245,
            "logloss": 1.5783048797244326,
            "mae": 0.285371910276686,
            "precision": 0.7429718875502008,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7695122614581773,
            "auditor_fn_violation": 0.01653417671701522,
            "auditor_fp_violation": 0.02833424807903403,
            "ave_precision_score": 0.7625942671035795,
            "fpr": 0.145993413830955,
            "logloss": 1.4271959977917774,
            "mae": 0.27372855512719296,
            "precision": 0.7302231237322515,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8532928898597416,
            "auditor_fn_violation": 0.019817236574123702,
            "auditor_fp_violation": 0.013921010959703299,
            "ave_precision_score": 0.8537052814982709,
            "fpr": 0.1337719298245614,
            "logloss": 0.6381346043448619,
            "mae": 0.27141817732350115,
            "precision": 0.7569721115537849,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8489620432954617,
            "auditor_fn_violation": 0.008290796670404676,
            "auditor_fp_violation": 0.023544084208875653,
            "ave_precision_score": 0.8502332710979656,
            "fpr": 0.132821075740944,
            "logloss": 0.5907213849313269,
            "mae": 0.25558950771502875,
            "precision": 0.7599206349206349,
            "recall": 0.8272138228941684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8394881919923853,
            "auditor_fn_violation": 0.01986859970700683,
            "auditor_fp_violation": 0.017697524690586323,
            "ave_precision_score": 0.8398589288575682,
            "fpr": 0.12828947368421054,
            "logloss": 0.7549177476203296,
            "mae": 0.27547541010443666,
            "precision": 0.7602459016393442,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8378487429397161,
            "auditor_fn_violation": 0.005746894803849286,
            "auditor_fp_violation": 0.01726909204955308,
            "ave_precision_score": 0.8381262955510502,
            "fpr": 0.1251372118551043,
            "logloss": 0.6823308320011342,
            "mae": 0.26053521648653816,
            "precision": 0.7615062761506276,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6678306284284243,
            "auditor_fn_violation": 0.015569728802658379,
            "auditor_fp_violation": 0.005839271575613621,
            "ave_precision_score": 0.668150968916511,
            "fpr": 0.20285087719298245,
            "logloss": 1.4905062264812396,
            "mae": 0.37269399711665535,
            "precision": 0.6502835538752363,
            "recall": 0.7006109979633401
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.6435532708463272,
            "auditor_fn_violation": 0.010277553207378977,
            "auditor_fp_violation": 0.007473145679786736,
            "ave_precision_score": 0.6437902484139097,
            "fpr": 0.21185510428100987,
            "logloss": 1.538406394736478,
            "mae": 0.3580757868459255,
            "precision": 0.6465201465201466,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8418315137025705,
            "auditor_fn_violation": 0.005154178725837001,
            "auditor_fp_violation": 0.007151935658623997,
            "ave_precision_score": 0.8415797566754148,
            "fpr": 0.09649122807017543,
            "logloss": 0.6533914376555381,
            "mae": 0.2731067601066695,
            "precision": 0.8035714285714286,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8626005381616728,
            "auditor_fn_violation": 0.006887264606098254,
            "auditor_fp_violation": 0.007012505880508072,
            "ave_precision_score": 0.8628003805644209,
            "fpr": 0.1163556531284303,
            "logloss": 0.6045609863902563,
            "mae": 0.263306257656766,
            "precision": 0.7725321888412017,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8346833270045255,
            "auditor_fn_violation": 0.017831939829206417,
            "auditor_fp_violation": 0.016491644788931954,
            "ave_precision_score": 0.8350471403797693,
            "fpr": 0.13815789473684212,
            "logloss": 0.9055231304712354,
            "mae": 0.27927050914760204,
            "precision": 0.7454545454545455,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8329516564725636,
            "auditor_fn_violation": 0.009514145564293386,
            "auditor_fp_violation": 0.024360004704406468,
            "ave_precision_score": 0.8332426034884197,
            "fpr": 0.13391877058177826,
            "logloss": 0.7893405911907556,
            "mae": 0.25794815668040544,
            "precision": 0.7540322580645161,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8199275095777074,
            "auditor_fn_violation": 0.020449226426555188,
            "auditor_fp_violation": 0.019294078426469977,
            "ave_precision_score": 0.8196049893125028,
            "fpr": 0.13157894736842105,
            "logloss": 0.9131563380738232,
            "mae": 0.2798327211222571,
            "precision": 0.7540983606557377,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8382143657954342,
            "auditor_fn_violation": 0.009701441228280226,
            "auditor_fp_violation": 0.018386388583973658,
            "ave_precision_score": 0.8385484434966413,
            "fpr": 0.12294182217343579,
            "logloss": 0.7448551417527559,
            "mae": 0.2634164485271373,
            "precision": 0.7632135306553911,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8396531959012702,
            "auditor_fn_violation": 0.01635804123342981,
            "auditor_fp_violation": 0.01989571613118307,
            "ave_precision_score": 0.8400871279318555,
            "fpr": 0.15350877192982457,
            "logloss": 0.8606312071512324,
            "mae": 0.2872966438033425,
            "precision": 0.7244094488188977,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8334185890811288,
            "auditor_fn_violation": 0.016344510221838682,
            "auditor_fp_violation": 0.02147855574721656,
            "ave_precision_score": 0.8336680243557587,
            "fpr": 0.15587266739846323,
            "logloss": 0.8272953228610886,
            "mae": 0.2729236394240322,
            "precision": 0.7215686274509804,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8127425873837995,
            "auditor_fn_violation": 0.008926019223210775,
            "auditor_fp_violation": 0.028857773888402723,
            "ave_precision_score": 0.8124057513747045,
            "fpr": 0.18640350877192982,
            "logloss": 0.623720374780256,
            "mae": 0.3183923435985333,
            "precision": 0.7113752122241087,
            "recall": 0.8533604887983707
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8423598296346151,
            "auditor_fn_violation": 0.007819001263653026,
            "auditor_fp_violation": 0.02057687784224557,
            "ave_precision_score": 0.8426547066991223,
            "fpr": 0.18551042810098792,
            "logloss": 0.5808232573043303,
            "mae": 0.30208033163458925,
            "precision": 0.707105719237435,
            "recall": 0.8812095032397408
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.792471821215637,
            "auditor_fn_violation": 0.015147657841140541,
            "auditor_fp_violation": 0.015324832270700504,
            "ave_precision_score": 0.7772871519714408,
            "fpr": 0.14583333333333334,
            "logloss": 2.5594605771297982,
            "mae": 0.29236277193350324,
            "precision": 0.7318548387096774,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.7761165241048793,
            "auditor_fn_violation": 0.01820798353694822,
            "auditor_fp_violation": 0.028145581778265642,
            "ave_precision_score": 0.7603527641044411,
            "fpr": 0.13721185510428102,
            "logloss": 2.35998983394017,
            "mae": 0.2676944797514164,
            "precision": 0.7433264887063655,
            "recall": 0.7818574514038877
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6743421052631579,
            "auc_prc": 0.7365470661238998,
            "auditor_fn_violation": 0.011460678172008437,
            "auditor_fp_violation": 0.015007084218860696,
            "ave_precision_score": 0.7369275598503477,
            "fpr": 0.19407894736842105,
            "logloss": 1.0787656984225682,
            "mae": 0.3378026753738782,
            "precision": 0.677007299270073,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.707488963520574,
            "auditor_fn_violation": 0.004426341831182596,
            "auditor_fp_violation": 0.007210973028069626,
            "ave_precision_score": 0.708875322412907,
            "fpr": 0.2052689352360044,
            "logloss": 1.1445270146909072,
            "mae": 0.32709088872494857,
            "precision": 0.6624548736462094,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6458846530355871,
            "auditor_fn_violation": 0.011018508593275446,
            "auditor_fp_violation": 0.005331395591115551,
            "ave_precision_score": 0.6452799675670916,
            "fpr": 0.22697368421052633,
            "logloss": 1.6870980318318987,
            "mae": 0.38014953694312215,
            "precision": 0.6387434554973822,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.6297350167819852,
            "auditor_fn_violation": 0.010192203284549534,
            "auditor_fp_violation": 0.010300689979614239,
            "ave_precision_score": 0.6299340306589738,
            "fpr": 0.2414928649835346,
            "logloss": 1.7452326615975697,
            "mae": 0.3697819847362111,
            "precision": 0.6232876712328768,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.837813958296135,
            "auditor_fn_violation": 5.136313288312299e-05,
            "auditor_fp_violation": 0.008050485477351335,
            "ave_precision_score": 0.8375965371789712,
            "fpr": 0.10526315789473684,
            "logloss": 0.6118666300886997,
            "mae": 0.28467392638154065,
            "precision": 0.7987421383647799,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8583726499672217,
            "auditor_fn_violation": 0.006221061041790644,
            "auditor_fp_violation": 0.008124901991532077,
            "ave_precision_score": 0.858600758163784,
            "fpr": 0.12733260153677278,
            "logloss": 0.5768510345781324,
            "mae": 0.27504675619094815,
            "precision": 0.7622950819672131,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.8029337061927724,
            "auditor_fn_violation": 0.03077098295637263,
            "auditor_fp_violation": 0.006730007917656374,
            "ave_precision_score": 0.8034295397277774,
            "fpr": 0.04057017543859649,
            "logloss": 0.79800026549634,
            "mae": 0.38142070138258677,
            "precision": 0.8348214285714286,
            "recall": 0.38085539714867617
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.8266435291173408,
            "auditor_fn_violation": 0.04201824117517361,
            "auditor_fp_violation": 0.00738738827034656,
            "ave_precision_score": 0.8269761719783852,
            "fpr": 0.031833150384193196,
            "logloss": 0.7083792167235631,
            "mae": 0.35346526120220434,
            "precision": 0.861904761904762,
            "recall": 0.39092872570194387
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5426264243519588,
            "auditor_fn_violation": 0.01480821452817381,
            "auditor_fp_violation": 0.016220777597199653,
            "ave_precision_score": 0.5408391383770924,
            "fpr": 0.16228070175438597,
            "logloss": 3.3918944538937437,
            "mae": 0.4532197347427919,
            "precision": 0.6327543424317618,
            "recall": 0.5193482688391039
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.5418967818486656,
            "auditor_fn_violation": 0.00968010374757287,
            "auditor_fp_violation": 0.015032048769013638,
            "ave_precision_score": 0.5383037574978767,
            "fpr": 0.17014270032930845,
            "logloss": 3.0327969514517124,
            "mae": 0.41656172514377127,
            "precision": 0.6309523809523809,
            "recall": 0.572354211663067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8177872205498574,
            "auditor_fn_violation": 0.017333940758209168,
            "auditor_fp_violation": 0.01758292703254574,
            "ave_precision_score": 0.818220096350294,
            "fpr": 0.15460526315789475,
            "logloss": 1.1491393828948926,
            "mae": 0.29311199881770233,
            "precision": 0.724609375,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7966049742781831,
            "auditor_fn_violation": 0.010007278451752403,
            "auditor_fp_violation": 0.018386388583973658,
            "ave_precision_score": 0.7970231957644268,
            "fpr": 0.1602634467618002,
            "logloss": 1.0676764123193632,
            "mae": 0.28080632293692404,
            "precision": 0.7103174603174603,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8411960528757585,
            "auditor_fn_violation": 0.015848876263979707,
            "auditor_fp_violation": 0.019067487602617,
            "ave_precision_score": 0.8415860804300674,
            "fpr": 0.14692982456140352,
            "logloss": 0.7710834174825161,
            "mae": 0.27447964752621645,
            "precision": 0.7413127413127413,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8405158549818528,
            "auditor_fn_violation": 0.002487001918002433,
            "auditor_fp_violation": 0.017768935236004396,
            "ave_precision_score": 0.8407628628321507,
            "fpr": 0.14489571899012074,
            "logloss": 0.6951091194740345,
            "mae": 0.26074742368378195,
            "precision": 0.7406679764243614,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5932017543859649,
            "auc_prc": 0.5713122424550333,
            "auditor_fn_violation": 0.008519580519526932,
            "auditor_fp_violation": 0.017793890903029543,
            "ave_precision_score": 0.5657263147976377,
            "fpr": 0.15899122807017543,
            "logloss": 2.834074142820031,
            "mae": 0.43969176017335637,
            "precision": 0.6463414634146342,
            "recall": 0.539714867617108
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.5587884027911909,
            "auditor_fn_violation": 0.005893886337611102,
            "auditor_fp_violation": 0.016279206523443626,
            "ave_precision_score": 0.5500121477822174,
            "fpr": 0.1712403951701427,
            "logloss": 2.610021617071818,
            "mae": 0.42156757264850847,
            "precision": 0.6276849642004774,
            "recall": 0.5680345572354212
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8561211502119348,
            "auditor_fn_violation": 0.01255270304069748,
            "auditor_fp_violation": 0.0007370713005792409,
            "ave_precision_score": 0.8564052989851875,
            "fpr": 0.03289473684210526,
            "logloss": 0.7966361905692003,
            "mae": 0.32703830534563405,
            "precision": 0.9035369774919614,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8716301196085672,
            "auditor_fn_violation": 0.0010621323729886492,
            "auditor_fp_violation": 0.008139603261721813,
            "ave_precision_score": 0.8718351022072437,
            "fpr": 0.042810098792535674,
            "logloss": 0.6460709899115652,
            "mae": 0.3053010524295037,
            "precision": 0.8785046728971962,
            "recall": 0.6090712742980562
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6447368421052632,
            "auc_prc": 0.6890482706752683,
            "auditor_fn_violation": 0.02422999964269125,
            "auditor_fp_violation": 0.01917166729174481,
            "ave_precision_score": 0.6893381792608366,
            "fpr": 0.21600877192982457,
            "logloss": 1.436602272578492,
            "mae": 0.36544441050825077,
            "precision": 0.6488413547237076,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.6583098598758088,
            "auditor_fn_violation": 0.01835023340833063,
            "auditor_fp_violation": 0.017053473420103497,
            "ave_precision_score": 0.6596643300811486,
            "fpr": 0.21953896816684962,
            "logloss": 1.4575178362782533,
            "mae": 0.348589907308106,
            "precision": 0.6466431095406361,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7996156471090639,
            "auditor_fn_violation": 0.01882793797120092,
            "auditor_fp_violation": 0.019057069633704214,
            "ave_precision_score": 0.7850542519685451,
            "fpr": 0.13267543859649122,
            "logloss": 2.34918659226428,
            "mae": 0.28615394640774455,
            "precision": 0.7484407484407485,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.7863312662822044,
            "auditor_fn_violation": 0.005694736517675736,
            "auditor_fp_violation": 0.02025835032146777,
            "ave_precision_score": 0.7726667203025045,
            "fpr": 0.12403951701427003,
            "logloss": 2.105477147165615,
            "mae": 0.26314963100511213,
            "precision": 0.7626050420168067,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8215618231595138,
            "auditor_fn_violation": 0.00997114731839783,
            "auditor_fp_violation": 0.031040338375630288,
            "ave_precision_score": 0.8220380071943294,
            "fpr": 0.2324561403508772,
            "logloss": 0.8298638207275051,
            "mae": 0.32020737971717744,
            "precision": 0.6718266253869969,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8307165263909856,
            "auditor_fn_violation": 0.001794719210608048,
            "auditor_fp_violation": 0.025386643405990287,
            "ave_precision_score": 0.8309503337403732,
            "fpr": 0.22502744237102085,
            "logloss": 0.7818068993952176,
            "mae": 0.30366446135546504,
            "precision": 0.6735668789808917,
            "recall": 0.9136069114470843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8398336169454975,
            "auditor_fn_violation": 0.004446260763926114,
            "auditor_fp_violation": 0.009373567529274497,
            "ave_precision_score": 0.8395400511795352,
            "fpr": 0.09758771929824561,
            "logloss": 0.5754642231280163,
            "mae": 0.28398187689584264,
            "precision": 0.8065217391304348,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8593604537951327,
            "auditor_fn_violation": 0.010521748819918778,
            "auditor_fp_violation": 0.013463913282107576,
            "ave_precision_score": 0.8595879135528428,
            "fpr": 0.11525795828759605,
            "logloss": 0.5049291949583118,
            "mae": 0.27247212207738136,
            "precision": 0.7746781115879828,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8294036857944627,
            "auditor_fn_violation": 0.009118072676599854,
            "auditor_fp_violation": 0.024930199608284374,
            "ave_precision_score": 0.8300367148016075,
            "fpr": 0.13596491228070176,
            "logloss": 0.5392271484641105,
            "mae": 0.31139288194166864,
            "precision": 0.7606177606177607,
            "recall": 0.8024439918533605
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8514095326607469,
            "auditor_fn_violation": 0.009758341176833189,
            "auditor_fp_violation": 0.026001646542261257,
            "ave_precision_score": 0.851664714856462,
            "fpr": 0.145993413830955,
            "logloss": 0.4948627516206441,
            "mae": 0.30098625323065564,
            "precision": 0.745697896749522,
            "recall": 0.8423326133909287
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7866378713099821,
            "auditor_fn_violation": 0.022233536999321117,
            "auditor_fp_violation": 0.02990217527190899,
            "ave_precision_score": 0.7758381775017459,
            "fpr": 0.1600877192982456,
            "logloss": 1.700977894368508,
            "mae": 0.2843490548992423,
            "precision": 0.7197696737044146,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7737318713813977,
            "auditor_fn_violation": 0.012008259975864938,
            "auditor_fp_violation": 0.03809589148502431,
            "ave_precision_score": 0.7646112630505989,
            "fpr": 0.16245883644346873,
            "logloss": 1.5409986957435182,
            "mae": 0.26857349206396824,
            "precision": 0.7196969696969697,
            "recall": 0.8207343412526998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 14289,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.847205768394705,
            "auditor_fn_violation": 0.018463929681637906,
            "auditor_fp_violation": 0.018856523732133187,
            "ave_precision_score": 0.8475298443758147,
            "fpr": 0.12280701754385964,
            "logloss": 0.679788005594599,
            "mae": 0.2769577463885727,
            "precision": 0.7671517671517671,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8433195523994801,
            "auditor_fn_violation": 0.003999592217035372,
            "auditor_fp_violation": 0.015475537086404261,
            "ave_precision_score": 0.8445900767446277,
            "fpr": 0.132821075740944,
            "logloss": 0.6133304982474665,
            "mae": 0.2605584486678837,
            "precision": 0.7540650406504065,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.7767185925249375,
            "auditor_fn_violation": 0.011194929788830531,
            "auditor_fp_violation": 0.0188487102554486,
            "ave_precision_score": 0.7770393650131742,
            "fpr": 0.19956140350877194,
            "logloss": 1.1524018399378375,
            "mae": 0.3217462260217203,
            "precision": 0.6767317939609236,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.7571394082637352,
            "auditor_fn_violation": 0.006448660836002497,
            "auditor_fp_violation": 0.01605623725889917,
            "ave_precision_score": 0.7576448730377446,
            "fpr": 0.20087815587266739,
            "logloss": 1.1237233429956486,
            "mae": 0.3174006382672187,
            "precision": 0.6648351648351648,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7972798939609048,
            "auditor_fn_violation": 0.016623789616607716,
            "auditor_fp_violation": 0.020309830395466102,
            "ave_precision_score": 0.7851007449088536,
            "fpr": 0.13815789473684212,
            "logloss": 2.0425862611351526,
            "mae": 0.28419222536501787,
            "precision": 0.7423312883435583,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7834798569091772,
            "auditor_fn_violation": 0.012638901072326951,
            "auditor_fp_violation": 0.026182962207934764,
            "ave_precision_score": 0.772946739497869,
            "fpr": 0.12623490669593854,
            "logloss": 1.8372337807883568,
            "mae": 0.26563194290283954,
            "precision": 0.7578947368421053,
            "recall": 0.7775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8278324929397505,
            "auditor_fn_violation": 0.021463090006074253,
            "auditor_fp_violation": 0.01866900029170314,
            "ave_precision_score": 0.8277774987480941,
            "fpr": 0.12828947368421054,
            "logloss": 1.0351562095626499,
            "mae": 0.2782415472122832,
            "precision": 0.7547169811320755,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.836139544080407,
            "auditor_fn_violation": 0.016000739699331194,
            "auditor_fp_violation": 0.02967206366630077,
            "ave_precision_score": 0.8363978236656078,
            "fpr": 0.1163556531284303,
            "logloss": 0.8591574664540308,
            "mae": 0.25762815539390016,
            "precision": 0.7700650759219089,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7357231085264092,
            "auditor_fn_violation": 0.013327616393325482,
            "auditor_fp_violation": 0.027373213318331476,
            "ave_precision_score": 0.689311692361305,
            "fpr": 0.2412280701754386,
            "logloss": 3.8030768010917564,
            "mae": 0.32783312817069565,
            "precision": 0.6599690880989181,
            "recall": 0.869653767820774
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7167922885952699,
            "auditor_fn_violation": 0.006135711118961198,
            "auditor_fp_violation": 0.018087462756782198,
            "ave_precision_score": 0.6669321730216526,
            "fpr": 0.24698133918770582,
            "logloss": 3.8318472010484297,
            "mae": 0.31403601068672055,
            "precision": 0.6500777604976672,
            "recall": 0.9028077753779697
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8308295293639372,
            "auditor_fn_violation": 0.021679708436059607,
            "auditor_fp_violation": 0.02212776597074634,
            "ave_precision_score": 0.8312057455765827,
            "fpr": 0.13706140350877194,
            "logloss": 0.9562255714654915,
            "mae": 0.2804598532896262,
            "precision": 0.7438524590163934,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8180693417221115,
            "auditor_fn_violation": 0.010810990225063004,
            "auditor_fp_violation": 0.024646679473106475,
            "ave_precision_score": 0.8193976028237095,
            "fpr": 0.13062568605927552,
            "logloss": 0.8692936027102018,
            "mae": 0.2616562628730921,
            "precision": 0.7551440329218106,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8331222368892237,
            "auditor_fn_violation": 0.002749044199092443,
            "auditor_fp_violation": 0.002745134808517729,
            "ave_precision_score": 0.8323702311715627,
            "fpr": 0.1074561403508772,
            "logloss": 0.7400189192322106,
            "mae": 0.29178431048725745,
            "precision": 0.7874186550976139,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8297840297575115,
            "auditor_fn_violation": 0.0018824399646271966,
            "auditor_fp_violation": 0.006277442371020855,
            "ave_precision_score": 0.8289387681001948,
            "fpr": 0.13062568605927552,
            "logloss": 0.6928608035964703,
            "mae": 0.28275287992634773,
            "precision": 0.750524109014675,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.857913528967772,
            "auditor_fn_violation": 0.02108791581805839,
            "auditor_fp_violation": 0.013436575405259001,
            "ave_precision_score": 0.8580785329676568,
            "fpr": 0.11951754385964912,
            "logloss": 0.5947744391569393,
            "mae": 0.27885184144274955,
            "precision": 0.7729166666666667,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8624708026495264,
            "auditor_fn_violation": 0.0032527803922777353,
            "auditor_fp_violation": 0.023228006899796146,
            "ave_precision_score": 0.8626815464611016,
            "fpr": 0.1251372118551043,
            "logloss": 0.5111848383735177,
            "mae": 0.26127690800532605,
            "precision": 0.7634854771784232,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.6722430149788262,
            "auditor_fn_violation": 0.019250008932718762,
            "auditor_fp_violation": 0.013590240446722506,
            "ave_precision_score": 0.6725371572113864,
            "fpr": 0.22916666666666666,
            "logloss": 1.4870211474253132,
            "mae": 0.3684811943966426,
            "precision": 0.6390328151986183,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6562869529664639,
            "auditor_fn_violation": 0.009445391459791893,
            "auditor_fp_violation": 0.009452916732005654,
            "ave_precision_score": 0.6564775039064799,
            "fpr": 0.24039517014270034,
            "logloss": 1.5565825937785733,
            "mae": 0.3564964761094043,
            "precision": 0.6288135593220339,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 14289,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6993987352756171,
            "auditor_fn_violation": 0.005578482867045413,
            "auditor_fp_violation": 0.013845480685085638,
            "ave_precision_score": 0.6709356941535718,
            "fpr": 0.2138157894736842,
            "logloss": 3.392937636123467,
            "mae": 0.3297270301483139,
            "precision": 0.6666666666666666,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.6567851317245228,
            "auditor_fn_violation": 0.01591301894531204,
            "auditor_fp_violation": 0.013721185510428103,
            "ave_precision_score": 0.6263174758590467,
            "fpr": 0.2305159165751921,
            "logloss": 3.5626121849705332,
            "mae": 0.3291944209395472,
            "precision": 0.6446700507614214,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8051495120254144,
            "auditor_fn_violation": 0.013349948190231178,
            "auditor_fp_violation": 0.018085594032587412,
            "ave_precision_score": 0.7770856445760808,
            "fpr": 0.16776315789473684,
            "logloss": 3.4763334418472756,
            "mae": 0.28277148282005765,
            "precision": 0.7208029197080292,
            "recall": 0.8044806517311609
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.7835922379311793,
            "auditor_fn_violation": 0.006379906731500997,
            "auditor_fp_violation": 0.03020620981652815,
            "ave_precision_score": 0.7469836610931897,
            "fpr": 0.1668496158068057,
            "logloss": 3.326530855856549,
            "mae": 0.2603505528822673,
            "precision": 0.7179962894248608,
            "recall": 0.8358531317494601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8405602743154159,
            "auditor_fn_violation": 0.015482634794726126,
            "auditor_fp_violation": 0.027326332458223957,
            "ave_precision_score": 0.8408634100591561,
            "fpr": 0.1875,
            "logloss": 0.6300937525014474,
            "mae": 0.2995236701470659,
            "precision": 0.7026086956521739,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8251450713334018,
            "auditor_fn_violation": 0.0006709452266870269,
            "auditor_fp_violation": 0.006791986827661917,
            "ave_precision_score": 0.8266631254902259,
            "fpr": 0.19209659714599342,
            "logloss": 0.6138096539016062,
            "mae": 0.28962476928304354,
            "precision": 0.6935201401050788,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 14289,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.672048354284024,
            "auditor_fn_violation": 0.011590202594061547,
            "auditor_fp_violation": 0.017585531524773934,
            "ave_precision_score": 0.6726932552575151,
            "fpr": 0.0800438596491228,
            "logloss": 3.2379583192523986,
            "mae": 0.4348154850494482,
            "precision": 0.7125984251968503,
            "recall": 0.36863543788187375
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6959314153108934,
            "auditor_fn_violation": 0.00497874549838428,
            "auditor_fp_violation": 0.012278010820134862,
            "ave_precision_score": 0.6966928944728235,
            "fpr": 0.07574094401756312,
            "logloss": 2.5945751738715987,
            "mae": 0.3792222336430015,
            "precision": 0.75,
            "recall": 0.4470842332613391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 14289,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8299237261825755,
            "auditor_fn_violation": 0.016393772108478942,
            "auditor_fp_violation": 0.011918156436221196,
            "ave_precision_score": 0.8302469441472975,
            "fpr": 0.11513157894736842,
            "logloss": 0.9438529575055341,
            "mae": 0.28038648402198285,
            "precision": 0.7707423580786026,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8243152249916497,
            "auditor_fn_violation": 0.005981607091630256,
            "auditor_fp_violation": 0.016960365375568456,
            "ave_precision_score": 0.8247283758925559,
            "fpr": 0.1163556531284303,
            "logloss": 0.8264887890684752,
            "mae": 0.2615157037467498,
            "precision": 0.7695652173913043,
            "recall": 0.7645788336933045
        }
    }
]