[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8217809988357156,
            "auditor_fn_violation": 0.012143758000150596,
            "auditor_fp_violation": 0.007414837542286212,
            "ave_precision_score": 0.8222282216419027,
            "fpr": 0.07456140350877193,
            "logloss": 0.9539902780921993,
            "mae": 0.28796091003239876,
            "precision": 0.8017492711370262,
            "recall": 0.5901287553648069
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8565921813147275,
            "auditor_fn_violation": 0.009177448669269946,
            "auditor_fp_violation": 0.017952370943005506,
            "ave_precision_score": 0.8567915317460437,
            "fpr": 0.06037321624588365,
            "logloss": 0.973892796143195,
            "mae": 0.28821137866604646,
            "precision": 0.8396501457725948,
            "recall": 0.5901639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.8528031314682227,
            "auditor_fn_violation": 0.003407122957608614,
            "auditor_fp_violation": 0.03392976555739123,
            "ave_precision_score": 0.8531514084291489,
            "fpr": 0.4067982456140351,
            "logloss": 1.1995776565076561,
            "mae": 0.4008990956047599,
            "precision": 0.5535499398315282,
            "recall": 0.9871244635193133
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.8681846630323538,
            "auditor_fn_violation": 0.008286696298429036,
            "auditor_fp_violation": 0.020425428113963046,
            "ave_precision_score": 0.8683483212989023,
            "fpr": 0.3940724478594951,
            "logloss": 1.130514635048715,
            "mae": 0.3905876740786675,
            "precision": 0.5700598802395209,
            "recall": 0.9754098360655737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8090409923588553,
            "auditor_fn_violation": 0.008668398463971091,
            "auditor_fp_violation": 0.01225808354968138,
            "ave_precision_score": 0.8090165375476657,
            "fpr": 0.16776315789473684,
            "logloss": 0.8950775046305705,
            "mae": 0.2763360736889323,
            "precision": 0.7129455909943715,
            "recall": 0.8154506437768241
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.848735415495079,
            "auditor_fn_violation": 0.007202497705637837,
            "auditor_fp_violation": 0.03337459420323704,
            "ave_precision_score": 0.8489323239550717,
            "fpr": 0.15806805708013172,
            "logloss": 0.831968952296748,
            "mae": 0.2722732158073729,
            "precision": 0.7318435754189944,
            "recall": 0.805327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.8057290788181868,
            "auditor_fn_violation": 0.013186130562457649,
            "auditor_fp_violation": 0.02347376288254269,
            "ave_precision_score": 0.8060764652470327,
            "fpr": 0.22916666666666666,
            "logloss": 1.1566086447508728,
            "mae": 0.295910870109112,
            "precision": 0.6618122977346278,
            "recall": 0.8776824034334764
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8336445803647552,
            "auditor_fn_violation": 0.012720213780569001,
            "auditor_fp_violation": 0.0304577880540699,
            "ave_precision_score": 0.8338920023989156,
            "fpr": 0.21185510428100987,
            "logloss": 1.1183851627638959,
            "mae": 0.2790938253521753,
            "precision": 0.6897106109324759,
            "recall": 0.8790983606557377
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8388755433139056,
            "auditor_fn_violation": 0.025162826594382952,
            "auditor_fp_violation": 0.03406006608449375,
            "ave_precision_score": 0.8391409785608088,
            "fpr": 0.17324561403508773,
            "logloss": 0.5394135622449379,
            "mae": 0.32812863019940425,
            "precision": 0.7122040072859745,
            "recall": 0.8390557939914163
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8597890689418956,
            "auditor_fn_violation": 0.02347897284554894,
            "auditor_fp_violation": 0.0215698333735562,
            "ave_precision_score": 0.8600110118334863,
            "fpr": 0.1756311745334797,
            "logloss": 0.5143690177561098,
            "mae": 0.3234795229729269,
            "precision": 0.7192982456140351,
            "recall": 0.8401639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7990974288995396,
            "auditor_fn_violation": 0.004936563511783754,
            "auditor_fp_violation": 0.012051569506726456,
            "ave_precision_score": 0.7999395709311059,
            "fpr": 0.12280701754385964,
            "logloss": 2.519985069457801,
            "mae": 0.3091532275504894,
            "precision": 0.7477477477477478,
            "recall": 0.7124463519313304
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8281275278509221,
            "auditor_fn_violation": 0.0040128844181317675,
            "auditor_fp_violation": 0.026427716924482234,
            "ave_precision_score": 0.8285472751682033,
            "fpr": 0.1141602634467618,
            "logloss": 2.237305028921979,
            "mae": 0.2950476825282626,
            "precision": 0.7758620689655172,
            "recall": 0.7377049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7886698450613113,
            "auditor_fn_violation": 0.006054231609065594,
            "auditor_fp_violation": 0.002915781606482575,
            "ave_precision_score": 0.7893845416857708,
            "fpr": 0.08223684210526316,
            "logloss": 0.8575282193391659,
            "mae": 0.3130482516202603,
            "precision": 0.7832369942196532,
            "recall": 0.5815450643776824
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8522923095319872,
            "auditor_fn_violation": 0.003688974465098707,
            "auditor_fp_violation": 0.011449242642460292,
            "ave_precision_score": 0.8525091331621281,
            "fpr": 0.06476399560922064,
            "logloss": 0.7984916027656651,
            "mae": 0.3001680862574789,
            "precision": 0.830945558739255,
            "recall": 0.5942622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8161380429407883,
            "auditor_fn_violation": 0.010769614486860932,
            "auditor_fp_violation": 0.016154806860199825,
            "ave_precision_score": 0.81660083407381,
            "fpr": 0.1524122807017544,
            "logloss": 0.8668803115320413,
            "mae": 0.2740973649997196,
            "precision": 0.7252964426877471,
            "recall": 0.7875536480686696
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.84752767429086,
            "auditor_fn_violation": 0.012497525687858778,
            "auditor_fp_violation": 0.026461452226919223,
            "ave_precision_score": 0.8477530722886673,
            "fpr": 0.13391877058177826,
            "logloss": 0.8397337324096827,
            "mae": 0.2611026652316663,
            "precision": 0.7579365079365079,
            "recall": 0.7827868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8109941958508609,
            "auditor_fn_violation": 0.01131786010089602,
            "auditor_fp_violation": 0.021002969868617737,
            "ave_precision_score": 0.811333948406564,
            "fpr": 0.1787280701754386,
            "logloss": 0.884852764615583,
            "mae": 0.2836235017214252,
            "precision": 0.7025547445255474,
            "recall": 0.8261802575107297
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8403264947823301,
            "auditor_fn_violation": 0.019983444602400535,
            "auditor_fp_violation": 0.03284520945730279,
            "ave_precision_score": 0.8405532286636999,
            "fpr": 0.15697036223929747,
            "logloss": 0.8547629350900433,
            "mae": 0.2673485400101989,
            "precision": 0.7371323529411765,
            "recall": 0.8217213114754098
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8121044527335105,
            "auditor_fn_violation": 0.011870811685867028,
            "auditor_fp_violation": 0.018487923845488165,
            "ave_precision_score": 0.8125733619696729,
            "fpr": 0.20065789473684212,
            "logloss": 0.9489374168632472,
            "mae": 0.28604229616874677,
            "precision": 0.6822916666666666,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8440834206231314,
            "auditor_fn_violation": 0.010877975922693493,
            "auditor_fp_violation": 0.029801247168180865,
            "ave_precision_score": 0.8442877515982742,
            "fpr": 0.17014270032930845,
            "logloss": 0.8927988641970518,
            "mae": 0.2638055467938657,
            "precision": 0.7275922671353251,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8151606975823695,
            "auditor_fn_violation": 0.009030758226037197,
            "auditor_fp_violation": 0.015943375816222176,
            "ave_precision_score": 0.8156206927233336,
            "fpr": 0.1524122807017544,
            "logloss": 0.8666487304239682,
            "mae": 0.2741739424604677,
            "precision": 0.7247524752475247,
            "recall": 0.7854077253218884
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8474153742946433,
            "auditor_fn_violation": 0.009841014198052942,
            "auditor_fp_violation": 0.022607842679309615,
            "ave_precision_score": 0.8476437056346117,
            "fpr": 0.13830954994511527,
            "logloss": 0.8402174497663627,
            "mae": 0.26087286722999864,
            "precision": 0.7514792899408284,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8628376179754902,
            "auditor_fn_violation": 0.006828363828025002,
            "auditor_fp_violation": 0.007601683581150186,
            "ave_precision_score": 0.8631430131250493,
            "fpr": 0.05701754385964912,
            "logloss": 0.49698407826425306,
            "mae": 0.29504627470573486,
            "precision": 0.8571428571428571,
            "recall": 0.6695278969957081
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8751813131682835,
            "auditor_fn_violation": 0.004235572510841986,
            "auditor_fp_violation": 0.012495037018006866,
            "ave_precision_score": 0.875358706938355,
            "fpr": 0.06915477497255763,
            "logloss": 0.5015778557999196,
            "mae": 0.29879780541532946,
            "precision": 0.8376288659793815,
            "recall": 0.6659836065573771
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.8652271479585193,
            "auditor_fn_violation": 0.0011764927339808751,
            "auditor_fp_violation": 0.011358272362520669,
            "ave_precision_score": 0.8656366890068107,
            "fpr": 0.44956140350877194,
            "logloss": 1.5274722967594767,
            "mae": 0.4354639683131194,
            "precision": 0.5308924485125858,
            "recall": 0.9957081545064378
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.8736010338718105,
            "auditor_fn_violation": 0.0018624822299400767,
            "auditor_fp_violation": 0.014729352048641125,
            "ave_precision_score": 0.8737458263002517,
            "fpr": 0.41822173435784854,
            "logloss": 1.4385804191927767,
            "mae": 0.41528348527382547,
            "precision": 0.5600461893764435,
            "recall": 0.9938524590163934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 10102,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8115225710644383,
            "auditor_fn_violation": 0.02240512762593179,
            "auditor_fp_violation": 0.020921839351742594,
            "ave_precision_score": 0.8121783242369639,
            "fpr": 0.17324561403508773,
            "logloss": 0.9007749669124694,
            "mae": 0.27674354297536774,
            "precision": 0.7057728119180633,
            "recall": 0.8133047210300429
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8405943220788705,
            "auditor_fn_violation": 0.011476309585935115,
            "auditor_fp_violation": 0.01823522847882332,
            "ave_precision_score": 0.8408136879277415,
            "fpr": 0.15697036223929747,
            "logloss": 0.8927225041417943,
            "mae": 0.26769160829718364,
            "precision": 0.7342007434944238,
            "recall": 0.8094262295081968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8204912437500597,
            "auditor_fn_violation": 0.012164934869362244,
            "auditor_fp_violation": 0.013693847848320366,
            "ave_precision_score": 0.8209223708453719,
            "fpr": 0.15570175438596492,
            "logloss": 0.8307385511332676,
            "mae": 0.27126081423801907,
            "precision": 0.7237354085603113,
            "recall": 0.7982832618025751
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8531790205121952,
            "auditor_fn_violation": 0.010128934156304554,
            "auditor_fp_violation": 0.027496866509408257,
            "ave_precision_score": 0.8533928130906696,
            "fpr": 0.1394072447859495,
            "logloss": 0.7994282722396051,
            "mae": 0.2594279921328528,
            "precision": 0.7529182879377432,
            "recall": 0.7930327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8206628668295721,
            "auditor_fn_violation": 0.03233472630073037,
            "auditor_fp_violation": 0.02474726614743136,
            "ave_precision_score": 0.8210018430889958,
            "fpr": 0.09210526315789473,
            "logloss": 0.6883806249831543,
            "mae": 0.3143964139301302,
            "precision": 0.7910447761194029,
            "recall": 0.6824034334763949
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8267769372999092,
            "auditor_fn_violation": 0.04495825160605352,
            "auditor_fp_violation": 0.023760033008695922,
            "ave_precision_score": 0.8280057176525841,
            "fpr": 0.09549945115257959,
            "logloss": 0.6965838954236881,
            "mae": 0.32003791279927324,
            "precision": 0.7928571428571428,
            "recall": 0.6823770491803278
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.8090961236178038,
            "auditor_fn_violation": 0.011663748964686397,
            "auditor_fp_violation": 0.022406773660608916,
            "ave_precision_score": 0.8094632795614709,
            "fpr": 0.21710526315789475,
            "logloss": 1.0327271662236985,
            "mae": 0.29070103278627424,
            "precision": 0.670549084858569,
            "recall": 0.8648068669527897
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8415545873514384,
            "auditor_fn_violation": 0.012672976912418352,
            "auditor_fp_violation": 0.026741714739472646,
            "ave_precision_score": 0.8417632757763445,
            "fpr": 0.19209659714599342,
            "logloss": 0.9647912179885584,
            "mae": 0.27167862629273754,
            "precision": 0.7068676716917923,
            "recall": 0.8647540983606558
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8210553982561819,
            "auditor_fn_violation": 0.0114543332580378,
            "auditor_fp_violation": 0.010945244276610814,
            "ave_precision_score": 0.8215626748599869,
            "fpr": 0.1513157894736842,
            "logloss": 0.7899350299844189,
            "mae": 0.2725899333850457,
            "precision": 0.7261904761904762,
            "recall": 0.7854077253218884
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8530224292773732,
            "auditor_fn_violation": 0.011678753306580771,
            "auditor_fp_violation": 0.026889631065542506,
            "ave_precision_score": 0.8532221281033817,
            "fpr": 0.132821075740944,
            "logloss": 0.7805262824451908,
            "mae": 0.2614467280224742,
            "precision": 0.7584830339321357,
            "recall": 0.7786885245901639
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.820175058490188,
            "auditor_fn_violation": 0.010837851065431815,
            "auditor_fp_violation": 0.00034419007159153703,
            "ave_precision_score": 0.8206203111396273,
            "fpr": 0.09100877192982457,
            "logloss": 0.8652209217081118,
            "mae": 0.2794796719886749,
            "precision": 0.7866323907455013,
            "recall": 0.6566523605150214
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8532405066999036,
            "auditor_fn_violation": 0.014976336578431207,
            "auditor_fp_violation": 0.022000607235443868,
            "ave_precision_score": 0.8534453676450169,
            "fpr": 0.0845225027442371,
            "logloss": 0.8939486194283979,
            "mae": 0.2784050570676097,
            "precision": 0.8075,
            "recall": 0.6618852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8236482210783919,
            "auditor_fn_violation": 0.0025318123635268428,
            "auditor_fp_violation": 0.017861006215089296,
            "ave_precision_score": 0.8229887791505439,
            "fpr": 0.3980263157894737,
            "logloss": 2.2638328282737303,
            "mae": 0.39803542870463554,
            "precision": 0.5589307411907655,
            "recall": 0.9871244635193133
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.8536185454278056,
            "auditor_fn_violation": 0.00478217055658527,
            "auditor_fp_violation": 0.007216759698250689,
            "ave_precision_score": 0.8535257021688003,
            "fpr": 0.3534577387486279,
            "logloss": 1.9833374832151354,
            "mae": 0.36117846256086433,
            "precision": 0.5969962453066333,
            "recall": 0.9774590163934426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.805721566199261,
            "auditor_fn_violation": 0.01322377832994504,
            "auditor_fp_violation": 0.016983321532530883,
            "ave_precision_score": 0.8061128685121557,
            "fpr": 0.15350877192982457,
            "logloss": 0.9727811173906583,
            "mae": 0.27920184290882494,
            "precision": 0.7211155378486056,
            "recall": 0.776824034334764
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8381510012687827,
            "auditor_fn_violation": 0.010545068470965074,
            "auditor_fp_violation": 0.02613188427234251,
            "ave_precision_score": 0.8384028352005496,
            "fpr": 0.13721185510428102,
            "logloss": 0.9407882336083762,
            "mae": 0.26429149159599463,
            "precision": 0.751984126984127,
            "recall": 0.7766393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 10102,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7650226731434305,
            "auditor_fn_violation": 0.0033388863790377254,
            "auditor_fp_violation": 0.009937259066949889,
            "ave_precision_score": 0.76652267645689,
            "fpr": 0.12280701754385964,
            "logloss": 0.6727276858475761,
            "mae": 0.3337501863881931,
            "precision": 0.748314606741573,
            "recall": 0.7145922746781116
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7614032601177931,
            "auditor_fn_violation": 0.006964063990210722,
            "auditor_fp_violation": 0.006365592067532888,
            "ave_precision_score": 0.7618589577575187,
            "fpr": 0.12733260153677278,
            "logloss": 0.7467085416987538,
            "mae": 0.3419597074262851,
            "precision": 0.7494600431965442,
            "recall": 0.7110655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7843543713418943,
            "auditor_fn_violation": 0.019826255553045707,
            "auditor_fp_violation": 0.019918771143104398,
            "ave_precision_score": 0.785019607435411,
            "fpr": 0.18421052631578946,
            "logloss": 0.9819265753858624,
            "mae": 0.3045063693387817,
            "precision": 0.6848030018761726,
            "recall": 0.7832618025751072
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8282909071856908,
            "auditor_fn_violation": 0.021522016879307555,
            "auditor_fp_violation": 0.03000365898280279,
            "ave_precision_score": 0.8285527829907671,
            "fpr": 0.15477497255762898,
            "logloss": 0.9043347654020802,
            "mae": 0.28226139902143244,
            "precision": 0.7314285714285714,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7955257600897778,
            "auditor_fn_violation": 0.03228766659137113,
            "auditor_fp_violation": 0.02551431830697821,
            "ave_precision_score": 0.79647801278784,
            "fpr": 0.14144736842105263,
            "logloss": 1.6524325047993351,
            "mae": 0.2865263482829995,
            "precision": 0.7295597484276729,
            "recall": 0.7467811158798283
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8297357727741934,
            "auditor_fn_violation": 0.022174335534721347,
            "auditor_fp_violation": 0.019465269506141126,
            "ave_precision_score": 0.8299789434498855,
            "fpr": 0.13062568605927552,
            "logloss": 1.6330349332010936,
            "mae": 0.27807504468235295,
            "precision": 0.7566462167689162,
            "recall": 0.7581967213114754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8116960365435755,
            "auditor_fn_violation": 0.012259054288080721,
            "auditor_fp_violation": 0.01775529069310047,
            "ave_precision_score": 0.812261130283584,
            "fpr": 0.14473684210526316,
            "logloss": 0.8616380986385206,
            "mae": 0.27285343135421397,
            "precision": 0.7311608961303462,
            "recall": 0.7703862660944206
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8408884166602968,
            "auditor_fn_violation": 0.015633153983192677,
            "auditor_fp_violation": 0.031039073265291824,
            "ave_precision_score": 0.8411291288334607,
            "fpr": 0.13830954994511527,
            "logloss": 0.8714234233906745,
            "mae": 0.2656924769950037,
            "precision": 0.7504950495049505,
            "recall": 0.7766393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8370602855771528,
            "auditor_fn_violation": 0.013040245463444022,
            "auditor_fp_violation": 0.008078632680355597,
            "ave_precision_score": 0.8378400655998786,
            "fpr": 0.13925438596491227,
            "logloss": 0.6261731553235297,
            "mae": 0.27724755186908734,
            "precision": 0.7381443298969073,
            "recall": 0.7682403433476395
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.86694333163799,
            "auditor_fn_violation": 0.010369617246405503,
            "auditor_fp_violation": 0.01998686918228222,
            "ave_precision_score": 0.8671074702281927,
            "fpr": 0.12623490669593854,
            "logloss": 0.6096539510133825,
            "mae": 0.26736262210515205,
            "precision": 0.7648261758691206,
            "recall": 0.7663934426229508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7666891466555791,
            "auditor_fn_violation": 0.01714855809050524,
            "auditor_fp_violation": 0.018662477381795297,
            "ave_precision_score": 0.7316433539607423,
            "fpr": 0.1611842105263158,
            "logloss": 4.215962787553512,
            "mae": 0.3137509068763583,
            "precision": 0.6924686192468619,
            "recall": 0.7103004291845494
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7922825465608297,
            "auditor_fn_violation": 0.017248204999010277,
            "auditor_fp_violation": 0.02630834585432058,
            "ave_precision_score": 0.7575841972066768,
            "fpr": 0.14050493962678376,
            "logloss": 4.238500106589827,
            "mae": 0.2941981283415545,
            "precision": 0.7310924369747899,
            "recall": 0.7131147540983607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8162363579334977,
            "auditor_fn_violation": 0.006851893682704621,
            "auditor_fp_violation": 0.021116060892140673,
            "ave_precision_score": 0.8168400136782646,
            "fpr": 0.18530701754385964,
            "logloss": 0.9499944445146056,
            "mae": 0.28174349868989806,
            "precision": 0.6971326164874552,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8490893888666227,
            "auditor_fn_violation": 0.007845818862356265,
            "auditor_fp_violation": 0.028656841908587714,
            "ave_precision_score": 0.8493038627889185,
            "fpr": 0.16575192096597147,
            "logloss": 0.888425100925549,
            "mae": 0.2607833980728848,
            "precision": 0.7298747763864043,
            "recall": 0.8360655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8135316035008293,
            "auditor_fn_violation": 0.014870868157518263,
            "auditor_fp_violation": 0.02172576901895996,
            "ave_precision_score": 0.813928854699215,
            "fpr": 0.14144736842105263,
            "logloss": 0.8066222321467407,
            "mae": 0.27695107845109523,
            "precision": 0.7378048780487805,
            "recall": 0.778969957081545
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8402427120454515,
            "auditor_fn_violation": 0.01714923251336129,
            "auditor_fp_violation": 0.027893905068858946,
            "ave_precision_score": 0.8404962153642486,
            "fpr": 0.1350164654226125,
            "logloss": 0.8064568184199925,
            "mae": 0.26641225092086307,
            "precision": 0.7559523809523809,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8093538931724423,
            "auditor_fn_violation": 0.022478070175438597,
            "auditor_fp_violation": 0.01708657855400834,
            "ave_precision_score": 0.8097366888809389,
            "fpr": 0.11732456140350878,
            "logloss": 0.8955317734062797,
            "mae": 0.27355774055423737,
            "precision": 0.759009009009009,
            "recall": 0.723175965665236
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8401329430516962,
            "auditor_fn_violation": 0.010898220294758058,
            "auditor_fp_violation": 0.013156767950424681,
            "ave_precision_score": 0.8403548908059808,
            "fpr": 0.1119648737650933,
            "logloss": 0.894759738282353,
            "mae": 0.2717498696422315,
            "precision": 0.7806451612903226,
            "recall": 0.7438524590163934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.8201973201790561,
            "auditor_fn_violation": 0.003929485731496122,
            "auditor_fp_violation": 0.019058295964125574,
            "ave_precision_score": 0.8193936768774364,
            "fpr": 0.3925438596491228,
            "logloss": 2.3027705860524073,
            "mae": 0.39579294846246665,
            "precision": 0.5612745098039216,
            "recall": 0.9828326180257511
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.8497879300890978,
            "auditor_fn_violation": 0.007000053984992172,
            "auditor_fp_violation": 0.006466797974843847,
            "ave_precision_score": 0.8497725967654075,
            "fpr": 0.3468715697036224,
            "logloss": 2.0144348970562564,
            "mae": 0.3587761718654716,
            "precision": 0.6,
            "recall": 0.9713114754098361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8162746518033447,
            "auditor_fn_violation": 0.020548622091709958,
            "auditor_fp_violation": 0.01863543387617025,
            "ave_precision_score": 0.8171565958938887,
            "fpr": 0.1206140350877193,
            "logloss": 0.5342882874919583,
            "mae": 0.31502923965627705,
            "precision": 0.7674418604651163,
            "recall": 0.778969957081545
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8213005427849223,
            "auditor_fn_violation": 0.02869077396483778,
            "auditor_fp_violation": 0.018878794248390438,
            "ave_precision_score": 0.8225837890736052,
            "fpr": 0.1350164654226125,
            "logloss": 0.5551188378913945,
            "mae": 0.32277826729213205,
            "precision": 0.7559523809523809,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8289511184563405,
            "auditor_fn_violation": 0.011068443641292076,
            "auditor_fp_violation": 0.014662497049799387,
            "ave_precision_score": 0.829394678672253,
            "fpr": 0.1611842105263158,
            "logloss": 0.7472744957531735,
            "mae": 0.27563425152331483,
            "precision": 0.7167630057803468,
            "recall": 0.7982832618025751
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8632531339534905,
            "auditor_fn_violation": 0.009042486188839504,
            "auditor_fp_violation": 0.026840325623519214,
            "ave_precision_score": 0.8634563167050188,
            "fpr": 0.1394072447859495,
            "logloss": 0.6980195670608123,
            "mae": 0.25839057417721134,
            "precision": 0.7543520309477756,
            "recall": 0.7991803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8147955387062866,
            "auditor_fn_violation": 0.009397823959039231,
            "auditor_fp_violation": 0.0207128668082763,
            "ave_precision_score": 0.8152988844279521,
            "fpr": 0.20723684210526316,
            "logloss": 0.983115609354429,
            "mae": 0.28603374456039493,
            "precision": 0.6774744027303754,
            "recall": 0.851931330472103
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8456374800079567,
            "auditor_fn_violation": 0.010207662269888973,
            "auditor_fp_violation": 0.02587757199243291,
            "ave_precision_score": 0.8458640287229338,
            "fpr": 0.18111964873765093,
            "logloss": 0.920806631428055,
            "mae": 0.2630314943629419,
            "precision": 0.7193877551020408,
            "recall": 0.8668032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6524122807017544,
            "auc_prc": 0.8219661654797829,
            "auditor_fn_violation": 0.005280099390106168,
            "auditor_fp_violation": 0.026006018409251836,
            "ave_precision_score": 0.8219623043277686,
            "fpr": 0.32785087719298245,
            "logloss": 1.562588337140211,
            "mae": 0.3492889237627361,
            "precision": 0.5997322623828648,
            "recall": 0.9613733905579399
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8525408596155735,
            "auditor_fn_violation": 0.0064871965593565,
            "auditor_fp_violation": 0.02384566877642058,
            "ave_precision_score": 0.8527547743155743,
            "fpr": 0.2864983534577388,
            "logloss": 1.3944500793496644,
            "mae": 0.31564065172319833,
            "precision": 0.6395027624309392,
            "recall": 0.9487704918032787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8261838136553482,
            "auditor_fn_violation": 0.011473157141781494,
            "auditor_fp_violation": 0.01842154433168123,
            "ave_precision_score": 0.8265460552345762,
            "fpr": 0.23135964912280702,
            "logloss": 1.0042134419492215,
            "mae": 0.29368844260557525,
            "precision": 0.6624,
            "recall": 0.8884120171673819
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8569807830323088,
            "auditor_fn_violation": 0.014629932878659734,
            "auditor_fp_violation": 0.02398580003269729,
            "ave_precision_score": 0.8571716672198826,
            "fpr": 0.19758507135016465,
            "logloss": 0.9455768890108772,
            "mae": 0.26734296835883914,
            "precision": 0.7087378640776699,
            "recall": 0.8975409836065574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 10102,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8242946119771871,
            "auditor_fn_violation": 0.009866068067163615,
            "auditor_fp_violation": 0.011685252930532618,
            "ave_precision_score": 0.8248394512167123,
            "fpr": 0.14802631578947367,
            "logloss": 0.7002414210864096,
            "mae": 0.27752555861803685,
            "precision": 0.7310756972111554,
            "recall": 0.7875536480686696
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8591238403873311,
            "auditor_fn_violation": 0.008637598747548188,
            "auditor_fp_violation": 0.023638066915269908,
            "ave_precision_score": 0.859323379986861,
            "fpr": 0.13721185510428102,
            "logloss": 0.6680647581869954,
            "mae": 0.26375507758072303,
            "precision": 0.7544204322200393,
            "recall": 0.7868852459016393
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8156133441859046,
            "auditor_fn_violation": 0.010769614486860932,
            "auditor_fp_violation": 0.01787821571866887,
            "ave_precision_score": 0.8160744769521341,
            "fpr": 0.1524122807017544,
            "logloss": 0.864991863946384,
            "mae": 0.27413902485175534,
            "precision": 0.7252964426877471,
            "recall": 0.7875536480686696
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8478550181973192,
            "auditor_fn_violation": 0.011788972665598961,
            "auditor_fp_violation": 0.026975266833267172,
            "ave_precision_score": 0.8480811118759097,
            "fpr": 0.1350164654226125,
            "logloss": 0.8356885822198128,
            "mae": 0.2612336235101084,
            "precision": 0.7569169960474308,
            "recall": 0.7848360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8372300644077515,
            "auditor_fn_violation": 0.01644266245011671,
            "auditor_fp_violation": 0.012272834552749589,
            "ave_precision_score": 0.8376304060183051,
            "fpr": 0.13157894736842105,
            "logloss": 0.5559490074957188,
            "mae": 0.28198796422196143,
            "precision": 0.7540983606557377,
            "recall": 0.7896995708154506
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8650579115820082,
            "auditor_fn_violation": 0.008439653776250205,
            "auditor_fp_violation": 0.028480380326609628,
            "ave_precision_score": 0.8652628361635384,
            "fpr": 0.12623490669593854,
            "logloss": 0.5543837034820083,
            "mae": 0.2698793885386548,
            "precision": 0.7762645914396887,
            "recall": 0.8176229508196722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7566462311270323,
            "auditor_fn_violation": 0.009501355319629553,
            "auditor_fp_violation": 0.021248819919754556,
            "ave_precision_score": 0.6731566904034851,
            "fpr": 0.17434210526315788,
            "logloss": 7.992345843025969,
            "mae": 0.3291460068504454,
            "precision": 0.6708074534161491,
            "recall": 0.6952789699570815
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7983886447902077,
            "auditor_fn_violation": 0.01576361771427543,
            "auditor_fp_violation": 0.027616237579569908,
            "ave_precision_score": 0.7277049652822426,
            "fpr": 0.14928649835345773,
            "logloss": 7.2074057455447775,
            "mae": 0.302720379330512,
            "precision": 0.7195876288659794,
            "recall": 0.7151639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8375068961284381,
            "auditor_fn_violation": 0.007134251938860026,
            "auditor_fp_violation": 0.010470753677916769,
            "ave_precision_score": 0.8381381624969304,
            "fpr": 0.4375,
            "logloss": 1.5023562339755667,
            "mae": 0.4241193684123005,
            "precision": 0.5327868852459017,
            "recall": 0.9763948497854077
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.8535092353666038,
            "auditor_fn_violation": 0.0050610930161415135,
            "auditor_fp_violation": 0.013302089253230162,
            "ave_precision_score": 0.8536975285117193,
            "fpr": 0.38748627881448955,
            "logloss": 1.3615029626636141,
            "mae": 0.3898932924512242,
            "precision": 0.5731559854897219,
            "recall": 0.9713114754098361
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8090326984830887,
            "auditor_fn_violation": 0.013247308184624652,
            "auditor_fp_violation": 0.015936000314688073,
            "ave_precision_score": 0.8095437130134027,
            "fpr": 0.1611842105263158,
            "logloss": 0.8396343559075203,
            "mae": 0.28076133360850014,
            "precision": 0.7162162162162162,
            "recall": 0.796137339055794
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8389387368738501,
            "auditor_fn_violation": 0.011649511435820839,
            "auditor_fp_violation": 0.02979086707512333,
            "ave_precision_score": 0.8391776007853603,
            "fpr": 0.14050493962678376,
            "logloss": 0.8187240094021387,
            "mae": 0.2702191612869082,
            "precision": 0.7495107632093934,
            "recall": 0.7848360655737705
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 10102,
        "test": {
            "accuracy": 0.49780701754385964,
            "auc_prc": 0.8562285704836978,
            "auditor_fn_violation": 0.002677697462540494,
            "auditor_fp_violation": 0.0005900401227283455,
            "ave_precision_score": 0.856758701011956,
            "fpr": 0.0010964912280701754,
            "logloss": 2.3866316428079895,
            "mae": 0.4830832756529212,
            "precision": 0.9,
            "recall": 0.019313304721030045
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.8880343123397929,
            "auditor_fn_violation": 0.005283781108851738,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8881724917673731,
            "fpr": 0.0,
            "logloss": 2.450876740795808,
            "mae": 0.5058142407106606,
            "precision": 1.0,
            "recall": 0.018442622950819672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8130625780541837,
            "auditor_fn_violation": 0.011830810932911683,
            "auditor_fp_violation": 0.010532216190700968,
            "ave_precision_score": 0.8135376426124171,
            "fpr": 0.15021929824561403,
            "logloss": 0.8876802079459034,
            "mae": 0.27532919395381245,
            "precision": 0.7265469061876247,
            "recall": 0.7811158798283262
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8449002733509681,
            "auditor_fn_violation": 0.00980952295261917,
            "auditor_fp_violation": 0.028726907536726073,
            "ave_precision_score": 0.8451331763429442,
            "fpr": 0.13172338090010977,
            "logloss": 0.8643507477794928,
            "mae": 0.2625633596484391,
            "precision": 0.7595190380761523,
            "recall": 0.7766393442622951
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8110233116535253,
            "auditor_fn_violation": 0.012903772306302238,
            "auditor_fp_violation": 0.021831484540948794,
            "ave_precision_score": 0.8112896452122651,
            "fpr": 0.2149122807017544,
            "logloss": 1.0200583137046426,
            "mae": 0.290274162512337,
            "precision": 0.6722408026755853,
            "recall": 0.8626609442060086
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8439052166146712,
            "auditor_fn_violation": 0.013012632488168294,
            "auditor_fp_violation": 0.029793462098387725,
            "ave_precision_score": 0.8441310285857291,
            "fpr": 0.19099890230515917,
            "logloss": 0.94727636383815,
            "mae": 0.2710279469566691,
            "precision": 0.7075630252100841,
            "recall": 0.8627049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7770938922406693,
            "auditor_fn_violation": 0.027115804532791207,
            "auditor_fp_violation": 0.015242703170482265,
            "ave_precision_score": 0.7779104119861451,
            "fpr": 0.12719298245614036,
            "logloss": 0.7619334384646936,
            "mae": 0.35280797109937234,
            "precision": 0.7289719626168224,
            "recall": 0.6695278969957081
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8110875479670347,
            "auditor_fn_violation": 0.029693995069370725,
            "auditor_fp_violation": 0.017259499731415093,
            "ave_precision_score": 0.8113436368799566,
            "fpr": 0.12843029637760703,
            "logloss": 0.7327617316519168,
            "mae": 0.3429326694365968,
            "precision": 0.7422907488986784,
            "recall": 0.6905737704918032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.807553750015636,
            "auditor_fn_violation": 0.022362773887508472,
            "auditor_fp_violation": 0.023532766894815513,
            "ave_precision_score": 0.8079852700923639,
            "fpr": 0.18201754385964913,
            "logloss": 0.92000377932944,
            "mae": 0.2821311613328152,
            "precision": 0.6992753623188406,
            "recall": 0.8283261802575107
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8396488803383659,
            "auditor_fn_violation": 0.013181335588706341,
            "auditor_fp_violation": 0.019665086297498666,
            "ave_precision_score": 0.839858081107332,
            "fpr": 0.1712403951701427,
            "logloss": 0.8960570458374442,
            "mae": 0.2710804465619568,
            "precision": 0.7204301075268817,
            "recall": 0.8237704918032787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8181978448217486,
            "auditor_fn_violation": 0.008880167156087651,
            "auditor_fp_violation": 0.019611458579183397,
            "ave_precision_score": 0.8186345229464839,
            "fpr": 0.2050438596491228,
            "logloss": 0.9274251747791958,
            "mae": 0.2856342786077479,
            "precision": 0.6781411359724613,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8495920667377956,
            "auditor_fn_violation": 0.008601608752766733,
            "auditor_fp_violation": 0.029700041260869905,
            "ave_precision_score": 0.849803780816783,
            "fpr": 0.17453347969264543,
            "logloss": 0.8724161770345327,
            "mae": 0.2640534092684718,
            "precision": 0.7253886010362695,
            "recall": 0.860655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.8640773816785497,
            "auditor_fn_violation": 0.004381258941344779,
            "auditor_fp_violation": 0.01924760050350091,
            "ave_precision_score": 0.8643821600801184,
            "fpr": 0.3958333333333333,
            "logloss": 0.9708600101115268,
            "mae": 0.38120078696183074,
            "precision": 0.5592185592185592,
            "recall": 0.9828326180257511
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.873166126967989,
            "auditor_fn_violation": 0.01156628457288874,
            "auditor_fp_violation": 0.012245914784626057,
            "ave_precision_score": 0.8733349775048325,
            "fpr": 0.3633369923161361,
            "logloss": 0.9134027919338459,
            "mae": 0.3678574998179117,
            "precision": 0.58625,
            "recall": 0.9610655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5164473684210527,
            "auc_prc": 0.8130465072696145,
            "auditor_fn_violation": 0.0006282471199457873,
            "auditor_fp_violation": 0.0030632916371646883,
            "ave_precision_score": 0.8128003546412921,
            "fpr": 0.4824561403508772,
            "logloss": 1.77644069277825,
            "mae": 0.44472749245790966,
            "precision": 0.5138121546961326,
            "recall": 0.9978540772532188
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.8406167462448406,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.005314607645457563,
            "ave_precision_score": 0.8408378402442708,
            "fpr": 0.442371020856202,
            "logloss": 1.6134948748818407,
            "mae": 0.41227377499289986,
            "precision": 0.547699214365881,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8100238769891526,
            "auditor_fn_violation": 0.01184257586025149,
            "auditor_fp_violation": 0.019967941153331763,
            "ave_precision_score": 0.8104405268025987,
            "fpr": 0.21710526315789475,
            "logloss": 1.021960818358685,
            "mae": 0.291472238876373,
            "precision": 0.669449081803005,
            "recall": 0.8605150214592274
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8445034284446193,
            "auditor_fn_violation": 0.013057619981645103,
            "auditor_fp_violation": 0.031698209174445255,
            "ave_precision_score": 0.8447260825347651,
            "fpr": 0.19209659714599342,
            "logloss": 0.9439648772438017,
            "mae": 0.2713530037190133,
            "precision": 0.7073578595317725,
            "recall": 0.8668032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.8091544246991274,
            "auditor_fn_violation": 0.016162657179429267,
            "auditor_fp_violation": 0.003719711273699945,
            "ave_precision_score": 0.8096069938463164,
            "fpr": 0.051535087719298246,
            "logloss": 1.185468839335678,
            "mae": 0.3191922793057919,
            "precision": 0.8272058823529411,
            "recall": 0.48283261802575106
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.8374961554080819,
            "auditor_fn_violation": 0.014818880351262356,
            "auditor_fp_violation": 0.008330024678671244,
            "ave_precision_score": 0.8377370515161369,
            "fpr": 0.04610318331503842,
            "logloss": 1.2342798048943162,
            "mae": 0.32368216018973817,
            "precision": 0.8531468531468531,
            "recall": 0.5
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7996560030679213,
            "auditor_fn_violation": 0.01138139070853099,
            "auditor_fp_violation": 0.018733773896624974,
            "ave_precision_score": 0.8001166833593536,
            "fpr": 0.1425438596491228,
            "logloss": 0.9598279915762157,
            "mae": 0.28389674408361043,
            "precision": 0.7308488612836439,
            "recall": 0.7575107296137339
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8324182054349871,
            "auditor_fn_violation": 0.017846538662251898,
            "auditor_fp_violation": 0.02775896385911101,
            "ave_precision_score": 0.8326767209242913,
            "fpr": 0.1207464324917673,
            "logloss": 0.9454318767631517,
            "mae": 0.27131276246920416,
            "precision": 0.7669491525423728,
            "recall": 0.7418032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.8112292752165895,
            "auditor_fn_violation": 0.0025318123635268428,
            "auditor_fp_violation": 0.019776178113445054,
            "ave_precision_score": 0.8086891816696696,
            "fpr": 0.4133771929824561,
            "logloss": 2.780318037571724,
            "mae": 0.4154743643581382,
            "precision": 0.5495818399044206,
            "recall": 0.9871244635193133
        },
        "train": {
            "accuracy": 0.6201975850713501,
            "auc_prc": 0.8424226243450521,
            "auditor_fn_violation": 0.0034842813697792017,
            "auditor_fp_violation": 0.010416423383235644,
            "ave_precision_score": 0.8412771848649266,
            "fpr": 0.3721185510428101,
            "logloss": 2.412598067381503,
            "mae": 0.3772183004251721,
            "precision": 0.5865853658536585,
            "recall": 0.985655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8009776700201079,
            "auditor_fn_violation": 0.00875310594081771,
            "auditor_fp_violation": 0.01917630398867123,
            "ave_precision_score": 0.8014771034792033,
            "fpr": 0.17543859649122806,
            "logloss": 0.9541473531037498,
            "mae": 0.28509254686730495,
            "precision": 0.7058823529411765,
            "recall": 0.8240343347639485
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8344973091066522,
            "auditor_fn_violation": 0.011919436396681722,
            "auditor_fp_violation": 0.029155086375349356,
            "ave_precision_score": 0.8347574864155374,
            "fpr": 0.16136114160263446,
            "logloss": 0.9021372019448479,
            "mae": 0.2703631127069211,
            "precision": 0.7307692307692307,
            "recall": 0.8176229508196722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8095346220378017,
            "auditor_fn_violation": 0.007590731119644607,
            "auditor_fp_violation": 0.019363150027535213,
            "ave_precision_score": 0.8100354928252255,
            "fpr": 0.19407894736842105,
            "logloss": 0.9742935984923622,
            "mae": 0.28460308010243,
            "precision": 0.6894736842105263,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8441434046143979,
            "auditor_fn_violation": 0.009832016699357585,
            "auditor_fp_violation": 0.024803232360978124,
            "ave_precision_score": 0.8443639665729026,
            "fpr": 0.16794731064763996,
            "logloss": 0.9199239392604007,
            "mae": 0.26446459566694447,
            "precision": 0.7277580071174378,
            "recall": 0.8381147540983607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8139999423976736,
            "auditor_fn_violation": 0.015393230931405766,
            "auditor_fp_violation": 0.02172576901895996,
            "ave_precision_score": 0.8143917558347518,
            "fpr": 0.14144736842105263,
            "logloss": 0.8106209154196246,
            "mae": 0.27745079655592997,
            "precision": 0.7351129363449692,
            "recall": 0.7682403433476395
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8407056606901778,
            "auditor_fn_violation": 0.014953842831692791,
            "auditor_fp_violation": 0.027201033857268537,
            "ave_precision_score": 0.8409261700637984,
            "fpr": 0.132821075740944,
            "logloss": 0.8131497279329575,
            "mae": 0.267408999756514,
            "precision": 0.7565392354124748,
            "recall": 0.7704918032786885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7635573751266169,
            "auditor_fn_violation": 0.011063737670356155,
            "auditor_fp_violation": 0.018940287939579893,
            "ave_precision_score": 0.7091451058639145,
            "fpr": 0.16447368421052633,
            "logloss": 5.702360611243026,
            "mae": 0.31774072924537244,
            "precision": 0.6875,
            "recall": 0.7081545064377682
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7993211485830947,
            "auditor_fn_violation": 0.02014764895359091,
            "auditor_fp_violation": 0.02658341832034524,
            "ave_precision_score": 0.7477320115995131,
            "fpr": 0.14050493962678376,
            "logloss": 5.550995728219229,
            "mae": 0.29500819175146964,
            "precision": 0.7316561844863732,
            "recall": 0.7151639344262295
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.809876806358159,
            "auditor_fn_violation": 0.012903772306302238,
            "auditor_fp_violation": 0.021831484540948794,
            "ave_precision_score": 0.8101410663240645,
            "fpr": 0.2149122807017544,
            "logloss": 1.0324580654792457,
            "mae": 0.29031499421080287,
            "precision": 0.6722408026755853,
            "recall": 0.8626609442060086
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8428415376367832,
            "auditor_fn_violation": 0.013012632488168294,
            "auditor_fp_violation": 0.029212176887165802,
            "ave_precision_score": 0.8430691235711195,
            "fpr": 0.18990120746432493,
            "logloss": 0.9597133003253607,
            "mae": 0.2710957623283463,
            "precision": 0.7087542087542088,
            "recall": 0.8627049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8201531350627393,
            "auditor_fn_violation": 0.007458963933438746,
            "auditor_fp_violation": 0.008747344819447727,
            "ave_precision_score": 0.8206188080793644,
            "fpr": 0.13706140350877194,
            "logloss": 0.7724200262662789,
            "mae": 0.27171666000907463,
            "precision": 0.7417355371900827,
            "recall": 0.7703862660944206
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8511062888933834,
            "auditor_fn_violation": 0.008277698799733672,
            "auditor_fp_violation": 0.023471985426349356,
            "ave_precision_score": 0.8513180268798767,
            "fpr": 0.12184412733260154,
            "logloss": 0.755547094865393,
            "mae": 0.26454831252285704,
            "precision": 0.7697095435684648,
            "recall": 0.7602459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8213001881466604,
            "auditor_fn_violation": 0.007458963933438746,
            "auditor_fp_violation": 0.008830933836834247,
            "ave_precision_score": 0.8217488130310571,
            "fpr": 0.13596491228070176,
            "logloss": 0.7603691528784844,
            "mae": 0.2718241297304314,
            "precision": 0.7432712215320911,
            "recall": 0.7703862660944206
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8519357929916196,
            "auditor_fn_violation": 0.008277698799733672,
            "auditor_fp_violation": 0.023471985426349356,
            "ave_precision_score": 0.852145686111003,
            "fpr": 0.12184412733260154,
            "logloss": 0.7430486477994696,
            "mae": 0.26470020644391534,
            "precision": 0.7697095435684648,
            "recall": 0.7602459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.8439985303230104,
            "auditor_fn_violation": 0.002560048189142384,
            "auditor_fp_violation": 0.01413146093934387,
            "ave_precision_score": 0.8443557628568306,
            "fpr": 0.43640350877192985,
            "logloss": 1.4460267881016666,
            "mae": 0.43177862457469934,
            "precision": 0.5361305361305362,
            "recall": 0.9871244635193133
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.860092898616299,
            "auditor_fn_violation": 0.0009537348617084453,
            "auditor_fp_violation": 0.016553653403502778,
            "ave_precision_score": 0.8602666090652907,
            "fpr": 0.4061470911086718,
            "logloss": 1.3133159340795448,
            "mae": 0.4018113796434342,
            "precision": 0.5667447306791569,
            "recall": 0.9918032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.8639756133244689,
            "auditor_fn_violation": 0.0011764927339808751,
            "auditor_fp_violation": 0.008376111242231145,
            "ave_precision_score": 0.864190075007806,
            "fpr": 0.4506578947368421,
            "logloss": 1.6244445317941798,
            "mae": 0.43973694785572764,
            "precision": 0.5302857142857142,
            "recall": 0.9957081545064378
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.8763503717541069,
            "auditor_fn_violation": 0.0011021935901819296,
            "auditor_fp_violation": 0.008150968073428782,
            "ave_precision_score": 0.8765113635828587,
            "fpr": 0.424807903402854,
            "logloss": 1.4830337253317152,
            "mae": 0.41265667573317094,
            "precision": 0.5567010309278351,
            "recall": 0.9959016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.8476023781500703,
            "auditor_fn_violation": 0.007586025148708681,
            "auditor_fp_violation": 0.015943375816222176,
            "ave_precision_score": 0.8481370405593808,
            "fpr": 0.3168859649122807,
            "logloss": 0.661494020667818,
            "mae": 0.3551800289713285,
            "precision": 0.605191256830601,
            "recall": 0.9506437768240343
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.8715035222928742,
            "auditor_fn_violation": 0.0031918626621799144,
            "auditor_fp_violation": 0.016224085448926038,
            "ave_precision_score": 0.8716768538901459,
            "fpr": 0.2897914379802415,
            "logloss": 0.6108278235559501,
            "mae": 0.3381150966730778,
            "precision": 0.6388508891928865,
            "recall": 0.9569672131147541
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.8226502996745962,
            "auditor_fn_violation": 0.010884910774791055,
            "auditor_fp_violation": 0.020798914326174176,
            "ave_precision_score": 0.8228906318422509,
            "fpr": 0.22916666666666666,
            "logloss": 1.0515290955885632,
            "mae": 0.293514614761885,
            "precision": 0.6623586429725363,
            "recall": 0.8798283261802575
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8555623868965083,
            "auditor_fn_violation": 0.010045707293372445,
            "auditor_fp_violation": 0.029515794609098665,
            "ave_precision_score": 0.8556757178188185,
            "fpr": 0.20636663007683864,
            "logloss": 0.9900067502783029,
            "mae": 0.27441919673584275,
            "precision": 0.6982343499197432,
            "recall": 0.8913934426229508
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6699561403508771,
            "auc_prc": 0.7564751909002724,
            "auditor_fn_violation": 0.011320213086363978,
            "auditor_fp_violation": 0.016019589332074584,
            "ave_precision_score": 0.6729608546950102,
            "fpr": 0.17105263157894737,
            "logloss": 8.102880408156885,
            "mae": 0.3299102772080476,
            "precision": 0.6729559748427673,
            "recall": 0.6888412017167382
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.797973309689364,
            "auditor_fn_violation": 0.015205772795162944,
            "auditor_fp_violation": 0.02447106938313702,
            "ave_precision_score": 0.7266673132655241,
            "fpr": 0.1437980241492865,
            "logloss": 7.3240806762529935,
            "mae": 0.3014331931346509,
            "precision": 0.7265135699373695,
            "recall": 0.7131147540983607
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6633771929824561,
            "auc_prc": 0.7020317469055745,
            "auditor_fn_violation": 0.007115428055116332,
            "auditor_fp_violation": 0.01775283219258911,
            "ave_precision_score": 0.6822651238691881,
            "fpr": 0.27960526315789475,
            "logloss": 2.291329443798676,
            "mae": 0.35232776387653836,
            "precision": 0.6188340807174888,
            "recall": 0.8884120171673819
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7118026546274995,
            "auditor_fn_violation": 0.012254593223083986,
            "auditor_fp_violation": 0.01761761294190004,
            "ave_precision_score": 0.693796066066837,
            "fpr": 0.26344676180021953,
            "logloss": 2.278517361272398,
            "mae": 0.3355025496914608,
            "precision": 0.6480938416422287,
            "recall": 0.9057377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7706454088402337,
            "auditor_fn_violation": 0.010776673443264818,
            "auditor_fp_violation": 0.021396329950436634,
            "ave_precision_score": 0.7302472261860433,
            "fpr": 0.1962719298245614,
            "logloss": 4.16450237746577,
            "mae": 0.31234956514026263,
            "precision": 0.6679035250463822,
            "recall": 0.7725321888412017
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.801403131119593,
            "auditor_fn_violation": 0.012277086969822396,
            "auditor_fp_violation": 0.03067317498501374,
            "ave_precision_score": 0.7629301677570891,
            "fpr": 0.17672886937431395,
            "logloss": 3.96736693350378,
            "mae": 0.2905164671754295,
            "precision": 0.7029520295202952,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 10102,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.814034094178395,
            "auditor_fn_violation": 0.008386040207815679,
            "auditor_fp_violation": 0.025347140272205183,
            "ave_precision_score": 0.8142899040334981,
            "fpr": 0.23903508771929824,
            "logloss": 1.0815174024415883,
            "mae": 0.3020917173454487,
            "precision": 0.6561514195583596,
            "recall": 0.8927038626609443
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8473788891121826,
            "auditor_fn_violation": 0.00992424106098505,
            "auditor_fp_violation": 0.032510451456197305,
            "ave_precision_score": 0.847556735327962,
            "fpr": 0.21075740944017562,
            "logloss": 0.9724292205344127,
            "mae": 0.27554550588460347,
            "precision": 0.6942675159235668,
            "recall": 0.8934426229508197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.8143748645394349,
            "auditor_fn_violation": 0.01006607183194037,
            "auditor_fp_violation": 0.019092714971284726,
            "ave_precision_score": 0.8147492822084599,
            "fpr": 0.20175438596491227,
            "logloss": 0.9542738650475728,
            "mae": 0.2843034687793361,
            "precision": 0.6816608996539792,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.846080503696923,
            "auditor_fn_violation": 0.008682586241024998,
            "auditor_fp_violation": 0.02748908143961511,
            "ave_precision_score": 0.8463010612115498,
            "fpr": 0.17453347969264543,
            "logloss": 0.910223278797267,
            "mae": 0.26437162895274685,
            "precision": 0.7225130890052356,
            "recall": 0.8483606557377049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.7595657282698317,
            "auditor_fn_violation": 0.009529591145245086,
            "auditor_fp_violation": 0.019579498072535607,
            "ave_precision_score": 0.7044297439537648,
            "fpr": 0.19956140350877194,
            "logloss": 4.988241920598346,
            "mae": 0.314610184303964,
            "precision": 0.6642066420664207,
            "recall": 0.7725321888412017
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8013065007306173,
            "auditor_fn_violation": 0.013077864353709676,
            "auditor_fp_violation": 0.026700194367242504,
            "ave_precision_score": 0.7517392101508702,
            "fpr": 0.17672886937431395,
            "logloss": 4.625413816941089,
            "mae": 0.29356070218318325,
            "precision": 0.7034990791896869,
            "recall": 0.7827868852459017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7621250031127412,
            "auditor_fn_violation": 0.011840222874783536,
            "auditor_fp_violation": 0.020031862166627345,
            "ave_precision_score": 0.6805612803755845,
            "fpr": 0.17543859649122806,
            "logloss": 7.707167933648865,
            "mae": 0.32328044590133515,
            "precision": 0.673469387755102,
            "recall": 0.7081545064377682
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8005001350156399,
            "auditor_fn_violation": 0.017803800543448923,
            "auditor_fp_violation": 0.02814302730223977,
            "ave_precision_score": 0.73178474402651,
            "fpr": 0.14818880351262348,
            "logloss": 7.0715952398031465,
            "mae": 0.2984164897753745,
            "precision": 0.7222222222222222,
            "recall": 0.7192622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8579233553911689,
            "auditor_fn_violation": 0.011357860853851369,
            "auditor_fp_violation": 0.004786700495633707,
            "ave_precision_score": 0.8582777331316653,
            "fpr": 0.10635964912280702,
            "logloss": 0.4724401005691737,
            "mae": 0.3049521182588171,
            "precision": 0.7872807017543859,
            "recall": 0.7703862660944206
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8795271163484275,
            "auditor_fn_violation": 0.009548595490453659,
            "auditor_fp_violation": 0.016089144239178104,
            "ave_precision_score": 0.8797126008089333,
            "fpr": 0.09769484083424808,
            "logloss": 0.46068538945715853,
            "mae": 0.3002090392921541,
            "precision": 0.8106382978723404,
            "recall": 0.7807377049180327
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8134617803130015,
            "auditor_fn_violation": 0.011437862359762067,
            "auditor_fp_violation": 0.02125619542128865,
            "ave_precision_score": 0.8139472185162463,
            "fpr": 0.18859649122807018,
            "logloss": 0.9281044471342476,
            "mae": 0.28287729891351004,
            "precision": 0.6934046345811051,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8477672328447703,
            "auditor_fn_violation": 0.00905148368753487,
            "auditor_fp_violation": 0.02920439181737265,
            "ave_precision_score": 0.8479609632397858,
            "fpr": 0.16575192096597147,
            "logloss": 0.8688681235281213,
            "mae": 0.2610730188755485,
            "precision": 0.7317939609236235,
            "recall": 0.8442622950819673
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6831140350877193,
            "auc_prc": 0.8598210845349027,
            "auditor_fn_violation": 0.004953034410059483,
            "auditor_fp_violation": 0.018291243804578715,
            "ave_precision_score": 0.8601456608569671,
            "fpr": 0.29605263157894735,
            "logloss": 0.6764521004682588,
            "mae": 0.3302927186157097,
            "precision": 0.6234309623430963,
            "recall": 0.9592274678111588
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8692353610923435,
            "auditor_fn_violation": 0.01124687336920336,
            "auditor_fp_violation": 0.016070979076327433,
            "ave_precision_score": 0.869424673746491,
            "fpr": 0.27771679473106475,
            "logloss": 0.6510639987010017,
            "mae": 0.31970870388228584,
            "precision": 0.6451612903225806,
            "recall": 0.9426229508196722
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8154162825243558,
            "auditor_fn_violation": 0.02080980347865372,
            "auditor_fp_violation": 0.019972858154354504,
            "ave_precision_score": 0.8160452676668585,
            "fpr": 0.1875,
            "logloss": 0.9136193457136865,
            "mae": 0.2814242637778307,
            "precision": 0.6951871657754011,
            "recall": 0.8369098712446352
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8435572632662254,
            "auditor_fn_violation": 0.008459898148314774,
            "auditor_fp_violation": 0.02173591486247675,
            "ave_precision_score": 0.8437720402684088,
            "fpr": 0.17453347969264543,
            "logloss": 0.9013400754632782,
            "mae": 0.26836730869885383,
            "precision": 0.7210526315789474,
            "recall": 0.8422131147540983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8157574059624804,
            "auditor_fn_violation": 0.008800165650176947,
            "auditor_fp_violation": 0.019682755094013064,
            "ave_precision_score": 0.8163679253617748,
            "fpr": 0.2050438596491228,
            "logloss": 0.986416977373819,
            "mae": 0.2843765531260461,
            "precision": 0.6781411359724613,
            "recall": 0.8454935622317596
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8486034534627097,
            "auditor_fn_violation": 0.009163952421226904,
            "auditor_fp_violation": 0.026523732785264417,
            "ave_precision_score": 0.8488192109203494,
            "fpr": 0.1756311745334797,
            "logloss": 0.9195652148403156,
            "mae": 0.26260454949548795,
            "precision": 0.7236614853195165,
            "recall": 0.8586065573770492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8161313288528231,
            "auditor_fn_violation": 0.02420280852345457,
            "auditor_fp_violation": 0.010861655259224294,
            "ave_precision_score": 0.8165571858165721,
            "fpr": 0.08771929824561403,
            "logloss": 0.8447545171891199,
            "mae": 0.29354023386785555,
            "precision": 0.7883597883597884,
            "recall": 0.6394849785407726
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8484277961926605,
            "auditor_fn_violation": 0.024761116409638125,
            "auditor_fp_violation": 0.01673011498548085,
            "ave_precision_score": 0.8488010593860846,
            "fpr": 0.08562019758507135,
            "logloss": 0.8096616839148514,
            "mae": 0.29037303933849495,
            "precision": 0.7989690721649485,
            "recall": 0.6352459016393442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.7653737944190118,
            "auditor_fn_violation": 0.01843799412694829,
            "auditor_fp_violation": 0.006121666273306585,
            "ave_precision_score": 0.7663071194399402,
            "fpr": 0.021929824561403508,
            "logloss": 0.8270263517114277,
            "mae": 0.3863960265237042,
            "precision": 0.875,
            "recall": 0.30042918454935624
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.8209293286675979,
            "auditor_fn_violation": 0.02457216893703552,
            "auditor_fp_violation": 0.0040170960132657595,
            "ave_precision_score": 0.821239808999521,
            "fpr": 0.01646542261251372,
            "logloss": 0.7885011318407201,
            "mae": 0.3808369580318534,
            "precision": 0.9085365853658537,
            "recall": 0.305327868852459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 10102,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0.8627748313743413,
            "auditor_fn_violation": 0.00034824184925834334,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8630608030601195,
            "fpr": 0.0,
            "logloss": 2.9544629788232553,
            "mae": 0.4918420860588633,
            "precision": 1.0,
            "recall": 0.01072961373390558
        },
        "train": {
            "accuracy": 0.47091108671789245,
            "auc_prc": 0.8841933731468258,
            "auditor_fn_violation": 0.0020739234492811107,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.8843453480157627,
            "fpr": 0.0,
            "logloss": 3.0392943218680273,
            "mae": 0.5153541565926445,
            "precision": 1.0,
            "recall": 0.012295081967213115
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8234046367581125,
            "auditor_fn_violation": 0.007317784805361048,
            "auditor_fp_violation": 0.01430847297616238,
            "ave_precision_score": 0.8238123098136244,
            "fpr": 0.1513157894736842,
            "logloss": 0.7645431371772525,
            "mae": 0.2761641958387854,
            "precision": 0.7288801571709234,
            "recall": 0.796137339055794
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.855162689128948,
            "auditor_fn_violation": 0.010428100987925357,
            "auditor_fp_violation": 0.022869940029012367,
            "ave_precision_score": 0.8553768791971794,
            "fpr": 0.13391877058177826,
            "logloss": 0.7058210708493963,
            "mae": 0.26094086952260664,
            "precision": 0.7607843137254902,
            "recall": 0.7950819672131147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8144601381890312,
            "auditor_fn_violation": 0.01431791657254725,
            "auditor_fp_violation": 0.018908327432932116,
            "ave_precision_score": 0.8151646006769653,
            "fpr": 0.2138157894736842,
            "logloss": 0.9493701908893311,
            "mae": 0.2892704635279136,
            "precision": 0.6760797342192691,
            "recall": 0.8733905579399142
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8478321290578721,
            "auditor_fn_violation": 0.013721185510428101,
            "auditor_fp_violation": 0.030008849029331548,
            "ave_precision_score": 0.8480468437902637,
            "fpr": 0.18990120746432493,
            "logloss": 0.8816967185562883,
            "mae": 0.2710825687117808,
            "precision": 0.7116666666666667,
            "recall": 0.875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8162963357461941,
            "auditor_fn_violation": 0.01509204879150667,
            "auditor_fp_violation": 0.0038426362992683536,
            "ave_precision_score": 0.8166807101431524,
            "fpr": 0.09758771929824561,
            "logloss": 0.8760800149625004,
            "mae": 0.28356854860248976,
            "precision": 0.7791563275434243,
            "recall": 0.6738197424892703
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8484104095272044,
            "auditor_fn_violation": 0.015032570945277223,
            "auditor_fp_violation": 0.02048251862577948,
            "ave_precision_score": 0.8486282251126831,
            "fpr": 0.0889132821075741,
            "logloss": 0.869747960548874,
            "mae": 0.2754781689167956,
            "precision": 0.8052884615384616,
            "recall": 0.6864754098360656
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8636620383455127,
            "auditor_fn_violation": 0.0017365032753557715,
            "auditor_fp_violation": 0.013497167807410927,
            "ave_precision_score": 0.8639763841552589,
            "fpr": 0.44627192982456143,
            "logloss": 1.4761249778404983,
            "mae": 0.4314890800517771,
            "precision": 0.532183908045977,
            "recall": 0.9935622317596566
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.8747444361108359,
            "auditor_fn_violation": 0.002870202083820698,
            "auditor_fp_violation": 0.01683910596258498,
            "ave_precision_score": 0.8749059116274472,
            "fpr": 0.4149286498353458,
            "logloss": 1.371120177880724,
            "mae": 0.4101694230517755,
            "precision": 0.5614849187935035,
            "recall": 0.9918032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8146201759252125,
            "auditor_fn_violation": 0.01194846020630977,
            "auditor_fp_violation": 0.01543938321139171,
            "ave_precision_score": 0.8150861917292466,
            "fpr": 0.16228070175438597,
            "logloss": 0.885050110310567,
            "mae": 0.2797325125087933,
            "precision": 0.7164750957854407,
            "recall": 0.8025751072961373
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8461570521813566,
            "auditor_fn_violation": 0.007944791348005258,
            "auditor_fp_violation": 0.02452037482516031,
            "ave_precision_score": 0.846369730412212,
            "fpr": 0.14928649835345773,
            "logloss": 0.8430561575959145,
            "mae": 0.2656020939670122,
            "precision": 0.7409523809523809,
            "recall": 0.7971311475409836
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 10102,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.8252667617579688,
            "auditor_fn_violation": 0.003416534899480461,
            "auditor_fp_violation": 0.019058295964125574,
            "ave_precision_score": 0.8243872371418688,
            "fpr": 0.3925438596491228,
            "logloss": 2.1821673348044093,
            "mae": 0.3928430316696844,
            "precision": 0.5618115055079559,
            "recall": 0.9849785407725322
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.8571805493548584,
            "auditor_fn_violation": 0.00478217055658527,
            "auditor_fp_violation": 0.011420697386552079,
            "ave_precision_score": 0.857041967734473,
            "fpr": 0.34796926454445665,
            "logloss": 1.9037484361963353,
            "mae": 0.35603709714863946,
            "precision": 0.6007556675062973,
            "recall": 0.9774590163934426
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8227379718337389,
            "auditor_fn_violation": 0.010461373390557943,
            "auditor_fp_violation": 0.019407403036739823,
            "ave_precision_score": 0.8232616471855797,
            "fpr": 0.2225877192982456,
            "logloss": 0.9318047546689098,
            "mae": 0.285419430514036,
            "precision": 0.6720516962843296,
            "recall": 0.8927038626609443
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8543687250821344,
            "auditor_fn_violation": 0.009114466178402406,
            "auditor_fp_violation": 0.026912986274921953,
            "ave_precision_score": 0.8545689574678698,
            "fpr": 0.1964873765093304,
            "logloss": 0.8733244671345118,
            "mae": 0.26924982725880686,
            "precision": 0.7103559870550162,
            "recall": 0.8995901639344263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7698030893993459,
            "auditor_fn_violation": 0.008291920789097212,
            "auditor_fp_violation": 0.0110927543072929,
            "ave_precision_score": 0.7470065153630333,
            "fpr": 0.14802631578947367,
            "logloss": 3.8136700670159187,
            "mae": 0.31649440202850715,
            "precision": 0.6952595936794582,
            "recall": 0.6609442060085837
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7945199010865217,
            "auditor_fn_violation": 0.014524212268989216,
            "auditor_fp_violation": 0.0234953406357288,
            "ave_precision_score": 0.7692463602644789,
            "fpr": 0.11855104281009879,
            "logloss": 3.9193039796202607,
            "mae": 0.296493656055056,
            "precision": 0.7517241379310344,
            "recall": 0.6700819672131147
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7701204811939363,
            "auditor_fn_violation": 0.019292127851818393,
            "auditor_fp_violation": 0.023734363936747698,
            "ave_precision_score": 0.7683007772867637,
            "fpr": 0.14802631578947367,
            "logloss": 0.8922673505728566,
            "mae": 0.2895660741685753,
            "precision": 0.7352941176470589,
            "recall": 0.8047210300429185
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8006831849747171,
            "auditor_fn_violation": 0.015034820319951058,
            "auditor_fp_violation": 0.030143790239079496,
            "ave_precision_score": 0.8007031712053633,
            "fpr": 0.14270032930845225,
            "logloss": 0.8181695764476021,
            "mae": 0.2817254901693718,
            "precision": 0.7556390977443609,
            "recall": 0.8237704918032787
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.8128229312831246,
            "auditor_fn_violation": 0.008193095399442815,
            "auditor_fp_violation": 0.032970950357957676,
            "ave_precision_score": 0.8130919591193227,
            "fpr": 0.32127192982456143,
            "logloss": 1.5627486581995238,
            "mae": 0.3445057074274933,
            "precision": 0.6024423337856174,
            "recall": 0.9527896995708155
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.8449080315907898,
            "auditor_fn_violation": 0.009526101743715248,
            "auditor_fp_violation": 0.025651804968431547,
            "ave_precision_score": 0.8450786677689219,
            "fpr": 0.27771679473106475,
            "logloss": 1.3702636768068144,
            "mae": 0.3103363714725665,
            "precision": 0.6446629213483146,
            "recall": 0.9405737704918032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6041666666666666,
            "auc_prc": 0.8555981486573728,
            "auditor_fn_violation": 0.012579060311723532,
            "auditor_fp_violation": 0.003643497757847534,
            "ave_precision_score": 0.8560753676395388,
            "fpr": 0.008771929824561403,
            "logloss": 1.119653553026526,
            "mae": 0.37965189846929837,
            "precision": 0.9338842975206612,
            "recall": 0.24248927038626608
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.8858018016847021,
            "auditor_fn_violation": 0.008151733817998618,
            "auditor_fp_violation": 0.0017827809826315094,
            "ave_precision_score": 0.8859431970722165,
            "fpr": 0.003293084522502744,
            "logloss": 1.1118834916932605,
            "mae": 0.392289703512764,
            "precision": 0.975609756097561,
            "recall": 0.2459016393442623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8092747842817429,
            "auditor_fn_violation": 0.012903772306302238,
            "auditor_fp_violation": 0.021831484540948794,
            "ave_precision_score": 0.8097687064468999,
            "fpr": 0.2149122807017544,
            "logloss": 1.0339204700287303,
            "mae": 0.29028528330726683,
            "precision": 0.6722408026755853,
            "recall": 0.8626609442060086
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8428485037754824,
            "auditor_fn_violation": 0.013012632488168294,
            "auditor_fp_violation": 0.029212176887165802,
            "ave_precision_score": 0.843075988700543,
            "fpr": 0.18990120746432493,
            "logloss": 0.9609409305327588,
            "mae": 0.27105465917462707,
            "precision": 0.7087542087542088,
            "recall": 0.8627049180327869
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7949740665704315,
            "auditor_fn_violation": 0.016748550560951737,
            "auditor_fp_violation": 0.022455943670836292,
            "ave_precision_score": 0.7953708481246597,
            "fpr": 0.13815789473684212,
            "logloss": 1.229026164264401,
            "mae": 0.28826496698979,
            "precision": 0.7272727272727273,
            "recall": 0.721030042918455
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8258941861774044,
            "auditor_fn_violation": 0.0156511489805834,
            "auditor_fp_violation": 0.026134479295606885,
            "ave_precision_score": 0.826179756158464,
            "fpr": 0.1207464324917673,
            "logloss": 1.1017677690541583,
            "mae": 0.2750012447724761,
            "precision": 0.7669491525423728,
            "recall": 0.7418032786885246
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6206140350877193,
            "auc_prc": 0.8407359075293016,
            "auditor_fn_violation": 0.02805229274903998,
            "auditor_fp_violation": 0.0036484147588702704,
            "ave_precision_score": 0.8413326510262994,
            "fpr": 0.007675438596491228,
            "logloss": 1.1269572668277388,
            "mae": 0.37762987887072585,
            "precision": 0.9477611940298507,
            "recall": 0.27253218884120173
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.8741003096717571,
            "auditor_fn_violation": 0.026691079879793425,
            "auditor_fp_violation": 0.0009679436776150698,
            "ave_precision_score": 0.8742519650777625,
            "fpr": 0.0043907793633369925,
            "logloss": 1.1103954852680218,
            "mae": 0.38838340879214367,
            "precision": 0.9710144927536232,
            "recall": 0.27459016393442626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8235067603933316,
            "auditor_fn_violation": 0.013176718620585804,
            "auditor_fp_violation": 0.018303536307135562,
            "ave_precision_score": 0.8239919969635747,
            "fpr": 0.2225877192982456,
            "logloss": 0.9615824037143952,
            "mae": 0.2845658828557685,
            "precision": 0.6709886547811994,
            "recall": 0.8884120171673819
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8557259480524229,
            "auditor_fn_violation": 0.011543790826150334,
            "auditor_fp_violation": 0.027294454694786342,
            "ave_precision_score": 0.8559235116602537,
            "fpr": 0.1964873765093304,
            "logloss": 0.904103893444609,
            "mae": 0.26668119470915547,
            "precision": 0.7089430894308943,
            "recall": 0.8934426229508197
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 10102,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7701710877639224,
            "auditor_fn_violation": 0.018708587455763873,
            "auditor_fp_violation": 0.01638590590826843,
            "ave_precision_score": 0.7305251450108874,
            "fpr": 0.15899122807017543,
            "logloss": 4.57644067869551,
            "mae": 0.31418780565797616,
            "precision": 0.696652719665272,
            "recall": 0.7145922746781116
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7980038480380003,
            "auditor_fn_violation": 0.017794803044753567,
            "auditor_fp_violation": 0.02521065101348633,
            "ave_precision_score": 0.7602634439816852,
            "fpr": 0.14050493962678376,
            "logloss": 4.533591670442805,
            "mae": 0.29444884433382956,
            "precision": 0.7305263157894737,
            "recall": 0.7110655737704918
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8170640305079625,
            "auditor_fn_violation": 0.010193133047210302,
            "auditor_fp_violation": 0.021730686019982695,
            "ave_precision_score": 0.8175808155738064,
            "fpr": 0.19846491228070176,
            "logloss": 0.9753773121867727,
            "mae": 0.28309063309922383,
            "precision": 0.6846689895470384,
            "recall": 0.8433476394849786
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8501186374474445,
            "auditor_fn_violation": 0.008284446923755198,
            "auditor_fp_violation": 0.027699278324030175,
            "ave_precision_score": 0.8503210516403755,
            "fpr": 0.1712403951701427,
            "logloss": 0.9075948487780643,
            "mae": 0.2613992708347956,
            "precision": 0.7267950963222417,
            "recall": 0.8504098360655737
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.8503155452245694,
            "auditor_fn_violation": 0.013517901513440253,
            "auditor_fp_violation": 0.011038667296042796,
            "ave_precision_score": 0.8507186174069932,
            "fpr": 0.2324561403508772,
            "logloss": 0.5676652481205745,
            "mae": 0.3327424732259605,
            "precision": 0.665086887835703,
            "recall": 0.9034334763948498
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8673562396130083,
            "auditor_fn_violation": 0.009449623004804664,
            "auditor_fp_violation": 0.017368490708519202,
            "ave_precision_score": 0.8675385568883776,
            "fpr": 0.20197585071350166,
            "logloss": 0.5264881329491921,
            "mae": 0.32194982685498913,
            "precision": 0.710236220472441,
            "recall": 0.9241803278688525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8618713823265035,
            "auditor_fn_violation": 0.00825427302160982,
            "auditor_fp_violation": 0.0148542600896861,
            "ave_precision_score": 0.8622000076353844,
            "fpr": 0.23684210526315788,
            "logloss": 0.6219177315967069,
            "mae": 0.30568625674908967,
            "precision": 0.660377358490566,
            "recall": 0.9012875536480687
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8888390272712872,
            "auditor_fn_violation": 0.004638210577459467,
            "auditor_fp_violation": 0.02208624300316852,
            "ave_precision_score": 0.8889848521812139,
            "fpr": 0.19209659714599342,
            "logloss": 0.5504903466845849,
            "mae": 0.27537048394644387,
            "precision": 0.7213375796178344,
            "recall": 0.9282786885245902
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 10102,
        "test": {
            "accuracy": 0.7785087719298246,
            "auc_prc": 0.8722760903340441,
            "auditor_fn_violation": 0.016729726677208043,
            "auditor_fp_violation": 0.015690150263551257,
            "ave_precision_score": 0.8725551367994526,
            "fpr": 0.13706140350877194,
            "logloss": 0.4870971941910545,
            "mae": 0.28775283006709,
            "precision": 0.7568093385214008,
            "recall": 0.8347639484978541
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.878811048511025,
            "auditor_fn_violation": 0.010747512191610735,
            "auditor_fp_violation": 0.020479923602515104,
            "ave_precision_score": 0.8789694485155741,
            "fpr": 0.1394072447859495,
            "logloss": 0.478991776024197,
            "mae": 0.2846186148753246,
            "precision": 0.7686703096539163,
            "recall": 0.8647540983606558
        }
    }
]