[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.5867834297743895,
            "auditor_fn_violation": 0.039642375168690985,
            "auditor_fp_violation": 0.011728010905642485,
            "ave_precision_score": 0.6107000706022354,
            "fpr": 0.08881578947368421,
            "logloss": 8.452692442022547,
            "mae": 0.44179979657962326,
            "precision": 0.6785714285714286,
            "recall": 0.36538461538461536
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6520226872823047,
            "auditor_fn_violation": 0.05081920559417814,
            "auditor_fp_violation": 0.006314973849034673,
            "ave_precision_score": 0.6719918879690234,
            "fpr": 0.07683863885839737,
            "logloss": 8.525142769540716,
            "mae": 0.4238117776287115,
            "precision": 0.7286821705426356,
            "recall": 0.3868312757201646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5638712613023427,
            "auditor_fn_violation": 0.04421577447893238,
            "auditor_fp_violation": 0.03429251620041094,
            "ave_precision_score": 0.5709122124968178,
            "fpr": 0.12938596491228072,
            "logloss": 9.228323601253434,
            "mae": 0.478987613059253,
            "precision": 0.6143790849673203,
            "recall": 0.4017094017094017
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.6170599510349002,
            "auditor_fn_violation": 0.06269057202097818,
            "auditor_fp_violation": 0.02334861496739201,
            "ave_precision_score": 0.6236594933662527,
            "fpr": 0.09879253567508232,
            "logloss": 9.280401837245492,
            "mae": 0.45357212255333884,
            "precision": 0.696969696969697,
            "recall": 0.42592592592592593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5274122807017544,
            "auc_prc": 0.5124671493564751,
            "auditor_fn_violation": 0.04466093117408908,
            "auditor_fp_violation": 0.028790303461356106,
            "ave_precision_score": 0.5365392264660914,
            "fpr": 0.12828947368421054,
            "logloss": 8.764965537571346,
            "mae": 0.48576637327866184,
            "precision": 0.5682656826568265,
            "recall": 0.32905982905982906
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5881680292264329,
            "auditor_fn_violation": 0.06010218048271469,
            "auditor_fp_violation": 0.027057532123716668,
            "ave_precision_score": 0.6078738490858648,
            "fpr": 0.10318331503841932,
            "logloss": 8.743947398788707,
            "mae": 0.45475077155199223,
            "precision": 0.6556776556776557,
            "recall": 0.3683127572016461
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8197544301741032,
            "auditor_fn_violation": 0.017571974808816917,
            "auditor_fp_violation": 0.01903301327643433,
            "ave_precision_score": 0.8200597315713435,
            "fpr": 0.13486842105263158,
            "logloss": 1.0322109777299107,
            "mae": 0.26952381681279347,
            "precision": 0.7479508196721312,
            "recall": 0.7799145299145299
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8316393420732525,
            "auditor_fn_violation": 0.019961783957393182,
            "auditor_fp_violation": 0.02256860592755214,
            "ave_precision_score": 0.8311992792143303,
            "fpr": 0.13611416026344675,
            "logloss": 0.8320329269272694,
            "mae": 0.25428186315119955,
            "precision": 0.7596899224806202,
            "recall": 0.8065843621399177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.5586035490348698,
            "auditor_fn_violation": 0.033485155195681515,
            "auditor_fp_violation": 0.013874071439860917,
            "ave_precision_score": 0.5830549623591251,
            "fpr": 0.09429824561403509,
            "logloss": 8.539867755343563,
            "mae": 0.44995847911103826,
            "precision": 0.6504065040650406,
            "recall": 0.3418803418803419
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6316780952959054,
            "auditor_fn_violation": 0.04461700388032869,
            "auditor_fp_violation": 0.006183250468134566,
            "ave_precision_score": 0.651966227753418,
            "fpr": 0.07354555433589462,
            "logloss": 8.581429565460006,
            "mae": 0.4277769652692482,
            "precision": 0.7298387096774194,
            "recall": 0.3724279835390947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.8038158618827352,
            "auditor_fn_violation": 0.03384128055180688,
            "auditor_fp_violation": 0.024187015963331754,
            "ave_precision_score": 0.7995200057560933,
            "fpr": 0.09429824561403509,
            "logloss": 4.415940956672322,
            "mae": 0.3031658810265193,
            "precision": 0.7712765957446809,
            "recall": 0.6196581196581197
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7973163509627527,
            "auditor_fn_violation": 0.04062826089902563,
            "auditor_fp_violation": 0.02866920643120036,
            "ave_precision_score": 0.7937170303173713,
            "fpr": 0.09879253567508232,
            "logloss": 4.429478624265033,
            "mae": 0.314566620849827,
            "precision": 0.7709923664122137,
            "recall": 0.6234567901234568
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8079432935472557,
            "auditor_fn_violation": 0.027177987704303505,
            "auditor_fp_violation": 0.015602773826458036,
            "ave_precision_score": 0.8050866677465607,
            "fpr": 0.09539473684210527,
            "logloss": 3.9278820756446153,
            "mae": 0.302838789935532,
            "precision": 0.7774936061381074,
            "recall": 0.6495726495726496
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8126810099370212,
            "auditor_fn_violation": 0.029181517167856965,
            "auditor_fp_violation": 0.025838445147543104,
            "ave_precision_score": 0.8096217961799864,
            "fpr": 0.09989023051591657,
            "logloss": 3.9717812228994718,
            "mae": 0.3094008810460785,
            "precision": 0.7780487804878049,
            "recall": 0.6563786008230452
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 9271,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.753265643064073,
            "auditor_fn_violation": 0.014694856800119971,
            "auditor_fp_violation": 0.011760115378536433,
            "ave_precision_score": 0.7535287226019043,
            "fpr": 0.08442982456140351,
            "logloss": 3.155143282334105,
            "mae": 0.32859095147066425,
            "precision": 0.7755102040816326,
            "recall": 0.5683760683760684
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7857003430092062,
            "auditor_fn_violation": 0.020038577423624384,
            "auditor_fp_violation": 0.015496868341189386,
            "ave_precision_score": 0.785851665968134,
            "fpr": 0.08232711306256861,
            "logloss": 2.9027418129557474,
            "mae": 0.315809265381167,
            "precision": 0.7928176795580111,
            "recall": 0.5905349794238683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.8017169808899923,
            "auditor_fn_violation": 0.036812115759484176,
            "auditor_fp_violation": 0.023984510826616092,
            "ave_precision_score": 0.7974296187665677,
            "fpr": 0.09758771929824561,
            "logloss": 4.39317757063177,
            "mae": 0.3052996979769944,
            "precision": 0.7632978723404256,
            "recall": 0.6132478632478633
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.795152360836901,
            "auditor_fn_violation": 0.03796759315725044,
            "auditor_fp_violation": 0.029361399883773485,
            "ave_precision_score": 0.7915461063321542,
            "fpr": 0.10098792535675083,
            "logloss": 4.410646562539365,
            "mae": 0.3176657691939059,
            "precision": 0.766497461928934,
            "recall": 0.6213991769547325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6093689297087952,
            "auditor_fn_violation": 0.03527046783625734,
            "auditor_fp_violation": 0.009502923976608192,
            "ave_precision_score": 0.6330324897323722,
            "fpr": 0.08114035087719298,
            "logloss": 8.398246517385479,
            "mae": 0.4285925804730284,
            "precision": 0.6954732510288066,
            "recall": 0.3611111111111111
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6635476736653579,
            "auditor_fn_violation": 0.04744932760544421,
            "auditor_fp_violation": 0.006702395557564414,
            "ave_precision_score": 0.6834764717235111,
            "fpr": 0.07354555433589462,
            "logloss": 8.485826896021832,
            "mae": 0.41393101126344495,
            "precision": 0.7423076923076923,
            "recall": 0.39711934156378603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5627250455380826,
            "auditor_fn_violation": 0.04647435897435898,
            "auditor_fp_violation": 0.015484234234234237,
            "ave_precision_score": 0.5877683143533304,
            "fpr": 0.0625,
            "logloss": 9.36035508948148,
            "mae": 0.4547906641637237,
            "precision": 0.6779661016949152,
            "recall": 0.2564102564102564
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6175244344718409,
            "auditor_fn_violation": 0.06128118605249964,
            "auditor_fp_violation": 0.010984696842513077,
            "ave_precision_score": 0.6379809014526855,
            "fpr": 0.05159165751920966,
            "logloss": 9.381856550801983,
            "mae": 0.44628683240832995,
            "precision": 0.745945945945946,
            "recall": 0.2839506172839506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8251001800686216,
            "auditor_fn_violation": 0.006082246213825163,
            "auditor_fp_violation": 0.018052592065749964,
            "ave_precision_score": 0.8253713479499889,
            "fpr": 0.1425438596491228,
            "logloss": 0.8214516487578077,
            "mae": 0.281101142071741,
            "precision": 0.7389558232931727,
            "recall": 0.7863247863247863
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8413808295114387,
            "auditor_fn_violation": 0.011175707967999717,
            "auditor_fp_violation": 0.02124104087299025,
            "ave_precision_score": 0.8416161881614052,
            "fpr": 0.141602634467618,
            "logloss": 0.689506757053852,
            "mae": 0.26459968886404395,
            "precision": 0.7538167938931297,
            "recall": 0.8127572016460906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7993447954034671,
            "auditor_fn_violation": 0.02825104963262859,
            "auditor_fp_violation": 0.01582503556187767,
            "ave_precision_score": 0.7954529356226525,
            "fpr": 0.10526315789473684,
            "logloss": 4.245544336937043,
            "mae": 0.3069984417114473,
            "precision": 0.7581863979848866,
            "recall": 0.6431623931623932
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7922632869278035,
            "auditor_fn_violation": 0.03285856902151573,
            "auditor_fp_violation": 0.019538968166849614,
            "ave_precision_score": 0.7888657467066482,
            "fpr": 0.10428100987925357,
            "logloss": 4.329495661170614,
            "mae": 0.31302852687653,
            "precision": 0.7642679900744417,
            "recall": 0.6337448559670782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8245982386272785,
            "auditor_fn_violation": 0.016250562303193883,
            "auditor_fp_violation": 0.022749723407618144,
            "ave_precision_score": 0.8253050637412069,
            "fpr": 0.14912280701754385,
            "logloss": 0.9349563845422345,
            "mae": 0.2850077027208588,
            "precision": 0.7290836653386454,
            "recall": 0.782051282051282
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8388472766390294,
            "auditor_fn_violation": 0.019175780244203227,
            "auditor_fp_violation": 0.021393426745011945,
            "ave_precision_score": 0.8390949218697918,
            "fpr": 0.1437980241492865,
            "logloss": 0.6695135688045112,
            "mae": 0.2655993895196391,
            "precision": 0.75,
            "recall": 0.808641975308642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.6045952554184153,
            "auditor_fn_violation": 0.024488304093567257,
            "auditor_fp_violation": 0.006549312470365104,
            "ave_precision_score": 0.6245295164452044,
            "fpr": 0.0668859649122807,
            "logloss": 7.900536022513482,
            "mae": 0.43079982750532275,
            "precision": 0.7188940092165899,
            "recall": 0.3333333333333333
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6519182739772988,
            "auditor_fn_violation": 0.04112290116680896,
            "auditor_fp_violation": 0.0105120423581068,
            "ave_precision_score": 0.6687984680800021,
            "fpr": 0.06695938529088913,
            "logloss": 7.9854407736375,
            "mae": 0.4258143082470586,
            "precision": 0.7370689655172413,
            "recall": 0.35185185185185186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 9271,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8407531199292376,
            "auditor_fn_violation": 0.01339687359424202,
            "auditor_fp_violation": 0.013098624940730216,
            "ave_precision_score": 0.8409991539945283,
            "fpr": 0.13596491228070176,
            "logloss": 0.8766171148190205,
            "mae": 0.27333443043060274,
            "precision": 0.7489878542510121,
            "recall": 0.7905982905982906
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8558892289169515,
            "auditor_fn_violation": 0.01824070686127035,
            "auditor_fp_violation": 0.022919868276619102,
            "ave_precision_score": 0.8561161036332137,
            "fpr": 0.1394072447859495,
            "logloss": 0.6313736258519104,
            "mae": 0.25401947531260666,
            "precision": 0.7608286252354048,
            "recall": 0.831275720164609
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5846690135236677,
            "auditor_fn_violation": 0.025758172139751102,
            "auditor_fp_violation": 0.012794867235656713,
            "ave_precision_score": 0.6085444168193787,
            "fpr": 0.09100877192982457,
            "logloss": 8.452425121333592,
            "mae": 0.44089607795691427,
            "precision": 0.668,
            "recall": 0.35683760683760685
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6503079855443554,
            "auditor_fn_violation": 0.047921381559630126,
            "auditor_fp_violation": 0.005953380254406925,
            "ave_precision_score": 0.6703673843956495,
            "fpr": 0.07683863885839737,
            "logloss": 8.526372111412917,
            "mae": 0.41979434678675814,
            "precision": 0.7318007662835249,
            "recall": 0.39300411522633744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5893839626191344,
            "auditor_fn_violation": 0.04038742690058481,
            "auditor_fp_violation": 0.013296190927769876,
            "ave_precision_score": 0.6132935951302649,
            "fpr": 0.08771929824561403,
            "logloss": 8.45412312872673,
            "mae": 0.4413631203484319,
            "precision": 0.673469387755102,
            "recall": 0.3525641025641026
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6533072712932484,
            "auditor_fn_violation": 0.05182203791790326,
            "auditor_fp_violation": 0.005312843029637761,
            "ave_precision_score": 0.6732608309564748,
            "fpr": 0.07464324917672886,
            "logloss": 8.526426345902026,
            "mae": 0.42352377137215574,
            "precision": 0.7322834645669292,
            "recall": 0.38271604938271603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5890909462449383,
            "auditor_fn_violation": 0.055738304093567274,
            "auditor_fp_violation": 0.020383870712818084,
            "ave_precision_score": 0.5926181695152294,
            "fpr": 0.12390350877192982,
            "logloss": 9.881209610059027,
            "mae": 0.4439666618929093,
            "precision": 0.6220735785953178,
            "recall": 0.3974358974358974
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.665898100116113,
            "auditor_fn_violation": 0.05700107962578996,
            "auditor_fp_violation": 0.018330212436236844,
            "ave_precision_score": 0.6655416663480919,
            "fpr": 0.09769484083424808,
            "logloss": 9.46527664719826,
            "mae": 0.4195855700196353,
            "precision": 0.6952054794520548,
            "recall": 0.4176954732510288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8104389980458097,
            "auditor_fn_violation": 0.02863529014844805,
            "auditor_fp_violation": 0.012654101469890947,
            "ave_precision_score": 0.8076938191560417,
            "fpr": 0.10087719298245613,
            "logloss": 3.768383860091323,
            "mae": 0.30183552169246025,
            "precision": 0.7688442211055276,
            "recall": 0.6538461538461539
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8152766783406722,
            "auditor_fn_violation": 0.028905964141968537,
            "auditor_fp_violation": 0.024175114612255445,
            "ave_precision_score": 0.8125997396827305,
            "fpr": 0.10428100987925357,
            "logloss": 3.8337766041694543,
            "mae": 0.3056435939688908,
            "precision": 0.7732696897374701,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8214751155633465,
            "auditor_fn_violation": 0.013164923526765633,
            "auditor_fp_violation": 0.018025426742532005,
            "ave_precision_score": 0.8217301756704397,
            "fpr": 0.11513157894736842,
            "logloss": 1.1153318419551392,
            "mae": 0.2861515871014902,
            "precision": 0.7569444444444444,
            "recall": 0.6987179487179487
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8423941813735055,
            "auditor_fn_violation": 0.009016456388087077,
            "auditor_fp_violation": 0.02030864596112869,
            "ave_precision_score": 0.8429145289419226,
            "fpr": 0.11964873765093303,
            "logloss": 0.8459110076583894,
            "mae": 0.2680152365643176,
            "precision": 0.770042194092827,
            "recall": 0.7510288065843621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.7221685678212753,
            "auditor_fn_violation": 0.02749662618083671,
            "auditor_fp_violation": 0.06706377430061641,
            "ave_precision_score": 0.5757485276961417,
            "fpr": 0.3366228070175439,
            "logloss": 9.450953674650323,
            "mae": 0.38313344098360014,
            "precision": 0.584573748308525,
            "recall": 0.9230769230769231
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7216346220283155,
            "auditor_fn_violation": 0.016187610955265552,
            "auditor_fp_violation": 0.06496287208626593,
            "ave_precision_score": 0.5811700674672817,
            "fpr": 0.3205268935236004,
            "logloss": 9.3538205987228,
            "mae": 0.3664661724154626,
            "precision": 0.6080536912751678,
            "recall": 0.9320987654320988
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7385568868154825,
            "auditor_fn_violation": 0.020177312940470836,
            "auditor_fp_violation": 0.0564347241978821,
            "ave_precision_score": 0.6106245398525418,
            "fpr": 0.30701754385964913,
            "logloss": 7.852534838143732,
            "mae": 0.35466297278068387,
            "precision": 0.6089385474860335,
            "recall": 0.9316239316239316
        },
        "train": {
            "accuracy": 0.6739846322722283,
            "auc_prc": 0.7416749699701225,
            "auditor_fn_violation": 0.015047002118596216,
            "auditor_fp_violation": 0.05525150125912056,
            "ave_precision_score": 0.6201782981427141,
            "fpr": 0.2843029637760702,
            "logloss": 7.648947257892649,
            "mae": 0.3363176889705567,
            "precision": 0.6336633663366337,
            "recall": 0.9218106995884774
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8082876823951626,
            "auditor_fn_violation": 0.03587494376968062,
            "auditor_fp_violation": 0.019492354196301562,
            "ave_precision_score": 0.805387522559345,
            "fpr": 0.09539473684210527,
            "logloss": 3.8785810066431625,
            "mae": 0.3028379629918883,
            "precision": 0.7704485488126649,
            "recall": 0.6239316239316239
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.8052718534213884,
            "auditor_fn_violation": 0.03406467816761755,
            "auditor_fp_violation": 0.028640795505908184,
            "ave_precision_score": 0.8023313263552123,
            "fpr": 0.09769484083424808,
            "logloss": 3.9935292600270387,
            "mae": 0.3123280481528929,
            "precision": 0.7758186397984886,
            "recall": 0.6337448559670782
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8444067694595798,
            "auditor_fn_violation": 0.017122132253711207,
            "auditor_fp_violation": 0.019964042990358786,
            "ave_precision_score": 0.8446166534884043,
            "fpr": 0.1337719298245614,
            "logloss": 0.8816755977951626,
            "mae": 0.27225792513376096,
            "precision": 0.7468879668049793,
            "recall": 0.7692307692307693
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8565971270136739,
            "auditor_fn_violation": 0.019839817863967157,
            "auditor_fp_violation": 0.028829340737392652,
            "ave_precision_score": 0.8568072460573891,
            "fpr": 0.13391877058177826,
            "logloss": 0.6357141655241838,
            "mae": 0.2532547259157157,
            "precision": 0.76171875,
            "recall": 0.8024691358024691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6765350877192983,
            "auc_prc": 0.7534670282926075,
            "auditor_fn_violation": 0.009371719898035693,
            "auditor_fp_violation": 0.02214714714714716,
            "ave_precision_score": 0.7362334029095458,
            "fpr": 0.18311403508771928,
            "logloss": 1.7044949113280503,
            "mae": 0.3463358016967976,
            "precision": 0.6706114398422091,
            "recall": 0.7264957264957265
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7698827426324559,
            "auditor_fn_violation": 0.013194924403608395,
            "auditor_fp_violation": 0.02713501646542261,
            "ave_precision_score": 0.7544901810398792,
            "fpr": 0.16794731064763996,
            "logloss": 1.69269174377256,
            "mae": 0.3275924467963695,
            "precision": 0.7040618955512572,
            "recall": 0.7489711934156379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.631018738824205,
            "auditor_fn_violation": 0.024038461538461554,
            "auditor_fp_violation": 0.002607871028923661,
            "ave_precision_score": 0.6425471839943706,
            "fpr": 0.04276315789473684,
            "logloss": 9.579167538751452,
            "mae": 0.43997586763947644,
            "precision": 0.7796610169491526,
            "recall": 0.2948717948717949
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.6710167370948105,
            "auditor_fn_violation": 0.02946158745646489,
            "auditor_fp_violation": 0.002872086265900435,
            "ave_precision_score": 0.6743997330128877,
            "fpr": 0.036223929747530186,
            "logloss": 9.498560591729207,
            "mae": 0.4424978071465177,
            "precision": 0.8176795580110497,
            "recall": 0.3045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.5646941015662652,
            "auditor_fn_violation": 0.010627530364372473,
            "auditor_fp_violation": 0.002318930772878142,
            "ave_precision_score": 0.5960306615315853,
            "fpr": 0.03618421052631579,
            "logloss": 10.245605995007047,
            "mae": 0.460209813912156,
            "precision": 0.7555555555555555,
            "recall": 0.21794871794871795
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6083512036353051,
            "auditor_fn_violation": 0.00010841430526757663,
            "auditor_fp_violation": 0.009034674242913413,
            "ave_precision_score": 0.6386357405891068,
            "fpr": 0.030735455543358946,
            "logloss": 10.6692087976184,
            "mae": 0.463235710760398,
            "precision": 0.8055555555555556,
            "recall": 0.23868312757201646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.5972551088503593,
            "auditor_fn_violation": 0.006391512970460357,
            "auditor_fp_violation": 0.010058578315157267,
            "ave_precision_score": 0.6212788826630689,
            "fpr": 0.10635964912280702,
            "logloss": 8.417969427033084,
            "mae": 0.463382737069306,
            "precision": 0.6367041198501873,
            "recall": 0.36324786324786323
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.642733995472061,
            "auditor_fn_violation": 0.008370487819201074,
            "auditor_fp_violation": 0.007200878155872668,
            "ave_precision_score": 0.6629840161279056,
            "fpr": 0.07464324917672886,
            "logloss": 8.498839224150851,
            "mae": 0.44606148529601136,
            "precision": 0.728,
            "recall": 0.37448559670781895
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6034416207613964,
            "auditor_fn_violation": 0.0294365721997301,
            "auditor_fp_violation": 0.010964912280701757,
            "ave_precision_score": 0.6271169944743775,
            "fpr": 0.08771929824561403,
            "logloss": 8.397488066711103,
            "mae": 0.4316525661497976,
            "precision": 0.6774193548387096,
            "recall": 0.358974358974359
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6571525111871844,
            "auditor_fn_violation": 0.045493352847908314,
            "auditor_fp_violation": 0.005989539613869698,
            "ave_precision_score": 0.677100289178583,
            "fpr": 0.07244785949506037,
            "logloss": 8.50813684957604,
            "mae": 0.4176826361224799,
            "precision": 0.7380952380952381,
            "recall": 0.38271604938271603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7704909721272047,
            "auditor_fn_violation": 0.022590530814215026,
            "auditor_fp_violation": 0.03265024893314368,
            "ave_precision_score": 0.760944054783582,
            "fpr": 0.1962719298245614,
            "logloss": 1.4049045694720161,
            "mae": 0.2912757934591674,
            "precision": 0.6881533101045296,
            "recall": 0.844017094017094
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7765649928066061,
            "auditor_fn_violation": 0.01746825493623884,
            "auditor_fp_violation": 0.033390585652482735,
            "ave_precision_score": 0.7667759376423977,
            "fpr": 0.18880351262349068,
            "logloss": 1.4008788186400096,
            "mae": 0.2801481844230788,
            "precision": 0.7084745762711865,
            "recall": 0.8600823045267489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8383820348554338,
            "auditor_fn_violation": 0.013115721997300947,
            "auditor_fp_violation": 0.011350165955429117,
            "ave_precision_score": 0.8386210009614588,
            "fpr": 0.13157894736842105,
            "logloss": 0.8778496696572667,
            "mae": 0.27395499710484833,
            "precision": 0.754601226993865,
            "recall": 0.7884615384615384
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.856700356400637,
            "auditor_fn_violation": 0.016451870824355272,
            "auditor_fp_violation": 0.022377477884677477,
            "ave_precision_score": 0.8569201670308237,
            "fpr": 0.132821075740944,
            "logloss": 0.6258564638802454,
            "mae": 0.25343812615577976,
            "precision": 0.768642447418738,
            "recall": 0.8271604938271605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.840164799462464,
            "auditor_fn_violation": 0.013935747488379066,
            "auditor_fp_violation": 0.014121028923660506,
            "ave_precision_score": 0.8404089237782604,
            "fpr": 0.14364035087719298,
            "logloss": 0.8698449237535035,
            "mae": 0.27648946428587007,
            "precision": 0.7416173570019724,
            "recall": 0.8034188034188035
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8573052438784217,
            "auditor_fn_violation": 0.018945399845509615,
            "auditor_fp_violation": 0.022788144895718992,
            "ave_precision_score": 0.857522377921535,
            "fpr": 0.141602634467618,
            "logloss": 0.6214516833781905,
            "mae": 0.2553806943940029,
            "precision": 0.7597765363128491,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8094134710360854,
            "auditor_fn_violation": 0.018520861448493037,
            "auditor_fp_violation": 0.012007072862336023,
            "ave_precision_score": 0.8096929583875732,
            "fpr": 0.12938596491228072,
            "logloss": 0.8604981001212072,
            "mae": 0.29187186979984797,
            "precision": 0.7451403887688985,
            "recall": 0.7371794871794872
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8256614159508328,
            "auditor_fn_violation": 0.010245151847786318,
            "auditor_fp_violation": 0.02549234842125655,
            "ave_precision_score": 0.8259291309886124,
            "fpr": 0.12623490669593854,
            "logloss": 0.7323247248743922,
            "mae": 0.27921681605104953,
            "precision": 0.7614107883817427,
            "recall": 0.7551440329218106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8151725082649213,
            "auditor_fn_violation": 0.005018556005398115,
            "auditor_fp_violation": 0.02028508771929825,
            "ave_precision_score": 0.8154525376492919,
            "fpr": 0.1611842105263158,
            "logloss": 0.921141457822125,
            "mae": 0.2834438698910564,
            "precision": 0.72,
            "recall": 0.8076923076923077
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8432581556714379,
            "auditor_fn_violation": 0.012535404046563949,
            "auditor_fp_violation": 0.014647123393814169,
            "ave_precision_score": 0.8434927455631742,
            "fpr": 0.15806805708013172,
            "logloss": 0.681029520001856,
            "mae": 0.26155416619863125,
            "precision": 0.7391304347826086,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8231523730478167,
            "auditor_fn_violation": 0.015004123556755136,
            "auditor_fp_violation": 0.018344001896633478,
            "ave_precision_score": 0.8234025163015541,
            "fpr": 0.13486842105263158,
            "logloss": 1.0065922081910141,
            "mae": 0.2698929083988442,
            "precision": 0.7432150313152401,
            "recall": 0.7606837606837606
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8366698086015163,
            "auditor_fn_violation": 0.020892340077606573,
            "auditor_fp_violation": 0.023697294505068772,
            "ave_precision_score": 0.837071309037901,
            "fpr": 0.13721185510428102,
            "logloss": 0.7801637460144976,
            "mae": 0.2552404750212434,
            "precision": 0.7577519379844961,
            "recall": 0.8045267489711934
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8428886012257262,
            "auditor_fn_violation": 0.01135852451641926,
            "auditor_fp_violation": 0.014639639639639644,
            "ave_precision_score": 0.843103672717199,
            "fpr": 0.13596491228070176,
            "logloss": 1.0141114435974792,
            "mae": 0.28208091152828974,
            "precision": 0.7422037422037422,
            "recall": 0.7628205128205128
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8622209712674723,
            "auditor_fn_violation": 0.00788714070821645,
            "auditor_fp_violation": 0.017201523858720223,
            "ave_precision_score": 0.8624607320328415,
            "fpr": 0.12733260153677278,
            "logloss": 1.0245309078958569,
            "mae": 0.2685068484949525,
            "precision": 0.768,
            "recall": 0.7901234567901234
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8170240348460948,
            "auditor_fn_violation": 0.004482025041235568,
            "auditor_fp_violation": 0.02236693930772878,
            "ave_precision_score": 0.8172945655823446,
            "fpr": 0.14583333333333334,
            "logloss": 1.4165318010096102,
            "mae": 0.2857286369731186,
            "precision": 0.7274590163934426,
            "recall": 0.7585470085470085
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8412746491260209,
            "auditor_fn_violation": 0.012079160511896208,
            "auditor_fp_violation": 0.022377477884677477,
            "ave_precision_score": 0.8414433210580695,
            "fpr": 0.132821075740944,
            "logloss": 1.1672451957771517,
            "mae": 0.26825998362243025,
            "precision": 0.7570281124497992,
            "recall": 0.7757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7891036892736565,
            "auditor_fn_violation": 0.016081871345029242,
            "auditor_fp_violation": 0.028081535482851278,
            "ave_precision_score": 0.77906977959181,
            "fpr": 0.17653508771929824,
            "logloss": 1.343464516561638,
            "mae": 0.27155578093016314,
            "precision": 0.7078039927404719,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.7941533146703322,
            "auditor_fn_violation": 0.015458073026069129,
            "auditor_fp_violation": 0.02762316781817008,
            "ave_precision_score": 0.7848134146133696,
            "fpr": 0.16245883644346873,
            "logloss": 1.3284256339447498,
            "mae": 0.2583010680171955,
            "precision": 0.7375886524822695,
            "recall": 0.8559670781893004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.5840032524846483,
            "auditor_fn_violation": 0.0516006897585845,
            "auditor_fp_violation": 0.02370791844476055,
            "ave_precision_score": 0.593394356188101,
            "fpr": 0.10197368421052631,
            "logloss": 9.82888052609839,
            "mae": 0.43935621976326855,
            "precision": 0.654275092936803,
            "recall": 0.37606837606837606
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6672631268652556,
            "auditor_fn_violation": 0.057283408545757614,
            "auditor_fp_violation": 0.012513721185510432,
            "ave_precision_score": 0.6697931568925308,
            "fpr": 0.08781558726673985,
            "logloss": 9.487765564389585,
            "mae": 0.4178568444250334,
            "precision": 0.7037037037037037,
            "recall": 0.39094650205761317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.533265499765236,
            "auditor_fn_violation": 0.018059304243514793,
            "auditor_fp_violation": 0.008910226015489178,
            "ave_precision_score": 0.557123362931504,
            "fpr": 0.09649122807017543,
            "logloss": 8.721309131694786,
            "mae": 0.4626809502368208,
            "precision": 0.6333333333333333,
            "recall": 0.3247863247863248
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6034658629607479,
            "auditor_fn_violation": 0.039817412240878515,
            "auditor_fp_violation": 0.003938787370052303,
            "ave_precision_score": 0.6232801579173616,
            "fpr": 0.08232711306256861,
            "logloss": 8.716706165736944,
            "mae": 0.4382339970002886,
            "precision": 0.70703125,
            "recall": 0.3724279835390947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.7234114629139832,
            "auditor_fn_violation": 0.01752511620932674,
            "auditor_fp_violation": 0.018758890469416797,
            "ave_precision_score": 0.6914161776880619,
            "fpr": 0.2138157894736842,
            "logloss": 2.745551807759714,
            "mae": 0.3090157373762602,
            "precision": 0.6608695652173913,
            "recall": 0.811965811965812
        },
        "train": {
            "accuracy": 0.721185510428101,
            "auc_prc": 0.7410639215534229,
            "auditor_fn_violation": 0.014787259512225974,
            "auditor_fp_violation": 0.02758700845870731,
            "ave_precision_score": 0.7090648190525419,
            "fpr": 0.1942919868276619,
            "logloss": 2.6688240064790576,
            "mae": 0.2874918875807325,
            "precision": 0.6979522184300341,
            "recall": 0.8415637860082305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8397854534564201,
            "auditor_fn_violation": 0.015332133753186383,
            "auditor_fp_violation": 0.018746542595226807,
            "ave_precision_score": 0.8400106597952459,
            "fpr": 0.16337719298245615,
            "logloss": 0.9330437158119482,
            "mae": 0.28039979758452666,
            "precision": 0.718336483931947,
            "recall": 0.811965811965812
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8578800814082601,
            "auditor_fn_violation": 0.019155452561965557,
            "auditor_fp_violation": 0.024934461160973725,
            "ave_precision_score": 0.8580771549333719,
            "fpr": 0.15806805708013172,
            "logloss": 0.6924709301974515,
            "mae": 0.25923986102667046,
            "precision": 0.7405405405405405,
            "recall": 0.845679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8262761534848541,
            "auditor_fn_violation": 0.013410931174089074,
            "auditor_fp_violation": 0.018768768768768773,
            "ave_precision_score": 0.8275717014851638,
            "fpr": 0.14035087719298245,
            "logloss": 0.9095587702112231,
            "mae": 0.2691512249094898,
            "precision": 0.744,
            "recall": 0.7948717948717948
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8512801381401861,
            "auditor_fn_violation": 0.021700930104393945,
            "auditor_fp_violation": 0.02455995350939498,
            "ave_precision_score": 0.8515012521839675,
            "fpr": 0.1394072447859495,
            "logloss": 0.6603361428570587,
            "mae": 0.25392936509541786,
            "precision": 0.758095238095238,
            "recall": 0.8189300411522634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5556526337011092,
            "auditor_fn_violation": 0.0369480056980057,
            "auditor_fp_violation": 0.010537675833728468,
            "ave_precision_score": 0.5796738561132443,
            "fpr": 0.0537280701754386,
            "logloss": 10.007546352406106,
            "mae": 0.45808893706425163,
            "precision": 0.6918238993710691,
            "recall": 0.23504273504273504
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.60629232437315,
            "auditor_fn_violation": 0.057791600601699404,
            "auditor_fp_violation": 0.010625686059275522,
            "ave_precision_score": 0.6264013078451734,
            "fpr": 0.04500548847420417,
            "logloss": 10.064004278970822,
            "mae": 0.4527878388566067,
            "precision": 0.7530120481927711,
            "recall": 0.257201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7579202338210659,
            "auditor_fn_violation": 0.01421689908532014,
            "auditor_fp_violation": 0.006648095463884939,
            "ave_precision_score": 0.7582986999281356,
            "fpr": 0.14912280701754385,
            "logloss": 1.1799802731205773,
            "mae": 0.32977994585178394,
            "precision": 0.7030567685589519,
            "recall": 0.688034188034188
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7976837880833274,
            "auditor_fn_violation": 0.0031440148527598294,
            "auditor_fp_violation": 0.018867437205398085,
            "ave_precision_score": 0.7980000625283652,
            "fpr": 0.12403951701427003,
            "logloss": 0.9636254735652091,
            "mae": 0.305163108865154,
            "precision": 0.754880694143167,
            "recall": 0.7160493827160493
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8076377243640962,
            "auditor_fn_violation": 0.02843848403058931,
            "auditor_fp_violation": 0.015602773826458036,
            "ave_precision_score": 0.8047816158280574,
            "fpr": 0.09539473684210527,
            "logloss": 3.9269021904313264,
            "mae": 0.30298780448928325,
            "precision": 0.7769230769230769,
            "recall": 0.6474358974358975
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8124001258985829,
            "auditor_fn_violation": 0.030703834704322582,
            "auditor_fp_violation": 0.02799767546974882,
            "ave_precision_score": 0.8093414595561712,
            "fpr": 0.09879253567508232,
            "logloss": 3.97169119236464,
            "mae": 0.3094879016177015,
            "precision": 0.7788697788697788,
            "recall": 0.6522633744855967
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8232711576361134,
            "auditor_fn_violation": 0.011719335732493629,
            "auditor_fp_violation": 0.006062806227279912,
            "ave_precision_score": 0.8235532213809569,
            "fpr": 0.13706140350877194,
            "logloss": 1.0653860642872146,
            "mae": 0.27532298190547644,
            "precision": 0.7346072186836518,
            "recall": 0.7393162393162394
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8413232569583953,
            "auditor_fn_violation": 0.012420213847217147,
            "auditor_fp_violation": 0.023860011622651257,
            "ave_precision_score": 0.8415631234626127,
            "fpr": 0.13830954994511527,
            "logloss": 0.8421892371113652,
            "mae": 0.2579620236519054,
            "precision": 0.7543859649122807,
            "recall": 0.7962962962962963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.737645641877137,
            "auditor_fn_violation": 0.022773279352226724,
            "auditor_fp_violation": 0.0583585229966809,
            "ave_precision_score": 0.6097135405958021,
            "fpr": 0.3059210526315789,
            "logloss": 7.894183606009611,
            "mae": 0.35832603439510485,
            "precision": 0.6075949367088608,
            "recall": 0.9230769230769231
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7410464393977453,
            "auditor_fn_violation": 0.015932385611614787,
            "auditor_fp_violation": 0.057738748627881455,
            "ave_precision_score": 0.6195499479967367,
            "fpr": 0.2843029637760702,
            "logloss": 7.681580737903276,
            "mae": 0.336453734962377,
            "precision": 0.634180790960452,
            "recall": 0.9238683127572016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6163598045590857,
            "auditor_fn_violation": 0.02364484930274405,
            "auditor_fp_violation": 0.007374150466255732,
            "ave_precision_score": 0.6394677230547621,
            "fpr": 0.07675438596491228,
            "logloss": 8.373940667787208,
            "mae": 0.442954027046644,
            "precision": 0.6916299559471366,
            "recall": 0.33547008547008544
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6660870880384424,
            "auditor_fn_violation": 0.03297150058950279,
            "auditor_fp_violation": 0.006139342674501196,
            "ave_precision_score": 0.6854664688082804,
            "fpr": 0.07354555433589462,
            "logloss": 8.478137725828141,
            "mae": 0.4322710479856641,
            "precision": 0.728744939271255,
            "recall": 0.37037037037037035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.5879892009296472,
            "auditor_fn_violation": 0.047627080521817376,
            "auditor_fp_violation": 0.014610004741583695,
            "ave_precision_score": 0.592993235313026,
            "fpr": 0.10526315789473684,
            "logloss": 9.775790379443222,
            "mae": 0.4394482093934386,
            "precision": 0.6470588235294118,
            "recall": 0.37606837606837606
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6695202494863723,
            "auditor_fn_violation": 0.05406711748948608,
            "auditor_fp_violation": 0.009427261574223543,
            "ave_precision_score": 0.6713831337652636,
            "fpr": 0.08781558726673985,
            "logloss": 9.372129266405562,
            "mae": 0.41636906799029855,
            "precision": 0.706959706959707,
            "recall": 0.39711934156378603
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8454205885565229,
            "auditor_fn_violation": 0.020353032688559005,
            "auditor_fp_violation": 0.015894183657341552,
            "ave_precision_score": 0.8456306590309005,
            "fpr": 0.12938596491228072,
            "logloss": 0.8666145590726424,
            "mae": 0.2718529718864718,
            "precision": 0.7536534446764092,
            "recall": 0.7713675213675214
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.859339070089403,
            "auditor_fn_violation": 0.017143012020436096,
            "auditor_fp_violation": 0.026688190094918324,
            "ave_precision_score": 0.8595410963929639,
            "fpr": 0.12733260153677278,
            "logloss": 0.6208738652779285,
            "mae": 0.25296789804796604,
            "precision": 0.7721021611001965,
            "recall": 0.808641975308642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8294121802499033,
            "auditor_fn_violation": 0.011827110511321036,
            "auditor_fp_violation": 0.014926110320847168,
            "ave_precision_score": 0.829659978350259,
            "fpr": 0.1524122807017544,
            "logloss": 0.9133277820049641,
            "mae": 0.2754993784086583,
            "precision": 0.7321772639691715,
            "recall": 0.811965811965812
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8482082522727619,
            "auditor_fn_violation": 0.018773743862169283,
            "auditor_fp_violation": 0.024030477174404336,
            "ave_precision_score": 0.8484344085493876,
            "fpr": 0.150384193194292,
            "logloss": 0.6821940414149644,
            "mae": 0.25598316404478066,
            "precision": 0.7476979742173112,
            "recall": 0.8353909465020576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7755087240068785,
            "auditor_fn_violation": 0.014516794122057287,
            "auditor_fp_violation": 0.010135135135135141,
            "ave_precision_score": 0.773736847870192,
            "fpr": 0.12280701754385964,
            "logloss": 3.7544655733009065,
            "mae": 0.3197953996192852,
            "precision": 0.7307692307692307,
            "recall": 0.6495726495726496
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7934976018775416,
            "auditor_fn_violation": 0.016962321511656803,
            "auditor_fp_violation": 0.019546716601020215,
            "ave_precision_score": 0.7912929664007038,
            "fpr": 0.12294182217343579,
            "logloss": 3.606911259521565,
            "mae": 0.30576724507097297,
            "precision": 0.7488789237668162,
            "recall": 0.6872427983539094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6044840405220092,
            "auditor_fn_violation": 0.039253448792922474,
            "auditor_fp_violation": 0.02364370949897266,
            "ave_precision_score": 0.628338302060604,
            "fpr": 0.1162280701754386,
            "logloss": 8.345347582544417,
            "mae": 0.4646793637153747,
            "precision": 0.6357388316151202,
            "recall": 0.3952991452991453
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6638617304746186,
            "auditor_fn_violation": 0.05712078708785625,
            "auditor_fp_violation": 0.018128753147801383,
            "ave_precision_score": 0.6838266592255559,
            "fpr": 0.08562019758507135,
            "logloss": 8.443046833076187,
            "mae": 0.43859954249776667,
            "precision": 0.723404255319149,
            "recall": 0.41975308641975306
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8421306334108122,
            "auditor_fn_violation": 0.014132553606237813,
            "auditor_fp_violation": 0.02040362731152205,
            "ave_precision_score": 0.8423588232522972,
            "fpr": 0.13486842105263158,
            "logloss": 0.9121671532748635,
            "mae": 0.26714334109542426,
            "precision": 0.7474332648870636,
            "recall": 0.7777777777777778
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.859247131820609,
            "auditor_fn_violation": 0.01826781043758724,
            "auditor_fp_violation": 0.02227674824045975,
            "ave_precision_score": 0.8594862164236601,
            "fpr": 0.13721185510428102,
            "logloss": 0.6695696175416467,
            "mae": 0.2503538044013152,
            "precision": 0.7605363984674329,
            "recall": 0.8168724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8440807929621545,
            "auditor_fn_violation": 0.013286755885440102,
            "auditor_fp_violation": 0.015573138928402092,
            "ave_precision_score": 0.8443129095859516,
            "fpr": 0.14144736842105263,
            "logloss": 0.8750955212128353,
            "mae": 0.2693707506869468,
            "precision": 0.742,
            "recall": 0.7927350427350427
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8596027193683282,
            "auditor_fn_violation": 0.0162395594765396,
            "auditor_fp_violation": 0.024510880092981215,
            "ave_precision_score": 0.8598129806316392,
            "fpr": 0.13830954994511527,
            "logloss": 0.6390345790573574,
            "mae": 0.2498865819683891,
            "precision": 0.7618147448015122,
            "recall": 0.8292181069958847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8413474719546923,
            "auditor_fn_violation": 0.013143837156995047,
            "auditor_fp_violation": 0.015424964438122336,
            "ave_precision_score": 0.8415843005052881,
            "fpr": 0.12828947368421054,
            "logloss": 0.775631680639666,
            "mae": 0.27144326504584704,
            "precision": 0.7515923566878981,
            "recall": 0.7564102564102564
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8440651812981564,
            "auditor_fn_violation": 0.014757897304549343,
            "auditor_fp_violation": 0.025773874862788152,
            "ave_precision_score": 0.844332978776831,
            "fpr": 0.12843029637760703,
            "logloss": 0.7488117180470747,
            "mae": 0.2638949662543425,
            "precision": 0.7636363636363637,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.5840041586979053,
            "auditor_fn_violation": 0.027552856500224925,
            "auditor_fp_violation": 0.014313655761024186,
            "ave_precision_score": 0.6079147187641731,
            "fpr": 0.09210526315789473,
            "logloss": 8.445530085584243,
            "mae": 0.441588063499863,
            "precision": 0.6666666666666666,
            "recall": 0.358974358974359
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6503757090180964,
            "auditor_fn_violation": 0.04596088953937475,
            "auditor_fp_violation": 0.008190094918318588,
            "ave_precision_score": 0.6704349734411972,
            "fpr": 0.07903402854006586,
            "logloss": 8.520831301809961,
            "mae": 0.420367116951539,
            "precision": 0.7262357414448669,
            "recall": 0.39300411522633744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8454312979870444,
            "auditor_fn_violation": 0.016672289698605493,
            "auditor_fp_violation": 0.017568555397502773,
            "ave_precision_score": 0.845625336768743,
            "fpr": 0.1337719298245614,
            "logloss": 0.8889009123846799,
            "mae": 0.27174109912029837,
            "precision": 0.7484536082474227,
            "recall": 0.7756410256410257
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8630921859130087,
            "auditor_fn_violation": 0.01642928451075787,
            "auditor_fp_violation": 0.027091108671789245,
            "ave_precision_score": 0.8632804153148369,
            "fpr": 0.13391877058177826,
            "logloss": 0.6348137443289591,
            "mae": 0.2517752562876944,
            "precision": 0.7667304015296367,
            "recall": 0.8251028806584362
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 9271,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8407799389669883,
            "auditor_fn_violation": 0.021463581496476238,
            "auditor_fp_violation": 0.02518472419788209,
            "ave_precision_score": 0.8411521468729415,
            "fpr": 0.15899122807017543,
            "logloss": 0.6807451710229545,
            "mae": 0.27696941264540936,
            "precision": 0.7264150943396226,
            "recall": 0.8226495726495726
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.846087114690055,
            "auditor_fn_violation": 0.015157675055223536,
            "auditor_fp_violation": 0.02746561632336799,
            "ave_precision_score": 0.8463327616970453,
            "fpr": 0.15477497255762898,
            "logloss": 0.6591013273135887,
            "mae": 0.2652467999688279,
            "precision": 0.7436363636363637,
            "recall": 0.8415637860082305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 9271,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8371078631328972,
            "auditor_fn_violation": 0.016189646123856656,
            "auditor_fp_violation": 0.023060889837205632,
            "ave_precision_score": 0.837347147450638,
            "fpr": 0.15021929824561403,
            "logloss": 0.9513028196153664,
            "mae": 0.2764810834538797,
            "precision": 0.7303149606299213,
            "recall": 0.7927350427350427
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8533213519672861,
            "auditor_fn_violation": 0.019507799054085187,
            "auditor_fp_violation": 0.02485181119648738,
            "ave_precision_score": 0.853526691311401,
            "fpr": 0.1437980241492865,
            "logloss": 0.7192208849321133,
            "mae": 0.2564868106662024,
            "precision": 0.7546816479400749,
            "recall": 0.8292181069958847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8419357660297108,
            "auditor_fn_violation": 0.018621607437396912,
            "auditor_fp_violation": 0.02421171171171172,
            "ave_precision_score": 0.8422492075149844,
            "fpr": 0.14144736842105263,
            "logloss": 0.6773661122548952,
            "mae": 0.2691757532202465,
            "precision": 0.7465618860510805,
            "recall": 0.811965811965812
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8433159394609933,
            "auditor_fn_violation": 0.012765784445257555,
            "auditor_fp_violation": 0.023885839736553238,
            "ave_precision_score": 0.8436062577409912,
            "fpr": 0.141602634467618,
            "logloss": 0.6657809049643938,
            "mae": 0.26218799220334305,
            "precision": 0.7542857142857143,
            "recall": 0.8148148148148148
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 9271,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8122148389810968,
            "auditor_fn_violation": 0.0051099302744039565,
            "auditor_fp_violation": 0.021796467520151727,
            "ave_precision_score": 0.8125113882356592,
            "fpr": 0.1425438596491228,
            "logloss": 1.3989153541290809,
            "mae": 0.2823900641148397,
            "precision": 0.7308488612836439,
            "recall": 0.7542735042735043
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8401940014894327,
            "auditor_fn_violation": 0.011464812782046589,
            "auditor_fp_violation": 0.02212177955704785,
            "ave_precision_score": 0.8403683810026341,
            "fpr": 0.13391877058177826,
            "logloss": 1.1410047314874248,
            "mae": 0.2677511308646397,
            "precision": 0.756,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6105751401682505,
            "auditor_fn_violation": 0.02341055630529315,
            "auditor_fp_violation": 0.016817804646752015,
            "ave_precision_score": 0.6305001942203697,
            "fpr": 0.08991228070175439,
            "logloss": 7.8932279890675225,
            "mae": 0.4303685524838008,
            "precision": 0.6746031746031746,
            "recall": 0.36324786324786323
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6557418811434381,
            "auditor_fn_violation": 0.03995970601654222,
            "auditor_fp_violation": 0.00892361335313489,
            "ave_precision_score": 0.6725967737418519,
            "fpr": 0.08342480790340286,
            "logloss": 7.962280210110755,
            "mae": 0.4224291058452113,
            "precision": 0.7142857142857143,
            "recall": 0.39094650205761317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.840263733289474,
            "auditor_fn_violation": 0.019596266306792624,
            "auditor_fp_violation": 0.02475995732574681,
            "ave_precision_score": 0.8406358222921386,
            "fpr": 0.16447368421052633,
            "logloss": 0.69055271793577,
            "mae": 0.27897978260950385,
            "precision": 0.7211895910780669,
            "recall": 0.8290598290598291
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8451862902176475,
            "auditor_fn_violation": 0.014468792490502456,
            "auditor_fp_violation": 0.027395880415832637,
            "ave_precision_score": 0.8454309174722885,
            "fpr": 0.15697036223929747,
            "logloss": 0.6679187880777094,
            "mae": 0.2664363264467153,
            "precision": 0.7423423423423423,
            "recall": 0.8477366255144033
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.835239903920091,
            "auditor_fn_violation": 0.0196150097465887,
            "auditor_fp_violation": 0.021789058795637754,
            "ave_precision_score": 0.8354725402908703,
            "fpr": 0.15679824561403508,
            "logloss": 0.9112610271919318,
            "mae": 0.27434536774713336,
            "precision": 0.7201565557729941,
            "recall": 0.7863247863247863
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8319208605172645,
            "auditor_fn_violation": 0.012808698441092642,
            "auditor_fp_violation": 0.027674824045974048,
            "ave_precision_score": 0.8321750377679576,
            "fpr": 0.14818880351262348,
            "logloss": 0.8716726928296019,
            "mae": 0.2633233702712809,
            "precision": 0.7423664122137404,
            "recall": 0.8004115226337448
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6002607796851813,
            "auditor_fn_violation": 0.0420157632328685,
            "auditor_fp_violation": 0.02086296823138929,
            "ave_precision_score": 0.6202760706092352,
            "fpr": 0.10526315789473684,
            "logloss": 7.8916921390338315,
            "mae": 0.4390190643976955,
            "precision": 0.6457564575645757,
            "recall": 0.37393162393162394
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.651910103241985,
            "auditor_fn_violation": 0.04780393272892358,
            "auditor_fp_violation": 0.013639826951636855,
            "ave_precision_score": 0.6687588053226212,
            "fpr": 0.09110867178924259,
            "logloss": 7.964106530632933,
            "mae": 0.42454771157023885,
            "precision": 0.7035714285714286,
            "recall": 0.4053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8219728667234679,
            "auditor_fn_violation": 0.019954734592892487,
            "auditor_fp_violation": 0.021697684526631896,
            "ave_precision_score": 0.8221969493872865,
            "fpr": 0.10416666666666667,
            "logloss": 1.1208470514429176,
            "mae": 0.2851502307462878,
            "precision": 0.7716346153846154,
            "recall": 0.6858974358974359
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8255531743193463,
            "auditor_fn_violation": 0.015869143933542034,
            "auditor_fp_violation": 0.02594950603732163,
            "ave_precision_score": 0.8258120451335977,
            "fpr": 0.1119648737650933,
            "logloss": 0.9217288089277063,
            "mae": 0.2841360282845549,
            "precision": 0.7697516930022573,
            "recall": 0.7016460905349794
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.589199756943857,
            "auditor_fn_violation": 0.047121007647323444,
            "auditor_fp_violation": 0.030365892207997472,
            "ave_precision_score": 0.6137374017349111,
            "fpr": 0.07785087719298246,
            "logloss": 8.33348022581245,
            "mae": 0.4466340483851494,
            "precision": 0.6757990867579908,
            "recall": 0.3162393162393162
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6442214249003174,
            "auditor_fn_violation": 0.0590180374300389,
            "auditor_fp_violation": 0.023702460127849167,
            "ave_precision_score": 0.6662234193074061,
            "fpr": 0.06147091108671789,
            "logloss": 8.49195422898456,
            "mae": 0.4322513979270026,
            "precision": 0.75,
            "recall": 0.345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8352935279982077,
            "auditor_fn_violation": 0.012839256260308891,
            "auditor_fp_violation": 0.013086277066540225,
            "ave_precision_score": 0.8355369695161823,
            "fpr": 0.15021929824561403,
            "logloss": 0.9284991898865395,
            "mae": 0.2748187570599914,
            "precision": 0.732943469785575,
            "recall": 0.8034188034188035
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.852114589539296,
            "auditor_fn_violation": 0.015340624195362581,
            "auditor_fp_violation": 0.023973655323819978,
            "ave_precision_score": 0.85233957219063,
            "fpr": 0.14928649835345773,
            "logloss": 0.6897840259725937,
            "mae": 0.25410580906316715,
            "precision": 0.75,
            "recall": 0.8395061728395061
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8273909969908166,
            "auditor_fn_violation": 0.003992352676563206,
            "auditor_fp_violation": 0.02096175122490912,
            "ave_precision_score": 0.8277151455297316,
            "fpr": 0.15021929824561403,
            "logloss": 0.8752273111000443,
            "mae": 0.2807166307005494,
            "precision": 0.7287128712871287,
            "recall": 0.7863247863247863
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8614830535629543,
            "auditor_fn_violation": 0.014766931829988299,
            "auditor_fp_violation": 0.014528314069865055,
            "ave_precision_score": 0.8616632623093391,
            "fpr": 0.14270032930845225,
            "logloss": 0.6268615398930663,
            "mae": 0.26143353864282715,
            "precision": 0.7560975609756098,
            "recall": 0.8292181069958847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7446270138713245,
            "auditor_fn_violation": 0.022810766231818862,
            "auditor_fp_violation": 0.015061936936936941,
            "ave_precision_score": 0.7432967328413371,
            "fpr": 0.15679824561403508,
            "logloss": 1.321824398578883,
            "mae": 0.3184668605338424,
            "precision": 0.700836820083682,
            "recall": 0.7158119658119658
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7769149709458065,
            "auditor_fn_violation": 0.017023304558369815,
            "auditor_fp_violation": 0.020672822367146647,
            "ave_precision_score": 0.7765061061106042,
            "fpr": 0.1525795828759605,
            "logloss": 1.029157451614421,
            "mae": 0.29429211830554586,
            "precision": 0.7306201550387597,
            "recall": 0.7757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.5891482618363042,
            "auditor_fn_violation": 0.047528677462888,
            "auditor_fp_violation": 0.030375770507349457,
            "ave_precision_score": 0.6136820504922597,
            "fpr": 0.07894736842105263,
            "logloss": 8.334225948829033,
            "mae": 0.4469181009999215,
            "precision": 0.6712328767123288,
            "recall": 0.3141025641025641
        },
        "train": {
            "accuracy": 0.5894621295279913,
            "auc_prc": 0.6439254418025289,
            "auditor_fn_violation": 0.058638587361602365,
            "auditor_fp_violation": 0.022749402724866016,
            "ave_precision_score": 0.6659279237128577,
            "fpr": 0.06147091108671789,
            "logloss": 8.49326916722606,
            "mae": 0.43279641128741725,
            "precision": 0.75,
            "recall": 0.345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7419771384857727,
            "auditor_fn_violation": 0.009971509971509977,
            "auditor_fp_violation": 0.012540501027343135,
            "ave_precision_score": 0.7382441969376298,
            "fpr": 0.15899122807017543,
            "logloss": 1.4083755532403692,
            "mae": 0.3140402828379066,
            "precision": 0.7105788423153693,
            "recall": 0.7606837606837606
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7341328525398082,
            "auditor_fn_violation": 0.005594629878079082,
            "auditor_fp_violation": 0.015930780654742693,
            "ave_precision_score": 0.7300642310770195,
            "fpr": 0.16245883644346873,
            "logloss": 1.5729322834020005,
            "mae": 0.31082321469064994,
            "precision": 0.7180952380952381,
            "recall": 0.7757201646090535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8420079214155004,
            "auditor_fn_violation": 0.013553849902534115,
            "auditor_fp_violation": 0.015103919709182867,
            "ave_precision_score": 0.8422474182134486,
            "fpr": 0.14035087719298245,
            "logloss": 0.8925917363675507,
            "mae": 0.2689327535106825,
            "precision": 0.7434869739478958,
            "recall": 0.7927350427350427
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8593967912691218,
            "auditor_fn_violation": 0.016668699434890438,
            "auditor_fp_violation": 0.0237980241492865,
            "ave_precision_score": 0.8596081036870482,
            "fpr": 0.13391877058177826,
            "logloss": 0.6485381136610565,
            "mae": 0.2487944388396421,
            "precision": 0.7676190476190476,
            "recall": 0.8292181069958847
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8301507992982948,
            "auditor_fn_violation": 0.030504948268106166,
            "auditor_fp_violation": 0.028355658289868822,
            "ave_precision_score": 0.8303557904635626,
            "fpr": 0.1206140350877193,
            "logloss": 1.4956552656798872,
            "mae": 0.27705604685019375,
            "precision": 0.759825327510917,
            "recall": 0.7435897435897436
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8246540603212318,
            "auditor_fn_violation": 0.02767952731362903,
            "auditor_fp_violation": 0.025686059275521412,
            "ave_precision_score": 0.8248752032333514,
            "fpr": 0.13062568605927552,
            "logloss": 1.5344874436782847,
            "mae": 0.2772859803199416,
            "precision": 0.7571428571428571,
            "recall": 0.7633744855967078
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 9271,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7477093978027297,
            "auditor_fn_violation": 0.0135233918128655,
            "auditor_fp_violation": 0.01547435593488225,
            "ave_precision_score": 0.7479456996246016,
            "fpr": 0.07675438596491228,
            "logloss": 3.322603133562121,
            "mae": 0.3385279362575269,
            "precision": 0.779874213836478,
            "recall": 0.5299145299145299
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7813285136719088,
            "auditor_fn_violation": 0.026448573222570056,
            "auditor_fp_violation": 0.009453089688125528,
            "ave_precision_score": 0.7814807245739527,
            "fpr": 0.07244785949506037,
            "logloss": 3.073688367070673,
            "mae": 0.3245017979664867,
            "precision": 0.8064516129032258,
            "recall": 0.565843621399177
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7635453055212532,
            "auditor_fn_violation": 0.023426956815114718,
            "auditor_fp_violation": 0.01820570570570571,
            "ave_precision_score": 0.7622277022858801,
            "fpr": 0.1524122807017544,
            "logloss": 1.2007816465780201,
            "mae": 0.30956430204281987,
            "precision": 0.7128099173553719,
            "recall": 0.7371794871794872
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.791072151527461,
            "auditor_fn_violation": 0.018782778387608244,
            "auditor_fp_violation": 0.02105507845289598,
            "ave_precision_score": 0.7906614212525163,
            "fpr": 0.1437980241492865,
            "logloss": 0.9135733908398264,
            "mae": 0.28545494002674,
            "precision": 0.7426326129666012,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 9271,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5466686186721874,
            "auditor_fn_violation": 0.0024600764732343756,
            "auditor_fp_violation": 0.004971254148885728,
            "ave_precision_score": 0.579892145195587,
            "fpr": 0.04276315789473684,
            "logloss": 10.243936988199952,
            "mae": 0.4647044905570495,
            "precision": 0.723404255319149,
            "recall": 0.21794871794871795
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.5995426414777768,
            "auditor_fn_violation": 0.012765784445257559,
            "auditor_fp_violation": 0.006702395557564411,
            "ave_precision_score": 0.6290731132886044,
            "fpr": 0.04061470911086718,
            "logloss": 10.701109159921039,
            "mae": 0.4670701267081073,
            "precision": 0.7549668874172185,
            "recall": 0.2345679012345679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.6105603534730881,
            "auditor_fn_violation": 0.02341055630529315,
            "auditor_fp_violation": 0.016817804646752015,
            "ave_precision_score": 0.6304854246861817,
            "fpr": 0.08991228070175439,
            "logloss": 7.893375445182478,
            "mae": 0.43036516036821093,
            "precision": 0.6746031746031746,
            "recall": 0.36324786324786323
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6557060475065022,
            "auditor_fn_violation": 0.03995970601654222,
            "auditor_fp_violation": 0.00892361335313489,
            "ave_precision_score": 0.672561314078723,
            "fpr": 0.08342480790340286,
            "logloss": 7.962431779695314,
            "mae": 0.4224369991310555,
            "precision": 0.7142857142857143,
            "recall": 0.39094650205761317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7571920630320733,
            "auditor_fn_violation": 0.01909956515219674,
            "auditor_fp_violation": 0.013943219535324803,
            "ave_precision_score": 0.7558016498820221,
            "fpr": 0.1513157894736842,
            "logloss": 1.2539739920088833,
            "mae": 0.3085422552711467,
            "precision": 0.7148760330578512,
            "recall": 0.7393162393162394
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7894030480782932,
            "auditor_fn_violation": 0.017359840630971256,
            "auditor_fp_violation": 0.020546264609026928,
            "ave_precision_score": 0.7889357697877953,
            "fpr": 0.14818880351262348,
            "logloss": 0.9667494298413182,
            "mae": 0.28562920753978505,
            "precision": 0.7378640776699029,
            "recall": 0.7818930041152263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.5943372794173056,
            "auditor_fn_violation": 0.039126930574298995,
            "auditor_fp_violation": 0.010016595542911332,
            "ave_precision_score": 0.6180434885500087,
            "fpr": 0.09649122807017543,
            "logloss": 8.436042004079278,
            "mae": 0.43850521707350293,
            "precision": 0.6653992395437263,
            "recall": 0.37393162393162394
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6598685542956135,
            "auditor_fn_violation": 0.04411107045574664,
            "auditor_fp_violation": 0.011555498159746887,
            "ave_precision_score": 0.6798063904659664,
            "fpr": 0.07903402854006586,
            "logloss": 8.50736381997981,
            "mae": 0.41713224867692555,
            "precision": 0.7272727272727273,
            "recall": 0.3950617283950617
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8116528247914766,
            "auditor_fn_violation": 0.026756260308891895,
            "auditor_fp_violation": 0.012417022285443342,
            "ave_precision_score": 0.8091610831478628,
            "fpr": 0.09868421052631579,
            "logloss": 3.73077443514777,
            "mae": 0.3010420336040233,
            "precision": 0.7738693467336684,
            "recall": 0.6581196581196581
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8168157067041886,
            "auditor_fn_violation": 0.028905964141968537,
            "auditor_fp_violation": 0.024549622263834184,
            "ave_precision_score": 0.814470965833415,
            "fpr": 0.10428100987925357,
            "logloss": 3.7850975384774963,
            "mae": 0.30459079498403385,
            "precision": 0.7732696897374701,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8430101780713262,
            "auditor_fn_violation": 0.018865272154745844,
            "auditor_fp_violation": 0.01911450924608819,
            "ave_precision_score": 0.8432551442084136,
            "fpr": 0.12938596491228072,
            "logloss": 0.8598874221484181,
            "mae": 0.26892202350932887,
            "precision": 0.7546777546777547,
            "recall": 0.7756410256410257
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8613724219699096,
            "auditor_fn_violation": 0.021330514561396376,
            "auditor_fp_violation": 0.021264286175502037,
            "ave_precision_score": 0.8615881697713781,
            "fpr": 0.132821075740944,
            "logloss": 0.6127233485840139,
            "mae": 0.254184777390148,
            "precision": 0.7632093933463796,
            "recall": 0.8024691358024691
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5833333333333334,
            "auc_prc": 0.5700345303050495,
            "auditor_fn_violation": 0.017019043334832822,
            "auditor_fp_violation": 0.0054725778409988966,
            "ave_precision_score": 0.581058264032412,
            "fpr": 0.09649122807017543,
            "logloss": 9.901269322597077,
            "mae": 0.4571642845644897,
            "precision": 0.6666666666666666,
            "recall": 0.37606837606837606
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6107099190741608,
            "auditor_fn_violation": 0.026317572603705056,
            "auditor_fp_violation": 0.006539678439981923,
            "ave_precision_score": 0.6218966995271082,
            "fpr": 0.07354555433589462,
            "logloss": 10.09016518382175,
            "mae": 0.4517459019163913,
            "precision": 0.726530612244898,
            "recall": 0.3662551440329218
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 9271,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.578811982179336,
            "auditor_fn_violation": 0.03383659469185785,
            "auditor_fp_violation": 0.00903864390706496,
            "ave_precision_score": 0.6027184224535473,
            "fpr": 0.08223684210526316,
            "logloss": 8.601490234844277,
            "mae": 0.44871677937051924,
            "precision": 0.6666666666666666,
            "recall": 0.32051282051282054
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.626769871927459,
            "auditor_fn_violation": 0.048682540327862935,
            "auditor_fp_violation": 0.014709110867178923,
            "ave_precision_score": 0.6468077297179061,
            "fpr": 0.07683863885839737,
            "logloss": 8.676104678226446,
            "mae": 0.44288170284606776,
            "precision": 0.6995708154506438,
            "recall": 0.33539094650205764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8085595931394975,
            "auditor_fn_violation": 0.028569688109161797,
            "auditor_fp_violation": 0.015084163110478903,
            "ave_precision_score": 0.8057090692348697,
            "fpr": 0.09210526315789473,
            "logloss": 3.940963173874562,
            "mae": 0.3015415591931942,
            "precision": 0.7806788511749347,
            "recall": 0.6388888888888888
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8128708580430809,
            "auditor_fn_violation": 0.03287212080967418,
            "auditor_fp_violation": 0.024092464647769103,
            "ave_precision_score": 0.809829828026458,
            "fpr": 0.09220636663007684,
            "logloss": 3.9842142675778094,
            "mae": 0.3099569816061325,
            "precision": 0.7873417721518987,
            "recall": 0.6399176954732511
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8371210725940431,
            "auditor_fn_violation": 0.01589443694706853,
            "auditor_fp_violation": 0.01600284495021337,
            "ave_precision_score": 0.837365269362802,
            "fpr": 0.13267543859649122,
            "logloss": 0.9110362599755073,
            "mae": 0.2708009724134338,
            "precision": 0.7494824016563147,
            "recall": 0.7735042735042735
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8553999073756962,
            "auditor_fn_violation": 0.017685083546773995,
            "auditor_fp_violation": 0.02528055788726029,
            "ave_precision_score": 0.8556180236115908,
            "fpr": 0.12843029637760703,
            "logloss": 0.667135968531833,
            "mae": 0.25104367867157573,
            "precision": 0.7705882352941177,
            "recall": 0.808641975308642
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7024058994789983,
            "auditor_fn_violation": 0.024835057729794573,
            "auditor_fp_violation": 0.05305140666982773,
            "ave_precision_score": 0.6840589983161862,
            "fpr": 0.23574561403508773,
            "logloss": 2.047747045542102,
            "mae": 0.33732433327395145,
            "precision": 0.6570972886762361,
            "recall": 0.8803418803418803
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7226020547302512,
            "auditor_fn_violation": 0.02594263979798801,
            "auditor_fp_violation": 0.04688835797765869,
            "ave_precision_score": 0.7030832201295678,
            "fpr": 0.23819978046103182,
            "logloss": 1.918237262061004,
            "mae": 0.32565817429291427,
            "precision": 0.6630434782608695,
            "recall": 0.8786008230452675
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.5961225497618439,
            "auditor_fn_violation": 0.03847793897136003,
            "auditor_fp_violation": 0.011942863916548127,
            "ave_precision_score": 0.6198316302473807,
            "fpr": 0.09539473684210527,
            "logloss": 8.422962318995502,
            "mae": 0.43670091070903255,
            "precision": 0.6753731343283582,
            "recall": 0.38675213675213677
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6610552934812828,
            "auditor_fn_violation": 0.04207830223197952,
            "auditor_fp_violation": 0.013688900368050622,
            "ave_precision_score": 0.6809978992015633,
            "fpr": 0.07574094401756312,
            "logloss": 8.497491671491453,
            "mae": 0.4162019173784087,
            "precision": 0.7406015037593985,
            "recall": 0.4053497942386831
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8286764040139702,
            "auditor_fn_violation": 0.01701435747488379,
            "auditor_fp_violation": 0.020524636478583852,
            "ave_precision_score": 0.8289586015919512,
            "fpr": 0.12390350877192982,
            "logloss": 0.8520376161456615,
            "mae": 0.2777519982533686,
            "precision": 0.7554112554112554,
            "recall": 0.7457264957264957
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8389650640364673,
            "auditor_fn_violation": 0.01226210965203525,
            "auditor_fp_violation": 0.025582746819913477,
            "ave_precision_score": 0.8392567409482486,
            "fpr": 0.12843029637760703,
            "logloss": 0.7651808722567033,
            "mae": 0.2745252526010722,
            "precision": 0.7612244897959184,
            "recall": 0.7674897119341564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 9271,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.866045398151962,
            "auditor_fn_violation": 0.005444969260758739,
            "auditor_fp_violation": 0.01077228544333808,
            "ave_precision_score": 0.8662515668836964,
            "fpr": 0.1611842105263158,
            "logloss": 0.49408449546239064,
            "mae": 0.3014604569241208,
            "precision": 0.7332123411978222,
            "recall": 0.8632478632478633
        },
        "train": {
            "accuracy": 0.7881448957189902,
            "auc_prc": 0.8717045064658567,
            "auditor_fn_violation": 0.009811494626715996,
            "auditor_fp_violation": 0.01322915994059534,
            "ave_precision_score": 0.8719874812364913,
            "fpr": 0.1394072447859495,
            "logloss": 0.47984480283668746,
            "mae": 0.3014829506357451,
            "precision": 0.7678244972577697,
            "recall": 0.8641975308641975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8361008157423253,
            "auditor_fn_violation": 0.01687143874643875,
            "auditor_fp_violation": 0.01809704441283389,
            "ave_precision_score": 0.8363323941392402,
            "fpr": 0.12280701754385964,
            "logloss": 0.8050574999609889,
            "mae": 0.27486600382028,
            "precision": 0.7591397849462366,
            "recall": 0.7542735042735043
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8447565042255823,
            "auditor_fn_violation": 0.010611050128064401,
            "auditor_fp_violation": 0.024456641053787052,
            "ave_precision_score": 0.8449883841420581,
            "fpr": 0.12294182217343579,
            "logloss": 0.6807327777354087,
            "mae": 0.2637520122589299,
            "precision": 0.7714285714285715,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8319873984591646,
            "auditor_fn_violation": 0.011728707452391662,
            "auditor_fp_violation": 0.021208708708708716,
            "ave_precision_score": 0.8324237461509739,
            "fpr": 0.16666666666666666,
            "logloss": 0.7730685661864913,
            "mae": 0.2761540170460076,
            "precision": 0.7216117216117216,
            "recall": 0.8418803418803419
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8423709926038323,
            "auditor_fn_violation": 0.013474994692216304,
            "auditor_fp_violation": 0.027416542906954226,
            "ave_precision_score": 0.8426103610169441,
            "fpr": 0.17672886937431395,
            "logloss": 0.7266809811164987,
            "mae": 0.270758638674551,
            "precision": 0.7219343696027634,
            "recall": 0.8600823045267489
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8205188521718689,
            "auditor_fn_violation": 0.01425438596491228,
            "auditor_fp_violation": 0.01966028528528529,
            "ave_precision_score": 0.8207803276149447,
            "fpr": 0.13925438596491227,
            "logloss": 1.0084936445154693,
            "mae": 0.2693659815339523,
            "precision": 0.7413441955193483,
            "recall": 0.7777777777777778
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8339098480679492,
            "auditor_fn_violation": 0.017371133787769964,
            "auditor_fp_violation": 0.023413185252146966,
            "ave_precision_score": 0.8335670856843951,
            "fpr": 0.13830954994511527,
            "logloss": 0.8052491802176188,
            "mae": 0.2543084194358502,
            "precision": 0.7590822179732314,
            "recall": 0.8168724279835391
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7999216871274697,
            "auditor_fn_violation": 0.028101102114260017,
            "auditor_fp_violation": 0.0053639165481270765,
            "ave_precision_score": 0.7955424565012819,
            "fpr": 0.05921052631578947,
            "logloss": 4.5159964329886995,
            "mae": 0.3274932240666075,
            "precision": 0.8353658536585366,
            "recall": 0.5854700854700855
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.8041263353761949,
            "auditor_fn_violation": 0.021974224498922633,
            "auditor_fp_violation": 0.011899012074643252,
            "ave_precision_score": 0.7999605656947281,
            "fpr": 0.05598243688254665,
            "logloss": 4.543608463208743,
            "mae": 0.33892839693786786,
            "precision": 0.8454545454545455,
            "recall": 0.5740740740740741
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 9271,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.5911157592102299,
            "auditor_fn_violation": 0.03565002249212776,
            "auditor_fp_violation": 0.010619171803382331,
            "ave_precision_score": 0.6155482488945585,
            "fpr": 0.07675438596491228,
            "logloss": 8.3925782074555,
            "mae": 0.4395439342346482,
            "precision": 0.6846846846846847,
            "recall": 0.3247863247863248
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6436151386999073,
            "auditor_fn_violation": 0.043521567670854175,
            "auditor_fp_violation": 0.012911474139600957,
            "ave_precision_score": 0.6656056016436832,
            "fpr": 0.06256860592755215,
            "logloss": 8.540707782874682,
            "mae": 0.42813195501400597,
            "precision": 0.75,
            "recall": 0.35185185185185186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7964116314988356,
            "auditor_fn_violation": 0.007169365721997308,
            "auditor_fp_violation": 0.017669807965860596,
            "ave_precision_score": 0.7967526620386691,
            "fpr": 0.13486842105263158,
            "logloss": 1.3581887061088826,
            "mae": 0.28799486715037853,
            "precision": 0.7354838709677419,
            "recall": 0.7307692307692307
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8216678512368956,
            "auditor_fn_violation": 0.010452945932882516,
            "auditor_fp_violation": 0.018717634144766584,
            "ave_precision_score": 0.8219190050254617,
            "fpr": 0.132821075740944,
            "logloss": 1.1203164530868222,
            "mae": 0.2714409343846358,
            "precision": 0.7505154639175258,
            "recall": 0.7489711934156379
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 9271,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8384379188450972,
            "auditor_fn_violation": 0.012839256260308891,
            "auditor_fp_violation": 0.014298838311996215,
            "ave_precision_score": 0.8386731238441968,
            "fpr": 0.14692982456140352,
            "logloss": 0.9005028582954941,
            "mae": 0.2739111038190125,
            "precision": 0.7372549019607844,
            "recall": 0.8034188034188035
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8549656594698547,
            "auditor_fn_violation": 0.016137921065351245,
            "auditor_fp_violation": 0.0240924646477691,
            "ave_precision_score": 0.8551850741891148,
            "fpr": 0.1437980241492865,
            "logloss": 0.660020059555099,
            "mae": 0.2533679811766472,
            "precision": 0.7565055762081785,
            "recall": 0.8374485596707819
        }
    }
]