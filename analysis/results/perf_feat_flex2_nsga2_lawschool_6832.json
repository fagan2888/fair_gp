[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4769736842105263,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.064688969706573,
            "mae": 0.5230263157894737,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.47639956092206365,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.084518485589896,
            "mae": 0.5236004390779363,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5054824561403509,
            "auc_prc": 0.4837295882368162,
            "auditor_fn_violation": 0.013390065835448162,
            "auditor_fp_violation": 0.003145795523291,
            "ave_precision_score": 0.48527259201877565,
            "fpr": 0.4298245614035088,
            "logloss": 0.693227509422087,
            "mae": 0.49888494976779874,
            "precision": 0.5160493827160494,
            "recall": 0.8763102725366876
        },
        "train": {
            "accuracy": 0.5246981339187706,
            "auc_prc": 0.4888513952859995,
            "auditor_fn_violation": 0.014148066837419197,
            "auditor_fp_violation": 0.001957640107847271,
            "ave_precision_score": 0.4915755949377348,
            "fpr": 0.42371020856201974,
            "logloss": 0.6910430679829045,
            "mae": 0.497808990245593,
            "precision": 0.5269607843137255,
            "recall": 0.9014675052410901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6267658626867336,
            "auditor_fn_violation": 0.05590036411784178,
            "auditor_fp_violation": 0.0652021576930833,
            "ave_precision_score": 0.5485277343944726,
            "fpr": 0.36293859649122806,
            "logloss": 0.6962366175973598,
            "mae": 0.49118032538446416,
            "precision": 0.5447042640990372,
            "recall": 0.8301886792452831
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6756739509603399,
            "auditor_fn_violation": 0.04171240395170142,
            "auditor_fp_violation": 0.05949809547415865,
            "ave_precision_score": 0.5885637473245892,
            "fpr": 0.3754116355653128,
            "logloss": 0.6774634690753458,
            "mae": 0.4825847037013878,
            "precision": 0.549407114624506,
            "recall": 0.8742138364779874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7147845233180472,
            "auditor_fn_violation": 0.0029860421493986544,
            "auditor_fp_violation": 0.002883645896350079,
            "ave_precision_score": 0.5339385847134974,
            "fpr": 0.4616228070175439,
            "logloss": 0.6886339376376269,
            "mae": 0.4932579683760802,
            "precision": 0.5269662921348315,
            "recall": 0.9832285115303984
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7655584132389657,
            "auditor_fn_violation": 0.0024232131392001328,
            "auditor_fp_violation": 0.006075260386368367,
            "ave_precision_score": 0.5370386694572261,
            "fpr": 0.45993413830954993,
            "logloss": 0.6838237319241832,
            "mae": 0.49242574581723053,
            "precision": 0.5292134831460674,
            "recall": 0.9874213836477987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7537905724421073,
            "auditor_fn_violation": 0.00048273198720070657,
            "auditor_fp_violation": 0.015759225650332723,
            "ave_precision_score": 0.7550753043271623,
            "fpr": 0.375,
            "logloss": 0.6829728797211153,
            "mae": 0.49466079306837757,
            "precision": 0.5703517587939698,
            "recall": 0.9517819706498952
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7794264075642708,
            "auditor_fn_violation": 0.003171118429076717,
            "auditor_fp_violation": 0.006452118753382883,
            "ave_precision_score": 0.7805874287125685,
            "fpr": 0.36553238199780463,
            "logloss": 0.6826893080522433,
            "mae": 0.49452938075646613,
            "precision": 0.575796178343949,
            "recall": 0.9475890985324947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.6267658626867336,
            "auditor_fn_violation": 0.05590036411784178,
            "auditor_fp_violation": 0.0652021576930833,
            "ave_precision_score": 0.5485277343944726,
            "fpr": 0.36293859649122806,
            "logloss": 0.6962366175973598,
            "mae": 0.49118032538446416,
            "precision": 0.5447042640990372,
            "recall": 0.8301886792452831
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6756739509603399,
            "auditor_fn_violation": 0.04171240395170142,
            "auditor_fp_violation": 0.05949809547415865,
            "ave_precision_score": 0.5885637473245892,
            "fpr": 0.3754116355653128,
            "logloss": 0.6774634690753458,
            "mae": 0.4825847037013878,
            "precision": 0.549407114624506,
            "recall": 0.8742138364779874
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.7127753113559443,
            "auditor_fn_violation": 0.0991853323035051,
            "auditor_fp_violation": 0.10356170598911071,
            "ave_precision_score": 0.5492848096674736,
            "fpr": 0.29605263157894735,
            "logloss": 0.6885470142998219,
            "mae": 0.49037814427886095,
            "precision": 0.5595432300163132,
            "recall": 0.7190775681341719
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.7279461211905732,
            "auditor_fn_violation": 0.08217292951050174,
            "auditor_fp_violation": 0.10530788569809851,
            "ave_precision_score": 0.5580541920666809,
            "fpr": 0.3029637760702525,
            "logloss": 0.6840005679257802,
            "mae": 0.4879295725853854,
            "precision": 0.56875,
            "recall": 0.7631027253668763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.765512937217257,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5310258744345139,
            "fpr": 0.4769736842105263,
            "logloss": 0.6865249365848027,
            "mae": 0.49509899082936737,
            "precision": 0.5230263157894737,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.765795184410432,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.531590368820864,
            "fpr": 0.47639956092206365,
            "logloss": 0.6864773864780332,
            "mae": 0.4950738356220735,
            "precision": 0.5236004390779363,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7543856761800953,
            "auditor_fn_violation": 0.0014964691603221894,
            "auditor_fp_violation": 0.010251562815083708,
            "ave_precision_score": 0.7556631045024207,
            "fpr": 0.3607456140350877,
            "logloss": 0.682315818207317,
            "mae": 0.4943163336761165,
            "precision": 0.5787451984635084,
            "recall": 0.9475890985324947
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7796011105691626,
            "auditor_fn_violation": 0.00285814883085144,
            "auditor_fp_violation": 0.006191605922493661,
            "ave_precision_score": 0.7809368347223518,
            "fpr": 0.3545554335894621,
            "logloss": 0.6820157352355135,
            "mae": 0.4941772662847416,
            "precision": 0.5821474773609314,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.48462750742588534,
            "auditor_fn_violation": 0.0005976681746294458,
            "auditor_fp_violation": 0.0040683605565638315,
            "ave_precision_score": 0.4958240685871801,
            "fpr": 0.47039473684210525,
            "logloss": 0.6905916914994384,
            "mae": 0.49826811492573797,
            "precision": 0.5259668508287293,
            "recall": 0.9979035639412998
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.4730724590864488,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017730048005179834,
            "ave_precision_score": 0.49443829169691916,
            "fpr": 0.47091108671789245,
            "logloss": 0.6906942477656235,
            "mae": 0.4983374970739157,
            "precision": 0.5264900662251656,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7543856761800953,
            "auditor_fn_violation": 0.0014964691603221894,
            "auditor_fp_violation": 0.010251562815083708,
            "ave_precision_score": 0.7556631045024207,
            "fpr": 0.3607456140350877,
            "logloss": 0.6823146297242175,
            "mae": 0.4943157096899915,
            "precision": 0.5787451984635084,
            "recall": 0.9475890985324947
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.7796011105691626,
            "auditor_fn_violation": 0.00285814883085144,
            "auditor_fp_violation": 0.006191605922493661,
            "ave_precision_score": 0.7809368347223518,
            "fpr": 0.3545554335894621,
            "logloss": 0.6820145179168979,
            "mae": 0.4941766289534082,
            "precision": 0.5821474773609314,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.48786308219605645,
            "auditor_fn_violation": 0.0005976681746294458,
            "auditor_fp_violation": 0.0040683605565638315,
            "ave_precision_score": 0.49741210430487554,
            "fpr": 0.47039473684210525,
            "logloss": 0.6903718766305057,
            "mae": 0.49808584820283086,
            "precision": 0.5259668508287293,
            "recall": 0.9979035639412998
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.4798377680620486,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017730048005179834,
            "ave_precision_score": 0.4968132687632112,
            "fpr": 0.47091108671789245,
            "logloss": 0.6904986655381717,
            "mae": 0.4981904617387037,
            "precision": 0.5264900662251656,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.715436274895376,
            "auditor_fn_violation": 0.003071094928095921,
            "auditor_fp_violation": 0.007196511393426099,
            "ave_precision_score": 0.7107643247669506,
            "fpr": 0.4616228070175439,
            "logloss": 0.7169687333947388,
            "mae": 0.4822844160839277,
            "precision": 0.5274971941638609,
            "recall": 0.9853249475890985
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7618820208746233,
            "auditor_fn_violation": 0.0008537626539821931,
            "auditor_fp_violation": 0.00563011224814987,
            "ave_precision_score": 0.7553474243104782,
            "fpr": 0.4621295279912184,
            "logloss": 0.675393439405502,
            "mae": 0.4800640613936413,
            "precision": 0.529082774049217,
            "recall": 0.9916142557651991
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6297835680018877,
            "auditor_fn_violation": 0.0038204788701313034,
            "auditor_fp_violation": 0.011746319822544858,
            "ave_precision_score": 0.6292936777446261,
            "fpr": 0.4298245614035088,
            "logloss": 0.8770391056705288,
            "mae": 0.48557081612709324,
            "precision": 0.5447154471544715,
            "recall": 0.9832285115303984
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.6927307925558706,
            "auditor_fn_violation": 0.004418394327886282,
            "auditor_fp_violation": 0.010673438314102605,
            "ave_precision_score": 0.6911169831249351,
            "fpr": 0.424807903402854,
            "logloss": 0.7576517233363376,
            "mae": 0.48020059985858027,
            "precision": 0.548951048951049,
            "recall": 0.9874213836477987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5285087719298246,
            "auc_prc": 0.48462750742588534,
            "auditor_fn_violation": 0.0005976681746294458,
            "auditor_fp_violation": 0.0040683605565638315,
            "ave_precision_score": 0.4958240685871801,
            "fpr": 0.47039473684210525,
            "logloss": 0.6905920397130131,
            "mae": 0.49826838102257043,
            "precision": 0.5259668508287293,
            "recall": 0.9979035639412998
        },
        "train": {
            "accuracy": 0.5290889132821076,
            "auc_prc": 0.4730724590864488,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017730048005179834,
            "ave_precision_score": 0.49443829169691916,
            "fpr": 0.47091108671789245,
            "logloss": 0.6906945381807295,
            "mae": 0.4983377036619134,
            "precision": 0.5264900662251656,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.7147845233180472,
            "auditor_fn_violation": 0.0029860421493986544,
            "auditor_fp_violation": 0.002883645896350079,
            "ave_precision_score": 0.5339385847134974,
            "fpr": 0.4616228070175439,
            "logloss": 0.6887618147038034,
            "mae": 0.4931133057464633,
            "precision": 0.5269662921348315,
            "recall": 0.9832285115303984
        },
        "train": {
            "accuracy": 0.5334796926454446,
            "auc_prc": 0.7655584132389657,
            "auditor_fn_violation": 0.0024232131392001328,
            "auditor_fp_violation": 0.006075260386368367,
            "ave_precision_score": 0.5370386694572261,
            "fpr": 0.45993413830954993,
            "logloss": 0.6838220502369641,
            "mae": 0.4922735786595015,
            "precision": 0.5292134831460674,
            "recall": 0.9874213836477987
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6019736842105263,
            "auc_prc": 0.7537905724421073,
            "auditor_fn_violation": 0.00048273198720070657,
            "auditor_fp_violation": 0.010952308933252669,
            "ave_precision_score": 0.7550753043271623,
            "fpr": 0.37280701754385964,
            "logloss": 0.6829404596166123,
            "mae": 0.49464382231235504,
            "precision": 0.5717884130982368,
            "recall": 0.9517819706498952
        },
        "train": {
            "accuracy": 0.6092206366630076,
            "auc_prc": 0.7794264075642708,
            "auditor_fn_violation": 0.003171118429076717,
            "auditor_fp_violation": 0.00503320906281143,
            "ave_precision_score": 0.7805874287125685,
            "fpr": 0.3633369923161361,
            "logloss": 0.6826560717241034,
            "mae": 0.49451203178103226,
            "precision": 0.5772669220945083,
            "recall": 0.9475890985324947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7063650110996982,
            "auditor_fn_violation": 0.012665967854647098,
            "auditor_fp_violation": 0.0076300665456745355,
            "ave_precision_score": 0.7032681734260968,
            "fpr": 0.06469298245614036,
            "logloss": 3.697131190615943,
            "mae": 0.37323978627368704,
            "precision": 0.7862318840579711,
            "recall": 0.4549266247379455
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7422188228503467,
            "auditor_fn_violation": 0.009623815145427319,
            "auditor_fp_violation": 0.01111352795075043,
            "ave_precision_score": 0.7408372407108461,
            "fpr": 0.08122941822173436,
            "logloss": 3.9821875614603988,
            "mae": 0.37929745050884006,
            "precision": 0.7394366197183099,
            "recall": 0.44025157232704404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.6858889706327664,
            "auditor_fn_violation": 0.008544356173452504,
            "auditor_fp_violation": 0.009074410163339387,
            "ave_precision_score": 0.6866703088515916,
            "fpr": 0.16447368421052633,
            "logloss": 0.683734087441708,
            "mae": 0.4708911122339431,
            "precision": 0.6753246753246753,
            "recall": 0.6540880503144654
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7262010372162643,
            "auditor_fn_violation": 0.0075135716044524604,
            "auditor_fp_violation": 0.009636445492116332,
            "ave_precision_score": 0.7267372691739933,
            "fpr": 0.15148188803512624,
            "logloss": 0.642101650549337,
            "mae": 0.4663453399481541,
            "precision": 0.7025862068965517,
            "recall": 0.6834381551362684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.706369071504693,
            "auditor_fn_violation": 0.012665967854647098,
            "auditor_fp_violation": 0.0076300665456745355,
            "ave_precision_score": 0.7032721535195404,
            "fpr": 0.06469298245614036,
            "logloss": 3.7012553741444827,
            "mae": 0.3742136543809386,
            "precision": 0.7862318840579711,
            "recall": 0.4549266247379455
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7421270128312203,
            "auditor_fn_violation": 0.006505625398403411,
            "auditor_fp_violation": 0.01111352795075043,
            "ave_precision_score": 0.7407455233609876,
            "fpr": 0.08122941822173436,
            "logloss": 3.9872367553680497,
            "mae": 0.38013542190018323,
            "precision": 0.7375886524822695,
            "recall": 0.4360587002096436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.6846765750817237,
            "auditor_fn_violation": 0.006753650373312737,
            "auditor_fp_violation": 0.012628554143980664,
            "ave_precision_score": 0.6865018071766877,
            "fpr": 0.4375,
            "logloss": 0.7052450762265219,
            "mae": 0.4872950505661337,
            "precision": 0.537122969837587,
            "recall": 0.9706498951781971
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6440742907944295,
            "auditor_fn_violation": 0.001836395142527736,
            "auditor_fp_violation": 0.009206472858609831,
            "ave_precision_score": 0.6456088376076465,
            "fpr": 0.43029637760702527,
            "logloss": 0.699433370503353,
            "mae": 0.4879036033127363,
            "precision": 0.5431235431235432,
            "recall": 0.9769392033542977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6295984072975973,
            "auditor_fn_violation": 0.053528081209312586,
            "auditor_fp_violation": 0.06600120992135512,
            "ave_precision_score": 0.6312090266973648,
            "fpr": 0.3256578947368421,
            "logloss": 0.7027398554592102,
            "mae": 0.4802011424316126,
            "precision": 0.5676855895196506,
            "recall": 0.8176100628930818
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6506056449769654,
            "auditor_fn_violation": 0.040281028289229935,
            "auditor_fp_violation": 0.04996787851502629,
            "ave_precision_score": 0.6521206189570453,
            "fpr": 0.3413830954994512,
            "logloss": 0.6947757599164378,
            "mae": 0.4783411472381535,
            "precision": 0.5644257703081232,
            "recall": 0.8448637316561844
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.7110365722920102,
            "auditor_fn_violation": 0.0001494170436573683,
            "auditor_fp_violation": 0.005064025005041337,
            "ave_precision_score": 0.7120166575809685,
            "fpr": 0.3366228070175439,
            "logloss": 0.9027145199728884,
            "mae": 0.4928917785648975,
            "precision": 0.5320121951219512,
            "recall": 0.7316561844863732
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6684629603681002,
            "auditor_fn_violation": 0.00642968424589285,
            "auditor_fp_violation": 0.014042400360165313,
            "ave_precision_score": 0.6701411092642209,
            "fpr": 0.32930845225027444,
            "logloss": 0.8909845617394395,
            "mae": 0.49945969904980464,
            "precision": 0.53198127925117,
            "recall": 0.7148846960167715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6892711086869332,
            "auditor_fn_violation": 0.006647909080878298,
            "auditor_fp_violation": 0.006629360758217389,
            "ave_precision_score": 0.6899547176744661,
            "fpr": 0.1206140350877193,
            "logloss": 0.6932321949308823,
            "mae": 0.47275417615054993,
            "precision": 0.6594427244582043,
            "recall": 0.44654088050314467
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7287003935111978,
            "auditor_fn_violation": 0.0130204557849899,
            "auditor_fp_violation": 0.0011432213549702347,
            "ave_precision_score": 0.7292309866087802,
            "fpr": 0.10647639956092206,
            "logloss": 0.6448264656703231,
            "mae": 0.4682031266317671,
            "precision": 0.7024539877300614,
            "recall": 0.480083857442348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.42170061961195204,
            "auditor_fn_violation": 0.00483191731950422,
            "auditor_fp_violation": 0.01939655172413793,
            "ave_precision_score": 0.4286702670326886,
            "fpr": 0.0712719298245614,
            "logloss": 9.330529226204526,
            "mae": 0.5584730080838748,
            "precision": 0.43478260869565216,
            "recall": 0.10482180293501048
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.4459598232773575,
            "auditor_fn_violation": 0.009025490913526056,
            "auditor_fp_violation": 0.012889062002053756,
            "ave_precision_score": 0.4508202916129563,
            "fpr": 0.06586169045005488,
            "logloss": 8.329509356737004,
            "mae": 0.5481893985863405,
            "precision": 0.4690265486725664,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6636385495228327,
            "auditor_fn_violation": 0.0991853323035051,
            "auditor_fp_violation": 0.10356170598911071,
            "ave_precision_score": 0.5628565035897143,
            "fpr": 0.29605263157894735,
            "logloss": 0.6882958155156589,
            "mae": 0.4904523643485287,
            "precision": 0.5595432300163132,
            "recall": 0.7190775681341719
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6614066473011793,
            "auditor_fn_violation": 0.08217292951050174,
            "auditor_fp_violation": 0.10530788569809851,
            "ave_precision_score": 0.5572577884180979,
            "fpr": 0.3029637760702525,
            "logloss": 0.6837812620514716,
            "mae": 0.4880308030269279,
            "precision": 0.56875,
            "recall": 0.7631027253668763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6857365524562486,
            "auditor_fn_violation": 0.010109787046231939,
            "auditor_fp_violation": 0.008376184714660215,
            "ave_precision_score": 0.6865410857988794,
            "fpr": 0.06798245614035088,
            "logloss": 0.6904625936073312,
            "mae": 0.4721328840322013,
            "precision": 0.6630434782608695,
            "recall": 0.2557651991614256
        },
        "train": {
            "accuracy": 0.5686059275521405,
            "auc_prc": 0.7175514003267535,
            "auditor_fn_violation": 0.005633452768055032,
            "auditor_fp_violation": 0.005559293226160548,
            "ave_precision_score": 0.7181041398173267,
            "fpr": 0.04610318331503842,
            "logloss": 0.6504230277269653,
            "mae": 0.46814695566604936,
            "precision": 0.75,
            "recall": 0.2641509433962264
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6324342515341308,
            "auditor_fn_violation": 0.061203519805803824,
            "auditor_fp_violation": 0.08031357128453319,
            "ave_precision_score": 0.6339724067162026,
            "fpr": 0.34100877192982454,
            "logloss": 0.7016798854327623,
            "mae": 0.4816590961918496,
            "precision": 0.5563480741797432,
            "recall": 0.8176100628930818
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.649579864468006,
            "auditor_fn_violation": 0.057448331250704754,
            "auditor_fp_violation": 0.07658571377986413,
            "ave_precision_score": 0.6510634794851399,
            "fpr": 0.34906695938529086,
            "logloss": 0.6938562833342671,
            "mae": 0.4809981564920637,
            "precision": 0.5558659217877095,
            "recall": 0.8343815513626834
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.4234822293725009,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.430043230948448,
            "fpr": 0.0712719298245614,
            "logloss": 9.738841388087883,
            "mae": 0.5588304046713229,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.438033850279289,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.4431756826147305,
            "fpr": 0.06695938529088913,
            "logloss": 8.750733566430318,
            "mae": 0.5504349543168772,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7692324543799824,
            "auditor_fn_violation": 0.01784499246018611,
            "auditor_fp_violation": 0.015504638031861265,
            "ave_precision_score": 0.7696103355574062,
            "fpr": 0.09978070175438597,
            "logloss": 0.7020111970822991,
            "mae": 0.3700948408979455,
            "precision": 0.7242424242424242,
            "recall": 0.5010482180293501
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7911960202788877,
            "auditor_fn_violation": 0.011218579348148773,
            "auditor_fp_violation": 0.007524521086363799,
            "ave_precision_score": 0.7915088316803849,
            "fpr": 0.0801317233809001,
            "logloss": 0.6957241056679107,
            "mae": 0.3587198976506027,
            "precision": 0.7739938080495357,
            "recall": 0.5241090146750524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6008771929824561,
            "auc_prc": 0.6745759244301286,
            "auditor_fn_violation": 0.0110890433631248,
            "auditor_fp_violation": 0.006089937487396656,
            "ave_precision_score": 0.6751463671943138,
            "fpr": 0.30372807017543857,
            "logloss": 0.6892297122164123,
            "mae": 0.47445943754728087,
            "precision": 0.5847076461769115,
            "recall": 0.8176100628930818
        },
        "train": {
            "accuracy": 0.6322722283205269,
            "auc_prc": 0.7300762003797042,
            "auditor_fn_violation": 0.0026004091617247422,
            "auditor_fp_violation": 0.006267483446053621,
            "ave_precision_score": 0.7305238309630148,
            "fpr": 0.27661909989023054,
            "logloss": 0.647100384526906,
            "mae": 0.4680748377452693,
            "precision": 0.6099071207430341,
            "recall": 0.8259958071278826
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.5572296092878728,
            "auditor_fn_violation": 0.011206278274302105,
            "auditor_fp_violation": 0.010170901391409555,
            "ave_precision_score": 0.5589457246917728,
            "fpr": 0.14912280701754385,
            "logloss": 0.7170274577192972,
            "mae": 0.4941364045238547,
            "precision": 0.5853658536585366,
            "recall": 0.4025157232704403
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5546276132857855,
            "auditor_fn_violation": 0.010107077025039877,
            "auditor_fp_violation": 0.017649111980049273,
            "ave_precision_score": 0.556268261253544,
            "fpr": 0.150384193194292,
            "logloss": 0.7105050754916761,
            "mae": 0.49292728898619453,
            "precision": 0.5758513931888545,
            "recall": 0.389937106918239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.6910792959772478,
            "auditor_fn_violation": 0.0038572584501085005,
            "auditor_fp_violation": 0.001527525710828806,
            "ave_precision_score": 0.6929862273917782,
            "fpr": 0.4342105263157895,
            "logloss": 0.7020061003875689,
            "mae": 0.48515135059623343,
            "precision": 0.5389988358556461,
            "recall": 0.9706498951781971
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6542473457735862,
            "auditor_fn_violation": 0.0028995712776753724,
            "auditor_fp_violation": 0.00869556419997269,
            "ave_precision_score": 0.655770542772935,
            "fpr": 0.42590559824368823,
            "logloss": 0.7010352708760397,
            "mae": 0.4885616189627433,
            "precision": 0.5451348182883939,
            "recall": 0.9748427672955975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.7082043391820076,
            "auditor_fn_violation": 0.01306594578689913,
            "auditor_fp_violation": 0.009097096188747733,
            "ave_precision_score": 0.7051060280867056,
            "fpr": 0.06907894736842106,
            "logloss": 3.6873713368360383,
            "mae": 0.3682725129414469,
            "precision": 0.775,
            "recall": 0.4549266247379455
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7417341659565502,
            "auditor_fn_violation": 0.010489084034638375,
            "auditor_fp_violation": 0.008675330193690026,
            "ave_precision_score": 0.7403551335019923,
            "fpr": 0.0845225027442371,
            "logloss": 3.971822320516514,
            "mae": 0.37674452650287027,
            "precision": 0.7335640138408305,
            "recall": 0.4444444444444444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5252192982456141,
            "auc_prc": 0.5470870169040554,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0013964508973583357,
            "ave_precision_score": 0.5488608271534121,
            "fpr": 0.47478070175438597,
            "logloss": 0.691676228512301,
            "mae": 0.4973761337694892,
            "precision": 0.5241758241758242,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5744417087191404,
            "auditor_fn_violation": 0.0005315880675738183,
            "auditor_fp_violation": 0.0006323126963331048,
            "ave_precision_score": 0.5757017248757551,
            "fpr": 0.47530186608122943,
            "logloss": 0.6915502218656331,
            "mae": 0.4973762503832284,
            "precision": 0.5236523652365237,
            "recall": 0.9979035639412998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.4868339118735496,
            "auditor_fn_violation": 0.016118650925006434,
            "auditor_fp_violation": 0.007637628554143984,
            "ave_precision_score": 0.4937140024831047,
            "fpr": 0.10855263157894737,
            "logloss": 7.610430495964343,
            "mae": 0.545911895686557,
            "precision": 0.505,
            "recall": 0.21174004192872117
        },
        "train": {
            "accuracy": 0.49286498353457736,
            "auc_prc": 0.5181729220870119,
            "auditor_fn_violation": 0.008091184612941775,
            "auditor_fp_violation": 0.009737615523529619,
            "ave_precision_score": 0.5230060747815719,
            "fpr": 0.11525795828759605,
            "logloss": 6.93258432029284,
            "mae": 0.5234114460257284,
            "precision": 0.5333333333333333,
            "recall": 0.25157232704402516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 6832,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.5877522915931349,
            "auditor_fn_violation": 0.012799293832064448,
            "auditor_fp_violation": 0.01447368421052632,
            "ave_precision_score": 0.5906440531718131,
            "fpr": 0.13486842105263158,
            "logloss": 0.6899989734656067,
            "mae": 0.49816366402726425,
            "precision": 0.6132075471698113,
            "recall": 0.4088050314465409
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5527021886852574,
            "auditor_fn_violation": 0.02313673779821287,
            "auditor_fp_violation": 0.017424008660154693,
            "ave_precision_score": 0.5539452731079553,
            "fpr": 0.150384193194292,
            "logloss": 0.691373978982704,
            "mae": 0.49885375295590884,
            "precision": 0.5623003194888179,
            "recall": 0.3689727463312369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 6832,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6027339478262704,
            "auditor_fn_violation": 0.02184707050645482,
            "auditor_fp_violation": 0.03449788263762857,
            "ave_precision_score": 0.6043285849135623,
            "fpr": 0.39144736842105265,
            "logloss": 0.710847941111545,
            "mae": 0.48663295251562405,
            "precision": 0.5526315789473685,
            "recall": 0.9245283018867925
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.5803152377742193,
            "auditor_fn_violation": 0.020934444375407035,
            "auditor_fp_violation": 0.02351191530044971,
            "ave_precision_score": 0.5818778537427626,
            "fpr": 0.3995609220636663,
            "logloss": 0.7025624244394714,
            "mae": 0.4881230844419887,
            "precision": 0.5500618046971569,
            "recall": 0.9329140461215933
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.4868245318465843,
            "auditor_fn_violation": 0.01403370848504911,
            "auditor_fp_violation": 0.0036953014720709815,
            "ave_precision_score": 0.4937068388426911,
            "fpr": 0.1074561403508772,
            "logloss": 7.622857138569335,
            "mae": 0.5469891729717855,
            "precision": 0.5050505050505051,
            "recall": 0.20964360587002095
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5180710827848851,
            "auditor_fn_violation": 0.011124228219272026,
            "auditor_fp_violation": 0.011209639480593062,
            "ave_precision_score": 0.5228989320519833,
            "fpr": 0.11964873765093303,
            "logloss": 6.942413821139212,
            "mae": 0.5245687026802197,
            "precision": 0.5260869565217391,
            "recall": 0.25366876310272535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4215040647015052,
            "auditor_fn_violation": 0.00483191731950422,
            "auditor_fp_violation": 0.01939655172413793,
            "ave_precision_score": 0.42847313755553573,
            "fpr": 0.0712719298245614,
            "logloss": 9.335547835832628,
            "mae": 0.5586137003552486,
            "precision": 0.43478260869565216,
            "recall": 0.10482180293501048
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.44582415779827367,
            "auditor_fn_violation": 0.009025490913526056,
            "auditor_fp_violation": 0.012889062002053756,
            "ave_precision_score": 0.45068453601827807,
            "fpr": 0.06586169045005488,
            "logloss": 8.334873340700332,
            "mae": 0.5483361987752405,
            "precision": 0.4690265486725664,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6129385964912281,
            "auc_prc": 0.678833214809448,
            "auditor_fn_violation": 0.008250119533634925,
            "auditor_fp_violation": 0.013543557168784031,
            "ave_precision_score": 0.6791558327385054,
            "fpr": 0.05592105263157895,
            "logloss": 3.9784783250698896,
            "mae": 0.39758778595608496,
            "precision": 0.7743362831858407,
            "recall": 0.3668763102725367
        },
        "train": {
            "accuracy": 0.6180021953896817,
            "auc_prc": 0.7021736791234721,
            "auditor_fn_violation": 0.003774045155069533,
            "auditor_fp_violation": 0.006343360969613583,
            "ave_precision_score": 0.7034994606904494,
            "fpr": 0.048298572996706916,
            "logloss": 4.287258702737201,
            "mae": 0.39653012358714557,
            "precision": 0.7972350230414746,
            "recall": 0.36268343815513626
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7078860207044888,
            "auditor_fn_violation": 0.012737228290852911,
            "auditor_fp_violation": 0.007259528130671506,
            "ave_precision_score": 0.7047866871780386,
            "fpr": 0.06578947368421052,
            "logloss": 3.662276621696306,
            "mae": 0.37177051715083503,
            "precision": 0.7849462365591398,
            "recall": 0.4591194968553459
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.7434054616246863,
            "auditor_fn_violation": 0.00832361056456494,
            "auditor_fp_violation": 0.009848902558084245,
            "ave_precision_score": 0.7420216429945232,
            "fpr": 0.08342480790340286,
            "logloss": 3.937544150315231,
            "mae": 0.37867201510126614,
            "precision": 0.738831615120275,
            "recall": 0.45073375262054505
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.7545148597301157,
            "auditor_fn_violation": 0.00015631321490308677,
            "auditor_fp_violation": 0.010503629764065343,
            "ave_precision_score": 0.7557888906659427,
            "fpr": 0.3519736842105263,
            "logloss": 0.6820709165110769,
            "mae": 0.4941876706128058,
            "precision": 0.5831168831168831,
            "recall": 0.9412997903563941
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7796011105691626,
            "auditor_fn_violation": 0.0008031352189751629,
            "auditor_fp_violation": 0.004011391745537146,
            "ave_precision_score": 0.7809368347223518,
            "fpr": 0.3424807903402854,
            "logloss": 0.6817646882989078,
            "mae": 0.49404575135129475,
            "precision": 0.5883905013192612,
            "recall": 0.9350104821802935
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 6832,
        "test": {
            "accuracy": 0.44846491228070173,
            "auc_prc": 0.48756848932650204,
            "auditor_fn_violation": 0.004105520614954584,
            "auditor_fp_violation": 0.011174127848356528,
            "ave_precision_score": 0.49378694246972815,
            "fpr": 0.18530701754385964,
            "logloss": 6.1940947329536185,
            "mae": 0.5676943979401343,
            "precision": 0.4583333333333333,
            "recall": 0.29979035639413
        },
        "train": {
            "accuracy": 0.4840834248079034,
            "auc_prc": 0.5201443388758742,
            "auditor_fn_violation": 0.0030652610649711145,
            "auditor_fp_violation": 0.0176819922402586,
            "ave_precision_score": 0.5256900634622603,
            "fpr": 0.18990120746432493,
            "logloss": 5.3095392651361175,
            "mae": 0.5313630077828413,
            "precision": 0.509915014164306,
            "recall": 0.37735849056603776
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5603803992913743,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5466261381350708,
            "fpr": 0.4769736842105263,
            "logloss": 0.6921115439561039,
            "mae": 0.4992261192385565,
            "precision": 0.5230263157894737,
            "recall": 1.0
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.5199396878627891,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0.5051477598839249,
            "fpr": 0.47639956092206365,
            "logloss": 0.6920845709789776,
            "mae": 0.49921530845005607,
            "precision": 0.5236004390779363,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.4234822293725009,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.430043230948448,
            "fpr": 0.0712719298245614,
            "logloss": 9.738869583919966,
            "mae": 0.5588309818432095,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.438033850279289,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.4431756826147305,
            "fpr": 0.06695938529088913,
            "logloss": 8.750761606127492,
            "mae": 0.5504354011716437,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.6892711086869332,
            "auditor_fn_violation": 0.006647909080878298,
            "auditor_fp_violation": 0.006629360758217389,
            "ave_precision_score": 0.6899547176744661,
            "fpr": 0.1206140350877193,
            "logloss": 0.6932322326160467,
            "mae": 0.4727542041555831,
            "precision": 0.6594427244582043,
            "recall": 0.44654088050314467
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7287003935111978,
            "auditor_fn_violation": 0.0130204557849899,
            "auditor_fp_violation": 0.0011432213549702347,
            "ave_precision_score": 0.7292309866087802,
            "fpr": 0.10647639956092206,
            "logloss": 0.6448265144050831,
            "mae": 0.4682031570229389,
            "precision": 0.7024539877300614,
            "recall": 0.480083857442348
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6853070175438597,
            "auc_prc": 0.7180990925110182,
            "auditor_fn_violation": 0.02211602118503807,
            "auditor_fp_violation": 0.011406029441419645,
            "ave_precision_score": 0.7183507200256101,
            "fpr": 0.11403508771929824,
            "logloss": 3.4400646798052,
            "mae": 0.3472220617323064,
            "precision": 0.7386934673366834,
            "recall": 0.6163522012578616
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.713871576581644,
            "auditor_fn_violation": 0.0210886279274739,
            "auditor_fp_violation": 0.013564371961737496,
            "ave_precision_score": 0.715098649311131,
            "fpr": 0.12403951701427003,
            "logloss": 4.004293207363367,
            "mae": 0.36835033569428677,
            "precision": 0.7087628865979382,
            "recall": 0.5765199161425576
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6118421052631579,
            "auc_prc": 0.7545148597301157,
            "auditor_fn_violation": 0.00015631321490308677,
            "auditor_fp_violation": 0.012719298245614052,
            "ave_precision_score": 0.7557888906659427,
            "fpr": 0.3574561403508772,
            "logloss": 0.6821191758992283,
            "mae": 0.4942130363105159,
            "precision": 0.5793548387096774,
            "recall": 0.9412997903563941
        },
        "train": {
            "accuracy": 0.6212952799121844,
            "auc_prc": 0.7796011105691626,
            "auditor_fn_violation": 0.002029699894372762,
            "auditor_fp_violation": 0.003745820413077241,
            "ave_precision_score": 0.7809368347223518,
            "fpr": 0.34796926454445665,
            "logloss": 0.6818141582378484,
            "mae": 0.4940716789792058,
            "precision": 0.5861618798955613,
            "recall": 0.9412997903563941
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7257535425754905,
            "auditor_fn_violation": 0.006477803523483764,
            "auditor_fp_violation": 0.01108842508570276,
            "ave_precision_score": 0.72727790492804,
            "fpr": 0.43201754385964913,
            "logloss": 0.7053021111421428,
            "mae": 0.4873482593449584,
            "precision": 0.5386416861826698,
            "recall": 0.9643605870020965
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.7208744483618945,
            "auditor_fn_violation": 0.004538059174266536,
            "auditor_fp_violation": 0.005594702737155198,
            "ave_precision_score": 0.7222055268708738,
            "fpr": 0.4138309549945115,
            "logloss": 0.6952248334815194,
            "mae": 0.4857703138032415,
            "precision": 0.5527876631079478,
            "recall": 0.9769392033542977
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 6832,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.42250396765455095,
            "auditor_fn_violation": 0.006689286108352657,
            "auditor_fp_violation": 0.01813369630973987,
            "ave_precision_score": 0.4290616351351145,
            "fpr": 0.06907894736842106,
            "logloss": 9.737088023325848,
            "mae": 0.5587955689252706,
            "precision": 0.4424778761061947,
            "recall": 0.10482180293501048
        },
        "train": {
            "accuracy": 0.4665203073545554,
            "auc_prc": 0.4349310448081164,
            "auditor_fn_violation": 0.008194740730001596,
            "auditor_fp_violation": 0.01394123032875202,
            "ave_precision_score": 0.44007059906633844,
            "fpr": 0.06586169045005488,
            "logloss": 8.755386654943054,
            "mae": 0.5514716434689528,
            "precision": 0.4594594594594595,
            "recall": 0.1069182389937107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.630848018917678,
            "auditor_fn_violation": 0.0597461289492074,
            "auditor_fp_violation": 0.07630066545674531,
            "ave_precision_score": 0.6323776928826793,
            "fpr": 0.34210526315789475,
            "logloss": 0.7018221582155783,
            "mae": 0.4816783015665255,
            "precision": 0.5568181818181818,
            "recall": 0.8218029350104822
        },
        "train": {
            "accuracy": 0.5631174533479693,
            "auc_prc": 0.6522895460434682,
            "auditor_fn_violation": 0.056171139140300134,
            "auditor_fp_violation": 0.07506310480709405,
            "ave_precision_score": 0.6537589666970972,
            "fpr": 0.35236004390779363,
            "logloss": 0.693880788133185,
            "mae": 0.48096093450367255,
            "precision": 0.5547850208044383,
            "recall": 0.8385744234800838
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5570175438596491,
            "auc_prc": 0.6636385495228327,
            "auditor_fn_violation": 0.0991853323035051,
            "auditor_fp_violation": 0.10356170598911071,
            "ave_precision_score": 0.5628565035897143,
            "fpr": 0.29605263157894735,
            "logloss": 0.6884916730920363,
            "mae": 0.4902098292582913,
            "precision": 0.5595432300163132,
            "recall": 0.7190775681341719
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6614066473011793,
            "auditor_fn_violation": 0.08217292951050174,
            "auditor_fp_violation": 0.10530788569809851,
            "ave_precision_score": 0.5572577884180979,
            "fpr": 0.3029637760702525,
            "logloss": 0.683750075827165,
            "mae": 0.48768798036973116,
            "precision": 0.56875,
            "recall": 0.7631027253668763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.4237339111192423,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.43029570470455525,
            "fpr": 0.0712719298245614,
            "logloss": 9.713867193369145,
            "mae": 0.558902165022207,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.4383009176780068,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.44344223599275556,
            "fpr": 0.06695938529088913,
            "logloss": 8.72517809809819,
            "mae": 0.5504538955406971,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.42341196386997126,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.4299729574303987,
            "fpr": 0.0712719298245614,
            "logloss": 9.738953113468087,
            "mae": 0.5588365374096561,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.43802965123306364,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.44317148142342244,
            "fpr": 0.06695938529088913,
            "logloss": 8.75083956314616,
            "mae": 0.5504392857502786,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.8312575693763657,
            "auditor_fn_violation": 0.015964636433851927,
            "auditor_fp_violation": 0.017211131276467034,
            "ave_precision_score": 0.8068573150549794,
            "fpr": 0.20942982456140352,
            "logloss": 3.5410036907574836,
            "mae": 0.309196981937287,
            "precision": 0.6723842195540308,
            "recall": 0.8218029350104822
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.820554934768092,
            "auditor_fn_violation": 0.006678218926836457,
            "auditor_fp_violation": 0.025171103815627743,
            "ave_precision_score": 0.7970485688260687,
            "fpr": 0.2052689352360044,
            "logloss": 3.5681901803027722,
            "mae": 0.312897759072991,
            "precision": 0.6719298245614035,
            "recall": 0.8029350104821803
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4791666666666667,
            "auc_prc": 0.4868488757611994,
            "auditor_fn_violation": 0.01403370848504911,
            "auditor_fp_violation": 0.0036953014720709815,
            "ave_precision_score": 0.49373118844478325,
            "fpr": 0.1074561403508772,
            "logloss": 7.621998150638679,
            "mae": 0.546975748716588,
            "precision": 0.5050505050505051,
            "recall": 0.20964360587002095
        },
        "train": {
            "accuracy": 0.48957189901207465,
            "auc_prc": 0.5180879720478468,
            "auditor_fn_violation": 0.011124228219272026,
            "auditor_fp_violation": 0.011209639480593062,
            "ave_precision_score": 0.5229158232275284,
            "fpr": 0.11964873765093303,
            "logloss": 6.941593000680267,
            "mae": 0.5245523299517125,
            "precision": 0.5260869565217391,
            "recall": 0.25366876310272535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5383771929824561,
            "auc_prc": 0.6116649431071826,
            "auditor_fn_violation": 0.0018274853801169592,
            "auditor_fp_violation": 0.004338072191974188,
            "ave_precision_score": 0.6130930981914473,
            "fpr": 0.4583333333333333,
            "logloss": 0.7173712350493006,
            "mae": 0.4902914585280998,
            "precision": 0.531390134529148,
            "recall": 0.9937106918238994
        },
        "train": {
            "accuracy": 0.5455543358946213,
            "auc_prc": 0.6868445655421642,
            "auditor_fn_violation": 0.0005016718559787549,
            "auditor_fp_violation": 0.007471406819871834,
            "ave_precision_score": 0.6869759409972935,
            "fpr": 0.45334796926454446,
            "logloss": 0.6790245558612329,
            "mae": 0.48459320650563553,
            "precision": 0.5354330708661418,
            "recall": 0.9979035639412998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6924533173699413,
            "auditor_fn_violation": 0.011454540439148193,
            "auditor_fp_violation": 0.013805706795724945,
            "ave_precision_score": 0.6941918689082962,
            "fpr": 0.06140350877192982,
            "logloss": 3.728801863481254,
            "mae": 0.37887493986958565,
            "precision": 0.7821011673151751,
            "recall": 0.42138364779874216
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7152628173652231,
            "auditor_fn_violation": 0.003474883039118929,
            "auditor_fp_violation": 0.0037534081654332376,
            "ave_precision_score": 0.716809845252727,
            "fpr": 0.06147091108671789,
            "logloss": 4.140864503585444,
            "mae": 0.3813729610390447,
            "precision": 0.7777777777777778,
            "recall": 0.4109014675052411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4214197232003123,
            "auditor_fn_violation": 0.006997315090661682,
            "auditor_fp_violation": 0.020634200443637833,
            "ave_precision_score": 0.42796192931968624,
            "fpr": 0.07346491228070176,
            "logloss": 9.73248921933507,
            "mae": 0.5603804694197595,
            "precision": 0.4369747899159664,
            "recall": 0.1090146750524109
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.4362235880940286,
            "auditor_fn_violation": 0.009299339311973165,
            "auditor_fp_violation": 0.013941230328752018,
            "ave_precision_score": 0.4413575196431526,
            "fpr": 0.06695938529088913,
            "logloss": 8.742934787162595,
            "mae": 0.5516539832993657,
            "precision": 0.46956521739130436,
            "recall": 0.11320754716981132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.7041548812947346,
            "auditor_fn_violation": 0.02051840817977859,
            "auditor_fp_violation": 0.014942528735632184,
            "ave_precision_score": 0.7018367261462618,
            "fpr": 0.12171052631578948,
            "logloss": 3.603266231899451,
            "mae": 0.36056698898562645,
            "precision": 0.7245657568238213,
            "recall": 0.6121593291404612
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.7429259088136063,
            "auditor_fn_violation": 0.013897230909429821,
            "auditor_fp_violation": 0.011791367161219507,
            "ave_precision_score": 0.741755278427819,
            "fpr": 0.132821075740944,
            "logloss": 3.92705863057069,
            "mae": 0.3720602397524172,
            "precision": 0.6997518610421837,
            "recall": 0.5911949685534591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.676563745780734,
            "auditor_fn_violation": 0.019766725513994634,
            "auditor_fp_violation": 0.020283827384553345,
            "ave_precision_score": 0.676843799184617,
            "fpr": 0.0800438596491228,
            "logloss": 3.856957865176675,
            "mae": 0.3706266325776817,
            "precision": 0.759075907590759,
            "recall": 0.48218029350104824
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.697630432735926,
            "auditor_fn_violation": 0.011957279649842244,
            "auditor_fp_violation": 0.008642449933480704,
            "ave_precision_score": 0.6979301046183088,
            "fpr": 0.0867178924259056,
            "logloss": 4.11317134671892,
            "mae": 0.3788821998667589,
            "precision": 0.7348993288590604,
            "recall": 0.4591194968553459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 6832,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7765196163067976,
            "auditor_fn_violation": 0.01280619000331017,
            "auditor_fp_violation": 0.023154869933454333,
            "ave_precision_score": 0.7768743341122397,
            "fpr": 0.13815789473684212,
            "logloss": 0.6467951558258515,
            "mae": 0.35605750766004984,
            "precision": 0.72,
            "recall": 0.6792452830188679
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7923004740286472,
            "auditor_fn_violation": 0.013565851334838354,
            "auditor_fp_violation": 0.00438572086176633,
            "ave_precision_score": 0.7926245115578132,
            "fpr": 0.12843029637760703,
            "logloss": 0.6470526475324937,
            "mae": 0.3495554899661816,
            "precision": 0.7291666666666666,
            "recall": 0.660377358490566
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.7057696899200974,
            "auditor_fn_violation": 0.021559730037882967,
            "auditor_fp_violation": 0.012439503932244406,
            "ave_precision_score": 0.7034466872163928,
            "fpr": 0.10964912280701754,
            "logloss": 3.6114034739005523,
            "mae": 0.3580294257787995,
            "precision": 0.7389033942558747,
            "recall": 0.5932914046121593
        },
        "train": {
            "accuracy": 0.6597145993413831,
            "auc_prc": 0.73936634039848,
            "auditor_fn_violation": 0.0139524608385284,
            "auditor_fp_violation": 0.015891282684243276,
            "ave_precision_score": 0.7383129296476333,
            "fpr": 0.11964873765093303,
            "logloss": 3.945648789821113,
            "mae": 0.37182531853517276,
            "precision": 0.7168831168831169,
            "recall": 0.5786163522012578
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 6832,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.48872403892347016,
            "auditor_fn_violation": 0.002767663393284055,
            "auditor_fp_violation": 0.013372151643476514,
            "ave_precision_score": 0.4949447624962336,
            "fpr": 0.18640350877192982,
            "logloss": 6.103781444984773,
            "mae": 0.5669339096571543,
            "precision": 0.4603174603174603,
            "recall": 0.3039832285115304
        },
        "train": {
            "accuracy": 0.4807903402854007,
            "auc_prc": 0.5217434062156923,
            "auditor_fn_violation": 0.002496853044664918,
            "auditor_fp_violation": 0.01448754849838381,
            "ave_precision_score": 0.527307464756423,
            "fpr": 0.1942919868276619,
            "logloss": 5.227413510587392,
            "mae": 0.5302321648750378,
            "precision": 0.505586592178771,
            "recall": 0.37945492662473795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6864035087719298,
            "auc_prc": 0.7244527616069983,
            "auditor_fn_violation": 0.01444747875979257,
            "auditor_fp_violation": 0.005696713046985284,
            "ave_precision_score": 0.7246894201046907,
            "fpr": 0.09320175438596491,
            "logloss": 3.4832373978799067,
            "mae": 0.34464814741541855,
            "precision": 0.7645429362880887,
            "recall": 0.5786163522012578
        },
        "train": {
            "accuracy": 0.6608122941822173,
            "auc_prc": 0.7198862169207022,
            "auditor_fn_violation": 0.01994490814572418,
            "auditor_fp_violation": 0.011133761957033092,
            "ave_precision_score": 0.7211066291040659,
            "fpr": 0.10537870472008781,
            "logloss": 4.097570023121471,
            "mae": 0.3655832403646237,
            "precision": 0.7333333333333333,
            "recall": 0.5534591194968553
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.42089599168010705,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.018463904012905832,
            "ave_precision_score": 0.4274334497889051,
            "fpr": 0.0712719298245614,
            "logloss": 9.746786057950661,
            "mae": 0.5614292760773112,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4698133918770582,
            "auc_prc": 0.43470782536124236,
            "auditor_fn_violation": 0.009529464016550577,
            "auditor_fp_violation": 0.013642778736082798,
            "ave_precision_score": 0.43982232601598215,
            "fpr": 0.06805708013172337,
            "logloss": 8.760867609257117,
            "mae": 0.5528952578009237,
            "precision": 0.4745762711864407,
            "recall": 0.11740041928721175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.517034649243995,
            "auditor_fn_violation": 0.013863602927654563,
            "auditor_fp_violation": 0.012724339584593672,
            "ave_precision_score": 0.5239183775537815,
            "fpr": 0.09649122807017543,
            "logloss": 6.772600277062167,
            "mae": 0.514929407360712,
            "precision": 0.5532994923857868,
            "recall": 0.22851153039832284
        },
        "train": {
            "accuracy": 0.5192096597145993,
            "auc_prc": 0.5504983239458903,
            "auditor_fn_violation": 0.017758723452238775,
            "auditor_fp_violation": 0.008895375012013944,
            "ave_precision_score": 0.5552821259727841,
            "fpr": 0.11086717892425905,
            "logloss": 6.183734804181455,
            "mae": 0.49379603683287265,
            "precision": 0.5809128630705395,
            "recall": 0.29350104821802936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6326754385964912,
            "auc_prc": 0.6924995363773673,
            "auditor_fn_violation": 0.01129592850049653,
            "auditor_fp_violation": 0.012991530550514219,
            "ave_precision_score": 0.6942415129759367,
            "fpr": 0.06140350877192982,
            "logloss": 3.744204624614813,
            "mae": 0.3802963658791455,
            "precision": 0.7795275590551181,
            "recall": 0.41509433962264153
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.7166025053707898,
            "auditor_fn_violation": 0.0026119153969536256,
            "auditor_fp_violation": 0.0040822107675264445,
            "ave_precision_score": 0.7181458177499699,
            "fpr": 0.059275521405049394,
            "logloss": 4.159151345377591,
            "mae": 0.38170893201041917,
            "precision": 0.7848605577689243,
            "recall": 0.4129979035639413
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6583062649365,
            "auditor_fn_violation": 0.0032687851704733535,
            "auditor_fp_violation": 2.5206694898170035e-05,
            "ave_precision_score": 0.6602367074822129,
            "fpr": 0.4331140350877193,
            "logloss": 0.6912137023843642,
            "mae": 0.4873513417612565,
            "precision": 0.5406976744186046,
            "recall": 0.9748427672955975
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6179970657305961,
            "auditor_fn_violation": 0.00473136392611156,
            "auditor_fp_violation": 0.007648454374845087,
            "ave_precision_score": 0.6195904428518149,
            "fpr": 0.43029637760702527,
            "logloss": 0.692079326403696,
            "mae": 0.49058203574200493,
            "precision": 0.5415204678362573,
            "recall": 0.9706498951781971
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6888569465909518,
            "auditor_fn_violation": 0.004992827981904463,
            "auditor_fp_violation": 0.009966727162734423,
            "ave_precision_score": 0.6891794234587204,
            "fpr": 0.051535087719298246,
            "logloss": 3.8890197421073704,
            "mae": 0.39144555003969156,
            "precision": 0.7982832618025751,
            "recall": 0.389937106918239
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7121744204723754,
            "auditor_fn_violation": 0.0010217536883237043,
            "auditor_fp_violation": 0.006950381158093351,
            "ave_precision_score": 0.7134763985265619,
            "fpr": 0.048298572996706916,
            "logloss": 4.212245877031793,
            "mae": 0.3919776297518659,
            "precision": 0.8026905829596412,
            "recall": 0.3752620545073375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 6832,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7276124432762968,
            "auditor_fn_violation": 0.021141362315642356,
            "auditor_fp_violation": 0.009064327485380117,
            "ave_precision_score": 0.7278338832430636,
            "fpr": 0.12719298245614036,
            "logloss": 3.4274982391618765,
            "mae": 0.34258622064649874,
            "precision": 0.722488038277512,
            "recall": 0.6331236897274634
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7265975526660037,
            "auditor_fn_violation": 0.01979072459365731,
            "auditor_fp_violation": 0.018794862585804838,
            "ave_precision_score": 0.727803612979214,
            "fpr": 0.1437980241492865,
            "logloss": 4.008781767291336,
            "mae": 0.3618109385061083,
            "precision": 0.6967592592592593,
            "recall": 0.6310272536687631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7193557585366629,
            "auditor_fn_violation": 0.016268067968663803,
            "auditor_fp_violation": 0.008136721113127651,
            "ave_precision_score": 0.7196058332510037,
            "fpr": 0.125,
            "logloss": 3.43235592813884,
            "mae": 0.3495469893668951,
            "precision": 0.7304964539007093,
            "recall": 0.6477987421383647
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.720627755519673,
            "auditor_fn_violation": 0.020607667294907112,
            "auditor_fp_violation": 0.01696115576643887,
            "ave_precision_score": 0.7218401174413168,
            "fpr": 0.1350164654226125,
            "logloss": 3.9928886873005163,
            "mae": 0.36579771699785507,
            "precision": 0.7132867132867133,
            "recall": 0.6415094339622641
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.4230926632073713,
            "auditor_fn_violation": 0.010121280664974813,
            "auditor_fp_violation": 0.018262250453720506,
            "ave_precision_score": 0.42965153440573517,
            "fpr": 0.06578947368421052,
            "logloss": 9.727564480093147,
            "mae": 0.5572781381397169,
            "precision": 0.4230769230769231,
            "recall": 0.09224318658280922
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.43597249362499163,
            "auditor_fn_violation": 0.008724027550529635,
            "auditor_fp_violation": 0.01411069013136929,
            "ave_precision_score": 0.44111298489216544,
            "fpr": 0.06256860592755215,
            "logloss": 8.743475179202065,
            "mae": 0.5498657556737543,
            "precision": 0.46226415094339623,
            "recall": 0.10272536687631027
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4616228070175439,
            "auc_prc": 0.42332946381697506,
            "auditor_fn_violation": 0.005227297804259081,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.42989050444673294,
            "fpr": 0.0712719298245614,
            "logloss": 9.725612098147828,
            "mae": 0.5588156420342424,
            "precision": 0.4396551724137931,
            "recall": 0.1069182389937107
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.4383852322255486,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.44352664525800944,
            "fpr": 0.06695938529088913,
            "logloss": 8.737318532934841,
            "mae": 0.550392908415303,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6392543859649122,
            "auc_prc": 0.7692130535075862,
            "auditor_fn_violation": 0.01784499246018611,
            "auditor_fp_violation": 0.015504638031861265,
            "ave_precision_score": 0.769590964458698,
            "fpr": 0.09978070175438597,
            "logloss": 0.7020104088906354,
            "mae": 0.37009716536552434,
            "precision": 0.7242424242424242,
            "recall": 0.5010482180293501
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7911584388585398,
            "auditor_fn_violation": 0.011218579348148773,
            "auditor_fp_violation": 0.007524521086363799,
            "ave_precision_score": 0.7914716287955915,
            "fpr": 0.0801317233809001,
            "logloss": 0.6957268405746379,
            "mae": 0.3587213418388499,
            "precision": 0.7739938080495357,
            "recall": 0.5241090146750524
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6348684210526315,
            "auc_prc": 0.6990388516638724,
            "auditor_fn_violation": 0.016006013461326272,
            "auditor_fp_violation": 0.00897610405323654,
            "ave_precision_score": 0.6994141083788228,
            "fpr": 0.0581140350877193,
            "logloss": 3.8338753024769185,
            "mae": 0.3773010058213196,
            "precision": 0.788,
            "recall": 0.4129979035639413
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7126094294002656,
            "auditor_fn_violation": 0.007099347136213129,
            "auditor_fp_violation": 0.002165038672244508,
            "ave_precision_score": 0.7138967305284591,
            "fpr": 0.059275521405049394,
            "logloss": 4.193660852730609,
            "mae": 0.38541674083994265,
            "precision": 0.7768595041322314,
            "recall": 0.3941299790356394
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 6832,
        "test": {
            "accuracy": 0.47478070175438597,
            "auc_prc": 0.4865802241403993,
            "auditor_fn_violation": 0.013509599470374055,
            "auditor_fp_violation": 0.007604859850776367,
            "ave_precision_score": 0.4934440235760345,
            "fpr": 0.11074561403508772,
            "logloss": 7.759152581957736,
            "mae": 0.5476375009151091,
            "precision": 0.495,
            "recall": 0.20754716981132076
        },
        "train": {
            "accuracy": 0.48737650933040616,
            "auc_prc": 0.5159541186658663,
            "auditor_fn_violation": 0.010010424649117377,
            "auditor_fp_violation": 0.012509674384253901,
            "ave_precision_score": 0.5207845610664447,
            "fpr": 0.1207464324917673,
            "logloss": 7.087473087549784,
            "mae": 0.5261791377135194,
            "precision": 0.5217391304347826,
            "recall": 0.25157232704402516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4594298245614035,
            "auc_prc": 0.42299569045295055,
            "auditor_fn_violation": 0.0047859428445327255,
            "auditor_fp_violation": 0.019789776164549307,
            "ave_precision_score": 0.42954683414503564,
            "fpr": 0.07785087719298246,
            "logloss": 9.71950366742007,
            "mae": 0.5621159333450791,
            "precision": 0.4365079365079365,
            "recall": 0.11530398322851153
        },
        "train": {
            "accuracy": 0.4643249176728869,
            "auc_prc": 0.43740902327669956,
            "auditor_fn_violation": 0.007720683838572131,
            "auditor_fp_violation": 0.012484381876400573,
            "ave_precision_score": 0.44254972053993014,
            "fpr": 0.07354555433589462,
            "logloss": 8.729604657291105,
            "mae": 0.5535275489186209,
            "precision": 0.45528455284552843,
            "recall": 0.11740041928721175
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 6832,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.4225229937352147,
            "auditor_fn_violation": 0.006689286108352657,
            "auditor_fp_violation": 0.01813369630973987,
            "ave_precision_score": 0.42908068232945806,
            "fpr": 0.06907894736842106,
            "logloss": 9.73664472399335,
            "mae": 0.5588716930061679,
            "precision": 0.4424778761061947,
            "recall": 0.10482180293501048
        },
        "train": {
            "accuracy": 0.4654226125137212,
            "auc_prc": 0.4349308719713428,
            "auditor_fn_violation": 0.008194740730001596,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.44007043659292916,
            "fpr": 0.06695938529088913,
            "logloss": 8.754865163425384,
            "mae": 0.5515496117433073,
            "precision": 0.45535714285714285,
            "recall": 0.1069182389937107
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.691736271849843,
            "auditor_fn_violation": 0.007303045349222123,
            "auditor_fp_violation": 0.007894736842105267,
            "ave_precision_score": 0.6924291035333405,
            "fpr": 0.09539473684210527,
            "logloss": 0.6862441782862071,
            "mae": 0.47223495783605435,
            "precision": 0.6692015209125475,
            "recall": 0.3689727463312369
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7253201691548681,
            "auditor_fn_violation": 0.011549958922740253,
            "auditor_fp_violation": 0.005963973351813727,
            "ave_precision_score": 0.7258494978322596,
            "fpr": 0.0801317233809001,
            "logloss": 0.6460330847299816,
            "mae": 0.46818491927755074,
            "precision": 0.7159533073929961,
            "recall": 0.3857442348008386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.7246448895237323,
            "auditor_fn_violation": 0.019010445400713526,
            "auditor_fp_violation": 0.0054975801572897725,
            "ave_precision_score": 0.7248801515338127,
            "fpr": 0.13486842105263158,
            "logloss": 3.449527685836363,
            "mae": 0.34503527069037854,
            "precision": 0.713953488372093,
            "recall": 0.6436058700209644
        },
        "train": {
            "accuracy": 0.6630076838638859,
            "auc_prc": 0.7284592596386315,
            "auditor_fn_violation": 0.01759763615903459,
            "auditor_fp_violation": 0.022358576942338143,
            "ave_precision_score": 0.7296619786696716,
            "fpr": 0.15148188803512624,
            "logloss": 3.8159777074529004,
            "mae": 0.3595433616129885,
            "precision": 0.6905829596412556,
            "recall": 0.6457023060796646
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.6764517429232308,
            "auditor_fn_violation": 0.019766725513994634,
            "auditor_fp_violation": 0.020283827384553345,
            "ave_precision_score": 0.6767320658758624,
            "fpr": 0.0800438596491228,
            "logloss": 3.8581575874963074,
            "mae": 0.37065243256444136,
            "precision": 0.759075907590759,
            "recall": 0.48218029350104824
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.697526550573244,
            "auditor_fn_violation": 0.011957279649842244,
            "auditor_fp_violation": 0.008642449933480704,
            "ave_precision_score": 0.6978266642636834,
            "fpr": 0.0867178924259056,
            "logloss": 4.114458352576183,
            "mae": 0.3789037677424018,
            "precision": 0.7348993288590604,
            "recall": 0.4591194968553459
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6924566079963423,
            "auditor_fn_violation": 0.011454540439148193,
            "auditor_fp_violation": 0.013805706795724945,
            "ave_precision_score": 0.6941951574780092,
            "fpr": 0.06140350877192982,
            "logloss": 3.728839801438571,
            "mae": 0.37887506801485904,
            "precision": 0.7821011673151751,
            "recall": 0.42138364779874216
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.7152628173652231,
            "auditor_fn_violation": 0.003474883039118929,
            "auditor_fp_violation": 0.0037534081654332376,
            "ave_precision_score": 0.716809845252727,
            "fpr": 0.06147091108671789,
            "logloss": 4.140917133131844,
            "mae": 0.3813732036441738,
            "precision": 0.7777777777777778,
            "recall": 0.4109014675052411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6381578947368421,
            "auc_prc": 0.700252113911476,
            "auditor_fn_violation": 0.010178748758689187,
            "auditor_fp_violation": 0.016704476709013913,
            "ave_precision_score": 0.7005253315957394,
            "fpr": 0.05592105263157895,
            "logloss": 3.9228327603304716,
            "mae": 0.3697362833292085,
            "precision": 0.7951807228915663,
            "recall": 0.41509433962264153
        },
        "train": {
            "accuracy": 0.6267837541163557,
            "auc_prc": 0.7151974912885734,
            "auditor_fn_violation": 0.004586385362227789,
            "auditor_fp_violation": 0.006581110543434827,
            "ave_precision_score": 0.7165232268201076,
            "fpr": 0.04939626783754116,
            "logloss": 4.219054263862793,
            "mae": 0.37646367782574763,
            "precision": 0.801762114537445,
            "recall": 0.38155136268343814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.831160581768107,
            "auditor_fn_violation": 0.018309334657398216,
            "auditor_fp_violation": 0.02094676346037507,
            "ave_precision_score": 0.8067767500503089,
            "fpr": 0.21052631578947367,
            "logloss": 3.5218173490990576,
            "mae": 0.3088431648079966,
            "precision": 0.6712328767123288,
            "recall": 0.8218029350104822
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.8206542887080874,
            "auditor_fn_violation": 0.008457082893219841,
            "auditor_fp_violation": 0.024536261868509313,
            "ave_precision_score": 0.7971781484632015,
            "fpr": 0.2030735455543359,
            "logloss": 3.5480954758350136,
            "mae": 0.3122785941660579,
            "precision": 0.6731448763250883,
            "recall": 0.7987421383647799
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6228070175438597,
            "auc_prc": 0.6728925100380838,
            "auditor_fn_violation": 0.005719224686454084,
            "auditor_fp_violation": 0.01696914700544465,
            "ave_precision_score": 0.6731951755367077,
            "fpr": 0.0625,
            "logloss": 3.978588480856104,
            "mae": 0.3949102104440747,
            "precision": 0.7692307692307693,
            "recall": 0.39832285115303984
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6965433457135883,
            "auditor_fn_violation": 0.005150190888442449,
            "auditor_fp_violation": 0.004507124899462281,
            "ave_precision_score": 0.6968328705780998,
            "fpr": 0.0570801317233809,
            "logloss": 4.243011949132531,
            "mae": 0.3944518207513055,
            "precision": 0.7777777777777778,
            "recall": 0.38155136268343814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7090535400961939,
            "auditor_fn_violation": 0.015263525690536614,
            "auditor_fp_violation": 0.008363581367211135,
            "ave_precision_score": 0.7059518361111823,
            "fpr": 0.09100877192982457,
            "logloss": 3.576095145662041,
            "mae": 0.36143811556860617,
            "precision": 0.7580174927113703,
            "recall": 0.5450733752620545
        },
        "train": {
            "accuracy": 0.6487376509330406,
            "auc_prc": 0.7456510081605057,
            "auditor_fn_violation": 0.013977774556031925,
            "auditor_fp_violation": 0.013217864604146966,
            "ave_precision_score": 0.7442622634615188,
            "fpr": 0.10647639956092206,
            "logloss": 3.8654845924373924,
            "mae": 0.3705650253993727,
            "precision": 0.7236467236467237,
            "recall": 0.5324947589098532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5385781895292954,
            "auditor_fn_violation": 0.0038848431350913984,
            "auditor_fp_violation": 0.004605263157894756,
            "ave_precision_score": 0.5405412169458245,
            "fpr": 0.41885964912280704,
            "logloss": 0.7167570559777257,
            "mae": 0.4889062572589872,
            "precision": 0.5446960667461264,
            "recall": 0.9580712788259959
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6104686754849674,
            "auditor_fn_violation": 0.0020918335646086627,
            "auditor_fp_violation": 0.014383849216185204,
            "ave_precision_score": 0.6117681574800624,
            "fpr": 0.40504939626783754,
            "logloss": 0.6753844491310494,
            "mae": 0.48096986737306563,
            "precision": 0.5494505494505495,
            "recall": 0.9433962264150944
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6293859649122807,
            "auc_prc": 0.6888569465909518,
            "auditor_fn_violation": 0.004992827981904463,
            "auditor_fp_violation": 0.009966727162734423,
            "ave_precision_score": 0.6891794234587204,
            "fpr": 0.051535087719298246,
            "logloss": 3.8890249031075244,
            "mae": 0.39144512300897727,
            "precision": 0.7982832618025751,
            "recall": 0.389937106918239
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7121744204723754,
            "auditor_fn_violation": 0.0010217536883237043,
            "auditor_fp_violation": 0.006950381158093351,
            "ave_precision_score": 0.7134763985265619,
            "fpr": 0.048298572996706916,
            "logloss": 4.212249828016312,
            "mae": 0.39197732178790123,
            "precision": 0.8026905829596412,
            "recall": 0.3752620545073375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 6832,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.691736271849843,
            "auditor_fn_violation": 0.007303045349222123,
            "auditor_fp_violation": 0.007894736842105267,
            "ave_precision_score": 0.6924291035333405,
            "fpr": 0.09539473684210527,
            "logloss": 0.6862441835080345,
            "mae": 0.4722349556466294,
            "precision": 0.6692015209125475,
            "recall": 0.3689727463312369
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.7253201691548681,
            "auditor_fn_violation": 0.011549958922740253,
            "auditor_fp_violation": 0.005963973351813727,
            "ave_precision_score": 0.7258494978322596,
            "fpr": 0.0801317233809001,
            "logloss": 0.6460330800961419,
            "mae": 0.46818491908126764,
            "precision": 0.7159533073929961,
            "recall": 0.3857442348008386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 6832,
        "test": {
            "accuracy": 0.46271929824561403,
            "auc_prc": 0.42368587896100335,
            "auditor_fn_violation": 0.004684798999595426,
            "auditor_fp_violation": 0.019232708207299862,
            "ave_precision_score": 0.43024756267188957,
            "fpr": 0.0712719298245614,
            "logloss": 9.713916299295533,
            "mae": 0.5589227942416376,
            "precision": 0.4444444444444444,
            "recall": 0.1090146750524109
        },
        "train": {
            "accuracy": 0.4676180021953897,
            "auc_prc": 0.43834009288500086,
            "auditor_fn_violation": 0.008293694352969885,
            "auditor_fp_violation": 0.013478377435036194,
            "ave_precision_score": 0.44348143160475606,
            "fpr": 0.06695938529088913,
            "logloss": 8.725204606894527,
            "mae": 0.5504673548256716,
            "precision": 0.4649122807017544,
            "recall": 0.1111111111111111
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 6832,
        "test": {
            "accuracy": 0.44956140350877194,
            "auc_prc": 0.4889574509841339,
            "auditor_fn_violation": 0.002767663393284055,
            "auditor_fp_violation": 0.013372151643476514,
            "ave_precision_score": 0.4951579918490384,
            "fpr": 0.18640350877192982,
            "logloss": 6.108478062249679,
            "mae": 0.5678397389868475,
            "precision": 0.4603174603174603,
            "recall": 0.3039832285115304
        },
        "train": {
            "accuracy": 0.4796926454445664,
            "auc_prc": 0.5214233525846437,
            "auditor_fn_violation": 0.002496853044664918,
            "auditor_fp_violation": 0.01261084441566719,
            "ave_precision_score": 0.5269874450625938,
            "fpr": 0.19538968166849616,
            "logloss": 5.235456881408774,
            "mae": 0.5310033999523114,
            "precision": 0.5041782729805014,
            "recall": 0.37945492662473795
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.8450788826045236,
            "auditor_fn_violation": 0.018408179778586928,
            "auditor_fp_violation": 0.019661222020568667,
            "ave_precision_score": 0.8067617619958195,
            "fpr": 0.21820175438596492,
            "logloss": 3.561103952179755,
            "mae": 0.29954142022358715,
            "precision": 0.6726973684210527,
            "recall": 0.8574423480083857
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8381871558127929,
            "auditor_fn_violation": 0.0077390938149383155,
            "auditor_fp_violation": 0.02758400906483482,
            "ave_precision_score": 0.8026388830310865,
            "fpr": 0.21295279912184412,
            "logloss": 3.5735173958999837,
            "mae": 0.2985289313541217,
            "precision": 0.674496644295302,
            "recall": 0.8427672955974843
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7275662140607603,
            "auditor_fn_violation": 0.02109538784067086,
            "auditor_fp_violation": 0.016485178463399874,
            "ave_precision_score": 0.7277869980298722,
            "fpr": 0.19298245614035087,
            "logloss": 3.45684473500399,
            "mae": 0.3551658010218411,
            "precision": 0.6679245283018868,
            "recall": 0.7421383647798742
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7267996140228374,
            "auditor_fn_violation": 0.016776090963693226,
            "auditor_fp_violation": 0.029460713147551443,
            "ave_precision_score": 0.7280073550691495,
            "fpr": 0.19978046103183314,
            "logloss": 4.022395294099801,
            "mae": 0.37005618394900996,
            "precision": 0.6520076481835564,
            "recall": 0.7148846960167715
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6304824561403509,
            "auc_prc": 0.7030684997508116,
            "auditor_fn_violation": 0.009089153701864729,
            "auditor_fp_violation": 0.007032667876588022,
            "ave_precision_score": 0.6996646991078412,
            "fpr": 0.05921052631578947,
            "logloss": 3.8073049957370655,
            "mae": 0.38379400275808306,
            "precision": 0.782258064516129,
            "recall": 0.40670859538784065
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.7384533988962912,
            "auditor_fn_violation": 0.0040133748478300485,
            "auditor_fp_violation": 0.00272147384501763,
            "ave_precision_score": 0.7370806258225855,
            "fpr": 0.059275521405049394,
            "logloss": 4.079219502693572,
            "mae": 0.38590591147399167,
            "precision": 0.7786885245901639,
            "recall": 0.39832285115303984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4605263157894737,
            "auc_prc": 0.4215093600678677,
            "auditor_fn_violation": 0.006997315090661682,
            "auditor_fp_violation": 0.020634200443637833,
            "ave_precision_score": 0.4280521407748609,
            "fpr": 0.07346491228070176,
            "logloss": 9.730765278442126,
            "mae": 0.5603486918098045,
            "precision": 0.4369747899159664,
            "recall": 0.1090146750524109
        },
        "train": {
            "accuracy": 0.46871569703622395,
            "auc_prc": 0.4362678039019585,
            "auditor_fn_violation": 0.009299339311973165,
            "auditor_fp_violation": 0.013941230328752018,
            "ave_precision_score": 0.44140176200015646,
            "fpr": 0.06695938529088913,
            "logloss": 8.741176269652948,
            "mae": 0.5516222417491274,
            "precision": 0.46956521739130436,
            "recall": 0.11320754716981132
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 6832,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7506323199858587,
            "auditor_fn_violation": 0.015550866159108466,
            "auditor_fp_violation": 0.017939604759023998,
            "ave_precision_score": 0.7510605939468797,
            "fpr": 0.13267543859649122,
            "logloss": 0.7046457037762934,
            "mae": 0.37477475120445497,
            "precision": 0.7012345679012346,
            "recall": 0.5953878406708596
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7656796121289072,
            "auditor_fn_violation": 0.008015243460431212,
            "auditor_fp_violation": 0.007375295290029193,
            "ave_precision_score": 0.766086580252105,
            "fpr": 0.1207464324917673,
            "logloss": 0.6975351784386773,
            "mae": 0.36795345138355157,
            "precision": 0.7193877551020408,
            "recall": 0.5911949685534591
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 6832,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.8289042616612947,
            "auditor_fn_violation": 0.01571867299275443,
            "auditor_fp_violation": 0.017506049606775563,
            "ave_precision_score": 0.8090258776876798,
            "fpr": 0.18421052631578946,
            "logloss": 3.3561201811581096,
            "mae": 0.29920476235079385,
            "precision": 0.6911764705882353,
            "recall": 0.7882599580712788
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.819082607377884,
            "auditor_fn_violation": 0.012454349011729458,
            "auditor_fp_violation": 0.02621821364075533,
            "ave_precision_score": 0.8009079892528359,
            "fpr": 0.18331503841931943,
            "logloss": 3.3932307883576263,
            "mae": 0.3072026136573825,
            "precision": 0.6872659176029963,
            "recall": 0.7693920335429769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 6832,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.5182021535615601,
            "auditor_fn_violation": 0.014440582588546845,
            "auditor_fp_violation": 0.010508671103044974,
            "ave_precision_score": 0.5250841472863492,
            "fpr": 0.09978070175438597,
            "logloss": 6.739755130002068,
            "mae": 0.5145368006536883,
            "precision": 0.542713567839196,
            "recall": 0.22641509433962265
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.5532525480488543,
            "auditor_fn_violation": 0.017293871548992416,
            "auditor_fp_violation": 0.011492915568550281,
            "ave_precision_score": 0.5580264390711129,
            "fpr": 0.1141602634467618,
            "logloss": 6.1571210378923675,
            "mae": 0.49196101774182643,
            "precision": 0.5755102040816327,
            "recall": 0.29559748427672955
        }
    }
]