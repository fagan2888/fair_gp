[
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(0)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6932681872994791,
            "mae": 0.5000442303063577,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6938439220438463,
            "mae": 0.5003320914330257,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(1)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5997807017543859,
            "auc_prc": 0.7033976259638456,
            "auditor_fn_violation": 0.0332015641054915,
            "auditor_fp_violation": 0.03819241840743766,
            "ave_precision_score": 0.7035957204108689,
            "fpr": 0.29385964912280704,
            "logloss": 2.2140576420347107,
            "mae": 0.46323991734271536,
            "precision": 0.5759493670886076,
            "recall": 0.789587852494577
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.7316979534172465,
            "auditor_fn_violation": 0.024305145806382666,
            "auditor_fp_violation": 0.037841585302443824,
            "ave_precision_score": 0.7318345267221885,
            "fpr": 0.265642151481888,
            "logloss": 1.8465954544890912,
            "mae": 0.4576748162244509,
            "precision": 0.6206896551724138,
            "recall": 0.8032454361054767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(2)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5434006846871224,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.014113373789240286,
            "ave_precision_score": 0.5395258474966221,
            "fpr": 0.12390350877192982,
            "logloss": 11.062082452633073,
            "mae": 0.48613376125167346,
            "precision": 0.5515873015873016,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.604610774622816,
            "auditor_fn_violation": 0.012099135426152745,
            "auditor_fp_violation": 0.015320458615854075,
            "ave_precision_score": 0.5971015041200796,
            "fpr": 0.1119648737650933,
            "logloss": 11.65021307597448,
            "mae": 0.49445609190886264,
            "precision": 0.6106870229007634,
            "recall": 0.32454361054766734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(3)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5969518373929531,
            "auditor_fn_violation": 0.013659759485481602,
            "auditor_fp_violation": 0.028071147936359748,
            "ave_precision_score": 0.5864318340982658,
            "fpr": 0.17105263157894737,
            "logloss": 8.879350919994655,
            "mae": 0.4640752829722259,
            "precision": 0.5666666666666667,
            "recall": 0.44251626898047725
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.659423426547181,
            "auditor_fn_violation": 0.016425344504734783,
            "auditor_fp_violation": 0.026675560270799748,
            "ave_precision_score": 0.6471002016401233,
            "fpr": 0.14818880351262348,
            "logloss": 9.222364190917416,
            "mae": 0.4700592242842132,
            "precision": 0.6239554317548747,
            "recall": 0.4543610547667343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(4)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7264106021544292,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.018073870930096863,
            "ave_precision_score": 0.6887467820862896,
            "fpr": 0.12828947368421054,
            "logloss": 2.4338927405916575,
            "mae": 0.4147000122292523,
            "precision": 0.6945169712793734,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6443468715697036,
            "auc_prc": 0.7476776584498299,
            "auditor_fn_violation": 0.01635186797380674,
            "auditor_fp_violation": 0.006720098319844117,
            "ave_precision_score": 0.7202627592389687,
            "fpr": 0.11306256860592755,
            "logloss": 1.958613124267363,
            "mae": 0.40921886662751206,
            "precision": 0.7253333333333334,
            "recall": 0.5517241379310345
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(5)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.740249927340693,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.018073870930096863,
            "ave_precision_score": 0.6958380148212475,
            "fpr": 0.12828947368421054,
            "logloss": 2.6486008568312234,
            "mae": 0.4142322093901927,
            "precision": 0.6945169712793734,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7643261177598731,
            "auditor_fn_violation": 0.017431750322294794,
            "auditor_fp_violation": 0.008098782031418231,
            "ave_precision_score": 0.7304661368792784,
            "fpr": 0.1163556531284303,
            "logloss": 2.1336467353113067,
            "mae": 0.4087823386969603,
            "precision": 0.7188328912466844,
            "recall": 0.5496957403651116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(6)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7089457703622735,
            "auditor_fn_violation": 0.027802355672260914,
            "auditor_fp_violation": 0.042977107402652974,
            "ave_precision_score": 0.7085215632735076,
            "fpr": 0.32127192982456143,
            "logloss": 2.1456704265181257,
            "mae": 0.45576350953808054,
            "precision": 0.5513016845329249,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7642509804960191,
            "auditor_fn_violation": 0.025013192377143906,
            "auditor_fp_violation": 0.032610465391099755,
            "ave_precision_score": 0.7634078411462588,
            "fpr": 0.283205268935236,
            "logloss": 1.7454310031418963,
            "mae": 0.43591080984169,
            "precision": 0.6120300751879699,
            "recall": 0.8255578093306288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(7)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5372807017543859,
            "auc_prc": 0.6329578468277758,
            "auditor_fn_violation": 0.026203999695551247,
            "auditor_fp_violation": 0.04237172754502664,
            "ave_precision_score": 0.5129919547811315,
            "fpr": 0.38048245614035087,
            "logloss": 2.532107609837643,
            "mae": 0.4880223718525209,
            "precision": 0.5266030013642565,
            "recall": 0.8373101952277657
        },
        "train": {
            "accuracy": 0.5642151481888035,
            "auc_prc": 0.6573778941278198,
            "auditor_fn_violation": 0.030005143357164966,
            "auditor_fp_violation": 0.04144454540202417,
            "ave_precision_score": 0.5544291334885905,
            "fpr": 0.34796926454445665,
            "logloss": 2.153941052871864,
            "mae": 0.4853325432509489,
            "precision": 0.5657534246575342,
            "recall": 0.8377281947261663
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(8)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.6987288814312724,
            "auditor_fn_violation": 0.02717680861589984,
            "auditor_fp_violation": 0.032092426187419795,
            "ave_precision_score": 0.6990539831189403,
            "fpr": 0.3574561403508772,
            "logloss": 2.2025494277052373,
            "mae": 0.46372645599125506,
            "precision": 0.5316091954022989,
            "recall": 0.8026030368763557
        },
        "train": {
            "accuracy": 0.5927552140504939,
            "auc_prc": 0.7408856564602646,
            "auditor_fn_violation": 0.025108934523504697,
            "auditor_fp_violation": 0.031137243367874844,
            "ave_precision_score": 0.7408956942488991,
            "fpr": 0.3040614709110867,
            "logloss": 1.8279509454924407,
            "mae": 0.4551202461989213,
            "precision": 0.5902366863905325,
            "recall": 0.8093306288032455
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(9)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.740249927340693,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.016734255261212902,
            "ave_precision_score": 0.6958380148212475,
            "fpr": 0.13157894736842105,
            "logloss": 2.650769416756704,
            "mae": 0.4150923420920184,
            "precision": 0.689119170984456,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7643294467365714,
            "auditor_fn_violation": 0.015902102542065324,
            "auditor_fp_violation": 0.008098782031418231,
            "ave_precision_score": 0.7304684616604922,
            "fpr": 0.1163556531284303,
            "logloss": 2.1350558468491405,
            "mae": 0.4093074052053801,
            "precision": 0.7203166226912929,
            "recall": 0.5537525354969574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(10)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.7387770067420733,
            "auditor_fn_violation": 0.007311527191079653,
            "auditor_fp_violation": 0.017458766094837985,
            "ave_precision_score": 0.6815350616897332,
            "fpr": 0.1118421052631579,
            "logloss": 3.2175608329477132,
            "mae": 0.42911443888748946,
            "precision": 0.7060518731988472,
            "recall": 0.5314533622559653
        },
        "train": {
            "accuracy": 0.6245883644346871,
            "auc_prc": 0.7635333228248355,
            "auditor_fn_violation": 0.013210189636246658,
            "auditor_fp_violation": 0.004393405427549514,
            "ave_precision_score": 0.7198020748212923,
            "fpr": 0.09549945115257959,
            "logloss": 2.558502110900368,
            "mae": 0.41837830280498667,
            "precision": 0.7323076923076923,
            "recall": 0.4827586206896552
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(11)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7401422626964385,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.01693361730268021,
            "ave_precision_score": 0.7014298974272071,
            "fpr": 0.12719298245614036,
            "logloss": 2.412741149245254,
            "mae": 0.41337961736216877,
            "precision": 0.6963350785340314,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6410537870472008,
            "auc_prc": 0.7625241575530807,
            "auditor_fn_violation": 0.01709553952926036,
            "auditor_fp_violation": 0.00733197128136177,
            "ave_precision_score": 0.7339272769179954,
            "fpr": 0.1119648737650933,
            "logloss": 1.9415820430516881,
            "mae": 0.40825296858270393,
            "precision": 0.7243243243243244,
            "recall": 0.5436105476673428
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(12)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.6861372418396977,
            "auditor_fn_violation": 0.006743064276743924,
            "auditor_fp_violation": 0.023801882755669662,
            "ave_precision_score": 0.6874123403517524,
            "fpr": 0.2894736842105263,
            "logloss": 0.6422770015696465,
            "mae": 0.4433844483103936,
            "precision": 0.6111929307805597,
            "recall": 0.9002169197396963
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.6833413372383328,
            "auditor_fn_violation": 0.005673278812263011,
            "auditor_fp_violation": 0.026749090068750363,
            "ave_precision_score": 0.6859489624755521,
            "fpr": 0.265642151481888,
            "logloss": 0.6472745121793291,
            "mae": 0.44448674974690433,
            "precision": 0.6420118343195266,
            "recall": 0.8803245436105477
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(13)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5434059897014604,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.014113373789240286,
            "ave_precision_score": 0.5395311498712116,
            "fpr": 0.12390350877192982,
            "logloss": 11.062098668285664,
            "mae": 0.48613380212994595,
            "precision": 0.5515873015873016,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6046281676616628,
            "auditor_fn_violation": 0.012099135426152745,
            "auditor_fp_violation": 0.015320458615854075,
            "ave_precision_score": 0.5971185360761109,
            "fpr": 0.1119648737650933,
            "logloss": 11.650229909361698,
            "mae": 0.49445619409496916,
            "precision": 0.6106870229007634,
            "recall": 0.32454361054766734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(14)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.6317200667120632,
            "auditor_fn_violation": 0.014373311260798424,
            "auditor_fp_violation": 0.007955031703427084,
            "ave_precision_score": 0.6329891250651956,
            "fpr": 0.043859649122807015,
            "logloss": 2.193587083565891,
            "mae": 0.4688115461941102,
            "precision": 0.696969696969697,
            "recall": 0.19956616052060738
        },
        "train": {
            "accuracy": 0.5159165751920965,
            "auc_prc": 0.6363266763575438,
            "auditor_fn_violation": 0.010723120392409217,
            "auditor_fp_violation": 0.007725880913240091,
            "ave_precision_score": 0.6379898078313753,
            "fpr": 0.03951701427003293,
            "logloss": 1.8757317763508676,
            "mae": 0.4836615409070138,
            "precision": 0.7096774193548387,
            "recall": 0.17849898580121704
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(15)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7392149017212777,
            "auditor_fn_violation": 0.010287038094150776,
            "auditor_fp_violation": 0.017842902711323765,
            "ave_precision_score": 0.6983958821275122,
            "fpr": 0.13486842105263158,
            "logloss": 2.5999276542630367,
            "mae": 0.4163135322497079,
            "precision": 0.690176322418136,
            "recall": 0.5943600867678959
        },
        "train": {
            "accuracy": 0.6454445664105378,
            "auc_prc": 0.7618270447621166,
            "auditor_fn_violation": 0.0157907744649016,
            "auditor_fp_violation": 0.00952210883460523,
            "ave_precision_score": 0.7301275691931284,
            "fpr": 0.12184412733260154,
            "logloss": 2.105748200968617,
            "mae": 0.4085950833228748,
            "precision": 0.7168367346938775,
            "recall": 0.5699797160243407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(16)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6930819951909878,
            "mae": 0.49996596310091646,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6932736440721047,
            "mae": 0.5000620153287894,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(17)",
        "seed": 26311,
        "test": {
            "accuracy": 0.680921052631579,
            "auc_prc": 0.7124048750557523,
            "auditor_fn_violation": 0.014656353465007422,
            "auditor_fp_violation": 0.007140564826700896,
            "ave_precision_score": 0.7095662531013434,
            "fpr": 0.18640350877192982,
            "logloss": 1.6705449850534844,
            "mae": 0.32778443910197536,
            "precision": 0.6666666666666666,
            "recall": 0.737527114967462
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7428317709573302,
            "auditor_fn_violation": 0.019362179180313643,
            "auditor_fp_violation": 0.0200710087763066,
            "ave_precision_score": 0.738327135606967,
            "fpr": 0.16575192096597147,
            "logloss": 1.6444376179552598,
            "mae": 0.3198968724314687,
            "precision": 0.7084942084942085,
            "recall": 0.744421906693712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(18)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.6890057817213624,
            "auditor_fn_violation": 0.0043835864063629815,
            "auditor_fp_violation": 0.023801882755669662,
            "ave_precision_score": 0.6904867674795335,
            "fpr": 0.2894736842105263,
            "logloss": 0.6418819604350872,
            "mae": 0.4463216754527246,
            "precision": 0.6106194690265486,
            "recall": 0.8980477223427332
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6807719345427401,
            "auditor_fn_violation": 0.00749015303157487,
            "auditor_fp_violation": 0.026749090068750363,
            "ave_precision_score": 0.6824018553710828,
            "fpr": 0.265642151481888,
            "logloss": 0.6458462412391381,
            "mae": 0.44701949825434223,
            "precision": 0.6414814814814814,
            "recall": 0.8782961460446247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(19)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.458745524181825,
            "mae": 0.5054824561403509,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.691127072108635,
            "mae": 0.5411635565312843,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(20)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7087563654819922,
            "auditor_fn_violation": 0.027802355672260914,
            "auditor_fp_violation": 0.042977107402652974,
            "ave_precision_score": 0.7088547225953108,
            "fpr": 0.32127192982456143,
            "logloss": 2.1347484449854734,
            "mae": 0.45632111059531194,
            "precision": 0.5513016845329249,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.7652029194243819,
            "auditor_fn_violation": 0.025013192377143906,
            "auditor_fp_violation": 0.032610465391099755,
            "ave_precision_score": 0.7650332732267768,
            "fpr": 0.283205268935236,
            "logloss": 1.7385509588922858,
            "mae": 0.4374964918144453,
            "precision": 0.6120300751879699,
            "recall": 0.8255578093306288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(21)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.8345867139478472,
            "auditor_fn_violation": 0.003988754424021007,
            "auditor_fp_violation": 0.024344050258684413,
            "ave_precision_score": 0.8348231179621974,
            "fpr": 0.4067982456140351,
            "logloss": 1.7027690909732098,
            "mae": 0.43039239495596854,
            "precision": 0.5475609756097561,
            "recall": 0.9739696312364425
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.853293988473451,
            "auditor_fn_violation": 0.0036560140540564615,
            "auditor_fp_violation": 0.020493805114522666,
            "ave_precision_score": 0.853856242257145,
            "fpr": 0.38199780461031835,
            "logloss": 1.4982761383394152,
            "mae": 0.40242658506477497,
            "precision": 0.5802171290711701,
            "recall": 0.9756592292089249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(22)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5499093123041396,
            "auditor_fn_violation": 0.0037485253263310142,
            "auditor_fp_violation": 0.013486112731940723,
            "ave_precision_score": 0.5432098910677627,
            "fpr": 0.12938596491228072,
            "logloss": 11.293051870852272,
            "mae": 0.4839632961393612,
            "precision": 0.5444015444015444,
            "recall": 0.30585683297180044
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5959598727572508,
            "auditor_fn_violation": 0.009841402021272583,
            "auditor_fp_violation": 0.014480118067846996,
            "ave_precision_score": 0.589362672386995,
            "fpr": 0.1141602634467618,
            "logloss": 11.856074323566586,
            "mae": 0.48920349862091456,
            "precision": 0.6133828996282528,
            "recall": 0.33468559837728196
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(23)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8328297353906603,
            "auditor_fn_violation": 0.003988754424021007,
            "auditor_fp_violation": 0.02463823083206911,
            "ave_precision_score": 0.8330833727486705,
            "fpr": 0.40899122807017546,
            "logloss": 1.7468762960579804,
            "mae": 0.43185132172841245,
            "precision": 0.5462287104622872,
            "recall": 0.9739696312364425
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.8527242426484145,
            "auditor_fn_violation": 0.0036560140540564615,
            "auditor_fp_violation": 0.020278467849095847,
            "ave_precision_score": 0.8532869846833566,
            "fpr": 0.38638858397365533,
            "logloss": 1.535424161722227,
            "mae": 0.4038011677078485,
            "precision": 0.5774309723889556,
            "recall": 0.9756592292089249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(24)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.8367450820283039,
            "auditor_fn_violation": 0.004626194009970698,
            "auditor_fp_violation": 0.02419331310537986,
            "ave_precision_score": 0.8369658524909084,
            "fpr": 0.40899122807017546,
            "logloss": 1.6562484919339322,
            "mae": 0.4333983406257421,
            "precision": 0.5456760048721072,
            "recall": 0.9718004338394793
        },
        "train": {
            "accuracy": 0.6026344676180022,
            "auc_prc": 0.8517602064553662,
            "auditor_fn_violation": 0.002665194167299381,
            "auditor_fp_violation": 0.02032048487649621,
            "ave_precision_score": 0.8526945559334143,
            "fpr": 0.38419319429198684,
            "logloss": 1.4503250112678279,
            "mae": 0.40237031989213207,
            "precision": 0.5788206979542719,
            "recall": 0.9756592292089249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(25)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6651308273771248,
            "auditor_fn_violation": 0.00738526087452908,
            "auditor_fp_violation": 0.013799743260590504,
            "ave_precision_score": 0.6557191938419493,
            "fpr": 0.07236842105263158,
            "logloss": 8.901921300786396,
            "mae": 0.41368495947209133,
            "precision": 0.7283950617283951,
            "recall": 0.3839479392624729
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7084107433733796,
            "auditor_fn_violation": 0.015485735533473035,
            "auditor_fp_violation": 0.013915514262154738,
            "ave_precision_score": 0.6989611925315651,
            "fpr": 0.06476399560922064,
            "logloss": 9.253429038445738,
            "mae": 0.4194690983030925,
            "precision": 0.7677165354330708,
            "recall": 0.39553752535496955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(26)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7450502732610396,
            "auditor_fn_violation": 0.01223265593484797,
            "auditor_fp_violation": 0.0102160890029953,
            "ave_precision_score": 0.7441067706845355,
            "fpr": 0.17434210526315788,
            "logloss": 1.4152617522059479,
            "mae": 0.32228322475453797,
            "precision": 0.6807228915662651,
            "recall": 0.735357917570499
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7937671513913545,
            "auditor_fn_violation": 0.01862073418640329,
            "auditor_fp_violation": 0.026229129354670984,
            "ave_precision_score": 0.7940161585055101,
            "fpr": 0.15697036223929747,
            "logloss": 1.2716660452036328,
            "mae": 0.3089927738931536,
            "precision": 0.7190569744597249,
            "recall": 0.742393509127789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(27)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933999812506834,
            "mae": 0.5000770334481147,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6944027504594399,
            "mae": 0.5005783850549997,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(28)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.7429670469725675,
            "auditor_fn_violation": 0.015001236823077222,
            "auditor_fp_violation": 0.009812502431244409,
            "ave_precision_score": 0.7434692335233463,
            "fpr": 0.15350877192982457,
            "logloss": 1.3461582166212454,
            "mae": 0.3150457660037038,
            "precision": 0.7021276595744681,
            "recall": 0.7158351409978309
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.793263671800968,
            "auditor_fn_violation": 0.018854523148447086,
            "auditor_fp_violation": 0.019209659714599342,
            "ave_precision_score": 0.7934102075044935,
            "fpr": 0.132821075740944,
            "logloss": 1.2244755053490721,
            "mae": 0.30761495861071714,
            "precision": 0.7420042643923241,
            "recall": 0.7058823529411765
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(29)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.688708111839299,
            "auditor_fn_violation": 0.0059938349126612625,
            "auditor_fp_violation": 0.024815711673863153,
            "ave_precision_score": 0.6905355391926679,
            "fpr": 0.2883771929824561,
            "logloss": 0.6416023412768949,
            "mae": 0.44183006444895034,
            "precision": 0.6109467455621301,
            "recall": 0.89587852494577
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6838415093990591,
            "auditor_fn_violation": 0.005880349035787525,
            "auditor_fp_violation": 0.027387223672393254,
            "ave_precision_score": 0.6857174239626387,
            "fpr": 0.2645444566410538,
            "logloss": 0.6465441106899377,
            "mae": 0.4429966180938931,
            "precision": 0.6419019316493314,
            "recall": 0.8762677484787018
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(30)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 17.458745524181825,
            "mae": 0.5054824561403509,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 18.691127072108635,
            "mae": 0.5411635565312843,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(31)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.8365301595381983,
            "auditor_fn_violation": 0.0034060204741789405,
            "auditor_fp_violation": 0.022651904150620454,
            "ave_precision_score": 0.8367446355622797,
            "fpr": 0.4100877192982456,
            "logloss": 1.6632607513688002,
            "mae": 0.43151125199618273,
            "precision": 0.5444579780755177,
            "recall": 0.9696312364425163
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.8508616945632052,
            "auditor_fn_violation": 0.003533553169176373,
            "auditor_fp_violation": 0.02032048487649621,
            "ave_precision_score": 0.8514883439364167,
            "fpr": 0.38419319429198684,
            "logloss": 1.458375511984114,
            "mae": 0.4005816767385821,
            "precision": 0.5778045838359469,
            "recall": 0.9716024340770791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(32)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.8347462667039256,
            "auditor_fn_violation": 0.002228660044906192,
            "auditor_fp_violation": 0.016632142996071114,
            "ave_precision_score": 0.8349706941483858,
            "fpr": 0.42653508771929827,
            "logloss": 1.6940522332367927,
            "mae": 0.44212266549533397,
            "precision": 0.5369047619047619,
            "recall": 0.9783080260303688
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8469317655613349,
            "auditor_fn_violation": 0.0022421474740772574,
            "auditor_fp_violation": 0.01632886727346257,
            "ave_precision_score": 0.8483110570227186,
            "fpr": 0.40175631174533477,
            "logloss": 1.5193225262944396,
            "mae": 0.4113660833740077,
            "precision": 0.5683962264150944,
            "recall": 0.9776876267748479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(33)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6648783470709408,
            "auditor_fn_violation": 0.011069566541081557,
            "auditor_fp_violation": 0.013799743260590504,
            "ave_precision_score": 0.6556738911066348,
            "fpr": 0.07236842105263158,
            "logloss": 8.912708343325615,
            "mae": 0.4136567513603845,
            "precision": 0.7295081967213115,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7109507898372915,
            "auditor_fn_violation": 0.01658788349739382,
            "auditor_fp_violation": 0.012626116733806375,
            "ave_precision_score": 0.7014326058258915,
            "fpr": 0.06366630076838639,
            "logloss": 9.259662056275225,
            "mae": 0.41951383388075475,
            "precision": 0.7725490196078432,
            "recall": 0.3995943204868154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(34)",
        "seed": 26311,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7834346796736483,
            "auditor_fn_violation": 0.0065813258743387774,
            "auditor_fp_violation": 0.012608433500602952,
            "ave_precision_score": 0.7748631336305909,
            "fpr": 0.17543859649122806,
            "logloss": 1.6231312701289056,
            "mae": 0.3057939926700642,
            "precision": 0.6881091617933723,
            "recall": 0.7657266811279827
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.8208466236356867,
            "auditor_fn_violation": 0.01581971976496416,
            "auditor_fp_violation": 0.024506431231256478,
            "ave_precision_score": 0.8190656055503747,
            "fpr": 0.15806805708013172,
            "logloss": 1.3503624723348038,
            "mae": 0.29964304817834964,
            "precision": 0.7236084452975048,
            "recall": 0.7647058823529411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(35)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6651397350649773,
            "auditor_fn_violation": 0.00738526087452908,
            "auditor_fp_violation": 0.013799743260590504,
            "ave_precision_score": 0.6557280530832352,
            "fpr": 0.07236842105263158,
            "logloss": 8.901940920829952,
            "mae": 0.4136876630490269,
            "precision": 0.7283950617283951,
            "recall": 0.3839479392624729
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7084002864478598,
            "auditor_fn_violation": 0.015485735533473035,
            "auditor_fp_violation": 0.013915514262154738,
            "ave_precision_score": 0.6989507619157358,
            "fpr": 0.06476399560922064,
            "logloss": 9.253457042051643,
            "mae": 0.41947411645944205,
            "precision": 0.7677165354330708,
            "recall": 0.39553752535496955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(36)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5712719298245614,
            "auc_prc": 0.5780533629796609,
            "auditor_fn_violation": 0.012934315180576179,
            "auditor_fp_violation": 0.012661920877581986,
            "ave_precision_score": 0.5808327076421589,
            "fpr": 0.13048245614035087,
            "logloss": 5.041192994657425,
            "mae": 0.42697484327201973,
            "precision": 0.6136363636363636,
            "recall": 0.40997830802603036
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6319578717090071,
            "auditor_fn_violation": 0.016536672581898497,
            "auditor_fp_violation": 0.016465422612513724,
            "ave_precision_score": 0.6337303127647813,
            "fpr": 0.1141602634467618,
            "logloss": 4.924255186119907,
            "mae": 0.431655410630155,
            "precision": 0.6770186335403726,
            "recall": 0.4421906693711968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(37)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7465571029870399,
            "auditor_fn_violation": 0.015400825817254637,
            "auditor_fp_violation": 0.009754152565449106,
            "ave_precision_score": 0.7453470954897783,
            "fpr": 0.17214912280701755,
            "logloss": 1.408254344072673,
            "mae": 0.31815330177489276,
            "precision": 0.6828282828282828,
            "recall": 0.7331887201735358
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7943737694411388,
            "auditor_fn_violation": 0.020978662860730798,
            "auditor_fp_violation": 0.02595339261235616,
            "ave_precision_score": 0.7944663079437715,
            "fpr": 0.150384193194292,
            "logloss": 1.2670714410152142,
            "mae": 0.3067967470843151,
            "precision": 0.7248995983935743,
            "recall": 0.7322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(38)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5200814707413267,
            "auditor_fn_violation": 0.005874909616775136,
            "auditor_fp_violation": 0.012676508344030812,
            "ave_precision_score": 0.5317102367083335,
            "fpr": 0.12171052631578948,
            "logloss": 7.697458983528891,
            "mae": 0.4646587833270139,
            "precision": 0.5827067669172933,
            "recall": 0.3362255965292842
        },
        "train": {
            "accuracy": 0.5433589462129528,
            "auc_prc": 0.5950641266916492,
            "auditor_fn_violation": 0.008955230527049378,
            "auditor_fp_violation": 0.017936018571526116,
            "ave_precision_score": 0.6041163665595741,
            "fpr": 0.11745334796926454,
            "logloss": 7.85509022842404,
            "mae": 0.4697276515913527,
            "precision": 0.6323024054982818,
            "recall": 0.37322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(39)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5756578947368421,
            "auc_prc": 0.6950106739568327,
            "auditor_fn_violation": 0.026572668112798268,
            "auditor_fp_violation": 0.04169341035515619,
            "ave_precision_score": 0.6955860587053729,
            "fpr": 0.3267543859649123,
            "logloss": 2.0865099169386507,
            "mae": 0.4561443931546442,
            "precision": 0.5552238805970149,
            "recall": 0.806941431670282
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.7562779942103808,
            "auditor_fn_violation": 0.02438975514502709,
            "auditor_fp_violation": 0.03334051124218092,
            "ave_precision_score": 0.7564899209145903,
            "fpr": 0.29527991218441274,
            "logloss": 1.6933440962324213,
            "mae": 0.4382618310254911,
            "precision": 0.6044117647058823,
            "recall": 0.8336713995943205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(40)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8249488631766606,
            "auditor_fn_violation": 0.004949670814780987,
            "auditor_fp_violation": 0.02665373244641537,
            "ave_precision_score": 0.8251996047385718,
            "fpr": 0.24451754385964913,
            "logloss": 0.5550891065200984,
            "mae": 0.3760195303169128,
            "precision": 0.6385737439222042,
            "recall": 0.8546637744034707
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.8354730911107473,
            "auditor_fn_violation": 0.011689448102190272,
            "auditor_fp_violation": 0.02726905078282976,
            "ave_precision_score": 0.8357974576749476,
            "fpr": 0.22283205268935236,
            "logloss": 0.5403215080880863,
            "mae": 0.36629348884936747,
            "precision": 0.6762360446570973,
            "recall": 0.8600405679513184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(41)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.696907016975473,
            "auditor_fn_violation": 0.028301841914982685,
            "auditor_fp_violation": 0.04106858054226475,
            "ave_precision_score": 0.6973512535041877,
            "fpr": 0.31469298245614036,
            "logloss": 2.1753080529538877,
            "mae": 0.4541019560279071,
            "precision": 0.5557275541795665,
            "recall": 0.7787418655097614
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.7560887963613878,
            "auditor_fn_violation": 0.02272428711065788,
            "auditor_fp_violation": 0.028393006265789215,
            "ave_precision_score": 0.7561639040887369,
            "fpr": 0.27552140504939626,
            "logloss": 1.7942852438502563,
            "mae": 0.44124478504362147,
            "precision": 0.6150306748466258,
            "recall": 0.8133874239350912
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(42)",
        "seed": 26311,
        "test": {
            "accuracy": 0.49451754385964913,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6933092089266504,
            "mae": 0.5000417388387417,
            "precision": 0,
            "recall": 0
        },
        "train": {
            "accuracy": 0.4588364434687157,
            "auc_prc": 0,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0,
            "ave_precision_score": 0,
            "fpr": 0.0,
            "logloss": 0.6942481130337075,
            "mae": 0.5005110769515242,
            "precision": 0,
            "recall": 0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(43)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7862247378616968,
            "auditor_fn_violation": 0.009773280815922677,
            "auditor_fp_violation": 0.011392811296534022,
            "ave_precision_score": 0.7775236560524045,
            "fpr": 0.1699561403508772,
            "logloss": 1.6261648073957287,
            "mae": 0.305399594959326,
            "precision": 0.6936758893280632,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.8204938505731264,
            "auditor_fn_violation": 0.013472923898353015,
            "auditor_fp_violation": 0.023920818911864043,
            "ave_precision_score": 0.8177459401686652,
            "fpr": 0.1525795828759605,
            "logloss": 1.3688865599588533,
            "mae": 0.29837052713865736,
            "precision": 0.7295719844357976,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(44)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7439646297677023,
            "auditor_fn_violation": 0.017505803554439245,
            "auditor_fp_violation": 0.010485957132298598,
            "ave_precision_score": 0.7443021204754761,
            "fpr": 0.14912280701754385,
            "logloss": 1.359151428561431,
            "mae": 0.31987200024502627,
            "precision": 0.7024070021881839,
            "recall": 0.6963123644251626
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.792549212764343,
            "auditor_fn_violation": 0.021568701669698508,
            "auditor_fp_violation": 0.016607230079989918,
            "ave_precision_score": 0.7928408246540817,
            "fpr": 0.12623490669593854,
            "logloss": 1.2511505414017388,
            "mae": 0.31140428036460294,
            "precision": 0.7466960352422908,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(45)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.8288083297561673,
            "auditor_fn_violation": 0.011240818967157595,
            "auditor_fp_violation": 0.022882872369393563,
            "ave_precision_score": 0.8290549328164899,
            "fpr": 0.1513157894736842,
            "logloss": 0.5348235036001484,
            "mae": 0.36833978118783417,
            "precision": 0.710691823899371,
            "recall": 0.735357917570499
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8372241772633671,
            "auditor_fn_violation": 0.0032730454686132793,
            "auditor_fp_violation": 0.02191187978928461,
            "ave_precision_score": 0.8375451933479068,
            "fpr": 0.14709110867178923,
            "logloss": 0.5285528892682385,
            "mae": 0.3631231386958735,
            "precision": 0.7276422764227642,
            "recall": 0.7261663286004056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(46)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.7261509697368479,
            "auditor_fn_violation": 0.017715112075198845,
            "auditor_fp_violation": 0.007655988641226136,
            "ave_precision_score": 0.7252829970983166,
            "fpr": 0.17543859649122806,
            "logloss": 1.47111718037764,
            "mae": 0.33050776138237775,
            "precision": 0.6780684104627767,
            "recall": 0.7310195227765727
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7826585795922829,
            "auditor_fn_violation": 0.02401346624421373,
            "auditor_fp_violation": 0.022552639457140006,
            "ave_precision_score": 0.7822765708511922,
            "fpr": 0.15148188803512624,
            "logloss": 1.2941758575183466,
            "mae": 0.31395814383983445,
            "precision": 0.7217741935483871,
            "recall": 0.7261663286004056
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(47)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5241618828198474,
            "auditor_fn_violation": 0.01156429577196789,
            "auditor_fp_violation": 0.014305442097483176,
            "ave_precision_score": 0.5350984970450434,
            "fpr": 0.11293859649122807,
            "logloss": 7.647500368371653,
            "mae": 0.46100749536707336,
            "precision": 0.6038461538461538,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6044526027292686,
            "auditor_fn_violation": 0.00912890232742478,
            "auditor_fp_violation": 0.012673385889631773,
            "ave_precision_score": 0.6130854844146134,
            "fpr": 0.10428100987925357,
            "logloss": 7.792363244206258,
            "mae": 0.4580685883143729,
            "precision": 0.6607142857142857,
            "recall": 0.3752535496957404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(48)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5237225433563572,
            "auditor_fn_violation": 0.011316931156524723,
            "auditor_fp_violation": 0.013804605749406776,
            "ave_precision_score": 0.5345688400316299,
            "fpr": 0.11513157894736842,
            "logloss": 7.623015599270087,
            "mae": 0.4608982607445439,
            "precision": 0.5977011494252874,
            "recall": 0.3383947939262473
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6038171353698758,
            "auditor_fn_violation": 0.008545543203086902,
            "auditor_fp_violation": 0.012563091192705845,
            "ave_precision_score": 0.6124615276153176,
            "fpr": 0.10318331503841932,
            "logloss": 7.806588990216303,
            "mae": 0.45908936103061265,
            "precision": 0.6618705035971223,
            "recall": 0.37322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(49)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6654282914995855,
            "auditor_fn_violation": 0.00738526087452908,
            "auditor_fp_violation": 0.013281888201657138,
            "ave_precision_score": 0.6560120144132581,
            "fpr": 0.0712719298245614,
            "logloss": 8.901499699392776,
            "mae": 0.4138308215293663,
            "precision": 0.731404958677686,
            "recall": 0.3839479392624729
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7082894828962131,
            "auditor_fn_violation": 0.01610249308096002,
            "auditor_fp_violation": 0.013915514262154738,
            "ave_precision_score": 0.6988405225205108,
            "fpr": 0.06476399560922064,
            "logloss": 9.25379938415099,
            "mae": 0.41976563132251304,
            "precision": 0.766798418972332,
            "recall": 0.3935091277890467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(50)",
        "seed": 26311,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5705423879386994,
            "auditor_fn_violation": 0.014173516763709705,
            "auditor_fp_violation": 0.017536565915898392,
            "ave_precision_score": 0.5685961297897015,
            "fpr": 0.14035087719298245,
            "logloss": 4.91160819179607,
            "mae": 0.41939635883373744,
            "precision": 0.6179104477611941,
            "recall": 0.4490238611713666
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6268847420405776,
            "auditor_fn_violation": 0.01408745488429674,
            "auditor_fp_violation": 0.021029522213877182,
            "ave_precision_score": 0.6256825987833852,
            "fpr": 0.1207464324917673,
            "logloss": 4.631030616068359,
            "mae": 0.42496616114726743,
            "precision": 0.6764705882352942,
            "recall": 0.4665314401622718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(51)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5778508771929824,
            "auc_prc": 0.8304465031857322,
            "auditor_fn_violation": 0.004609544468546637,
            "auditor_fp_violation": 0.02436350021394951,
            "ave_precision_score": 0.8307539636706243,
            "fpr": 0.4100877192982456,
            "logloss": 1.7555248287491492,
            "mae": 0.4323916287758697,
            "precision": 0.5461165048543689,
            "recall": 0.9761388286334056
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.8530296978636518,
            "auditor_fn_violation": 0.0036560140540564615,
            "auditor_fp_violation": 0.021672907945945088,
            "ave_precision_score": 0.8535696232914957,
            "fpr": 0.38748627881448955,
            "logloss": 1.5460136005771932,
            "mae": 0.40464768277252494,
            "precision": 0.5767386091127098,
            "recall": 0.9756592292089249
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(52)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.7627057940812421,
            "auditor_fn_violation": 0.00831525668835864,
            "auditor_fp_violation": 0.014142548722137938,
            "ave_precision_score": 0.7614383823151119,
            "fpr": 0.17763157894736842,
            "logloss": 1.3055505465428154,
            "mae": 0.30600479944194064,
            "precision": 0.6842105263157895,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8047374622528234,
            "auditor_fn_violation": 0.00692683296112646,
            "auditor_fp_violation": 0.027967583863360627,
            "ave_precision_score": 0.8039788286064352,
            "fpr": 0.1602634467618002,
            "logloss": 1.1858721763424658,
            "mae": 0.2956764320896045,
            "precision": 0.7281191806331471,
            "recall": 0.7931034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(53)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.5234197576830838,
            "auditor_fn_violation": 0.009240495490352775,
            "auditor_fp_violation": 0.011672404403469876,
            "ave_precision_score": 0.534202066022202,
            "fpr": 0.11293859649122807,
            "logloss": 7.618149045556603,
            "mae": 0.46157687242517287,
            "precision": 0.6007751937984496,
            "recall": 0.3362255965292842
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6038582261909007,
            "auditor_fn_violation": 0.009678863028613554,
            "auditor_fp_violation": 0.01410196482124381,
            "ave_precision_score": 0.6123525728058816,
            "fpr": 0.10757409440175632,
            "logloss": 7.757169448739694,
            "mae": 0.4592881848550771,
            "precision": 0.6537102473498233,
            "recall": 0.3752535496957404
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(54)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.4994398174512744,
            "auditor_fn_violation": 0.007665924572820344,
            "auditor_fp_violation": 0.015910063406854167,
            "ave_precision_score": 0.50962538543186,
            "fpr": 0.14144736842105263,
            "logloss": 7.768744840103522,
            "mae": 0.47749975913171755,
            "precision": 0.5582191780821918,
            "recall": 0.35357917570498915
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5607059200505087,
            "auditor_fn_violation": 0.006853356430198402,
            "auditor_fp_violation": 0.021129312653953014,
            "ave_precision_score": 0.5699944172034717,
            "fpr": 0.13611416026344675,
            "logloss": 7.966695587851662,
            "mae": 0.4822255296117895,
            "precision": 0.6038338658146964,
            "recall": 0.38336713995943206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(55)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7397283619412495,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.016734255261212902,
            "ave_precision_score": 0.6982190867341691,
            "fpr": 0.13157894736842105,
            "logloss": 2.54650215767023,
            "mae": 0.4137021786157499,
            "precision": 0.689119170984456,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.760863743704348,
            "auditor_fn_violation": 0.015902102542065324,
            "auditor_fp_violation": 0.008098782031418231,
            "ave_precision_score": 0.7281451898792096,
            "fpr": 0.1163556531284303,
            "logloss": 2.100447895711022,
            "mae": 0.4084569916505322,
            "precision": 0.7203166226912929,
            "recall": 0.5537525354969574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(56)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5219298245614035,
            "auc_prc": 0.5445068781324987,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.010007001983895442,
            "ave_precision_score": 0.5406193830848689,
            "fpr": 0.125,
            "logloss": 11.057059091154693,
            "mae": 0.48608530764761165,
            "precision": 0.549407114624506,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.6048184364431457,
            "auditor_fn_violation": 0.012600111773389489,
            "auditor_fp_violation": 0.014900288341850535,
            "ave_precision_score": 0.5972954711369917,
            "fpr": 0.11306256860592755,
            "logloss": 11.64548041519524,
            "mae": 0.4944471955356128,
            "precision": 0.6098484848484849,
            "recall": 0.3265720081135903
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(57)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.8252233174548887,
            "auditor_fn_violation": 0.004949670814780987,
            "auditor_fp_violation": 0.02665373244641537,
            "ave_precision_score": 0.8254737121862556,
            "fpr": 0.24451754385964913,
            "logloss": 0.5550628300411607,
            "mae": 0.37608570625940174,
            "precision": 0.6385737439222042,
            "recall": 0.8546637744034707
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.835861157854687,
            "auditor_fn_violation": 0.011689448102190272,
            "auditor_fp_violation": 0.02726905078282976,
            "ave_precision_score": 0.8361776727990573,
            "fpr": 0.22283205268935236,
            "logloss": 0.5402664668864364,
            "mae": 0.3663416811634105,
            "precision": 0.6762360446570973,
            "recall": 0.8600405679513184
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(58)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.5239873796785013,
            "auditor_fn_violation": 0.01018238383377098,
            "auditor_fp_violation": 0.009598552923328282,
            "ave_precision_score": 0.5347507821755615,
            "fpr": 0.11513157894736842,
            "logloss": 7.600272407685794,
            "mae": 0.4614596208642347,
            "precision": 0.5930232558139535,
            "recall": 0.3318872017353579
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6053578254641496,
            "auditor_fn_violation": 0.008955230527049378,
            "auditor_fp_violation": 0.015777393788832923,
            "ave_precision_score": 0.613856966331078,
            "fpr": 0.10318331503841932,
            "logloss": 7.733610685580831,
            "mae": 0.4584635378441305,
            "precision": 0.6618705035971223,
            "recall": 0.37322515212981744
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(59)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.73970091880397,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.018073870930096863,
            "ave_precision_score": 0.6981813095635776,
            "fpr": 0.12828947368421054,
            "logloss": 2.5330225629654812,
            "mae": 0.4138345347815438,
            "precision": 0.6945169712793734,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6399560922063666,
            "auc_prc": 0.7608378621054318,
            "auditor_fn_violation": 0.017431750322294794,
            "auditor_fp_violation": 0.008098782031418231,
            "ave_precision_score": 0.7281123472173947,
            "fpr": 0.1163556531284303,
            "logloss": 2.0922682949848768,
            "mae": 0.4085368865080644,
            "precision": 0.7188328912466844,
            "recall": 0.5496957403651116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(60)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.688992704874936,
            "auditor_fn_violation": 0.0043835864063629815,
            "auditor_fp_violation": 0.023801882755669662,
            "ave_precision_score": 0.690473916651136,
            "fpr": 0.2894736842105263,
            "logloss": 0.6418327528889295,
            "mae": 0.4460349435727805,
            "precision": 0.6106194690265486,
            "recall": 0.8980477223427332
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6809633900133971,
            "auditor_fn_violation": 0.00749015303157487,
            "auditor_fp_violation": 0.026749090068750363,
            "ave_precision_score": 0.6825903154522248,
            "fpr": 0.265642151481888,
            "logloss": 0.6458764408406517,
            "mae": 0.44677385194628355,
            "precision": 0.6414814814814814,
            "recall": 0.8782961460446247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(61)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5625,
            "auc_prc": 0.8347683831222857,
            "auditor_fn_violation": 0.002228660044906192,
            "auditor_fp_violation": 0.016632142996071114,
            "ave_precision_score": 0.8349937760104977,
            "fpr": 0.42653508771929827,
            "logloss": 1.6944691993355794,
            "mae": 0.4421935370028542,
            "precision": 0.5369047619047619,
            "recall": 0.9783080260303688
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.8469427872396565,
            "auditor_fn_violation": 0.0022421474740772574,
            "auditor_fp_violation": 0.01632886727346257,
            "ave_precision_score": 0.8483300075208544,
            "fpr": 0.40175631174533477,
            "logloss": 1.5202187489954893,
            "mae": 0.41157881550809816,
            "precision": 0.5683962264150944,
            "recall": 0.9776876267748479
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(62)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5228295771670572,
            "auditor_fn_violation": 0.0083937473836435,
            "auditor_fp_violation": 0.011358773874820087,
            "ave_precision_score": 0.5336034540001771,
            "fpr": 0.11842105263157894,
            "logloss": 7.616280466247675,
            "mae": 0.46115930313701237,
            "precision": 0.5924528301886792,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.6067122665681746,
            "auditor_fn_violation": 0.009102183588905506,
            "auditor_fp_violation": 0.01834831065289209,
            "ave_precision_score": 0.6150504141411754,
            "fpr": 0.11086717892425905,
            "logloss": 7.745361978892968,
            "mae": 0.45796492107116715,
            "precision": 0.6505190311418685,
            "recall": 0.3813387423935091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(63)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6546052631578947,
            "auc_prc": 0.7396905983923403,
            "auditor_fn_violation": 0.0044906191726605035,
            "auditor_fp_violation": 0.016734255261212902,
            "ave_precision_score": 0.6981658002329512,
            "fpr": 0.13157894736842105,
            "logloss": 2.5413343350645134,
            "mae": 0.4137958857443249,
            "precision": 0.689119170984456,
            "recall": 0.5770065075921909
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.7608439491419468,
            "auditor_fn_violation": 0.015902102542065324,
            "auditor_fp_violation": 0.008098782031418231,
            "ave_precision_score": 0.7281040016929172,
            "fpr": 0.1163556531284303,
            "logloss": 2.097029859679886,
            "mae": 0.4085032544727514,
            "precision": 0.7203166226912929,
            "recall": 0.5537525354969574
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(64)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5214606233994793,
            "auditor_fn_violation": 0.01156429577196789,
            "auditor_fp_violation": 0.01160919204885829,
            "ave_precision_score": 0.5323985936099486,
            "fpr": 0.1162280701754386,
            "logloss": 7.635303306374037,
            "mae": 0.4623351923570285,
            "precision": 0.596958174904943,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6005986602186498,
            "auditor_fn_violation": 0.01018206593739355,
            "auditor_fp_violation": 0.016580969437864697,
            "ave_precision_score": 0.6092607590098033,
            "fpr": 0.10867178924259056,
            "logloss": 7.779660007269096,
            "mae": 0.4603803178769459,
            "precision": 0.6538461538461539,
            "recall": 0.3793103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(65)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.739011447377803,
            "auditor_fn_violation": 0.01783165886516726,
            "auditor_fp_violation": 0.009333547282841253,
            "ave_precision_score": 0.7392079127756399,
            "fpr": 0.15021929824561403,
            "logloss": 1.3790932775290479,
            "mae": 0.3237415449447252,
            "precision": 0.6989010989010989,
            "recall": 0.6898047722342733
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7887019369808341,
            "auditor_fn_violation": 0.022917997964922755,
            "auditor_fp_violation": 0.01724798974784532,
            "ave_precision_score": 0.7890769099767869,
            "fpr": 0.12733260153677278,
            "logloss": 1.2718681757770367,
            "mae": 0.31421701794280854,
            "precision": 0.7461706783369803,
            "recall": 0.691683569979716
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(66)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.5392838201780095,
            "auditor_fn_violation": 0.008669654070099328,
            "auditor_fp_violation": 0.017935289998833013,
            "ave_precision_score": 0.541882529539453,
            "fpr": 0.14802631578947367,
            "logloss": 5.542395490826766,
            "mae": 0.4506047733325026,
            "precision": 0.5896656534954408,
            "recall": 0.420824295010846
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.6005386778062167,
            "auditor_fn_violation": 0.0075280045778105455,
            "auditor_fp_violation": 0.01592182732052165,
            "ave_precision_score": 0.6031344349420938,
            "fpr": 0.1350164654226125,
            "logloss": 5.452875034589981,
            "mae": 0.44999923332486924,
            "precision": 0.6455331412103746,
            "recall": 0.4543610547667343
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(67)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.522492133378525,
            "auditor_fn_violation": 0.01156429577196789,
            "auditor_fp_violation": 0.011234780410005054,
            "ave_precision_score": 0.5334268547819937,
            "fpr": 0.11513157894736842,
            "logloss": 7.64857364596402,
            "mae": 0.46169350034078444,
            "precision": 0.5992366412213741,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.6022635747169575,
            "auditor_fn_violation": 0.01018206593739355,
            "auditor_fp_violation": 0.01344282270390076,
            "ave_precision_score": 0.6109134408768722,
            "fpr": 0.10647639956092206,
            "logloss": 7.79439995551508,
            "mae": 0.45947721205718506,
            "precision": 0.6584507042253521,
            "recall": 0.3793103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(68)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.7311932081769469,
            "auditor_fn_violation": 0.018002911291243293,
            "auditor_fp_violation": 0.014820865912008405,
            "ave_precision_score": 0.7319363731188939,
            "fpr": 0.1699561403508772,
            "logloss": 1.4294208561283015,
            "mae": 0.3262944400649415,
            "precision": 0.6810699588477366,
            "recall": 0.7180043383947939
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7830127363192749,
            "auditor_fn_violation": 0.012088002618436382,
            "auditor_fp_violation": 0.018269528726516427,
            "ave_precision_score": 0.7837406086674001,
            "fpr": 0.150384193194292,
            "logloss": 1.3062767104087838,
            "mae": 0.31537678057855834,
            "precision": 0.7265469061876247,
            "recall": 0.7383367139959433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(69)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5456061351327318,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.014113373789240286,
            "ave_precision_score": 0.5417203710937157,
            "fpr": 0.12390350877192982,
            "logloss": 10.96052432690884,
            "mae": 0.48609933924296855,
            "precision": 0.5515873015873016,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5997089907782479,
            "auditor_fn_violation": 0.012099135426152745,
            "auditor_fp_violation": 0.015320458615854075,
            "ave_precision_score": 0.5923090472402615,
            "fpr": 0.1119648737650933,
            "logloss": 11.556371421820558,
            "mae": 0.4956105818006863,
            "precision": 0.6106870229007634,
            "recall": 0.32454361054766734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(70)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.5241931528195007,
            "auditor_fn_violation": 0.0083937473836435,
            "auditor_fp_violation": 0.00813494378962929,
            "ave_precision_score": 0.5344259207486661,
            "fpr": 0.11403508771929824,
            "logloss": 7.639041465023337,
            "mae": 0.46079838942341766,
            "precision": 0.6015325670498084,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.5565312843029637,
            "auc_prc": 0.6053563950733287,
            "auditor_fn_violation": 0.0096142927438586,
            "auditor_fp_violation": 0.018629299523631952,
            "ave_precision_score": 0.6136919276118813,
            "fpr": 0.10757409440175632,
            "logloss": 7.778136641191584,
            "mae": 0.45904140488479267,
            "precision": 0.656140350877193,
            "recall": 0.3793103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(71)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6640141321788832,
            "auditor_fn_violation": 0.009571107812916235,
            "auditor_fp_violation": 0.013799743260590504,
            "ave_precision_score": 0.6546297840886272,
            "fpr": 0.07236842105263158,
            "logloss": 8.906652095583787,
            "mae": 0.41346280157658577,
            "precision": 0.7295081967213115,
            "recall": 0.38611713665943603
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.7091564786618944,
            "auditor_fn_violation": 0.015490188656559566,
            "auditor_fp_violation": 0.012957000824584163,
            "ave_precision_score": 0.6997062410764137,
            "fpr": 0.06366630076838639,
            "logloss": 9.256202839404697,
            "mae": 0.41916110038203264,
            "precision": 0.7725490196078432,
            "recall": 0.3995943204868154
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(72)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5390436763954292,
            "auditor_fn_violation": 0.008120219203105383,
            "auditor_fp_violation": 0.013184638425331628,
            "ave_precision_score": 0.5418410195578125,
            "fpr": 0.13267543859649122,
            "logloss": 5.646314413520021,
            "mae": 0.4398811552431607,
            "precision": 0.621875,
            "recall": 0.4316702819956616
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6034827581797377,
            "auditor_fn_violation": 0.007463434293055598,
            "auditor_fp_violation": 0.020278467849095854,
            "ave_precision_score": 0.6061261011310387,
            "fpr": 0.1207464324917673,
            "logloss": 5.578408156136124,
            "mae": 0.44449549251980064,
            "precision": 0.6646341463414634,
            "recall": 0.4421906693711968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(73)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.8469786188071369,
            "auditor_fn_violation": 0.0035439738174068585,
            "auditor_fp_violation": 0.01714270432178008,
            "ave_precision_score": 0.847179615813544,
            "fpr": 0.4100877192982456,
            "logloss": 1.765493383945042,
            "mae": 0.42973947335032564,
            "precision": 0.5439024390243903,
            "recall": 0.9674620390455532
        },
        "train": {
            "accuracy": 0.6114160263446762,
            "auc_prc": 0.8611348268760234,
            "auditor_fn_violation": 0.002059569427528762,
            "auditor_fp_violation": 0.023660838554824343,
            "ave_precision_score": 0.8623551015983947,
            "fpr": 0.3721185510428101,
            "logloss": 1.5730254240220234,
            "mae": 0.39233761845804693,
            "precision": 0.5850673194614443,
            "recall": 0.9695740365111561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(74)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7835954116513578,
            "auditor_fn_violation": 0.00758029835978232,
            "auditor_fp_violation": 0.012608433500602952,
            "ave_precision_score": 0.7750381841611812,
            "fpr": 0.17543859649122806,
            "logloss": 1.6235926850978393,
            "mae": 0.30580830349511157,
            "precision": 0.6868884540117417,
            "recall": 0.7613882863340564
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8216270368621245,
            "auditor_fn_violation": 0.0160245634269454,
            "auditor_fp_violation": 0.023802646022300544,
            "ave_precision_score": 0.8198370394109842,
            "fpr": 0.15697036223929747,
            "logloss": 1.3483571269563022,
            "mae": 0.2993586512518416,
            "precision": 0.7239382239382239,
            "recall": 0.7606490872210954
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(75)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7868932638464674,
            "auditor_fn_violation": 0.008108326673516766,
            "auditor_fp_violation": 0.01866466332127436,
            "ave_precision_score": 0.7781479331510285,
            "fpr": 0.19188596491228072,
            "logloss": 1.634554163819656,
            "mae": 0.307536911303882,
            "precision": 0.6722846441947565,
            "recall": 0.7787418655097614
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8201016645241671,
            "auditor_fn_violation": 0.008970816457852304,
            "auditor_fp_violation": 0.02575381173220448,
            "ave_precision_score": 0.8173558959695282,
            "fpr": 0.16794731064763996,
            "logloss": 1.3740975636835702,
            "mae": 0.2993692551264215,
            "precision": 0.71875,
            "recall": 0.7931034482758621
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(76)",
        "seed": 26311,
        "test": {
            "accuracy": 0.668859649122807,
            "auc_prc": 0.7010828559416695,
            "auditor_fn_violation": 0.0218037637477642,
            "auditor_fp_violation": 0.016442505932236357,
            "ave_precision_score": 0.7027437878263767,
            "fpr": 0.16337719298245615,
            "logloss": 1.9765384401489383,
            "mae": 0.34211241055701214,
            "precision": 0.6739606126914661,
            "recall": 0.6681127982646421
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7587311200149631,
            "auditor_fn_violation": 0.013078822505193472,
            "auditor_fp_violation": 0.02120021638769112,
            "ave_precision_score": 0.759194443845939,
            "fpr": 0.14818880351262348,
            "logloss": 1.7846841240129994,
            "mae": 0.325666096496105,
            "precision": 0.7222222222222222,
            "recall": 0.7119675456389453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(77)",
        "seed": 26311,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7831660870657955,
            "auditor_fn_violation": 0.0065813258743387774,
            "auditor_fp_violation": 0.012608433500602952,
            "ave_precision_score": 0.774597229291926,
            "fpr": 0.17543859649122806,
            "logloss": 1.6327365579034772,
            "mae": 0.3060730477750562,
            "precision": 0.6881091617933723,
            "recall": 0.7657266811279827
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.8207700313195795,
            "auditor_fn_violation": 0.016939680221231157,
            "auditor_fp_violation": 0.024506431231256478,
            "ave_precision_score": 0.8189903968401,
            "fpr": 0.15806805708013172,
            "logloss": 1.3590322852895453,
            "mae": 0.29978218801534157,
            "precision": 0.7230769230769231,
            "recall": 0.7626774847870182
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(78)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7440837938284312,
            "auditor_fn_violation": 0.012648894470449439,
            "auditor_fp_violation": 0.012365309059789168,
            "ave_precision_score": 0.7431002778177564,
            "fpr": 0.17324561403508773,
            "logloss": 1.4127949749036544,
            "mae": 0.3224405661382644,
            "precision": 0.6808080808080809,
            "recall": 0.7310195227765727
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7931798337931371,
            "auditor_fn_violation": 0.019106124602837088,
            "auditor_fp_violation": 0.025131434513836738,
            "ave_precision_score": 0.7934664087515815,
            "fpr": 0.15697036223929747,
            "logloss": 1.2717784696191137,
            "mae": 0.30919736969772854,
            "precision": 0.717948717948718,
            "recall": 0.7383367139959433
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(79)",
        "seed": 26311,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7465373978249705,
            "auditor_fn_violation": 0.013057997488297753,
            "auditor_fp_violation": 0.009812502431244409,
            "ave_precision_score": 0.7474509975434387,
            "fpr": 0.15350877192982457,
            "logloss": 1.3233359017808488,
            "mae": 0.31271120567078065,
            "precision": 0.7040169133192389,
            "recall": 0.7223427331887202
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7957141274000391,
            "auditor_fn_violation": 0.020034600766382495,
            "auditor_fp_violation": 0.02017867740902001,
            "ave_precision_score": 0.7959072537472766,
            "fpr": 0.13391877058177826,
            "logloss": 1.2012726355227827,
            "mae": 0.3058677067501387,
            "precision": 0.7398720682302772,
            "recall": 0.7038539553752535
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(80)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.606089961450371,
            "auditor_fn_violation": 0.011749819233550264,
            "auditor_fp_violation": 0.03163292099428172,
            "ave_precision_score": 0.5944776344667182,
            "fpr": 0.16447368421052633,
            "logloss": 8.948777578497015,
            "mae": 0.4632370880706908,
            "precision": 0.5714285714285714,
            "recall": 0.43383947939262474
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.6731703193356191,
            "auditor_fn_violation": 0.010674136038457164,
            "auditor_fp_violation": 0.02661253472969921,
            "ave_precision_score": 0.660214631463377,
            "fpr": 0.14050493962678376,
            "logloss": 9.300408251060578,
            "mae": 0.4674920681658786,
            "precision": 0.6311239193083573,
            "recall": 0.44421906693711966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(81)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5514331119111435,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.014113373789240286,
            "ave_precision_score": 0.5448275641015149,
            "fpr": 0.12390350877192982,
            "logloss": 11.285697970999259,
            "mae": 0.4843589000164224,
            "precision": 0.5515873015873016,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5214050493962679,
            "auc_prc": 0.6091189934252457,
            "auditor_fn_violation": 0.01159815907891603,
            "auditor_fp_violation": 0.015320458615854075,
            "ave_precision_score": 0.6022344853875097,
            "fpr": 0.1119648737650933,
            "logloss": 11.844361855309316,
            "mae": 0.4934775236413865,
            "precision": 0.6091954022988506,
            "recall": 0.3225152129817444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(82)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5361842105263158,
            "auc_prc": 0.8467489480899187,
            "auditor_fn_violation": 0.002877992160444495,
            "auditor_fp_violation": 0.010563756953359022,
            "ave_precision_score": 0.8469659562330912,
            "fpr": 0.4583333333333333,
            "logloss": 2.473993075005047,
            "mae": 0.4566725418032882,
            "precision": 0.5217391304347826,
            "recall": 0.9891540130151844
        },
        "train": {
            "accuracy": 0.5806805708013172,
            "auc_prc": 0.8658429515151808,
            "auditor_fn_violation": 0.0005855856858811507,
            "auditor_fp_violation": 0.016604604015777406,
            "ave_precision_score": 0.8663767426157444,
            "fpr": 0.41602634467618005,
            "logloss": 2.2139439683659092,
            "mae": 0.4153915929641783,
            "precision": 0.5638665132336018,
            "recall": 0.9939148073022313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(83)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.4962318551011394,
            "auditor_fn_violation": 0.008136868744529433,
            "auditor_fp_violation": 0.01324541953553507,
            "ave_precision_score": 0.5037271642626728,
            "fpr": 0.13815789473684212,
            "logloss": 7.73387762594214,
            "mae": 0.4753392610724427,
            "precision": 0.5625,
            "recall": 0.351409978308026
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.557206830747558,
            "auditor_fn_violation": 0.010019526944734526,
            "auditor_fp_violation": 0.01309355616363532,
            "ave_precision_score": 0.5642728481802717,
            "fpr": 0.1141602634467618,
            "logloss": 7.89687117913401,
            "mae": 0.4741767430229008,
            "precision": 0.6325088339222615,
            "recall": 0.3630831643002028
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(84)",
        "seed": 26311,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.5400976611329272,
            "auditor_fn_violation": 0.009066864558359023,
            "auditor_fp_violation": 0.014701734936009654,
            "ave_precision_score": 0.5428105338621819,
            "fpr": 0.13157894736842105,
            "logloss": 5.649766271257359,
            "mae": 0.4391434676486784,
            "precision": 0.6238244514106583,
            "recall": 0.4316702819956616
        },
        "train": {
            "accuracy": 0.5718990120746432,
            "auc_prc": 0.6032467241329689,
            "auditor_fn_violation": 0.0064503487908657555,
            "auditor_fp_violation": 0.016328867273462572,
            "ave_precision_score": 0.6058251243638547,
            "fpr": 0.12294182217343579,
            "logloss": 5.585934946432116,
            "mae": 0.4441051534527394,
            "precision": 0.6574923547400612,
            "recall": 0.43610547667342797
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(85)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.6648660156458224,
            "auditor_fn_violation": 0.00738526087452908,
            "auditor_fp_violation": 0.013799743260590504,
            "ave_precision_score": 0.6554694691848153,
            "fpr": 0.07236842105263158,
            "logloss": 8.901956041968267,
            "mae": 0.4137050679245552,
            "precision": 0.7283950617283951,
            "recall": 0.3839479392624729
        },
        "train": {
            "accuracy": 0.6081229418221734,
            "auc_prc": 0.7083977137853901,
            "auditor_fn_violation": 0.015485735533473035,
            "auditor_fp_violation": 0.013915514262154738,
            "ave_precision_score": 0.6989482827990025,
            "fpr": 0.06476399560922064,
            "logloss": 9.253526133382731,
            "mae": 0.4195045742589464,
            "precision": 0.7677165354330708,
            "recall": 0.39553752535496955
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(86)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.665441386482066,
            "auditor_fn_violation": 0.00738526087452908,
            "auditor_fp_violation": 0.013281888201657138,
            "ave_precision_score": 0.6560249140961796,
            "fpr": 0.0712719298245614,
            "logloss": 8.901794107119708,
            "mae": 0.41383086741838176,
            "precision": 0.731404958677686,
            "recall": 0.3839479392624729
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.7084870219354836,
            "auditor_fn_violation": 0.01610249308096002,
            "auditor_fp_violation": 0.013915514262154738,
            "ave_precision_score": 0.6990359374724344,
            "fpr": 0.06476399560922064,
            "logloss": 9.253026570684309,
            "mae": 0.4196846686450965,
            "precision": 0.766798418972332,
            "recall": 0.3935091277890467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(87)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5844298245614035,
            "auc_prc": 0.548570060373887,
            "auditor_fn_violation": 0.00736623282718729,
            "auditor_fp_violation": 0.0056161745827984595,
            "ave_precision_score": 0.5516670257535015,
            "fpr": 0.1206140350877193,
            "logloss": 5.856283312947292,
            "mae": 0.435822018062233,
            "precision": 0.6357615894039735,
            "recall": 0.4164859002169197
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6108500921976638,
            "auditor_fn_violation": 0.008436441687466475,
            "auditor_fp_violation": 0.015120877735702398,
            "ave_precision_score": 0.613742427417059,
            "fpr": 0.1163556531284303,
            "logloss": 5.765247707165931,
            "mae": 0.4409957503178911,
            "precision": 0.6666666666666666,
            "recall": 0.4300202839756592
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(88)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.530619880843557,
            "auditor_fn_violation": 0.0050329185219012956,
            "auditor_fp_violation": 0.012623020967051778,
            "ave_precision_score": 0.5337648607598565,
            "fpr": 0.1337719298245614,
            "logloss": 5.855340685389138,
            "mae": 0.449584381215133,
            "precision": 0.6064516129032258,
            "recall": 0.4078091106290672
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5913527631877789,
            "auditor_fn_violation": 0.00900866800408797,
            "auditor_fp_violation": 0.017463327013272127,
            "ave_precision_score": 0.5942980677708654,
            "fpr": 0.1251372118551043,
            "logloss": 5.782805059745275,
            "mae": 0.45822518426822334,
            "precision": 0.6415094339622641,
            "recall": 0.41379310344827586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(89)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.4982056837822467,
            "auditor_fn_violation": 0.00917627583057427,
            "auditor_fp_violation": 0.015518633057143974,
            "ave_precision_score": 0.508356553269505,
            "fpr": 0.13815789473684212,
            "logloss": 7.709648365893464,
            "mae": 0.4775471160401346,
            "precision": 0.5563380281690141,
            "recall": 0.34273318872017355
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.5598414424970722,
            "auditor_fn_violation": 0.00917343355829028,
            "auditor_fp_violation": 0.02232942399907563,
            "ave_precision_score": 0.568854826733576,
            "fpr": 0.132821075740944,
            "logloss": 7.897986280828845,
            "mae": 0.48300120970670096,
            "precision": 0.6058631921824105,
            "recall": 0.3772819472616633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(90)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.7451679426014948,
            "auditor_fn_violation": 0.01393566617193744,
            "auditor_fp_violation": 0.0102160890029953,
            "ave_precision_score": 0.7441643288054687,
            "fpr": 0.17434210526315788,
            "logloss": 1.4118998605811137,
            "mae": 0.32226799261142747,
            "precision": 0.6800804828973843,
            "recall": 0.7331887201735358
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7939674906751728,
            "auditor_fn_violation": 0.01862073418640329,
            "auditor_fp_violation": 0.02563563884264098,
            "ave_precision_score": 0.7941035507731853,
            "fpr": 0.15477497255762898,
            "logloss": 1.2683029537584707,
            "mae": 0.30904335099658153,
            "precision": 0.7218934911242604,
            "recall": 0.742393509127789
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(91)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5402015412962907,
            "auditor_fn_violation": 0.009066864558359023,
            "auditor_fp_violation": 0.013184638425331628,
            "ave_precision_score": 0.5429991641237464,
            "fpr": 0.13267543859649122,
            "logloss": 5.652000039840759,
            "mae": 0.43905653747052564,
            "precision": 0.621875,
            "recall": 0.4316702819956616
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6038370980013376,
            "auditor_fn_violation": 0.006022848974557082,
            "auditor_fp_violation": 0.016328867273462572,
            "ave_precision_score": 0.606480340920794,
            "fpr": 0.12294182217343579,
            "logloss": 5.587167024143749,
            "mae": 0.44386562531850987,
            "precision": 0.6585365853658537,
            "recall": 0.4381338742393509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(92)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.520080416845878,
            "auditor_fn_violation": 0.006153194809148689,
            "auditor_fp_violation": 0.005713424359123974,
            "ave_precision_score": 0.5303018107590319,
            "fpr": 0.11732456140350878,
            "logloss": 7.62933935322689,
            "mae": 0.4632975745752981,
            "precision": 0.5946969696969697,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.599995577117735,
            "auditor_fn_violation": 0.011224096739645938,
            "auditor_fp_violation": 0.021712298909132927,
            "ave_precision_score": 0.608205277174088,
            "fpr": 0.1163556531284303,
            "logloss": 7.770794348724061,
            "mae": 0.4632453664433874,
            "precision": 0.636986301369863,
            "recall": 0.3772819472616633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(93)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.5707265836135279,
            "auditor_fn_violation": 0.015519751113140766,
            "auditor_fp_violation": 0.01687283619247676,
            "ave_precision_score": 0.5688456545277512,
            "fpr": 0.13925438596491227,
            "logloss": 4.91686206684296,
            "mae": 0.41919696404553813,
            "precision": 0.6174698795180723,
            "recall": 0.44468546637744033
        },
        "train": {
            "accuracy": 0.5916575192096597,
            "auc_prc": 0.6275515287593263,
            "auditor_fn_violation": 0.014889017039875496,
            "auditor_fp_violation": 0.019923949180405368,
            "ave_precision_score": 0.6263474658708248,
            "fpr": 0.11964873765093303,
            "logloss": 4.637627813172013,
            "mae": 0.4248152817906137,
            "precision": 0.6784660766961652,
            "recall": 0.4665314401622718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(94)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.5213625574007973,
            "auditor_fn_violation": 0.01156429577196789,
            "auditor_fp_violation": 0.01160919204885829,
            "ave_precision_score": 0.5323008763411499,
            "fpr": 0.1162280701754386,
            "logloss": 7.635212865835423,
            "mae": 0.46237431167310683,
            "precision": 0.596958174904943,
            "recall": 0.3405639913232104
        },
        "train": {
            "accuracy": 0.5554335894621295,
            "auc_prc": 0.6005050105448881,
            "auditor_fn_violation": 0.01018206593739355,
            "auditor_fp_violation": 0.016580969437864697,
            "ave_precision_score": 0.6091676825804779,
            "fpr": 0.10867178924259056,
            "logloss": 7.779554209245979,
            "mae": 0.4604292127762913,
            "precision": 0.6538461538461539,
            "recall": 0.3793103448275862
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(95)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.7088455847795894,
            "auditor_fn_violation": 0.027802355672260914,
            "auditor_fp_violation": 0.042977107402652974,
            "ave_precision_score": 0.7089669227165967,
            "fpr": 0.32127192982456143,
            "logloss": 2.1345252382395667,
            "mae": 0.4564651790724217,
            "precision": 0.5513016845329249,
            "recall": 0.7809110629067245
        },
        "train": {
            "accuracy": 0.6223929747530187,
            "auc_prc": 0.76505147796016,
            "auditor_fn_violation": 0.025013192377143906,
            "auditor_fp_violation": 0.032610465391099755,
            "ave_precision_score": 0.7648157657401918,
            "fpr": 0.283205268935236,
            "logloss": 1.7384531148292117,
            "mae": 0.43768430937257863,
            "precision": 0.6120300751879699,
            "recall": 0.8255578093306288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(96)",
        "seed": 26311,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7439351485035998,
            "auditor_fn_violation": 0.017505803554439245,
            "auditor_fp_violation": 0.010485957132298598,
            "ave_precision_score": 0.7442369927791668,
            "fpr": 0.14912280701754385,
            "logloss": 1.35907118091099,
            "mae": 0.31986823199276404,
            "precision": 0.7024070021881839,
            "recall": 0.6963123644251626
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7925857757616106,
            "auditor_fn_violation": 0.021568701669698508,
            "auditor_fp_violation": 0.016607230079989918,
            "ave_precision_score": 0.7928773075512083,
            "fpr": 0.12623490669593854,
            "logloss": 1.251105064453032,
            "mae": 0.3114025401802918,
            "precision": 0.7466960352422908,
            "recall": 0.6876267748478702
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(97)",
        "seed": 26311,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7490911224802121,
            "auditor_fn_violation": 0.018592780758838537,
            "auditor_fp_violation": 0.011178861788617895,
            "ave_precision_score": 0.7499475830538663,
            "fpr": 0.14473684210526316,
            "logloss": 1.348289649495092,
            "mae": 0.3170648087824209,
            "precision": 0.7079646017699115,
            "recall": 0.6941431670281996
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7954650526873851,
            "auditor_fn_violation": 0.020969756614557706,
            "auditor_fp_violation": 0.02235305857698833,
            "ave_precision_score": 0.7956112370924094,
            "fpr": 0.1251372118551043,
            "logloss": 1.2403484920244232,
            "mae": 0.30935038006111726,
            "precision": 0.748898678414097,
            "recall": 0.6896551724137931
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(98)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5230263157894737,
            "auc_prc": 0.5456179808106218,
            "auditor_fn_violation": 0.0006636031510446563,
            "auditor_fp_violation": 0.014113373789240286,
            "ave_precision_score": 0.5417321974701688,
            "fpr": 0.12390350877192982,
            "logloss": 10.960623953093005,
            "mae": 0.48609919031814425,
            "precision": 0.5515873015873016,
            "recall": 0.30151843817787416
        },
        "train": {
            "accuracy": 0.5225027442371021,
            "auc_prc": 0.5997125055486154,
            "auditor_fn_violation": 0.012099135426152745,
            "auditor_fp_violation": 0.015320458615854075,
            "ave_precision_score": 0.5923126747084645,
            "fpr": 0.1119648737650933,
            "logloss": 11.556464974495896,
            "mae": 0.49560968883316175,
            "precision": 0.6106870229007634,
            "recall": 0.32454361054766734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2_nsga2",
        "model": "feat_flex2_nsga2:archive(99)",
        "seed": 26311,
        "test": {
            "accuracy": 0.5197368421052632,
            "auc_prc": 0.5498626628977532,
            "auditor_fn_violation": 0.0037485253263310142,
            "auditor_fp_violation": 0.013486112731940723,
            "ave_precision_score": 0.5431632416613765,
            "fpr": 0.12938596491228072,
            "logloss": 11.292990486260466,
            "mae": 0.4839637284045528,
            "precision": 0.5444015444015444,
            "recall": 0.30585683297180044
        },
        "train": {
            "accuracy": 0.5257958287596048,
            "auc_prc": 0.5959598727572508,
            "auditor_fn_violation": 0.009841402021272583,
            "auditor_fp_violation": 0.014480118067846996,
            "ave_precision_score": 0.589362672386995,
            "fpr": 0.1141602634467618,
            "logloss": 11.85602963081165,
            "mae": 0.4892032706213462,
            "precision": 0.6133828996282528,
            "recall": 0.33468559837728196
        }
    }
]