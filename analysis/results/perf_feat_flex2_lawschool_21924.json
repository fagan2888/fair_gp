[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6704260806012521,
            "auditor_fn_violation": 0.01072372887412013,
            "auditor_fp_violation": 0.009053214985206486,
            "ave_precision_score": 0.6707148219584662,
            "fpr": 0.20723684210526316,
            "logloss": 1.179397442509422,
            "mae": 0.3207871226696503,
            "precision": 0.6823529411764706,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.6518943124577598,
            "auditor_fn_violation": 0.004838866458191583,
            "auditor_fp_violation": 0.010437901834718526,
            "ave_precision_score": 0.6518606704959431,
            "fpr": 0.20417124039517015,
            "logloss": 1.2214584161531836,
            "mae": 0.3262479456941518,
            "precision": 0.6696269982238011,
            "recall": 0.8142548596112311
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5800438596491229,
            "auc_prc": 0.7040605508001412,
            "auditor_fn_violation": 0.01335888090899346,
            "auditor_fp_violation": 0.011420698420635917,
            "ave_precision_score": 0.7045670296217399,
            "fpr": 0.06359649122807018,
            "logloss": 4.430652025489043,
            "mae": 0.4333555933885914,
            "precision": 0.7410714285714286,
            "recall": 0.3380855397148676
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6908084291545571,
            "auditor_fn_violation": 0.01090345264146157,
            "auditor_fp_violation": 0.0094921201191783,
            "ave_precision_score": 0.6912845610584868,
            "fpr": 0.06256860592755215,
            "logloss": 4.233355080433182,
            "mae": 0.41372455774822076,
            "precision": 0.7385321100917431,
            "recall": 0.34773218142548595
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7215469231205314,
            "auditor_fn_violation": 0.014232054168006577,
            "auditor_fp_violation": 0.017442284452223202,
            "ave_precision_score": 0.722405767457775,
            "fpr": 0.16557017543859648,
            "logloss": 1.3948414291088291,
            "mae": 0.30498364920860244,
            "precision": 0.7177570093457943,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7119699824550875,
            "auditor_fn_violation": 0.005851211376196388,
            "auditor_fp_violation": 0.020866002822643878,
            "ave_precision_score": 0.7115982517748661,
            "fpr": 0.1602634467618002,
            "logloss": 1.4351657144549117,
            "mae": 0.30299964964852993,
            "precision": 0.7044534412955465,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8364060601873904,
            "auditor_fn_violation": 0.01165049844570694,
            "auditor_fp_violation": 0.022679918323123723,
            "ave_precision_score": 0.836642524027642,
            "fpr": 0.13925438596491227,
            "logloss": 0.8029319371681944,
            "mae": 0.2740243961763698,
            "precision": 0.7533980582524272,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8137488567878746,
            "auditor_fn_violation": 0.002399281163983285,
            "auditor_fp_violation": 0.01851870001568136,
            "ave_precision_score": 0.8142455077651688,
            "fpr": 0.1350164654226125,
            "logloss": 0.796867148026703,
            "mae": 0.27417157285463434,
            "precision": 0.7415966386554622,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 21924,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8071914486215486,
            "auditor_fn_violation": 0.009415085575445742,
            "auditor_fp_violation": 0.021286514981039305,
            "ave_precision_score": 0.8073860549157422,
            "fpr": 0.16776315789473684,
            "logloss": 0.9171698693100843,
            "mae": 0.2877947877896715,
            "precision": 0.7228260869565217,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.780173751359651,
            "auditor_fn_violation": 0.0028307724405099255,
            "auditor_fp_violation": 0.006262741100831115,
            "ave_precision_score": 0.7785510829247901,
            "fpr": 0.16245883644346873,
            "logloss": 0.9484975845758665,
            "mae": 0.2963553340011711,
            "precision": 0.7131782945736435,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 21924,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6782939285608961,
            "auditor_fn_violation": 0.010848786936792084,
            "auditor_fp_violation": 0.008928199358253114,
            "ave_precision_score": 0.6787396838883252,
            "fpr": 0.19407894736842105,
            "logloss": 1.162382574908886,
            "mae": 0.31742007772093783,
            "precision": 0.6932409012131716,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6554647184952591,
            "auditor_fn_violation": 0.007072189438895389,
            "auditor_fp_violation": 0.0095166222361612,
            "ave_precision_score": 0.6554087879192365,
            "fpr": 0.19099890230515917,
            "logloss": 1.2090332975464082,
            "mae": 0.32586068156143516,
            "precision": 0.6777777777777778,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8344537969213529,
            "auditor_fn_violation": 0.01101180905420374,
            "auditor_fp_violation": 0.018411155561111812,
            "ave_precision_score": 0.8346887509505534,
            "fpr": 0.14692982456140352,
            "logloss": 0.8182753100222429,
            "mae": 0.27965212762561786,
            "precision": 0.7403100775193798,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8037696206048518,
            "auditor_fn_violation": 0.0054268325932388655,
            "auditor_fp_violation": 0.015808765877371813,
            "ave_precision_score": 0.8042722305690797,
            "fpr": 0.13611416026344675,
            "logloss": 0.8399473476709564,
            "mae": 0.28048520543169786,
            "precision": 0.7383966244725738,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8065283762585771,
            "auditor_fn_violation": 0.01668185228856255,
            "auditor_fp_violation": 0.0234560570071259,
            "ave_precision_score": 0.8068752467240136,
            "fpr": 0.1513157894736842,
            "logloss": 0.911634481682356,
            "mae": 0.2805606607159809,
            "precision": 0.7371428571428571,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8026056030417774,
            "auditor_fn_violation": 0.004044638009639803,
            "auditor_fp_violation": 0.02317655245413204,
            "ave_precision_score": 0.8032358892332914,
            "fpr": 0.1437980241492865,
            "logloss": 0.8570488241195169,
            "mae": 0.2756868119233737,
            "precision": 0.7326530612244898,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6865742240031244,
            "auditor_fn_violation": 0.01531514631793334,
            "auditor_fp_violation": 0.008930803850481317,
            "ave_precision_score": 0.6875706986064833,
            "fpr": 0.15570175438596492,
            "logloss": 1.3887125643595848,
            "mae": 0.3497212325778798,
            "precision": 0.7016806722689075,
            "recall": 0.6802443991853361
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.6943718293462994,
            "auditor_fn_violation": 0.004722695729895944,
            "auditor_fp_violation": 0.014010310490826409,
            "ave_precision_score": 0.694528362316193,
            "fpr": 0.1437980241492865,
            "logloss": 1.4427323760569244,
            "mae": 0.33433718608977225,
            "precision": 0.7095343680709535,
            "recall": 0.6911447084233261
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8336376792660767,
            "auditor_fn_violation": 0.01611685782684818,
            "auditor_fp_violation": 0.031238279784973122,
            "ave_precision_score": 0.8338696675837041,
            "fpr": 0.15350877192982457,
            "logloss": 0.8525853553047739,
            "mae": 0.27754513307875106,
            "precision": 0.7368421052631579,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8005981991725273,
            "auditor_fn_violation": 0.008857425324744603,
            "auditor_fp_violation": 0.019601693586325863,
            "ave_precision_score": 0.8013383968512781,
            "fpr": 0.14050493962678376,
            "logloss": 0.858314938044422,
            "mae": 0.28085594641635686,
            "precision": 0.7338877338877339,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8331237545764657,
            "auditor_fn_violation": 0.01661262371815486,
            "auditor_fp_violation": 0.026190773846730842,
            "ave_precision_score": 0.8333801929797069,
            "fpr": 0.14692982456140352,
            "logloss": 0.7775949181290552,
            "mae": 0.27255063116852724,
            "precision": 0.7442748091603053,
            "recall": 0.7942973523421588
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8034557150002881,
            "auditor_fn_violation": 0.0030536305723423587,
            "auditor_fp_violation": 0.010854437823427949,
            "ave_precision_score": 0.8041373225499073,
            "fpr": 0.12843029637760703,
            "logloss": 0.7898191389153598,
            "mae": 0.27420108227923506,
            "precision": 0.7510638297872341,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6939604226048399,
            "auditor_fn_violation": 0.006065316039589816,
            "auditor_fp_violation": 0.02844105513189148,
            "ave_precision_score": 0.6863043823537809,
            "fpr": 0.21162280701754385,
            "logloss": 1.8125170505153223,
            "mae": 0.3001332669756753,
            "precision": 0.6861788617886179,
            "recall": 0.8594704684317719
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6787778242291325,
            "auditor_fn_violation": 0.004118133776520715,
            "auditor_fp_violation": 0.018954837697977105,
            "ave_precision_score": 0.671507661554431,
            "fpr": 0.20856201975850713,
            "logloss": 1.7407651350652382,
            "mae": 0.31747934532726063,
            "precision": 0.6631205673758865,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8361433053961422,
            "auditor_fn_violation": 0.01442410762139565,
            "auditor_fp_violation": 0.02407071717297996,
            "ave_precision_score": 0.8363806578136046,
            "fpr": 0.13815789473684212,
            "logloss": 0.7963927016964788,
            "mae": 0.27511350654011446,
            "precision": 0.75390625,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8127387926330052,
            "auditor_fn_violation": 0.003008584779737929,
            "auditor_fp_violation": 0.018082562333385604,
            "ave_precision_score": 0.8132290455606302,
            "fpr": 0.13391877058177826,
            "logloss": 0.7921161269056316,
            "mae": 0.27521791977669413,
            "precision": 0.7436974789915967,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8549673457582956,
            "auditor_fn_violation": 0.013142262479008108,
            "auditor_fp_violation": 0.025508396882943707,
            "ave_precision_score": 0.8551552032735428,
            "fpr": 0.13596491228070176,
            "logloss": 0.8633185737070662,
            "mae": 0.28256611088527694,
            "precision": 0.752,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8399076831794017,
            "auditor_fn_violation": 0.009701441228280228,
            "auditor_fp_violation": 0.01621550101928807,
            "ave_precision_score": 0.8401574567750121,
            "fpr": 0.1163556531284303,
            "logloss": 0.8648166047569286,
            "mae": 0.27949684401067715,
            "precision": 0.7607223476297968,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8289333373936805,
            "auditor_fn_violation": 0.014310215457176551,
            "auditor_fp_violation": 0.026253281660207527,
            "ave_precision_score": 0.8291705554940794,
            "fpr": 0.14802631578947367,
            "logloss": 0.8948856068077223,
            "mae": 0.28106658621771363,
            "precision": 0.7368421052631579,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7979965692329156,
            "auditor_fn_violation": 0.010059436737925956,
            "auditor_fp_violation": 0.015882272228320532,
            "ave_precision_score": 0.7986231447544787,
            "fpr": 0.13062568605927552,
            "logloss": 0.9041074327160683,
            "mae": 0.2816531493567204,
            "precision": 0.7424242424242424,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.839219128488611,
            "auditor_fn_violation": 0.012624164790795726,
            "auditor_fp_violation": 0.02407071717297996,
            "ave_precision_score": 0.8394494636690191,
            "fpr": 0.13815789473684212,
            "logloss": 0.7718865141585128,
            "mae": 0.27358081822286046,
            "precision": 0.75390625,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8155836517837982,
            "auditor_fn_violation": 0.001071615697747472,
            "auditor_fp_violation": 0.017646424651089853,
            "ave_precision_score": 0.8160640223267369,
            "fpr": 0.132821075740944,
            "logloss": 0.7660203418142806,
            "mae": 0.27367583818176416,
            "precision": 0.7452631578947368,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.6657873737065951,
            "auditor_fn_violation": 0.008943884660735344,
            "auditor_fp_violation": 0.018314789348668585,
            "ave_precision_score": 0.6533765400530763,
            "fpr": 0.20285087719298245,
            "logloss": 2.3071715353297133,
            "mae": 0.3270567808580573,
            "precision": 0.6843003412969283,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6551499560986633,
            "auditor_fn_violation": 0.002389797839224453,
            "auditor_fp_violation": 0.0011368982280069032,
            "ave_precision_score": 0.6414131290833248,
            "fpr": 0.19319429198682767,
            "logloss": 2.271419211762533,
            "mae": 0.32657078725161104,
            "precision": 0.6788321167883211,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8381844560404552,
            "auditor_fn_violation": 0.012286954657519564,
            "auditor_fp_violation": 0.02407071717297996,
            "ave_precision_score": 0.8384162191851277,
            "fpr": 0.13815789473684212,
            "logloss": 0.7822129492673144,
            "mae": 0.2738959659151272,
            "precision": 0.754863813229572,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8149770137284122,
            "auditor_fn_violation": 0.00021337480707361205,
            "auditor_fp_violation": 0.018082562333385604,
            "ave_precision_score": 0.8154728518714757,
            "fpr": 0.13391877058177826,
            "logloss": 0.7763307757133614,
            "mae": 0.27419480343395214,
            "precision": 0.7426160337552743,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.672825007962837,
            "auditor_fn_violation": 0.011132400757494556,
            "auditor_fp_violation": 0.005630912197358009,
            "ave_precision_score": 0.6735665434610303,
            "fpr": 0.19846491228070176,
            "logloss": 1.208692528149029,
            "mae": 0.3231312857183256,
            "precision": 0.6879310344827586,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6468054728909787,
            "auditor_fn_violation": 0.004395521025716409,
            "auditor_fp_violation": 0.011579700486122002,
            "ave_precision_score": 0.6456142819853699,
            "fpr": 0.1942919868276619,
            "logloss": 1.327399873553552,
            "mae": 0.32636017527509475,
            "precision": 0.6758241758241759,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8409943331538697,
            "auditor_fn_violation": 0.014185157394504593,
            "auditor_fp_violation": 0.02674813518356462,
            "ave_precision_score": 0.8412161700019134,
            "fpr": 0.14802631578947367,
            "logloss": 0.7566043289813567,
            "mae": 0.2745837943112488,
            "precision": 0.7388781431334622,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8154886202059433,
            "auditor_fn_violation": 0.0016500985080359345,
            "auditor_fp_violation": 0.017016720244629135,
            "ave_precision_score": 0.8159839706743335,
            "fpr": 0.13721185510428102,
            "logloss": 0.7580944698027146,
            "mae": 0.2756915614015876,
            "precision": 0.7390396659707724,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8383215710651797,
            "auditor_fn_violation": 0.011831386000643155,
            "auditor_fp_violation": 0.022330916364545574,
            "ave_precision_score": 0.838553472526263,
            "fpr": 0.13925438596491227,
            "logloss": 0.78149862944183,
            "mae": 0.2738408069843293,
            "precision": 0.7529182879377432,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.815301077425057,
            "auditor_fn_violation": 0.002399281163983285,
            "auditor_fp_violation": 0.018082562333385604,
            "ave_precision_score": 0.8157795979144947,
            "fpr": 0.13391877058177826,
            "logloss": 0.7750851557329538,
            "mae": 0.27394497284477953,
            "precision": 0.7431578947368421,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7007963144782899,
            "auditor_fn_violation": 0.006467288383892529,
            "auditor_fp_violation": 0.027091928157686386,
            "ave_precision_score": 0.6955073316599516,
            "fpr": 0.20942982456140352,
            "logloss": 1.696608074807033,
            "mae": 0.2966053936797755,
            "precision": 0.6848184818481848,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6859423132701166,
            "auditor_fn_violation": 0.002543901866555394,
            "auditor_fp_violation": 0.02991708483612985,
            "ave_precision_score": 0.6815349367117779,
            "fpr": 0.19099890230515917,
            "logloss": 1.5720382787870633,
            "mae": 0.30838962947183396,
            "precision": 0.6807339449541284,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 21924,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7974229926188758,
            "auditor_fn_violation": 0.017644352735198487,
            "auditor_fp_violation": 0.024667145893236663,
            "ave_precision_score": 0.7512765490751505,
            "fpr": 0.15350877192982457,
            "logloss": 4.076612133044802,
            "mae": 0.28392885235621984,
            "precision": 0.7338403041825095,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7862697162061915,
            "auditor_fn_violation": 0.004734549885844481,
            "auditor_fp_violation": 0.02531558726673985,
            "ave_precision_score": 0.7512621456261573,
            "fpr": 0.14270032930845225,
            "logloss": 3.9308008017282448,
            "mae": 0.2800879769470075,
            "precision": 0.7336065573770492,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.848131285240968,
            "auditor_fn_violation": 0.015199020974023656,
            "auditor_fp_violation": 0.02676376213693379,
            "ave_precision_score": 0.8483816636980195,
            "fpr": 0.14912280701754385,
            "logloss": 0.5465106386093628,
            "mae": 0.2835770629411727,
            "precision": 0.7509157509157509,
            "recall": 0.835030549898167
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.824097750431436,
            "auditor_fn_violation": 0.0026316226205745506,
            "auditor_fp_violation": 0.028177434530343427,
            "ave_precision_score": 0.8246329846938929,
            "fpr": 0.1437980241492865,
            "logloss": 0.5725237363118103,
            "mae": 0.29143476106418637,
            "precision": 0.7358870967741935,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8378861002641744,
            "auditor_fn_violation": 0.016382606210026084,
            "auditor_fp_violation": 0.022330916364545574,
            "ave_precision_score": 0.8381191299787513,
            "fpr": 0.13925438596491227,
            "logloss": 0.7844865437134332,
            "mae": 0.27410272661578877,
            "precision": 0.7524366471734892,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8150513941191366,
            "auditor_fn_violation": 0.002399281163983285,
            "auditor_fp_violation": 0.018082562333385604,
            "ave_precision_score": 0.8155458318319359,
            "fpr": 0.13391877058177826,
            "logloss": 0.7758434061933149,
            "mae": 0.27334876032325484,
            "precision": 0.7431578947368421,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.6996926542677588,
            "auditor_fn_violation": 0.014379444027584232,
            "auditor_fp_violation": 0.010287744301371016,
            "ave_precision_score": 0.7006513422819218,
            "fpr": 0.15789473684210525,
            "logloss": 1.3110500122627973,
            "mae": 0.32638341841937757,
            "precision": 0.7137176938369781,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.6936977504353757,
            "auditor_fn_violation": 0.0032409262363291965,
            "auditor_fp_violation": 0.014617962992002511,
            "ave_precision_score": 0.6938795071770099,
            "fpr": 0.14709110867178923,
            "logloss": 1.350309265466946,
            "mae": 0.3206281921211136,
            "precision": 0.7154989384288747,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.765334264249113,
            "auditor_fn_violation": 0.013347715010540617,
            "auditor_fp_violation": 0.025211484768929447,
            "ave_precision_score": 0.7668085429109945,
            "fpr": 0.15899122807017543,
            "logloss": 0.665130300038986,
            "mae": 0.3292676956847782,
            "precision": 0.7184466019417476,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.7432972459231264,
            "auditor_fn_violation": 0.017133997008011048,
            "auditor_fp_violation": 0.028606221577544298,
            "ave_precision_score": 0.7440153608786251,
            "fpr": 0.14818880351262348,
            "logloss": 0.6765505308132291,
            "mae": 0.3316622509398769,
            "precision": 0.7169811320754716,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7192214718355417,
            "auditor_fn_violation": 0.01249017400936149,
            "auditor_fp_violation": 0.011892111513939244,
            "ave_precision_score": 0.7201061659798746,
            "fpr": 0.16337719298245615,
            "logloss": 1.39022863720716,
            "mae": 0.3042995664160274,
            "precision": 0.7209737827715356,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7112440118166807,
            "auditor_fn_violation": 0.005381786800634442,
            "auditor_fp_violation": 0.018910733887407875,
            "ave_precision_score": 0.7108394394608611,
            "fpr": 0.1525795828759605,
            "logloss": 1.4262754406028908,
            "mae": 0.3025824401931178,
            "precision": 0.7139917695473251,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8057028556779636,
            "auditor_fn_violation": 0.006487387001107657,
            "auditor_fp_violation": 0.02227101304329708,
            "ave_precision_score": 0.8057854511403608,
            "fpr": 0.1699561403508772,
            "logloss": 0.9314508494623188,
            "mae": 0.2899285604681497,
            "precision": 0.7217235188509874,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7782419656878936,
            "auditor_fn_violation": 0.000545291173632566,
            "auditor_fp_violation": 0.007750019601693589,
            "ave_precision_score": 0.7765881035880985,
            "fpr": 0.16794731064763996,
            "logloss": 0.9645048382711064,
            "mae": 0.2991000525134541,
            "precision": 0.7080152671755725,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8142517403517405,
            "auditor_fn_violation": 0.01464965877014328,
            "auditor_fp_violation": 0.02209130307955162,
            "ave_precision_score": 0.8145767645650623,
            "fpr": 0.15021929824561403,
            "logloss": 0.8723071336692175,
            "mae": 0.2822765070013702,
            "precision": 0.7410207939508506,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7868737703562683,
            "auditor_fn_violation": 0.0037648799292543996,
            "auditor_fp_violation": 0.00563058648267211,
            "ave_precision_score": 0.7855338455326235,
            "fpr": 0.14270032930845225,
            "logloss": 0.9051745330221899,
            "mae": 0.2884332419024999,
            "precision": 0.7368421052631579,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5910087719298246,
            "auc_prc": 0.643665173182609,
            "auditor_fn_violation": 0.0002501161253439103,
            "auditor_fp_violation": 0.009298037254656829,
            "ave_precision_score": 0.6445651776954999,
            "fpr": 0.3958333333333333,
            "logloss": 1.4722326175509983,
            "mae": 0.4026649724447021,
            "precision": 0.5702380952380952,
            "recall": 0.9755600814663951
        },
        "train": {
            "accuracy": 0.557628979143798,
            "auc_prc": 0.5695092987465784,
            "auditor_fn_violation": 0.0048293831334327506,
            "auditor_fp_violation": 0.015671554022267546,
            "ave_precision_score": 0.5710874681378677,
            "fpr": 0.42371020856201974,
            "logloss": 1.781071938828288,
            "mae": 0.43115788854405074,
            "precision": 0.5360576923076923,
            "recall": 0.9632829373650108
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 21924,
        "test": {
            "accuracy": 0.48903508771929827,
            "auc_prc": 0.474769024144891,
            "auditor_fn_violation": 0.016288812663022116,
            "auditor_fp_violation": 0.008368233529191152,
            "ave_precision_score": 0.47491976813470405,
            "fpr": 0.22587719298245615,
            "logloss": 2.2905714683816707,
            "mae": 0.5242350051896346,
            "precision": 0.528604118993135,
            "recall": 0.47046843177189407
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.488383505179252,
            "auditor_fn_violation": 0.01162418532313244,
            "auditor_fp_violation": 0.005802101301552461,
            "ave_precision_score": 0.48861445370683976,
            "fpr": 0.21844127332601537,
            "logloss": 2.1117431247912495,
            "mae": 0.4762059587860817,
            "precision": 0.5587583148558758,
            "recall": 0.5442764578833693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8686564098691765,
            "auditor_fn_violation": 0.012065869868153074,
            "auditor_fp_violation": 0.019963432929116145,
            "ave_precision_score": 0.8688479452891029,
            "fpr": 0.10855263157894737,
            "logloss": 0.48366855183762675,
            "mae": 0.3063690421345599,
            "precision": 0.7983706720977597,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8403224916638166,
            "auditor_fn_violation": 2.3708311897042234e-06,
            "auditor_fp_violation": 0.014446448173122161,
            "ave_precision_score": 0.8406138068932039,
            "fpr": 0.1141602634467618,
            "logloss": 0.5089199153734238,
            "mae": 0.3164459653945004,
            "precision": 0.7739130434782608,
            "recall": 0.7688984881209503
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4276315789473684,
            "auc_prc": 0.4410768530592508,
            "auditor_fn_violation": 0.002514560331582535,
            "auditor_fp_violation": 0.009446493311663966,
            "ave_precision_score": 0.4401537361748096,
            "fpr": 0.24232456140350878,
            "logloss": 3.086317634717546,
            "mae": 0.5749638875965882,
            "precision": 0.46228710462287104,
            "recall": 0.3869653767820774
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.45931133675628344,
            "auditor_fn_violation": 0.005225311942113796,
            "auditor_fp_violation": 0.011021052218911722,
            "ave_precision_score": 0.45741786983645916,
            "fpr": 0.22063666300768386,
            "logloss": 2.929834177513787,
            "mae": 0.5211252748206436,
            "precision": 0.524822695035461,
            "recall": 0.4794816414686825
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4868421052631579,
            "auc_prc": 0.47325341182380853,
            "auditor_fn_violation": 0.01577294815450031,
            "auditor_fp_violation": 0.009537650539650796,
            "ave_precision_score": 0.4733889697439845,
            "fpr": 0.22807017543859648,
            "logloss": 2.3620286932610925,
            "mae": 0.5252637284684131,
            "precision": 0.5261958997722096,
            "recall": 0.47046843177189407
        },
        "train": {
            "accuracy": 0.5466520307354555,
            "auc_prc": 0.4871353597302127,
            "auditor_fn_violation": 0.013715258432453836,
            "auditor_fp_violation": 0.0054296691234122655,
            "ave_precision_score": 0.4873385953683102,
            "fpr": 0.21624588364434688,
            "logloss": 2.180931407465476,
            "mae": 0.4775872598447421,
            "precision": 0.5563063063063063,
            "recall": 0.5334773218142549
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 21924,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.813393789765815,
            "auditor_fn_violation": 0.01136688462500447,
            "auditor_fp_violation": 0.021453202483643796,
            "ave_precision_score": 0.8136421419623527,
            "fpr": 0.1425438596491228,
            "logloss": 0.8490587230547928,
            "mae": 0.2801545916918896,
            "precision": 0.7485493230174082,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7875771560622241,
            "auditor_fn_violation": 0.001370340427650534,
            "auditor_fp_violation": 0.008830562960639799,
            "ave_precision_score": 0.7869749334212459,
            "fpr": 0.141602634467618,
            "logloss": 0.8600048510986062,
            "mae": 0.28730459142156595,
            "precision": 0.73125,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 21924,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.7283228247902098,
            "auditor_fn_violation": 0.011159198913781398,
            "auditor_fp_violation": 0.023476892944951453,
            "ave_precision_score": 0.7291843893805697,
            "fpr": 0.3267543859649123,
            "logloss": 0.8217966634365877,
            "mae": 0.36387607450351905,
            "precision": 0.6089238845144357,
            "recall": 0.945010183299389
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7175229987550471,
            "auditor_fn_violation": 0.008361921606095881,
            "auditor_fp_violation": 0.024595225027442384,
            "ave_precision_score": 0.7182773421853965,
            "fpr": 0.3194291986827662,
            "logloss": 0.8185231223578731,
            "mae": 0.3752067850577583,
            "precision": 0.6013698630136987,
            "recall": 0.9481641468682506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8460941212408718,
            "auditor_fn_violation": 0.015341944474220178,
            "auditor_fp_violation": 0.01724694753510856,
            "ave_precision_score": 0.8463186411899997,
            "fpr": 0.12609649122807018,
            "logloss": 0.722438937743863,
            "mae": 0.26726012387960346,
            "precision": 0.7709163346613546,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8158326042485554,
            "auditor_fn_violation": 0.001903777445334562,
            "auditor_fp_violation": 0.014078916418378554,
            "ave_precision_score": 0.8162635227130253,
            "fpr": 0.12623490669593854,
            "logloss": 0.7439449530832891,
            "mae": 0.2766749994289479,
            "precision": 0.7505422993492408,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8271864222338573,
            "auditor_fn_violation": 0.007282398970950804,
            "auditor_fp_violation": 0.0213932991623953,
            "ave_precision_score": 0.8274616373404695,
            "fpr": 0.15350877192982457,
            "logloss": 0.8283035180842444,
            "mae": 0.2815910614812351,
            "precision": 0.7333333333333333,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8042083814374539,
            "auditor_fn_violation": 0.01006654923149507,
            "auditor_fp_violation": 0.017749333542418064,
            "ave_precision_score": 0.8047370708972135,
            "fpr": 0.1394072447859495,
            "logloss": 0.8342451236520972,
            "mae": 0.27767549985821693,
            "precision": 0.7386831275720165,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6655701754385965,
            "auc_prc": 0.6933064357001151,
            "auditor_fn_violation": 0.018475095580090757,
            "auditor_fp_violation": 0.010022086094095098,
            "ave_precision_score": 0.6942407002076219,
            "fpr": 0.13596491228070176,
            "logloss": 1.3982325910129474,
            "mae": 0.360530874810433,
            "precision": 0.7142857142857143,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.6904500548847421,
            "auc_prc": 0.6976800633161258,
            "auditor_fn_violation": 0.011932393377794325,
            "auditor_fp_violation": 0.013466363493805866,
            "ave_precision_score": 0.6978062135768132,
            "fpr": 0.13391877058177826,
            "logloss": 1.4710904801905422,
            "mae": 0.34334222278070214,
            "precision": 0.7129411764705882,
            "recall": 0.6544276457883369
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8454711872711225,
            "auditor_fn_violation": 0.01895522921356344,
            "auditor_fp_violation": 0.029790182106096602,
            "ave_precision_score": 0.8456653147688153,
            "fpr": 0.1425438596491228,
            "logloss": 0.778506965091925,
            "mae": 0.2781801468466369,
            "precision": 0.746588693957115,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8087085584477813,
            "auditor_fn_violation": 0.011643151972650092,
            "auditor_fp_violation": 0.015504939626783754,
            "ave_precision_score": 0.8102205555307334,
            "fpr": 0.1207464324917673,
            "logloss": 0.7821649827262975,
            "mae": 0.2742124367135183,
            "precision": 0.7566371681415929,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.6939227283333602,
            "auditor_fn_violation": 0.01327178690106121,
            "auditor_fp_violation": 0.009553277493019962,
            "ave_precision_score": 0.694907850328395,
            "fpr": 0.1524122807017544,
            "logloss": 1.3304519170070719,
            "mae": 0.3366762691240621,
            "precision": 0.7139917695473251,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.6899574586633794,
            "auditor_fn_violation": 0.005412607606100628,
            "auditor_fp_violation": 0.011089658146463857,
            "ave_precision_score": 0.6901463894889117,
            "fpr": 0.14709110867178923,
            "logloss": 1.3729951810546337,
            "mae": 0.3277395722476552,
            "precision": 0.7105831533477321,
            "recall": 0.7105831533477321
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.840601711767935,
            "auditor_fn_violation": 0.012286954657519564,
            "auditor_fp_violation": 0.021810017918906535,
            "ave_precision_score": 0.8408297686303664,
            "fpr": 0.13925438596491227,
            "logloss": 0.7661449628907859,
            "mae": 0.27261715864835523,
            "precision": 0.7533980582524272,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8162679861821533,
            "auditor_fn_violation": 0.00020863314469419798,
            "auditor_fp_violation": 0.017646424651089853,
            "ave_precision_score": 0.8167451354371216,
            "fpr": 0.132821075740944,
            "logloss": 0.7642559937113169,
            "mae": 0.2735284007386919,
            "precision": 0.7447257383966245,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.806147587138753,
            "auditor_fn_violation": 0.009555775895951694,
            "auditor_fp_violation": 0.024047276742926196,
            "ave_precision_score": 0.8064653620810112,
            "fpr": 0.16666666666666666,
            "logloss": 0.9363308361809868,
            "mae": 0.28427599491043476,
            "precision": 0.7241379310344828,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.7834451625337073,
            "auditor_fn_violation": 0.0008866908649503455,
            "auditor_fp_violation": 0.016301258428728243,
            "ave_precision_score": 0.7812925752671359,
            "fpr": 0.15477497255762898,
            "logloss": 0.9744713968126704,
            "mae": 0.28684352092081594,
            "precision": 0.7235294117647059,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.6426386165776694,
            "auditor_fn_violation": 0.008057312323578807,
            "auditor_fp_violation": 0.005883547943492949,
            "ave_precision_score": 0.643613616467634,
            "fpr": 0.3223684210526316,
            "logloss": 1.2916413587274782,
            "mae": 0.39342111732765805,
            "precision": 0.6005434782608695,
            "recall": 0.90020366598778
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.5856331126503305,
            "auditor_fn_violation": 0.0020910731093213997,
            "auditor_fp_violation": 0.007958287596048304,
            "ave_precision_score": 0.5870813089323241,
            "fpr": 0.3380900109769484,
            "logloss": 1.6027938030674578,
            "mae": 0.40681368519544897,
            "precision": 0.5769230769230769,
            "recall": 0.9071274298056156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8388909932338491,
            "auditor_fn_violation": 0.016860506663808197,
            "auditor_fp_violation": 0.025258365629036973,
            "ave_precision_score": 0.839121001594038,
            "fpr": 0.14802631578947367,
            "logloss": 0.7655771380012354,
            "mae": 0.2750610942554397,
            "precision": 0.7398843930635838,
            "recall": 0.7820773930753564
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8149652856653596,
            "auditor_fn_violation": 0.004964520511246038,
            "auditor_fp_violation": 0.018695115257958292,
            "ave_precision_score": 0.8154697829701032,
            "fpr": 0.13830954994511527,
            "logloss": 0.7627602353512624,
            "mae": 0.2751176302358994,
            "precision": 0.7358490566037735,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8675426074687255,
            "auditor_fn_violation": 0.011119001679351129,
            "auditor_fp_violation": 0.014806538317289666,
            "ave_precision_score": 0.8677524278555888,
            "fpr": 0.12719298245614036,
            "logloss": 0.48576779074196674,
            "mae": 0.3049377773971636,
            "precision": 0.7756286266924565,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8472424515851127,
            "auditor_fn_violation": 0.002330527059481784,
            "auditor_fp_violation": 0.020383311118080602,
            "ave_precision_score": 0.847489636547824,
            "fpr": 0.13721185510428102,
            "logloss": 0.5108303176377539,
            "mae": 0.31151675787559097,
            "precision": 0.7438524590163934,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8462210019798448,
            "auditor_fn_violation": 0.01199217493836424,
            "auditor_fp_violation": 0.024107180064174692,
            "ave_precision_score": 0.8464312861284927,
            "fpr": 0.1337719298245614,
            "logloss": 0.740914875064855,
            "mae": 0.27303332013840637,
            "precision": 0.7579365079365079,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8079045399307683,
            "auditor_fn_violation": 0.008188850929247291,
            "auditor_fp_violation": 0.009859651873921918,
            "ave_precision_score": 0.8085890992352075,
            "fpr": 0.1251372118551043,
            "logloss": 0.7714131304600559,
            "mae": 0.27745652057388404,
            "precision": 0.75,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8728368170214388,
            "auditor_fn_violation": 0.01672651588237396,
            "auditor_fp_violation": 0.017955369421177647,
            "ave_precision_score": 0.8730337466940834,
            "fpr": 0.11513157894736842,
            "logloss": 0.48204472448480734,
            "mae": 0.3044083708338899,
            "precision": 0.7912524850894632,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8525418948226896,
            "auditor_fn_violation": 0.014037691474253962,
            "auditor_fp_violation": 0.010704974909832217,
            "ave_precision_score": 0.8527591769138282,
            "fpr": 0.11306256860592755,
            "logloss": 0.5054326286703698,
            "mae": 0.30805055798250164,
            "precision": 0.7794432548179872,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7885741750504702,
            "auditor_fn_violation": 0.020319702004502095,
            "auditor_fp_violation": 0.02378943201233488,
            "ave_precision_score": 0.7494310728041246,
            "fpr": 0.1337719298245614,
            "logloss": 3.892558987861251,
            "mae": 0.28324437593218155,
            "precision": 0.7505112474437627,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7832207250490031,
            "auditor_fn_violation": 0.010445882221848161,
            "auditor_fp_violation": 0.019518386388583976,
            "ave_precision_score": 0.7527823019488757,
            "fpr": 0.13062568605927552,
            "logloss": 3.736207559307109,
            "mae": 0.2803208491311751,
            "precision": 0.741304347826087,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7836695655660135,
            "auditor_fn_violation": 0.006005020187944402,
            "auditor_fp_violation": 0.004151560611743135,
            "ave_precision_score": 0.7831509560927841,
            "fpr": 0.10635964912280702,
            "logloss": 1.0208897569247721,
            "mae": 0.31510598153830927,
            "precision": 0.7616707616707616,
            "recall": 0.6313645621181263
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7582130500322402,
            "auditor_fn_violation": 0.016372960196115154,
            "auditor_fp_violation": 0.0042584679316293,
            "ave_precision_score": 0.7552341931896025,
            "fpr": 0.09440175631174534,
            "logloss": 1.082262520104217,
            "mae": 0.31392533416118307,
            "precision": 0.7669376693766937,
            "recall": 0.6112311015118791
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5668859649122807,
            "auc_prc": 0.6690518139523276,
            "auditor_fn_violation": 0.011290956515525063,
            "auditor_fp_violation": 0.015569654540150852,
            "ave_precision_score": 0.6671103843877797,
            "fpr": 0.06140350877192982,
            "logloss": 8.234676760371782,
            "mae": 0.45030190040565427,
            "precision": 0.7307692307692307,
            "recall": 0.3095723014256619
        },
        "train": {
            "accuracy": 0.6048298572996706,
            "auc_prc": 0.6618781152610285,
            "auditor_fn_violation": 0.011880235091620783,
            "auditor_fp_violation": 0.008553689038732947,
            "ave_precision_score": 0.6598038227580603,
            "fpr": 0.05598243688254665,
            "logloss": 7.659639423005628,
            "mae": 0.4187986801114587,
            "precision": 0.751219512195122,
            "recall": 0.3326133909287257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7889340310079638,
            "auditor_fn_violation": 0.006737503126451567,
            "auditor_fp_violation": 0.015106054923532113,
            "ave_precision_score": 0.78644521076389,
            "fpr": 0.18421052631578946,
            "logloss": 1.1716343623033467,
            "mae": 0.30569734952076577,
            "precision": 0.7068062827225131,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7559916839388485,
            "auditor_fn_violation": 0.0012873613360107946,
            "auditor_fp_violation": 0.0032930845225027463,
            "ave_precision_score": 0.7507084693662197,
            "fpr": 0.19319429198682767,
            "logloss": 1.245179540125691,
            "mae": 0.31582714679421453,
            "precision": 0.68,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 21924,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8174494490894555,
            "auditor_fn_violation": 0.011931879086718835,
            "auditor_fp_violation": 0.019176876276201193,
            "ave_precision_score": 0.8177725686554735,
            "fpr": 0.13486842105263158,
            "logloss": 0.8171357417667225,
            "mae": 0.2782200607149494,
            "precision": 0.7554671968190855,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7930103200247394,
            "auditor_fn_violation": 0.005097287057869621,
            "auditor_fp_violation": 0.013544770268151174,
            "ave_precision_score": 0.7929475692488175,
            "fpr": 0.12623490669593854,
            "logloss": 0.8089606733921394,
            "mae": 0.2800455682130958,
            "precision": 0.7510822510822511,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8590173216328214,
            "auditor_fn_violation": 0.008952817379497633,
            "auditor_fp_violation": 0.012595324415551945,
            "ave_precision_score": 0.8592575984676531,
            "fpr": 0.06469298245614036,
            "logloss": 0.49519990815161447,
            "mae": 0.3239966012014632,
            "precision": 0.854320987654321,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.847123749098075,
            "auditor_fn_violation": 0.01275033013824317,
            "auditor_fp_violation": 0.006042222047984949,
            "ave_precision_score": 0.8473375550578378,
            "fpr": 0.06366630076838639,
            "logloss": 0.5159083721472307,
            "mae": 0.32972431132563773,
            "precision": 0.8366197183098592,
            "recall": 0.6414686825053996
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8356569876219759,
            "auditor_fn_violation": 0.01345714081537857,
            "auditor_fp_violation": 0.02492759511605618,
            "ave_precision_score": 0.835890249822131,
            "fpr": 0.14144736842105263,
            "logloss": 0.8214122839413617,
            "mae": 0.27603762375014207,
            "precision": 0.7465618860510805,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8097883827707795,
            "auditor_fn_violation": 0.0031318680016026836,
            "auditor_fp_violation": 0.015901873921906857,
            "ave_precision_score": 0.8102987397377348,
            "fpr": 0.12843029637760703,
            "logloss": 0.8227585137005348,
            "mae": 0.2750302808582093,
            "precision": 0.7505330490405118,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8429290662138126,
            "auditor_fn_violation": 0.009075642262479013,
            "auditor_fp_violation": 0.022570529649539532,
            "ave_precision_score": 0.8431517861779709,
            "fpr": 0.14035087719298245,
            "logloss": 0.7431428275953508,
            "mae": 0.2739821942601738,
            "precision": 0.7455268389662028,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8159007968900528,
            "auditor_fn_violation": 0.005886773844041979,
            "auditor_fp_violation": 0.011251372118551045,
            "ave_precision_score": 0.8164292768580538,
            "fpr": 0.12294182217343579,
            "logloss": 0.749314019504419,
            "mae": 0.27480311680086544,
            "precision": 0.7565217391304347,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7342372142265257,
            "auditor_fn_violation": 0.014939972129917467,
            "auditor_fp_violation": 0.008922990373796727,
            "ave_precision_score": 0.7340828107118121,
            "fpr": 0.16337719298245615,
            "logloss": 1.4244847969022363,
            "mae": 0.29994976456703837,
            "precision": 0.7225325884543762,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7196822662927874,
            "auditor_fn_violation": 0.007121976893879227,
            "auditor_fp_violation": 0.011319978046103187,
            "ave_precision_score": 0.7181838150477319,
            "fpr": 0.15148188803512624,
            "logloss": 1.4250602239982921,
            "mae": 0.2979947524468684,
            "precision": 0.7212121212121212,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6748177965309607,
            "auditor_fn_violation": 0.011290956515525067,
            "auditor_fp_violation": 0.013394903529607875,
            "ave_precision_score": 0.6757712854347293,
            "fpr": 0.13596491228070176,
            "logloss": 1.6350534298461081,
            "mae": 0.3984912817804038,
            "precision": 0.6892230576441103,
            "recall": 0.560081466395112
        },
        "train": {
            "accuracy": 0.6531284302963776,
            "auc_prc": 0.6634025524558496,
            "auditor_fn_violation": 0.004616008326359139,
            "auditor_fp_violation": 0.015014897287125614,
            "ave_precision_score": 0.6645373922517883,
            "fpr": 0.13172338090010977,
            "logloss": 1.6475244767558679,
            "mae": 0.37568110115950687,
            "precision": 0.689922480620155,
            "recall": 0.5766738660907127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.6666768833358504,
            "auditor_fn_violation": 0.013099832064887273,
            "auditor_fp_violation": 0.009311059715797812,
            "ave_precision_score": 0.6664569055949822,
            "fpr": 0.20285087719298245,
            "logloss": 1.243898262530558,
            "mae": 0.3215696837218741,
            "precision": 0.685374149659864,
            "recall": 0.8207739307535642
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6401367827456906,
            "auditor_fn_violation": 0.005244278591631439,
            "auditor_fp_violation": 0.011623804296691239,
            "ave_precision_score": 0.6399651924869216,
            "fpr": 0.19758507135016465,
            "logloss": 1.3223007985156696,
            "mae": 0.3303903653194868,
            "precision": 0.6739130434782609,
            "recall": 0.8034557235421166
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 21924,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8443134306369913,
            "auditor_fn_violation": 0.014607228356022444,
            "auditor_fp_violation": 0.018023086219110723,
            "ave_precision_score": 0.8445401770448318,
            "fpr": 0.13157894736842105,
            "logloss": 0.720137116112878,
            "mae": 0.2695307120539429,
            "precision": 0.7642436149312377,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8141205356457026,
            "auditor_fn_violation": 0.002285481266877358,
            "auditor_fp_violation": 0.012574486435628047,
            "ave_precision_score": 0.8145979996465778,
            "fpr": 0.12843029637760703,
            "logloss": 0.7405948594037369,
            "mae": 0.2781703022249707,
            "precision": 0.7483870967741936,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8412666928969528,
            "auditor_fn_violation": 0.017983796048165225,
            "auditor_fp_violation": 0.019387840146685008,
            "ave_precision_score": 0.8414993972808187,
            "fpr": 0.14473684210526316,
            "logloss": 0.7568599388267493,
            "mae": 0.2718171489807242,
            "precision": 0.7461538461538462,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8088008336594215,
            "auditor_fn_violation": 0.004426341831182594,
            "auditor_fp_violation": 0.015887172651717123,
            "ave_precision_score": 0.8095227754025248,
            "fpr": 0.13391877058177826,
            "logloss": 0.7698944304993763,
            "mae": 0.27348933937754677,
            "precision": 0.7436974789915967,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6956140123193272,
            "auditor_fn_violation": 0.014906474434558913,
            "auditor_fp_violation": 0.007987977663874652,
            "ave_precision_score": 0.696579970697928,
            "fpr": 0.14912280701754385,
            "logloss": 1.331710658637025,
            "mae": 0.3385798227731345,
            "precision": 0.7178423236514523,
            "recall": 0.7046843177189409
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.6947870889950372,
            "auditor_fn_violation": 0.006052732027321458,
            "auditor_fp_violation": 0.014600811510114487,
            "ave_precision_score": 0.6949576902752901,
            "fpr": 0.141602634467618,
            "logloss": 1.3797726468600768,
            "mae": 0.3271813238497701,
            "precision": 0.7164835164835165,
            "recall": 0.7041036717062635
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 21924,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8321112002717649,
            "auditor_fn_violation": 0.012045771250937934,
            "auditor_fp_violation": 0.02527659707463434,
            "ave_precision_score": 0.8323337957305321,
            "fpr": 0.1425438596491228,
            "logloss": 0.8779970008448104,
            "mae": 0.2790156657676714,
            "precision": 0.7430830039525692,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8031782866538588,
            "auditor_fn_violation": 0.011235369008020529,
            "auditor_fp_violation": 0.014909538184099111,
            "ave_precision_score": 0.8037287197660803,
            "fpr": 0.12843029637760703,
            "logloss": 0.8809524245670717,
            "mae": 0.27811012996061774,
            "precision": 0.7456521739130435,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6239035087719298,
            "auc_prc": 0.5750241141751351,
            "auditor_fn_violation": 0.019339336120341586,
            "auditor_fp_violation": 0.015340459224069682,
            "ave_precision_score": 0.5746251944776822,
            "fpr": 0.22587719298245615,
            "logloss": 1.3455848726390205,
            "mae": 0.4174790335227411,
            "precision": 0.6321428571428571,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.5637409990859029,
            "auditor_fn_violation": 0.01669776406910499,
            "auditor_fp_violation": 0.01555394386074959,
            "ave_precision_score": 0.5639842540174591,
            "fpr": 0.2261251372118551,
            "logloss": 1.460583525689585,
            "mae": 0.40308329172533386,
            "precision": 0.6327985739750446,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7702504960210408,
            "auditor_fn_violation": 0.013780951870511305,
            "auditor_fp_violation": 0.012514585156477897,
            "ave_precision_score": 0.7535972668252351,
            "fpr": 0.16776315789473684,
            "logloss": 2.0504380905601822,
            "mae": 0.30258744494862466,
            "precision": 0.7145522388059702,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7572600243700723,
            "auditor_fn_violation": 0.007337722532142542,
            "auditor_fp_violation": 0.016602634467618005,
            "ave_precision_score": 0.7404818265003305,
            "fpr": 0.15367727771679474,
            "logloss": 1.9203818348097044,
            "mae": 0.2940201970844048,
            "precision": 0.7194388777555111,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7916666666666666,
            "auc_prc": 0.8793417721022168,
            "auditor_fn_violation": 0.007976917854718267,
            "auditor_fp_violation": 0.01283233320831771,
            "ave_precision_score": 0.8795369637414601,
            "fpr": 0.1074561403508772,
            "logloss": 0.46261908027291604,
            "mae": 0.30128017729944795,
            "precision": 0.8028169014084507,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8638341255666138,
            "auditor_fn_violation": 0.00968958707233169,
            "auditor_fp_violation": 0.01747981025560609,
            "ave_precision_score": 0.8640467586793501,
            "fpr": 0.1163556531284303,
            "logloss": 0.4788266250589523,
            "mae": 0.30362990377715565,
            "precision": 0.7749469214437368,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7955761986284013,
            "auditor_fn_violation": 0.013816682745560442,
            "auditor_fp_violation": 0.0232893695045214,
            "ave_precision_score": 0.7458663682978238,
            "fpr": 0.15570175438596492,
            "logloss": 4.231241739820737,
            "mae": 0.28421676311918037,
            "precision": 0.7310606060606061,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7820436217744673,
            "auditor_fn_violation": 0.008459125684873864,
            "auditor_fp_violation": 0.025180825623333857,
            "ave_precision_score": 0.7423606642458184,
            "fpr": 0.141602634467618,
            "logloss": 4.117135508984523,
            "mae": 0.28100235241693533,
            "precision": 0.7351129363449692,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8333652851317437,
            "auditor_fn_violation": 0.013486172151355993,
            "auditor_fp_violation": 0.021765741551027215,
            "ave_precision_score": 0.833616059392914,
            "fpr": 0.13815789473684212,
            "logloss": 0.841289029575001,
            "mae": 0.271059683313621,
            "precision": 0.75390625,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.801989699922268,
            "auditor_fn_violation": 0.006481852472658395,
            "auditor_fp_violation": 0.011334679316292935,
            "ave_precision_score": 0.8027286371262654,
            "fpr": 0.1251372118551043,
            "logloss": 0.8487938319247547,
            "mae": 0.273866223529057,
            "precision": 0.7510917030567685,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7196797116866371,
            "auditor_fn_violation": 0.012208793368349588,
            "auditor_fp_violation": 0.01380380880943451,
            "ave_precision_score": 0.7205829520807814,
            "fpr": 0.1524122807017544,
            "logloss": 1.3544116646782234,
            "mae": 0.30419637362849744,
            "precision": 0.7306201550387597,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7126836432769027,
            "auditor_fn_violation": 0.006965502035358576,
            "auditor_fp_violation": 0.015171710835816225,
            "ave_precision_score": 0.7125177513509136,
            "fpr": 0.14928649835345773,
            "logloss": 1.4305834366490366,
            "mae": 0.30539241365193537,
            "precision": 0.7154811715481172,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8223105089679537,
            "auditor_fn_violation": 0.01962071676135349,
            "auditor_fp_violation": 0.02379464099679126,
            "ave_precision_score": 0.8225701987809633,
            "fpr": 0.21271929824561403,
            "logloss": 1.106481219908167,
            "mae": 0.2840868907883864,
            "precision": 0.6896,
            "recall": 0.8778004073319755
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7917331017374747,
            "auditor_fn_violation": 0.003935579774913292,
            "auditor_fp_violation": 0.025099968637290266,
            "ave_precision_score": 0.7926115595713105,
            "fpr": 0.2217343578485181,
            "logloss": 1.1277748233112843,
            "mae": 0.2980193740836778,
            "precision": 0.6622073578595318,
            "recall": 0.8552915766738661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.823697013202758,
            "auditor_fn_violation": 0.013481705791974845,
            "auditor_fp_violation": 0.022953390007084226,
            "ave_precision_score": 0.8239608843721046,
            "fpr": 0.1425438596491228,
            "logloss": 0.9262238160124897,
            "mae": 0.2843169427552682,
            "precision": 0.7420634920634921,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8028738056386313,
            "auditor_fn_violation": 0.012752700969432871,
            "auditor_fp_violation": 0.01922681119648738,
            "ave_precision_score": 0.8033289692045387,
            "fpr": 0.13062568605927552,
            "logloss": 0.9156103244251953,
            "mae": 0.27948450738346237,
            "precision": 0.7435344827586207,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6548207359012577,
            "auditor_fn_violation": 0.007474452424339881,
            "auditor_fp_violation": 0.006724798933199984,
            "ave_precision_score": 0.6559033698410481,
            "fpr": 0.06907894736842106,
            "logloss": 3.3838125120703113,
            "mae": 0.4459262685373573,
            "precision": 0.7136363636363636,
            "recall": 0.319755600814664
        },
        "train": {
            "accuracy": 0.6234906695938529,
            "auc_prc": 0.670374826174806,
            "auditor_fn_violation": 0.008824233688088722,
            "auditor_fp_violation": 0.009448016308609067,
            "ave_precision_score": 0.6719415488077976,
            "fpr": 0.05817782656421515,
            "logloss": 3.062309437316543,
            "mae": 0.4148058698126751,
            "precision": 0.7654867256637168,
            "recall": 0.37365010799136067
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8220660502408084,
            "auditor_fn_violation": 0.015236985028763356,
            "auditor_fp_violation": 0.023054965203983837,
            "ave_precision_score": 0.8223759007170317,
            "fpr": 0.14583333333333334,
            "logloss": 0.7967952571150483,
            "mae": 0.2761821152048549,
            "precision": 0.7461832061068703,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7983728632221435,
            "auditor_fn_violation": 0.0019440815755595786,
            "auditor_fp_violation": 0.015549043437352991,
            "ave_precision_score": 0.7982994130483617,
            "fpr": 0.141602634467618,
            "logloss": 0.7804252545323235,
            "mae": 0.27985252151180123,
            "precision": 0.735655737704918,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.6409083112220232,
            "auditor_fn_violation": 0.010701397077214424,
            "auditor_fp_violation": 0.0019820185856565388,
            "ave_precision_score": 0.6429242774759683,
            "fpr": 0.20614035087719298,
            "logloss": 0.7630133467032183,
            "mae": 0.3684997149833004,
            "precision": 0.6850921273031826,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.5964996352838933,
            "auditor_fn_violation": 0.012797746762037302,
            "auditor_fp_violation": 0.01793064920809159,
            "ave_precision_score": 0.5977282920315433,
            "fpr": 0.2217343578485181,
            "logloss": 0.8356056869066367,
            "mae": 0.39195169311253975,
            "precision": 0.6462346760070052,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8167561324738167,
            "auditor_fn_violation": 0.013437042198163439,
            "auditor_fp_violation": 0.02282316539567446,
            "ave_precision_score": 0.8170820968557584,
            "fpr": 0.15350877192982457,
            "logloss": 0.8648833882068235,
            "mae": 0.27789672519608294,
            "precision": 0.7397769516728625,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.7907222549290502,
            "auditor_fn_violation": 0.002937459844046728,
            "auditor_fp_violation": 0.009857201662223621,
            "ave_precision_score": 0.7900097102247461,
            "fpr": 0.14818880351262348,
            "logloss": 0.877401406395383,
            "mae": 0.28485455240494073,
            "precision": 0.7294589178356713,
            "recall": 0.7861771058315334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7082476762583492,
            "auditor_fn_violation": 0.013803283667417017,
            "auditor_fp_violation": 0.029495874484310538,
            "ave_precision_score": 0.7031866732038157,
            "fpr": 0.22478070175438597,
            "logloss": 1.646713034354645,
            "mae": 0.29735291917167195,
            "precision": 0.6801872074882995,
            "recall": 0.8879837067209776
        },
        "train": {
            "accuracy": 0.6893523600439078,
            "auc_prc": 0.697005201180685,
            "auditor_fn_violation": 0.005272728565907926,
            "auditor_fp_violation": 0.024080680570801323,
            "ave_precision_score": 0.6935155382163402,
            "fpr": 0.22283205268935236,
            "logloss": 1.4599963350179619,
            "mae": 0.31297605571351267,
            "precision": 0.6535836177474402,
            "recall": 0.8272138228941684
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 21924,
        "test": {
            "accuracy": 0.4923245614035088,
            "auc_prc": 0.47559004367523816,
            "auditor_fn_violation": 0.013959606245756971,
            "auditor_fp_violation": 0.00870160853440013,
            "ave_precision_score": 0.4757310621317435,
            "fpr": 0.22697368421052633,
            "logloss": 2.354462150475088,
            "mae": 0.521723632701796,
            "precision": 0.5316742081447964,
            "recall": 0.4786150712830957
        },
        "train": {
            "accuracy": 0.5499451152579583,
            "auc_prc": 0.48913916772527594,
            "auditor_fn_violation": 0.014523711868143852,
            "auditor_fp_violation": 0.008418927395326958,
            "ave_precision_score": 0.4893481340672208,
            "fpr": 0.21624588364434688,
            "logloss": 2.1766498481319454,
            "mae": 0.47481610565345694,
            "precision": 0.5592841163310962,
            "recall": 0.5399568034557235
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8554230895857178,
            "auditor_fn_violation": 0.012244524243398721,
            "auditor_fp_violation": 0.01901800225028129,
            "ave_precision_score": 0.8556592448280513,
            "fpr": 0.14364035087719298,
            "logloss": 0.5009395452816503,
            "mae": 0.30728245039445984,
            "precision": 0.7555970149253731,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8449092197602799,
            "auditor_fn_violation": 0.005543003321534499,
            "auditor_fp_violation": 0.019160655480633535,
            "ave_precision_score": 0.8451420071160246,
            "fpr": 0.13611416026344675,
            "logloss": 0.514735231633711,
            "mae": 0.3110740106597821,
            "precision": 0.7489878542510121,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8631922378324581,
            "auditor_fn_violation": 0.014832779504770072,
            "auditor_fp_violation": 0.020028545234821026,
            "ave_precision_score": 0.863695711734186,
            "fpr": 0.14473684210526316,
            "logloss": 0.48592620084840377,
            "mae": 0.31049745820111413,
            "precision": 0.7595628415300546,
            "recall": 0.8492871690427699
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8301016680427127,
            "auditor_fn_violation": 0.008997304364937304,
            "auditor_fp_violation": 0.019569840834248085,
            "ave_precision_score": 0.8306261456103363,
            "fpr": 0.15916575192096596,
            "logloss": 0.5180467544750844,
            "mae": 0.32357026540708006,
            "precision": 0.7232824427480916,
            "recall": 0.8185745140388769
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.839103554257285,
            "auditor_fn_violation": 0.012746989673777114,
            "auditor_fp_violation": 0.02252364878943202,
            "ave_precision_score": 0.8393388267606452,
            "fpr": 0.1513157894736842,
            "logloss": 0.7730192871325691,
            "mae": 0.27610855191978756,
            "precision": 0.7376425855513308,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8016621149404827,
            "auditor_fn_violation": 0.004080200477485402,
            "auditor_fp_violation": 0.018464795358318964,
            "ave_precision_score": 0.8023405672355468,
            "fpr": 0.14489571899012074,
            "logloss": 0.8092235372172869,
            "mae": 0.27846508738278863,
            "precision": 0.7300613496932515,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.8174893105231738,
            "auditor_fn_violation": 0.012561635759459752,
            "auditor_fp_violation": 0.025242738675667786,
            "ave_precision_score": 0.8177533703802323,
            "fpr": 0.14473684210526316,
            "logloss": 0.838037845324217,
            "mae": 0.2939844262709821,
            "precision": 0.7322515212981744,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7743950840532476,
            "auditor_fn_violation": 0.01082758604339096,
            "auditor_fp_violation": 0.01742100517484711,
            "ave_precision_score": 0.7751703731952733,
            "fpr": 0.1350164654226125,
            "logloss": 0.8674342720363454,
            "mae": 0.29370282810045933,
            "precision": 0.7331887201735358,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.8102524980454107,
            "auditor_fn_violation": 0.01600743202201022,
            "auditor_fp_violation": 0.022448118514814357,
            "ave_precision_score": 0.8105746584362348,
            "fpr": 0.15021929824561403,
            "logloss": 0.8853587441407323,
            "mae": 0.2859545222213136,
            "precision": 0.7360308285163777,
            "recall": 0.7780040733197556
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.786893093289832,
            "auditor_fn_violation": 0.003696125824752906,
            "auditor_fp_violation": 0.014733122941822175,
            "ave_precision_score": 0.787464133045849,
            "fpr": 0.141602634467618,
            "logloss": 0.8757205302113467,
            "mae": 0.2841182670415559,
            "precision": 0.7318087318087318,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8264435252382003,
            "auditor_fn_violation": 0.01165049844570694,
            "auditor_fp_violation": 0.023544609742884533,
            "ave_precision_score": 0.8267403902534793,
            "fpr": 0.15021929824561403,
            "logloss": 0.8376540949802804,
            "mae": 0.2788960839914103,
            "precision": 0.7390476190476191,
            "recall": 0.790224032586558
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8062368173198285,
            "auditor_fn_violation": 0.0011261448151107332,
            "auditor_fp_violation": 0.018597106790026657,
            "ave_precision_score": 0.8067223699238142,
            "fpr": 0.13721185510428102,
            "logloss": 0.8379492441378414,
            "mae": 0.2767943025600261,
            "precision": 0.7412008281573499,
            "recall": 0.7732181425485961
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6469298245614035,
            "auc_prc": 0.6767508130646049,
            "auditor_fn_violation": 0.01156563761746526,
            "auditor_fp_violation": 0.008795370254615164,
            "ave_precision_score": 0.6777927061727589,
            "fpr": 0.14692982456140352,
            "logloss": 1.4638031452211844,
            "mae": 0.3736709441488205,
            "precision": 0.6933638443935927,
            "recall": 0.6171079429735234
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6886156922977524,
            "auditor_fn_violation": 0.013191304739528634,
            "auditor_fp_violation": 0.017264191626156507,
            "ave_precision_score": 0.6887852559740605,
            "fpr": 0.1394072447859495,
            "logloss": 1.4905898194524985,
            "mae": 0.34877041501105693,
            "precision": 0.703962703962704,
            "recall": 0.652267818574514
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.744785283736783,
            "auditor_fn_violation": 0.024247865080215817,
            "auditor_fp_violation": 0.01373609201150145,
            "ave_precision_score": 0.7455509689994201,
            "fpr": 0.23903508771929824,
            "logloss": 0.7605069527360346,
            "mae": 0.34972308339887315,
            "precision": 0.655608214849921,
            "recall": 0.845213849287169
        },
        "train": {
            "accuracy": 0.6827661909989023,
            "auc_prc": 0.7147156997652326,
            "auditor_fn_violation": 0.022987579215397128,
            "auditor_fp_violation": 0.031833150384193196,
            "ave_precision_score": 0.7154459573256676,
            "fpr": 0.23819978046103182,
            "logloss": 0.7830677221011915,
            "mae": 0.3578404642313895,
            "precision": 0.6430921052631579,
            "recall": 0.8444924406047516
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7301189256790871,
            "auditor_fn_violation": 0.012941276306856762,
            "auditor_fp_violation": 0.015988977788890284,
            "ave_precision_score": 0.7308031781004298,
            "fpr": 0.16228070175438597,
            "logloss": 1.4305819221827332,
            "mae": 0.299009450873929,
            "precision": 0.7228464419475655,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.719027201713013,
            "auditor_fn_violation": 0.003956917255620647,
            "auditor_fp_violation": 0.019557589775756633,
            "ave_precision_score": 0.7186438401738364,
            "fpr": 0.15697036223929747,
            "logloss": 1.4737294856632899,
            "mae": 0.2971689980451866,
            "precision": 0.7099391480730223,
            "recall": 0.755939524838013
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8426448995701665,
            "auditor_fn_violation": 0.008852324293421948,
            "auditor_fp_violation": 0.01600460474225945,
            "ave_precision_score": 0.8428738134622566,
            "fpr": 0.13267543859649122,
            "logloss": 0.7193607203335646,
            "mae": 0.2739034509851448,
            "precision": 0.7589641434262948,
            "recall": 0.7759674134419552
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8054172144596448,
            "auditor_fn_violation": 0.003184026287776236,
            "auditor_fp_violation": 0.01025168574564843,
            "ave_precision_score": 0.8060619621333122,
            "fpr": 0.132821075740944,
            "logloss": 0.7553329358736862,
            "mae": 0.28072269912648534,
            "precision": 0.7408993576017131,
            "recall": 0.7473002159827213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 21924,
        "test": {
            "accuracy": 0.6260964912280702,
            "auc_prc": 0.76073421017596,
            "auditor_fn_violation": 0.005332833101082645,
            "auditor_fp_violation": 0.017551673125807403,
            "ave_precision_score": 0.7187766899479194,
            "fpr": 0.35635964912280704,
            "logloss": 3.571459510925701,
            "mae": 0.3727110598158917,
            "precision": 0.59375,
            "recall": 0.9674134419551935
        },
        "train": {
            "accuracy": 0.5949506037321625,
            "auc_prc": 0.7472639825158242,
            "auditor_fn_violation": 0.0025130810610892074,
            "auditor_fp_violation": 0.00516504625999687,
            "ave_precision_score": 0.7127904939133368,
            "fpr": 0.38199780461031835,
            "logloss": 3.244158337047755,
            "mae": 0.39546427522393496,
            "precision": 0.5594936708860759,
            "recall": 0.9546436285097192
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5679824561403509,
            "auc_prc": 0.6690817802240682,
            "auditor_fn_violation": 0.012362882766998972,
            "auditor_fp_violation": 0.015710297120473393,
            "ave_precision_score": 0.6671393217700987,
            "fpr": 0.0625,
            "logloss": 8.240506085050159,
            "mae": 0.4497225141210468,
            "precision": 0.7298578199052133,
            "recall": 0.3136456211812627
        },
        "train": {
            "accuracy": 0.6070252469813392,
            "auc_prc": 0.6614689799179452,
            "auditor_fn_violation": 0.012095980729884099,
            "auditor_fp_violation": 0.011643405990277562,
            "ave_precision_score": 0.6593961837766026,
            "fpr": 0.05817782656421515,
            "logloss": 7.670834428093942,
            "mae": 0.4187325028124373,
            "precision": 0.7488151658767772,
            "recall": 0.3412526997840173
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8660265593794648,
            "auditor_fn_violation": 0.02281193053917891,
            "auditor_fp_violation": 0.01618431470600492,
            "ave_precision_score": 0.8662154932642359,
            "fpr": 0.09758771929824561,
            "logloss": 0.6554314511749674,
            "mae": 0.30544731560869304,
            "precision": 0.8048245614035088,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8419818352821065,
            "auditor_fn_violation": 0.02127820992761853,
            "auditor_fp_violation": 0.008325819350791913,
            "ave_precision_score": 0.8422040454792677,
            "fpr": 0.09440175631174534,
            "logloss": 0.6344346668944899,
            "mae": 0.3097653803448703,
            "precision": 0.7957244655581948,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8662760812920289,
            "auditor_fn_violation": 0.02281193053917891,
            "auditor_fp_violation": 0.015233675042713675,
            "ave_precision_score": 0.866465273564791,
            "fpr": 0.09868421052631579,
            "logloss": 0.6456576339981218,
            "mae": 0.30547697316028727,
            "precision": 0.8030634573304157,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8422650419929503,
            "auditor_fn_violation": 0.02127820992761853,
            "auditor_fp_violation": 0.006686627724635409,
            "ave_precision_score": 0.8424884271717624,
            "fpr": 0.09549945115257959,
            "logloss": 0.6288261578396216,
            "mae": 0.3098526633422447,
            "precision": 0.7938388625592417,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8414844989825279,
            "auditor_fn_violation": 0.0102547611391003,
            "auditor_fp_violation": 0.021252656582072763,
            "ave_precision_score": 0.8417071041426112,
            "fpr": 0.14035087719298245,
            "logloss": 0.7747353211841185,
            "mae": 0.2747787388654876,
            "precision": 0.7470355731225297,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8043892293350264,
            "auditor_fn_violation": 0.0039711422427588915,
            "auditor_fp_violation": 0.010976948408342483,
            "ave_precision_score": 0.8052283310401678,
            "fpr": 0.1251372118551043,
            "logloss": 0.7983935537681175,
            "mae": 0.27705522590692505,
            "precision": 0.7532467532467533,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 21924,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.5881304677366582,
            "auditor_fn_violation": 0.01646970021795835,
            "auditor_fp_violation": 0.029076551235571128,
            "ave_precision_score": 0.5841303156040107,
            "fpr": 0.20614035087719298,
            "logloss": 2.4595392894470436,
            "mae": 0.4550613692584961,
            "precision": 0.5991471215351812,
            "recall": 0.5723014256619144
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.5993056509184951,
            "auditor_fn_violation": 0.015142498808657328,
            "auditor_fp_violation": 0.03464599341383097,
            "ave_precision_score": 0.5968352551153554,
            "fpr": 0.2074643249176729,
            "logloss": 2.2605585560979153,
            "mae": 0.43306486879564876,
            "precision": 0.6012658227848101,
            "recall": 0.6155507559395248
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7232238791981854,
            "auditor_fn_violation": 0.012135098438560765,
            "auditor_fp_violation": 0.013814226778347292,
            "ave_precision_score": 0.7241115984115147,
            "fpr": 0.1524122807017544,
            "logloss": 1.3484965380189091,
            "mae": 0.3023839748819545,
            "precision": 0.7311411992263056,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.71571119764406,
            "auditor_fn_violation": 0.007700459704167695,
            "auditor_fp_violation": 0.0143827426689666,
            "ave_precision_score": 0.7160242479944867,
            "fpr": 0.14818880351262348,
            "logloss": 1.406385598896573,
            "mae": 0.3041292984701799,
            "precision": 0.7175732217573222,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8718568185817974,
            "auditor_fn_violation": 0.003354235895237077,
            "auditor_fp_violation": 0.019153435846147437,
            "ave_precision_score": 0.872040557209689,
            "fpr": 0.12171052631578948,
            "logloss": 0.47872435754242404,
            "mae": 0.30373625011564226,
            "precision": 0.783203125,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8421139849191239,
            "auditor_fn_violation": 0.003456671874592515,
            "auditor_fp_violation": 0.019062647012701904,
            "ave_precision_score": 0.8423942438275123,
            "fpr": 0.12733260153677278,
            "logloss": 0.510599364734715,
            "mae": 0.31705120805871767,
            "precision": 0.7588357588357588,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7998826268163404,
            "auditor_fn_violation": 0.01421865508986315,
            "auditor_fp_violation": 0.023409176147018377,
            "ave_precision_score": 0.7806628805774315,
            "fpr": 0.13925438596491227,
            "logloss": 1.7098124772304961,
            "mae": 0.27454985143618105,
            "precision": 0.7529182879377432,
            "recall": 0.7881873727087576
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7906343024265787,
            "auditor_fn_violation": 0.007890126199344226,
            "auditor_fp_violation": 0.01128567508232712,
            "ave_precision_score": 0.7748054438482738,
            "fpr": 0.13062568605927552,
            "logloss": 1.4627325862403244,
            "mae": 0.27423871547764245,
            "precision": 0.7457264957264957,
            "recall": 0.7537796976241901
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7974071610968755,
            "auditor_fn_violation": 0.016858273484117628,
            "auditor_fp_violation": 0.02357065466516648,
            "ave_precision_score": 0.7492227664552479,
            "fpr": 0.1600877192982456,
            "logloss": 4.150675027861302,
            "mae": 0.28144103983229674,
            "precision": 0.7271028037383177,
            "recall": 0.7922606924643585
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7855208535674338,
            "auditor_fn_violation": 0.006071698676839115,
            "auditor_fp_violation": 0.02541604594636977,
            "ave_precision_score": 0.7490862852001878,
            "fpr": 0.1525795828759605,
            "logloss": 3.99034682859704,
            "mae": 0.2803344906451642,
            "precision": 0.7231075697211156,
            "recall": 0.7840172786177105
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8427279581617574,
            "auditor_fn_violation": 0.016065494693965062,
            "auditor_fp_violation": 0.026229841230153775,
            "ave_precision_score": 0.8429502936551512,
            "fpr": 0.14364035087719298,
            "logloss": 0.7720710133258768,
            "mae": 0.2724799901617607,
            "precision": 0.746615087040619,
            "recall": 0.7861507128309573
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8062078320081301,
            "auditor_fn_violation": 0.009089766781335874,
            "auditor_fp_violation": 0.018383938372275362,
            "ave_precision_score": 0.8070380162857433,
            "fpr": 0.132821075740944,
            "logloss": 0.793387948894598,
            "mae": 0.27518013471955893,
            "precision": 0.7436440677966102,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 21924,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8459758374722925,
            "auditor_fn_violation": 0.009555775895951696,
            "auditor_fp_violation": 0.00027868066841688104,
            "ave_precision_score": 0.8464933901614012,
            "fpr": 0.20723684210526316,
            "logloss": 0.5628137493048901,
            "mae": 0.3079803774200723,
            "precision": 0.6956521739130435,
            "recall": 0.879837067209776
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8225036818063655,
            "auditor_fn_violation": 0.0025533851913142245,
            "auditor_fp_violation": 0.013015524541320371,
            "ave_precision_score": 0.8240819375288457,
            "fpr": 0.21075740944017562,
            "logloss": 0.579157312120963,
            "mae": 0.31932143454105644,
            "precision": 0.6821192052980133,
            "recall": 0.8898488120950324
        }
    }
]