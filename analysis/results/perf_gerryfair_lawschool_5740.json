[
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.001",
        "seed": 5740,
        "test": {
            "accuracy": 0.3344298245614035,
            "auc_prc": 0.8781521003602951,
            "auditor_fn_violation": 0.0095712201448179,
            "auditor_fp_violation": 0.005206398348813207,
            "ave_precision_score": 0.8302988192571386,
            "fpr": 0.45285087719298245,
            "logloss": 4.655277200927431,
            "mae": 0.3373538011695909,
            "precision": 0.415014164305949,
            "recall": 0.6016427104722792
        },
        "train": {
            "accuracy": 0.32821075740944017,
            "auc_prc": 0.8778311037713391,
            "auditor_fn_violation": 0.008971951193713768,
            "auditor_fp_violation": 0.0022646136806400473,
            "ave_precision_score": 0.8279815183582315,
            "fpr": 0.47859495060373214,
            "logloss": 4.553389559068723,
            "mae": 0.32865427047644424,
            "precision": 0.40027510316368636,
            "recall": 0.6231263383297645,
            "self_error": 0.3286542704764439,
            "self_fairness_violation": 0.0005824105714336246
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.01108080808080808",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.021161616161616163",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.031242424242424245",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.041323232323232324",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.0514040404040404",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.06148484848484849",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.07156565656565657",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.08164646464646465",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.09172727272727273",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.1018080808080808",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.11188888888888888",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.12196969696969698",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.13205050505050506",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.14213131313131314",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.15221212121212122",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.1622929292929293",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.17237373737373737",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.18245454545454545",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.19253535353535353",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2026161616161616",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2126969696969697",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.22277777777777777",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.23285858585858585",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.24293939393939395",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.25302020202020203",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2631010101010101",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.2731818181818182",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.28326262626262627",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.29334343434343435",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.30342424242424243",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3135050505050505",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3235858585858586",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.33366666666666667",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.34374747474747475",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3538282828282828",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.3639090909090909",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.373989898989899",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.38407070707070706",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.39415151515151514",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4042323232323232",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4143131313131313",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4243939393939394",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.43447474747474746",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.44455555555555554",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4546363636363636",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4647171717171717",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4747979797979798",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.4848787878787879",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.494959595959596",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5050404040404041",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5151212121212121",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5252020202020202",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5352828282828282",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5453636363636364",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5554444444444444",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5655252525252525",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5756060606060606",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5856868686868687",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.5957676767676767",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6058484848484849",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6159292929292929",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.626010101010101",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.636090909090909",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6461717171717172",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6562525252525253",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6663333333333333",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6764141414141415",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6864949494949495",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.6965757575757576",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7066565656565656",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7167373737373738",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7268181818181818",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7368989898989899",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.746979797979798",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7570606060606061",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7671414141414141",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7772222222222223",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7873030303030303",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.7973838383838384",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8074646464646464",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8175454545454546",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8276262626262626",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8377070707070707",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8477878787878788",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8578686868686869",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8679494949494949",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.878030303030303",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8881111111111111",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.8981919191919192",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9082727272727272",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9183535353535354",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9284343434343434",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9385151515151515",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9485959595959595",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9586767676767677",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9687575757575758",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.9788383838383838",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.988919191919192",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    },
    {
        "dataset": "lawschool",
        "method": "gerryfair",
        "model": "gerryfair:g=0.999",
        "seed": 5740,
        "test": {
            "accuracy": 0.20614035087719298,
            "auc_prc": 0.8586711103819584,
            "auditor_fn_violation": 0.017125076551749,
            "auditor_fp_violation": 0.005497936016511869,
            "ave_precision_score": 0.7547477543272861,
            "fpr": 0.36403508771929827,
            "logloss": 7.1199170228116415,
            "mae": 0.20614035087719298,
            "precision": 0.2224824355971897,
            "recall": 0.19507186858316222
        },
        "train": {
            "accuracy": 0.1986827661909989,
            "auc_prc": 0.8565409799590297,
            "auditor_fn_violation": 0.008478341093981025,
            "auditor_fp_violation": 0.006264771906923388,
            "ave_precision_score": 0.7512798784354003,
            "fpr": 0.3929747530186608,
            "logloss": 6.862335118394984,
            "mae": 0.1986827661909989,
            "precision": 0.2097130242825607,
            "recall": 0.20342612419700215,
            "self_error": 0.1986827661909989,
            "self_fairness_violation": 0.006264771906923395
        }
    }
]