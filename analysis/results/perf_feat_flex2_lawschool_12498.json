[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6556279877794009,
            "auditor_fn_violation": 0.016632373113854595,
            "auditor_fp_violation": 0.01613334980644099,
            "ave_precision_score": 0.5862074419038685,
            "fpr": 0.30701754385964913,
            "logloss": 5.8441807941782535,
            "mae": 0.38227802056932864,
            "precision": 0.6078431372549019,
            "recall": 0.8930041152263375
        },
        "train": {
            "accuracy": 0.6355653128430296,
            "auc_prc": 0.6771770654084428,
            "auditor_fn_violation": 0.007993470122998118,
            "auditor_fp_violation": 0.0008573417944213436,
            "ave_precision_score": 0.6085870058442756,
            "fpr": 0.31174533479692645,
            "logloss": 5.231658007052116,
            "mae": 0.37446577275994986,
            "precision": 0.5965909090909091,
            "recall": 0.8974358974358975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 12498,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8184549300292185,
            "auditor_fn_violation": 0.01937811349361057,
            "auditor_fp_violation": 0.015150111193476652,
            "ave_precision_score": 0.8191211711642357,
            "fpr": 0.11513157894736842,
            "logloss": 0.8925795232549897,
            "mae": 0.26902858776329774,
            "precision": 0.7727272727272727,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8355246460531851,
            "auditor_fn_violation": 0.008971544372202989,
            "auditor_fp_violation": 0.011737653410907078,
            "ave_precision_score": 0.8357708239837165,
            "fpr": 0.1350164654226125,
            "logloss": 0.869594808761045,
            "mae": 0.26551754148151174,
            "precision": 0.74375,
            "recall": 0.7628205128205128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6296628497436709,
            "auditor_fn_violation": 0.014619883040935673,
            "auditor_fp_violation": 0.013700992504736022,
            "ave_precision_score": 0.5822920101079423,
            "fpr": 0.29714912280701755,
            "logloss": 4.733530185562965,
            "mae": 0.37735181512282,
            "precision": 0.6145092460881935,
            "recall": 0.8888888888888888
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.6638559562742965,
            "auditor_fn_violation": 0.005572912268850798,
            "auditor_fp_violation": 0.004878919055536437,
            "ave_precision_score": 0.6130231352782468,
            "fpr": 0.2854006586169045,
            "logloss": 4.223913906979576,
            "mae": 0.3628806935000079,
            "precision": 0.6176470588235294,
            "recall": 0.8974358974358975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6390743712619003,
            "auditor_fn_violation": 0.010599415204678364,
            "auditor_fp_violation": 0.023901449633473366,
            "ave_precision_score": 0.5693414671202528,
            "fpr": 0.27521929824561403,
            "logloss": 5.880924465193972,
            "mae": 0.38476890192600577,
            "precision": 0.6173780487804879,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.6333699231613611,
            "auc_prc": 0.6303653193472734,
            "auditor_fn_violation": 0.003222719468603114,
            "auditor_fp_violation": 0.00990651009854476,
            "ave_precision_score": 0.562414580226369,
            "fpr": 0.2843029637760702,
            "logloss": 5.700723829686221,
            "mae": 0.38621022398676524,
            "precision": 0.602760736196319,
            "recall": 0.8397435897435898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8243717084002441,
            "auditor_fn_violation": 0.013320337881741393,
            "auditor_fp_violation": 0.030367144386788582,
            "ave_precision_score": 0.8248439641051093,
            "fpr": 0.18859649122807018,
            "logloss": 0.8488779042140915,
            "mae": 0.2689315304107813,
            "precision": 0.7123745819397993,
            "recall": 0.8765432098765432
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8490064402053203,
            "auditor_fn_violation": 0.010561794590334657,
            "auditor_fp_violation": 0.020665406258595115,
            "ave_precision_score": 0.8492199626443149,
            "fpr": 0.21295279912184412,
            "logloss": 0.8654330120223929,
            "mae": 0.2774061159733445,
            "precision": 0.6824877250409165,
            "recall": 0.8910256410256411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7939739373464375,
            "auditor_fn_violation": 0.02065735325969244,
            "auditor_fp_violation": 0.024369903632320247,
            "ave_precision_score": 0.7943831929781288,
            "fpr": 0.12828947368421054,
            "logloss": 1.0800794004327423,
            "mae": 0.287059021526656,
            "precision": 0.7515923566878981,
            "recall": 0.7283950617283951
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8127512517433026,
            "auditor_fn_violation": 0.0075642432942103705,
            "auditor_fp_violation": 0.011584025690519438,
            "ave_precision_score": 0.8130477927012731,
            "fpr": 0.14489571899012074,
            "logloss": 1.0169538428902143,
            "mae": 0.2857929038565222,
            "precision": 0.7255717255717256,
            "recall": 0.7457264957264957
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.704182222174641,
            "auditor_fn_violation": 0.010831799148075954,
            "auditor_fp_violation": 0.019989086566180706,
            "ave_precision_score": 0.6709190790937145,
            "fpr": 0.1962719298245614,
            "logloss": 3.436766671405902,
            "mae": 0.33214201289390877,
            "precision": 0.6814946619217082,
            "recall": 0.7880658436213992
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7197353863519633,
            "auditor_fn_violation": 0.004404852374116917,
            "auditor_fp_violation": 0.015243834448786226,
            "ave_precision_score": 0.6854829600524928,
            "fpr": 0.2283205268935236,
            "logloss": 3.251971452846007,
            "mae": 0.33272693882469045,
            "precision": 0.6492411467116358,
            "recall": 0.8226495726495726
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5317982456140351,
            "auc_prc": 0.7637844793704089,
            "auditor_fn_violation": 0.0019493177387914231,
            "auditor_fp_violation": 0.0015057449962935542,
            "ave_precision_score": 0.5333349854680766,
            "fpr": 0.46381578947368424,
            "logloss": 15.920538964275174,
            "mae": 0.4671295809443619,
            "precision": 0.532596685082873,
            "recall": 0.9917695473251029
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7535628446659663,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0019699038340027764,
            "ave_precision_score": 0.5133526129423417,
            "fpr": 0.4829857299670692,
            "logloss": 16.61577722655643,
            "mae": 0.4836669543581175,
            "precision": 0.5154185022026432,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8241774763014764,
            "auditor_fn_violation": 0.01735434264674031,
            "auditor_fp_violation": 0.019664772259286718,
            "ave_precision_score": 0.8247917653655491,
            "fpr": 0.1206140350877193,
            "logloss": 0.7708899183258907,
            "mae": 0.27243306804074957,
            "precision": 0.7679324894514767,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8480610844654722,
            "auditor_fn_violation": 0.012780639289969701,
            "auditor_fp_violation": 0.018110725940536167,
            "ave_precision_score": 0.8482709323409606,
            "fpr": 0.14050493962678376,
            "logloss": 0.721725932516734,
            "mae": 0.26254026942760567,
            "precision": 0.7414141414141414,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8208664301789921,
            "auditor_fn_violation": 0.01747391885062451,
            "auditor_fp_violation": 0.01990672102792192,
            "ave_precision_score": 0.8215355217944604,
            "fpr": 0.12171052631578948,
            "logloss": 0.7936559241410943,
            "mae": 0.27110100875654203,
            "precision": 0.7668067226890757,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8412288827643184,
            "auditor_fn_violation": 0.011291245649094167,
            "auditor_fp_violation": 0.011891281131294716,
            "ave_precision_score": 0.8414550895602488,
            "fpr": 0.14050493962678376,
            "logloss": 0.7527759773536916,
            "mae": 0.2673220903190776,
            "precision": 0.7387755102040816,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 12498,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8227956089426472,
            "auditor_fn_violation": 0.01083856761244675,
            "auditor_fp_violation": 0.02141503994728606,
            "ave_precision_score": 0.8231047439942356,
            "fpr": 0.12609649122807018,
            "logloss": 1.0111166530126767,
            "mae": 0.26822887527259776,
            "precision": 0.7672064777327935,
            "recall": 0.779835390946502
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8394523781185287,
            "auditor_fn_violation": 0.007805829979265764,
            "auditor_fp_violation": 0.01584843386450531,
            "ave_precision_score": 0.8396748188007849,
            "fpr": 0.150384193194292,
            "logloss": 0.9215149125588032,
            "mae": 0.2716790575423596,
            "precision": 0.7265469061876247,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6416008851573876,
            "auditor_fn_violation": 0.013760288065843626,
            "auditor_fp_violation": 0.01582962688411169,
            "ave_precision_score": 0.5648509702058214,
            "fpr": 0.3157894736842105,
            "logloss": 6.688628451261306,
            "mae": 0.40098844908801806,
            "precision": 0.5960729312762973,
            "recall": 0.8744855967078189
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.6751187490018189,
            "auditor_fn_violation": 0.009778396990252094,
            "auditor_fp_violation": 0.007564926295862226,
            "ave_precision_score": 0.5968527748631968,
            "fpr": 0.3336992316136114,
            "logloss": 5.868526564228895,
            "mae": 0.39332489776859314,
            "precision": 0.5795297372060858,
            "recall": 0.8952991452991453
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.6637126907927792,
            "auditor_fn_violation": 0.018015396000288786,
            "auditor_fp_violation": 0.015381764269829507,
            "ave_precision_score": 0.6648120777380427,
            "fpr": 0.11842105263157894,
            "logloss": 2.760959291394219,
            "mae": 0.34001420275312827,
            "precision": 0.7320099255583127,
            "recall": 0.6069958847736625
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.6827252990810948,
            "auditor_fn_violation": 0.002516723427810154,
            "auditor_fp_violation": 0.011331283311817195,
            "ave_precision_score": 0.6808512349424387,
            "fpr": 0.12294182217343579,
            "logloss": 2.409384493022811,
            "mae": 0.31222080954518966,
            "precision": 0.735224586288416,
            "recall": 0.6645299145299145
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.6777139550683813,
            "auditor_fn_violation": 0.01563064038697567,
            "auditor_fp_violation": 0.02093629025615684,
            "ave_precision_score": 0.6788052198979057,
            "fpr": 0.18201754385964913,
            "logloss": 2.517771273602162,
            "mae": 0.3221809827817539,
            "precision": 0.7067137809187279,
            "recall": 0.823045267489712
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7131363135042981,
            "auditor_fn_violation": 0.005303179562235545,
            "auditor_fp_violation": 0.01177977714069078,
            "ave_precision_score": 0.7112399055261234,
            "fpr": 0.20197585071350166,
            "logloss": 2.2999551088306465,
            "mae": 0.3214979381853418,
            "precision": 0.6822107081174439,
            "recall": 0.844017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8261707160159932,
            "auditor_fn_violation": 0.02393329001516137,
            "auditor_fp_violation": 0.021798554484803563,
            "ave_precision_score": 0.826464958915272,
            "fpr": 0.12609649122807018,
            "logloss": 1.0307567225145033,
            "mae": 0.27274117511889384,
            "precision": 0.7599164926931107,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8442306912081823,
            "auditor_fn_violation": 0.008443806467955756,
            "auditor_fp_violation": 0.020529123603412518,
            "ave_precision_score": 0.8444481868751152,
            "fpr": 0.13611416026344675,
            "logloss": 0.9322411498848407,
            "mae": 0.26195902239239127,
            "precision": 0.743801652892562,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6162280701754386,
            "auc_prc": 0.601568919167879,
            "auditor_fn_violation": 0.004670240415854451,
            "auditor_fp_violation": 0.016390742113499716,
            "ave_precision_score": 0.5493196803876508,
            "fpr": 0.3442982456140351,
            "logloss": 5.171598924378763,
            "mae": 0.4135801711782462,
            "precision": 0.5890052356020943,
            "recall": 0.9259259259259259
        },
        "train": {
            "accuracy": 0.6147091108671789,
            "auc_prc": 0.5983491533178253,
            "auditor_fn_violation": 0.004299304793267472,
            "auditor_fp_violation": 0.00097132365148315,
            "ave_precision_score": 0.5486145381304058,
            "fpr": 0.3424807903402854,
            "logloss": 4.836087612853785,
            "mae": 0.4130718867370141,
            "precision": 0.5789473684210527,
            "recall": 0.9166666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.715447075263997,
            "auditor_fn_violation": 0.011513157894736843,
            "auditor_fp_violation": 0.008478502594514459,
            "ave_precision_score": 0.6410641776532444,
            "fpr": 0.18859649122807018,
            "logloss": 5.528741751652562,
            "mae": 0.336625179627695,
            "precision": 0.699825479930192,
            "recall": 0.8251028806584362
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.6876858345914693,
            "auditor_fn_violation": 0.006389146894086524,
            "auditor_fp_violation": 0.006987583411179637,
            "ave_precision_score": 0.6102513267640344,
            "fpr": 0.2074643249176729,
            "logloss": 5.894835225532055,
            "mae": 0.3582571543083893,
            "precision": 0.6701570680628273,
            "recall": 0.8205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7028508771929824,
            "auc_prc": 0.6648271929159029,
            "auditor_fn_violation": 0.010998754602555783,
            "auditor_fp_violation": 0.020462688411168772,
            "ave_precision_score": 0.6630380641219713,
            "fpr": 0.13815789473684212,
            "logloss": 2.1654548632899417,
            "mae": 0.32101777953933575,
            "precision": 0.7301927194860813,
            "recall": 0.7016460905349794
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6709910567924433,
            "auditor_fn_violation": 0.0044752174280165615,
            "auditor_fp_violation": 0.012396765888699195,
            "ave_precision_score": 0.6658653068908768,
            "fpr": 0.15477497255762898,
            "logloss": 2.0443809458832054,
            "mae": 0.3125101983123733,
            "precision": 0.7116564417177914,
            "recall": 0.7435897435897436
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5394736842105263,
            "auc_prc": 0.8012609562121882,
            "auditor_fn_violation": 0.0014168652082882105,
            "auditor_fp_violation": 0.0023422699942344124,
            "ave_precision_score": 0.7986491614450172,
            "fpr": 0.4583333333333333,
            "logloss": 2.4580010296815096,
            "mae": 0.44598989227844404,
            "precision": 0.5365853658536586,
            "recall": 0.9958847736625515
        },
        "train": {
            "accuracy": 0.5236004390779363,
            "auc_prc": 0.817389225122424,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0022647699424887245,
            "ave_precision_score": 0.8163578068993876,
            "fpr": 0.47639956092206365,
            "logloss": 2.558300907034635,
            "mae": 0.4642811091943249,
            "precision": 0.5188470066518847,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.6834380006093099,
            "auditor_fn_violation": 0.018536567756840663,
            "auditor_fp_violation": 0.018666090107898853,
            "ave_precision_score": 0.6845232736459103,
            "fpr": 0.16228070175438597,
            "logloss": 2.4761416607515825,
            "mae": 0.30309022824067455,
            "precision": 0.7164750957854407,
            "recall": 0.7695473251028807
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7185838752502164,
            "auditor_fn_violation": 0.005988066086858627,
            "auditor_fp_violation": 0.01618046796985924,
            "ave_precision_score": 0.7166929340612871,
            "fpr": 0.1690450054884742,
            "logloss": 2.2087637959451905,
            "mae": 0.29039686055362707,
            "precision": 0.7088846880907372,
            "recall": 0.8012820512820513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8182996283903559,
            "auditor_fn_violation": 0.009065229947296225,
            "auditor_fp_violation": 0.024833209785025945,
            "ave_precision_score": 0.818569264433072,
            "fpr": 0.2236842105263158,
            "logloss": 1.0532080061683053,
            "mae": 0.2748896070126435,
            "precision": 0.6861538461538461,
            "recall": 0.9176954732510288
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.839399410851642,
            "auditor_fn_violation": 0.009140420501562106,
            "auditor_fp_violation": 0.027994935240960122,
            "ave_precision_score": 0.8396793645902256,
            "fpr": 0.2327113062568606,
            "logloss": 1.0586582549294543,
            "mae": 0.29517296852361186,
            "precision": 0.6671899529042387,
            "recall": 0.9081196581196581
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6217105263157895,
            "auc_prc": 0.6377992465968962,
            "auditor_fn_violation": 0.006199913363656058,
            "auditor_fp_violation": 0.022503809406144496,
            "ave_precision_score": 0.5653856293658357,
            "fpr": 0.2817982456140351,
            "logloss": 6.101076595310747,
            "mae": 0.3912507601544488,
            "precision": 0.6076335877862595,
            "recall": 0.8189300411522634
        },
        "train": {
            "accuracy": 0.6256860592755215,
            "auc_prc": 0.6354957573334636,
            "auditor_fn_violation": 0.0017638173510840923,
            "auditor_fp_violation": 0.011450220901794716,
            "ave_precision_score": 0.5628243710300775,
            "fpr": 0.2864983534577388,
            "logloss": 5.935922719519335,
            "mae": 0.391322769388203,
            "precision": 0.5978428351309707,
            "recall": 0.8290598290598291
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6776315789473685,
            "auc_prc": 0.6775710754991652,
            "auditor_fn_violation": 0.009597682477799439,
            "auditor_fp_violation": 0.0179737048019109,
            "ave_precision_score": 0.6787603711209835,
            "fpr": 0.2642543859649123,
            "logloss": 2.855358357054611,
            "mae": 0.32365595336169556,
            "precision": 0.642433234421365,
            "recall": 0.8909465020576132
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.6952997350056589,
            "auditor_fn_violation": 0.00941015320817736,
            "auditor_fp_violation": 0.027682724067269137,
            "ave_precision_score": 0.6945229285247383,
            "fpr": 0.2810098792535675,
            "logloss": 2.7741901313025537,
            "mae": 0.33811464618034853,
            "precision": 0.6224188790560472,
            "recall": 0.9017094017094017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8148882691541287,
            "auditor_fn_violation": 0.015910403580968888,
            "auditor_fp_violation": 0.02251667902149741,
            "ave_precision_score": 0.817025197004106,
            "fpr": 0.125,
            "logloss": 0.8113274072090957,
            "mae": 0.26998477721257746,
            "precision": 0.7634854771784232,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8417336247436782,
            "auditor_fn_violation": 0.012560162121084182,
            "auditor_fp_violation": 0.01625728183005306,
            "ave_precision_score": 0.8420049671151952,
            "fpr": 0.14270032930845225,
            "logloss": 0.7401458594675623,
            "mae": 0.26355084581102045,
            "precision": 0.7394789579158316,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8086084411120489,
            "auditor_fn_violation": 0.01322557938055014,
            "auditor_fp_violation": 0.02001482579688658,
            "ave_precision_score": 0.8068967690259351,
            "fpr": 0.14144736842105263,
            "logloss": 1.2116113751124868,
            "mae": 0.26603035727248486,
            "precision": 0.7485380116959064,
            "recall": 0.7901234567901234
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.832092889241087,
            "auditor_fn_violation": 0.009625939373469563,
            "auditor_fp_violation": 0.019463641026530518,
            "ave_precision_score": 0.8322361563815321,
            "fpr": 0.17014270032930845,
            "logloss": 1.0300517667213924,
            "mae": 0.2728599571323505,
            "precision": 0.7058823529411765,
            "recall": 0.7948717948717948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8105868226038088,
            "auditor_fn_violation": 0.01604126055880442,
            "auditor_fp_violation": 0.01952063256733384,
            "ave_precision_score": 0.8088595711707389,
            "fpr": 0.125,
            "logloss": 1.2339272623738766,
            "mae": 0.2640796283752484,
            "precision": 0.7678207739307535,
            "recall": 0.7757201646090535
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8386766715799173,
            "auditor_fn_violation": 0.009851107545948385,
            "auditor_fp_violation": 0.014029679884432312,
            "ave_precision_score": 0.8387629449574745,
            "fpr": 0.15367727771679474,
            "logloss": 1.0427510224666825,
            "mae": 0.266737907455905,
            "precision": 0.7244094488188977,
            "recall": 0.7863247863247863
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8120336128368573,
            "auditor_fn_violation": 0.016851220128510577,
            "auditor_fp_violation": 0.019731694259121985,
            "ave_precision_score": 0.8124252989588627,
            "fpr": 0.12280701754385964,
            "logloss": 0.9504113050797982,
            "mae": 0.2796341698751229,
            "precision": 0.7601713062098501,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8366939738656562,
            "auditor_fn_violation": 0.00740709467383452,
            "auditor_fp_violation": 0.017265773478404158,
            "ave_precision_score": 0.8369173177573885,
            "fpr": 0.13830954994511527,
            "logloss": 0.8814928744597076,
            "mae": 0.2693478484261465,
            "precision": 0.7402061855670103,
            "recall": 0.7670940170940171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6677631578947368,
            "auc_prc": 0.6180703563839616,
            "auditor_fn_violation": 0.017268608764710133,
            "auditor_fp_violation": 0.01091858166543119,
            "ave_precision_score": 0.5894928781755175,
            "fpr": 0.21162280701754385,
            "logloss": 4.026312876789041,
            "mae": 0.34661100279233115,
            "precision": 0.6608084358523726,
            "recall": 0.7736625514403292
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.6278626899777907,
            "auditor_fn_violation": 0.0059435015527221965,
            "auditor_fp_violation": 0.016264715429426643,
            "ave_precision_score": 0.6020367215894069,
            "fpr": 0.23380900109769484,
            "logloss": 3.4972364415657453,
            "mae": 0.338776106338934,
            "precision": 0.6420168067226891,
            "recall": 0.8162393162393162
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6282894736842105,
            "auc_prc": 0.6282211910725313,
            "auditor_fn_violation": 0.006136741029528555,
            "auditor_fp_violation": 0.014686805040770948,
            "ave_precision_score": 0.5700335639638981,
            "fpr": 0.3201754385964912,
            "logloss": 5.591295004882905,
            "mae": 0.39592417366530075,
            "precision": 0.600547195622435,
            "recall": 0.9032921810699589
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.6570298054702961,
            "auditor_fn_violation": 0.0014401381031457876,
            "auditor_fp_violation": 0.008518904882140287,
            "ave_precision_score": 0.5973539338553562,
            "fpr": 0.3205268935236004,
            "logloss": 4.882138128602913,
            "mae": 0.38478090368207246,
            "precision": 0.5977961432506887,
            "recall": 0.9273504273504274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8205619712765841,
            "auditor_fn_violation": 0.01746263807667317,
            "auditor_fp_violation": 0.017343093649617003,
            "ave_precision_score": 0.8211543171699913,
            "fpr": 0.11513157894736842,
            "logloss": 0.8308708279890807,
            "mae": 0.27241911629474663,
            "precision": 0.7741935483870968,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8419245903471021,
            "auditor_fn_violation": 0.010421064482535396,
            "auditor_fp_violation": 0.009993235424570033,
            "ave_precision_score": 0.8421542769515054,
            "fpr": 0.12843029637760703,
            "logloss": 0.7697725883225764,
            "mae": 0.26490648875151285,
            "precision": 0.7531645569620253,
            "recall": 0.7628205128205128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.6688561571170303,
            "auditor_fn_violation": 0.016190166774962097,
            "auditor_fp_violation": 0.016256898113829178,
            "ave_precision_score": 0.6699513665536684,
            "fpr": 0.12390350877192982,
            "logloss": 2.681814897292566,
            "mae": 0.3303741222757866,
            "precision": 0.7378190255220418,
            "recall": 0.654320987654321
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.6880157089691366,
            "auditor_fn_violation": 0.006311745334796928,
            "auditor_fp_violation": 0.012153934975828418,
            "ave_precision_score": 0.6861358001961348,
            "fpr": 0.12952799121844127,
            "logloss": 2.351889496902331,
            "mae": 0.30513810364251787,
            "precision": 0.738359201773836,
            "recall": 0.7115384615384616
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6535087719298246,
            "auc_prc": 0.7757450437481566,
            "auditor_fn_violation": 0.007675438596491228,
            "auditor_fp_violation": 0.00657894736842107,
            "ave_precision_score": 0.7676671583875533,
            "fpr": 0.30701754385964913,
            "logloss": 1.7342268942266026,
            "mae": 0.347951310202549,
            "precision": 0.6164383561643836,
            "recall": 0.9259259259259259
        },
        "train": {
            "accuracy": 0.6300768386388584,
            "auc_prc": 0.789778286850436,
            "auditor_fn_violation": 0.0063539643671367075,
            "auditor_fp_violation": 0.003897683938221837,
            "ave_precision_score": 0.78282411965344,
            "fpr": 0.3402854006586169,
            "logloss": 1.766786282276013,
            "mae": 0.36622439076320773,
            "precision": 0.5872170439414115,
            "recall": 0.9423076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 12498,
        "test": {
            "accuracy": 0.555921052631579,
            "auc_prc": 0.8126227821193125,
            "auditor_fn_violation": 0.002391524077683922,
            "auditor_fp_violation": 0.0017734329956346404,
            "ave_precision_score": 0.8100669095521923,
            "fpr": 0.43969298245614036,
            "logloss": 2.072151254901551,
            "mae": 0.4259241261346041,
            "precision": 0.5458663646659117,
            "recall": 0.9917695473251029
        },
        "train": {
            "accuracy": 0.5301866081229418,
            "auc_prc": 0.8308506728396886,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0004162815649213504,
            "ave_precision_score": 0.8307494246047212,
            "fpr": 0.4698133918770582,
            "logloss": 2.1415322059692574,
            "mae": 0.4478779501233055,
            "precision": 0.5223214285714286,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5866228070175439,
            "auc_prc": 0.782631584903925,
            "auditor_fn_violation": 0.01459280918345247,
            "auditor_fp_violation": 0.004195494605057245,
            "ave_precision_score": 0.7832713586270317,
            "fpr": 0.02412280701754386,
            "logloss": 2.0733049293762806,
            "mae": 0.4121938784794508,
            "precision": 0.8562091503267973,
            "recall": 0.26954732510288065
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7889731171359163,
            "auditor_fn_violation": 0.0077448469325527665,
            "auditor_fp_violation": 0.0014198174803567152,
            "ave_precision_score": 0.7894086134771808,
            "fpr": 0.03293084522502744,
            "logloss": 1.816236242947503,
            "mae": 0.3832817254087635,
            "precision": 0.8265895953757225,
            "recall": 0.3055555555555556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 12498,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8390401103933043,
            "auditor_fn_violation": 0.007397931557288283,
            "auditor_fp_violation": 0.020658306564533407,
            "ave_precision_score": 0.8375440226526047,
            "fpr": 0.25109649122807015,
            "logloss": 1.1325594492303592,
            "mae": 0.3050404168964218,
            "precision": 0.6612426035502958,
            "recall": 0.9197530864197531
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.8561921745479079,
            "auditor_fn_violation": 0.008769831217690715,
            "auditor_fp_violation": 0.02698644359260904,
            "ave_precision_score": 0.8563673822801784,
            "fpr": 0.27332601536772777,
            "logloss": 1.1343837705296296,
            "mae": 0.3260731319291813,
            "precision": 0.6316568047337278,
            "recall": 0.9123931623931624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8160484034305515,
            "auditor_fn_violation": 0.023103025052342796,
            "auditor_fp_violation": 0.01711658841940532,
            "ave_precision_score": 0.816500174425629,
            "fpr": 0.1206140350877193,
            "logloss": 0.9517819244793606,
            "mae": 0.27744790308446454,
            "precision": 0.7649572649572649,
            "recall": 0.7366255144032922
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8356293252977636,
            "auditor_fn_violation": 0.00624841678628726,
            "auditor_fp_violation": 0.020340805752614776,
            "ave_precision_score": 0.8358616740857955,
            "fpr": 0.1350164654226125,
            "logloss": 0.9283376365295013,
            "mae": 0.2692328247791779,
            "precision": 0.7421383647798742,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7899328586059841,
            "auditor_fn_violation": 0.012111038914157827,
            "auditor_fp_violation": 0.01731992834198172,
            "ave_precision_score": 0.7813836701725347,
            "fpr": 0.13048245614035087,
            "logloss": 3.0829073305100994,
            "mae": 0.28171978143662413,
            "precision": 0.7520833333333333,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8100256577847837,
            "auditor_fn_violation": 0.01268447371630687,
            "auditor_fp_violation": 0.021029652627901275,
            "ave_precision_score": 0.8060421865331894,
            "fpr": 0.14818880351262348,
            "logloss": 2.551381928129752,
            "mae": 0.27492201531285443,
            "precision": 0.7294589178356713,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8258213301591313,
            "auditor_fn_violation": 0.006976030611508195,
            "auditor_fp_violation": 0.02183716333086237,
            "ave_precision_score": 0.826189533949858,
            "fpr": 0.23026315789473684,
            "logloss": 1.0532051055096265,
            "mae": 0.2789764297394634,
            "precision": 0.6808510638297872,
            "recall": 0.9218106995884774
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8460151808987619,
            "auditor_fn_violation": 0.008289003349376569,
            "auditor_fp_violation": 0.024872823504050075,
            "ave_precision_score": 0.8462338660279995,
            "fpr": 0.24698133918770582,
            "logloss": 1.0991570438476188,
            "mae": 0.2987936410046353,
            "precision": 0.6549079754601227,
            "recall": 0.9123931623931624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5339912280701754,
            "auc_prc": 0.7637844880932531,
            "auditor_fn_violation": 0.0010513681322648185,
            "auditor_fp_violation": 0.0015057449962935542,
            "ave_precision_score": 0.5333349941903581,
            "fpr": 0.46381578947368424,
            "logloss": 15.924545465576367,
            "mae": 0.4665771750692409,
            "precision": 0.5336273428886439,
            "recall": 0.9958847736625515
        },
        "train": {
            "accuracy": 0.5148188803512623,
            "auc_prc": 0.7532755504367001,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0005550420865618082,
            "ave_precision_score": 0.5127841023988011,
            "fpr": 0.48518111964873767,
            "logloss": 16.65510427067274,
            "mae": 0.48491771757971297,
            "precision": 0.5142857142857142,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.7633069295132524,
            "auditor_fn_violation": 0.014750740018771209,
            "auditor_fp_violation": 0.010300840128490245,
            "ave_precision_score": 0.7496879499779621,
            "fpr": 0.14473684210526316,
            "logloss": 1.6405772280394066,
            "mae": 0.28739193957582715,
            "precision": 0.7532710280373832,
            "recall": 0.8292181069958847
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.755944174392468,
            "auditor_fn_violation": 0.008657247131451303,
            "auditor_fp_violation": 0.00646723145502797,
            "ave_precision_score": 0.7416042751313159,
            "fpr": 0.1525795828759605,
            "logloss": 1.5400485743194972,
            "mae": 0.2896818511496287,
            "precision": 0.7397003745318352,
            "recall": 0.844017094017094
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.7806344645598574,
            "auditor_fn_violation": 0.01688731860515487,
            "auditor_fp_violation": 0.017821843340746234,
            "ave_precision_score": 0.7781683946270991,
            "fpr": 0.13815789473684212,
            "logloss": 1.7179795928507353,
            "mae": 0.28506311660800066,
            "precision": 0.7485029940119761,
            "recall": 0.7716049382716049
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7899278024522086,
            "auditor_fn_violation": 0.011671216940152178,
            "auditor_fp_violation": 0.012748622925716047,
            "ave_precision_score": 0.7868378750486362,
            "fpr": 0.16355653128430298,
            "logloss": 1.7508458801191917,
            "mae": 0.28683326784955154,
            "precision": 0.7129094412331407,
            "recall": 0.7905982905982906
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8178310522927488,
            "auditor_fn_violation": 0.010107573460399977,
            "auditor_fp_violation": 0.013644366197183098,
            "ave_precision_score": 0.8183701544781106,
            "fpr": 0.11513157894736842,
            "logloss": 0.8379835801384785,
            "mae": 0.26928547831117294,
            "precision": 0.776595744680851,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8362550485808531,
            "auditor_fn_violation": 0.009513355287230152,
            "auditor_fp_violation": 0.0104070391230335,
            "ave_precision_score": 0.8364994935042738,
            "fpr": 0.141602634467618,
            "logloss": 0.8082065128240039,
            "mae": 0.266917265349151,
            "precision": 0.7383367139959433,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7866422754797451,
            "auditor_fn_violation": 0.007479153129737927,
            "auditor_fp_violation": 0.009868421052631578,
            "ave_precision_score": 0.7860489121743647,
            "fpr": 0.18859649122807018,
            "logloss": 1.073104326243341,
            "mae": 0.3078544378943007,
            "precision": 0.7049742710120068,
            "recall": 0.845679012345679
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8188412609696653,
            "auditor_fn_violation": 0.0026809085535759542,
            "auditor_fp_violation": 0.013496938595991314,
            "ave_precision_score": 0.8190804430196578,
            "fpr": 0.19758507135016465,
            "logloss": 0.917632746968368,
            "mae": 0.3016137513667514,
            "precision": 0.6984924623115578,
            "recall": 0.8910256410256411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 12498,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8201346728347387,
            "auditor_fn_violation": 0.018572666233484948,
            "auditor_fp_violation": 0.02289504571287374,
            "ave_precision_score": 0.8204454441958398,
            "fpr": 0.12609649122807018,
            "logloss": 1.1264227369074804,
            "mae": 0.2684068360838596,
            "precision": 0.764344262295082,
            "recall": 0.7674897119341564
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8354003694682568,
            "auditor_fn_violation": 0.008830814264403727,
            "auditor_fp_violation": 0.01588560186137328,
            "ave_precision_score": 0.8356370205147394,
            "fpr": 0.14709110867178923,
            "logloss": 1.049605929440705,
            "mae": 0.2709143930234349,
            "precision": 0.7292929292929293,
            "recall": 0.7713675213675214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 12498,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8098508605535734,
            "auditor_fn_violation": 0.017638618150314058,
            "auditor_fp_violation": 0.013719009966230133,
            "ave_precision_score": 0.8073066004596116,
            "fpr": 0.1206140350877193,
            "logloss": 1.6150580148848475,
            "mae": 0.28013564618690606,
            "precision": 0.7777777777777778,
            "recall": 0.7921810699588477
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.7730912078797837,
            "auditor_fn_violation": 0.007749537936146061,
            "auditor_fp_violation": 0.0035656498328679167,
            "ave_precision_score": 0.7651915475310086,
            "fpr": 0.145993413830955,
            "logloss": 1.8847371919821636,
            "mae": 0.29224974752644534,
            "precision": 0.7387033398821218,
            "recall": 0.8034188034188035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 12498,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.8191890005698763,
            "auditor_fn_violation": 0.007763428633311675,
            "auditor_fp_violation": 0.022400852483320976,
            "ave_precision_score": 0.8191301161748281,
            "fpr": 0.26206140350877194,
            "logloss": 1.2931272897720676,
            "mae": 0.30146526407330765,
            "precision": 0.6566091954022989,
            "recall": 0.9403292181069959
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.839529309247349,
            "auditor_fn_violation": 0.006262489797067185,
            "auditor_fp_violation": 0.026094411667777578,
            "ave_precision_score": 0.8398582541603227,
            "fpr": 0.29418221734357847,
            "logloss": 1.3338347887286737,
            "mae": 0.32848283629722796,
            "precision": 0.6203966005665722,
            "recall": 0.9358974358974359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8028956865583932,
            "auditor_fn_violation": 0.02418146704209083,
            "auditor_fp_violation": 0.01894922164566346,
            "ave_precision_score": 0.8019977319687916,
            "fpr": 0.12828947368421054,
            "logloss": 1.8549972920714735,
            "mae": 0.27980850900252513,
            "precision": 0.7587628865979381,
            "recall": 0.757201646090535
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7958834442801268,
            "auditor_fn_violation": 0.005713642376650057,
            "auditor_fp_violation": 0.010312880197634634,
            "ave_precision_score": 0.7945882515988906,
            "fpr": 0.1437980241492865,
            "logloss": 2.0224805763755924,
            "mae": 0.28774618606800006,
            "precision": 0.7298969072164948,
            "recall": 0.7564102564102564
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7042295557970508,
            "auditor_fn_violation": 0.007059508338748106,
            "auditor_fp_violation": 0.013976402273288861,
            "ave_precision_score": 0.7033171371361403,
            "fpr": 0.125,
            "logloss": 1.6673428920640168,
            "mae": 0.3187699181209865,
            "precision": 0.7579617834394905,
            "recall": 0.7345679012345679
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.7017407638024091,
            "auditor_fn_violation": 0.006698753131244902,
            "auditor_fp_violation": 0.013913220160912655,
            "ave_precision_score": 0.6990229608627448,
            "fpr": 0.12952799121844127,
            "logloss": 1.5648453751990778,
            "mae": 0.31368889132314354,
            "precision": 0.756198347107438,
            "recall": 0.782051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8567085400681977,
            "auditor_fn_violation": 0.023283517435564224,
            "auditor_fp_violation": 0.01750267687999341,
            "ave_precision_score": 0.8571160908892838,
            "fpr": 0.11951754385964912,
            "logloss": 0.569258909744003,
            "mae": 0.30830853941507846,
            "precision": 0.7733887733887734,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8485070326460895,
            "auditor_fn_violation": 0.014692223254243013,
            "auditor_fp_violation": 0.012463668283061554,
            "ave_precision_score": 0.8487594892721875,
            "fpr": 0.13391877058177826,
            "logloss": 0.6008487387278042,
            "mae": 0.30880819827994,
            "precision": 0.758893280632411,
            "recall": 0.8205128205128205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 12498,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.75039212115418,
            "auditor_fn_violation": 0.02215544004043029,
            "auditor_fp_violation": 0.008298327979573354,
            "ave_precision_score": 0.7448784541871626,
            "fpr": 0.14583333333333334,
            "logloss": 1.9022690840041303,
            "mae": 0.3237075754326808,
            "precision": 0.73767258382643,
            "recall": 0.7695473251028807
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7195947184375769,
            "auditor_fn_violation": 0.013378742248116565,
            "auditor_fp_violation": 0.011051284402078431,
            "ave_precision_score": 0.7115945611184182,
            "fpr": 0.1525795828759605,
            "logloss": 2.3516034401413046,
            "mae": 0.33610446703492924,
            "precision": 0.7169042769857433,
            "recall": 0.7521367521367521
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7679946631796536,
            "auditor_fn_violation": 0.005563677712800519,
            "auditor_fp_violation": 0.026580903549954703,
            "ave_precision_score": 0.7238655171268122,
            "fpr": 0.13706140350877194,
            "logloss": 4.176182557297867,
            "mae": 0.29392090624611444,
            "precision": 0.742798353909465,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7642425485955516,
            "auditor_fn_violation": 0.0012876804863632514,
            "auditor_fp_violation": 0.017203826816957528,
            "ave_precision_score": 0.7192370755752951,
            "fpr": 0.16794731064763996,
            "logloss": 4.001369674995861,
            "mae": 0.29822354092456543,
            "precision": 0.7034883720930233,
            "recall": 0.7756410256410257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8127484753687437,
            "auditor_fn_violation": 0.022112573099415212,
            "auditor_fp_violation": 0.018300593031875464,
            "ave_precision_score": 0.8132891717673276,
            "fpr": 0.11842105263157894,
            "logloss": 0.9690313149733024,
            "mae": 0.279662069152971,
            "precision": 0.7647058823529411,
            "recall": 0.7222222222222222
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8344859862522064,
            "auditor_fn_violation": 0.005812153452109543,
            "auditor_fp_violation": 0.020259036159505223,
            "ave_precision_score": 0.8347242235745017,
            "fpr": 0.13391877058177826,
            "logloss": 0.937789445626785,
            "mae": 0.269196728372719,
            "precision": 0.7431578947368421,
            "recall": 0.7542735042735043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8084454176591254,
            "auditor_fn_violation": 0.018572666233484948,
            "auditor_fp_violation": 0.022285025945144556,
            "ave_precision_score": 0.8067980533926405,
            "fpr": 0.12828947368421054,
            "logloss": 1.2521800855948708,
            "mae": 0.2681752446067098,
            "precision": 0.7612244897959184,
            "recall": 0.7674897119341564
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8297955678186812,
            "auditor_fn_violation": 0.007702627900212972,
            "auditor_fp_violation": 0.010939780411474507,
            "ave_precision_score": 0.8299360759921895,
            "fpr": 0.14709110867178923,
            "logloss": 1.1043767568452394,
            "mae": 0.2723733626188455,
            "precision": 0.7292929292929293,
            "recall": 0.7713675213675214
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.6757056604547526,
            "auditor_fn_violation": 0.010518193632228728,
            "auditor_fp_violation": 0.023898875710402768,
            "ave_precision_score": 0.6738920732982021,
            "fpr": 0.15460526315789475,
            "logloss": 2.0762744195668117,
            "mae": 0.30814020861019875,
            "precision": 0.7235294117647059,
            "recall": 0.7592592592592593
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.6858956577172557,
            "auditor_fn_violation": 0.008591573081144985,
            "auditor_fp_violation": 0.015449497364789028,
            "ave_precision_score": 0.6831640354486194,
            "fpr": 0.1800219538968167,
            "logloss": 1.8952633300110302,
            "mae": 0.3036136869992564,
            "precision": 0.6934579439252336,
            "recall": 0.7927350427350427
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8103306388787572,
            "auditor_fn_violation": 0.01660981156595192,
            "auditor_fp_violation": 0.016717630343464296,
            "ave_precision_score": 0.8086575300143192,
            "fpr": 0.12171052631578948,
            "logloss": 1.2149634839776946,
            "mae": 0.2668309031209884,
            "precision": 0.7706611570247934,
            "recall": 0.7674897119341564
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.837368573885946,
            "auditor_fn_violation": 0.006830101231857542,
            "auditor_fp_violation": 0.01258508373949695,
            "ave_precision_score": 0.8365809273667534,
            "fpr": 0.1437980241492865,
            "logloss": 1.018403691167031,
            "mae": 0.2657056224667485,
            "precision": 0.7353535353535353,
            "recall": 0.7777777777777778
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.822337112708442,
            "auditor_fn_violation": 0.007318966139628909,
            "auditor_fp_violation": 0.023497343711391158,
            "ave_precision_score": 0.8224812411557987,
            "fpr": 0.26206140350877194,
            "logloss": 1.3994357660605,
            "mae": 0.30064590584433193,
            "precision": 0.6580829756795422,
            "recall": 0.9465020576131687
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8410978834804519,
            "auditor_fn_violation": 0.006027939617401748,
            "auditor_fp_violation": 0.027543963545628696,
            "ave_precision_score": 0.8413167946583398,
            "fpr": 0.29198682766191,
            "logloss": 1.4872726780537777,
            "mae": 0.32719065454688,
            "precision": 0.6226950354609929,
            "recall": 0.938034188034188
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8211081574058168,
            "auditor_fn_violation": 0.011181503140567471,
            "auditor_fp_violation": 0.02368266617247344,
            "ave_precision_score": 0.8219610208970769,
            "fpr": 0.18092105263157895,
            "logloss": 0.9018038772128671,
            "mae": 0.266238607265418,
            "precision": 0.7208121827411168,
            "recall": 0.8765432098765432
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.8418160430459688,
            "auditor_fn_violation": 0.01030144389090602,
            "auditor_fp_violation": 0.02285088447443213,
            "ave_precision_score": 0.8420441215115091,
            "fpr": 0.21075740944017562,
            "logloss": 0.9197152404177319,
            "mae": 0.2792727805764684,
            "precision": 0.6831683168316832,
            "recall": 0.8846153846153846
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8258557923419397,
            "auditor_fn_violation": 0.016882806295574322,
            "auditor_fp_violation": 0.022120294868626968,
            "ave_precision_score": 0.8263354507040033,
            "fpr": 0.12719298245614036,
            "logloss": 0.6989049104166921,
            "mae": 0.2663347157619579,
            "precision": 0.7684630738522954,
            "recall": 0.7921810699588477
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8460026672399295,
            "auditor_fn_violation": 0.011678253445542141,
            "auditor_fp_violation": 0.008395011559247037,
            "ave_precision_score": 0.8462188287467522,
            "fpr": 0.15148188803512624,
            "logloss": 0.6727854425231898,
            "mae": 0.264565274952035,
            "precision": 0.7320388349514563,
            "recall": 0.8055555555555556
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8096815400494122,
            "auditor_fn_violation": 0.017451357302721824,
            "auditor_fp_violation": 0.020601680256980483,
            "ave_precision_score": 0.8105273069241824,
            "fpr": 0.12280701754385964,
            "logloss": 1.5429828558358798,
            "mae": 0.2744946398959586,
            "precision": 0.7651991614255765,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8369979072748462,
            "auditor_fn_violation": 0.011661834932965562,
            "auditor_fp_violation": 0.013615876185968837,
            "ave_precision_score": 0.8370959030638991,
            "fpr": 0.141602634467618,
            "logloss": 1.5182480407442709,
            "mae": 0.2687309866004736,
            "precision": 0.7388663967611336,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8141532868740262,
            "auditor_fn_violation": 0.011255956248646306,
            "auditor_fp_violation": 0.02327341240425006,
            "ave_precision_score": 0.8146638564290946,
            "fpr": 0.13815789473684212,
            "logloss": 1.0093334634354052,
            "mae": 0.27163277959176535,
            "precision": 0.7474949899799599,
            "recall": 0.7674897119341564
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8270155263727647,
            "auditor_fn_violation": 0.0055729122688508055,
            "auditor_fp_violation": 0.018948244803294576,
            "ave_precision_score": 0.8272681026550186,
            "fpr": 0.15916575192096596,
            "logloss": 1.051959654627046,
            "mae": 0.2771100108263432,
            "precision": 0.7128712871287128,
            "recall": 0.7692307692307693
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5899122807017544,
            "auc_prc": 0.8501131391181073,
            "auditor_fn_violation": 0.0020373077756118694,
            "auditor_fp_violation": 0.007665142904208874,
            "ave_precision_score": 0.8505320019890076,
            "fpr": 0.3958333333333333,
            "logloss": 1.1639661059251698,
            "mae": 0.38871795970286865,
            "precision": 0.5671462829736211,
            "recall": 0.9732510288065843
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.8578089804629936,
            "auditor_fn_violation": 0.002964714270971132,
            "auditor_fp_violation": 0.01304348903420201,
            "ave_precision_score": 0.8580036968629097,
            "fpr": 0.4149286498353458,
            "logloss": 1.2253394688147923,
            "mae": 0.40479843168131985,
            "precision": 0.5478468899521531,
            "recall": 0.9786324786324786
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8116419263252064,
            "auditor_fn_violation": 0.01706104252400549,
            "auditor_fp_violation": 0.01696987480438185,
            "ave_precision_score": 0.8120240582217902,
            "fpr": 0.11732456140350878,
            "logloss": 1.0069126635461312,
            "mae": 0.2773080857076359,
            "precision": 0.7683982683982684,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8308400911246445,
            "auditor_fn_violation": 0.007646335857093272,
            "auditor_fp_violation": 0.013628265518258159,
            "ave_precision_score": 0.8310896083061853,
            "fpr": 0.1350164654226125,
            "logloss": 0.9785529812074748,
            "mae": 0.27026862264571877,
            "precision": 0.7432150313152401,
            "recall": 0.7606837606837606
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8247294798072113,
            "auditor_fn_violation": 0.018556873149953072,
            "auditor_fp_violation": 0.019664772259286718,
            "ave_precision_score": 0.825340496800662,
            "fpr": 0.1206140350877193,
            "logloss": 0.7626796395463032,
            "mae": 0.2707835940069672,
            "precision": 0.7684210526315789,
            "recall": 0.7510288065843621
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8474662015290391,
            "auditor_fn_violation": 0.013700075994258215,
            "auditor_fp_violation": 0.018598865632735596,
            "ave_precision_score": 0.8476778204791213,
            "fpr": 0.14050493962678376,
            "logloss": 0.7183291787998778,
            "mae": 0.2637124748671224,
            "precision": 0.7424547283702213,
            "recall": 0.7884615384615384
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6386873963529733,
            "auditor_fn_violation": 0.005135008302649631,
            "auditor_fp_violation": 0.023335186557944154,
            "ave_precision_score": 0.5665769373460425,
            "fpr": 0.2850877192982456,
            "logloss": 6.06605469816931,
            "mae": 0.39044992729129,
            "precision": 0.604261796042618,
            "recall": 0.8168724279835391
        },
        "train": {
            "accuracy": 0.6278814489571899,
            "auc_prc": 0.6358596745121703,
            "auditor_fn_violation": 0.0026152345032696357,
            "auditor_fp_violation": 0.01592524772469912,
            "ave_precision_score": 0.5631884172983069,
            "fpr": 0.2854006586169045,
            "logloss": 5.924031173431902,
            "mae": 0.3908240633921592,
            "precision": 0.5993836671802774,
            "recall": 0.8311965811965812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.8501276354865626,
            "auditor_fn_violation": 0.022426178615262433,
            "auditor_fp_violation": 0.008354954287126272,
            "ave_precision_score": 0.850277412697983,
            "fpr": 0.09758771929824561,
            "logloss": 0.7512117625638577,
            "mae": 0.27424736091577295,
            "precision": 0.8090128755364807,
            "recall": 0.7757201646090535
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8699988755636718,
            "auditor_fn_violation": 0.009344479157871033,
            "auditor_fp_violation": 0.0073840420444380595,
            "ave_precision_score": 0.8702037095502937,
            "fpr": 0.09879253567508232,
            "logloss": 0.659156092871951,
            "mae": 0.27210914013620097,
            "precision": 0.8051948051948052,
            "recall": 0.7948717948717948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7146306869113502,
            "auditor_fn_violation": 0.010951375351960151,
            "auditor_fp_violation": 0.005842805370233103,
            "ave_precision_score": 0.6402481262456216,
            "fpr": 0.19846491228070176,
            "logloss": 5.535413908269124,
            "mae": 0.3399105094806034,
            "precision": 0.690068493150685,
            "recall": 0.8292181069958847
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.6868176535934973,
            "auditor_fn_violation": 0.005488474204171241,
            "auditor_fp_violation": 0.0024332648616235465,
            "ave_precision_score": 0.609381071532308,
            "fpr": 0.21844127332601537,
            "logloss": 5.901904873167852,
            "mae": 0.3616406103905485,
            "precision": 0.6621392190152802,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.6915846997864319,
            "auditor_fn_violation": 0.012668309147353988,
            "auditor_fp_violation": 0.00900358290091426,
            "ave_precision_score": 0.6897420943104842,
            "fpr": 0.10526315789473684,
            "logloss": 1.7866949107593089,
            "mae": 0.35372268083901554,
            "precision": 0.7686746987951807,
            "recall": 0.6563786008230452
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6841855851571486,
            "auditor_fn_violation": 0.01556474992259845,
            "auditor_fp_violation": 0.007277493786749855,
            "ave_precision_score": 0.6790139187373958,
            "fpr": 0.10976948408342481,
            "logloss": 1.7393933299237376,
            "mae": 0.34905906206121595,
            "precision": 0.7555012224938875,
            "recall": 0.6602564102564102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8157392630423841,
            "auditor_fn_violation": 0.021550790556638517,
            "auditor_fp_violation": 0.018213079647475497,
            "ave_precision_score": 0.8162112116872067,
            "fpr": 0.1206140350877193,
            "logloss": 0.9607147206121666,
            "mae": 0.2776216960504123,
            "precision": 0.7639484978540773,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8353005975590896,
            "auditor_fn_violation": 0.005812153452109543,
            "auditor_fp_violation": 0.019243110911780534,
            "ave_precision_score": 0.8355337279965123,
            "fpr": 0.1350164654226125,
            "logloss": 0.9332855153819667,
            "mae": 0.26896837105118077,
            "precision": 0.7415966386554622,
            "recall": 0.7542735042735043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.6753145721995801,
            "auditor_fn_violation": 0.011844812648906218,
            "auditor_fp_violation": 0.01599950580677045,
            "ave_precision_score": 0.6729782260609218,
            "fpr": 0.13157894736842105,
            "logloss": 2.617600423221442,
            "mae": 0.32302473324784586,
            "precision": 0.7345132743362832,
            "recall": 0.6831275720164609
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6965971855820169,
            "auditor_fn_violation": 0.004425961890286811,
            "auditor_fp_violation": 0.009311822148657124,
            "ave_precision_score": 0.6945500209383184,
            "fpr": 0.1394072447859495,
            "logloss": 1.8865971330356295,
            "mae": 0.3029919840444495,
            "precision": 0.7309322033898306,
            "recall": 0.7371794871794872
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 12498,
        "test": {
            "accuracy": 0.643640350877193,
            "auc_prc": 0.6618589797781153,
            "auditor_fn_violation": 0.017106165619810848,
            "auditor_fp_violation": 0.011157956510995807,
            "ave_precision_score": 0.662958432819542,
            "fpr": 0.10855263157894737,
            "logloss": 3.0273287689637773,
            "mae": 0.3585711646809335,
            "precision": 0.724233983286908,
            "recall": 0.5349794238683128
        },
        "train": {
            "accuracy": 0.6838638858397366,
            "auc_prc": 0.6939512634643612,
            "auditor_fn_violation": 0.0025096869224201825,
            "auditor_fp_violation": 0.00846439182006725,
            "ave_precision_score": 0.6920931107665087,
            "fpr": 0.10318331503841932,
            "logloss": 2.5429496810400054,
            "mae": 0.32202973940818985,
            "precision": 0.7445652173913043,
            "recall": 0.5854700854700855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7690078699839549,
            "auditor_fn_violation": 0.004185167135946863,
            "auditor_fp_violation": 0.026068692858907835,
            "ave_precision_score": 0.7248779684213977,
            "fpr": 0.13486842105263158,
            "logloss": 4.145337687524141,
            "mae": 0.2927971417662026,
            "precision": 0.7458677685950413,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7654684239089422,
            "auditor_fn_violation": 0.004639402553782357,
            "auditor_fp_violation": 0.013534106592859281,
            "ave_precision_score": 0.7204597988931856,
            "fpr": 0.16136114160263446,
            "logloss": 3.958489813971846,
            "mae": 0.2968580055154657,
            "precision": 0.7111984282907662,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8414349568534943,
            "auditor_fn_violation": 0.02348431521189806,
            "auditor_fp_violation": 0.017734329956346266,
            "ave_precision_score": 0.839770323942192,
            "fpr": 0.15021929824561403,
            "logloss": 0.8846935368773396,
            "mae": 0.2826586518285503,
            "precision": 0.7509090909090909,
            "recall": 0.8497942386831275
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8600135526581694,
            "auditor_fn_violation": 0.013268503663673806,
            "auditor_fp_violation": 0.011185089190803152,
            "ave_precision_score": 0.8601411229522122,
            "fpr": 0.15148188803512624,
            "logloss": 0.7528977325587343,
            "mae": 0.28786522576284584,
            "precision": 0.7439703153988868,
            "recall": 0.8568376068376068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6195175438596491,
            "auc_prc": 0.8430027012492944,
            "auditor_fn_violation": 0.004110714027868024,
            "auditor_fp_violation": 0.020354583642204122,
            "ave_precision_score": 0.8434188629397916,
            "fpr": 0.3684210526315789,
            "logloss": 0.9390024664581583,
            "mae": 0.3697348875616546,
            "precision": 0.5856966707768188,
            "recall": 0.977366255144033
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.8568187066852979,
            "auditor_fn_violation": 0.005404036139491683,
            "auditor_fp_violation": 0.013335877276230102,
            "ave_precision_score": 0.8570706445360494,
            "fpr": 0.38638858397365533,
            "logloss": 0.9499517992068314,
            "mae": 0.3816083225346979,
            "precision": 0.5643564356435643,
            "recall": 0.9743589743589743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8129639651219577,
            "auditor_fn_violation": 0.015240325608259338,
            "auditor_fp_violation": 0.017999444032616753,
            "ave_precision_score": 0.8136829189803625,
            "fpr": 0.12171052631578948,
            "logloss": 1.018119122295875,
            "mae": 0.27617023148693415,
            "precision": 0.7618025751072961,
            "recall": 0.7304526748971193
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.833373180717344,
            "auditor_fn_violation": 0.007099833938472797,
            "auditor_fp_violation": 0.013335877276230078,
            "ave_precision_score": 0.8336056711331922,
            "fpr": 0.14489571899012074,
            "logloss": 1.0264059655369746,
            "mae": 0.2708760367494216,
            "precision": 0.728952772073922,
            "recall": 0.7585470085470085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.819694177868536,
            "auditor_fn_violation": 0.017126471012923253,
            "auditor_fp_violation": 0.019222057491145708,
            "ave_precision_score": 0.8199760796208933,
            "fpr": 0.12280701754385964,
            "logloss": 1.1181966546484174,
            "mae": 0.2694758441093767,
            "precision": 0.7661795407098121,
            "recall": 0.7551440329218106
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8354796019621586,
            "auditor_fn_violation": 0.007662754369669851,
            "auditor_fp_violation": 0.009401025341140266,
            "ave_precision_score": 0.8357140643160744,
            "fpr": 0.13830954994511527,
            "logloss": 1.0289261176830715,
            "mae": 0.26954933214742305,
            "precision": 0.7402061855670103,
            "recall": 0.7670940170940171
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.592084293819314,
            "auditor_fn_violation": 0.017067810988376293,
            "auditor_fp_violation": 0.004537826373445351,
            "ave_precision_score": 0.5823353156949559,
            "fpr": 0.2050438596491228,
            "logloss": 3.7569218264927344,
            "mae": 0.3462110130034506,
            "precision": 0.6660714285714285,
            "recall": 0.7674897119341564
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.6000721873823527,
            "auditor_fn_violation": 0.00360503626145778,
            "auditor_fp_violation": 0.011227212920586854,
            "ave_precision_score": 0.590841222383388,
            "fpr": 0.22283205268935236,
            "logloss": 3.473560438879188,
            "mae": 0.33956808269035543,
            "precision": 0.6426056338028169,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.81574376186175,
            "auditor_fn_violation": 0.010075987293336223,
            "auditor_fp_violation": 0.024395642863026114,
            "ave_precision_score": 0.8157108752582917,
            "fpr": 0.20285087719298245,
            "logloss": 1.0032299179831423,
            "mae": 0.2693946517347139,
            "precision": 0.7020933977455717,
            "recall": 0.897119341563786
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.835043907896348,
            "auditor_fn_violation": 0.010958184393969244,
            "auditor_fp_violation": 0.026676710285375885,
            "ave_precision_score": 0.835355287312415,
            "fpr": 0.2261251372118551,
            "logloss": 1.0045615949807427,
            "mae": 0.28878173428572035,
            "precision": 0.6719745222929936,
            "recall": 0.9017094017094017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.809954007442603,
            "auditor_fn_violation": 0.012424644430005054,
            "auditor_fp_violation": 0.01881795156906351,
            "ave_precision_score": 0.8103888537839361,
            "fpr": 0.12171052631578948,
            "logloss": 0.9904939386076393,
            "mae": 0.27501926966288,
            "precision": 0.7648305084745762,
            "recall": 0.742798353909465
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8213626598119411,
            "auditor_fn_violation": 0.0016043232289115954,
            "auditor_fp_violation": 0.010154296744331263,
            "ave_precision_score": 0.8216350903959273,
            "fpr": 0.145993413830955,
            "logloss": 0.9886136737686019,
            "mae": 0.27883781887508524,
            "precision": 0.7291242362525459,
            "recall": 0.7649572649572649
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6173245614035088,
            "auc_prc": 0.6405683450770795,
            "auditor_fn_violation": 0.016203703703703706,
            "auditor_fp_violation": 0.01796598303269913,
            "ave_precision_score": 0.5685935054617863,
            "fpr": 0.31359649122807015,
            "logloss": 6.387733782801818,
            "mae": 0.4002540708682899,
            "precision": 0.5966149506346967,
            "recall": 0.8703703703703703
        },
        "train": {
            "accuracy": 0.6136114160263447,
            "auc_prc": 0.6721013873859715,
            "auditor_fn_violation": 0.008310112865546457,
            "auditor_fp_violation": 0.008422268090283546,
            "ave_precision_score": 0.5971461967098443,
            "fpr": 0.33040614709110866,
            "logloss": 5.674198381022828,
            "mae": 0.3906783242181906,
            "precision": 0.5807799442896936,
            "recall": 0.8910256410256411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8090883087593839,
            "auditor_fn_violation": 0.015039527831925494,
            "auditor_fp_violation": 0.01726072811135821,
            "ave_precision_score": 0.8065714677171574,
            "fpr": 0.12280701754385964,
            "logloss": 1.2682104948400155,
            "mae": 0.2673135978759376,
            "precision": 0.768595041322314,
            "recall": 0.7654320987654321
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8377650555745315,
            "auditor_fn_violation": 0.009466445251297063,
            "auditor_fp_violation": 0.016881704177435064,
            "ave_precision_score": 0.8369980899878837,
            "fpr": 0.14709110867178923,
            "logloss": 1.0194129441876532,
            "mae": 0.26537326381817555,
            "precision": 0.7314629258517034,
            "recall": 0.7799145299145299
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6896929824561403,
            "auc_prc": 0.685742465552076,
            "auditor_fn_violation": 0.007167803768680965,
            "auditor_fp_violation": 0.009806646898937498,
            "ave_precision_score": 0.6638960639342123,
            "fpr": 0.24342105263157895,
            "logloss": 2.421045117033194,
            "mae": 0.32656454256807044,
            "precision": 0.6568778979907264,
            "recall": 0.8744855967078189
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.6800445516453184,
            "auditor_fn_violation": 0.005981029581468662,
            "auditor_fp_violation": 0.01702294256553338,
            "ave_precision_score": 0.6562147597851073,
            "fpr": 0.2645444566410538,
            "logloss": 2.5819691363836688,
            "mae": 0.3317943408072623,
            "precision": 0.6303680981595092,
            "recall": 0.8782051282051282
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7148118285169236,
            "auditor_fn_violation": 0.015310266406757636,
            "auditor_fp_violation": 0.00850166790214974,
            "ave_precision_score": 0.6404303608614638,
            "fpr": 0.20065789473684212,
            "logloss": 5.525857428960794,
            "mae": 0.33336430299316167,
            "precision": 0.6893039049235993,
            "recall": 0.8353909465020576
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.6877220652077294,
            "auditor_fn_violation": 0.005699569365870137,
            "auditor_fp_violation": 0.008955009378724546,
            "ave_precision_score": 0.6102830283574731,
            "fpr": 0.21624588364434688,
            "logloss": 5.887985057693011,
            "mae": 0.3545903419382337,
            "precision": 0.6620926243567753,
            "recall": 0.8247863247863247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 12498,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8180601553749896,
            "auditor_fn_violation": 0.012047866580030325,
            "auditor_fp_violation": 0.021306935178321395,
            "ave_precision_score": 0.8184320530039944,
            "fpr": 0.12938596491228072,
            "logloss": 0.827707315408051,
            "mae": 0.26586269716502775,
            "precision": 0.764,
            "recall": 0.7860082304526749
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8259681432119463,
            "auditor_fn_violation": 0.008528244532635313,
            "auditor_fp_violation": 0.019062226660356372,
            "ave_precision_score": 0.8262608173233095,
            "fpr": 0.15367727771679474,
            "logloss": 0.8108777752240716,
            "mae": 0.27054410142652496,
            "precision": 0.7265625,
            "recall": 0.7948717948717948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8150405029846507,
            "auditor_fn_violation": 0.021550790556638517,
            "auditor_fp_violation": 0.020478131949592294,
            "ave_precision_score": 0.8154242340553796,
            "fpr": 0.12171052631578948,
            "logloss": 0.9495687600790099,
            "mae": 0.2783194379043462,
            "precision": 0.7623126338329764,
            "recall": 0.7325102880658436
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8357059282243543,
            "auditor_fn_violation": 0.005812153452109543,
            "auditor_fp_violation": 0.020259036159505223,
            "ave_precision_score": 0.8359377718309253,
            "fpr": 0.13391877058177826,
            "logloss": 0.9242647737058605,
            "mae": 0.2694290126797751,
            "precision": 0.7431578947368421,
            "recall": 0.7542735042735043
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 12498,
        "test": {
            "accuracy": 0.618421052631579,
            "auc_prc": 0.6381064127339324,
            "auditor_fn_violation": 0.014087430510432462,
            "auditor_fp_violation": 0.019160283337451622,
            "ave_precision_score": 0.5610920134879075,
            "fpr": 0.32456140350877194,
            "logloss": 6.787683996963424,
            "mae": 0.4058608293918458,
            "precision": 0.5945205479452055,
            "recall": 0.8930041152263375
        },
        "train": {
            "accuracy": 0.605927552140505,
            "auc_prc": 0.6703879990129342,
            "auditor_fn_violation": 0.006135832700047849,
            "auditor_fp_violation": 0.010486330849685196,
            "ave_precision_score": 0.5900012676036489,
            "fpr": 0.3413830954994512,
            "logloss": 6.059003955504654,
            "mae": 0.39844683822545657,
            "precision": 0.5745554035567716,
            "recall": 0.8974358974358975
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6359649122807017,
            "auc_prc": 0.6387311050787752,
            "auditor_fn_violation": 0.006964749837556857,
            "auditor_fp_violation": 0.006954740136726813,
            "ave_precision_score": 0.5660293063749726,
            "fpr": 0.31469298245614036,
            "logloss": 6.1478878702486925,
            "mae": 0.3834027473435626,
            "precision": 0.6057692307692307,
            "recall": 0.9074074074074074
        },
        "train": {
            "accuracy": 0.6190998902305159,
            "auc_prc": 0.6362133779141059,
            "auditor_fn_violation": 0.007332038616341582,
            "auditor_fp_violation": 0.013142603692516606,
            "ave_precision_score": 0.5629204249507784,
            "fpr": 0.33479692645444564,
            "logloss": 6.009955070116741,
            "mae": 0.3898277103170187,
            "precision": 0.5827633378932968,
            "recall": 0.9102564102564102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6842105263157895,
            "auc_prc": 0.6889461222909908,
            "auditor_fn_violation": 0.006957981373186051,
            "auditor_fp_violation": 0.009358784284655308,
            "ave_precision_score": 0.6905325893211396,
            "fpr": 0.2324561403508772,
            "logloss": 1.1131982194228693,
            "mae": 0.3563169792537427,
            "precision": 0.6591639871382636,
            "recall": 0.8436213991769548
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.6809096701516715,
            "auditor_fn_violation": 0.005078011389756726,
            "auditor_fp_violation": 0.011142965461019439,
            "ave_precision_score": 0.6823304642425739,
            "fpr": 0.24039517014270034,
            "logloss": 1.395047350856339,
            "mae": 0.35228040653096127,
            "precision": 0.6512738853503185,
            "recall": 0.8739316239316239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8144549679649442,
            "auditor_fn_violation": 0.01816655837123675,
            "auditor_fp_violation": 0.02234422617576806,
            "ave_precision_score": 0.8165631327088649,
            "fpr": 0.12390350877192982,
            "logloss": 0.8084880823894015,
            "mae": 0.2711345546214142,
            "precision": 0.7631027253668763,
            "recall": 0.7489711934156379
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8410499759746652,
            "auditor_fn_violation": 0.013878334130803947,
            "auditor_fp_violation": 0.015967371454482838,
            "ave_precision_score": 0.841322331212801,
            "fpr": 0.145993413830955,
            "logloss": 0.7361952656087493,
            "mae": 0.2642317473567777,
            "precision": 0.734,
            "recall": 0.7841880341880342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.8188669812260865,
            "auditor_fn_violation": 0.0073708576998050696,
            "auditor_fp_violation": 0.024642739477802503,
            "ave_precision_score": 0.8188600103692294,
            "fpr": 0.2708333333333333,
            "logloss": 1.3459652790545407,
            "mae": 0.30821160037522183,
            "precision": 0.6501416430594901,
            "recall": 0.9444444444444444
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8342737218641916,
            "auditor_fn_violation": 0.004934935780160808,
            "auditor_fp_violation": 0.02955103537649942,
            "ave_precision_score": 0.8346308061209539,
            "fpr": 0.305159165751921,
            "logloss": 1.4129048036522565,
            "mae": 0.33565192939350164,
            "precision": 0.6128133704735376,
            "recall": 0.9401709401709402
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.8079465484277286,
            "auditor_fn_violation": 0.01625785141867013,
            "auditor_fp_violation": 0.01281298904538341,
            "ave_precision_score": 0.8050557981344182,
            "fpr": 0.11293859649122807,
            "logloss": 1.8121052770146353,
            "mae": 0.2788699401868945,
            "precision": 0.7889344262295082,
            "recall": 0.7921810699588477
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.7690583371166715,
            "auditor_fn_violation": 0.006614315066565342,
            "auditor_fp_violation": 0.006278913604230222,
            "ave_precision_score": 0.7574297591686039,
            "fpr": 0.14818880351262348,
            "logloss": 2.3236106454684062,
            "mae": 0.29307193200620923,
            "precision": 0.734251968503937,
            "recall": 0.7970085470085471
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6271929824561403,
            "auc_prc": 0.6379216815046974,
            "auditor_fn_violation": 0.007066276803118909,
            "auditor_fp_violation": 0.020601680256980493,
            "ave_precision_score": 0.5713071199013262,
            "fpr": 0.2631578947368421,
            "logloss": 5.690633782857463,
            "mae": 0.3884846168384035,
            "precision": 0.6166134185303515,
            "recall": 0.7942386831275721
        },
        "train": {
            "accuracy": 0.6289791437980241,
            "auc_prc": 0.6295004194410723,
            "auditor_fn_violation": 0.0027114000769324622,
            "auditor_fp_violation": 0.013095524229817168,
            "ave_precision_score": 0.5630563690155438,
            "fpr": 0.270032930845225,
            "logloss": 5.571955383377978,
            "mae": 0.3859689874609378,
            "precision": 0.6045016077170418,
            "recall": 0.8034188034188035
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6578947368421053,
            "auc_prc": 0.7040571968928017,
            "auditor_fn_violation": 0.01734080571799871,
            "auditor_fp_violation": 0.010702372127501854,
            "ave_precision_score": 0.6753442675057206,
            "fpr": 0.20394736842105263,
            "logloss": 2.9984992833987714,
            "mae": 0.3476466164148871,
            "precision": 0.6593406593406593,
            "recall": 0.7407407407407407
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7097071463605371,
            "auditor_fn_violation": 0.0019092384624766643,
            "auditor_fp_violation": 0.001764240917999966,
            "ave_precision_score": 0.6793555443959232,
            "fpr": 0.21844127332601537,
            "logloss": 2.979638326921806,
            "mae": 0.33938487219652436,
            "precision": 0.6452762923351159,
            "recall": 0.7735042735042735
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6513157894736842,
            "auc_prc": 0.6721480756769588,
            "auditor_fn_violation": 0.015562955743267637,
            "auditor_fp_violation": 0.007309941520467834,
            "ave_precision_score": 0.6528486363026869,
            "fpr": 0.15570175438596492,
            "logloss": 3.0288098048722887,
            "mae": 0.3540040618681504,
            "precision": 0.6858407079646017,
            "recall": 0.6378600823045267
        },
        "train": {
            "accuracy": 0.6882546652030735,
            "auc_prc": 0.6833077641390191,
            "auditor_fn_violation": 0.000591066452756919,
            "auditor_fp_violation": 0.006003870427407183,
            "ave_precision_score": 0.6623423804167962,
            "fpr": 0.15367727771679474,
            "logloss": 2.9539527556795115,
            "mae": 0.3244216918705315,
            "precision": 0.6982758620689655,
            "recall": 0.6923076923076923
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8132780351730556,
            "auditor_fn_violation": 0.02578784925276154,
            "auditor_fp_violation": 0.01788104357136974,
            "ave_precision_score": 0.8147735265751426,
            "fpr": 0.08662280701754387,
            "logloss": 0.7518012076387431,
            "mae": 0.3205811250081438,
            "precision": 0.8068459657701712,
            "recall": 0.6790123456790124
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7651790074463681,
            "auditor_fn_violation": 0.01275952977379981,
            "auditor_fp_violation": 0.009351468011982961,
            "ave_precision_score": 0.7664305996425016,
            "fpr": 0.10098792535675083,
            "logloss": 1.1025207305633309,
            "mae": 0.33654535102529765,
            "precision": 0.7825059101654847,
            "recall": 0.7072649572649573
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 12498,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6740928215760646,
            "auditor_fn_violation": 0.017110677929391388,
            "auditor_fp_violation": 0.019134544106745737,
            "ave_precision_score": 0.6741377216367032,
            "fpr": 0.17105263157894737,
            "logloss": 2.629600682532853,
            "mae": 0.31191644221804593,
            "precision": 0.7062146892655368,
            "recall": 0.7716049382716049
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.6938006173025643,
            "auditor_fn_violation": 0.008063835176897753,
            "auditor_fp_violation": 0.011326327578901462,
            "ave_precision_score": 0.6919309356901999,
            "fpr": 0.1756311745334797,
            "logloss": 2.287335771661489,
            "mae": 0.3031248201159881,
            "precision": 0.7026022304832714,
            "recall": 0.8076923076923077
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.817931171003903,
            "auditor_fn_violation": 0.005505017688253556,
            "auditor_fp_violation": 0.018205357878263738,
            "ave_precision_score": 0.8180579480488097,
            "fpr": 0.27521929824561403,
            "logloss": 1.418852070123771,
            "mae": 0.31129140545484907,
            "precision": 0.6484593837535014,
            "recall": 0.9526748971193416
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.8377956818281946,
            "auditor_fn_violation": 0.004085864129771926,
            "auditor_fp_violation": 0.028597056790221353,
            "ave_precision_score": 0.8380480185100988,
            "fpr": 0.30735455543358947,
            "logloss": 1.4731677753916863,
            "mae": 0.33955498574695364,
            "precision": 0.6121883656509696,
            "recall": 0.9444444444444444
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 12498,
        "test": {
            "accuracy": 0.6798245614035088,
            "auc_prc": 0.680049147593403,
            "auditor_fn_violation": 0.004764998917045702,
            "auditor_fp_violation": 0.01000226505230212,
            "ave_precision_score": 0.6818860930341689,
            "fpr": 0.23793859649122806,
            "logloss": 1.1422426762619913,
            "mae": 0.36012038116062567,
            "precision": 0.6544585987261147,
            "recall": 0.845679012345679
        },
        "train": {
            "accuracy": 0.6926454445664105,
            "auc_prc": 0.697679783447416,
            "auditor_fn_violation": 0.0027020180697458424,
            "auditor_fp_violation": 0.016187901569232832,
            "ave_precision_score": 0.699390697075752,
            "fpr": 0.24368825466520308,
            "logloss": 1.2428160302874878,
            "mae": 0.35131623538899115,
            "precision": 0.6487341772151899,
            "recall": 0.8760683760683761
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5548245614035088,
            "auc_prc": 0.6833052522129118,
            "auditor_fn_violation": 0.0016244314489928528,
            "auditor_fp_violation": 0.003570031298904545,
            "ave_precision_score": 0.5425462681662063,
            "fpr": 0.4418859649122807,
            "logloss": 10.851481769753912,
            "mae": 0.44263315639177747,
            "precision": 0.5451467268623025,
            "recall": 0.9938271604938271
        },
        "train": {
            "accuracy": 0.5378704720087816,
            "auc_prc": 0.6746252297127335,
            "auditor_fn_violation": 0.0014659386229089854,
            "auditor_fp_violation": 0.0015784009336600954,
            "ave_precision_score": 0.5353664468974304,
            "fpr": 0.4544456641053787,
            "logloss": 10.698027487645389,
            "mae": 0.4581736577813437,
            "precision": 0.5268571428571428,
            "recall": 0.9850427350427351
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 12498,
        "test": {
            "accuracy": 0.5307017543859649,
            "auc_prc": 0.7637844880932531,
            "auditor_fn_violation": 0.001362717493321782,
            "auditor_fp_violation": 0.0015057449962935542,
            "ave_precision_score": 0.5333349941903581,
            "fpr": 0.46381578947368424,
            "logloss": 15.924972890595036,
            "mae": 0.46763328178323654,
            "precision": 0.5320796460176991,
            "recall": 0.9897119341563786
        },
        "train": {
            "accuracy": 0.5170142700329309,
            "auc_prc": 0.7532755504367001,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0017320286540477212,
            "ave_precision_score": 0.5127841023988011,
            "fpr": 0.4829857299670692,
            "logloss": 16.648780174561143,
            "mae": 0.4840813388600709,
            "precision": 0.5154185022026432,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 12498,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.8019771707834961,
            "auditor_fn_violation": 0.0029668435492022235,
            "auditor_fp_violation": 0.005050037064492236,
            "ave_precision_score": 0.8002006470405538,
            "fpr": 0.42543859649122806,
            "logloss": 1.79281418469121,
            "mae": 0.405962356642536,
            "precision": 0.5535097813578826,
            "recall": 0.9897119341563786
        },
        "train": {
            "accuracy": 0.5411635565312843,
            "auc_prc": 0.820933899244537,
            "auditor_fn_violation": 0.00041749931980447906,
            "auditor_fp_violation": 0.005094493437370706,
            "ave_precision_score": 0.8207805703679045,
            "fpr": 0.4566410537870472,
            "logloss": 1.8487275563225845,
            "mae": 0.4308752286789477,
            "precision": 0.528344671201814,
            "recall": 0.9957264957264957
        }
    }
]