[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8454230530216138,
            "auditor_fn_violation": 0.007852292020373524,
            "auditor_fp_violation": 0.010403175163860435,
            "ave_precision_score": 0.8242457959120542,
            "fpr": 0.10087719298245613,
            "logloss": 2.8670301126400766,
            "mae": 0.23994734230906514,
            "precision": 0.7865429234338747,
            "recall": 0.7290322580645161
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8795442585781476,
            "auditor_fn_violation": 0.010622274001692565,
            "auditor_fp_violation": 0.003103198922074076,
            "ave_precision_score": 0.8633495429513708,
            "fpr": 0.07793633369923161,
            "logloss": 2.4998467033103284,
            "mae": 0.21524630245834667,
            "precision": 0.8382687927107062,
            "recall": 0.7525562372188139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8285220747743435,
            "auditor_fn_violation": 0.011198358800226385,
            "auditor_fp_violation": 0.010982083284273324,
            "ave_precision_score": 0.8288310916273038,
            "fpr": 0.08771929824561403,
            "logloss": 0.5452381677353341,
            "mae": 0.31477398952119984,
            "precision": 0.8034398034398035,
            "recall": 0.7032258064516129
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8580176342355262,
            "auditor_fn_violation": 0.014573077518805603,
            "auditor_fp_violation": 0.011525795828759604,
            "ave_precision_score": 0.8590099581959563,
            "fpr": 0.06476399560922064,
            "logloss": 0.5156130519927541,
            "mae": 0.3021349902520351,
            "precision": 0.8517587939698492,
            "recall": 0.6932515337423313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8040824554400275,
            "auditor_fn_violation": 0.02770232031692134,
            "auditor_fp_violation": 0.010555261195494329,
            "ave_precision_score": 0.8045666869018139,
            "fpr": 0.08771929824561403,
            "logloss": 1.1592535345405246,
            "mae": 0.3207122404704632,
            "precision": 0.7938144329896907,
            "recall": 0.6623655913978495
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8465285723630224,
            "auditor_fn_violation": 0.026486096987736806,
            "auditor_fp_violation": 0.012477825003511587,
            "ave_precision_score": 0.8469048005320319,
            "fpr": 0.06037321624588365,
            "logloss": 1.0552997848176118,
            "mae": 0.3015579173587416,
            "precision": 0.8571428571428571,
            "recall": 0.6748466257668712
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 29759,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8232656480144152,
            "auditor_fn_violation": 0.01833380494246369,
            "auditor_fp_violation": 0.013933042898072928,
            "ave_precision_score": 0.8235561678359024,
            "fpr": 0.08991228070175439,
            "logloss": 1.1319868561481354,
            "mae": 0.312845392471877,
            "precision": 0.7985257985257985,
            "recall": 0.6989247311827957
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8500590591897621,
            "auditor_fn_violation": 0.02799009605391051,
            "auditor_fp_violation": 0.007111605911945107,
            "ave_precision_score": 0.8502949401835085,
            "fpr": 0.07464324917672886,
            "logloss": 1.0558154089167573,
            "mae": 0.3015374270473572,
            "precision": 0.8373205741626795,
            "recall": 0.7157464212678937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.834913076819814,
            "auditor_fn_violation": 0.011773721939256744,
            "auditor_fp_violation": 0.00633119431688842,
            "ave_precision_score": 0.8349656317214299,
            "fpr": 0.06469298245614036,
            "logloss": 0.5681210935374049,
            "mae": 0.3201190644636211,
            "precision": 0.8405405405405405,
            "recall": 0.6688172043010753
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8650854717984722,
            "auditor_fn_violation": 0.003932845319307987,
            "auditor_fp_violation": 0.010937930819213303,
            "ave_precision_score": 0.8652355317318781,
            "fpr": 0.05378704720087816,
            "logloss": 0.5474256656711637,
            "mae": 0.31380784831395214,
            "precision": 0.8682795698924731,
            "recall": 0.6605316973415133
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7145286830015751,
            "auditor_fn_violation": 0.012945670628183366,
            "auditor_fp_violation": 0.023166136818556463,
            "ave_precision_score": 0.7159760945919385,
            "fpr": 0.17763157894736842,
            "logloss": 1.296157257794665,
            "mae": 0.31040654966288234,
            "precision": 0.6914285714285714,
            "recall": 0.7806451612903226
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7921355504627354,
            "auditor_fn_violation": 0.009823134199367424,
            "auditor_fp_violation": 0.01560703565167178,
            "ave_precision_score": 0.7927692244474152,
            "fpr": 0.14818880351262348,
            "logloss": 0.968535723455434,
            "mae": 0.2818607115718011,
            "precision": 0.7403846153846154,
            "recall": 0.787321063394683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.815765632775274,
            "auditor_fn_violation": 0.011651103565365032,
            "auditor_fp_violation": 0.009976353075081443,
            "ave_precision_score": 0.8124233758993306,
            "fpr": 0.06798245614035088,
            "logloss": 0.5838117017594897,
            "mae": 0.3278676676027795,
            "precision": 0.8258426966292135,
            "recall": 0.632258064516129
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8576138723761892,
            "auditor_fn_violation": 0.0063639363471678844,
            "auditor_fp_violation": 0.01255325900916133,
            "ave_precision_score": 0.8570002935535087,
            "fpr": 0.050493962678375415,
            "logloss": 0.5570203891837903,
            "mae": 0.3203322552016739,
            "precision": 0.8693181818181818,
            "recall": 0.6257668711656442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8109449025404536,
            "auditor_fn_violation": 0.01058290888511602,
            "auditor_fp_violation": 0.008232269712312106,
            "ave_precision_score": 0.8114557817216648,
            "fpr": 0.06359649122807018,
            "logloss": 0.5922431996199078,
            "mae": 0.3249452432807486,
            "precision": 0.833810888252149,
            "recall": 0.6258064516129033
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8604211489774298,
            "auditor_fn_violation": 0.0035736813632068084,
            "auditor_fp_violation": 0.009239365105789692,
            "ave_precision_score": 0.8606514855889913,
            "fpr": 0.048298572996706916,
            "logloss": 0.5721020316675115,
            "mae": 0.319166199853654,
            "precision": 0.8735632183908046,
            "recall": 0.621676891615542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 29759,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8057913401165134,
            "auditor_fn_violation": 0.02405913978494624,
            "auditor_fp_violation": 0.00836718474037443,
            "ave_precision_score": 0.8060725252524661,
            "fpr": 0.07017543859649122,
            "logloss": 1.158969861001919,
            "mae": 0.3285453275445441,
            "precision": 0.8160919540229885,
            "recall": 0.610752688172043
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8334429934606304,
            "auditor_fn_violation": 0.029159623685964992,
            "auditor_fp_violation": 0.010352666982275611,
            "ave_precision_score": 0.833704161831632,
            "fpr": 0.052689352360043906,
            "logloss": 1.112074795829034,
            "mae": 0.32638866346160783,
            "precision": 0.8624641833810889,
            "recall": 0.6155419222903885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8388194350610265,
            "auditor_fn_violation": 0.009927372193925681,
            "auditor_fp_violation": 0.012797303661839163,
            "ave_precision_score": 0.8079592102473552,
            "fpr": 0.1118421052631579,
            "logloss": 3.3651355379094516,
            "mae": 0.2369719918469665,
            "precision": 0.7758241758241758,
            "recall": 0.7591397849462366
        },
        "train": {
            "accuracy": 0.7936333699231614,
            "auc_prc": 0.8792785029664003,
            "auditor_fn_violation": 0.011684052446916693,
            "auditor_fp_violation": 0.006791661681085835,
            "ave_precision_score": 0.8600299957535874,
            "fpr": 0.0889132821075741,
            "logloss": 2.8093559663281837,
            "mae": 0.2098077870493081,
            "precision": 0.8250539956803455,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8032001119650779,
            "auditor_fn_violation": 0.022849462365591395,
            "auditor_fp_violation": 0.015922426311864673,
            "ave_precision_score": 0.8036772049590276,
            "fpr": 0.10307017543859649,
            "logloss": 1.2793510646311144,
            "mae": 0.3296362457814743,
            "precision": 0.7701711491442543,
            "recall": 0.6774193548387096
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8397006570466397,
            "auditor_fn_violation": 0.021385968811099967,
            "auditor_fp_violation": 0.008084444467565982,
            "ave_precision_score": 0.8399659347542802,
            "fpr": 0.06915477497255763,
            "logloss": 1.1906865144053949,
            "mae": 0.31614184954009683,
            "precision": 0.8405063291139241,
            "recall": 0.6789366053169734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8000547316092264,
            "auditor_fn_violation": 0.010988492737219399,
            "auditor_fp_violation": 0.014063051925114799,
            "ave_precision_score": 0.8006264813130677,
            "fpr": 0.09429824561403509,
            "logloss": 0.5559738601740135,
            "mae": 0.32190915248346547,
            "precision": 0.7922705314009661,
            "recall": 0.7053763440860215
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8583374112366096,
            "auditor_fn_violation": 0.013354164842787203,
            "auditor_fp_violation": 0.01153099817397683,
            "ave_precision_score": 0.8586090900230403,
            "fpr": 0.07135016465422613,
            "logloss": 0.5061075810253536,
            "mae": 0.3058457381153862,
            "precision": 0.8470588235294118,
            "recall": 0.7361963190184049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 29759,
        "test": {
            "accuracy": 0.5043859649122807,
            "auc_prc": 0.7259815441425662,
            "auditor_fn_violation": 0.010365968685153746,
            "auditor_fp_violation": 0.0034734487224773397,
            "ave_precision_score": 0.727009287486969,
            "fpr": 0.48026315789473684,
            "logloss": 3.842833540044795,
            "mae": 0.49146016257452935,
            "precision": 0.5073115860517435,
            "recall": 0.9698924731182795
        },
        "train": {
            "accuracy": 0.5323819978046103,
            "auc_prc": 0.7883605669069645,
            "auditor_fn_violation": 0.0068892136329658646,
            "auditor_fp_violation": 0.0027312312390425824,
            "ave_precision_score": 0.7890224210840968,
            "fpr": 0.45773874862788144,
            "logloss": 3.3628856174902846,
            "mae": 0.46556428208726774,
            "precision": 0.5351170568561873,
            "recall": 0.9815950920245399
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7780627341895028,
            "auditor_fn_violation": 0.013610639501980758,
            "auditor_fp_violation": 0.014156265944503319,
            "ave_precision_score": 0.7412317605521408,
            "fpr": 0.12609649122807018,
            "logloss": 3.7580101432494066,
            "mae": 0.28459949922775624,
            "precision": 0.7450110864745011,
            "recall": 0.7225806451612903
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7908535803357422,
            "auditor_fn_violation": 0.011921998567833722,
            "auditor_fp_violation": 0.019321510136769665,
            "ave_precision_score": 0.7579368088232765,
            "fpr": 0.11855104281009879,
            "logloss": 3.6339445013565137,
            "mae": 0.2879032616236944,
            "precision": 0.7636761487964989,
            "recall": 0.7137014314928425
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8433511780779956,
            "auditor_fn_violation": 0.010540464063384271,
            "auditor_fp_violation": 0.013795674869500374,
            "ave_precision_score": 0.817502061805424,
            "fpr": 0.1162280701754386,
            "logloss": 3.1419395183951977,
            "mae": 0.23565023197697504,
            "precision": 0.7749469214437368,
            "recall": 0.7849462365591398
        },
        "train": {
            "accuracy": 0.7980241492864983,
            "auc_prc": 0.8804082689461769,
            "auditor_fn_violation": 0.012209329732714677,
            "auditor_fp_violation": 0.005259571014613388,
            "ave_precision_score": 0.8622164394362122,
            "fpr": 0.09220636663007684,
            "logloss": 2.6684981989995817,
            "mae": 0.2082402039847106,
            "precision": 0.8224101479915433,
            "recall": 0.7955010224948875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8091011936928715,
            "auditor_fn_violation": 0.02501179022825882,
            "auditor_fp_violation": 0.0104301581694729,
            "ave_precision_score": 0.8093719076899576,
            "fpr": 0.07456140350877193,
            "logloss": 1.0011587264437183,
            "mae": 0.3306694721243395,
            "precision": 0.8062678062678063,
            "recall": 0.6086021505376344
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.821651226590635,
            "auditor_fn_violation": 0.03243475001066268,
            "auditor_fp_violation": 0.009728385556208743,
            "ave_precision_score": 0.8221562958380326,
            "fpr": 0.052689352360043906,
            "logloss": 0.9627551688030971,
            "mae": 0.3284911935625757,
            "precision": 0.8628571428571429,
            "recall": 0.6175869120654397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7853066771974213,
            "auditor_fn_violation": 0.007309941520467835,
            "auditor_fp_violation": 0.006549511362298364,
            "ave_precision_score": 0.7860833911971553,
            "fpr": 0.09210526315789473,
            "logloss": 0.6149366040978639,
            "mae": 0.32344989082035647,
            "precision": 0.7868020304568528,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8301184834734161,
            "auditor_fn_violation": 0.008914000435486295,
            "auditor_fp_violation": 0.012623490669593855,
            "ave_precision_score": 0.8310292459751016,
            "fpr": 0.06256860592755215,
            "logloss": 0.5846464926523137,
            "mae": 0.3122736377156985,
            "precision": 0.8463611859838275,
            "recall": 0.6421267893660532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8416657060111132,
            "auditor_fn_violation": 0.014445387662705153,
            "auditor_fp_violation": 0.011835727461831314,
            "ave_precision_score": 0.8419254193787681,
            "fpr": 0.08333333333333333,
            "logloss": 0.5737421570927799,
            "mae": 0.3041615592139296,
            "precision": 0.81,
            "recall": 0.6967741935483871
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8622448190919493,
            "auditor_fn_violation": 0.0063212856273808645,
            "auditor_fp_violation": 0.009330406147091111,
            "ave_precision_score": 0.8629377195705283,
            "fpr": 0.06256860592755215,
            "logloss": 0.511322951902945,
            "mae": 0.29350818416082114,
            "precision": 0.8589108910891089,
            "recall": 0.7096114519427403
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.6710988767164319,
            "auditor_fn_violation": 0.025674401056404453,
            "auditor_fp_violation": 0.02205247458691472,
            "ave_precision_score": 0.6730120188656135,
            "fpr": 0.2149122807017544,
            "logloss": 1.302534663917261,
            "mae": 0.3680075822176783,
            "precision": 0.6524822695035462,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7148645756630563,
            "auditor_fn_violation": 0.03139990886214615,
            "auditor_fp_violation": 0.020226718204566622,
            "ave_precision_score": 0.7165969408867081,
            "fpr": 0.17453347969264543,
            "logloss": 1.2036808869482092,
            "mae": 0.3470814956088318,
            "precision": 0.7155635062611807,
            "recall": 0.8179959100204499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7982025745121305,
            "auditor_fn_violation": 0.02843095642331635,
            "auditor_fp_violation": 0.01062885121080105,
            "ave_precision_score": 0.799019231828118,
            "fpr": 0.12390350877192982,
            "logloss": 0.9174915424046708,
            "mae": 0.3220465702486222,
            "precision": 0.7488888888888889,
            "recall": 0.7247311827956989
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8494070336076662,
            "auditor_fn_violation": 0.032102523351269084,
            "auditor_fp_violation": 0.020476430774993372,
            "ave_precision_score": 0.8496465446441759,
            "fpr": 0.10098792535675083,
            "logloss": 0.8116879473319281,
            "mae": 0.3049135411555239,
            "precision": 0.7991266375545851,
            "recall": 0.7484662576687117
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7415237569343716,
            "auditor_fn_violation": 0.0230711186568572,
            "auditor_fp_violation": 0.013800580870520827,
            "ave_precision_score": 0.742924293342177,
            "fpr": 0.18201754385964913,
            "logloss": 1.2627475268508694,
            "mae": 0.30775147409554493,
            "precision": 0.6891385767790262,
            "recall": 0.7913978494623656
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8071203268406446,
            "auditor_fn_violation": 0.01677071197519973,
            "auditor_fp_violation": 0.015019170642125471,
            "ave_precision_score": 0.808484117588554,
            "fpr": 0.15587266739846323,
            "logloss": 0.9746918381587283,
            "mae": 0.27761265539267505,
            "precision": 0.7340823970037453,
            "recall": 0.8016359918200409
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7990607227043479,
            "auditor_fn_violation": 0.027412280701754384,
            "auditor_fp_violation": 0.014487421013383572,
            "ave_precision_score": 0.7996283081668645,
            "fpr": 0.09429824561403509,
            "logloss": 1.0923146063282443,
            "mae": 0.327532507605642,
            "precision": 0.7828282828282829,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8507681786941022,
            "auditor_fn_violation": 0.02531432458095668,
            "auditor_fp_violation": 0.006726632365870537,
            "ave_precision_score": 0.8511259038934373,
            "fpr": 0.06366630076838639,
            "logloss": 0.9837726274573135,
            "mae": 0.30677118808852305,
            "precision": 0.8516624040920716,
            "recall": 0.6809815950920245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8128966652474291,
            "auditor_fn_violation": 0.008121109224674593,
            "auditor_fp_violation": 0.009495564975077517,
            "ave_precision_score": 0.813343827438026,
            "fpr": 0.0668859649122807,
            "logloss": 0.6268413735803644,
            "mae": 0.34063741440982803,
            "precision": 0.8221574344023324,
            "recall": 0.6064516129032258
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8522522443644927,
            "auditor_fn_violation": 0.0036230664071707085,
            "auditor_fp_violation": 0.009879253567508236,
            "ave_precision_score": 0.8524932772766904,
            "fpr": 0.050493962678375415,
            "logloss": 0.6112509657263763,
            "mae": 0.3364630408997062,
            "precision": 0.8658892128279884,
            "recall": 0.6073619631901841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7963342984709879,
            "auditor_fn_violation": 0.020868704018109804,
            "auditor_fp_violation": 0.0026835825581851764,
            "ave_precision_score": 0.7968581959307739,
            "fpr": 0.08442982456140351,
            "logloss": 1.3810702172307796,
            "mae": 0.3169804398053256,
            "precision": 0.7935656836461126,
            "recall": 0.6365591397849463
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8431995143227488,
            "auditor_fn_violation": 0.029583886109109527,
            "auditor_fp_violation": 0.010428100987925359,
            "ave_precision_score": 0.8434607006045483,
            "fpr": 0.06476399560922064,
            "logloss": 1.3006732053825176,
            "mae": 0.30698642971230816,
            "precision": 0.8447368421052631,
            "recall": 0.656441717791411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7951508374559071,
            "auditor_fn_violation": 0.028654970760233923,
            "auditor_fp_violation": 0.013152988735821656,
            "ave_precision_score": 0.7960179516427486,
            "fpr": 0.12938596491228072,
            "logloss": 0.9215811393370147,
            "mae": 0.3220574200702082,
            "precision": 0.7429193899782135,
            "recall": 0.7333333333333333
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8463391549361636,
            "auditor_fn_violation": 0.03253352009859051,
            "auditor_fp_violation": 0.020117468955004915,
            "ave_precision_score": 0.8465955737201917,
            "fpr": 0.10428100987925357,
            "logloss": 0.8186384325489022,
            "mae": 0.30606056645373575,
            "precision": 0.7934782608695652,
            "recall": 0.7464212678936605
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 29759,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8165696402621409,
            "auditor_fn_violation": 0.021399264289756654,
            "auditor_fp_violation": 0.015976392323089606,
            "ave_precision_score": 0.7974310526106372,
            "fpr": 0.13157894736842105,
            "logloss": 0.5310131632854302,
            "mae": 0.3226403839193824,
            "precision": 0.7484276729559748,
            "recall": 0.7677419354838709
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8530797036155187,
            "auditor_fn_violation": 0.019509337140471268,
            "auditor_fp_violation": 0.0238527528209717,
            "ave_precision_score": 0.8378622855947665,
            "fpr": 0.10537870472008781,
            "logloss": 0.5000076247640549,
            "mae": 0.3111603017661283,
            "precision": 0.7948717948717948,
            "recall": 0.7607361963190185
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7853811022829091,
            "auditor_fn_violation": 0.027674023769100175,
            "auditor_fp_violation": 0.015799776286353474,
            "ave_precision_score": 0.7865100855386089,
            "fpr": 0.13596491228070176,
            "logloss": 0.8820425891632175,
            "mae": 0.32693869185831803,
            "precision": 0.7361702127659574,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.849620510191246,
            "auditor_fn_violation": 0.031222571658821183,
            "auditor_fp_violation": 0.0144807279121428,
            "ave_precision_score": 0.8498283181559404,
            "fpr": 0.11086717892425905,
            "logloss": 0.7683914243672437,
            "mae": 0.3049693802609346,
            "precision": 0.7900207900207901,
            "recall": 0.7770961145194274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8188003625643675,
            "auditor_fn_violation": 0.027388700245236753,
            "auditor_fp_violation": 0.017212704580242554,
            "ave_precision_score": 0.8191730565732656,
            "fpr": 0.06907894736842106,
            "logloss": 0.8920655724350841,
            "mae": 0.3288066430410615,
            "precision": 0.8163265306122449,
            "recall": 0.6021505376344086
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.846134850564569,
            "auditor_fn_violation": 0.026438956718498528,
            "auditor_fp_violation": 0.006107553285020887,
            "ave_precision_score": 0.8464814412170828,
            "fpr": 0.04720087815587267,
            "logloss": 0.8108747998208622,
            "mae": 0.31931474246079755,
            "precision": 0.8757225433526011,
            "recall": 0.6196319018404908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7251821220919241,
            "auditor_fn_violation": 0.026528013582342955,
            "auditor_fp_violation": 0.01899112995015503,
            "ave_precision_score": 0.7265426400388169,
            "fpr": 0.13267543859649122,
            "logloss": 1.1976986167572916,
            "mae": 0.3140134140038131,
            "precision": 0.7346491228070176,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.7884128292758651,
            "auditor_fn_violation": 0.025900210784346747,
            "auditor_fp_violation": 0.02220881173232894,
            "ave_precision_score": 0.789019286853156,
            "fpr": 0.1141602634467618,
            "logloss": 0.965024905951543,
            "mae": 0.29255061246961717,
            "precision": 0.7763440860215054,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.7903854282000988,
            "auditor_fn_violation": 0.008156479909451047,
            "auditor_fp_violation": 0.01825768279759802,
            "ave_precision_score": 0.791055189220562,
            "fpr": 0.11403508771929824,
            "logloss": 0.5518147796896214,
            "mae": 0.3182673721335289,
            "precision": 0.7699115044247787,
            "recall": 0.7483870967741936
        },
        "train": {
            "accuracy": 0.7848518111964874,
            "auc_prc": 0.8585340012146225,
            "auditor_fn_violation": 0.013702104925260227,
            "auditor_fp_violation": 0.010857294468346337,
            "ave_precision_score": 0.8587751154097076,
            "fpr": 0.09440175631174534,
            "logloss": 0.49541724843567425,
            "mae": 0.30095510200201714,
            "precision": 0.8150537634408602,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8194627968532956,
            "auditor_fn_violation": 0.024429352952273158,
            "auditor_fp_violation": 0.015946956316966916,
            "ave_precision_score": 0.8197100894503956,
            "fpr": 0.06798245614035088,
            "logloss": 1.45102926959384,
            "mae": 0.3154067493719295,
            "precision": 0.8292011019283747,
            "recall": 0.6473118279569893
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8452379212519809,
            "auditor_fn_violation": 0.030374046812532134,
            "auditor_fp_violation": 0.008133866747129608,
            "ave_precision_score": 0.8464321403250277,
            "fpr": 0.05378704720087816,
            "logloss": 1.3708908005951344,
            "mae": 0.307527509839044,
            "precision": 0.8638888888888889,
            "recall": 0.6359918200408998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.819221577686124,
            "auditor_fn_violation": 0.016411997736276173,
            "auditor_fp_violation": 0.00554132815259626,
            "ave_precision_score": 0.8195144646078588,
            "fpr": 0.07456140350877193,
            "logloss": 0.5820215279047223,
            "mae": 0.32879111903623615,
            "precision": 0.8073654390934845,
            "recall": 0.6129032258064516
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.85947503670929,
            "auditor_fn_violation": 0.005647853209691144,
            "auditor_fp_violation": 0.008781558726673985,
            "ave_precision_score": 0.8597086211805585,
            "fpr": 0.054884742041712405,
            "logloss": 0.5517872414412003,
            "mae": 0.32066386600324537,
            "precision": 0.8529411764705882,
            "recall": 0.5930470347648262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 29759,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7991972170401593,
            "auditor_fn_violation": 0.043185248066402566,
            "auditor_fp_violation": 0.04350641704933475,
            "ave_precision_score": 0.7999168196678491,
            "fpr": 0.14912280701754385,
            "logloss": 1.1140423815767646,
            "mae": 0.31748052960959433,
            "precision": 0.7235772357723578,
            "recall": 0.7655913978494624
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8355626362168038,
            "auditor_fn_violation": 0.0492952529748877,
            "auditor_fp_violation": 0.038929149260486635,
            "ave_precision_score": 0.8358224587541965,
            "fpr": 0.141602634467618,
            "logloss": 1.035710459241977,
            "mae": 0.3079938065003428,
            "precision": 0.7460629921259843,
            "recall": 0.7750511247443763
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8329197321894128,
            "auditor_fn_violation": 0.011943501226183742,
            "auditor_fp_violation": 0.01864035087719298,
            "ave_precision_score": 0.8332405437334289,
            "fpr": 0.16337719298245615,
            "logloss": 0.5510806168478206,
            "mae": 0.320764439464128,
            "precision": 0.7101167315175098,
            "recall": 0.7849462365591398
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8564868200931115,
            "auditor_fn_violation": 0.0021617180607840136,
            "auditor_fp_violation": 0.025772418206127325,
            "ave_precision_score": 0.8571842952987423,
            "fpr": 0.12403951701427003,
            "logloss": 0.4902926882212309,
            "mae": 0.2985776705548789,
            "precision": 0.7766798418972332,
            "recall": 0.803680981595092
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8203257758786795,
            "auditor_fn_violation": 0.02574985851726089,
            "auditor_fp_violation": 0.014627242042466347,
            "ave_precision_score": 0.8205880664638896,
            "fpr": 0.0668859649122807,
            "logloss": 1.2929848111587026,
            "mae": 0.31765106703053914,
            "precision": 0.828169014084507,
            "recall": 0.632258064516129
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8502513579514315,
            "auditor_fn_violation": 0.024268259558811973,
            "auditor_fp_violation": 0.00808444446756598,
            "ave_precision_score": 0.8506811339586796,
            "fpr": 0.050493962678375415,
            "logloss": 1.2181015790656218,
            "mae": 0.3103315331317837,
            "precision": 0.8700564971751412,
            "recall": 0.6298568507157464
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 29759,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7376953168527979,
            "auditor_fn_violation": 0.02093944538766271,
            "auditor_fp_violation": 0.0212160014129283,
            "ave_precision_score": 0.7390863884474819,
            "fpr": 0.17982456140350878,
            "logloss": 1.2590988111541175,
            "mae": 0.3082233238976124,
            "precision": 0.6876190476190476,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8032647499030978,
            "auditor_fn_violation": 0.01635093910150647,
            "auditor_fp_violation": 0.016002413888180793,
            "ave_precision_score": 0.80460974024039,
            "fpr": 0.14818880351262348,
            "logloss": 0.9861732103122075,
            "mae": 0.2785007705966212,
            "precision": 0.7388781431334622,
            "recall": 0.7811860940695297
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8388599855227266,
            "auditor_fn_violation": 0.012275985663082443,
            "auditor_fp_violation": 0.012054044507241263,
            "ave_precision_score": 0.8079910208144991,
            "fpr": 0.1118421052631579,
            "logloss": 3.3779528059305983,
            "mae": 0.2355370877108459,
            "precision": 0.7787418655097614,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7958287596048299,
            "auc_prc": 0.8798118412449576,
            "auditor_fn_violation": 0.010478608419252083,
            "auditor_fp_violation": 0.006705822985001641,
            "ave_precision_score": 0.8605507893290826,
            "fpr": 0.09001097694840834,
            "logloss": 2.8154208251571946,
            "mae": 0.20881681207571653,
            "precision": 0.8244111349036403,
            "recall": 0.787321063394683
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 29759,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8326920089168759,
            "auditor_fn_violation": 0.008552631578947367,
            "auditor_fp_violation": 0.010619039208760154,
            "ave_precision_score": 0.8330639647439646,
            "fpr": 0.06030701754385965,
            "logloss": 0.5747577311173767,
            "mae": 0.3197009298754366,
            "precision": 0.8414985590778098,
            "recall": 0.6279569892473118
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8568052571325098,
            "auditor_fn_violation": 0.010721044089620387,
            "auditor_fp_violation": 0.007574614636278035,
            "ave_precision_score": 0.8571787580249131,
            "fpr": 0.04171240395170143,
            "logloss": 0.5721619116727008,
            "mae": 0.31623605118183223,
            "precision": 0.8865671641791045,
            "recall": 0.6073619631901841
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8153359802627853,
            "auditor_fn_violation": 0.03210243350311263,
            "auditor_fp_violation": 0.01793388673024844,
            "ave_precision_score": 0.8158330840413417,
            "fpr": 0.07785087719298246,
            "logloss": 1.0843047307111469,
            "mae": 0.32065477122238706,
            "precision": 0.8054794520547945,
            "recall": 0.632258064516129
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8439275636330561,
            "auditor_fn_violation": 0.030115897719084406,
            "auditor_fp_violation": 0.005350612055914806,
            "ave_precision_score": 0.8443370197842428,
            "fpr": 0.04939626783754116,
            "logloss": 0.9755956209823461,
            "mae": 0.308288426144307,
            "precision": 0.8770491803278688,
            "recall": 0.656441717791411
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.81094721047594,
            "auditor_fn_violation": 0.010872948500282975,
            "auditor_fp_violation": 0.006917461438831982,
            "ave_precision_score": 0.8114493255028492,
            "fpr": 0.0625,
            "logloss": 0.5977029246924679,
            "mae": 0.3270846561226471,
            "precision": 0.8347826086956521,
            "recall": 0.6193548387096774
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.860589277254693,
            "auditor_fn_violation": 0.004345883868824347,
            "auditor_fp_violation": 0.00901566426144906,
            "ave_precision_score": 0.8608094271182507,
            "fpr": 0.04720087815587267,
            "logloss": 0.5792317312128366,
            "mae": 0.3219138492148218,
            "precision": 0.875,
            "recall": 0.6155419222903885
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8082155922523376,
            "auditor_fn_violation": 0.01129503867194869,
            "auditor_fp_violation": 0.008232269712312106,
            "ave_precision_score": 0.8091279603209087,
            "fpr": 0.06359649122807018,
            "logloss": 0.5960258743719529,
            "mae": 0.3259753787587805,
            "precision": 0.8328530259365994,
            "recall": 0.621505376344086
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8605577239043191,
            "auditor_fn_violation": 0.0028575982257300707,
            "auditor_fp_violation": 0.009239365105789692,
            "ave_precision_score": 0.8607710773395144,
            "fpr": 0.048298572996706916,
            "logloss": 0.576148524230843,
            "mae": 0.3203917388757231,
            "precision": 0.8728323699421965,
            "recall": 0.6175869120654397
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7821545387250601,
            "auditor_fn_violation": 0.004664214299188839,
            "auditor_fp_violation": 0.015027081125632882,
            "ave_precision_score": 0.7836178910609253,
            "fpr": 0.09539473684210527,
            "logloss": 0.5967451934485695,
            "mae": 0.3218271053215415,
            "precision": 0.779746835443038,
            "recall": 0.6623655913978495
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8319633286245731,
            "auditor_fn_violation": 0.00754693262757616,
            "auditor_fp_violation": 0.016304149910779785,
            "ave_precision_score": 0.8334714013774582,
            "fpr": 0.06805708013172337,
            "logloss": 0.5611112026664333,
            "mae": 0.3103284965045382,
            "precision": 0.8397932816537468,
            "recall": 0.6646216768916156
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7208708790663704,
            "auditor_fn_violation": 0.02000330126391247,
            "auditor_fp_violation": 0.022032850582832927,
            "ave_precision_score": 0.7222325100537104,
            "fpr": 0.14473684210526316,
            "logloss": 1.170654416079942,
            "mae": 0.3137707101884476,
            "precision": 0.7226890756302521,
            "recall": 0.7397849462365591
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.7799361161908946,
            "auditor_fn_violation": 0.016615822519131098,
            "auditor_fp_violation": 0.021038284058453552,
            "ave_precision_score": 0.7806275097411327,
            "fpr": 0.12294182217343579,
            "logloss": 0.9186824859816453,
            "mae": 0.28665343251906206,
            "precision": 0.7695473251028807,
            "recall": 0.7648261758691206
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8438053708025619,
            "auditor_fn_violation": 0.01561969439728353,
            "auditor_fp_violation": 0.0061398602770909375,
            "ave_precision_score": 0.8440006931499344,
            "fpr": 0.08114035087719298,
            "logloss": 0.5377088608620201,
            "mae": 0.3058166342285531,
            "precision": 0.8092783505154639,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8680208790237172,
            "auditor_fn_violation": 0.010316984639006554,
            "auditor_fp_violation": 0.009535898783171454,
            "ave_precision_score": 0.8685666616742231,
            "fpr": 0.06366630076838639,
            "logloss": 0.50530035925314,
            "mae": 0.29677222960201244,
            "precision": 0.8501291989664083,
            "recall": 0.6728016359918201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7394880455289088,
            "auditor_fn_violation": 0.02093944538766271,
            "auditor_fp_violation": 0.018434298834334166,
            "ave_precision_score": 0.7409114474121329,
            "fpr": 0.17214912280701755,
            "logloss": 1.3063071182741581,
            "mae": 0.3049552730371291,
            "precision": 0.696911196911197,
            "recall": 0.7763440860215054
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.80494310562028,
            "auditor_fn_violation": 0.017017637195019295,
            "auditor_fp_violation": 0.015211657415162763,
            "ave_precision_score": 0.8062796400921497,
            "fpr": 0.14709110867178923,
            "logloss": 0.9990362080797589,
            "mae": 0.2772946339959565,
            "precision": 0.7413127413127413,
            "recall": 0.7852760736196319
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.811666540458082,
            "auditor_fn_violation": 0.008946425202791932,
            "auditor_fp_violation": 0.008595313787825269,
            "ave_precision_score": 0.8121647010861046,
            "fpr": 0.06907894736842106,
            "logloss": 0.6067606631160367,
            "mae": 0.3307320459586519,
            "precision": 0.8230337078651685,
            "recall": 0.6301075268817204
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8523185770607168,
            "auditor_fn_violation": 0.006000282841615439,
            "auditor_fp_violation": 0.012496033211771868,
            "ave_precision_score": 0.8526886376864777,
            "fpr": 0.05378704720087816,
            "logloss": 0.5899493546674729,
            "mae": 0.3257239552687048,
            "precision": 0.8615819209039548,
            "recall": 0.623721881390593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7967439563859364,
            "auditor_fn_violation": 0.02397896623278627,
            "auditor_fp_violation": 0.005901919227599202,
            "ave_precision_score": 0.7972135120210291,
            "fpr": 0.06578947368421052,
            "logloss": 1.1984919053489023,
            "mae": 0.323492591947815,
            "precision": 0.8265895953757225,
            "recall": 0.6150537634408603
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8480851906986944,
            "auditor_fn_violation": 0.02627059861407609,
            "auditor_fp_violation": 0.006591371390222713,
            "ave_precision_score": 0.8482979344932093,
            "fpr": 0.042810098792535674,
            "logloss": 1.1178896744792322,
            "mae": 0.3141823688035571,
            "precision": 0.8898305084745762,
            "recall": 0.6441717791411042
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.748356025385395,
            "auditor_fn_violation": 0.013879456706281833,
            "auditor_fp_violation": 0.021775285529259395,
            "ave_precision_score": 0.7510452047479552,
            "fpr": 0.17434210526315788,
            "logloss": 0.5584930296501227,
            "mae": 0.34358188789746347,
            "precision": 0.6959847036328872,
            "recall": 0.7827956989247312
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8247266081229023,
            "auditor_fn_violation": 0.005993548517438532,
            "auditor_fp_violation": 0.02116314034366693,
            "ave_precision_score": 0.8256952834117426,
            "fpr": 0.12952799121844127,
            "logloss": 0.49451634508017683,
            "mae": 0.3198578082123193,
            "precision": 0.7677165354330708,
            "recall": 0.7975460122699386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.78631638460571,
            "auditor_fn_violation": 0.008920486700622525,
            "auditor_fp_violation": 0.007695062600573026,
            "ave_precision_score": 0.7871935565263405,
            "fpr": 0.09320175438596491,
            "logloss": 0.6141948478863271,
            "mae": 0.3212863054573781,
            "precision": 0.7858942065491183,
            "recall": 0.6709677419354839
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8299137404438718,
            "auditor_fn_violation": 0.008929713858565724,
            "auditor_fp_violation": 0.011525795828759604,
            "ave_precision_score": 0.8306804809851077,
            "fpr": 0.06476399560922064,
            "logloss": 0.5840622666614811,
            "mae": 0.3103473168226832,
            "precision": 0.8451443569553806,
            "recall": 0.6584867075664622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8384306115474462,
            "auditor_fn_violation": 0.011278532352386341,
            "auditor_fp_violation": 0.013435083794497428,
            "ave_precision_score": 0.8084057992492325,
            "fpr": 0.11074561403508772,
            "logloss": 3.3272952662676247,
            "mae": 0.23908296878484575,
            "precision": 0.7770419426048565,
            "recall": 0.7569892473118279
        },
        "train": {
            "accuracy": 0.7892425905598244,
            "auc_prc": 0.8788889448028134,
            "auditor_fn_violation": 0.011636912177678413,
            "auditor_fp_violation": 0.006013911071110858,
            "ave_precision_score": 0.8605176270376513,
            "fpr": 0.08562019758507135,
            "logloss": 2.777793476768511,
            "mae": 0.21322597228789106,
            "precision": 0.8278145695364238,
            "recall": 0.7668711656441718
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8437394047921125,
            "auditor_fn_violation": 0.015138653084323715,
            "auditor_fp_violation": 0.007785823619451316,
            "ave_precision_score": 0.8439343340295385,
            "fpr": 0.08223684210526316,
            "logloss": 0.5363665963520741,
            "mae": 0.3058724930816792,
            "precision": 0.8076923076923077,
            "recall": 0.6774193548387096
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8680109105534445,
            "auditor_fn_violation": 0.008469535039811082,
            "auditor_fp_violation": 0.009535898783171454,
            "ave_precision_score": 0.8685573347683577,
            "fpr": 0.06366630076838639,
            "logloss": 0.5031671549130952,
            "mae": 0.2965025444531406,
            "precision": 0.8508997429305912,
            "recall": 0.6768916155419223
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8215275274729839,
            "auditor_fn_violation": 0.024700528202225996,
            "auditor_fp_violation": 0.01368038384551984,
            "ave_precision_score": 0.8217938724851639,
            "fpr": 0.0668859649122807,
            "logloss": 1.3175557391385682,
            "mae": 0.3141957413027849,
            "precision": 0.8305555555555556,
            "recall": 0.6430107526881721
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8499152206411884,
            "auditor_fn_violation": 0.02402806866316931,
            "auditor_fp_violation": 0.008388781662773579,
            "ave_precision_score": 0.8503447588950042,
            "fpr": 0.05378704720087816,
            "logloss": 1.2463685508426627,
            "mae": 0.30742414779583754,
            "precision": 0.8631284916201117,
            "recall": 0.6319018404907976
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8257422682299889,
            "auditor_fn_violation": 0.013978494623655918,
            "auditor_fp_violation": 0.008580595784763926,
            "ave_precision_score": 0.8260109498340666,
            "fpr": 0.12171052631578948,
            "logloss": 0.7454805114830022,
            "mae": 0.2737242840863377,
            "precision": 0.7549668874172185,
            "recall": 0.7354838709677419
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8467371823793293,
            "auditor_fn_violation": 0.007326944704464187,
            "auditor_fp_violation": 0.01230874878395181,
            "ave_precision_score": 0.8482109768073214,
            "fpr": 0.09879253567508232,
            "logloss": 0.6822818650939418,
            "mae": 0.26598408392479767,
            "precision": 0.7986577181208053,
            "recall": 0.7300613496932515
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7820841090194113,
            "auditor_fn_violation": 0.027350971514808534,
            "auditor_fp_violation": 0.01621188037207112,
            "ave_precision_score": 0.7825710881300739,
            "fpr": 0.08552631578947369,
            "logloss": 1.361904680794907,
            "mae": 0.3386923165411265,
            "precision": 0.7857142857142857,
            "recall": 0.6150537634408603
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8364968015130675,
            "auditor_fn_violation": 0.02112557494292661,
            "auditor_fp_violation": 0.0069555355554283904,
            "ave_precision_score": 0.8370130638991049,
            "fpr": 0.052689352360043906,
            "logloss": 1.244505076452856,
            "mae": 0.32274105971338796,
            "precision": 0.8674033149171271,
            "recall": 0.6421267893660532
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7270641421645755,
            "auditor_fn_violation": 0.018953970948877574,
            "auditor_fp_violation": 0.0208088033282311,
            "ave_precision_score": 0.7284620905550165,
            "fpr": 0.15679824561403508,
            "logloss": 1.2810230979202335,
            "mae": 0.30736310524480953,
            "precision": 0.7075664621676891,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7909644576487601,
            "auditor_fn_violation": 0.015845864788239173,
            "auditor_fp_violation": 0.015045182368211585,
            "ave_precision_score": 0.7923749571996817,
            "fpr": 0.13172338090010977,
            "logloss": 0.9906247708843611,
            "mae": 0.2815760222462932,
            "precision": 0.7565922920892495,
            "recall": 0.7627811860940695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7917387289029824,
            "auditor_fn_violation": 0.00947462742878702,
            "auditor_fp_violation": 0.009647651006711408,
            "ave_precision_score": 0.7920254237133957,
            "fpr": 0.0756578947368421,
            "logloss": 0.8628650416883772,
            "mae": 0.3532308304777949,
            "precision": 0.7883435582822086,
            "recall": 0.5526881720430108
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7886358143385165,
            "auditor_fn_violation": 0.012911944221837623,
            "auditor_fp_violation": 0.014665411167354243,
            "ave_precision_score": 0.7889747111262332,
            "fpr": 0.08342480790340286,
            "logloss": 0.9012247627470391,
            "mae": 0.3693807574023962,
            "precision": 0.7751479289940828,
            "recall": 0.5357873210633947
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 29759,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7736420614208537,
            "auditor_fn_violation": 0.013287587247689114,
            "auditor_fp_violation": 0.013798127870010602,
            "ave_precision_score": 0.7743788603529781,
            "fpr": 0.1425438596491228,
            "logloss": 0.5699374971354905,
            "mae": 0.35797747964317206,
            "precision": 0.7291666666666666,
            "recall": 0.7526881720430108
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8372052053841439,
            "auditor_fn_violation": 0.0042516033303477896,
            "auditor_fp_violation": 0.01691282430119498,
            "ave_precision_score": 0.8375519034587867,
            "fpr": 0.10537870472008781,
            "logloss": 0.5233683417283632,
            "mae": 0.34011300278236656,
            "precision": 0.7926565874730022,
            "recall": 0.7505112474437627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7854223013941278,
            "auditor_fn_violation": 0.009161007357102437,
            "auditor_fp_violation": 0.006549511362298364,
            "ave_precision_score": 0.7861986733255606,
            "fpr": 0.09210526315789473,
            "logloss": 0.6156927460924346,
            "mae": 0.32324297547344477,
            "precision": 0.7851662404092071,
            "recall": 0.6602150537634408
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8303354450578748,
            "auditor_fn_violation": 0.009091337638811267,
            "auditor_fp_violation": 0.012623490669593855,
            "ave_precision_score": 0.8312455494604646,
            "fpr": 0.06037321624588365,
            "logloss": 0.5858549518117756,
            "mae": 0.3122040946869758,
            "precision": 0.8501362397820164,
            "recall": 0.6380368098159509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.8177306808006579,
            "auditor_fn_violation": 0.005494246368609709,
            "auditor_fp_violation": 0.0041651948663605325,
            "ave_precision_score": 0.8179705050752489,
            "fpr": 0.023026315789473683,
            "logloss": 0.7777729823820945,
            "mae": 0.3772027463728272,
            "precision": 0.8917525773195877,
            "recall": 0.3720430107526882
        },
        "train": {
            "accuracy": 0.6344676180021954,
            "auc_prc": 0.7950106649790207,
            "auditor_fn_violation": 0.011051025974288364,
            "auditor_fp_violation": 0.005337606192871747,
            "ave_precision_score": 0.7966920620456011,
            "fpr": 0.025246981339187707,
            "logloss": 0.8044341597227547,
            "mae": 0.39091171346667186,
            "precision": 0.8861386138613861,
            "recall": 0.3660531697341513
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8345874415969423,
            "auditor_fn_violation": 0.02361346915676288,
            "auditor_fp_violation": 0.02897484202676714,
            "ave_precision_score": 0.833075043908944,
            "fpr": 0.14583333333333334,
            "logloss": 0.530095632059071,
            "mae": 0.3202601494614786,
            "precision": 0.73767258382643,
            "recall": 0.8043010752688172
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8561920916630164,
            "auditor_fn_violation": 0.023401776514717868,
            "auditor_fp_violation": 0.022286846910587296,
            "ave_precision_score": 0.8552932353274884,
            "fpr": 0.13391877058177826,
            "logloss": 0.49908716278772364,
            "mae": 0.30891975848173925,
            "precision": 0.7640232108317214,
            "recall": 0.8077709611451943
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8187519316392128,
            "auditor_fn_violation": 0.010222127900396153,
            "auditor_fp_violation": 0.009797284037835079,
            "ave_precision_score": 0.8190169942183676,
            "fpr": 0.12390350877192982,
            "logloss": 0.7365969122466364,
            "mae": 0.27776112880596704,
            "precision": 0.7532751091703057,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8451422441067701,
            "auditor_fn_violation": 0.008678299089294903,
            "auditor_fp_violation": 0.013869452349118986,
            "ave_precision_score": 0.8454279772626903,
            "fpr": 0.10208562019758508,
            "logloss": 0.6712879694115081,
            "mae": 0.27061611307998157,
            "precision": 0.7942477876106194,
            "recall": 0.7341513292433538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8199011562126943,
            "auditor_fn_violation": 0.010964912280701756,
            "auditor_fp_violation": 0.007542976568939131,
            "ave_precision_score": 0.8203806468532351,
            "fpr": 0.0756578947368421,
            "logloss": 0.5666217841643255,
            "mae": 0.31840484800724017,
            "precision": 0.8226221079691517,
            "recall": 0.6881720430107527
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8649346925201804,
            "auditor_fn_violation": 0.007266335786872111,
            "auditor_fp_violation": 0.007002356662383403,
            "ave_precision_score": 0.8651394982469648,
            "fpr": 0.05598243688254665,
            "logloss": 0.5601924068530049,
            "mae": 0.3137682089510524,
            "precision": 0.8671875,
            "recall": 0.6809815950920245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.8456123499281311,
            "auditor_fn_violation": 0.01406102622146765,
            "auditor_fp_violation": 0.011649299423054283,
            "ave_precision_score": 0.8458692531125931,
            "fpr": 0.08333333333333333,
            "logloss": 0.5393994181742268,
            "mae": 0.2963141391114812,
            "precision": 0.8095238095238095,
            "recall": 0.6946236559139785
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8724360324668354,
            "auditor_fn_violation": 0.0032279860554594113,
            "auditor_fp_violation": 0.009083294749272972,
            "ave_precision_score": 0.8728645642167141,
            "fpr": 0.06476399560922064,
            "logloss": 0.49186921796972616,
            "mae": 0.28330453505262154,
            "precision": 0.8532338308457711,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8105339372535725,
            "auditor_fn_violation": 0.012325504621769477,
            "auditor_fp_violation": 0.008232269712312106,
            "ave_precision_score": 0.8110692886753739,
            "fpr": 0.06359649122807018,
            "logloss": 0.591525133318902,
            "mae": 0.3245275334170162,
            "precision": 0.8347578347578347,
            "recall": 0.6301075268817204
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.86047128416857,
            "auditor_fn_violation": 0.005044008808496021,
            "auditor_fp_violation": 0.010266828286191418,
            "ave_precision_score": 0.8607128760708547,
            "fpr": 0.04939626783754116,
            "logloss": 0.5711628991477226,
            "mae": 0.3186635784871271,
            "precision": 0.8714285714285714,
            "recall": 0.623721881390593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7787920417000492,
            "auditor_fn_violation": 0.007392473118279577,
            "auditor_fp_violation": 0.012157070528670672,
            "ave_precision_score": 0.780010789980454,
            "fpr": 0.09210526315789473,
            "logloss": 0.6040977786447456,
            "mae": 0.3233270864594695,
            "precision": 0.7894736842105263,
            "recall": 0.6774193548387096
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8275939736070529,
            "auditor_fn_violation": 0.003658982802780828,
            "auditor_fp_violation": 0.013011065388277038,
            "ave_precision_score": 0.8287450829987227,
            "fpr": 0.06586169045005488,
            "logloss": 0.5690489664333626,
            "mae": 0.3109378456695232,
            "precision": 0.844559585492228,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8128984353850031,
            "auditor_fn_violation": 0.016124316166760994,
            "auditor_fp_violation": 0.008183209702107619,
            "ave_precision_score": 0.8134435924141754,
            "fpr": 0.13486842105263158,
            "logloss": 0.5723353474043434,
            "mae": 0.3079565077087816,
            "precision": 0.7463917525773196,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8589248636806533,
            "auditor_fn_violation": 0.006148437973507171,
            "auditor_fp_violation": 0.01757092097117381,
            "ave_precision_score": 0.859264901292561,
            "fpr": 0.11745334796926454,
            "logloss": 0.4880890678043377,
            "mae": 0.2886513811489998,
            "precision": 0.7842741935483871,
            "recall": 0.7955010224948875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8148598498305251,
            "auditor_fn_violation": 0.005876249764195437,
            "auditor_fp_violation": 0.012767867655716476,
            "ave_precision_score": 0.815542737379268,
            "fpr": 0.09320175438596491,
            "logloss": 0.5703377290061926,
            "mae": 0.3070888103658881,
            "precision": 0.7990543735224587,
            "recall": 0.7268817204301076
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8456629599003247,
            "auditor_fn_violation": 0.009928638611472147,
            "auditor_fp_violation": 0.012881006757846437,
            "ave_precision_score": 0.8472983122639692,
            "fpr": 0.06805708013172337,
            "logloss": 0.5418781785676705,
            "mae": 0.2949626772239207,
            "precision": 0.8502415458937198,
            "recall": 0.7198364008179959
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.6587957627821064,
            "auditor_fn_violation": 0.0067840973401245095,
            "auditor_fp_violation": 0.04174761568350406,
            "ave_precision_score": 0.6352254182663549,
            "fpr": 0.2138157894736842,
            "logloss": 2.9623723577544614,
            "mae": 0.3250446855392891,
            "precision": 0.6683673469387755,
            "recall": 0.8451612903225807
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.6883326473155348,
            "auditor_fn_violation": 0.012678487650371847,
            "auditor_fp_violation": 0.026074154228726314,
            "ave_precision_score": 0.6671700090825683,
            "fpr": 0.18660812294182216,
            "logloss": 2.685834643001393,
            "mae": 0.3027685882292231,
            "precision": 0.702276707530648,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7789154703239924,
            "auditor_fn_violation": 0.015775325410299953,
            "auditor_fp_violation": 0.012517661603673617,
            "ave_precision_score": 0.7420515383942561,
            "fpr": 0.12171052631578948,
            "logloss": 3.748018880849061,
            "mae": 0.28055104707452394,
            "precision": 0.7482993197278912,
            "recall": 0.7096774193548387
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7908681018418329,
            "auditor_fn_violation": 0.006539028775767209,
            "auditor_fp_violation": 0.02046342491195031,
            "ave_precision_score": 0.7580172821126673,
            "fpr": 0.11306256860592755,
            "logloss": 3.6297643696975297,
            "mae": 0.288304949437362,
            "precision": 0.7674943566591422,
            "recall": 0.6952965235173824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8030262790428617,
            "auditor_fn_violation": 0.012009526504433125,
            "auditor_fp_violation": 0.014440814003689314,
            "ave_precision_score": 0.8033278345917712,
            "fpr": 0.14583333333333334,
            "logloss": 0.8079109552734522,
            "mae": 0.28543153563120666,
            "precision": 0.7296747967479674,
            "recall": 0.7720430107526882
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8223378185528412,
            "auditor_fn_violation": 0.013533746820837802,
            "auditor_fp_violation": 0.02148828691974342,
            "ave_precision_score": 0.8226341858243236,
            "fpr": 0.13721185510428102,
            "logloss": 0.7423187998430246,
            "mae": 0.2781372001678805,
            "precision": 0.7504990019960079,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8103231927072967,
            "auditor_fn_violation": 0.01058290888511602,
            "auditor_fp_violation": 0.008232269712312106,
            "ave_precision_score": 0.8108386629697784,
            "fpr": 0.06359649122807018,
            "logloss": 0.5927012361380954,
            "mae": 0.324991737879923,
            "precision": 0.833810888252149,
            "recall": 0.6258064516129033
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8605060409152112,
            "auditor_fn_violation": 0.0035736813632068084,
            "auditor_fp_violation": 0.008903813839278745,
            "ave_precision_score": 0.8607283301281746,
            "fpr": 0.04720087815587267,
            "logloss": 0.5723095641292487,
            "mae": 0.3190258696509687,
            "precision": 0.8760806916426513,
            "recall": 0.621676891615542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7843041419877985,
            "auditor_fn_violation": 0.02810790416902472,
            "auditor_fp_violation": 0.01636887240472546,
            "ave_precision_score": 0.7847616978963183,
            "fpr": 0.0800438596491228,
            "logloss": 1.3934836121462773,
            "mae": 0.33874433012271404,
            "precision": 0.7966573816155988,
            "recall": 0.6150537634408603
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8315047351995495,
            "auditor_fn_violation": 0.022957311119042655,
            "auditor_fp_violation": 0.008230110133648251,
            "ave_precision_score": 0.832127824270201,
            "fpr": 0.052689352360043906,
            "logloss": 1.2971194649514308,
            "mae": 0.32748695572268716,
            "precision": 0.8640226628895185,
            "recall": 0.623721881390593
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7369862090952406,
            "auditor_fn_violation": 0.02815506508205999,
            "auditor_fp_violation": 0.014651772047568587,
            "ave_precision_score": 0.7383375107555324,
            "fpr": 0.17105263157894737,
            "logloss": 1.2380061121896349,
            "mae": 0.3067547358190137,
            "precision": 0.6947162426614482,
            "recall": 0.7634408602150538
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8028681990351003,
            "auditor_fn_violation": 0.018108597711676645,
            "auditor_fp_violation": 0.014774660416915948,
            "ave_precision_score": 0.8042389081936676,
            "fpr": 0.14270032930845225,
            "logloss": 0.9615870909692011,
            "mae": 0.28216735538181237,
            "precision": 0.7440944881889764,
            "recall": 0.7730061349693251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7799707211288348,
            "auditor_fn_violation": 0.008099886813808712,
            "auditor_fp_violation": 0.008843066839357903,
            "ave_precision_score": 0.7807183095490204,
            "fpr": 0.04824561403508772,
            "logloss": 0.6567834338095082,
            "mae": 0.36431618077627365,
            "precision": 0.8450704225352113,
            "recall": 0.5161290322580645
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.840519257194565,
            "auditor_fn_violation": 0.015033256337560247,
            "auditor_fp_violation": 0.0075902216719297075,
            "ave_precision_score": 0.8418466309796612,
            "fpr": 0.038419319429198684,
            "logloss": 0.646658797668318,
            "mae": 0.36509460108876063,
            "precision": 0.8717948717948718,
            "recall": 0.4867075664621677
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8437888761129376,
            "auditor_fn_violation": 0.017458970005659318,
            "auditor_fp_violation": 0.018819419914439348,
            "ave_precision_score": 0.8281427715009391,
            "fpr": 0.08771929824561403,
            "logloss": 2.6065391933330577,
            "mae": 0.2477843869749471,
            "precision": 0.800498753117207,
            "recall": 0.6903225806451613
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8735703362109822,
            "auditor_fn_violation": 0.0185418392337237,
            "auditor_fp_violation": 0.004822574016366579,
            "ave_precision_score": 0.8621768642228341,
            "fpr": 0.06476399560922064,
            "logloss": 2.249215706189739,
            "mae": 0.2394034219729717,
            "precision": 0.8498727735368957,
            "recall": 0.6830265848670757
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7862654996979529,
            "auditor_fn_violation": 0.007309941520467834,
            "auditor_fp_violation": 0.007695062600573026,
            "ave_precision_score": 0.7871483806560101,
            "fpr": 0.09320175438596491,
            "logloss": 0.6146807577856847,
            "mae": 0.32102693031999496,
            "precision": 0.7848101265822784,
            "recall": 0.6666666666666666
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8299730545200243,
            "auditor_fn_violation": 0.008929713858565724,
            "auditor_fp_violation": 0.011705276738753833,
            "ave_precision_score": 0.8307371269698707,
            "fpr": 0.06147091108671789,
            "logloss": 0.5848091446534651,
            "mae": 0.31021975192474455,
            "precision": 0.8518518518518519,
            "recall": 0.6584867075664622
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.840625671721168,
            "auditor_fn_violation": 0.008701188455008493,
            "auditor_fp_violation": 0.010557714196004559,
            "ave_precision_score": 0.8114910886950241,
            "fpr": 0.12938596491228072,
            "logloss": 3.2292383618765523,
            "mae": 0.2358455813542028,
            "precision": 0.7611336032388664,
            "recall": 0.8086021505376344
        },
        "train": {
            "accuracy": 0.8046103183315039,
            "auc_prc": 0.8809957888821416,
            "auditor_fn_violation": 0.012916433771288888,
            "auditor_fp_violation": 0.009015664261449067,
            "ave_precision_score": 0.8627744919176402,
            "fpr": 0.09879253567508232,
            "logloss": 2.66867349352076,
            "mae": 0.2070290700082658,
            "precision": 0.8167006109979633,
            "recall": 0.820040899795501
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.741915143872421,
            "auditor_fn_violation": 0.014270892284474628,
            "auditor_fp_violation": 0.018610914871070305,
            "ave_precision_score": 0.7140669082869779,
            "fpr": 0.18092105263157895,
            "logloss": 2.5854225577156877,
            "mae": 0.3092333520415528,
            "precision": 0.6898496240601504,
            "recall": 0.789247311827957
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7694854675745313,
            "auditor_fn_violation": 0.015111823452957387,
            "auditor_fp_violation": 0.02122036614105639,
            "ave_precision_score": 0.7484862720898346,
            "fpr": 0.15367727771679474,
            "logloss": 2.186461235325527,
            "mae": 0.289678540648793,
            "precision": 0.7388059701492538,
            "recall": 0.8098159509202454
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8198051663359718,
            "auditor_fn_violation": 0.024724108658743634,
            "auditor_fp_violation": 0.01467630205267083,
            "ave_precision_score": 0.8200732143936209,
            "fpr": 0.0668859649122807,
            "logloss": 1.1600963711592591,
            "mae": 0.3142748695240684,
            "precision": 0.8310249307479224,
            "recall": 0.6451612903225806
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8483415009740485,
            "auditor_fn_violation": 0.024187447668689212,
            "auditor_fp_violation": 0.008388781662773579,
            "ave_precision_score": 0.8488569935484116,
            "fpr": 0.05378704720087816,
            "logloss": 1.098282553361547,
            "mae": 0.30756003276360944,
            "precision": 0.8638888888888889,
            "recall": 0.6359918200408998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 29759,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.812087926485605,
            "auditor_fn_violation": 0.008906338426711943,
            "auditor_fp_violation": 0.01039826916283999,
            "ave_precision_score": 0.8123566492341584,
            "fpr": 0.06907894736842106,
            "logloss": 0.7361822767229931,
            "mae": 0.3325024525982937,
            "precision": 0.7993630573248408,
            "recall": 0.5397849462365591
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.8200561754910765,
            "auditor_fn_violation": 0.005899267978961979,
            "auditor_fp_violation": 0.006586169045005493,
            "ave_precision_score": 0.8205273977440679,
            "fpr": 0.06147091108671789,
            "logloss": 0.7488333258857649,
            "mae": 0.3360696962125417,
            "precision": 0.8276923076923077,
            "recall": 0.5501022494887525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8246969826596748,
            "auditor_fn_violation": 0.01316732691944917,
            "auditor_fp_violation": 0.014173436948074885,
            "ave_precision_score": 0.8250542913306737,
            "fpr": 0.09320175438596491,
            "logloss": 0.5342954191031669,
            "mae": 0.31571138826180495,
            "precision": 0.7931873479318735,
            "recall": 0.7010752688172043
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8690810243867297,
            "auditor_fn_violation": 0.019271391019554242,
            "auditor_fp_violation": 0.014108760229111289,
            "ave_precision_score": 0.8692618899829297,
            "fpr": 0.07025246981339188,
            "logloss": 0.5047930964113716,
            "mae": 0.3038701071924275,
            "precision": 0.8427518427518428,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7908662690755817,
            "auditor_fn_violation": 0.008262591963780421,
            "auditor_fp_violation": 0.012419541583264648,
            "ave_precision_score": 0.791442684102699,
            "fpr": 0.09649122807017543,
            "logloss": 0.588908628444943,
            "mae": 0.318362632545279,
            "precision": 0.784841075794621,
            "recall": 0.6903225806451613
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8323766538916721,
            "auditor_fn_violation": 0.004357107742452512,
            "auditor_fp_violation": 0.013328408446527698,
            "ave_precision_score": 0.8338309058966498,
            "fpr": 0.06586169045005488,
            "logloss": 0.5450975181668635,
            "mae": 0.3033897237965692,
            "precision": 0.8484848484848485,
            "recall": 0.6871165644171779
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7769538604165632,
            "auditor_fn_violation": 0.004857574042633465,
            "auditor_fp_violation": 0.007964892656697677,
            "ave_precision_score": 0.7782618637193898,
            "fpr": 0.09649122807017543,
            "logloss": 0.5817610227002713,
            "mae": 0.3475801660817141,
            "precision": 0.7671957671957672,
            "recall": 0.6236559139784946
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8360651594331157,
            "auditor_fn_violation": 0.01158528235898887,
            "auditor_fp_violation": 0.008765951691022315,
            "ave_precision_score": 0.8360413202382144,
            "fpr": 0.06586169045005488,
            "logloss": 0.5468710368832618,
            "mae": 0.3356578757840236,
            "precision": 0.8324022346368715,
            "recall": 0.6094069529652352
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8169221314088644,
            "auditor_fn_violation": 0.015027824938690815,
            "auditor_fp_violation": 0.009794831037324866,
            "ave_precision_score": 0.8175793142134111,
            "fpr": 0.13815789473684212,
            "logloss": 0.5699684222529665,
            "mae": 0.30598522143128903,
            "precision": 0.7418032786885246,
            "recall": 0.7784946236559139
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8600854439250022,
            "auditor_fn_violation": 0.005694993478929423,
            "auditor_fp_violation": 0.018057340248984245,
            "ave_precision_score": 0.8604090085413594,
            "fpr": 0.1119648737650933,
            "logloss": 0.4885167633880085,
            "mae": 0.2879994172792549,
            "precision": 0.7909836065573771,
            "recall": 0.7893660531697342
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8138871417220491,
            "auditor_fn_violation": 0.010431993963403134,
            "auditor_fp_violation": 0.00912270889752346,
            "ave_precision_score": 0.8137233529743554,
            "fpr": 0.12719298245614036,
            "logloss": 0.7635444663969356,
            "mae": 0.27816143848403213,
            "precision": 0.7489177489177489,
            "recall": 0.7440860215053764
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8432692920480109,
            "auditor_fn_violation": 0.0077646757759625065,
            "auditor_fp_violation": 0.01572668959166792,
            "ave_precision_score": 0.8440177459895172,
            "fpr": 0.10867178924259056,
            "logloss": 0.6874270624694101,
            "mae": 0.2700096818964562,
            "precision": 0.7843137254901961,
            "recall": 0.7361963190184049
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8054389564914691,
            "auditor_fn_violation": 0.007616487455197144,
            "auditor_fp_violation": 0.012767867655716476,
            "ave_precision_score": 0.8034683294732532,
            "fpr": 0.09320175438596491,
            "logloss": 0.5792248389134403,
            "mae": 0.3059633543797597,
            "precision": 0.7976190476190477,
            "recall": 0.7204301075268817
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8281056050691398,
            "auditor_fn_violation": 0.008215875495814618,
            "auditor_fp_violation": 0.012881006757846437,
            "ave_precision_score": 0.8335041389278539,
            "fpr": 0.06805708013172337,
            "logloss": 0.5463340981802508,
            "mae": 0.29359759012304665,
            "precision": 0.8495145631067961,
            "recall": 0.7157464212678937
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.788692240827082,
            "auditor_fn_violation": 0.023205527259007742,
            "auditor_fp_violation": 0.004302562894933083,
            "ave_precision_score": 0.7891981288328032,
            "fpr": 0.08114035087719298,
            "logloss": 1.509610847997144,
            "mae": 0.32250767555666654,
            "precision": 0.7932960893854749,
            "recall": 0.610752688172043
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.8367774455865908,
            "auditor_fn_violation": 0.03555498687929173,
            "auditor_fp_violation": 0.004541647374636485,
            "ave_precision_score": 0.8370362000331055,
            "fpr": 0.05598243688254665,
            "logloss": 1.431101770090004,
            "mae": 0.3136188058746364,
            "precision": 0.856338028169014,
            "recall": 0.621676891615542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7894654612070545,
            "auditor_fn_violation": 0.009047821165817775,
            "auditor_fp_violation": 0.009471034969975275,
            "ave_precision_score": 0.7902539961286238,
            "fpr": 0.09320175438596491,
            "logloss": 0.6029380059863677,
            "mae": 0.32183212038280706,
            "precision": 0.7880299251870324,
            "recall": 0.6795698924731183
        },
        "train": {
            "accuracy": 0.7650933040614709,
            "auc_prc": 0.8324450705902313,
            "auditor_fn_violation": 0.0010774918683035624,
            "auditor_fp_violation": 0.009626939824472875,
            "ave_precision_score": 0.8331531795551976,
            "fpr": 0.06256860592755215,
            "logloss": 0.5701440468249156,
            "mae": 0.3097647642476523,
            "precision": 0.8534704370179949,
            "recall": 0.6789366053169734
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7216287471739488,
            "auditor_fn_violation": 0.022186851537445772,
            "auditor_fp_violation": 0.018247870795557126,
            "ave_precision_score": 0.7229765156403403,
            "fpr": 0.14692982456140352,
            "logloss": 1.1693979630452072,
            "mae": 0.31439413462205,
            "precision": 0.7190775681341719,
            "recall": 0.7376344086021506
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.7764254477245751,
            "auditor_fn_violation": 0.013704349699985855,
            "auditor_fp_violation": 0.020897820737588512,
            "ave_precision_score": 0.7771034324551327,
            "fpr": 0.1207464324917673,
            "logloss": 0.9204391586649406,
            "mae": 0.28684813936999387,
            "precision": 0.7736625514403292,
            "recall": 0.7689161554192229
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.81188665278744,
            "auditor_fn_violation": 0.026405395208451237,
            "auditor_fp_violation": 0.017516876643510346,
            "ave_precision_score": 0.8124384315693164,
            "fpr": 0.1074561403508772,
            "logloss": 1.396906445772067,
            "mae": 0.3127428366344508,
            "precision": 0.7603911980440098,
            "recall": 0.6688172043010753
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8447237727809297,
            "auditor_fn_violation": 0.03649330271460608,
            "auditor_fp_violation": 0.016278138184693664,
            "ave_precision_score": 0.8449443575064011,
            "fpr": 0.08781558726673985,
            "logloss": 1.33637662284275,
            "mae": 0.3099659937434938,
            "precision": 0.8076923076923077,
            "recall": 0.6871165644171779
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7230909972844499,
            "auditor_fn_violation": 0.031321920392378806,
            "auditor_fp_violation": 0.012689371639389305,
            "ave_precision_score": 0.7244640613023644,
            "fpr": 0.12719298245614036,
            "logloss": 1.5964852410899393,
            "mae": 0.32009205049602785,
            "precision": 0.7351598173515982,
            "recall": 0.6924731182795699
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.77680369475881,
            "auditor_fn_violation": 0.022838338058584134,
            "auditor_fp_violation": 0.02195389681668497,
            "ave_precision_score": 0.7774274744383192,
            "fpr": 0.1141602634467618,
            "logloss": 1.4039185906720144,
            "mae": 0.3041818354309248,
            "precision": 0.775377969762419,
            "recall": 0.7341513292433538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 29759,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8178989932304742,
            "auditor_fn_violation": 0.010222127900396153,
            "auditor_fp_violation": 0.009581419992935365,
            "ave_precision_score": 0.818162897439124,
            "fpr": 0.125,
            "logloss": 0.7415704407616484,
            "mae": 0.2770314308535009,
            "precision": 0.7516339869281046,
            "recall": 0.7419354838709677
        },
        "train": {
            "accuracy": 0.7541163556531284,
            "auc_prc": 0.8449972395506651,
            "auditor_fn_violation": 0.00824056801779658,
            "auditor_fp_violation": 0.014119164919545733,
            "ave_precision_score": 0.8452829187650235,
            "fpr": 0.10537870472008781,
            "logloss": 0.6733798745734875,
            "mae": 0.27004971636466485,
            "precision": 0.7899343544857768,
            "recall": 0.7382413087934561
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7921493219469831,
            "auditor_fn_violation": 0.0056805319750990405,
            "auditor_fp_violation": 0.010067114093959733,
            "ave_precision_score": 0.7935071573465912,
            "fpr": 0.10197368421052631,
            "logloss": 0.5506130842176743,
            "mae": 0.3368783870899821,
            "precision": 0.7651515151515151,
            "recall": 0.6516129032258065
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.85171600517113,
            "auditor_fn_violation": 0.010184542930194244,
            "auditor_fp_violation": 0.0015242871486466113,
            "ave_precision_score": 0.8519395297429618,
            "fpr": 0.07464324917672886,
            "logloss": 0.5308021250294876,
            "mae": 0.3262665354974903,
            "precision": 0.820580474934037,
            "recall": 0.6359918200408998
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.8042696337716154,
            "auditor_fn_violation": 0.027506602527824952,
            "auditor_fp_violation": 0.01503444012716355,
            "ave_precision_score": 0.8046009286435096,
            "fpr": 0.06798245614035088,
            "logloss": 1.217356731825156,
            "mae": 0.32375247401814206,
            "precision": 0.8160237388724035,
            "recall": 0.5913978494623656
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8487850022000402,
            "auditor_fn_violation": 0.02823477649900444,
            "auditor_fp_violation": 0.006107553285020887,
            "ave_precision_score": 0.84899359442939,
            "fpr": 0.04720087815587267,
            "logloss": 1.1426907712447911,
            "mae": 0.3142080434269023,
            "precision": 0.8716417910447761,
            "recall": 0.5971370143149284
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8428136206580261,
            "auditor_fn_violation": 0.014523203169213362,
            "auditor_fp_violation": 0.010574885199576122,
            "ave_precision_score": 0.8430505054855452,
            "fpr": 0.0756578947368421,
            "logloss": 0.5511834621725236,
            "mae": 0.3067613700323068,
            "precision": 0.8198433420365535,
            "recall": 0.6752688172043011
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8668239642334188,
            "auditor_fn_violation": 0.009430298622381764,
            "auditor_fp_violation": 0.0133075990656588,
            "ave_precision_score": 0.8672703727523322,
            "fpr": 0.0570801317233809,
            "logloss": 0.5249133303273443,
            "mae": 0.2995306491301294,
            "precision": 0.8631578947368421,
            "recall": 0.6707566462167689
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7257575839179592,
            "auditor_fn_violation": 0.024766553480475392,
            "auditor_fp_violation": 0.013584716825621101,
            "ave_precision_score": 0.7271109432005202,
            "fpr": 0.06578947368421052,
            "logloss": 1.2052230566431616,
            "mae": 0.33208117293090206,
            "precision": 0.8136645962732919,
            "recall": 0.5634408602150538
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7890017146871463,
            "auditor_fn_violation": 0.03131685219729776,
            "auditor_fp_violation": 0.010693420594003777,
            "ave_precision_score": 0.7903368224437388,
            "fpr": 0.05159165751920966,
            "logloss": 1.0480050753070698,
            "mae": 0.3254953901119649,
            "precision": 0.8553846153846154,
            "recall": 0.5685071574642127
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8210314398657665,
            "auditor_fn_violation": 0.023804470854555754,
            "auditor_fp_violation": 0.016592095451155853,
            "ave_precision_score": 0.8213329495975747,
            "fpr": 0.0800438596491228,
            "logloss": 0.9488624487842043,
            "mae": 0.31035453832687854,
            "precision": 0.8103896103896104,
            "recall": 0.6709677419354839
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8556460054357474,
            "auditor_fn_violation": 0.03225067848316082,
            "auditor_fp_violation": 0.009379828426654739,
            "ave_precision_score": 0.8559048926907487,
            "fpr": 0.06037321624588365,
            "logloss": 0.8780351093855625,
            "mae": 0.29750178478153255,
            "precision": 0.8582474226804123,
            "recall": 0.6809815950920245
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8479019043699662,
            "auditor_fn_violation": 0.015541878890775327,
            "auditor_fp_violation": 0.006441579339848506,
            "ave_precision_score": 0.848143459232025,
            "fpr": 0.08333333333333333,
            "logloss": 0.5382155760196055,
            "mae": 0.29720401044055744,
            "precision": 0.8085642317380353,
            "recall": 0.6903225806451613
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8747733376423152,
            "auditor_fn_violation": 0.004424450984221487,
            "auditor_fp_violation": 0.01174689550049162,
            "ave_precision_score": 0.8752014326801674,
            "fpr": 0.06586169045005488,
            "logloss": 0.48754960426376137,
            "mae": 0.28308171654349085,
            "precision": 0.8511166253101737,
            "recall": 0.7014314928425358
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.798061270021249,
            "auditor_fn_violation": 0.03349132239200151,
            "auditor_fp_violation": 0.011691000431728093,
            "ave_precision_score": 0.7989577663997458,
            "fpr": 0.0581140350877193,
            "logloss": 1.366409807948387,
            "mae": 0.32278852178355844,
            "precision": 0.8413173652694611,
            "recall": 0.6043010752688172
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8499299426926651,
            "auditor_fn_violation": 0.026391816449260246,
            "auditor_fp_violation": 0.006492526831095459,
            "ave_precision_score": 0.8501635288108305,
            "fpr": 0.043907793633369926,
            "logloss": 1.2767068872266962,
            "mae": 0.3119271271201331,
            "precision": 0.8833819241982507,
            "recall": 0.6196319018404908
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 29759,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8153800914500586,
            "auditor_fn_violation": 0.02156668553103188,
            "auditor_fp_violation": 0.016072059342988346,
            "ave_precision_score": 0.8156528203722393,
            "fpr": 0.0668859649122807,
            "logloss": 1.5142965495905232,
            "mae": 0.3185242353746416,
            "precision": 0.8291316526610645,
            "recall": 0.6365591397849463
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8455621106335798,
            "auditor_fn_violation": 0.026205500147032743,
            "auditor_fp_violation": 0.008227508961039638,
            "ave_precision_score": 0.8467584905193158,
            "fpr": 0.05159165751920966,
            "logloss": 1.428690433139001,
            "mae": 0.30981393233058485,
            "precision": 0.8660968660968661,
            "recall": 0.621676891615542
        }
    }
]