[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8069821504425486,
            "auditor_fn_violation": 0.011114535319969997,
            "auditor_fp_violation": 0.02078384798099763,
            "ave_precision_score": 0.7604659015141854,
            "fpr": 0.11842105263157894,
            "logloss": 3.88055389832797,
            "mae": 0.27029295311793794,
            "precision": 0.773109243697479,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7772756242159482,
            "auditor_fn_violation": 0.010455365546606983,
            "auditor_fp_violation": 0.01830798180962835,
            "ave_precision_score": 0.7212047772160673,
            "fpr": 0.12843029637760703,
            "logloss": 4.4156154403128465,
            "mae": 0.2856567184739101,
            "precision": 0.7439824945295405,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8427266134009817,
            "auditor_fn_violation": 0.011724193375495769,
            "auditor_fp_violation": 0.019359190732174857,
            "ave_precision_score": 0.8429919643326484,
            "fpr": 0.10964912280701754,
            "logloss": 0.6890193303201051,
            "mae": 0.2739762929126362,
            "precision": 0.7830802603036876,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8316726316810484,
            "auditor_fn_violation": 0.011844672623775173,
            "auditor_fp_violation": 0.012393170769954533,
            "ave_precision_score": 0.832426843606208,
            "fpr": 0.1251372118551043,
            "logloss": 0.7081422935167234,
            "mae": 0.27924095123448045,
            "precision": 0.748898678414097,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7933950093057263,
            "auditor_fn_violation": 0.006494086540179374,
            "auditor_fp_violation": 0.02083854231778973,
            "ave_precision_score": 0.7759663350334055,
            "fpr": 0.11951754385964912,
            "logloss": 2.507052088435775,
            "mae": 0.27929920785239015,
            "precision": 0.7650862068965517,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7777357080024778,
            "auditor_fn_violation": 0.0069986936720144695,
            "auditor_fp_violation": 0.010376646542261251,
            "ave_precision_score": 0.7613182223087966,
            "fpr": 0.1394072447859495,
            "logloss": 2.495171690770011,
            "mae": 0.293350926170871,
            "precision": 0.7262931034482759,
            "recall": 0.7278617710583153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.836359413757367,
            "auditor_fn_violation": 0.004332368599707012,
            "auditor_fp_violation": 0.020385360670083764,
            "ave_precision_score": 0.8366309263323285,
            "fpr": 0.11293859649122807,
            "logloss": 0.771455794212454,
            "mae": 0.2701069515139601,
            "precision": 0.7799145299145299,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8203437199812198,
            "auditor_fn_violation": 0.009220162496769744,
            "auditor_fp_violation": 0.010462403951701432,
            "ave_precision_score": 0.820885253025255,
            "fpr": 0.13062568605927552,
            "logloss": 0.7999411834424225,
            "mae": 0.28211959644007095,
            "precision": 0.7407407407407407,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7988010950510129,
            "auditor_fn_violation": 0.008809893879301107,
            "auditor_fp_violation": 0.02520888027670126,
            "ave_precision_score": 0.7520806360667579,
            "fpr": 0.17214912280701755,
            "logloss": 4.090744765263138,
            "mae": 0.2745260273699749,
            "precision": 0.7191413237924866,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7702351938199813,
            "auditor_fn_violation": 0.00858715056911803,
            "auditor_fp_violation": 0.02085620197585071,
            "ave_precision_score": 0.7145872983932238,
            "fpr": 0.19319429198682767,
            "logloss": 4.637033998522915,
            "mae": 0.2972060217143891,
            "precision": 0.68,
            "recall": 0.8077753779697624
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.6972598935566643,
            "auditor_fn_violation": 0.004028656161789403,
            "auditor_fp_violation": 0.02802954535983665,
            "ave_precision_score": 0.6871484168353631,
            "fpr": 0.15789473684210525,
            "logloss": 2.0161363647877844,
            "mae": 0.2969753285391222,
            "precision": 0.7251908396946565,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.6711392668700651,
            "auditor_fn_violation": 0.0032575220546571457,
            "auditor_fp_violation": 0.03452838325231301,
            "ave_precision_score": 0.6545661366014086,
            "fpr": 0.1877058177826564,
            "logloss": 2.3231481052368306,
            "mae": 0.31116220531339794,
            "precision": 0.6821561338289963,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7917946641257319,
            "auditor_fn_violation": 0.008722799871368855,
            "auditor_fp_violation": 0.017499583281243496,
            "ave_precision_score": 0.7694149747553237,
            "fpr": 0.11951754385964912,
            "logloss": 2.6062757166151136,
            "mae": 0.2717753205265849,
            "precision": 0.7705263157894737,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7485710350905059,
            "auditor_fn_violation": 0.016771259835985902,
            "auditor_fp_violation": 0.01289056374470755,
            "ave_precision_score": 0.7186391460163533,
            "fpr": 0.1525795828759605,
            "logloss": 3.0639684618317276,
            "mae": 0.299678858239766,
            "precision": 0.7067510548523207,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7127066140507359,
            "auditor_fn_violation": 0.02125093793547004,
            "auditor_fp_violation": 0.05798641496853774,
            "ave_precision_score": 0.6192731356642392,
            "fpr": 0.23355263157894737,
            "logloss": 6.879778066598007,
            "mae": 0.3500598089114708,
            "precision": 0.6553398058252428,
            "recall": 0.824847250509165
        },
        "train": {
            "accuracy": 0.6586169045005489,
            "auc_prc": 0.6953777217255074,
            "auditor_fn_violation": 0.01744220506267292,
            "auditor_fp_violation": 0.06153216637917516,
            "ave_precision_score": 0.5914908975838366,
            "fpr": 0.2513721185510428,
            "logloss": 7.403082039393262,
            "mae": 0.36461043227994844,
            "precision": 0.6245901639344262,
            "recall": 0.8228941684665226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8230125496397631,
            "auditor_fn_violation": 0.0019830635652267193,
            "auditor_fp_violation": 0.0172808059340751,
            "ave_precision_score": 0.823348867163382,
            "fpr": 0.1118421052631579,
            "logloss": 0.8554939745873288,
            "mae": 0.27265132883520643,
            "precision": 0.782051282051282,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8063226440353393,
            "auditor_fn_violation": 0.012178959821523828,
            "auditor_fp_violation": 0.009291202759918453,
            "ave_precision_score": 0.8065751388064955,
            "fpr": 0.13172338090010977,
            "logloss": 0.8842589941928464,
            "mae": 0.2886168382579615,
            "precision": 0.7379912663755459,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.806154557607832,
            "auditor_fn_violation": 0.009252063458034091,
            "auditor_fp_violation": 0.023906634162603663,
            "ave_precision_score": 0.7710086632024189,
            "fpr": 0.12609649122807018,
            "logloss": 3.799731547634493,
            "mae": 0.2744961372567794,
            "precision": 0.7638603696098563,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7778020757493369,
            "auditor_fn_violation": 0.005102028720249034,
            "auditor_fp_violation": 0.01766602634467618,
            "ave_precision_score": 0.7350873457428341,
            "fpr": 0.145993413830955,
            "logloss": 4.267462204506584,
            "mae": 0.2883470027987468,
            "precision": 0.7229166666666667,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8442952568804762,
            "auditor_fn_violation": 0.012186461571443886,
            "auditor_fp_violation": 0.022070467141726054,
            "ave_precision_score": 0.8445390968322966,
            "fpr": 0.14802631578947367,
            "logloss": 0.7287800479863734,
            "mae": 0.26196440006321864,
            "precision": 0.7476635514018691,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8328937597023768,
            "auditor_fn_violation": 0.012257197250784157,
            "auditor_fp_violation": 0.006975752705033716,
            "ave_precision_score": 0.8333055768908199,
            "fpr": 0.16575192096597147,
            "logloss": 0.7727999379213844,
            "mae": 0.27753478506871737,
            "precision": 0.7084942084942085,
            "recall": 0.7926565874730022
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8061305065425676,
            "auditor_fn_violation": 0.010366420123628836,
            "auditor_fp_violation": 0.020968766929199485,
            "ave_precision_score": 0.7597924093979608,
            "fpr": 0.11293859649122807,
            "logloss": 3.890088668671414,
            "mae": 0.2699488971092901,
            "precision": 0.7784946236559139,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7775104205091593,
            "auditor_fn_violation": 0.010268069882620148,
            "auditor_fp_violation": 0.01603418535361456,
            "ave_precision_score": 0.722120162667681,
            "fpr": 0.12623490669593854,
            "logloss": 4.412423745841257,
            "mae": 0.2860060668090106,
            "precision": 0.7461368653421634,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8310217796320005,
            "auditor_fn_violation": 0.011780022867760035,
            "auditor_fp_violation": 0.019671729799558276,
            "ave_precision_score": 0.8313437736857501,
            "fpr": 0.1206140350877193,
            "logloss": 0.8284252465865762,
            "mae": 0.26729866218874837,
            "precision": 0.7693920335429769,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7387486278814489,
            "auc_prc": 0.8113688000528881,
            "auditor_fn_violation": 0.015159094626985276,
            "auditor_fp_violation": 0.015779363336992314,
            "ave_precision_score": 0.8127383973794526,
            "fpr": 0.13172338090010977,
            "logloss": 1.029729629463962,
            "mae": 0.2789143508962318,
            "precision": 0.7419354838709677,
            "recall": 0.7451403887688985
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8367072121720427,
            "auditor_fn_violation": 0.0032247114731839815,
            "auditor_fp_violation": 0.018244468058507313,
            "ave_precision_score": 0.8369875060417845,
            "fpr": 0.11951754385964912,
            "logloss": 0.7868594368201431,
            "mae": 0.2665773941872441,
            "precision": 0.7752577319587629,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8199283682628191,
            "auditor_fn_violation": 0.006507931615745166,
            "auditor_fp_violation": 0.008781558726673994,
            "ave_precision_score": 0.8203844321451776,
            "fpr": 0.14050493962678376,
            "logloss": 0.8276059854141399,
            "mae": 0.28495211447438995,
            "precision": 0.7333333333333333,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.7915872289848296,
            "auditor_fn_violation": 0.004837067209775973,
            "auditor_fp_violation": 0.017132349877067975,
            "ave_precision_score": 0.7580553138691093,
            "fpr": 0.1425438596491228,
            "logloss": 3.5602569083659623,
            "mae": 0.28593996269819205,
            "precision": 0.7405189620758483,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7520684439098014,
            "auditor_fn_violation": 0.0017188526125374265,
            "auditor_fp_violation": 0.01293956797867336,
            "ave_precision_score": 0.7076030860607526,
            "fpr": 0.16355653128430298,
            "logloss": 4.2651247025484045,
            "mae": 0.3071665922206335,
            "precision": 0.7002012072434608,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8379875017388928,
            "auditor_fn_violation": 0.008148872690892206,
            "auditor_fp_violation": 0.019861857732216527,
            "ave_precision_score": 0.8382896850244823,
            "fpr": 0.13815789473684212,
            "logloss": 0.6323835047393251,
            "mae": 0.2760851491409668,
            "precision": 0.7567567567567568,
            "recall": 0.7983706720977597
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8340811681552915,
            "auditor_fn_violation": 0.017138738670390456,
            "auditor_fp_violation": 0.013704034028540065,
            "ave_precision_score": 0.8343361909451874,
            "fpr": 0.132821075740944,
            "logloss": 0.6267365188881354,
            "mae": 0.27986063304695197,
            "precision": 0.753061224489796,
            "recall": 0.796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.837042312326931,
            "auditor_fn_violation": 0.004332368599707012,
            "auditor_fp_violation": 0.020385360670083764,
            "ave_precision_score": 0.8373118207478378,
            "fpr": 0.11293859649122807,
            "logloss": 0.7724600308575603,
            "mae": 0.2696343145008526,
            "precision": 0.7799145299145299,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8211785474279645,
            "auditor_fn_violation": 0.008985450208988775,
            "auditor_fp_violation": 0.010462403951701432,
            "ave_precision_score": 0.8216982684411074,
            "fpr": 0.13062568605927552,
            "logloss": 0.800984032329268,
            "mae": 0.28178397802679855,
            "precision": 0.740174672489083,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8012583537044377,
            "auditor_fn_violation": 0.004461893021760101,
            "auditor_fp_violation": 0.022291848981122648,
            "ave_precision_score": 0.769644401454741,
            "fpr": 0.12938596491228072,
            "logloss": 3.574731597997173,
            "mae": 0.27095728456294416,
            "precision": 0.7644710578842315,
            "recall": 0.780040733197556
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7724848097801192,
            "auditor_fn_violation": 0.011688197765254526,
            "auditor_fp_violation": 0.012579386859024624,
            "ave_precision_score": 0.7334392162790245,
            "fpr": 0.14818880351262348,
            "logloss": 4.016773854167553,
            "mae": 0.2860916768735337,
            "precision": 0.7227926078028748,
            "recall": 0.7602591792656588
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7991631769774563,
            "auditor_fn_violation": 0.0034368635437881977,
            "auditor_fp_violation": 0.01977590948868609,
            "ave_precision_score": 0.7684617167449673,
            "fpr": 0.12719298245614036,
            "logloss": 3.463166813070204,
            "mae": 0.2799417876559956,
            "precision": 0.7578288100208769,
            "recall": 0.7393075356415478
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.768409477764008,
            "auditor_fn_violation": 0.00363448421382053,
            "auditor_fp_violation": 0.008213109612670546,
            "ave_precision_score": 0.7296970787251034,
            "fpr": 0.14270032930845225,
            "logloss": 3.9224973562219545,
            "mae": 0.29381108181489474,
            "precision": 0.7257383966244726,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.837042312326931,
            "auditor_fn_violation": 0.004332368599707012,
            "auditor_fp_violation": 0.020385360670083764,
            "ave_precision_score": 0.8373118207478378,
            "fpr": 0.11293859649122807,
            "logloss": 0.7724600501612795,
            "mae": 0.2696343149640478,
            "precision": 0.7799145299145299,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8211785474279645,
            "auditor_fn_violation": 0.008985450208988775,
            "auditor_fp_violation": 0.010462403951701432,
            "ave_precision_score": 0.8216982684411074,
            "fpr": 0.13062568605927552,
            "logloss": 0.8009840440317384,
            "mae": 0.2817839783893953,
            "precision": 0.740174672489083,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8326042243937309,
            "auditor_fn_violation": 0.009830456997891878,
            "auditor_fp_violation": 0.02076040755094387,
            "ave_precision_score": 0.8329640848965958,
            "fpr": 0.15021929824561403,
            "logloss": 0.6488164385563024,
            "mae": 0.27674853361816115,
            "precision": 0.7444029850746269,
            "recall": 0.8126272912423625
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8344494849169387,
            "auditor_fn_violation": 0.016678797419587336,
            "auditor_fp_violation": 0.014211227850086263,
            "ave_precision_score": 0.8346985306064922,
            "fpr": 0.14928649835345773,
            "logloss": 0.6367934073475007,
            "mae": 0.2815394069859327,
            "precision": 0.7301587301587301,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8053230040799845,
            "auditor_fn_violation": 0.011335620109336485,
            "auditor_fp_violation": 0.022661686877526368,
            "ave_precision_score": 0.7665466464098107,
            "fpr": 0.12719298245614036,
            "logloss": 3.9483806929480934,
            "mae": 0.2737057253433663,
            "precision": 0.7627811860940695,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7783183293921188,
            "auditor_fn_violation": 0.010588132093230573,
            "auditor_fp_violation": 0.015933726673984638,
            "ave_precision_score": 0.7346074998165031,
            "fpr": 0.14818880351262348,
            "logloss": 4.353513512882979,
            "mae": 0.28942958557707155,
            "precision": 0.7199170124481328,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.803724891972889,
            "auditor_fn_violation": 0.006087647836495522,
            "auditor_fp_violation": 0.022924740592574076,
            "ave_precision_score": 0.7695432268121614,
            "fpr": 0.13267543859649122,
            "logloss": 3.78904734146506,
            "mae": 0.2771863268482735,
            "precision": 0.7535641547861507,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7748839597832203,
            "auditor_fn_violation": 0.004172662893883966,
            "auditor_fp_violation": 0.01493404030108202,
            "ave_precision_score": 0.7337904719477313,
            "fpr": 0.141602634467618,
            "logloss": 4.235376349415682,
            "mae": 0.2919149371397251,
            "precision": 0.7295597484276729,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 4719,
        "test": {
            "accuracy": 0.756578947368421,
            "auc_prc": 0.8525713746348658,
            "auditor_fn_violation": 0.004975524350591352,
            "auditor_fp_violation": 0.01828093094970205,
            "ave_precision_score": 0.8528300036804901,
            "fpr": 0.09429824561403509,
            "logloss": 0.7402358429157416,
            "mae": 0.2725356886137694,
            "precision": 0.8049886621315193,
            "recall": 0.7230142566191446
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8366971969872847,
            "auditor_fn_violation": 0.011465339633422084,
            "auditor_fp_violation": 0.010746628508703154,
            "ave_precision_score": 0.8371905628660219,
            "fpr": 0.1119648737650933,
            "logloss": 0.7598733346090534,
            "mae": 0.2783834800731788,
            "precision": 0.7681818181818182,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8307506861253102,
            "auditor_fn_violation": 0.018211580376603427,
            "auditor_fp_violation": 0.022523648789432017,
            "ave_precision_score": 0.8310343969813139,
            "fpr": 0.11074561403508772,
            "logloss": 0.9608078905840781,
            "mae": 0.2687864408001867,
            "precision": 0.7789934354485777,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8088708808609759,
            "auditor_fn_violation": 0.023570803688065006,
            "auditor_fp_violation": 0.01525011761016152,
            "ave_precision_score": 0.8095397873196647,
            "fpr": 0.1251372118551043,
            "logloss": 1.229525705923712,
            "mae": 0.2818792682648418,
            "precision": 0.7477876106194691,
            "recall": 0.7300215982721382
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8065425035563378,
            "auditor_fn_violation": 0.01264649658770144,
            "auditor_fp_violation": 0.02201577280493396,
            "ave_precision_score": 0.7684122013559425,
            "fpr": 0.12828947368421054,
            "logloss": 3.929228611016656,
            "mae": 0.2735497903623047,
            "precision": 0.7617107942973523,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7783970356847996,
            "auditor_fn_violation": 0.012513247019272492,
            "auditor_fp_violation": 0.017031421514818894,
            "ave_precision_score": 0.7346775048388736,
            "fpr": 0.14818880351262348,
            "logloss": 4.35651620980136,
            "mae": 0.28936156775445004,
            "precision": 0.7199170124481328,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 4719,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8482053065440205,
            "auditor_fn_violation": 0.012186461571443886,
            "auditor_fp_violation": 0.02076040755094387,
            "ave_precision_score": 0.8484408858875725,
            "fpr": 0.15021929824561403,
            "logloss": 0.715582801814198,
            "mae": 0.2618753135988122,
            "precision": 0.74487895716946,
            "recall": 0.814663951120163
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.8370463228286567,
            "auditor_fn_violation": 0.005772973946936057,
            "auditor_fp_violation": 0.006926748471067902,
            "ave_precision_score": 0.8374223828010009,
            "fpr": 0.16575192096597147,
            "logloss": 0.7617965388371724,
            "mae": 0.2768502096566376,
            "precision": 0.710172744721689,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.8010014740471801,
            "auditor_fn_violation": 0.009343623825347485,
            "auditor_fp_violation": 0.019135204400550075,
            "ave_precision_score": 0.8014903688668931,
            "fpr": 0.12609649122807018,
            "logloss": 0.8839269854570159,
            "mae": 0.28083517027383625,
            "precision": 0.7648261758691206,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.7986258401485501,
            "auditor_fn_violation": 0.009554449694518402,
            "auditor_fp_violation": 0.016168946997020553,
            "ave_precision_score": 0.7990045587577732,
            "fpr": 0.141602634467618,
            "logloss": 0.8521723091517412,
            "mae": 0.2835040022790909,
            "precision": 0.736734693877551,
            "recall": 0.7796976241900648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8121565921441565,
            "auditor_fn_violation": 0.00782506163575946,
            "auditor_fp_violation": 0.022534066758344795,
            "ave_precision_score": 0.8125439676713553,
            "fpr": 0.1162280701754386,
            "logloss": 1.0000514751049436,
            "mae": 0.27253602518041714,
            "precision": 0.7763713080168776,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7955795722895987,
            "auditor_fn_violation": 0.009447762290981595,
            "auditor_fp_violation": 0.013481064763995609,
            "ave_precision_score": 0.7957564054352735,
            "fpr": 0.13062568605927552,
            "logloss": 1.0244270259253345,
            "mae": 0.28707295211015965,
            "precision": 0.7418655097613883,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 4719,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8080155534573747,
            "auditor_fn_violation": 0.009696466216457646,
            "auditor_fp_violation": 0.02021346418302287,
            "ave_precision_score": 0.7629903905825404,
            "fpr": 0.12280701754385964,
            "logloss": 3.7666255037652774,
            "mae": 0.26704995269065573,
            "precision": 0.7700205338809035,
            "recall": 0.7637474541751528
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7779312596237198,
            "auditor_fn_violation": 0.008670129660757772,
            "auditor_fp_violation": 0.017661125921279597,
            "ave_precision_score": 0.7226842016741222,
            "fpr": 0.13172338090010977,
            "logloss": 4.318195918759553,
            "mae": 0.28305693366097323,
            "precision": 0.7430406852248393,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5921052631578947,
            "auc_prc": 0.6373817566146458,
            "auditor_fn_violation": 0.005502554757566012,
            "auditor_fp_violation": 0.006032004000500061,
            "ave_precision_score": 0.5517758141624103,
            "fpr": 0.3508771929824561,
            "logloss": 7.226174474174645,
            "mae": 0.42059499613063517,
            "precision": 0.5783926218708827,
            "recall": 0.8940936863543788
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.628324394274759,
            "auditor_fn_violation": 0.008070309369761943,
            "auditor_fp_violation": 0.009242198525952662,
            "ave_precision_score": 0.5346757459442011,
            "fpr": 0.36553238199780463,
            "logloss": 7.642509773685521,
            "mae": 0.43256440956895514,
            "precision": 0.5554072096128171,
            "recall": 0.8984881209503239
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8039970323999163,
            "auditor_fn_violation": 0.009191767606388686,
            "auditor_fp_violation": 0.026758553152477396,
            "ave_precision_score": 0.766071579962001,
            "fpr": 0.15679824561403508,
            "logloss": 3.868553835780205,
            "mae": 0.2750548175295784,
            "precision": 0.7356746765249538,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7776965091020638,
            "auditor_fn_violation": 0.007543984845647041,
            "auditor_fp_violation": 0.014042163242904186,
            "ave_precision_score": 0.7341802806061385,
            "fpr": 0.17453347969264543,
            "logloss": 4.285999803146653,
            "mae": 0.2948112980848283,
            "precision": 0.693050193050193,
            "recall": 0.775377969762419
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7620614035087719,
            "auc_prc": 0.8131820420623129,
            "auditor_fn_violation": 0.013803283667417015,
            "auditor_fp_violation": 0.017736592074009253,
            "ave_precision_score": 0.7665480786307319,
            "fpr": 0.1074561403508772,
            "logloss": 3.725709776773098,
            "mae": 0.2636850823836484,
            "precision": 0.7914893617021277,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.7827000007027518,
            "auditor_fn_violation": 0.013274283831168377,
            "auditor_fp_violation": 0.010609416653598875,
            "ave_precision_score": 0.7235974169611158,
            "fpr": 0.12843029637760703,
            "logloss": 4.346998373997302,
            "mae": 0.2830090022609122,
            "precision": 0.7456521739130435,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6929824561403509,
            "auc_prc": 0.7632942101416387,
            "auditor_fn_violation": 0.02255958123414444,
            "auditor_fp_violation": 0.02131516439554945,
            "ave_precision_score": 0.7647414531683213,
            "fpr": 0.08223684210526316,
            "logloss": 1.307092103394678,
            "mae": 0.3416212464463313,
            "precision": 0.7922437673130194,
            "recall": 0.5824847250509165
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7408006063655264,
            "auditor_fn_violation": 0.020455531504790268,
            "auditor_fp_violation": 0.021473655323819976,
            "ave_precision_score": 0.7423525049885542,
            "fpr": 0.09220636663007684,
            "logloss": 1.3070480941465534,
            "mae": 0.34673699274261893,
            "precision": 0.7565217391304347,
            "recall": 0.5637149028077754
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 4719,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7883185638687571,
            "auditor_fn_violation": 0.027686961803694583,
            "auditor_fp_violation": 0.025766241613535027,
            "ave_precision_score": 0.7564478090334213,
            "fpr": 0.08552631578947369,
            "logloss": 5.541390610168042,
            "mae": 0.30650154274654345,
            "precision": 0.7941952506596306,
            "recall": 0.6130346232179226
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7553683774462531,
            "auditor_fn_violation": 0.036653050192867125,
            "auditor_fp_violation": 0.02093460875019602,
            "ave_precision_score": 0.7170459345146285,
            "fpr": 0.08781558726673985,
            "logloss": 6.032829589098222,
            "mae": 0.3111568585269512,
            "precision": 0.7714285714285715,
            "recall": 0.5831533477321814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.855751714254746,
            "auditor_fn_violation": 0.012175295672991037,
            "auditor_fp_violation": 0.02288046422469476,
            "ave_precision_score": 0.8559588705350176,
            "fpr": 0.15570175438596492,
            "logloss": 0.7620677390981142,
            "mae": 0.2599485091934539,
            "precision": 0.7422867513611615,
            "recall": 0.8329938900203666
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8299046412159059,
            "auditor_fn_violation": 0.010732752795802682,
            "auditor_fp_violation": 0.02093460875019602,
            "ave_precision_score": 0.8305044159373541,
            "fpr": 0.1734357848518112,
            "logloss": 0.8280309024384497,
            "mae": 0.2811998535460914,
            "precision": 0.7013232514177694,
            "recall": 0.8012958963282938
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7937375098363789,
            "auditor_fn_violation": 0.0020969557294458143,
            "auditor_fp_violation": 0.021526128266033256,
            "ave_precision_score": 0.7755943598075208,
            "fpr": 0.11513157894736842,
            "logloss": 2.53038990014573,
            "mae": 0.280263379545004,
            "precision": 0.7722342733188721,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.7822075746784649,
            "auditor_fn_violation": 0.0065648315642981335,
            "auditor_fp_violation": 0.01476007527050338,
            "ave_precision_score": 0.7656170437762357,
            "fpr": 0.13172338090010977,
            "logloss": 2.4908686520015673,
            "mae": 0.29250843208709476,
            "precision": 0.7368421052631579,
            "recall": 0.7257019438444925
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.806659255341851,
            "auditor_fn_violation": 0.012110533461964489,
            "auditor_fp_violation": 0.023659207400925118,
            "ave_precision_score": 0.7601558561578579,
            "fpr": 0.12171052631578948,
            "logloss": 3.868760240501265,
            "mae": 0.27128492048320674,
            "precision": 0.7692307692307693,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7771209711206146,
            "auditor_fn_violation": 0.007745505496772119,
            "auditor_fp_violation": 0.012363768229575038,
            "ave_precision_score": 0.7211177220843497,
            "fpr": 0.12952799121844127,
            "logloss": 4.405552408749558,
            "mae": 0.2866994938167572,
            "precision": 0.74235807860262,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7969919407696138,
            "auditor_fn_violation": 0.010766159288240968,
            "auditor_fp_violation": 0.018622119431595613,
            "ave_precision_score": 0.7772623382132001,
            "fpr": 0.11403508771929824,
            "logloss": 2.6073739125603783,
            "mae": 0.27325183487252325,
            "precision": 0.776824034334764,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7823676764536271,
            "auditor_fn_violation": 0.011425035503197064,
            "auditor_fp_violation": 0.011405735455543364,
            "ave_precision_score": 0.7649113001463173,
            "fpr": 0.13062568605927552,
            "logloss": 2.5840448307921036,
            "mae": 0.28693466288409697,
            "precision": 0.741304347826087,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 4719,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8551551794650063,
            "auditor_fn_violation": 0.013148962018079824,
            "auditor_fp_violation": 0.02307840563403759,
            "ave_precision_score": 0.8553652065150519,
            "fpr": 0.15679824561403508,
            "logloss": 0.7652350192262714,
            "mae": 0.26055600419192965,
            "precision": 0.7395264116575592,
            "recall": 0.8268839103869654
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.8292052134474783,
            "auditor_fn_violation": 0.010839440199339485,
            "auditor_fp_violation": 0.026040849929433906,
            "ave_precision_score": 0.829874166538972,
            "fpr": 0.17453347969264543,
            "logloss": 0.834077276402222,
            "mae": 0.2826496529259814,
            "precision": 0.6994328922495274,
            "recall": 0.7991360691144709
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8448060993054018,
            "auditor_fn_violation": 0.004466359381141246,
            "auditor_fp_violation": 0.022409051131391425,
            "ave_precision_score": 0.8450554138610289,
            "fpr": 0.12609649122807018,
            "logloss": 0.7434804723272083,
            "mae": 0.26290610990883173,
            "precision": 0.77,
            "recall": 0.7841140529531568
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8231261742935139,
            "auditor_fn_violation": 0.010915306797410112,
            "auditor_fp_violation": 0.012853810569233183,
            "ave_precision_score": 0.8239439539593008,
            "fpr": 0.1525795828759605,
            "logloss": 0.7893030959741614,
            "mae": 0.2819911997769018,
            "precision": 0.7186234817813765,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8124648025500105,
            "auditor_fn_violation": 0.010918015507199773,
            "auditor_fp_violation": 0.016853669208651084,
            "ave_precision_score": 0.8129035716892409,
            "fpr": 0.11403508771929824,
            "logloss": 0.9494835454835369,
            "mae": 0.2857133055063937,
            "precision": 0.7744034707158352,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7990104669232917,
            "auditor_fn_violation": 0.008980708546609362,
            "auditor_fp_violation": 0.012476477967696412,
            "ave_precision_score": 0.7994348390268307,
            "fpr": 0.1437980241492865,
            "logloss": 1.0465703711095085,
            "mae": 0.30240774391429615,
            "precision": 0.7182795698924731,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8207162060309381,
            "auditor_fn_violation": 0.004184978740129353,
            "auditor_fp_violation": 0.02351335583614619,
            "ave_precision_score": 0.8210611771187476,
            "fpr": 0.13925438596491227,
            "logloss": 0.8737386692097807,
            "mae": 0.27179387563296736,
            "precision": 0.7490118577075099,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8115569720666427,
            "auditor_fn_violation": 0.004940812199348974,
            "auditor_fp_violation": 0.015083503214677751,
            "ave_precision_score": 0.8119638510401251,
            "fpr": 0.1525795828759605,
            "logloss": 0.9129666990409814,
            "mae": 0.28815642239199785,
            "precision": 0.719758064516129,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7930970051599431,
            "auditor_fn_violation": 0.006826830314074388,
            "auditor_fp_violation": 0.021466224944784777,
            "ave_precision_score": 0.775331028776536,
            "fpr": 0.12828947368421054,
            "logloss": 2.3508994581937195,
            "mae": 0.27244086519831834,
            "precision": 0.7607361963190185,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.7798792607230941,
            "auditor_fn_violation": 0.00636805257555246,
            "auditor_fp_violation": 0.011606652814803204,
            "ave_precision_score": 0.7644145528867887,
            "fpr": 0.141602634467618,
            "logloss": 2.3000068206188518,
            "mae": 0.28769582995124515,
            "precision": 0.7295597484276729,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7264265931424847,
            "auditor_fn_violation": 0.00637349483688856,
            "auditor_fp_violation": 0.01551496020335875,
            "ave_precision_score": 0.72567856366433,
            "fpr": 0.15350877192982457,
            "logloss": 1.2907835819412417,
            "mae": 0.3175172484921508,
            "precision": 0.716024340770791,
            "recall": 0.7189409368635438
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.632822324030635,
            "auditor_fn_violation": 0.0025604976848833424,
            "auditor_fp_violation": 0.016926062411792387,
            "ave_precision_score": 0.632890449612277,
            "fpr": 0.19099890230515917,
            "logloss": 2.0910909463041816,
            "mae": 0.3536015072718373,
            "precision": 0.6581532416502947,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8072093641887428,
            "auditor_fn_violation": 0.007778164862257482,
            "auditor_fp_violation": 0.025240134183439598,
            "ave_precision_score": 0.7726921991012067,
            "fpr": 0.12390350877192982,
            "logloss": 3.797939899202094,
            "mae": 0.2757971471580231,
            "precision": 0.7655601659751037,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.7775152978911049,
            "auditor_fn_violation": 0.005822761401919904,
            "auditor_fp_violation": 0.0141450721342324,
            "ave_precision_score": 0.7347938720310956,
            "fpr": 0.1437980241492865,
            "logloss": 4.277532729684889,
            "mae": 0.28951838432151983,
            "precision": 0.7265135699373695,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8270628891033653,
            "auditor_fn_violation": 0.00565441097652482,
            "auditor_fp_violation": 0.021922011084718928,
            "ave_precision_score": 0.8273719876179655,
            "fpr": 0.13706140350877194,
            "logloss": 0.8210251995669463,
            "mae": 0.26651954891873314,
            "precision": 0.7577519379844961,
            "recall": 0.7963340122199593
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8186477611576424,
            "auditor_fn_violation": 0.005426832593238865,
            "auditor_fp_violation": 0.012623490669593859,
            "ave_precision_score": 0.8190895584830946,
            "fpr": 0.15806805708013172,
            "logloss": 0.858826451792884,
            "mae": 0.2812795354508883,
            "precision": 0.7170923379174853,
            "recall": 0.7883369330453563
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8277483880970107,
            "auditor_fn_violation": 0.002934398113409805,
            "auditor_fp_violation": 0.020763012043172067,
            "ave_precision_score": 0.828069182944132,
            "fpr": 0.12938596491228072,
            "logloss": 0.8133973213410458,
            "mae": 0.26931379046638315,
            "precision": 0.7625754527162978,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8136294458146711,
            "auditor_fn_violation": 0.009542595538569874,
            "auditor_fp_violation": 0.015063901521091433,
            "ave_precision_score": 0.8140407390760236,
            "fpr": 0.150384193194292,
            "logloss": 0.8574700708562476,
            "mae": 0.2882335813387081,
            "precision": 0.7226720647773279,
            "recall": 0.7710583153347732
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7767238646836607,
            "auditor_fn_violation": 0.019839568371029407,
            "auditor_fp_violation": 0.018741926074092596,
            "ave_precision_score": 0.7778338201537491,
            "fpr": 0.09210526315789473,
            "logloss": 1.1561132853586102,
            "mae": 0.3278623785386338,
            "precision": 0.7823834196891192,
            "recall": 0.615071283095723
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.76478383022595,
            "auditor_fn_violation": 0.024971964921181727,
            "auditor_fp_violation": 0.02134624431550886,
            "ave_precision_score": 0.765296064349559,
            "fpr": 0.10098792535675083,
            "logloss": 1.143881612724,
            "mae": 0.3341817940969883,
            "precision": 0.7520215633423181,
            "recall": 0.6025917926565875
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8314238844836965,
            "auditor_fn_violation": 0.015822078107692854,
            "auditor_fp_violation": 0.023693065799891652,
            "ave_precision_score": 0.8316978367548289,
            "fpr": 0.1206140350877193,
            "logloss": 0.8677161042865734,
            "mae": 0.267456165587994,
            "precision": 0.7689075630252101,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8106333831031157,
            "auditor_fn_violation": 0.015064261379397004,
            "auditor_fp_violation": 0.01313313470283833,
            "ave_precision_score": 0.8113618116149461,
            "fpr": 0.12843029637760703,
            "logloss": 0.9247462846622932,
            "mae": 0.2785127775630194,
            "precision": 0.7483870967741936,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8209823342670929,
            "auditor_fn_violation": 0.0014671990567048973,
            "auditor_fp_violation": 0.022218923198733184,
            "ave_precision_score": 0.8213378443708286,
            "fpr": 0.13486842105263158,
            "logloss": 0.8671809208836031,
            "mae": 0.27249928094718945,
            "precision": 0.7535070140280561,
            "recall": 0.7657841140529531
        },
        "train": {
            "accuracy": 0.7321624588364435,
            "auc_prc": 0.807731812683981,
            "auditor_fn_violation": 0.005685253192916905,
            "auditor_fp_violation": 0.011682609377450212,
            "ave_precision_score": 0.8081564698274781,
            "fpr": 0.14928649835345773,
            "logloss": 0.9078227830203236,
            "mae": 0.28935562684579463,
            "precision": 0.7230142566191446,
            "recall": 0.7667386609071274
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8024808642211063,
            "auditor_fn_violation": 0.004263140029299324,
            "auditor_fp_violation": 0.01989832062341126,
            "ave_precision_score": 0.7683836176157866,
            "fpr": 0.12719298245614036,
            "logloss": 3.7798490686064534,
            "mae": 0.2784368630139265,
            "precision": 0.7603305785123967,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7736871922285498,
            "auditor_fn_violation": 0.00709115608841304,
            "auditor_fp_violation": 0.008715403010820136,
            "ave_precision_score": 0.7320115372245183,
            "fpr": 0.141602634467618,
            "logloss": 4.246650658562363,
            "mae": 0.2916470735998597,
            "precision": 0.7266949152542372,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7923579104030103,
            "auditor_fn_violation": 0.00441276306856755,
            "auditor_fp_violation": 0.023440430053756723,
            "ave_precision_score": 0.7743310236562857,
            "fpr": 0.1337719298245614,
            "logloss": 2.487415229179135,
            "mae": 0.2759091888917612,
            "precision": 0.7505112474437627,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.775929924717478,
            "auditor_fn_violation": 0.0039782547363280095,
            "auditor_fp_violation": 0.009009428414615023,
            "ave_precision_score": 0.7588545747588794,
            "fpr": 0.1437980241492865,
            "logloss": 2.494625672757515,
            "mae": 0.2913002855349039,
            "precision": 0.7242105263157895,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 4719,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8611539771704191,
            "auditor_fn_violation": 0.009470915067710013,
            "auditor_fp_violation": 0.010829478684835605,
            "ave_precision_score": 0.8598769664351947,
            "fpr": 0.08114035087719298,
            "logloss": 1.7536664265977602,
            "mae": 0.26588879479155975,
            "precision": 0.8271028037383178,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8378965422666926,
            "auditor_fn_violation": 0.010113965855289203,
            "auditor_fp_violation": 0.007093362866551675,
            "ave_precision_score": 0.8372036073351536,
            "fpr": 0.09110867178924259,
            "logloss": 1.970265243435617,
            "mae": 0.2700962050902568,
            "precision": 0.8004807692307693,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7693715945985689,
            "auditor_fn_violation": 0.005203308679029545,
            "auditor_fp_violation": 0.02542765762386965,
            "ave_precision_score": 0.7362254910170141,
            "fpr": 0.14364035087719298,
            "logloss": 3.4001034477146646,
            "mae": 0.2866174314340319,
            "precision": 0.7390438247011952,
            "recall": 0.7556008146639511
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7461578616893018,
            "auditor_fn_violation": 0.0077170555224956375,
            "auditor_fp_violation": 0.01913125294025404,
            "ave_precision_score": 0.7069542745531853,
            "fpr": 0.16465422612513722,
            "logloss": 3.759243571666113,
            "mae": 0.3029324928839454,
            "precision": 0.7017892644135189,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.801291623941881,
            "auditor_fn_violation": 0.010315056990745707,
            "auditor_fp_violation": 0.017150581322665337,
            "ave_precision_score": 0.7548827829795605,
            "fpr": 0.11842105263157894,
            "logloss": 3.9326227620053884,
            "mae": 0.27987391516908544,
            "precision": 0.7677419354838709,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7728427019495315,
            "auditor_fn_violation": 0.008978337715419652,
            "auditor_fp_violation": 0.013765289320997331,
            "ave_precision_score": 0.7167583222952858,
            "fpr": 0.1394072447859495,
            "logloss": 4.4630107673044215,
            "mae": 0.2954659320886408,
            "precision": 0.7251082251082251,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7924564166820933,
            "auditor_fn_violation": 0.0040755529352913865,
            "auditor_fp_violation": 0.02354200525065634,
            "ave_precision_score": 0.7736838243412488,
            "fpr": 0.12828947368421054,
            "logloss": 2.5363780669453346,
            "mae": 0.27539983964087233,
            "precision": 0.7577639751552795,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7763669600777492,
            "auditor_fn_violation": 0.0040825713086751125,
            "auditor_fp_violation": 0.011192567037792069,
            "ave_precision_score": 0.7592028686861769,
            "fpr": 0.14270032930845225,
            "logloss": 2.5251011060472557,
            "mae": 0.291723858184231,
            "precision": 0.7251585623678647,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7986404344326876,
            "auditor_fn_violation": 0.008809893879301107,
            "auditor_fp_violation": 0.024542130266283296,
            "ave_precision_score": 0.751915686427424,
            "fpr": 0.17214912280701755,
            "logloss": 4.082401597868975,
            "mae": 0.275349789235399,
            "precision": 0.7191413237924866,
            "recall": 0.8187372708757638
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7705850530642806,
            "auditor_fn_violation": 0.008122467655935498,
            "auditor_fp_violation": 0.019158205268935236,
            "ave_precision_score": 0.7149458983737907,
            "fpr": 0.1877058177826564,
            "logloss": 4.6222442415486675,
            "mae": 0.29674376360390686,
            "precision": 0.6856617647058824,
            "recall": 0.8056155507559395
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7941271371055834,
            "auditor_fn_violation": 0.015411173044627868,
            "auditor_fp_violation": 0.018319998333124976,
            "ave_precision_score": 0.7475489648005406,
            "fpr": 0.12390350877192982,
            "logloss": 3.9531581611991427,
            "mae": 0.2988986537241484,
            "precision": 0.7521929824561403,
            "recall": 0.6985743380855397
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.7694827867652687,
            "auditor_fn_violation": 0.015227848731486773,
            "auditor_fp_violation": 0.013015524541320378,
            "ave_precision_score": 0.7131194635657405,
            "fpr": 0.14050493962678376,
            "logloss": 4.471252331367106,
            "mae": 0.30891926289416727,
            "precision": 0.7149220489977728,
            "recall": 0.693304535637149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8007881993601879,
            "auditor_fn_violation": 0.006109979633401225,
            "auditor_fp_violation": 0.019273242488644413,
            "ave_precision_score": 0.7661717324969094,
            "fpr": 0.13157894736842105,
            "logloss": 3.7974486681256283,
            "mae": 0.2793876831002334,
            "precision": 0.754601226993865,
            "recall": 0.7515274949083504
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7712019405510036,
            "auditor_fn_violation": 0.004997712147901931,
            "auditor_fp_violation": 0.012322114630704092,
            "ave_precision_score": 0.7290803842114053,
            "fpr": 0.14818880351262348,
            "logloss": 4.2661491344890665,
            "mae": 0.2935638406686973,
            "precision": 0.7204968944099379,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7923450196823614,
            "auditor_fn_violation": 0.0040755529352913865,
            "auditor_fp_violation": 0.02402123182064425,
            "ave_precision_score": 0.7743625336839534,
            "fpr": 0.13267543859649122,
            "logloss": 2.442403824061257,
            "mae": 0.2758827940326995,
            "precision": 0.7515400410677618,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7756662106936746,
            "auditor_fn_violation": 0.006266106834395071,
            "auditor_fp_violation": 0.00987925356750824,
            "ave_precision_score": 0.7586591426895277,
            "fpr": 0.14489571899012074,
            "logloss": 2.4429904269583584,
            "mae": 0.29167086120659685,
            "precision": 0.7226890756302521,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.8721079296561649,
            "auditor_fn_violation": 0.006592346446564474,
            "auditor_fp_violation": 0.008870900529232824,
            "ave_precision_score": 0.8722916041041662,
            "fpr": 0.0756578947368421,
            "logloss": 0.4971438609779202,
            "mae": 0.28791617823733023,
            "precision": 0.8368794326241135,
            "recall": 0.7209775967413442
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8432171920458889,
            "auditor_fn_violation": 0.009367154030531576,
            "auditor_fp_violation": 0.010957346714756157,
            "ave_precision_score": 0.8438976265201383,
            "fpr": 0.07135016465422613,
            "logloss": 0.5053014016146361,
            "mae": 0.2903676320830387,
            "precision": 0.8320413436692506,
            "recall": 0.6954643628509719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8577438159945817,
            "auditor_fn_violation": 0.01583324400614571,
            "auditor_fp_violation": 0.021278701504354722,
            "ave_precision_score": 0.8579392706854534,
            "fpr": 0.11951754385964912,
            "logloss": 0.6733341481825825,
            "mae": 0.26437237880269016,
            "precision": 0.7743271221532091,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8312292455356197,
            "auditor_fn_violation": 0.012883096684866749,
            "auditor_fp_violation": 0.013593774502116988,
            "ave_precision_score": 0.8318517775455652,
            "fpr": 0.12733260153677278,
            "logloss": 0.729384239780777,
            "mae": 0.2760352870832755,
            "precision": 0.75,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8299203880466788,
            "auditor_fn_violation": 0.01531067995855219,
            "auditor_fp_violation": 0.020140538400633415,
            "ave_precision_score": 0.8302168213802485,
            "fpr": 0.10964912280701754,
            "logloss": 0.9464968771560193,
            "mae": 0.2698096537471966,
            "precision": 0.7811816192560175,
            "recall": 0.7270875763747454
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.80709548332638,
            "auditor_fn_violation": 0.023350316387422267,
            "auditor_fp_violation": 0.015590697036223932,
            "ave_precision_score": 0.8078004373926657,
            "fpr": 0.12403951701427003,
            "logloss": 1.1778349416584488,
            "mae": 0.2836380843897141,
            "precision": 0.7472035794183445,
            "recall": 0.7213822894168467
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8307949639790512,
            "auditor_fn_violation": 0.017088290992246402,
            "auditor_fp_violation": 0.01907009209484519,
            "ave_precision_score": 0.8310848685039449,
            "fpr": 0.1074561403508772,
            "logloss": 0.9544932556729473,
            "mae": 0.2696503803062322,
            "precision": 0.7841409691629956,
            "recall": 0.725050916496945
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8071586233465792,
            "auditor_fn_violation": 0.022691225316683775,
            "auditor_fp_violation": 0.015465736239611106,
            "ave_precision_score": 0.8078063221383633,
            "fpr": 0.1207464324917673,
            "logloss": 1.2045431554346355,
            "mae": 0.28418899812092896,
            "precision": 0.751131221719457,
            "recall": 0.7170626349892009
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.807716365004578,
            "auditor_fn_violation": 0.027532872405045206,
            "auditor_fp_violation": 0.01903362920365046,
            "ave_precision_score": 0.8061364635656686,
            "fpr": 0.12609649122807018,
            "logloss": 3.5649803769234585,
            "mae": 0.31140330352039247,
            "precision": 0.7466960352422908,
            "recall": 0.6904276985743381
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7858554492761947,
            "auditor_fn_violation": 0.04019270115909938,
            "auditor_fp_violation": 0.02736151403481261,
            "ave_precision_score": 0.7841859830575971,
            "fpr": 0.1437980241492865,
            "logloss": 3.7514626670657205,
            "mae": 0.31882199057397154,
            "precision": 0.704954954954955,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.8403783873987689,
            "auditor_fn_violation": 0.008984081895165617,
            "auditor_fp_violation": 0.02444315956161187,
            "ave_precision_score": 0.8406189865481742,
            "fpr": 0.14583333333333334,
            "logloss": 0.7546930031991228,
            "mae": 0.26351646446311916,
            "precision": 0.7495291902071564,
            "recall": 0.8105906313645621
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.8211012014769439,
            "auditor_fn_violation": 0.008440159035356214,
            "auditor_fp_violation": 0.01777383565940098,
            "ave_precision_score": 0.8217970588629525,
            "fpr": 0.1602634467618002,
            "logloss": 0.7990623368426067,
            "mae": 0.27998973865622717,
            "precision": 0.71484375,
            "recall": 0.7904967602591793
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8069922357739298,
            "auditor_fn_violation": 0.010596437631757601,
            "auditor_fp_violation": 0.02630537150477143,
            "ave_precision_score": 0.7721417885863762,
            "fpr": 0.16885964912280702,
            "logloss": 3.7398012784300114,
            "mae": 0.27405940827685427,
            "precision": 0.7240143369175627,
            "recall": 0.8228105906313645
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.7792779582742642,
            "auditor_fn_violation": 0.007389880818316096,
            "auditor_fp_violation": 0.021240885212482363,
            "ave_precision_score": 0.7368171843457265,
            "fpr": 0.18990120746432493,
            "logloss": 4.209056819833682,
            "mae": 0.29749404596812834,
            "precision": 0.6802218114602587,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7687182141823582,
            "auditor_fn_violation": 0.005585182406117128,
            "auditor_fp_violation": 0.010535171063049556,
            "ave_precision_score": 0.7691124385571708,
            "fpr": 0.27850877192982454,
            "logloss": 0.8391188030444419,
            "mae": 0.36558255549135266,
            "precision": 0.6308139534883721,
            "recall": 0.8839103869653768
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7535731555807779,
            "auditor_fn_violation": 0.005891515506421395,
            "auditor_fp_violation": 0.012630841304688735,
            "ave_precision_score": 0.7539371115488032,
            "fpr": 0.29527991218441274,
            "logloss": 0.9018372856245241,
            "mae": 0.3864114324810289,
            "precision": 0.6020710059171598,
            "recall": 0.8790496760259179
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8052015607753396,
            "auditor_fn_violation": 0.010717029335048424,
            "auditor_fp_violation": 0.02036192024003001,
            "ave_precision_score": 0.7586471922480365,
            "fpr": 0.11293859649122807,
            "logloss": 3.9037754594394034,
            "mae": 0.27479954642608484,
            "precision": 0.7799145299145299,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7766105398919843,
            "auditor_fn_violation": 0.005934190467836119,
            "auditor_fp_violation": 0.01077358083738435,
            "ave_precision_score": 0.7211159335025809,
            "fpr": 0.12403951701427003,
            "logloss": 4.415300459702851,
            "mae": 0.28948689025288943,
            "precision": 0.7466367713004485,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8110814815449968,
            "auditor_fn_violation": 0.007742433987208352,
            "auditor_fp_violation": 0.022974225944909787,
            "ave_precision_score": 0.8114677664259067,
            "fpr": 0.11732456140350878,
            "logloss": 1.0262853704260964,
            "mae": 0.27271969469637697,
            "precision": 0.772823779193206,
            "recall": 0.7413441955193483
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7939451974693316,
            "auditor_fn_violation": 0.009082654287766754,
            "auditor_fp_violation": 0.013481064763995609,
            "ave_precision_score": 0.7936363115739149,
            "fpr": 0.13062568605927552,
            "logloss": 1.0506005446868472,
            "mae": 0.2871750692074024,
            "precision": 0.7424242424242424,
            "recall": 0.7408207343412527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8233171215514358,
            "auditor_fn_violation": 0.007257833994354523,
            "auditor_fp_violation": 0.02175011459765804,
            "ave_precision_score": 0.8236390840926999,
            "fpr": 0.13048245614035087,
            "logloss": 0.8548132341607932,
            "mae": 0.273055099758725,
            "precision": 0.7576374745417516,
            "recall": 0.7576374745417516
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8085501010175523,
            "auditor_fn_violation": 0.00884320033760636,
            "auditor_fp_violation": 0.015274619727144431,
            "ave_precision_score": 0.8089937840725947,
            "fpr": 0.14709110867178923,
            "logloss": 0.89423707551913,
            "mae": 0.289605126214399,
            "precision": 0.7219917012448133,
            "recall": 0.7516198704103672
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8188545418812504,
            "auditor_fn_violation": 0.005623146460856828,
            "auditor_fp_violation": 0.019111763970496323,
            "ave_precision_score": 0.819213542724804,
            "fpr": 0.10964912280701754,
            "logloss": 0.9370847327089086,
            "mae": 0.27096291292912833,
            "precision": 0.7863247863247863,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8005898237362694,
            "auditor_fn_violation": 0.011892089247569303,
            "auditor_fp_violation": 0.012986122000940884,
            "ave_precision_score": 0.8009332767939401,
            "fpr": 0.12843029637760703,
            "logloss": 0.9707892203549668,
            "mae": 0.287451393602707,
            "precision": 0.7445414847161572,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.836007756847769,
            "auditor_fn_violation": 0.004281005466823888,
            "auditor_fp_violation": 0.02048433137475518,
            "ave_precision_score": 0.8362806285829544,
            "fpr": 0.11732456140350878,
            "logloss": 0.7841613754317897,
            "mae": 0.26392650067570583,
            "precision": 0.779835390946502,
            "recall": 0.7718940936863544
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8190935119563956,
            "auditor_fn_violation": 0.011745097713807485,
            "auditor_fp_violation": 0.01501489728712561,
            "ave_precision_score": 0.8195195119676553,
            "fpr": 0.14270032930845225,
            "logloss": 0.8337644933935021,
            "mae": 0.27949287244260934,
            "precision": 0.7297297297297297,
            "recall": 0.7580993520518359
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7631578947368421,
            "auc_prc": 0.8741819542586442,
            "auditor_fn_violation": 0.009794726122842747,
            "auditor_fp_violation": 0.01415801975246906,
            "ave_precision_score": 0.874383581331188,
            "fpr": 0.07675438596491228,
            "logloss": 0.48494914318588017,
            "mae": 0.286167306969506,
            "precision": 0.8313253012048193,
            "recall": 0.7026476578411406
        },
        "train": {
            "accuracy": 0.7738748627881449,
            "auc_prc": 0.8555836441579071,
            "auditor_fn_violation": 0.012482426213806306,
            "auditor_fp_violation": 0.01387799905911871,
            "ave_precision_score": 0.8562917596203857,
            "fpr": 0.08342480790340286,
            "logloss": 0.4994191933632619,
            "mae": 0.2896048079656783,
            "precision": 0.8141809290953546,
            "recall": 0.7192224622030238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8062300248554497,
            "auditor_fn_violation": 0.005971522492585848,
            "auditor_fp_violation": 0.0175490686335792,
            "ave_precision_score": 0.7598919452691457,
            "fpr": 0.11951754385964912,
            "logloss": 3.8956536605647956,
            "mae": 0.26943569803103756,
            "precision": 0.7738589211618258,
            "recall": 0.7596741344195519
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7778499778744252,
            "auditor_fn_violation": 0.005588049114138924,
            "auditor_fp_violation": 0.004569644817312217,
            "ave_precision_score": 0.7223684919718685,
            "fpr": 0.12623490669593854,
            "logloss": 4.4104857135142685,
            "mae": 0.2863360286973228,
            "precision": 0.7444444444444445,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 4719,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8183166000601233,
            "auditor_fn_violation": 0.010576339014542472,
            "auditor_fp_violation": 0.0213386048256032,
            "ave_precision_score": 0.8186328955091065,
            "fpr": 0.11951754385964912,
            "logloss": 0.9824996858238837,
            "mae": 0.27151324288669687,
            "precision": 0.7705263157894737,
            "recall": 0.745417515274949
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8025260912349952,
            "auditor_fn_violation": 0.012292759718629753,
            "auditor_fp_violation": 0.007889681668496159,
            "ave_precision_score": 0.8030132430493655,
            "fpr": 0.13830954994511527,
            "logloss": 1.0336674795881289,
            "mae": 0.284526933600744,
            "precision": 0.7301927194860813,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8042672682664312,
            "auditor_fn_violation": 0.005071551077285885,
            "auditor_fp_violation": 0.0219376380380881,
            "ave_precision_score": 0.7706672431658004,
            "fpr": 0.11403508771929824,
            "logloss": 3.7755625817894196,
            "mae": 0.2786159079678598,
            "precision": 0.7758620689655172,
            "recall": 0.7331975560081466
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7754167065224131,
            "auditor_fn_violation": 0.010097370036961258,
            "auditor_fp_violation": 0.010168378547906544,
            "ave_precision_score": 0.7336326530794888,
            "fpr": 0.1350164654226125,
            "logloss": 4.257540485126724,
            "mae": 0.290995947957357,
            "precision": 0.7349137931034483,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.792731549578986,
            "auditor_fn_violation": 0.005609747382713404,
            "auditor_fp_violation": 0.02106513314164271,
            "ave_precision_score": 0.7730730864402574,
            "fpr": 0.1206140350877193,
            "logloss": 2.6454550626300692,
            "mae": 0.28043899001439265,
            "precision": 0.7649572649572649,
            "recall": 0.7291242362525459
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.779212557332106,
            "auditor_fn_violation": 0.0008345325787767989,
            "auditor_fp_violation": 0.010082621138466363,
            "ave_precision_score": 0.7617338915231865,
            "fpr": 0.1394072447859495,
            "logloss": 2.611812871488879,
            "mae": 0.29334256034677425,
            "precision": 0.7286324786324786,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 4719,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7886843668014525,
            "auditor_fn_violation": 0.017387537070782874,
            "auditor_fp_violation": 0.019721215151893987,
            "ave_precision_score": 0.789324897441346,
            "fpr": 0.09978070175438597,
            "logloss": 1.1314735241612657,
            "mae": 0.3268626895071074,
            "precision": 0.7702020202020202,
            "recall": 0.6211812627291242
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7703033247283229,
            "auditor_fn_violation": 0.025704551758801108,
            "auditor_fp_violation": 0.018677963776070255,
            "ave_precision_score": 0.7707363267730063,
            "fpr": 0.09989023051591657,
            "logloss": 1.1296312819033285,
            "mae": 0.3342493345238645,
            "precision": 0.7547169811320755,
            "recall": 0.6047516198704104
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7957942030779539,
            "auditor_fn_violation": 0.007566012791653268,
            "auditor_fp_violation": 0.02442492811601451,
            "ave_precision_score": 0.7658662797013143,
            "fpr": 0.14473684210526316,
            "logloss": 3.3964526223435105,
            "mae": 0.2827903986028042,
            "precision": 0.7411764705882353,
            "recall": 0.769857433808554
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7703371794354751,
            "auditor_fn_violation": 0.00507594957716226,
            "auditor_fp_violation": 0.017247040144268474,
            "ave_precision_score": 0.7357595313776593,
            "fpr": 0.15697036223929747,
            "logloss": 3.7306925093647707,
            "mae": 0.2962053812895253,
            "precision": 0.7122736418511066,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8434229745691489,
            "auditor_fn_violation": 0.0012193161110515601,
            "auditor_fp_violation": 0.017679293244988962,
            "ave_precision_score": 0.8436802249833742,
            "fpr": 0.11293859649122807,
            "logloss": 0.7275827269899039,
            "mae": 0.2669982337453221,
            "precision": 0.7822410147991543,
            "recall": 0.7535641547861507
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8268660415155629,
            "auditor_fn_violation": 0.007240518453364566,
            "auditor_fp_violation": 0.01027128743923475,
            "ave_precision_score": 0.8274297495027907,
            "fpr": 0.12952799121844127,
            "logloss": 0.7546874496991609,
            "mae": 0.2785144077890348,
            "precision": 0.7445887445887446,
            "recall": 0.7429805615550756
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7925073127794724,
            "auditor_fn_violation": 0.006583413727802195,
            "auditor_fp_violation": 0.02057027961828563,
            "ave_precision_score": 0.78098570429573,
            "fpr": 0.12719298245614036,
            "logloss": 2.0777416908671524,
            "mae": 0.27770088581747343,
            "precision": 0.7573221757322176,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7784468294841563,
            "auditor_fn_violation": 0.008200705085195817,
            "auditor_fp_violation": 0.01156499921593226,
            "ave_precision_score": 0.7664722912140163,
            "fpr": 0.14489571899012074,
            "logloss": 2.0809417663907546,
            "mae": 0.2940653834252842,
            "precision": 0.7215189873417721,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.806952931162459,
            "auditor_fn_violation": 0.011114535319969997,
            "auditor_fp_violation": 0.02078384798099763,
            "ave_precision_score": 0.7604727551179834,
            "fpr": 0.11842105263157894,
            "logloss": 3.8743949433425477,
            "mae": 0.2702751091084122,
            "precision": 0.773109243697479,
            "recall": 0.7494908350305499
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7779874973166333,
            "auditor_fn_violation": 0.007672009729891206,
            "auditor_fp_violation": 0.01830798180962835,
            "ave_precision_score": 0.7225569559370911,
            "fpr": 0.12843029637760703,
            "logloss": 4.389246021369167,
            "mae": 0.28571052083892695,
            "precision": 0.7445414847161572,
            "recall": 0.7365010799136069
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7921481551165985,
            "auditor_fn_violation": 0.010786257905456106,
            "auditor_fp_violation": 0.014741426011584782,
            "ave_precision_score": 0.7763226012573855,
            "fpr": 0.1074561403508772,
            "logloss": 2.3799534620247957,
            "mae": 0.28241298291061245,
            "precision": 0.7817371937639198,
            "recall": 0.714867617107943
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.775975551807652,
            "auditor_fn_violation": 0.014986023950136677,
            "auditor_fp_violation": 0.013054727928493026,
            "ave_precision_score": 0.7612639521790971,
            "fpr": 0.13721185510428102,
            "logloss": 2.366952023135607,
            "mae": 0.2965727408749379,
            "precision": 0.7234513274336283,
            "recall": 0.7062634989200864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7995331263020177,
            "auditor_fn_violation": 0.007409690213313328,
            "auditor_fp_violation": 0.02807121723548778,
            "ave_precision_score": 0.7534100937967015,
            "fpr": 0.16776315789473684,
            "logloss": 4.0470667429936675,
            "mae": 0.27513858671740066,
            "precision": 0.723826714801444,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7703417939776644,
            "auditor_fn_violation": 0.009613720474261072,
            "auditor_fp_violation": 0.015529441743766666,
            "ave_precision_score": 0.7146901091352389,
            "fpr": 0.18551042810098792,
            "logloss": 4.605045565988668,
            "mae": 0.29649413351192005,
            "precision": 0.6852886405959032,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8472459156188374,
            "auditor_fn_violation": 0.01217529567299103,
            "auditor_fp_violation": 0.018960703421260994,
            "ave_precision_score": 0.8474725262350584,
            "fpr": 0.13048245614035087,
            "logloss": 0.6754583683724352,
            "mae": 0.27149567936027796,
            "precision": 0.7586206896551724,
            "recall": 0.7617107942973523
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8376999194312226,
            "auditor_fn_violation": 0.015528944292579542,
            "auditor_fp_violation": 0.014184275521405054,
            "ave_precision_score": 0.8379544507885638,
            "fpr": 0.13721185510428102,
            "logloss": 0.7061418338056502,
            "mae": 0.28240333668249695,
            "precision": 0.7351694915254238,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7859717449835963,
            "auditor_fn_violation": 0.026213063207917973,
            "auditor_fp_violation": 0.021070342126099095,
            "ave_precision_score": 0.7636989384087571,
            "fpr": 0.12938596491228072,
            "logloss": 4.766120373108108,
            "mae": 0.2983170069190251,
            "precision": 0.7467811158798283,
            "recall": 0.7087576374745418
        },
        "train": {
            "accuracy": 0.6937431394072447,
            "auc_prc": 0.7559100402112431,
            "auditor_fn_violation": 0.034713710279686956,
            "auditor_fp_violation": 0.027555080758977578,
            "ave_precision_score": 0.7312210736952306,
            "fpr": 0.14270032930845225,
            "logloss": 5.264998064702424,
            "mae": 0.3107454474845183,
            "precision": 0.7072072072072072,
            "recall": 0.6781857451403888
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8041336585039368,
            "auditor_fn_violation": 0.005323900382320365,
            "auditor_fp_violation": 0.02076822102762845,
            "ave_precision_score": 0.7631282557599302,
            "fpr": 0.1206140350877193,
            "logloss": 4.076013500495092,
            "mae": 0.2783910222514746,
            "precision": 0.7654584221748401,
            "recall": 0.7311608961303462
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.7745856176142499,
            "auditor_fn_violation": 0.008750737921207802,
            "auditor_fp_violation": 0.013750588050807594,
            "ave_precision_score": 0.725105881183589,
            "fpr": 0.13611416026344675,
            "logloss": 4.583453700277149,
            "mae": 0.2939183603982444,
            "precision": 0.7321814254859611,
            "recall": 0.7321814254859611
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8343655287510504,
            "auditor_fn_violation": 0.005178743702433271,
            "auditor_fp_violation": 0.016580197524690587,
            "ave_precision_score": 0.834636148713778,
            "fpr": 0.1206140350877193,
            "logloss": 0.9417651693831643,
            "mae": 0.28071237120708764,
            "precision": 0.7664543524416136,
            "recall": 0.7352342158859471
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8236841607703689,
            "auditor_fn_violation": 0.012987413257213854,
            "auditor_fp_violation": 0.01509085384977262,
            "ave_precision_score": 0.8240371240538946,
            "fpr": 0.12184412733260154,
            "logloss": 0.9246404975465298,
            "mae": 0.2844380996443318,
            "precision": 0.7511210762331838,
            "recall": 0.7235421166306696
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8000088178612125,
            "auditor_fn_violation": 0.008908153785686213,
            "auditor_fp_violation": 0.023638371463099554,
            "ave_precision_score": 0.7544158900897378,
            "fpr": 0.17324561403508773,
            "logloss": 4.256255014617219,
            "mae": 0.27607669518991174,
            "precision": 0.7173524150268337,
            "recall": 0.8167006109979633
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7698178577342469,
            "auditor_fn_violation": 0.007389880818316096,
            "auditor_fp_violation": 0.022365532381997812,
            "ave_precision_score": 0.7139396479038246,
            "fpr": 0.1942919868276619,
            "logloss": 4.832964456712506,
            "mae": 0.2988090444316766,
            "precision": 0.6752293577981652,
            "recall": 0.7948164146868251
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7094298245614035,
            "auc_prc": 0.7845990171397138,
            "auditor_fn_violation": 0.02505404294851181,
            "auditor_fp_violation": 0.02025253156644581,
            "ave_precision_score": 0.7628916853376687,
            "fpr": 0.13267543859649122,
            "logloss": 4.8361168116945805,
            "mae": 0.3009450799084057,
            "precision": 0.7414529914529915,
            "recall": 0.7067209775967414
        },
        "train": {
            "accuracy": 0.6948408342480791,
            "auc_prc": 0.7551421093740328,
            "auditor_fn_violation": 0.033092061745927506,
            "auditor_fp_violation": 0.027594284146150234,
            "ave_precision_score": 0.730409248481184,
            "fpr": 0.14709110867178923,
            "logloss": 5.297930825191009,
            "mae": 0.31091210783370254,
            "precision": 0.7041942604856513,
            "recall": 0.6889848812095032
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 4719,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7903247516610289,
            "auditor_fn_violation": 0.009352556544109767,
            "auditor_fp_violation": 0.01931751885652374,
            "ave_precision_score": 0.7652650143815309,
            "fpr": 0.12719298245614036,
            "logloss": 3.022691781975964,
            "mae": 0.2812634710993536,
            "precision": 0.7573221757322176,
            "recall": 0.7372708757637475
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.7696083797733306,
            "auditor_fn_violation": 0.01082047354982184,
            "auditor_fp_violation": 0.013904951387799916,
            "ave_precision_score": 0.7426207919556508,
            "fpr": 0.141602634467618,
            "logloss": 3.1827387121092436,
            "mae": 0.29352698959762613,
            "precision": 0.7261146496815286,
            "recall": 0.7386609071274298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8453692824584782,
            "auditor_fn_violation": 0.006491853360488801,
            "auditor_fp_violation": 0.017926720006667504,
            "ave_precision_score": 0.8456386691206483,
            "fpr": 0.1162280701754386,
            "logloss": 0.715091961071941,
            "mae": 0.26358996046645716,
            "precision": 0.7805383022774327,
            "recall": 0.7678207739307535
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8281578625394659,
            "auditor_fn_violation": 0.010237249077153962,
            "auditor_fp_violation": 0.007389838482044851,
            "ave_precision_score": 0.8287790728068118,
            "fpr": 0.13721185510428102,
            "logloss": 0.7559477106362984,
            "mae": 0.2784318458610377,
            "precision": 0.7390396659707724,
            "recall": 0.7645788336933045
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.8680950452221636,
            "auditor_fn_violation": 0.02047825776253261,
            "auditor_fp_violation": 0.014207505104804771,
            "ave_precision_score": 0.8683533899455622,
            "fpr": 0.09649122807017543,
            "logloss": 0.5100528301057244,
            "mae": 0.3107622689041595,
            "precision": 0.8057395143487859,
            "recall": 0.7433808553971487
        },
        "train": {
            "accuracy": 0.7793633369923162,
            "auc_prc": 0.8461356221301108,
            "auditor_fn_violation": 0.028189182845613846,
            "auditor_fp_violation": 0.012834208875646855,
            "ave_precision_score": 0.8464789603444552,
            "fpr": 0.08562019758507135,
            "logloss": 0.49019864778284766,
            "mae": 0.3124057703806401,
            "precision": 0.8133971291866029,
            "recall": 0.734341252699784
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.8498803506823127,
            "auditor_fn_violation": 0.006869260728195236,
            "auditor_fp_violation": 0.017483956327874323,
            "ave_precision_score": 0.8501294372041657,
            "fpr": 0.11842105263157894,
            "logloss": 0.6909338734287575,
            "mae": 0.26200313515217405,
            "precision": 0.7786885245901639,
            "recall": 0.7739307535641547
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8304985035416392,
            "auditor_fn_violation": 0.012757442631812289,
            "auditor_fp_violation": 0.006101027128743928,
            "ave_precision_score": 0.8312950835946178,
            "fpr": 0.1350164654226125,
            "logloss": 0.7327303908896245,
            "mae": 0.27718486610177584,
            "precision": 0.7415966386554622,
            "recall": 0.7624190064794817
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.7967375651002628,
            "auditor_fn_violation": 0.011768856969307179,
            "auditor_fp_violation": 0.023716506229945408,
            "ave_precision_score": 0.7715549002716613,
            "fpr": 0.12280701754385964,
            "logloss": 3.0031448498593063,
            "mae": 0.273220771763191,
            "precision": 0.7661795407098121,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.773307746815932,
            "auditor_fn_violation": 0.010590502924420275,
            "auditor_fp_violation": 0.014519954524070887,
            "ave_precision_score": 0.7464170776376311,
            "fpr": 0.14270032930845225,
            "logloss": 3.1877832885050856,
            "mae": 0.290779535496759,
            "precision": 0.7274633123689728,
            "recall": 0.7494600431965442
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 4719,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.8390844992499061,
            "auditor_fn_violation": 0.0006252903133597744,
            "auditor_fp_violation": 0.005156894611826482,
            "ave_precision_score": 0.8150420464688446,
            "fpr": 0.44846491228070173,
            "logloss": 5.364734863289055,
            "mae": 0.4492992822933786,
            "precision": 0.5450500556173526,
            "recall": 0.9979633401221996
        },
        "train": {
            "accuracy": 0.5126234906695939,
            "auc_prc": 0.8236556801261895,
            "auditor_fn_violation": 0.0,
            "auditor_fp_violation": 0.0021463854477027,
            "ave_precision_score": 0.7952381494955885,
            "fpr": 0.48737650933040616,
            "logloss": 5.789592425764995,
            "mae": 0.4856073123440719,
            "precision": 0.5104740904079382,
            "recall": 1.0
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 4719,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7922437423369101,
            "auditor_fn_violation": 0.016025297459534793,
            "auditor_fp_violation": 0.025057819727465944,
            "ave_precision_score": 0.7438849726938555,
            "fpr": 0.11951754385964912,
            "logloss": 4.044311907068262,
            "mae": 0.30806038159495946,
            "precision": 0.7528344671201814,
            "recall": 0.6761710794297352
        },
        "train": {
            "accuracy": 0.7003293084522503,
            "auc_prc": 0.7640759283045252,
            "auditor_fn_violation": 0.025209048040152397,
            "auditor_fp_violation": 0.012106496001254515,
            "ave_precision_score": 0.7056490159849164,
            "fpr": 0.1350164654226125,
            "logloss": 4.570308914852782,
            "mae": 0.31930619572667407,
            "precision": 0.7178899082568807,
            "recall": 0.6760259179265659
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 4719,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8044813873073622,
            "auditor_fn_violation": 0.004868331725443962,
            "auditor_fp_violation": 0.021734487644288866,
            "ave_precision_score": 0.7718695513309072,
            "fpr": 0.12171052631578948,
            "logloss": 3.7053985564365353,
            "mae": 0.2773323655104076,
            "precision": 0.7677824267782427,
            "recall": 0.7474541751527495
        },
        "train": {
            "accuracy": 0.7299670691547749,
            "auc_prc": 0.774043919134121,
            "auditor_fn_violation": 0.00989584938583619,
            "auditor_fp_violation": 0.01166300768386389,
            "ave_precision_score": 0.7333424763190084,
            "fpr": 0.13830954994511527,
            "logloss": 4.192469126161301,
            "mae": 0.29301184951830517,
            "precision": 0.7313432835820896,
            "recall": 0.7408207343412527
        }
    }
]