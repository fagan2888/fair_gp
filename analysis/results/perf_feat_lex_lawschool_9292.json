[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7423981513175193,
            "auditor_fn_violation": 0.01940224272020257,
            "auditor_fp_violation": 0.029333066272237977,
            "ave_precision_score": 0.7429074156832005,
            "fpr": 0.17434210526315788,
            "logloss": 1.1399049737891895,
            "mae": 0.304883087381719,
            "precision": 0.7071823204419889,
            "recall": 0.7917525773195876
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7781297647853284,
            "auditor_fn_violation": 0.015040057669937908,
            "auditor_fp_violation": 0.030199025485394698,
            "ave_precision_score": 0.7785667224418322,
            "fpr": 0.18221734357848518,
            "logloss": 0.9239516504886339,
            "mae": 0.28851710718241425,
            "precision": 0.7035714285714286,
            "recall": 0.8400852878464818
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7422324099697046,
            "auditor_fn_violation": 0.01799376017362995,
            "auditor_fp_violation": 0.030429557500308145,
            "ave_precision_score": 0.7429429176527991,
            "fpr": 0.1524122807017544,
            "logloss": 0.9774132505192291,
            "mae": 0.30567478641297074,
            "precision": 0.7236580516898609,
            "recall": 0.7505154639175258
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.7815918397411635,
            "auditor_fn_violation": 0.006717237085702118,
            "auditor_fp_violation": 0.029828988084299,
            "ave_precision_score": 0.7822205602630128,
            "fpr": 0.15477497255762898,
            "logloss": 0.7831761906401783,
            "mae": 0.2901870361302546,
            "precision": 0.7213438735177866,
            "recall": 0.7782515991471215
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.824206545333844,
            "auditor_fn_violation": 0.0031176523783686023,
            "auditor_fp_violation": 0.019444102058424766,
            "ave_precision_score": 0.8245518374295959,
            "fpr": 0.20394736842105263,
            "logloss": 0.7885372264749538,
            "mae": 0.30259170742264313,
            "precision": 0.6995153473344103,
            "recall": 0.8927835051546392
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8493959165401491,
            "auditor_fn_violation": 0.006405950489047628,
            "auditor_fp_violation": 0.019599564895619658,
            "ave_precision_score": 0.8497347434111691,
            "fpr": 0.21844127332601537,
            "logloss": 0.6909975123279076,
            "mae": 0.2928230936396724,
            "precision": 0.6821086261980831,
            "recall": 0.9104477611940298
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7872524462132277,
            "auditor_fn_violation": 0.006974588533188648,
            "auditor_fp_violation": 0.015694975142774983,
            "ave_precision_score": 0.78315807446246,
            "fpr": 0.1513157894736842,
            "logloss": 1.2307102371630478,
            "mae": 0.288261999114813,
            "precision": 0.73046875,
            "recall": 0.7711340206185567
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.7958427627406408,
            "auditor_fn_violation": 0.011859317182317987,
            "auditor_fp_violation": 0.021799921522269297,
            "ave_precision_score": 0.7922586523919232,
            "fpr": 0.15916575192096596,
            "logloss": 1.058782733415204,
            "mae": 0.27321333629139866,
            "precision": 0.720616570327553,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 9292,
        "test": {
            "accuracy": 0.694078947368421,
            "auc_prc": 0.7061261077610574,
            "auditor_fn_violation": 0.009922680412371133,
            "auditor_fp_violation": 0.019274620978676205,
            "ave_precision_score": 0.6820081697255626,
            "fpr": 0.20285087719298245,
            "logloss": 2.5219360839790363,
            "mae": 0.32150318924202825,
            "precision": 0.6788194444444444,
            "recall": 0.8061855670103093
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7162657059222057,
            "auditor_fn_violation": 0.006410631490501078,
            "auditor_fp_violation": 0.018948895103088944,
            "ave_precision_score": 0.6938756643640637,
            "fpr": 0.20417124039517015,
            "logloss": 2.3160610978625837,
            "mae": 0.3049008901190452,
            "precision": 0.6787564766839378,
            "recall": 0.837953091684435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.8172155721093852,
            "auditor_fn_violation": 0.017211521070718036,
            "auditor_fp_violation": 0.020864148075105803,
            "ave_precision_score": 0.8174833106919907,
            "fpr": 0.13925438596491227,
            "logloss": 0.7219931081976323,
            "mae": 0.2819432880307687,
            "precision": 0.7529182879377432,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.7760702524698134,
            "auc_prc": 0.8362653042233716,
            "auditor_fn_violation": 0.012467847371266608,
            "auditor_fp_violation": 0.023371959608803422,
            "ave_precision_score": 0.8366324073859552,
            "fpr": 0.1394072447859495,
            "logloss": 0.631202280303732,
            "mae": 0.26639450623683986,
            "precision": 0.7552986512524085,
            "recall": 0.835820895522388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8115489769847622,
            "auditor_fn_violation": 0.006979110146500273,
            "auditor_fp_violation": 0.018265438185628004,
            "ave_precision_score": 0.811900090366586,
            "fpr": 0.15679824561403508,
            "logloss": 0.7272780970972726,
            "mae": 0.29747641663293745,
            "precision": 0.7351851851851852,
            "recall": 0.8185567010309278
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8288122858168632,
            "auditor_fn_violation": 0.01035671571576023,
            "auditor_fp_violation": 0.017950539161877714,
            "ave_precision_score": 0.8292664953553425,
            "fpr": 0.1712403951701427,
            "logloss": 0.6532184270249677,
            "mae": 0.28687286752344615,
            "precision": 0.7219251336898396,
            "recall": 0.8635394456289979
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8098067531117653,
            "auditor_fn_violation": 0.006563121721830352,
            "auditor_fp_violation": 0.01827314187107112,
            "ave_precision_score": 0.8101895400516763,
            "fpr": 0.17324561403508773,
            "logloss": 0.735786118570442,
            "mae": 0.30123931678660976,
            "precision": 0.7247386759581882,
            "recall": 0.8577319587628865
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8252900619392474,
            "auditor_fn_violation": 0.009392429416349334,
            "auditor_fp_violation": 0.015561438625944349,
            "ave_precision_score": 0.8256073159957922,
            "fpr": 0.18441273326015367,
            "logloss": 0.685467366880417,
            "mae": 0.28754819805466014,
            "precision": 0.7123287671232876,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8164876575073063,
            "auditor_fn_violation": 0.01263790920600471,
            "auditor_fp_violation": 0.01935936151855048,
            "ave_precision_score": 0.8164648090374366,
            "fpr": 0.12280701754385964,
            "logloss": 0.9166620925830913,
            "mae": 0.28821724784459013,
            "precision": 0.7586206896551724,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8397658790291294,
            "auditor_fn_violation": 0.012884456500623748,
            "auditor_fp_violation": 0.016326348153041514,
            "ave_precision_score": 0.8400638070311001,
            "fpr": 0.1251372118551043,
            "logloss": 0.7794240887756604,
            "mae": 0.2728481775508088,
            "precision": 0.7558886509635975,
            "recall": 0.7526652452025586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.7432191991156949,
            "auditor_fn_violation": 0.008138903960933261,
            "auditor_fp_violation": 0.014143966473560953,
            "ave_precision_score": 0.7419962279642782,
            "fpr": 0.14912280701754385,
            "logloss": 1.4989008432501405,
            "mae": 0.29169732536959814,
            "precision": 0.7348927875243665,
            "recall": 0.777319587628866
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.803008219447845,
            "auditor_fn_violation": 0.0037728871714814683,
            "auditor_fp_violation": 0.026548320924249125,
            "ave_precision_score": 0.8037947132398225,
            "fpr": 0.15148188803512624,
            "logloss": 1.0123917639321538,
            "mae": 0.2713087378438714,
            "precision": 0.7272727272727273,
            "recall": 0.7846481876332623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.809518454754234,
            "auditor_fn_violation": 0.011550461204557787,
            "auditor_fp_violation": 0.019649533670241182,
            "ave_precision_score": 0.809870056782712,
            "fpr": 0.15460526315789475,
            "logloss": 0.8870192638291003,
            "mae": 0.28265611511475464,
            "precision": 0.7288461538461538,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8271179989962056,
            "auditor_fn_violation": 0.014873882118340398,
            "auditor_fp_violation": 0.02448207181209054,
            "ave_precision_score": 0.8275598200247173,
            "fpr": 0.15806805708013172,
            "logloss": 0.7667581143553339,
            "mae": 0.2651669661758641,
            "precision": 0.7328385899814471,
            "recall": 0.8422174840085288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.8050760867541147,
            "auditor_fn_violation": 0.01945424127328631,
            "auditor_fp_violation": 0.021418813427010148,
            "ave_precision_score": 0.8054709637363404,
            "fpr": 0.16337719298245615,
            "logloss": 0.924612193775079,
            "mae": 0.27998079336401643,
            "precision": 0.7261029411764706,
            "recall": 0.8144329896907216
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8133097407808723,
            "auditor_fn_violation": 0.01677904970989494,
            "auditor_fp_violation": 0.023771798679786026,
            "ave_precision_score": 0.8145707944924733,
            "fpr": 0.1668496158068057,
            "logloss": 0.8503765313672613,
            "mae": 0.2638948167761383,
            "precision": 0.7256317689530686,
            "recall": 0.8571428571428571
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.7966857227769191,
            "auditor_fn_violation": 0.013983089166214506,
            "auditor_fp_violation": 0.024962508730843512,
            "ave_precision_score": 0.7969778118388371,
            "fpr": 0.19846491228070176,
            "logloss": 0.9133576860980375,
            "mae": 0.31207714773231826,
            "precision": 0.6978297161936561,
            "recall": 0.8618556701030928
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8173307772510443,
            "auditor_fn_violation": 0.009453282435244197,
            "auditor_fp_violation": 0.026103779348436162,
            "ave_precision_score": 0.8168232764549807,
            "fpr": 0.1964873765093304,
            "logloss": 0.8295129723120374,
            "mae": 0.2935098546548046,
            "precision": 0.7036423841059603,
            "recall": 0.906183368869936
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8065438809000426,
            "auditor_fn_violation": 0.011179688913004167,
            "auditor_fp_violation": 0.01627275155100867,
            "ave_precision_score": 0.8066803468402965,
            "fpr": 0.12390350877192982,
            "logloss": 1.1107626003796078,
            "mae": 0.27754648711328367,
            "precision": 0.7635983263598326,
            "recall": 0.7525773195876289
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8181506284848192,
            "auditor_fn_violation": 0.010796729852384623,
            "auditor_fp_violation": 0.01883713884101306,
            "ave_precision_score": 0.818304170276248,
            "fpr": 0.1350164654226125,
            "logloss": 0.9381488853774523,
            "mae": 0.26543720766812806,
            "precision": 0.7474332648870636,
            "recall": 0.7761194029850746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7712039096630213,
            "auditor_fn_violation": 0.0065224272020256826,
            "auditor_fp_violation": 0.02437446074201898,
            "ave_precision_score": 0.7712824969361076,
            "fpr": 0.2225877192982456,
            "logloss": 1.1465074505805284,
            "mae": 0.3119251407185323,
            "precision": 0.6793048973143759,
            "recall": 0.8865979381443299
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.7961083699710191,
            "auditor_fn_violation": 0.006307649458525159,
            "auditor_fp_violation": 0.029560773055316875,
            "ave_precision_score": 0.7949172413426348,
            "fpr": 0.22722283205268934,
            "logloss": 1.0478338147741175,
            "mae": 0.29847229479825793,
            "precision": 0.677570093457944,
            "recall": 0.9275053304904051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7709649862865577,
            "auditor_fn_violation": 0.011410291191897272,
            "auditor_fp_violation": 0.01936706520399359,
            "ave_precision_score": 0.7626796132692915,
            "fpr": 0.13596491228070176,
            "logloss": 1.4399693600427588,
            "mae": 0.27727015643533154,
            "precision": 0.7484787018255578,
            "recall": 0.7608247422680412
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8098220429442098,
            "auditor_fn_violation": 0.016662024673558658,
            "auditor_fp_violation": 0.021283359244229656,
            "ave_precision_score": 0.8050489915375227,
            "fpr": 0.14489571899012074,
            "logloss": 1.08454215718783,
            "mae": 0.26187793887062716,
            "precision": 0.7365269461077845,
            "recall": 0.7867803837953091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7010164601803975,
            "auditor_fn_violation": 0.013806746247060955,
            "auditor_fp_violation": 0.02620793787748059,
            "ave_precision_score": 0.7012489391152545,
            "fpr": 0.21162280701754385,
            "logloss": 1.0742150838312514,
            "mae": 0.3056332411517017,
            "precision": 0.6861788617886179,
            "recall": 0.8701030927835052
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7324596677285946,
            "auditor_fn_violation": 0.0009479027943238171,
            "auditor_fp_violation": 0.0323149440473648,
            "ave_precision_score": 0.7341845484777741,
            "fpr": 0.21734357848518113,
            "logloss": 0.900601748528619,
            "mae": 0.29434903975063836,
            "precision": 0.6769983686786297,
            "recall": 0.8848614072494669
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6984649122807017,
            "auc_prc": 0.7027934219518559,
            "auditor_fn_violation": 0.01984988243805391,
            "auditor_fp_violation": 0.03764534286536013,
            "ave_precision_score": 0.7012090398284057,
            "fpr": 0.14035087719298245,
            "logloss": 1.4212711195905374,
            "mae": 0.3156455713412248,
            "precision": 0.7253218884120172,
            "recall": 0.6969072164948453
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.7247363872023679,
            "auditor_fn_violation": 0.0073819392920921505,
            "auditor_fp_violation": 0.03251362184661081,
            "ave_precision_score": 0.7265263882324748,
            "fpr": 0.13721185510428102,
            "logloss": 1.093080149822717,
            "mae": 0.30584448671272013,
            "precision": 0.7306034482758621,
            "recall": 0.7228144989339019
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8253707968757689,
            "auditor_fn_violation": 0.008107252667751854,
            "auditor_fp_violation": 0.016123813632441763,
            "ave_precision_score": 0.8248004136954252,
            "fpr": 0.10855263157894737,
            "logloss": 0.869028416456177,
            "mae": 0.28417746992234144,
            "precision": 0.7760180995475113,
            "recall": 0.7072164948453609
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8492404133825322,
            "auditor_fn_violation": 0.013504689193205993,
            "auditor_fp_violation": 0.01085774172879487,
            "ave_precision_score": 0.849429966437574,
            "fpr": 0.11855104281009879,
            "logloss": 0.7314706570971922,
            "mae": 0.27475738008476164,
            "precision": 0.7631578947368421,
            "recall": 0.7420042643923241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.6962729785357592,
            "auditor_fn_violation": 0.007885693615482005,
            "auditor_fp_violation": 0.028192920826656812,
            "ave_precision_score": 0.6944845140978347,
            "fpr": 0.17763157894736842,
            "logloss": 1.5701496343562538,
            "mae": 0.3013934516979365,
            "precision": 0.7043795620437956,
            "recall": 0.7958762886597938
        },
        "train": {
            "accuracy": 0.7409440175631175,
            "auc_prc": 0.7482190955783439,
            "auditor_fn_violation": 0.00935966240617518,
            "auditor_fp_violation": 0.034997094337186035,
            "ave_precision_score": 0.7494405307122346,
            "fpr": 0.1712403951701427,
            "logloss": 1.0697678087042062,
            "mae": 0.2775387314883009,
            "precision": 0.7137614678899082,
            "recall": 0.8294243070362474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7710746080158697,
            "auditor_fn_violation": 0.014175257731958763,
            "auditor_fp_violation": 0.01984212580631908,
            "ave_precision_score": 0.7628122576692766,
            "fpr": 0.14364035087719298,
            "logloss": 1.4429913003480594,
            "mae": 0.2768555981438438,
            "precision": 0.7385229540918163,
            "recall": 0.7628865979381443
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8093712151705688,
            "auditor_fn_violation": 0.017530350443173814,
            "auditor_fp_violation": 0.022500260764611514,
            "ave_precision_score": 0.804630048445585,
            "fpr": 0.15148188803512624,
            "logloss": 1.0904340270127875,
            "mae": 0.2624464091668247,
            "precision": 0.73046875,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 9292,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8151027914335769,
            "auditor_fn_violation": 0.019411285946825833,
            "auditor_fp_violation": 0.030735137022885092,
            "ave_precision_score": 0.8154698811700779,
            "fpr": 0.15899122807017543,
            "logloss": 0.8226135356612982,
            "mae": 0.27979318215101645,
            "precision": 0.7319778188539742,
            "recall": 0.8164948453608247
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8239550682494781,
            "auditor_fn_violation": 0.02311946617859425,
            "auditor_fp_violation": 0.031453179093135185,
            "ave_precision_score": 0.8243832779309302,
            "fpr": 0.16794731064763996,
            "logloss": 0.757289819630263,
            "mae": 0.2640344555170102,
            "precision": 0.7248201438848921,
            "recall": 0.8592750533049041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.8169262052048973,
            "auditor_fn_violation": 0.016989962018448185,
            "auditor_fp_violation": 0.014038682772505038,
            "ave_precision_score": 0.8181750836769439,
            "fpr": 0.09539473684210527,
            "logloss": 0.9569534123146972,
            "mae": 0.27865176403831166,
            "precision": 0.7967289719626168,
            "recall": 0.7030927835051546
        },
        "train": {
            "accuracy": 0.7749725576289791,
            "auc_prc": 0.8461549306835645,
            "auditor_fn_violation": 0.02021490477672793,
            "auditor_fp_violation": 0.014111090691448412,
            "ave_precision_score": 0.8460379675468492,
            "fpr": 0.09769484083424808,
            "logloss": 0.7336440686501698,
            "mae": 0.24360818760651565,
            "precision": 0.7986425339366516,
            "recall": 0.7526652452025586
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8133905656214859,
            "auditor_fn_violation": 0.015287574606619645,
            "auditor_fp_violation": 0.018239759234150953,
            "ave_precision_score": 0.8137940347928443,
            "fpr": 0.12390350877192982,
            "logloss": 0.8037712576896631,
            "mae": 0.28631780493053255,
            "precision": 0.7590618336886994,
            "recall": 0.734020618556701
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8318252254888187,
            "auditor_fn_violation": 0.017923554565263698,
            "auditor_fp_violation": 0.020468780267320984,
            "ave_precision_score": 0.832181078078824,
            "fpr": 0.12843029637760703,
            "logloss": 0.6971380351548289,
            "mae": 0.26902656534696395,
            "precision": 0.7547169811320755,
            "recall": 0.767590618336887
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.8105326456612181,
            "auditor_fn_violation": 0.02764062217399168,
            "auditor_fp_violation": 0.043233082706766915,
            "ave_precision_score": 0.8108733408120525,
            "fpr": 0.20065789473684212,
            "logloss": 0.9253571280983006,
            "mae": 0.308819535124186,
            "precision": 0.6929530201342282,
            "recall": 0.8515463917525773
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.8257432480905276,
            "auditor_fn_violation": 0.028813904446717335,
            "auditor_fp_violation": 0.03975294415663758,
            "ave_precision_score": 0.826165608443278,
            "fpr": 0.21624588364434688,
            "logloss": 0.8168174721207804,
            "mae": 0.29890755266463187,
            "precision": 0.6754530477759473,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8144182463525447,
            "auditor_fn_violation": 0.013350063302586368,
            "auditor_fp_violation": 0.018830375118123178,
            "ave_precision_score": 0.8143301667409082,
            "fpr": 0.13157894736842105,
            "logloss": 0.9925536431837717,
            "mae": 0.287025585154092,
            "precision": 0.7484276729559748,
            "recall": 0.7360824742268042
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.835099848264996,
            "auditor_fn_violation": 0.01566263086324688,
            "auditor_fp_violation": 0.020225399963244604,
            "ave_precision_score": 0.8352078299037583,
            "fpr": 0.13830954994511527,
            "logloss": 0.8527262453849693,
            "mae": 0.27493449714345264,
            "precision": 0.7396694214876033,
            "recall": 0.7633262260127932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.8675720290962405,
            "auditor_fn_violation": 0.017290649303671555,
            "auditor_fp_violation": 0.013658634290644645,
            "ave_precision_score": 0.8687742815768724,
            "fpr": 0.11951754385964912,
            "logloss": 0.4814230522971762,
            "mae": 0.2762574501152573,
            "precision": 0.7828685258964143,
            "recall": 0.8103092783505155
        },
        "train": {
            "accuracy": 0.8024149286498353,
            "auc_prc": 0.8855539415437944,
            "auditor_fn_violation": 0.014595362531860069,
            "auditor_fp_violation": 0.01246703190268762,
            "ave_precision_score": 0.8857015651867459,
            "fpr": 0.11855104281009879,
            "logloss": 0.47596207239574234,
            "mae": 0.26036462096155455,
            "precision": 0.7861386138613862,
            "recall": 0.8464818763326226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8023652039344449,
            "auditor_fn_violation": 0.012167661421595224,
            "auditor_fp_violation": 0.008052919183203918,
            "ave_precision_score": 0.8024149802627514,
            "fpr": 0.12280701754385964,
            "logloss": 0.8440004833992575,
            "mae": 0.2896802391288363,
            "precision": 0.7661795407098121,
            "recall": 0.756701030927835
        },
        "train": {
            "accuracy": 0.7694840834248079,
            "auc_prc": 0.8218632776746378,
            "auditor_fn_violation": 0.006221050931636318,
            "auditor_fp_violation": 0.010875126036228902,
            "ave_precision_score": 0.8219863085060289,
            "fpr": 0.132821075740944,
            "logloss": 0.7160830121309903,
            "mae": 0.2707808134627478,
            "precision": 0.7584830339321357,
            "recall": 0.8102345415778252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8150032875846444,
            "auditor_fn_violation": 0.010377102550189912,
            "auditor_fp_violation": 0.015949196762397796,
            "ave_precision_score": 0.8153685174449121,
            "fpr": 0.12938596491228072,
            "logloss": 1.0711794248123487,
            "mae": 0.27861323104058544,
            "precision": 0.7546777546777547,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8334360557881355,
            "auditor_fn_violation": 0.01170250363362738,
            "auditor_fp_violation": 0.0170589725377612,
            "ave_precision_score": 0.8338208778939673,
            "fpr": 0.13721185510428102,
            "logloss": 0.9171609509266078,
            "mae": 0.26591833806969506,
            "precision": 0.745417515274949,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8104763315576661,
            "auditor_fn_violation": 0.026338397540242357,
            "auditor_fp_violation": 0.016488454743415915,
            "ave_precision_score": 0.8109235346603132,
            "fpr": 0.10855263157894737,
            "logloss": 1.89257186812201,
            "mae": 0.29486909823081764,
            "precision": 0.7697674418604651,
            "recall": 0.6824742268041237
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8126779812815506,
            "auditor_fn_violation": 0.04000383842119184,
            "auditor_fp_violation": 0.020741962241284252,
            "ave_precision_score": 0.8132975444381934,
            "fpr": 0.10757409440175632,
            "logloss": 1.8718502802519743,
            "mae": 0.28447013667362603,
            "precision": 0.7726218097447796,
            "recall": 0.7100213219616205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.7585911384840881,
            "auditor_fn_violation": 0.00862497739193345,
            "auditor_fp_violation": 0.012415773039155276,
            "ave_precision_score": 0.75645206997188,
            "fpr": 0.13157894736842105,
            "logloss": 1.4024358996180077,
            "mae": 0.28028328102620476,
            "precision": 0.75,
            "recall": 0.7422680412371134
        },
        "train": {
            "accuracy": 0.7716794731064764,
            "auc_prc": 0.8144949397382326,
            "auditor_fn_violation": 0.01724949035596676,
            "auditor_fp_violation": 0.01470464061669589,
            "ave_precision_score": 0.8133785432586568,
            "fpr": 0.11745334796926454,
            "logloss": 0.9568728232829238,
            "mae": 0.24782003631930286,
            "precision": 0.7747368421052632,
            "recall": 0.7846481876332623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7039473684210527,
            "auc_prc": 0.7295054675759606,
            "auditor_fn_violation": 0.036236209079399534,
            "auditor_fp_violation": 0.037270430173795145,
            "ave_precision_score": 0.7313895656850512,
            "fpr": 0.10855263157894737,
            "logloss": 0.8872176884850029,
            "mae": 0.33029161274922825,
            "precision": 0.7602905569007264,
            "recall": 0.6474226804123712
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7674184950472027,
            "auditor_fn_violation": 0.019323173999845532,
            "auditor_fp_violation": 0.03773884796678108,
            "ave_precision_score": 0.7681929171758795,
            "fpr": 0.10537870472008781,
            "logloss": 0.7680324504272036,
            "mae": 0.31707891124189,
            "precision": 0.76,
            "recall": 0.6481876332622601
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8169132918134723,
            "auditor_fn_violation": 0.018274100198950986,
            "auditor_fp_violation": 0.02873474670282264,
            "ave_precision_score": 0.817253012851618,
            "fpr": 0.13596491228070176,
            "logloss": 0.9791210381794532,
            "mae": 0.2784974619876537,
            "precision": 0.7474541751527495,
            "recall": 0.756701030927835
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8351555799203645,
            "auditor_fn_violation": 0.02336755925562715,
            "auditor_fp_violation": 0.027300813088893424,
            "ave_precision_score": 0.8355091626318806,
            "fpr": 0.145993413830955,
            "logloss": 0.8326752093811667,
            "mae": 0.260400017733364,
            "precision": 0.7366336633663366,
            "recall": 0.7931769722814499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7930520129271328,
            "auditor_fn_violation": 0.011346988605534456,
            "auditor_fp_violation": 0.02606413574920909,
            "ave_precision_score": 0.7909825380764514,
            "fpr": 0.38377192982456143,
            "logloss": 1.7086490555677263,
            "mae": 0.3846023110162717,
            "precision": 0.5726495726495726,
            "recall": 0.9670103092783505
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.8103507099882984,
            "auditor_fn_violation": 0.006286584951984628,
            "auditor_fp_violation": 0.02402014592884354,
            "ave_precision_score": 0.8076738584029457,
            "fpr": 0.3929747530186608,
            "logloss": 1.655530520925513,
            "mae": 0.38758644635938483,
            "precision": 0.5607361963190184,
            "recall": 0.9744136460554371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7904061021907652,
            "auditor_fn_violation": 0.007535268583830712,
            "auditor_fp_violation": 0.02311619211964338,
            "ave_precision_score": 0.7908727962276234,
            "fpr": 0.17653508771929824,
            "logloss": 0.9128602342110164,
            "mae": 0.30975041468959635,
            "precision": 0.7185314685314685,
            "recall": 0.8474226804123711
        },
        "train": {
            "accuracy": 0.7596048298572997,
            "auc_prc": 0.8035135737307713,
            "auditor_fn_violation": 0.009256680374199256,
            "auditor_fp_violation": 0.01851677088972886,
            "ave_precision_score": 0.803102796036814,
            "fpr": 0.17892425905598244,
            "logloss": 0.8359864086089451,
            "mae": 0.29566524199577626,
            "precision": 0.7170138888888888,
            "recall": 0.8805970149253731
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.8128689756244163,
            "auditor_fn_violation": 0.006131307650569724,
            "auditor_fp_violation": 0.01772361230946218,
            "ave_precision_score": 0.8113349448374124,
            "fpr": 0.41776315789473684,
            "logloss": 2.0620987667065434,
            "mae": 0.41029727376355785,
            "precision": 0.5559440559440559,
            "recall": 0.9835051546391752
        },
        "train": {
            "accuracy": 0.562019758507135,
            "auc_prc": 0.8321445776321297,
            "auditor_fn_violation": 0.0038056541816556236,
            "auditor_fp_violation": 0.015896707412172004,
            "ave_precision_score": 0.8298340607510885,
            "fpr": 0.4313940724478595,
            "logloss": 2.0700362786223945,
            "mae": 0.42369124219795035,
            "precision": 0.5408878504672897,
            "recall": 0.9872068230277186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7302631578947368,
            "auc_prc": 0.7710239694847641,
            "auditor_fn_violation": 0.014175257731958763,
            "auditor_fp_violation": 0.01984212580631908,
            "ave_precision_score": 0.76277008054122,
            "fpr": 0.14364035087719298,
            "logloss": 1.4448505668715332,
            "mae": 0.276860250269793,
            "precision": 0.7385229540918163,
            "recall": 0.7628865979381443
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.8097234510675958,
            "auditor_fn_violation": 0.017530350443173814,
            "auditor_fp_violation": 0.022500260764611514,
            "ave_precision_score": 0.804970392139779,
            "fpr": 0.15148188803512624,
            "logloss": 1.0919197763517687,
            "mae": 0.2624409434129584,
            "precision": 0.73046875,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 9292,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6817185143405556,
            "auditor_fn_violation": 0.011116386326641352,
            "auditor_fp_violation": 0.033451970089157325,
            "ave_precision_score": 0.676110681360391,
            "fpr": 0.16885964912280702,
            "logloss": 1.9952830871287988,
            "mae": 0.3089639856620304,
            "precision": 0.7066666666666667,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7233809001097695,
            "auc_prc": 0.7242869992438103,
            "auditor_fn_violation": 0.006251477441083746,
            "auditor_fp_violation": 0.04003854349305373,
            "ave_precision_score": 0.72172830729267,
            "fpr": 0.1668496158068057,
            "logloss": 1.3291186602814224,
            "mae": 0.2884316283905274,
            "precision": 0.708253358925144,
            "recall": 0.7867803837953091
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.791407140844524,
            "auditor_fn_violation": 0.006940676433351424,
            "auditor_fp_violation": 0.022068490899379605,
            "ave_precision_score": 0.791661502937708,
            "fpr": 0.1787280701754386,
            "logloss": 0.913167516942122,
            "mae": 0.3100767735535587,
            "precision": 0.7155322862129145,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8042756574618328,
            "auditor_fn_violation": 0.009015608799346536,
            "auditor_fp_violation": 0.01714589407493134,
            "ave_precision_score": 0.8038274354243924,
            "fpr": 0.18111964873765093,
            "logloss": 0.8373894107201607,
            "mae": 0.29644129443867695,
            "precision": 0.7150259067357513,
            "recall": 0.8827292110874201
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.8170524286364216,
            "auditor_fn_violation": 0.010888044854404052,
            "auditor_fp_violation": 0.019729138419820047,
            "ave_precision_score": 0.8175008386429574,
            "fpr": 0.12938596491228072,
            "logloss": 0.8154709512910333,
            "mae": 0.28252001315069974,
            "precision": 0.7546777546777547,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.834090498461599,
            "auditor_fn_violation": 0.01569539787342104,
            "auditor_fp_violation": 0.02195389681668496,
            "ave_precision_score": 0.8344347144078317,
            "fpr": 0.14270032930845225,
            "logloss": 0.711134930362496,
            "mae": 0.27077633201187734,
            "precision": 0.7389558232931727,
            "recall": 0.7846481876332623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.815143007614231,
            "auditor_fn_violation": 0.012423132573702301,
            "auditor_fp_violation": 0.017952154977607958,
            "ave_precision_score": 0.8153724763058032,
            "fpr": 0.12171052631578948,
            "logloss": 0.9883211224081693,
            "mae": 0.28748867220777014,
            "precision": 0.7612903225806451,
            "recall": 0.7298969072164948
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8347175721903692,
            "auditor_fn_violation": 0.015583053838538218,
            "auditor_fp_violation": 0.01849938658229483,
            "ave_precision_score": 0.8351281458138203,
            "fpr": 0.12843029637760703,
            "logloss": 0.8483563019784809,
            "mae": 0.2741781666167609,
            "precision": 0.75,
            "recall": 0.7484008528784648
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8187056366096817,
            "auditor_fn_violation": 0.018106800506420693,
            "auditor_fp_violation": 0.021927256666255807,
            "ave_precision_score": 0.8189820480265515,
            "fpr": 0.12719298245614036,
            "logloss": 0.9988082456874149,
            "mae": 0.27895518662927093,
            "precision": 0.7578288100208769,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8330569151819092,
            "auditor_fn_violation": 0.02279647707830613,
            "auditor_fp_violation": 0.024799956290884172,
            "ave_precision_score": 0.8335773121625525,
            "fpr": 0.1394072447859495,
            "logloss": 0.8488321264717055,
            "mae": 0.25983232383106564,
            "precision": 0.742914979757085,
            "recall": 0.7825159914712153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8126188203387805,
            "auditor_fn_violation": 0.012221920781334782,
            "auditor_fp_violation": 0.02236379884136571,
            "ave_precision_score": 0.8129968210092193,
            "fpr": 0.16557017543859648,
            "logloss": 0.7172187110686082,
            "mae": 0.300084709985656,
            "precision": 0.7289048473967684,
            "recall": 0.8371134020618557
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8325735080594199,
            "auditor_fn_violation": 0.012247840302954414,
            "auditor_fp_violation": 0.019177374572221868,
            "ave_precision_score": 0.8330336389912647,
            "fpr": 0.1712403951701427,
            "logloss": 0.6419879351382011,
            "mae": 0.2876173395074523,
            "precision": 0.7238938053097345,
            "recall": 0.8720682302771855
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7160283137601339,
            "auditor_fn_violation": 0.01652649665400616,
            "auditor_fp_violation": 0.0333466863881014,
            "ave_precision_score": 0.7150922207006932,
            "fpr": 0.1787280701754386,
            "logloss": 1.329507583098927,
            "mae": 0.3270926572162903,
            "precision": 0.6941838649155723,
            "recall": 0.7628865979381443
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7471591146512869,
            "auditor_fn_violation": 0.010043088618379015,
            "auditor_fp_violation": 0.03567756579960364,
            "ave_precision_score": 0.7476599355228306,
            "fpr": 0.19319429198682767,
            "logloss": 1.0753875355955391,
            "mae": 0.3175134434704398,
            "precision": 0.6840215439856373,
            "recall": 0.8123667377398721
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8223859601067272,
            "auditor_fn_violation": 0.014224995478386696,
            "auditor_fp_violation": 0.016123813632441763,
            "ave_precision_score": 0.8225404581311546,
            "fpr": 0.1162280701754386,
            "logloss": 0.8867479402874823,
            "mae": 0.2869664975099416,
            "precision": 0.7654867256637168,
            "recall": 0.7134020618556701
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.842761667382912,
            "auditor_fn_violation": 0.014183434403956391,
            "auditor_fp_violation": 0.017458811608743817,
            "ave_precision_score": 0.8430439922409257,
            "fpr": 0.1251372118551043,
            "logloss": 0.7760814266913856,
            "mae": 0.2731989150586309,
            "precision": 0.7537796976241901,
            "recall": 0.744136460554371
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.8121870450656498,
            "auditor_fn_violation": 0.02473322481461386,
            "auditor_fp_violation": 0.0401901269567361,
            "ave_precision_score": 0.8136882779331582,
            "fpr": 0.1962719298245614,
            "logloss": 0.7651161516028626,
            "mae": 0.3009851575884622,
            "precision": 0.6960950764006791,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8523407409267987,
            "auditor_fn_violation": 0.01975616663428974,
            "auditor_fp_violation": 0.036149425572812935,
            "ave_precision_score": 0.8525902418871707,
            "fpr": 0.19758507135016465,
            "logloss": 0.6834013155354006,
            "mae": 0.2897423023318894,
            "precision": 0.6949152542372882,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7401315789473685,
            "auc_prc": 0.8117806497886907,
            "auditor_fn_violation": 0.003572074516187379,
            "auditor_fp_violation": 0.013252906857307206,
            "ave_precision_score": 0.8121512474932939,
            "fpr": 0.17763157894736842,
            "logloss": 0.7332735669159028,
            "mae": 0.3119214056482234,
            "precision": 0.7167832167832168,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8393705768144203,
            "auditor_fn_violation": 0.01018585916270927,
            "auditor_fp_violation": 0.017014270032930854,
            "ave_precision_score": 0.8397125489220271,
            "fpr": 0.17672886937431395,
            "logloss": 0.6389080723898479,
            "mae": 0.29634024563736694,
            "precision": 0.7190226876090751,
            "recall": 0.8784648187633263
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7518791450781965,
            "auditor_fn_violation": 0.013503798155181771,
            "auditor_fp_violation": 0.02897099305641152,
            "ave_precision_score": 0.7523129637797401,
            "fpr": 0.17214912280701755,
            "logloss": 1.06490636366228,
            "mae": 0.3017712721293064,
            "precision": 0.7087198515769945,
            "recall": 0.7876288659793814
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.7877334785581167,
            "auditor_fn_violation": 0.013450857676491313,
            "auditor_fp_violation": 0.026488717584475328,
            "ave_precision_score": 0.7882387867459499,
            "fpr": 0.1800219538968167,
            "logloss": 0.8664671587769802,
            "mae": 0.2858035132006057,
            "precision": 0.7045045045045045,
            "recall": 0.8336886993603412
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8079423898579807,
            "auditor_fn_violation": 0.014222734671730873,
            "auditor_fp_violation": 0.018432351370228854,
            "ave_precision_score": 0.8081957766658834,
            "fpr": 0.16557017543859648,
            "logloss": 0.8462149736740028,
            "mae": 0.2926650276491081,
            "precision": 0.7317939609236235,
            "recall": 0.8494845360824742
        },
        "train": {
            "accuracy": 0.7705817782656421,
            "auc_prc": 0.8264553352510908,
            "auditor_fn_violation": 0.010583744286252602,
            "auditor_fp_violation": 0.021243623684380455,
            "ave_precision_score": 0.8264008856184367,
            "fpr": 0.1712403951701427,
            "logloss": 0.7480607250793699,
            "mae": 0.2784019742039892,
            "precision": 0.7272727272727273,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8154483014196162,
            "auditor_fn_violation": 0.01341788750226081,
            "auditor_fp_violation": 0.020042421627840097,
            "ave_precision_score": 0.8158321844617129,
            "fpr": 0.1611842105263158,
            "logloss": 0.8758353957010707,
            "mae": 0.2824225303657411,
            "precision": 0.7267657992565055,
            "recall": 0.8061855670103093
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8310697318979213,
            "auditor_fn_violation": 0.015437942793481242,
            "auditor_fp_violation": 0.020468780267320984,
            "ave_precision_score": 0.831469606168967,
            "fpr": 0.1712403951701427,
            "logloss": 0.7687625404388193,
            "mae": 0.26632650022351556,
            "precision": 0.7179023508137432,
            "recall": 0.8464818763326226
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.823090559014866,
            "auditor_fn_violation": 0.02286353771025502,
            "auditor_fp_violation": 0.01956736102551461,
            "ave_precision_score": 0.8233293278133668,
            "fpr": 0.13486842105263158,
            "logloss": 0.6973412956504271,
            "mae": 0.3142990479388748,
            "precision": 0.7549800796812749,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.7727771679473107,
            "auc_prc": 0.8511909403500003,
            "auditor_fn_violation": 0.017373536894483208,
            "auditor_fp_violation": 0.026925808742816564,
            "ave_precision_score": 0.8514760343291581,
            "fpr": 0.13172338090010977,
            "logloss": 0.6008230201616683,
            "mae": 0.29195530723696567,
            "precision": 0.7609561752988048,
            "recall": 0.814498933901919
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7050438596491229,
            "auc_prc": 0.7008753807996464,
            "auditor_fn_violation": 0.009701121360101296,
            "auditor_fp_violation": 0.029173856773080244,
            "ave_precision_score": 0.6959344970789211,
            "fpr": 0.17324561403508773,
            "logloss": 1.7412684763440733,
            "mae": 0.3067765201116657,
            "precision": 0.7030075187969925,
            "recall": 0.7711340206185567
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7323168927467079,
            "auditor_fn_violation": 0.007885146948338131,
            "auditor_fp_violation": 0.02593738669156762,
            "ave_precision_score": 0.7296944884160659,
            "fpr": 0.1778265642151482,
            "logloss": 1.347218636000247,
            "mae": 0.2930100248202118,
            "precision": 0.6977611940298507,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.818379625519954,
            "auditor_fn_violation": 0.012696690179055893,
            "auditor_fp_violation": 0.019826718435432843,
            "ave_precision_score": 0.8187482002879048,
            "fpr": 0.13815789473684212,
            "logloss": 0.9777325042560989,
            "mae": 0.2752992325738307,
            "precision": 0.7454545454545455,
            "recall": 0.7608247422680412
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8357330959714961,
            "auditor_fn_violation": 0.016849264731696702,
            "auditor_fp_violation": 0.01874525035886178,
            "ave_precision_score": 0.8361937642555275,
            "fpr": 0.14928649835345773,
            "logloss": 0.8396452368085537,
            "mae": 0.2605190442878291,
            "precision": 0.7333333333333333,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.8177691811131885,
            "auditor_fn_violation": 0.021828088261891847,
            "auditor_fp_violation": 0.016806873741731378,
            "ave_precision_score": 0.818217733577448,
            "fpr": 0.07894736842105263,
            "logloss": 0.6003323723506772,
            "mae": 0.34058299456389424,
            "precision": 0.8115183246073299,
            "recall": 0.6391752577319587
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8367736625000626,
            "auditor_fn_violation": 0.02429205704268372,
            "auditor_fp_violation": 0.009561369088714609,
            "ave_precision_score": 0.8370293968374771,
            "fpr": 0.0801317233809001,
            "logloss": 0.544941393183286,
            "mae": 0.3118392418880623,
            "precision": 0.8170426065162907,
            "recall": 0.6950959488272921
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8083857401523991,
            "auditor_fn_violation": 0.0160291191897269,
            "auditor_fp_violation": 0.023511647972390005,
            "ave_precision_score": 0.8084816987642474,
            "fpr": 0.15350877192982457,
            "logloss": 1.062479777778676,
            "mae": 0.2813228147692479,
            "precision": 0.7281553398058253,
            "recall": 0.7731958762886598
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.8253384990659555,
            "auditor_fn_violation": 0.021478775169159692,
            "auditor_fp_violation": 0.028122842483273822,
            "ave_precision_score": 0.8249620778323276,
            "fpr": 0.16245883644346873,
            "logloss": 0.9522194229628314,
            "mae": 0.269740184489538,
            "precision": 0.7186311787072244,
            "recall": 0.8059701492537313
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.811622898952769,
            "auditor_fn_violation": 0.012160879001627793,
            "auditor_fp_violation": 0.021190270758864375,
            "ave_precision_score": 0.8120202554757795,
            "fpr": 0.1206140350877193,
            "logloss": 0.8591288803918123,
            "mae": 0.2873022394199548,
            "precision": 0.7619047619047619,
            "recall": 0.7257731958762886
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8274630152854128,
            "auditor_fn_violation": 0.015695397873421044,
            "auditor_fp_violation": 0.0201955982933577,
            "ave_precision_score": 0.8277334924667534,
            "fpr": 0.12952799121844127,
            "logloss": 0.7427897275904524,
            "mae": 0.2716587299114393,
            "precision": 0.751578947368421,
            "recall": 0.7611940298507462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8083734771988728,
            "auditor_fn_violation": 0.02972508591065292,
            "auditor_fp_violation": 0.019957681087965817,
            "ave_precision_score": 0.8090206794813861,
            "fpr": 0.1162280701754386,
            "logloss": 1.6807007580997473,
            "mae": 0.29500675185054037,
            "precision": 0.7585421412300684,
            "recall": 0.6865979381443299
        },
        "train": {
            "accuracy": 0.7420417124039517,
            "auc_prc": 0.8146962556231552,
            "auditor_fn_violation": 0.03860187848588327,
            "auditor_fp_violation": 0.024328096517674872,
            "ave_precision_score": 0.8152358911805202,
            "fpr": 0.1163556531284303,
            "logloss": 1.6283283166622584,
            "mae": 0.28361059874925265,
            "precision": 0.7623318385650224,
            "recall": 0.7249466950959488
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8200561319485401,
            "auditor_fn_violation": 0.013013203110869958,
            "auditor_fp_violation": 0.020966863881014014,
            "ave_precision_score": 0.8207061314705816,
            "fpr": 0.14912280701754385,
            "logloss": 0.7036439409100739,
            "mae": 0.29792613775600585,
            "precision": 0.7453183520599251,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8479846619615701,
            "auditor_fn_violation": 0.011742292145981712,
            "auditor_fp_violation": 0.024929096860394084,
            "ave_precision_score": 0.8483178448291169,
            "fpr": 0.150384193194292,
            "logloss": 0.6026826598004285,
            "mae": 0.2771047615126935,
            "precision": 0.7467652495378928,
            "recall": 0.8614072494669509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 9292,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8153024286425486,
            "auditor_fn_violation": 0.015651564478205825,
            "auditor_fp_violation": 0.02218147828587863,
            "ave_precision_score": 0.8156365425091402,
            "fpr": 0.12280701754385964,
            "logloss": 1.0496425814862798,
            "mae": 0.2791857147050482,
            "precision": 0.7642105263157895,
            "recall": 0.7484536082474227
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8259691276990158,
            "auditor_fn_violation": 0.022162201381363527,
            "auditor_fp_violation": 0.021683198315212263,
            "ave_precision_score": 0.8265167800294545,
            "fpr": 0.13721185510428102,
            "logloss": 0.8977341473241089,
            "mae": 0.2613632624531996,
            "precision": 0.7464503042596349,
            "recall": 0.7846481876332623
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7621278563409876,
            "auditor_fn_violation": 0.011871495749683492,
            "auditor_fp_violation": 0.023491104811208353,
            "ave_precision_score": 0.7620573360693681,
            "fpr": 0.18092105263157895,
            "logloss": 1.12558228723504,
            "mae": 0.3002684170291753,
            "precision": 0.7021660649819494,
            "recall": 0.8020618556701031
        },
        "train": {
            "accuracy": 0.7376509330406147,
            "auc_prc": 0.7973376624476712,
            "auditor_fn_violation": 0.008699641201238598,
            "auditor_fp_violation": 0.029384446508486033,
            "ave_precision_score": 0.7977671058032896,
            "fpr": 0.18660812294182216,
            "logloss": 0.912786512615725,
            "mae": 0.2838531549723774,
            "precision": 0.7017543859649122,
            "recall": 0.8528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6754385964912281,
            "auc_prc": 0.6674686102493024,
            "auditor_fn_violation": 0.032069542412732875,
            "auditor_fp_violation": 0.046034656312913425,
            "ave_precision_score": 0.6675806982120885,
            "fpr": 0.13815789473684212,
            "logloss": 1.331638535671675,
            "mae": 0.340732642655296,
            "precision": 0.7142857142857143,
            "recall": 0.6494845360824743
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.6791296989407629,
            "auditor_fn_violation": 0.030309484411094913,
            "auditor_fp_violation": 0.04622984041205777,
            "ave_precision_score": 0.6808565004813765,
            "fpr": 0.132821075740944,
            "logloss": 1.1118462393076094,
            "mae": 0.33893854841095356,
            "precision": 0.7105263157894737,
            "recall": 0.6332622601279317
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.7696807963956372,
            "auditor_fn_violation": 0.014557334056791462,
            "auditor_fp_violation": 0.01885605406960023,
            "ave_precision_score": 0.761685450737692,
            "fpr": 0.14583333333333334,
            "logloss": 1.441910867182574,
            "mae": 0.27720083789940875,
            "precision": 0.7361111111111112,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8090819410091233,
            "auditor_fn_violation": 0.017827594035467947,
            "auditor_fp_violation": 0.023068975964953244,
            "ave_precision_score": 0.8043220473050395,
            "fpr": 0.1525795828759605,
            "logloss": 1.090812223993954,
            "mae": 0.26291934878720413,
            "precision": 0.7306201550387597,
            "recall": 0.8038379530916845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.8313251355374194,
            "auditor_fn_violation": 0.005450804847169473,
            "auditor_fp_violation": 0.018992152512428615,
            "ave_precision_score": 0.831854600525996,
            "fpr": 0.16228070175438597,
            "logloss": 0.5990527202348382,
            "mae": 0.28786224158574714,
            "precision": 0.7289377289377289,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.7672886937431395,
            "auc_prc": 0.8625141282735236,
            "auditor_fn_violation": 0.005830187310273162,
            "auditor_fp_violation": 0.020684842374001023,
            "ave_precision_score": 0.8626812105608229,
            "fpr": 0.16136114160263446,
            "logloss": 0.5592969990720987,
            "mae": 0.2690242651611532,
            "precision": 0.7332123411978222,
            "recall": 0.8614072494669509
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8160621518007403,
            "auditor_fn_violation": 0.013429191535539882,
            "auditor_fp_violation": 0.021020789679115828,
            "ave_precision_score": 0.8164313307774979,
            "fpr": 0.12171052631578948,
            "logloss": 1.064273148664721,
            "mae": 0.276582534943456,
            "precision": 0.7643312101910829,
            "recall": 0.7422680412371134
        },
        "train": {
            "accuracy": 0.7508232711306256,
            "auc_prc": 0.8397257231669246,
            "auditor_fn_violation": 0.015749229390135726,
            "auditor_fp_violation": 0.0218197893021939,
            "ave_precision_score": 0.8400563010310047,
            "fpr": 0.13611416026344675,
            "logloss": 0.8822883172077608,
            "mae": 0.25942037319052963,
            "precision": 0.746938775510204,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7975191473974319,
            "auditor_fn_violation": 0.010675529028757461,
            "auditor_fp_violation": 0.017929043921278608,
            "ave_precision_score": 0.7962573084533653,
            "fpr": 0.13925438596491227,
            "logloss": 1.0841715161241172,
            "mae": 0.28586377458217715,
            "precision": 0.746,
            "recall": 0.7690721649484537
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.821075283728629,
            "auditor_fn_violation": 0.012212732792053536,
            "auditor_fp_violation": 0.021745285127476643,
            "ave_precision_score": 0.8205248432615851,
            "fpr": 0.145993413830955,
            "logloss": 0.8748843751206129,
            "mae": 0.26205167614136926,
            "precision": 0.7387033398821218,
            "recall": 0.8017057569296375
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.8350833195775478,
            "auditor_fn_violation": 0.03464912280701755,
            "auditor_fp_violation": 0.04255002259747731,
            "ave_precision_score": 0.8356596193014989,
            "fpr": 0.15460526315789475,
            "logloss": 0.7100660256603069,
            "mae": 0.2863762326064381,
            "precision": 0.7334593572778828,
            "recall": 0.8
        },
        "train": {
            "accuracy": 0.7661909989023051,
            "auc_prc": 0.8552991724002139,
            "auditor_fn_violation": 0.038484853449546996,
            "auditor_fp_violation": 0.037406062653044,
            "ave_precision_score": 0.8555110834909679,
            "fpr": 0.14928649835345773,
            "logloss": 0.6317335551200852,
            "mae": 0.2680748838690616,
            "precision": 0.7424242424242424,
            "recall": 0.835820895522388
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8159934332296297,
            "auditor_fn_violation": 0.006070265870862726,
            "auditor_fp_violation": 0.017161243272114723,
            "ave_precision_score": 0.8164431924891853,
            "fpr": 0.12938596491228072,
            "logloss": 0.8002538125245692,
            "mae": 0.28544770650863954,
            "precision": 0.7505285412262156,
            "recall": 0.7319587628865979
        },
        "train": {
            "accuracy": 0.7628979143798024,
            "auc_prc": 0.8460641564421014,
            "auditor_fn_violation": 0.010651618807327646,
            "auditor_fp_violation": 0.015705480030397703,
            "ave_precision_score": 0.8463270991249521,
            "fpr": 0.13062568605927552,
            "logloss": 0.6693507115430238,
            "mae": 0.26442500584836315,
            "precision": 0.7576374745417516,
            "recall": 0.7931769722814499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.7626323372668117,
            "auditor_fn_violation": 0.011778802676795083,
            "auditor_fp_violation": 0.021400838160976217,
            "ave_precision_score": 0.763001765915989,
            "fpr": 0.17434210526315788,
            "logloss": 1.1185747625510527,
            "mae": 0.3005526243371106,
            "precision": 0.708256880733945,
            "recall": 0.7958762886597938
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7976338419441819,
            "auditor_fn_violation": 0.010593106289159505,
            "auditor_fp_violation": 0.02762614798515877,
            "ave_precision_score": 0.7980052809414901,
            "fpr": 0.18331503841931943,
            "logloss": 0.8597132097140587,
            "mae": 0.2826864769481405,
            "precision": 0.7017857142857142,
            "recall": 0.837953091684435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.787578986195759,
            "auditor_fn_violation": 0.006687466087900167,
            "auditor_fp_violation": 0.019551953654628383,
            "ave_precision_score": 0.7531376727264993,
            "fpr": 0.18969298245614036,
            "logloss": 2.2260053420240182,
            "mae": 0.3042451410131995,
            "precision": 0.6996527777777778,
            "recall": 0.8309278350515464
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7954971436707188,
            "auditor_fn_violation": 0.0031292494716319654,
            "auditor_fp_violation": 0.02176018596242011,
            "ave_precision_score": 0.7637415968938055,
            "fpr": 0.21405049396267836,
            "logloss": 1.9957329660986114,
            "mae": 0.30537587219951967,
            "precision": 0.6717171717171717,
            "recall": 0.8507462686567164
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.8163134156955957,
            "auditor_fn_violation": 0.014116476758907577,
            "auditor_fp_violation": 0.017453983318953134,
            "ave_precision_score": 0.8167096041576536,
            "fpr": 0.13048245614035087,
            "logloss": 0.728506544600083,
            "mae": 0.2842822033940537,
            "precision": 0.7571428571428571,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7782656421514819,
            "auc_prc": 0.8351118808436953,
            "auditor_fn_violation": 0.00945796343669765,
            "auditor_fp_violation": 0.017501030641083593,
            "ave_precision_score": 0.8354803517285972,
            "fpr": 0.12403951701427003,
            "logloss": 0.6303458677144985,
            "mae": 0.2657375861968565,
            "precision": 0.77079107505071,
            "recall": 0.8102345415778252
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7566240696471254,
            "auditor_fn_violation": 0.013580665581479485,
            "auditor_fp_violation": 0.028241710834463207,
            "ave_precision_score": 0.7567966435736307,
            "fpr": 0.17105263157894737,
            "logloss": 1.0515704957730327,
            "mae": 0.30096505264636236,
            "precision": 0.7094972067039106,
            "recall": 0.7855670103092783
        },
        "train": {
            "accuracy": 0.7332601536772777,
            "auc_prc": 0.7922434787189898,
            "auditor_fn_violation": 0.01283998698681596,
            "auditor_fp_violation": 0.03140102617083311,
            "ave_precision_score": 0.7927350874082746,
            "fpr": 0.17892425905598244,
            "logloss": 0.8553815662631902,
            "mae": 0.2842814207055813,
            "precision": 0.7047101449275363,
            "recall": 0.8294243070362474
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.8086324796094915,
            "auditor_fn_violation": 0.008936968710435884,
            "auditor_fp_violation": 0.018391265047865573,
            "ave_precision_score": 0.8090206683302947,
            "fpr": 0.15021929824561403,
            "logloss": 0.713307586966736,
            "mae": 0.2971306056902553,
            "precision": 0.7439252336448599,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8290568661522243,
            "auditor_fn_violation": 0.0068576671293056465,
            "auditor_fp_violation": 0.01819888641093523,
            "ave_precision_score": 0.8295183400713844,
            "fpr": 0.1690450054884742,
            "logloss": 0.6298356031871432,
            "mae": 0.2826461528094882,
            "precision": 0.7259786476868327,
            "recall": 0.8699360341151386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7907848340573957,
            "auditor_fn_violation": 0.021825827455236032,
            "auditor_fp_violation": 0.024312831258474055,
            "ave_precision_score": 0.7912501830355397,
            "fpr": 0.14802631578947367,
            "logloss": 1.006854193123017,
            "mae": 0.28872695759133593,
            "precision": 0.7321428571428571,
            "recall": 0.7608247422680412
        },
        "train": {
            "accuracy": 0.7453347969264544,
            "auc_prc": 0.8114448510049864,
            "auditor_fn_violation": 0.025853171027409607,
            "auditor_fp_violation": 0.020751896131246558,
            "ave_precision_score": 0.8123430011617467,
            "fpr": 0.14709110867178923,
            "logloss": 0.8571869965948917,
            "mae": 0.2710385915627044,
            "precision": 0.7346534653465346,
            "recall": 0.7910447761194029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.8018434873181193,
            "auditor_fn_violation": 0.009802857659612953,
            "auditor_fp_violation": 0.018185833436049147,
            "ave_precision_score": 0.8022256720537195,
            "fpr": 0.13157894736842105,
            "logloss": 0.9341737534678094,
            "mae": 0.2894589436808086,
            "precision": 0.7484276729559748,
            "recall": 0.7360824742268042
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8222177941638183,
            "auditor_fn_violation": 0.011267170498456438,
            "auditor_fp_violation": 0.017195563524742837,
            "ave_precision_score": 0.8226777922863752,
            "fpr": 0.14489571899012074,
            "logloss": 0.7912611002485692,
            "mae": 0.2735256110183205,
            "precision": 0.7311608961303462,
            "recall": 0.7654584221748401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7258771929824561,
            "auc_prc": 0.8138388186165031,
            "auditor_fn_violation": 0.011681587990595052,
            "auditor_fp_violation": 0.018406672418751796,
            "ave_precision_score": 0.8136246936746473,
            "fpr": 0.12280701754385964,
            "logloss": 0.8354789952736699,
            "mae": 0.30163853230279575,
            "precision": 0.7559912854030502,
            "recall": 0.7154639175257732
        },
        "train": {
            "accuracy": 0.7310647639956093,
            "auc_prc": 0.8338260501411027,
            "auditor_fn_violation": 0.01237188684147087,
            "auditor_fp_violation": 0.013867710387372037,
            "ave_precision_score": 0.8340338689692122,
            "fpr": 0.13611416026344675,
            "logloss": 0.7480795601201241,
            "mae": 0.29930772148856705,
            "precision": 0.7372881355932204,
            "recall": 0.7420042643923241
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8182081352429532,
            "auditor_fn_violation": 0.020109875203472603,
            "auditor_fp_violation": 0.01914365832614323,
            "ave_precision_score": 0.8185648624320695,
            "fpr": 0.19078947368421054,
            "logloss": 0.7386190804511696,
            "mae": 0.30417623814751177,
            "precision": 0.702054794520548,
            "recall": 0.845360824742268
        },
        "train": {
            "accuracy": 0.747530186608123,
            "auc_prc": 0.8412030406237814,
            "auditor_fn_violation": 0.009436898930157119,
            "auditor_fp_violation": 0.02226433087800687,
            "ave_precision_score": 0.8416698209127066,
            "fpr": 0.1942919868276619,
            "logloss": 0.6578102897229886,
            "mae": 0.29302416848934754,
            "precision": 0.7015177065767285,
            "recall": 0.8869936034115139
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7860860613889031,
            "auditor_fn_violation": 0.008075601374570453,
            "auditor_fp_violation": 0.005520974567566457,
            "ave_precision_score": 0.7866817418355313,
            "fpr": 0.0756578947368421,
            "logloss": 2.440429229651689,
            "mae": 0.3603333823355155,
            "precision": 0.8005780346820809,
            "recall": 0.5711340206185567
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7988049793055116,
            "auditor_fn_violation": 0.007934297463599367,
            "auditor_fp_violation": 0.013172338090010978,
            "ave_precision_score": 0.7991885623287539,
            "fpr": 0.07903402854006586,
            "logloss": 2.929477057047171,
            "mae": 0.34674083895030056,
            "precision": 0.7942857142857143,
            "recall": 0.5927505330490405
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7510964912280702,
            "auc_prc": 0.8090516687918277,
            "auditor_fn_violation": 0.011098299873394835,
            "auditor_fp_violation": 0.020019310571510743,
            "ave_precision_score": 0.8094489639464638,
            "fpr": 0.16337719298245615,
            "logloss": 0.725297304761431,
            "mae": 0.29888461968613755,
            "precision": 0.7320143884892086,
            "recall": 0.8391752577319588
        },
        "train": {
            "accuracy": 0.7574094401756312,
            "auc_prc": 0.8301119745512326,
            "auditor_fn_violation": 0.007515347833515506,
            "auditor_fp_violation": 0.018263456695690194,
            "ave_precision_score": 0.8305753064457313,
            "fpr": 0.1778265642151482,
            "logloss": 0.6457415495127163,
            "mae": 0.28673327097178025,
            "precision": 0.7167832167832168,
            "recall": 0.8742004264392325
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.822577194580109,
            "auditor_fn_violation": 0.01345858202206547,
            "auditor_fp_violation": 0.016519269485188386,
            "ave_precision_score": 0.8221057157630409,
            "fpr": 0.10964912280701754,
            "logloss": 0.9356758246830388,
            "mae": 0.2864235358929044,
            "precision": 0.7737556561085973,
            "recall": 0.7051546391752578
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8444828005485645,
            "auditor_fn_violation": 0.01599030096498845,
            "auditor_fp_violation": 0.015819719764964164,
            "ave_precision_score": 0.8445983625042275,
            "fpr": 0.11525795828759605,
            "logloss": 0.8022328252883629,
            "mae": 0.27356695580348217,
            "precision": 0.765625,
            "recall": 0.7313432835820896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6907894736842105,
            "auc_prc": 0.6343986586289393,
            "auditor_fn_violation": 0.0107727437149575,
            "auditor_fp_violation": 0.011216566005176877,
            "ave_precision_score": 0.6197577345602148,
            "fpr": 0.17653508771929824,
            "logloss": 3.123504966320361,
            "mae": 0.325037749878569,
            "precision": 0.6933333333333334,
            "recall": 0.7505154639175258
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.6399603433938696,
            "auditor_fn_violation": 0.018656131292728768,
            "auditor_fp_violation": 0.01570051308541655,
            "ave_precision_score": 0.6294994900250692,
            "fpr": 0.1800219538968167,
            "logloss": 2.9743861904231363,
            "mae": 0.30006243951470746,
            "precision": 0.6951672862453532,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8482466658745722,
            "auditor_fn_violation": 0.012025230602278896,
            "auditor_fp_violation": 0.011260220222687873,
            "ave_precision_score": 0.8473036315691638,
            "fpr": 0.10964912280701754,
            "logloss": 1.0638429363792539,
            "mae": 0.2423120733954146,
            "precision": 0.7885835095137421,
            "recall": 0.7690721649484537
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8763420030316716,
            "auditor_fn_violation": 0.009743504525358155,
            "auditor_fp_violation": 0.01734208840168678,
            "ave_precision_score": 0.8765104585098977,
            "fpr": 0.10428100987925357,
            "logloss": 0.8829202766146691,
            "mae": 0.22323259132563186,
            "precision": 0.7939262472885033,
            "recall": 0.7803837953091685
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7904654391358109,
            "auditor_fn_violation": 0.010804395008138902,
            "auditor_fp_violation": 0.012479970417847902,
            "ave_precision_score": 0.7895346636581448,
            "fpr": 0.15460526315789475,
            "logloss": 1.0297443709070733,
            "mae": 0.3014764197873056,
            "precision": 0.7364485981308411,
            "recall": 0.8123711340206186
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8010905325176126,
            "auditor_fn_violation": 0.011761016151795518,
            "auditor_fp_violation": 0.01556143862594434,
            "ave_precision_score": 0.7987801496899286,
            "fpr": 0.16575192096597147,
            "logloss": 0.9531577297783241,
            "mae": 0.2879544324955916,
            "precision": 0.7274368231046932,
            "recall": 0.8592750533049041
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.8157544422385961,
            "auditor_fn_violation": 0.00885331886417074,
            "auditor_fp_violation": 0.01807027815440241,
            "ave_precision_score": 0.8160639587595024,
            "fpr": 0.15570175438596492,
            "logloss": 0.7603682499574442,
            "mae": 0.3091131884935557,
            "precision": 0.737037037037037,
            "recall": 0.8206185567010309
        },
        "train": {
            "accuracy": 0.756311745334797,
            "auc_prc": 0.8417077111947159,
            "auditor_fn_violation": 0.008716024706325673,
            "auditor_fp_violation": 0.026751965668476298,
            "ave_precision_score": 0.842029216387589,
            "fpr": 0.15477497255762898,
            "logloss": 0.6582311099156175,
            "mae": 0.2936659106564566,
            "precision": 0.7334593572778828,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.7415520811213263,
            "auditor_fn_violation": 0.0289722372942666,
            "auditor_fp_violation": 0.034276264431570745,
            "ave_precision_score": 0.7368889928162279,
            "fpr": 0.15789473684210525,
            "logloss": 2.61893787459592,
            "mae": 0.2965098930095535,
            "precision": 0.7176470588235294,
            "recall": 0.7546391752577319
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.7729488983111312,
            "auditor_fn_violation": 0.03767504019809998,
            "auditor_fp_violation": 0.034704044583298156,
            "ave_precision_score": 0.7689110194076535,
            "fpr": 0.14928649835345773,
            "logloss": 2.168622881304044,
            "mae": 0.26913752653068407,
            "precision": 0.7322834645669292,
            "recall": 0.7931769722814499
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 9292,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.813884847754815,
            "auditor_fn_violation": 0.008355941399891481,
            "auditor_fp_violation": 0.02617969103085583,
            "ave_precision_score": 0.8130199791321708,
            "fpr": 0.3892543859649123,
            "logloss": 1.796015440503409,
            "mae": 0.39437246616478405,
            "precision": 0.571773220747889,
            "recall": 0.977319587628866
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.8316746119890916,
            "auditor_fn_violation": 0.003365640045031234,
            "auditor_fp_violation": 0.021390148561324394,
            "ave_precision_score": 0.8299561848196765,
            "fpr": 0.41602634467618005,
            "logloss": 1.7854657686805842,
            "mae": 0.40487207802824166,
            "precision": 0.5488095238095239,
            "recall": 0.9829424307036247
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8181829001948577,
            "auditor_fn_violation": 0.011326641345632122,
            "auditor_fp_violation": 0.010482147992933158,
            "ave_precision_score": 0.818507090598099,
            "fpr": 0.17434210526315788,
            "logloss": 0.7387681388435124,
            "mae": 0.315849644216717,
            "precision": 0.7150537634408602,
            "recall": 0.822680412371134
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8471491039812058,
            "auditor_fn_violation": 0.0016430315101612842,
            "auditor_fp_violation": 0.017170728799837085,
            "ave_precision_score": 0.847328900456737,
            "fpr": 0.1734357848518112,
            "logloss": 0.6421182058149913,
            "mae": 0.2993504617633615,
            "precision": 0.720353982300885,
            "recall": 0.8678038379530917
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.7011548761075486,
            "auditor_fn_violation": 0.008986706456863811,
            "auditor_fp_violation": 0.029099387813796795,
            "ave_precision_score": 0.6958601992301737,
            "fpr": 0.17214912280701755,
            "logloss": 1.7370434455642518,
            "mae": 0.30671763401532054,
            "precision": 0.7048872180451128,
            "recall": 0.7731958762886598
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.7293300373254302,
            "auditor_fn_violation": 0.008788580228854164,
            "auditor_fp_violation": 0.02498373325518673,
            "ave_precision_score": 0.7268466806901459,
            "fpr": 0.1800219538968167,
            "logloss": 1.3492940012897419,
            "mae": 0.29532585341412365,
            "precision": 0.6951672862453532,
            "recall": 0.7974413646055437
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.7825890325786995,
            "auditor_fn_violation": 0.018158799059504436,
            "auditor_fp_violation": 0.03092516126381528,
            "ave_precision_score": 0.7554758048755121,
            "fpr": 0.17105263157894737,
            "logloss": 3.233182173516725,
            "mae": 0.2855290580615355,
            "precision": 0.708411214953271,
            "recall": 0.7814432989690722
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8022373218685435,
            "auditor_fn_violation": 0.023903533922047287,
            "auditor_fp_violation": 0.030800025828113906,
            "ave_precision_score": 0.7819557903080556,
            "fpr": 0.1712403951701427,
            "logloss": 2.503117264610049,
            "mae": 0.2649932328837492,
            "precision": 0.711645101663586,
            "recall": 0.8208955223880597
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7720393654951978,
            "auditor_fn_violation": 0.012219659974678965,
            "auditor_fp_violation": 0.019546817864332964,
            "ave_precision_score": 0.7376095669673133,
            "fpr": 0.14473684210526316,
            "logloss": 2.1811285305895742,
            "mae": 0.3291783548941072,
            "precision": 0.7203389830508474,
            "recall": 0.7010309278350515
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7824099865744005,
            "auditor_fn_violation": 0.004800366990513957,
            "auditor_fp_violation": 0.024561542931788947,
            "ave_precision_score": 0.7506634102619041,
            "fpr": 0.16355653128430298,
            "logloss": 1.9382501827760656,
            "mae": 0.32285364212014106,
            "precision": 0.6971544715447154,
            "recall": 0.7313432835820896
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7138157894736842,
            "auc_prc": 0.7543603543128504,
            "auditor_fn_violation": 0.012886597938144331,
            "auditor_fp_violation": 0.027419984387197505,
            "ave_precision_score": 0.7544387251752651,
            "fpr": 0.17434210526315788,
            "logloss": 1.1453040188735157,
            "mae": 0.30420757032221235,
            "precision": 0.7066420664206642,
            "recall": 0.7896907216494845
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.7854269147464114,
            "auditor_fn_violation": 0.013146592582017,
            "auditor_fp_violation": 0.02720395766176099,
            "ave_precision_score": 0.785660138783104,
            "fpr": 0.18441273326015367,
            "logloss": 0.9455351687404223,
            "mae": 0.29212550219215105,
            "precision": 0.697841726618705,
            "recall": 0.8272921108742004
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7971382256911972,
            "auditor_fn_violation": 0.008604630132031109,
            "auditor_fp_violation": 0.013471177944862155,
            "ave_precision_score": 0.7969410913205539,
            "fpr": 0.15021929824561403,
            "logloss": 1.021135845752227,
            "mae": 0.2926234589699556,
            "precision": 0.7385496183206107,
            "recall": 0.797938144329897
        },
        "train": {
            "accuracy": 0.7585071350164654,
            "auc_prc": 0.8130773368150919,
            "auditor_fn_violation": 0.007976426476680424,
            "auditor_fp_violation": 0.020831367250944963,
            "ave_precision_score": 0.8133320358738929,
            "fpr": 0.15806805708013172,
            "logloss": 0.8742109081228575,
            "mae": 0.28252068253688295,
            "precision": 0.7318435754189944,
            "recall": 0.837953091684435
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7971938489783,
            "auditor_fn_violation": 0.015079580394284682,
            "auditor_fp_violation": 0.03425315337524139,
            "ave_precision_score": 0.7973969769518998,
            "fpr": 0.25,
            "logloss": 1.0214868632957748,
            "mae": 0.32706062352359333,
            "precision": 0.6561085972850679,
            "recall": 0.8969072164948454
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.8110234941631304,
            "auditor_fn_violation": 0.005942531345155985,
            "auditor_fp_violation": 0.034788482647977716,
            "ave_precision_score": 0.8099183798459334,
            "fpr": 0.2502744237102086,
            "logloss": 0.9768103717644446,
            "mae": 0.31954834191307513,
            "precision": 0.6550680786686838,
            "recall": 0.9232409381663113
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 9292,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.6979644894343593,
            "auditor_fn_violation": 0.009504431181045402,
            "auditor_fp_violation": 0.02589979045975595,
            "ave_precision_score": 0.6930676299773182,
            "fpr": 0.17982456140350878,
            "logloss": 1.7019299579691887,
            "mae": 0.30853833359877775,
            "precision": 0.6990825688073394,
            "recall": 0.7855670103092783
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7304888724816807,
            "auditor_fn_violation": 0.006349778471606218,
            "auditor_fp_violation": 0.026180766995643995,
            "ave_precision_score": 0.7278998283733153,
            "fpr": 0.18990120746432493,
            "logloss": 1.3421982042394003,
            "mae": 0.29285779168035536,
            "precision": 0.6894075403949731,
            "recall": 0.8187633262260128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8185133219888807,
            "auditor_fn_violation": 0.009506691987701215,
            "auditor_fp_violation": 0.01758751386663381,
            "ave_precision_score": 0.8187695185335586,
            "fpr": 0.13267543859649122,
            "logloss": 0.9307363420696038,
            "mae": 0.2783903005983224,
            "precision": 0.7510288065843621,
            "recall": 0.7525773195876289
        },
        "train": {
            "accuracy": 0.7552140504939627,
            "auc_prc": 0.8382905080965204,
            "auditor_fn_violation": 0.00978095253698576,
            "auditor_fp_violation": 0.019132672067391512,
            "ave_precision_score": 0.8386196030615454,
            "fpr": 0.13721185510428102,
            "logloss": 0.8056666913940307,
            "mae": 0.26271821840942655,
            "precision": 0.7479838709677419,
            "recall": 0.7910447761194029
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.8214857850192179,
            "auditor_fn_violation": 0.017589075782239103,
            "auditor_fp_violation": 0.027479045975594724,
            "ave_precision_score": 0.821672171919569,
            "fpr": 0.14035087719298245,
            "logloss": 0.9919807308314931,
            "mae": 0.2749599977381624,
            "precision": 0.7434869739478958,
            "recall": 0.7649484536082474
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8372689759426617,
            "auditor_fn_violation": 0.0223705059460421,
            "auditor_fp_violation": 0.029178318291768285,
            "ave_precision_score": 0.8376299720608997,
            "fpr": 0.150384193194292,
            "logloss": 0.8605489821564672,
            "mae": 0.2595160030187403,
            "precision": 0.7334630350194552,
            "recall": 0.8038379530916845
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 9292,
        "test": {
            "accuracy": 0.6995614035087719,
            "auc_prc": 0.7211873566794862,
            "auditor_fn_violation": 0.0204761258817146,
            "auditor_fp_violation": 0.013930831176301409,
            "ave_precision_score": 0.7196093662941929,
            "fpr": 0.15679824561403508,
            "logloss": 1.4415170294478954,
            "mae": 0.315055351579369,
            "precision": 0.7122736418511066,
            "recall": 0.7298969072164948
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7596645111558362,
            "auditor_fn_violation": 0.02764599458408132,
            "auditor_fp_violation": 0.021477070098494526,
            "ave_precision_score": 0.7580754715741429,
            "fpr": 0.15367727771679474,
            "logloss": 1.1783341134324343,
            "mae": 0.2907721710788963,
            "precision": 0.7188755020080321,
            "recall": 0.7633262260127932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 9292,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8158103536330807,
            "auditor_fn_violation": 0.01385874480014469,
            "auditor_fp_violation": 0.02008864374049879,
            "ave_precision_score": 0.8163908503673108,
            "fpr": 0.13925438596491227,
            "logloss": 0.8360200705851075,
            "mae": 0.28698432282024183,
            "precision": 0.742914979757085,
            "recall": 0.756701030927835
        },
        "train": {
            "accuracy": 0.7442371020856202,
            "auc_prc": 0.828222031940155,
            "auditor_fn_violation": 0.01351639169683962,
            "auditor_fp_violation": 0.027233759331647886,
            "ave_precision_score": 0.8286392440723487,
            "fpr": 0.150384193194292,
            "logloss": 0.7359261944840232,
            "mae": 0.27517874124928426,
            "precision": 0.7313725490196078,
            "recall": 0.7953091684434968
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.816979908327057,
            "auditor_fn_violation": 0.013413365888949176,
            "auditor_fp_violation": 0.020484099593245417,
            "ave_precision_score": 0.8173538848544856,
            "fpr": 0.15021929824561403,
            "logloss": 0.729952517477209,
            "mae": 0.2816387734142553,
            "precision": 0.7458256029684601,
            "recall": 0.8288659793814434
        },
        "train": {
            "accuracy": 0.7683863885839737,
            "auc_prc": 0.8366417638379267,
            "auditor_fn_violation": 0.010253733683784313,
            "auditor_fp_violation": 0.025629436102736297,
            "ave_precision_score": 0.8370154093270757,
            "fpr": 0.15587266739846323,
            "logloss": 0.6450636339552137,
            "mae": 0.2685777748054845,
            "precision": 0.7380073800738007,
            "recall": 0.8528784648187633
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7719298245614035,
            "auc_prc": 0.8556195872886747,
            "auditor_fn_violation": 0.014026044492674982,
            "auditor_fp_violation": 0.014973396606269779,
            "ave_precision_score": 0.8561193301443429,
            "fpr": 0.11513157894736842,
            "logloss": 0.5273315112866067,
            "mae": 0.28074612058458515,
            "precision": 0.784394250513347,
            "recall": 0.7876288659793814
        },
        "train": {
            "accuracy": 0.7914379802414928,
            "auc_prc": 0.880865513410404,
            "auditor_fn_violation": 0.00920987035966475,
            "auditor_fp_violation": 0.01621955883594678,
            "ave_precision_score": 0.8809983611713716,
            "fpr": 0.11525795828759605,
            "logloss": 0.48658358899234216,
            "mae": 0.2602636396134033,
            "precision": 0.7852760736196319,
            "recall": 0.8187633262260128
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 9292,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.7591305161429208,
            "auditor_fn_violation": 0.005093597395550737,
            "auditor_fp_violation": 0.015312358765766879,
            "ave_precision_score": 0.7508371078954071,
            "fpr": 0.15021929824561403,
            "logloss": 1.4800642545569924,
            "mae": 0.28815873842820455,
            "precision": 0.7313725490196078,
            "recall": 0.7690721649484537
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.7890479471106233,
            "auditor_fn_violation": 0.00669617257916159,
            "auditor_fp_violation": 0.026339709235040806,
            "ave_precision_score": 0.7836366738917291,
            "fpr": 0.16245883644346873,
            "logloss": 1.150397355639729,
            "mae": 0.27777850191665576,
            "precision": 0.7120622568093385,
            "recall": 0.7803837953091685
        }
    }
]