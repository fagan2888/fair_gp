[
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(0)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8641772446860885,
            "auditor_fn_violation": 0.005160241612803941,
            "auditor_fp_violation": 0.020148026315789484,
            "ave_precision_score": 0.8643769638052718,
            "fpr": 0.14144736842105263,
            "logloss": 0.4805296969885373,
            "mae": 0.29511069108705495,
            "precision": 0.7435387673956262,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7058177826564215,
            "auc_prc": 0.8044218105725256,
            "auditor_fn_violation": 0.01595845511574289,
            "auditor_fp_violation": 0.016763102569350135,
            "ave_precision_score": 0.8052154341251456,
            "fpr": 0.15367727771679474,
            "logloss": 0.5766451669549018,
            "mae": 0.33887261136626146,
            "precision": 0.7254901960784313,
            "recall": 0.7429718875502008
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(1)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.7824339866133846,
            "auditor_fn_violation": 0.023293224838411827,
            "auditor_fp_violation": 0.015466297322253008,
            "ave_precision_score": 0.7830029594164085,
            "fpr": 0.09210526315789473,
            "logloss": 0.7081996607296506,
            "mae": 0.3525292474808163,
            "precision": 0.7606837606837606,
            "recall": 0.5855263157894737
        },
        "train": {
            "accuracy": 0.6125137211855104,
            "auc_prc": 0.7263269224660122,
            "auditor_fn_violation": 0.02693981193710077,
            "auditor_fp_violation": 0.020170474932424003,
            "ave_precision_score": 0.7277692776692766,
            "fpr": 0.11745334796926454,
            "logloss": 0.8953950661098539,
            "mae": 0.41142928122944566,
            "precision": 0.7019498607242339,
            "recall": 0.5060240963855421
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(2)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.8079081658425206,
            "auditor_fn_violation": 0.008262157586949837,
            "auditor_fp_violation": 0.008235707140658665,
            "ave_precision_score": 0.8085975234931053,
            "fpr": 0.11732456140350878,
            "logloss": 0.5078584736114576,
            "mae": 0.31449746931474165,
            "precision": 0.7673913043478261,
            "recall": 0.7741228070175439
        },
        "train": {
            "accuracy": 0.6959385290889133,
            "auc_prc": 0.7457365014271249,
            "auditor_fn_violation": 0.006874920097514102,
            "auditor_fp_violation": 0.019936583537766814,
            "ave_precision_score": 0.7468727368222432,
            "fpr": 0.14709110867178923,
            "logloss": 0.6222773258300391,
            "mae": 0.3628192974722706,
            "precision": 0.7259713701431493,
            "recall": 0.7128514056224899
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(3)",
        "seed": 6126,
        "test": {
            "accuracy": 0.5,
            "auc_prc": 0.7007229676553683,
            "auditor_fn_violation": 0.0006203831948291958,
            "auditor_fp_violation": 0.0005650777162203756,
            "ave_precision_score": 0.7021643743563615,
            "fpr": 0.0010964912280701754,
            "logloss": 4.199441704596935,
            "mae": 0.5008906737942181,
            "precision": 0.5,
            "recall": 0.0021929824561403508
        },
        "train": {
            "accuracy": 0.45554335894621295,
            "auc_prc": 0.6823205433298019,
            "auditor_fn_violation": 0.001527515109835629,
            "auditor_fp_violation": 0.0005767549163705371,
            "ave_precision_score": 0.6835442027977281,
            "fpr": 0.0010976948408342481,
            "logloss": 4.738787083208143,
            "mae": 0.5455262934061594,
            "precision": 0.75,
            "recall": 0.006024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(4)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7280701754385965,
            "auc_prc": 0.811142576007919,
            "auditor_fn_violation": 0.00827177593105571,
            "auditor_fp_violation": 0.019881117266851336,
            "ave_precision_score": 0.8117975003496714,
            "fpr": 0.13925438596491227,
            "logloss": 0.581059651729756,
            "mae": 0.32247908160742983,
            "precision": 0.7251082251082251,
            "recall": 0.7346491228070176
        },
        "train": {
            "accuracy": 0.6553238199780461,
            "auc_prc": 0.7492225782572032,
            "auditor_fn_violation": 0.017153135042915903,
            "auditor_fp_violation": 0.02218778821134214,
            "ave_precision_score": 0.7508679500008513,
            "fpr": 0.15697036223929747,
            "logloss": 0.7220407491038651,
            "mae": 0.3752579225327423,
            "precision": 0.6957446808510638,
            "recall": 0.6566265060240963
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(5)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.8022261508613884,
            "auditor_fn_violation": 0.008021698984302866,
            "auditor_fp_violation": 0.018366228070175444,
            "ave_precision_score": 0.8025161079486907,
            "fpr": 0.1425438596491228,
            "logloss": 1.1503363678153322,
            "mae": 0.2845864503317036,
            "precision": 0.7263157894736842,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7928491975534037,
            "auditor_fn_violation": 0.00734000767063865,
            "auditor_fp_violation": 0.023088801652123757,
            "ave_precision_score": 0.7937300829037628,
            "fpr": 0.15367727771679474,
            "logloss": 1.0468150944254255,
            "mae": 0.3047611499084914,
            "precision": 0.7307692307692307,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(6)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7697368421052632,
            "auc_prc": 0.7378214890731419,
            "auditor_fn_violation": 0.005347799322868577,
            "auditor_fp_violation": 0.01694271314250539,
            "ave_precision_score": 0.7390964151335462,
            "fpr": 0.1337719298245614,
            "logloss": 0.6710059098851182,
            "mae": 0.2695909551352598,
            "precision": 0.7510204081632653,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7302805397303895,
            "auditor_fn_violation": 0.012797622983702104,
            "auditor_fp_violation": 0.021712031851755385,
            "ave_precision_score": 0.7315783499265209,
            "fpr": 0.16136114160263446,
            "logloss": 0.7837757207786563,
            "mae": 0.31582734794104983,
            "precision": 0.7226415094339622,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(7)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7828947368421053,
            "auc_prc": 0.841790362179401,
            "auditor_fn_violation": 0.004044513696522009,
            "auditor_fp_violation": 0.021275777162203757,
            "ave_precision_score": 0.8420501584917598,
            "fpr": 0.12609649122807018,
            "logloss": 0.5753004809905571,
            "mae": 0.26075983368779915,
            "precision": 0.764344262295082,
            "recall": 0.8179824561403509
        },
        "train": {
            "accuracy": 0.7288693743139407,
            "auc_prc": 0.8195286231042065,
            "auditor_fn_violation": 0.0109240474521577,
            "auditor_fp_violation": 0.020478786316290274,
            "ave_precision_score": 0.8198328425333059,
            "fpr": 0.150384193194292,
            "logloss": 0.671292718329643,
            "mae": 0.2992765670762428,
            "precision": 0.7390476190476191,
            "recall": 0.7791164658634538
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(8)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8487779019541618,
            "auditor_fn_violation": 0.006487573099415207,
            "auditor_fp_violation": 0.019210237765466306,
            "ave_precision_score": 0.8490250836672878,
            "fpr": 0.15460526315789475,
            "logloss": 0.6141663609188249,
            "mae": 0.27981917679203,
            "precision": 0.7191235059760956,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8187790504257517,
            "auditor_fn_violation": 0.012495646692147295,
            "auditor_fp_violation": 0.02111401408132511,
            "ave_precision_score": 0.8191439330069585,
            "fpr": 0.17233809001097694,
            "logloss": 0.7145950682858507,
            "mae": 0.31411801126393557,
            "precision": 0.7124542124542125,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(9)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.767437482036536,
            "auditor_fn_violation": 0.03233927746999076,
            "auditor_fp_violation": 0.01541820560172361,
            "ave_precision_score": 0.7689702749761562,
            "fpr": 0.0800438596491228,
            "logloss": 0.7320464739494638,
            "mae": 0.3666172355797403,
            "precision": 0.7598684210526315,
            "recall": 0.506578947368421
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7294821236063174,
            "auditor_fn_violation": 0.03037837408911167,
            "auditor_fp_violation": 0.01757374888037784,
            "ave_precision_score": 0.7303002575625063,
            "fpr": 0.09659714599341383,
            "logloss": 0.9092900330157864,
            "mae": 0.4196133134144427,
            "precision": 0.7161290322580646,
            "recall": 0.4457831325301205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(10)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.8509866225158236,
            "auditor_fn_violation": 0.007437384579870734,
            "auditor_fp_violation": 0.020833333333333346,
            "ave_precision_score": 0.851221312494127,
            "fpr": 0.15789473684210525,
            "logloss": 0.5385952799873074,
            "mae": 0.26963912084267994,
            "precision": 0.7318435754189944,
            "recall": 0.8618421052631579
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8133281697244018,
            "auditor_fn_violation": 0.009105577083305784,
            "auditor_fp_violation": 0.018921282256414075,
            "ave_precision_score": 0.81412321301856,
            "fpr": 0.1690450054884742,
            "logloss": 0.6180295133413084,
            "mae": 0.3033062735001786,
            "precision": 0.727433628318584,
            "recall": 0.8253012048192772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(11)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7642543859649122,
            "auc_prc": 0.8566009692070643,
            "auditor_fn_violation": 0.004061345798707298,
            "auditor_fp_violation": 0.015879886118805794,
            "ave_precision_score": 0.8568045965907168,
            "fpr": 0.14692982456140352,
            "logloss": 0.49711771145600947,
            "mae": 0.3012736588456104,
            "precision": 0.7367387033398821,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7959630752207147,
            "auditor_fn_violation": 0.01158530940446749,
            "auditor_fp_violation": 0.015646802731213605,
            "ave_precision_score": 0.7972995677662724,
            "fpr": 0.16245883644346873,
            "logloss": 0.5813798587402675,
            "mae": 0.3412783404436007,
            "precision": 0.7196969696969697,
            "recall": 0.7630522088353414
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(12)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712370261360287,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347859836759594,
            "fpr": 0.16447368421052633,
            "logloss": 10.3816754891248,
            "mae": 0.3040842894186968,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804143614551388,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525588768989944,
            "fpr": 0.17014270032930845,
            "logloss": 11.230264008754103,
            "mae": 0.32981724458880535,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(13)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7582697319875031,
            "auditor_fn_violation": 0.006477954755309327,
            "auditor_fp_violation": 0.022853185595567874,
            "ave_precision_score": 0.7592704009463414,
            "fpr": 0.1513157894736842,
            "logloss": 0.6357301162495951,
            "mae": 0.33728394273815576,
            "precision": 0.6973684210526315,
            "recall": 0.6973684210526315
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7199478101615613,
            "auditor_fn_violation": 0.012630103289116948,
            "auditor_fp_violation": 0.023181826638635137,
            "ave_precision_score": 0.7216322011547134,
            "fpr": 0.1690450054884742,
            "logloss": 0.7772854526566301,
            "mae": 0.38591146965702317,
            "precision": 0.6764705882352942,
            "recall": 0.6465863453815262
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(14)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7423245614035088,
            "auc_prc": 0.7734655378695962,
            "auditor_fn_violation": 0.0030009233610341665,
            "auditor_fp_violation": 0.019051535087719305,
            "ave_precision_score": 0.7752136447541096,
            "fpr": 0.14144736842105263,
            "logloss": 0.5735024048696936,
            "mae": 0.30417457683481125,
            "precision": 0.7306889352818372,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7327913868437782,
            "auditor_fn_violation": 0.018991443270337114,
            "auditor_fp_violation": 0.02456391215251845,
            "ave_precision_score": 0.7334637532268816,
            "fpr": 0.15806805708013172,
            "logloss": 0.7075750640731265,
            "mae": 0.36068469497470906,
            "precision": 0.7037037037037037,
            "recall": 0.6867469879518072
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(15)",
        "seed": 6126,
        "test": {
            "accuracy": 0.706140350877193,
            "auc_prc": 0.7686911900918693,
            "auditor_fn_violation": 0.001106109572176055,
            "auditor_fp_violation": 0.02475280855647891,
            "ave_precision_score": 0.7698366978786408,
            "fpr": 0.23903508771929824,
            "logloss": 0.7228047003281435,
            "mae": 0.34371213619433866,
            "precision": 0.6506410256410257,
            "recall": 0.8903508771929824
        },
        "train": {
            "accuracy": 0.6981339187705817,
            "auc_prc": 0.7459641591580746,
            "auditor_fn_violation": 0.015156123946940343,
            "auditor_fp_violation": 0.022009711808591795,
            "ave_precision_score": 0.7467733908492888,
            "fpr": 0.2305159165751921,
            "logloss": 0.781599185138199,
            "mae": 0.35609132689541423,
            "precision": 0.6734059097978227,
            "recall": 0.8694779116465864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(16)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7268503350977142,
            "auditor_fn_violation": 0.007853377962449988,
            "auditor_fp_violation": 0.025493421052631585,
            "ave_precision_score": 0.728247775082566,
            "fpr": 0.19956140350877194,
            "logloss": 0.7558321145846624,
            "mae": 0.294527863183599,
            "precision": 0.6862068965517242,
            "recall": 0.8728070175438597
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7283656001416281,
            "auditor_fn_violation": 0.015063547273616971,
            "auditor_fp_violation": 0.02569881698795726,
            "ave_precision_score": 0.7290689130504395,
            "fpr": 0.20856201975850713,
            "logloss": 0.8365110506394974,
            "mae": 0.3181459892500086,
            "precision": 0.6915584415584416,
            "recall": 0.8554216867469879
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(17)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7521929824561403,
            "auc_prc": 0.7686529933503401,
            "auditor_fn_violation": 0.004436461218836566,
            "auditor_fp_violation": 0.02183604570637119,
            "ave_precision_score": 0.7695734103074724,
            "fpr": 0.15899122807017543,
            "logloss": 0.6106431608950061,
            "mae": 0.2888933787518845,
            "precision": 0.7211538461538461,
            "recall": 0.8223684210526315
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.728064000478023,
            "auditor_fn_violation": 0.01643456372140593,
            "auditor_fp_violation": 0.025244323482430237,
            "ave_precision_score": 0.7293082766325696,
            "fpr": 0.17453347969264543,
            "logloss": 0.7193035403317625,
            "mae": 0.336145018643925,
            "precision": 0.7066420664206642,
            "recall": 0.7690763052208835
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(18)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.6197546474736937,
            "auditor_fn_violation": 0.009024411357340724,
            "auditor_fp_violation": 0.03911299630655587,
            "ave_precision_score": 0.5972278180681865,
            "fpr": 0.17324561403508773,
            "logloss": 2.759578593060745,
            "mae": 0.3400999144998199,
            "precision": 0.6920077972709552,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.6288862940326575,
            "auditor_fn_violation": 0.005929315505711104,
            "auditor_fp_violation": 0.02915403077266554,
            "ave_precision_score": 0.6068665579130855,
            "fpr": 0.18990120746432493,
            "logloss": 2.564583581892782,
            "mae": 0.3919136096451444,
            "precision": 0.6666666666666666,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(19)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7954938307168846,
            "auditor_fn_violation": 0.010517659279778394,
            "auditor_fp_violation": 0.015134464450600182,
            "ave_precision_score": 0.7961185433220443,
            "fpr": 0.13925438596491227,
            "logloss": 0.5746086256753511,
            "mae": 0.3069404614908515,
            "precision": 0.735966735966736,
            "recall": 0.7763157894736842
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7364699441020801,
            "auditor_fn_violation": 0.020219186295125625,
            "auditor_fp_violation": 0.01589132555290065,
            "ave_precision_score": 0.7371401168909918,
            "fpr": 0.15477497255762898,
            "logloss": 0.7085146207115527,
            "mae": 0.366026842062668,
            "precision": 0.7086776859504132,
            "recall": 0.6887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(20)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.7257203203369322,
            "auditor_fn_violation": 0.0080505540166205,
            "auditor_fp_violation": 0.015899122807017548,
            "ave_precision_score": 0.7266647455030815,
            "fpr": 0.14473684210526316,
            "logloss": 1.1740063867553683,
            "mae": 0.30511953953726967,
            "precision": 0.725,
            "recall": 0.7631578947368421
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.7271029797864927,
            "auditor_fn_violation": 0.005113759097862364,
            "auditor_fp_violation": 0.02078709770015655,
            "ave_precision_score": 0.7287748932735033,
            "fpr": 0.15806805708013172,
            "logloss": 1.0570792498071235,
            "mae": 0.32675498337164344,
            "precision": 0.7262357414448669,
            "recall": 0.7670682730923695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(21)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7576754385964912,
            "auc_prc": 0.8091181884360823,
            "auditor_fn_violation": 0.006271160357032945,
            "auditor_fp_violation": 0.01222010618651893,
            "ave_precision_score": 0.8096906485011796,
            "fpr": 0.08881578947368421,
            "logloss": 0.5749446013527518,
            "mae": 0.3215654980025679,
            "precision": 0.7959697732997482,
            "recall": 0.6929824561403509
        },
        "train": {
            "accuracy": 0.6684961580680571,
            "auc_prc": 0.767642012034573,
            "auditor_fn_violation": 0.014719691058415888,
            "auditor_fp_violation": 0.016034849817803922,
            "ave_precision_score": 0.7682906730744615,
            "fpr": 0.1141602634467618,
            "logloss": 0.720095639955909,
            "mae": 0.37804895810093875,
            "precision": 0.7425742574257426,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(22)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.6477461054008509,
            "auditor_fn_violation": 0.004410010772545402,
            "auditor_fp_violation": 0.018683633425669435,
            "ave_precision_score": 0.6268247194650179,
            "fpr": 0.21271929824561403,
            "logloss": 2.3240537000334207,
            "mae": 0.31874837764419345,
            "precision": 0.6700680272108843,
            "recall": 0.8640350877192983
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6736336391948863,
            "auditor_fn_violation": 0.015658683030695782,
            "auditor_fp_violation": 0.02350342730628876,
            "ave_precision_score": 0.6620660839036183,
            "fpr": 0.20856201975850713,
            "logloss": 1.8196049674703512,
            "mae": 0.33321979068425145,
            "precision": 0.6875,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(23)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7254105368443877,
            "auditor_fn_violation": 0.007920706371191138,
            "auditor_fp_violation": 0.02132386888273315,
            "ave_precision_score": 0.7274101135071417,
            "fpr": 0.17982456140350878,
            "logloss": 0.6884393224537138,
            "mae": 0.2853594413002914,
            "precision": 0.7023593466424682,
            "recall": 0.8486842105263158
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7292537223221025,
            "auditor_fn_violation": 0.013747635988520496,
            "auditor_fp_violation": 0.022737964560137994,
            "ave_precision_score": 0.7300066489300456,
            "fpr": 0.1942919868276619,
            "logloss": 0.7806090502696378,
            "mae": 0.31815756105129045,
            "precision": 0.7,
            "recall": 0.8293172690763052
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(24)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7817982456140351,
            "auc_prc": 0.8138683406734979,
            "auditor_fn_violation": 0.0022795475530932646,
            "auditor_fp_violation": 0.016303093259464455,
            "ave_precision_score": 0.8146891253559825,
            "fpr": 0.11842105263157894,
            "logloss": 0.5783531794343566,
            "mae": 0.2632214059322634,
            "precision": 0.7716701902748414,
            "recall": 0.8004385964912281
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8142329575191283,
            "auditor_fn_violation": 0.007203346867161294,
            "auditor_fp_violation": 0.0222329717762191,
            "ave_precision_score": 0.8146232280869685,
            "fpr": 0.15367727771679474,
            "logloss": 0.6947915840837083,
            "mae": 0.3083053218660977,
            "precision": 0.7302504816955684,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(25)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.7507450803531333,
            "auditor_fn_violation": 0.005597876269621428,
            "auditor_fp_violation": 0.021439289012003697,
            "ave_precision_score": 0.7524370383369245,
            "fpr": 0.13486842105263158,
            "logloss": 0.590393556925185,
            "mae": 0.31476858647217515,
            "precision": 0.7320261437908496,
            "recall": 0.7368421052631579
        },
        "train": {
            "accuracy": 0.6509330406147091,
            "auc_prc": 0.7149187714891538,
            "auditor_fn_violation": 0.0075229568107776975,
            "auditor_fp_violation": 0.019654850721475218,
            "ave_precision_score": 0.7157439155247526,
            "fpr": 0.15697036223929747,
            "logloss": 0.7475291356444426,
            "mae": 0.37862181497950403,
            "precision": 0.6931330472103004,
            "recall": 0.6485943775100401
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(26)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7543859649122807,
            "auc_prc": 0.7193970334975928,
            "auditor_fn_violation": 0.004373941982148353,
            "auditor_fp_violation": 0.018633137119113588,
            "ave_precision_score": 0.7192438266124233,
            "fpr": 0.14802631578947367,
            "logloss": 0.8006054046337435,
            "mae": 0.2900967741027413,
            "precision": 0.7310756972111554,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.6970362239297475,
            "auc_prc": 0.7142538686715413,
            "auditor_fn_violation": 0.008629468477642734,
            "auditor_fp_violation": 0.025321401328396814,
            "ave_precision_score": 0.7130261114822145,
            "fpr": 0.16136114160263446,
            "logloss": 0.8794527188749418,
            "mae": 0.3415625871208543,
            "precision": 0.7151162790697675,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(27)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8536908807658184,
            "auditor_fn_violation": 0.015956832871652817,
            "auditor_fp_violation": 0.013869652200677138,
            "ave_precision_score": 0.8539033886975407,
            "fpr": 0.07017543859649122,
            "logloss": 0.5068649282519416,
            "mae": 0.30884591616257484,
            "precision": 0.8284182305630027,
            "recall": 0.6776315789473685
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8155406196568754,
            "auditor_fn_violation": 0.02303616221196532,
            "auditor_fp_violation": 0.01382351299559062,
            "ave_precision_score": 0.815970802695734,
            "fpr": 0.09220636663007684,
            "logloss": 0.6098887459077896,
            "mae": 0.3505902143501776,
            "precision": 0.7975903614457831,
            "recall": 0.6646586345381527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(28)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.6534715386878425,
            "auditor_fn_violation": 0.03473905432440751,
            "auditor_fp_violation": 0.07197406894429056,
            "ave_precision_score": 0.6383333547059108,
            "fpr": 0.2850877192982456,
            "logloss": 3.1298441210790195,
            "mae": 0.36025382275039397,
            "precision": 0.6078431372549019,
            "recall": 0.8837719298245614
        },
        "train": {
            "accuracy": 0.6564215148188803,
            "auc_prc": 0.7003901611852323,
            "auditor_fn_violation": 0.045948888859499465,
            "auditor_fp_violation": 0.06466565490919432,
            "ave_precision_score": 0.6913612929827219,
            "fpr": 0.2623490669593853,
            "logloss": 2.6755989979349697,
            "mae": 0.3583200437556132,
            "precision": 0.6395173453996983,
            "recall": 0.8514056224899599
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(29)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7357456140350878,
            "auc_prc": 0.7637448799602047,
            "auditor_fn_violation": 0.008199638350261622,
            "auditor_fp_violation": 0.017680921052631582,
            "ave_precision_score": 0.7643361130069682,
            "fpr": 0.14364035087719298,
            "logloss": 1.1267988884784128,
            "mae": 0.29213262155351793,
            "precision": 0.7253668763102725,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7636958340252915,
            "auditor_fn_violation": 0.005964582809834293,
            "auditor_fp_violation": 0.02199110681128951,
            "ave_precision_score": 0.7652052248635062,
            "fpr": 0.15367727771679474,
            "logloss": 1.0171037716950229,
            "mae": 0.3121842282137287,
            "precision": 0.7312859884836852,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(30)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7864810585510817,
            "auditor_fn_violation": 0.0030009233610341665,
            "auditor_fp_violation": 0.01575484764542937,
            "ave_precision_score": 0.7873402275317838,
            "fpr": 0.13596491228070176,
            "logloss": 0.5694051114624856,
            "mae": 0.3019530867025248,
            "precision": 0.7383966244725738,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7373391643609669,
            "auditor_fn_violation": 0.01634639546109796,
            "auditor_fp_violation": 0.023280167338661454,
            "ave_precision_score": 0.738904914253335,
            "fpr": 0.15916575192096596,
            "logloss": 0.7052404866169482,
            "mae": 0.35930704294333826,
            "precision": 0.7010309278350515,
            "recall": 0.6827309236947792
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(31)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.7658805659131978,
            "auditor_fn_violation": 0.008209256694367497,
            "auditor_fp_violation": 0.01833256386580487,
            "ave_precision_score": 0.7672634220307119,
            "fpr": 0.19298245614035087,
            "logloss": 0.6025951938716039,
            "mae": 0.30855985113783135,
            "precision": 0.6912280701754386,
            "recall": 0.8640350877192983
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7541488320000662,
            "auditor_fn_violation": 0.007450217996023612,
            "auditor_fp_violation": 0.024864249966112327,
            "ave_precision_score": 0.7558952495458992,
            "fpr": 0.2052689352360044,
            "logloss": 0.6792700148776617,
            "mae": 0.33370847806015536,
            "precision": 0.6898839137645107,
            "recall": 0.8353413654618473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(32)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7664473684210527,
            "auc_prc": 0.8411685613405401,
            "auditor_fn_violation": 0.003012946291166514,
            "auditor_fp_violation": 0.02256463527239151,
            "ave_precision_score": 0.8414563547094258,
            "fpr": 0.14912280701754385,
            "logloss": 0.5902269540546887,
            "mae": 0.26012492163690576,
            "precision": 0.7359223300970874,
            "recall": 0.831140350877193
        },
        "train": {
            "accuracy": 0.725576289791438,
            "auc_prc": 0.8275745450842562,
            "auditor_fn_violation": 0.00868677784684292,
            "auditor_fp_violation": 0.02258646672496233,
            "ave_precision_score": 0.8278692542618337,
            "fpr": 0.16136114160263446,
            "logloss": 0.6859351037513844,
            "mae": 0.29631828480815253,
            "precision": 0.7287822878228782,
            "recall": 0.7931726907630522
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(33)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7554824561403509,
            "auc_prc": 0.8649317401875884,
            "auditor_fn_violation": 0.002539242843951988,
            "auditor_fp_violation": 0.019770506309633746,
            "ave_precision_score": 0.8651345322912576,
            "fpr": 0.13925438596491227,
            "logloss": 0.48666057677046665,
            "mae": 0.29951462448061966,
            "precision": 0.7392197125256673,
            "recall": 0.7894736842105263
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7950355715415611,
            "auditor_fn_violation": 0.011572084165421293,
            "auditor_fp_violation": 0.01670728757744331,
            "ave_precision_score": 0.7958680851894031,
            "fpr": 0.15367727771679474,
            "logloss": 0.5981143834488527,
            "mae": 0.3504244312920028,
            "precision": 0.7183098591549296,
            "recall": 0.7168674698795181
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(34)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.651363668823154,
            "auditor_fn_violation": 0.0046745152354570685,
            "auditor_fp_violation": 0.017543859649122816,
            "ave_precision_score": 0.6295165834696731,
            "fpr": 0.21052631578947367,
            "logloss": 2.421540982544649,
            "mae": 0.3076725559227877,
            "precision": 0.6689655172413793,
            "recall": 0.8508771929824561
        },
        "train": {
            "accuracy": 0.703622392974753,
            "auc_prc": 0.6796945801546176,
            "auditor_fn_violation": 0.013829191629305368,
            "auditor_fp_violation": 0.024619727144425278,
            "ave_precision_score": 0.6674132061675276,
            "fpr": 0.20636663007683864,
            "logloss": 1.9320187402666822,
            "mae": 0.3217609579741733,
            "precision": 0.6887417218543046,
            "recall": 0.8353413654618473
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(35)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7730263157894737,
            "auc_prc": 0.7865363929836549,
            "auditor_fn_violation": 0.006251923668821176,
            "auditor_fp_violation": 0.020203331794398278,
            "ave_precision_score": 0.7874294581739599,
            "fpr": 0.1337719298245614,
            "logloss": 0.5721310921520747,
            "mae": 0.2763861486948069,
            "precision": 0.7525354969574036,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7178924259055982,
            "auc_prc": 0.7527467181855201,
            "auditor_fn_violation": 0.017792354930148697,
            "auditor_fp_violation": 0.023997788663177786,
            "ave_precision_score": 0.753612034365767,
            "fpr": 0.15148188803512624,
            "logloss": 0.688817790658929,
            "mae": 0.3268329280913274,
            "precision": 0.7330754352030948,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(36)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6820175438596491,
            "auc_prc": 0.7696436824314016,
            "auditor_fn_violation": 0.032238284856879046,
            "auditor_fp_violation": 0.014446752847029854,
            "ave_precision_score": 0.7702456970229028,
            "fpr": 0.08442982456140351,
            "logloss": 0.729838537296062,
            "mae": 0.36487731575483884,
            "precision": 0.759375,
            "recall": 0.5328947368421053
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.7271731154999457,
            "auditor_fn_violation": 0.033115998571674195,
            "auditor_fp_violation": 0.018270107350834435,
            "ave_precision_score": 0.7277877022906892,
            "fpr": 0.10428100987925357,
            "logloss": 0.9104892374427992,
            "mae": 0.419648447561637,
            "precision": 0.7058823529411765,
            "recall": 0.4578313253012048
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(37)",
        "seed": 6126,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8732507522073604,
            "auditor_fn_violation": 0.00978426054170515,
            "auditor_fp_violation": 0.006639062019082795,
            "ave_precision_score": 0.8739350237737609,
            "fpr": 0.025219298245614034,
            "logloss": 0.5797800720630244,
            "mae": 0.3317531462602538,
            "precision": 0.916058394160584,
            "recall": 0.5504385964912281
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.8120352294541535,
            "auditor_fn_violation": 0.022302161444901467,
            "auditor_fp_violation": 0.008337696648176846,
            "ave_precision_score": 0.8134403690552787,
            "fpr": 0.043907793633369926,
            "logloss": 0.7073689130036053,
            "mae": 0.38525975501404014,
            "precision": 0.8606271777003485,
            "recall": 0.4959839357429719
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(38)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.7283190334186881,
            "auditor_fn_violation": 0.004693751923668825,
            "auditor_fp_violation": 0.021929824561403508,
            "ave_precision_score": 0.7297624944414448,
            "fpr": 0.14035087719298245,
            "logloss": 0.6258856887122293,
            "mae": 0.28177650966755574,
            "precision": 0.7398373983739838,
            "recall": 0.7982456140350878
        },
        "train": {
            "accuracy": 0.7014270032930845,
            "auc_prc": 0.7196935710271388,
            "auditor_fn_violation": 0.021180220332482506,
            "auditor_fp_violation": 0.021895423968020675,
            "ave_precision_score": 0.7208271777224925,
            "fpr": 0.16355653128430298,
            "logloss": 0.7431417966308358,
            "mae": 0.33041013674801584,
            "precision": 0.7156488549618321,
            "recall": 0.7530120481927711
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(39)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.6687554984336619,
            "auditor_fn_violation": 0.006271160357032934,
            "auditor_fp_violation": 0.016310307017543865,
            "ave_precision_score": 0.6474538176564175,
            "fpr": 0.20723684210526316,
            "logloss": 2.3353540916700726,
            "mae": 0.29966604107545736,
            "precision": 0.6746987951807228,
            "recall": 0.8596491228070176
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.706285041613029,
            "auditor_fn_violation": 0.015195799664078928,
            "auditor_fp_violation": 0.02479514569041816,
            "ave_precision_score": 0.6944616390130247,
            "fpr": 0.20197585071350166,
            "logloss": 1.8414756294653454,
            "mae": 0.31011511614614523,
            "precision": 0.6938435940099834,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(40)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7609649122807017,
            "auc_prc": 0.7863030012128995,
            "auditor_fn_violation": 0.00471779778393352,
            "auditor_fp_violation": 0.022341008771929825,
            "ave_precision_score": 0.7872278205587967,
            "fpr": 0.15899122807017543,
            "logloss": 0.6148867438879468,
            "mae": 0.2709972030087987,
            "precision": 0.7253787878787878,
            "recall": 0.8399122807017544
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7750908415334147,
            "auditor_fn_violation": 0.008411252033380506,
            "auditor_fp_violation": 0.02194858110317003,
            "ave_precision_score": 0.7760596319348386,
            "fpr": 0.17233809001097694,
            "logloss": 0.7112148400596735,
            "mae": 0.30721017441423004,
            "precision": 0.7191413237924866,
            "recall": 0.8072289156626506
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(41)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7763157894736842,
            "auc_prc": 0.7422335081115969,
            "auditor_fn_violation": 0.006540473991997541,
            "auditor_fp_violation": 0.018159433671899053,
            "ave_precision_score": 0.7436628874540999,
            "fpr": 0.11403508771929824,
            "logloss": 0.6239313322591002,
            "mae": 0.280803560405203,
            "precision": 0.7739130434782608,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7353124943426896,
            "auditor_fn_violation": 0.01776149603904091,
            "auditor_fp_violation": 0.02030070991353992,
            "ave_precision_score": 0.7365377323914282,
            "fpr": 0.1394072447859495,
            "logloss": 0.7472824849075137,
            "mae": 0.33224791950012783,
            "precision": 0.7397540983606558,
            "recall": 0.7248995983935743
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(42)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712338934492111,
            "auditor_fn_violation": 0.007184903047091416,
            "auditor_fp_violation": 0.027001096491228085,
            "ave_precision_score": 0.6347828527626952,
            "fpr": 0.16557017543859648,
            "logloss": 10.382414885207428,
            "mae": 0.3045722266103615,
            "precision": 0.6860706860706861,
            "recall": 0.7236842105263158
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7804171322098932,
            "auditor_fn_violation": 0.01522225014217132,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525616461087898,
            "fpr": 0.17014270032930845,
            "logloss": 11.229022002851037,
            "mae": 0.32916866300952685,
            "precision": 0.6954813359528488,
            "recall": 0.7108433734939759
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(43)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712370261360287,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347859836759594,
            "fpr": 0.16447368421052633,
            "logloss": 10.38149942392435,
            "mae": 0.30394549370874047,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804143614551388,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525588768989944,
            "fpr": 0.17014270032930845,
            "logloss": 11.230044545741318,
            "mae": 0.3296793602840437,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(44)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7742280193023351,
            "auditor_fn_violation": 0.007875019236688213,
            "auditor_fp_violation": 0.021266158818097878,
            "ave_precision_score": 0.7755960022704949,
            "fpr": 0.18859649122807018,
            "logloss": 0.5927875278635537,
            "mae": 0.3081792951847443,
            "precision": 0.6966490299823633,
            "recall": 0.8662280701754386
        },
        "train": {
            "accuracy": 0.7091108671789242,
            "auc_prc": 0.7569862788313753,
            "auditor_fn_violation": 0.007769827939640012,
            "auditor_fp_violation": 0.023285483052176398,
            "ave_precision_score": 0.7587178073404508,
            "fpr": 0.20197585071350166,
            "logloss": 0.6737390036005705,
            "mae": 0.3334654689767489,
            "precision": 0.6938435940099834,
            "recall": 0.8373493975903614
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(45)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7708333333333334,
            "auc_prc": 0.8650215000594831,
            "auditor_fn_violation": 0.005160241612803941,
            "auditor_fp_violation": 0.02042214912280703,
            "ave_precision_score": 0.8652218208232765,
            "fpr": 0.13925438596491227,
            "logloss": 0.4782181114752854,
            "mae": 0.29489892211195345,
            "precision": 0.7465069860279441,
            "recall": 0.8201754385964912
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.8050342830435616,
            "auditor_fn_violation": 0.01712668456482351,
            "auditor_fp_violation": 0.016763102569350135,
            "ave_precision_score": 0.8058266856478786,
            "fpr": 0.15367727771679474,
            "logloss": 0.5750289526511324,
            "mae": 0.3390833614813215,
            "precision": 0.724950884086444,
            "recall": 0.7409638554216867
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(46)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7851069925367841,
            "auditor_fn_violation": 0.012061403508771933,
            "auditor_fp_violation": 0.023769332871652823,
            "ave_precision_score": 0.7859390061861551,
            "fpr": 0.12828947368421054,
            "logloss": 0.6013429794518513,
            "mae": 0.303634617680377,
            "precision": 0.7450980392156863,
            "recall": 0.75
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7424771960714402,
            "auditor_fn_violation": 0.016650575959160464,
            "auditor_fp_violation": 0.023572531581982924,
            "ave_precision_score": 0.743015601066138,
            "fpr": 0.15367727771679474,
            "logloss": 0.7354112374653853,
            "mae": 0.3586544331450245,
            "precision": 0.7077244258872651,
            "recall": 0.6807228915662651
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(47)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.7503968437777404,
            "auditor_fn_violation": 0.006780932594644511,
            "auditor_fp_violation": 0.020696271929824567,
            "ave_precision_score": 0.752339843792261,
            "fpr": 0.13706140350877194,
            "logloss": 0.6267279563888946,
            "mae": 0.27077086485303625,
            "precision": 0.7469635627530364,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7457847652192713,
            "auditor_fn_violation": 0.012458175181516408,
            "auditor_fp_violation": 0.023761239411763155,
            "ave_precision_score": 0.7470331336095898,
            "fpr": 0.16245883644346873,
            "logloss": 0.7408722706586929,
            "mae": 0.31495422061262335,
            "precision": 0.7223264540337712,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(48)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712338934492111,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347828527626952,
            "fpr": 0.16447368421052633,
            "logloss": 10.382289123479566,
            "mae": 0.3044921058605899,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804171322098932,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525616461087898,
            "fpr": 0.17014270032930845,
            "logloss": 11.229641843077987,
            "mae": 0.32944201861235234,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(49)",
        "seed": 6126,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.7623882982606998,
            "auditor_fn_violation": 0.004155124653739613,
            "auditor_fp_violation": 0.017817982456140358,
            "ave_precision_score": 0.7634062921434914,
            "fpr": 0.14692982456140352,
            "logloss": 0.5814883414141228,
            "mae": 0.30548495007678866,
            "precision": 0.726530612244898,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.6673984632272228,
            "auc_prc": 0.7315428340134634,
            "auditor_fn_violation": 0.013145887611918585,
            "auditor_fp_violation": 0.02697193037478439,
            "ave_precision_score": 0.7322467554833341,
            "fpr": 0.16245883644346873,
            "logloss": 0.7020015366147472,
            "mae": 0.3584430344693125,
            "precision": 0.6985743380855397,
            "recall": 0.6887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(50)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.7504985119598305,
            "auditor_fn_violation": 0.0039026431209603007,
            "auditor_fp_violation": 0.019231879039704525,
            "ave_precision_score": 0.7515981104232432,
            "fpr": 0.13267543859649122,
            "logloss": 0.568510252013931,
            "mae": 0.31579818200981735,
            "precision": 0.740343347639485,
            "recall": 0.756578947368421
        },
        "train": {
            "accuracy": 0.6641053787047201,
            "auc_prc": 0.7160085892370783,
            "auditor_fn_violation": 0.003293084522502753,
            "auditor_fp_violation": 0.02078178198664161,
            "ave_precision_score": 0.7169983746103056,
            "fpr": 0.15367727771679474,
            "logloss": 0.7059922038917437,
            "mae": 0.3735004704134819,
            "precision": 0.7033898305084746,
            "recall": 0.6666666666666666
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(51)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.8573689036724101,
            "auditor_fn_violation": 0.015899122807017545,
            "auditor_fp_violation": 0.00585516697445368,
            "ave_precision_score": 0.8586849050656314,
            "fpr": 0.025219298245614034,
            "logloss": 0.6206524271511903,
            "mae": 0.34867067401513885,
            "precision": 0.9083665338645418,
            "recall": 0.5
        },
        "train": {
            "accuracy": 0.6542261251372119,
            "auc_prc": 0.7959227286776441,
            "auditor_fn_violation": 0.027548172933225774,
            "auditor_fp_violation": 0.012425480341162493,
            "ave_precision_score": 0.7973033457383809,
            "fpr": 0.042810098792535674,
            "logloss": 0.7746620620618975,
            "mae": 0.4060111365160413,
            "precision": 0.8505747126436781,
            "recall": 0.4457831325301205
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(52)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6787280701754386,
            "auc_prc": 0.8488078727652666,
            "auditor_fn_violation": 0.008021698984302862,
            "auditor_fp_violation": 0.031798245614035096,
            "ave_precision_score": 0.8490884613342337,
            "fpr": 0.2894736842105263,
            "logloss": 0.6376400509294691,
            "mae": 0.3431689300907014,
            "precision": 0.61794500723589,
            "recall": 0.9364035087719298
        },
        "train": {
            "accuracy": 0.672886937431394,
            "auc_prc": 0.842126679075204,
            "auditor_fn_violation": 0.015795343834173133,
            "auditor_fp_violation": 0.032893635230422894,
            "ave_precision_score": 0.8424398770942562,
            "fpr": 0.27661909989023054,
            "logloss": 0.6601814459521361,
            "mae": 0.34649745619687267,
            "precision": 0.6420454545454546,
            "recall": 0.9076305220883534
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(53)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7598684210526315,
            "auc_prc": 0.7440648730718054,
            "auditor_fn_violation": 0.007944752231455831,
            "auditor_fp_violation": 0.017866074176669747,
            "ave_precision_score": 0.7452681893359858,
            "fpr": 0.12938596491228072,
            "logloss": 0.6214974943124062,
            "mae": 0.28184990564518914,
            "precision": 0.7505285412262156,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7184879552362686,
            "auditor_fn_violation": 0.01814061955836519,
            "auditor_fp_violation": 0.023654925141464427,
            "ave_precision_score": 0.7202354001176975,
            "fpr": 0.15587266739846323,
            "logloss": 0.7528370270848489,
            "mae": 0.3374077285025143,
            "precision": 0.716566866267465,
            "recall": 0.7208835341365462
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(54)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712338934492111,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347828527626952,
            "fpr": 0.16447368421052633,
            "logloss": 10.382282944316787,
            "mae": 0.304496527134784,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804171322098932,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525616461087898,
            "fpr": 0.17014270032930845,
            "logloss": 11.229346192590212,
            "mae": 0.3293183978920972,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(55)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7467105263157895,
            "auc_prc": 0.7621490754705617,
            "auditor_fn_violation": 0.015543244075100037,
            "auditor_fp_violation": 0.020566424284395205,
            "ave_precision_score": 0.7628378754512708,
            "fpr": 0.11293859649122807,
            "logloss": 0.6434891737813266,
            "mae": 0.31583258545815346,
            "precision": 0.7610208816705336,
            "recall": 0.7192982456140351
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.7029248551230682,
            "auditor_fn_violation": 0.01639929641728274,
            "auditor_fp_violation": 0.026246335479995653,
            "ave_precision_score": 0.7037810028073714,
            "fpr": 0.141602634467618,
            "logloss": 0.8071275574722953,
            "mae": 0.3764961655123571,
            "precision": 0.7094594594594594,
            "recall": 0.6325301204819277
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(56)",
        "seed": 6126,
        "test": {
            "accuracy": 0.75,
            "auc_prc": 0.8147508327140786,
            "auditor_fn_violation": 0.015499961526623581,
            "auditor_fp_violation": 0.020198522622345345,
            "ave_precision_score": 0.8150775634721587,
            "fpr": 0.1162280701754386,
            "logloss": 0.5405289446880254,
            "mae": 0.31118391520731004,
            "precision": 0.759090909090909,
            "recall": 0.7324561403508771
        },
        "train": {
            "accuracy": 0.677277716794731,
            "auc_prc": 0.7446885308362691,
            "auditor_fn_violation": 0.02707206432756272,
            "auditor_fp_violation": 0.01972395499716938,
            "ave_precision_score": 0.7462655612049138,
            "fpr": 0.1394072447859495,
            "logloss": 0.6732525207117694,
            "mae": 0.3625231741261275,
            "precision": 0.722707423580786,
            "recall": 0.6646586345381527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(57)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6074561403508771,
            "auc_prc": 0.6737500248103384,
            "auditor_fn_violation": 0.005802266081871373,
            "auditor_fp_violation": 0.01421110341643583,
            "ave_precision_score": 0.673699974093755,
            "fpr": 0.12390350877192982,
            "logloss": 4.995774887758584,
            "mae": 0.4078895365713597,
            "precision": 0.6512345679012346,
            "recall": 0.46271929824561403
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6828225277882827,
            "auditor_fn_violation": 0.015579331596418625,
            "auditor_fp_violation": 0.015904614836687994,
            "ave_precision_score": 0.6828821194046804,
            "fpr": 0.14270032930845225,
            "logloss": 5.953964012023613,
            "mae": 0.43912488689078505,
            "precision": 0.6408839779005525,
            "recall": 0.46586345381526106
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(58)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7587719298245614,
            "auc_prc": 0.8246458799485266,
            "auditor_fn_violation": 0.0008367959372114486,
            "auditor_fp_violation": 0.011359264389042785,
            "ave_precision_score": 0.8249806629513188,
            "fpr": 0.1600877192982456,
            "logloss": 0.6868279963217988,
            "mae": 0.26867290146158074,
            "precision": 0.7234848484848485,
            "recall": 0.8377192982456141
        },
        "train": {
            "accuracy": 0.7200878155872668,
            "auc_prc": 0.8117102290731755,
            "auditor_fn_violation": 0.009738184351015483,
            "auditor_fp_violation": 0.018655496580667282,
            "ave_precision_score": 0.8120573056531531,
            "fpr": 0.17233809001097694,
            "logloss": 0.7880714825745136,
            "mae": 0.3023874567936793,
            "precision": 0.718132854578097,
            "recall": 0.8032128514056225
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(59)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7560052088977499,
            "auditor_fn_violation": 0.0034337488457987096,
            "auditor_fp_violation": 0.018503289473684216,
            "ave_precision_score": 0.7572754040864181,
            "fpr": 0.14583333333333334,
            "logloss": 0.5831782019171982,
            "mae": 0.3062038124587975,
            "precision": 0.7280163599182005,
            "recall": 0.7807017543859649
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7329314925609027,
            "auditor_fn_violation": 0.013758657021058995,
            "auditor_fp_violation": 0.02650148972871257,
            "ave_precision_score": 0.7336485768204848,
            "fpr": 0.16355653128430298,
            "logloss": 0.6999020775453726,
            "mae": 0.3572992097492341,
            "precision": 0.6989898989898989,
            "recall": 0.6947791164658634
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(60)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712370261360287,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347859836759594,
            "fpr": 0.16447368421052633,
            "logloss": 10.381499296420776,
            "mae": 0.3039453603294596,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804143614551388,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525588768989944,
            "fpr": 0.17014270032930845,
            "logloss": 11.230044937633897,
            "mae": 0.3296794183020665,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(61)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7839912280701754,
            "auc_prc": 0.8423166574875467,
            "auditor_fn_violation": 0.007783644967682369,
            "auditor_fp_violation": 0.012287434595260084,
            "ave_precision_score": 0.8426210505632846,
            "fpr": 0.1074561403508772,
            "logloss": 0.6062772247075585,
            "mae": 0.25610164893929416,
            "precision": 0.7846153846153846,
            "recall": 0.7828947368421053
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8302768717789601,
            "auditor_fn_violation": 0.007419359104915833,
            "auditor_fp_violation": 0.016877390409921245,
            "ave_precision_score": 0.8305577426558287,
            "fpr": 0.13721185510428102,
            "logloss": 0.7168506129070573,
            "mae": 0.29712079106240447,
            "precision": 0.7484909456740443,
            "recall": 0.7469879518072289
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(62)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7796052631578947,
            "auc_prc": 0.841596287459023,
            "auditor_fn_violation": 0.012061403508771938,
            "auditor_fp_violation": 0.007560018467220683,
            "ave_precision_score": 0.8419160563236454,
            "fpr": 0.07456140350877193,
            "logloss": 0.605888969957123,
            "mae": 0.27552493273564677,
            "precision": 0.8260869565217391,
            "recall": 0.7083333333333334
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.82175335474453,
            "auditor_fn_violation": 0.009852803089415845,
            "auditor_fp_violation": 0.009015450121331165,
            "ave_precision_score": 0.8222389927962761,
            "fpr": 0.10537870472008781,
            "logloss": 0.7308399228158784,
            "mae": 0.322345853494548,
            "precision": 0.7767441860465116,
            "recall": 0.6706827309236948
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(63)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7712370261360287,
            "auditor_fn_violation": 0.006641466605109263,
            "auditor_fp_violation": 0.02658991228070176,
            "ave_precision_score": 0.6347859836759594,
            "fpr": 0.16447368421052633,
            "logloss": 10.381745455198462,
            "mae": 0.3041346611111964,
            "precision": 0.6868475991649269,
            "recall": 0.7214912280701754
        },
        "train": {
            "accuracy": 0.6695938529088913,
            "auc_prc": 0.7804143614551388,
            "auditor_fn_violation": 0.015235475381217523,
            "auditor_fp_violation": 0.022033632519409,
            "ave_precision_score": 0.6525588768989944,
            "fpr": 0.17014270032930845,
            "logloss": 11.23020666902663,
            "mae": 0.32979983669571766,
            "precision": 0.6942800788954635,
            "recall": 0.7068273092369478
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(64)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7214912280701754,
            "auc_prc": 0.7714373043781113,
            "auditor_fn_violation": 0.02091028008618037,
            "auditor_fp_violation": 0.014773776546629735,
            "ave_precision_score": 0.7717117455122957,
            "fpr": 0.09210526315789473,
            "logloss": 1.7496249379791853,
            "mae": 0.33452312713412174,
            "precision": 0.772972972972973,
            "recall": 0.6271929824561403
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7343174413648399,
            "auditor_fn_violation": 0.021173607712959418,
            "auditor_fp_violation": 0.01864220729687994,
            "ave_precision_score": 0.7352639722730241,
            "fpr": 0.10757409440175632,
            "logloss": 1.9990357278456323,
            "mae": 0.37337900705704785,
            "precision": 0.7537688442211056,
            "recall": 0.6024096385542169
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(65)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.7510909990000307,
            "auditor_fn_violation": 0.006607802400738689,
            "auditor_fp_violation": 0.022341008771929825,
            "ave_precision_score": 0.7528484288726496,
            "fpr": 0.13267543859649122,
            "logloss": 0.6168731932255919,
            "mae": 0.2731605934717855,
            "precision": 0.7515400410677618,
            "recall": 0.8026315789473685
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7458602663947045,
            "auditor_fn_violation": 0.013774086466612889,
            "auditor_fp_violation": 0.023466217311684204,
            "ave_precision_score": 0.7471037854992733,
            "fpr": 0.15806805708013172,
            "logloss": 0.7289625830087548,
            "mae": 0.3184865212566608,
            "precision": 0.7257142857142858,
            "recall": 0.7650602409638554
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(66)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7738382271466693,
            "auditor_fn_violation": 0.0125158702677747,
            "auditor_fp_violation": 0.019467528470298555,
            "ave_precision_score": 0.7755679269249832,
            "fpr": 0.1600877192982456,
            "logloss": 0.5857675057913607,
            "mae": 0.3056672463916536,
            "precision": 0.7165048543689321,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.6915477497255763,
            "auc_prc": 0.7304219081581969,
            "auditor_fn_violation": 0.01611495377778954,
            "auditor_fp_violation": 0.024279521479469386,
            "ave_precision_score": 0.7316120526501776,
            "fpr": 0.1690450054884742,
            "logloss": 0.696532230519552,
            "mae": 0.3536756949933219,
            "precision": 0.7066666666666667,
            "recall": 0.7449799196787149
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(67)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7998886748955462,
            "auditor_fn_violation": 0.011142851646660516,
            "auditor_fp_violation": 0.02046783625730995,
            "ave_precision_score": 0.8005037774619904,
            "fpr": 0.12280701754385964,
            "logloss": 0.561678605433927,
            "mae": 0.30349951441064804,
            "precision": 0.7511111111111111,
            "recall": 0.7412280701754386
        },
        "train": {
            "accuracy": 0.6652030735455543,
            "auc_prc": 0.7479493713211913,
            "auditor_fn_violation": 0.009409757581368285,
            "auditor_fp_violation": 0.021435614748978725,
            "ave_precision_score": 0.7487394237595781,
            "fpr": 0.15148188803512624,
            "logloss": 0.6986810138240621,
            "mae": 0.3603456758839844,
            "precision": 0.7057569296375267,
            "recall": 0.6646586345381527
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(68)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7741228070175439,
            "auc_prc": 0.863135761510974,
            "auditor_fn_violation": 0.007216162665435525,
            "auditor_fp_violation": 0.012025334718374886,
            "ave_precision_score": 0.863314908846164,
            "fpr": 0.11513157894736842,
            "logloss": 0.4794504814237823,
            "mae": 0.30073379026317415,
            "precision": 0.7717391304347826,
            "recall": 0.7785087719298246
        },
        "train": {
            "accuracy": 0.7047200878155873,
            "auc_prc": 0.7967770387385834,
            "auditor_fn_violation": 0.012616878050070762,
            "auditor_fp_violation": 0.01968408714580737,
            "ave_precision_score": 0.7971571148034505,
            "fpr": 0.14818880351262348,
            "logloss": 0.5900329033492274,
            "mae": 0.35065217040945357,
            "precision": 0.7294589178356713,
            "recall": 0.7309236947791165
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(69)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7754446408817935,
            "auditor_fn_violation": 0.009233610341643581,
            "auditor_fp_violation": 0.017955043859649127,
            "ave_precision_score": 0.7758980773875632,
            "fpr": 0.15021929824561403,
            "logloss": 1.1118513343824579,
            "mae": 0.2914540094063474,
            "precision": 0.7192622950819673,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.7135016465422612,
            "auc_prc": 0.7650946754988419,
            "auditor_fn_violation": 0.006784547630698427,
            "auditor_fp_violation": 0.02073925627852213,
            "ave_precision_score": 0.766614276550541,
            "fpr": 0.16465422612513722,
            "logloss": 1.0070744930858637,
            "mae": 0.31214468217092683,
            "precision": 0.7206703910614525,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(70)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.844876293308205,
            "auditor_fn_violation": 0.006809787626962143,
            "auditor_fp_violation": 0.02042936288088643,
            "ave_precision_score": 0.8451231423086318,
            "fpr": 0.1611842105263158,
            "logloss": 0.5448917331292796,
            "mae": 0.2717886817422767,
            "precision": 0.7272727272727273,
            "recall": 0.8596491228070176
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8033376718715504,
            "auditor_fn_violation": 0.010395037890309867,
            "auditor_fp_violation": 0.021116671938082563,
            "ave_precision_score": 0.8038089527038418,
            "fpr": 0.1690450054884742,
            "logloss": 0.633471270269976,
            "mae": 0.3085063821880536,
            "precision": 0.7269503546099291,
            "recall": 0.8232931726907631
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(71)",
        "seed": 6126,
        "test": {
            "accuracy": 0.743421052631579,
            "auc_prc": 0.8483507705402036,
            "auditor_fn_violation": 0.006487573099415207,
            "auditor_fp_violation": 0.01914771852877809,
            "ave_precision_score": 0.848602338628958,
            "fpr": 0.1524122807017544,
            "logloss": 0.6122049331882452,
            "mae": 0.2809676511021125,
            "precision": 0.722,
            "recall": 0.7916666666666666
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.8165142873928404,
            "auditor_fn_violation": 0.012495646692147295,
            "auditor_fp_violation": 0.02111401408132511,
            "ave_precision_score": 0.8168794880931888,
            "fpr": 0.17233809001097694,
            "logloss": 0.7124137835693377,
            "mae": 0.3153729471874167,
            "precision": 0.7124542124542125,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(72)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6710526315789473,
            "auc_prc": 0.7550733069895365,
            "auditor_fn_violation": 0.0314327485380117,
            "auditor_fp_violation": 0.01683931594336719,
            "ave_precision_score": 0.7567498764182333,
            "fpr": 0.08442982456140351,
            "logloss": 0.7684170635918166,
            "mae": 0.36666407228882525,
            "precision": 0.7516129032258064,
            "recall": 0.5109649122807017
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.714393573792079,
            "auditor_fn_violation": 0.03204475420893233,
            "auditor_fp_violation": 0.018323264485983794,
            "ave_precision_score": 0.7160997637695434,
            "fpr": 0.10318331503841932,
            "logloss": 0.9154167866104416,
            "mae": 0.42002274829313635,
            "precision": 0.7053291536050157,
            "recall": 0.45180722891566266
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(73)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8389019080553874,
            "auditor_fn_violation": 0.00036549707602339835,
            "auditor_fp_violation": 0.017813173284087422,
            "ave_precision_score": 0.8392187055283256,
            "fpr": 0.14912280701754385,
            "logloss": 0.6332945537313089,
            "mae": 0.2601564615099575,
            "precision": 0.7364341085271318,
            "recall": 0.8333333333333334
        },
        "train": {
            "accuracy": 0.7244785949506037,
            "auc_prc": 0.8248221967103839,
            "auditor_fn_violation": 0.008900585878089748,
            "auditor_fp_violation": 0.022339286046517807,
            "ave_precision_score": 0.8251180607510809,
            "fpr": 0.16465422612513722,
            "logloss": 0.7380140188053778,
            "mae": 0.2963471478288297,
            "precision": 0.7257769652650823,
            "recall": 0.7971887550200804
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(74)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7247807017543859,
            "auc_prc": 0.7091009297307,
            "auditor_fn_violation": 0.02619315558633426,
            "auditor_fp_violation": 0.03018236380424747,
            "ave_precision_score": 0.7103957708236195,
            "fpr": 0.14035087719298245,
            "logloss": 1.2030634981259185,
            "mae": 0.32303513523190663,
            "precision": 0.7223427331887202,
            "recall": 0.7302631578947368
        },
        "train": {
            "accuracy": 0.6619099890230515,
            "auc_prc": 0.7142117626334719,
            "auditor_fn_violation": 0.03206238786099393,
            "auditor_fp_violation": 0.027689551699300718,
            "ave_precision_score": 0.715005718813383,
            "fpr": 0.141602634467618,
            "logloss": 1.453251407816592,
            "mae": 0.3709434659358807,
            "precision": 0.7120535714285714,
            "recall": 0.6405622489959839
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(75)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7346491228070176,
            "auc_prc": 0.7588716764693363,
            "auditor_fn_violation": 0.009233610341643581,
            "auditor_fp_violation": 0.017955043859649127,
            "ave_precision_score": 0.7596418858031868,
            "fpr": 0.15021929824561403,
            "logloss": 1.1354039309839339,
            "mae": 0.29795696129770327,
            "precision": 0.7192622950819673,
            "recall": 0.7697368421052632
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.7618237505110472,
            "auditor_fn_violation": 0.00833630901211873,
            "auditor_fp_violation": 0.02047347060277533,
            "ave_precision_score": 0.7633496445326925,
            "fpr": 0.16794731064763996,
            "logloss": 1.030864788429158,
            "mae": 0.31543724587717176,
            "precision": 0.7177121771217713,
            "recall": 0.7811244979919679
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(76)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.774580041158903,
            "auditor_fn_violation": 0.008949869190520161,
            "auditor_fp_violation": 0.017955043859649127,
            "ave_precision_score": 0.7750243537893705,
            "fpr": 0.15021929824561403,
            "logloss": 1.129725541665499,
            "mae": 0.2918480467812609,
            "precision": 0.7186858316221766,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7591237735214893,
            "auditor_fn_violation": 0.007260656236361473,
            "auditor_fp_violation": 0.020927964108302353,
            "ave_precision_score": 0.7606496739870852,
            "fpr": 0.1668496158068057,
            "logloss": 1.027157155883949,
            "mae": 0.313392305277872,
            "precision": 0.7179962894248608,
            "recall": 0.7771084337349398
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(77)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7390350877192983,
            "auc_prc": 0.6856500528508178,
            "auditor_fn_violation": 0.006540473991997538,
            "auditor_fp_violation": 0.020717913204062795,
            "ave_precision_score": 0.6772959998415613,
            "fpr": 0.19078947368421054,
            "logloss": 1.4640395014666157,
            "mae": 0.29632151130333606,
            "precision": 0.6925795053003534,
            "recall": 0.8596491228070176
        },
        "train": {
            "accuracy": 0.70801317233809,
            "auc_prc": 0.7093355487880901,
            "auditor_fn_violation": 0.016465422612513724,
            "auditor_fp_violation": 0.01723088535866448,
            "ave_precision_score": 0.70468678588102,
            "fpr": 0.20087815587266739,
            "logloss": 1.1532895047065068,
            "mae": 0.3238166424391626,
            "precision": 0.6939799331103679,
            "recall": 0.8333333333333334
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(78)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7982456140350878,
            "auc_prc": 0.8906344120732529,
            "auditor_fn_violation": 0.007963988919667597,
            "auditor_fp_violation": 0.00797841643582641,
            "ave_precision_score": 0.8907741285678774,
            "fpr": 0.0537280701754386,
            "logloss": 0.4762296932632313,
            "mae": 0.2772026478144717,
            "precision": 0.8675675675675676,
            "recall": 0.7039473684210527
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8408024585415825,
            "auditor_fn_violation": 0.027755368344949502,
            "auditor_fp_violation": 0.012816185284510277,
            "ave_precision_score": 0.8411268318957048,
            "fpr": 0.08342480790340286,
            "logloss": 0.5922503438783492,
            "mae": 0.32615775005655767,
            "precision": 0.8109452736318408,
            "recall": 0.6546184738955824
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(79)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7182017543859649,
            "auc_prc": 0.7789114616691373,
            "auditor_fn_violation": 0.006795360110803324,
            "auditor_fp_violation": 0.030124653739612185,
            "ave_precision_score": 0.780270535717243,
            "fpr": 0.23684210526315788,
            "logloss": 0.6904111710672695,
            "mae": 0.3231436209742944,
            "precision": 0.6576862123613312,
            "recall": 0.9100877192982456
        },
        "train": {
            "accuracy": 0.716794731064764,
            "auc_prc": 0.7598547048205978,
            "auditor_fn_violation": 0.007101953367807127,
            "auditor_fp_violation": 0.030400565591917995,
            "ave_precision_score": 0.7615786868459354,
            "fpr": 0.2305159165751921,
            "logloss": 0.7559286884649962,
            "mae": 0.335373018829931,
            "precision": 0.6818181818181818,
            "recall": 0.9036144578313253
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(80)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7105263157894737,
            "auc_prc": 0.7697712373804688,
            "auditor_fn_violation": 0.002029470606340416,
            "auditor_fp_violation": 0.025767543859649134,
            "ave_precision_score": 0.7707324991463538,
            "fpr": 0.2324561403508772,
            "logloss": 0.7077953099938938,
            "mae": 0.3397402681712584,
            "precision": 0.6558441558441559,
            "recall": 0.8859649122807017
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7449457084925435,
            "auditor_fn_violation": 0.014098104823244683,
            "auditor_fp_violation": 0.021443588319251115,
            "ave_precision_score": 0.7457618868219996,
            "fpr": 0.2239297475301866,
            "logloss": 0.7718325861572028,
            "mae": 0.35454870613024014,
            "precision": 0.6772151898734177,
            "recall": 0.8594377510040161
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(81)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7127192982456141,
            "auc_prc": 0.6496048944881953,
            "auditor_fn_violation": 0.004862072945521705,
            "auditor_fp_violation": 0.019469933056325023,
            "ave_precision_score": 0.6277830221335108,
            "fpr": 0.2138157894736842,
            "logloss": 2.439588605562196,
            "mae": 0.31002897897920584,
            "precision": 0.666095890410959,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7025246981339188,
            "auc_prc": 0.6786218646099967,
            "auditor_fn_violation": 0.014560988189861535,
            "auditor_fp_violation": 0.023043618087246805,
            "ave_precision_score": 0.6664819880946516,
            "fpr": 0.20965971459934138,
            "logloss": 1.9421692353708027,
            "mae": 0.3220108079489969,
            "precision": 0.6863711001642037,
            "recall": 0.8393574297188755
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(82)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.7725339634982945,
            "auditor_fn_violation": 0.0028855032317636198,
            "auditor_fp_violation": 0.023730859495229305,
            "ave_precision_score": 0.7734739928174195,
            "fpr": 0.15679824561403508,
            "logloss": 0.5902139270340719,
            "mae": 0.3150596715174942,
            "precision": 0.720703125,
            "recall": 0.8092105263157895
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.713778432537473,
            "auditor_fn_violation": 0.007727948015993728,
            "auditor_fp_violation": 0.02157116544360958,
            "ave_precision_score": 0.714658150453713,
            "fpr": 0.16794731064763996,
            "logloss": 0.700451188791122,
            "mae": 0.364720149342948,
            "precision": 0.7046332046332047,
            "recall": 0.7329317269076305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(83)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7248128572637906,
            "auditor_fn_violation": 0.0068025738688827315,
            "auditor_fp_violation": 0.020256232686980617,
            "ave_precision_score": 0.7268128513612886,
            "fpr": 0.18421052631578946,
            "logloss": 0.6921361245706825,
            "mae": 0.2876093741875242,
            "precision": 0.6994633273703041,
            "recall": 0.8574561403508771
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.729109764294338,
            "auditor_fn_violation": 0.012458175181516413,
            "auditor_fp_violation": 0.0235326637306209,
            "ave_precision_score": 0.7298483090872172,
            "fpr": 0.19538968166849616,
            "logloss": 0.7799245862413882,
            "mae": 0.3189195973528072,
            "precision": 0.6993243243243243,
            "recall": 0.8313253012048193
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(84)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6973684210526315,
            "auc_prc": 0.7030519937007689,
            "auditor_fn_violation": 0.028352473838104048,
            "auditor_fp_violation": 0.031935307017543865,
            "ave_precision_score": 0.7043985083774064,
            "fpr": 0.10416666666666667,
            "logloss": 1.2650447936919262,
            "mae": 0.36139030178248394,
            "precision": 0.7432432432432432,
            "recall": 0.6030701754385965
        },
        "train": {
            "accuracy": 0.6377607025246982,
            "auc_prc": 0.7246832954059743,
            "auditor_fn_violation": 0.04360581734181513,
            "auditor_fp_violation": 0.025411768458150717,
            "ave_precision_score": 0.7254361638793301,
            "fpr": 0.11086717892425905,
            "logloss": 1.5574451059319008,
            "mae": 0.4005422603306133,
            "precision": 0.727027027027027,
            "recall": 0.5401606425702812
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(85)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7445175438596491,
            "auc_prc": 0.7228762296489182,
            "auditor_fn_violation": 0.00783414127423823,
            "auditor_fp_violation": 0.022607917820867966,
            "ave_precision_score": 0.7249149874648899,
            "fpr": 0.18201754385964913,
            "logloss": 0.7616508938603029,
            "mae": 0.2788726882008632,
            "precision": 0.7009009009009008,
            "recall": 0.8530701754385965
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.726324102963627,
            "auditor_fn_violation": 0.011770462751114229,
            "auditor_fp_violation": 0.02493335424180649,
            "ave_precision_score": 0.7272350493388786,
            "fpr": 0.1942919868276619,
            "logloss": 0.862338084335954,
            "mae": 0.31043900142817926,
            "precision": 0.6989795918367347,
            "recall": 0.8253012048192772
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(86)",
        "seed": 6126,
        "test": {
            "accuracy": 0.768640350877193,
            "auc_prc": 0.8216183092818038,
            "auditor_fn_violation": 0.005482456140350877,
            "auditor_fp_violation": 0.01932565789473685,
            "ave_precision_score": 0.8220812066851115,
            "fpr": 0.13925438596491227,
            "logloss": 0.6968037796256749,
            "mae": 0.2525487724687643,
            "precision": 0.7454909819639278,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.7156970362239298,
            "auc_prc": 0.8146935585345465,
            "auditor_fn_violation": 0.016240593548728397,
            "auditor_fp_violation": 0.025717421985259534,
            "ave_precision_score": 0.8150620836417114,
            "fpr": 0.1602634467618002,
            "logloss": 0.821327013330158,
            "mae": 0.29576131606563355,
            "precision": 0.7250470809792844,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(87)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7489035087719298,
            "auc_prc": 0.7939729752402547,
            "auditor_fn_violation": 0.011484302862419207,
            "auditor_fp_violation": 0.02166532009849186,
            "ave_precision_score": 0.7949165921794075,
            "fpr": 0.13048245614035087,
            "logloss": 0.5819332439480336,
            "mae": 0.30303445442593946,
            "precision": 0.7440860215053764,
            "recall": 0.7587719298245614
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7533625700485373,
            "auditor_fn_violation": 0.019390404648230688,
            "auditor_fp_violation": 0.023253588771086773,
            "ave_precision_score": 0.7538429165058355,
            "fpr": 0.15477497255762898,
            "logloss": 0.706498756653349,
            "mae": 0.35519990279655467,
            "precision": 0.7086776859504132,
            "recall": 0.6887550200803213
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(88)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6732456140350878,
            "auc_prc": 0.7682572443440552,
            "auditor_fn_violation": 0.03233206371191137,
            "auditor_fp_violation": 0.014985380116959065,
            "ave_precision_score": 0.7689629645755287,
            "fpr": 0.08333333333333333,
            "logloss": 0.7269970118219516,
            "mae": 0.3644835672891707,
            "precision": 0.7548387096774194,
            "recall": 0.5131578947368421
        },
        "train": {
            "accuracy": 0.6004390779363337,
            "auc_prc": 0.7240922439769759,
            "auditor_fn_violation": 0.03180229149308542,
            "auditor_fp_violation": 0.017419593188444712,
            "ave_precision_score": 0.7248624110182239,
            "fpr": 0.10098792535675083,
            "logloss": 0.9062855212044975,
            "mae": 0.41875207558188393,
            "precision": 0.710691823899371,
            "recall": 0.4538152610441767
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(89)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7017543859649122,
            "auc_prc": 0.738325658776188,
            "auditor_fn_violation": 0.02563769621421976,
            "auditor_fp_violation": 0.02588777316097261,
            "ave_precision_score": 0.7400739842458927,
            "fpr": 0.15570175438596492,
            "logloss": 0.6615065344429805,
            "mae": 0.3485130371734972,
            "precision": 0.6965811965811965,
            "recall": 0.7149122807017544
        },
        "train": {
            "accuracy": 0.7069154774972558,
            "auc_prc": 0.7821086962277048,
            "auditor_fn_violation": 0.034566366453740324,
            "auditor_fp_violation": 0.026873589674758065,
            "ave_precision_score": 0.7827253391523796,
            "fpr": 0.1437980241492865,
            "logloss": 0.6629853657519604,
            "mae": 0.35140164700533805,
            "precision": 0.7342799188640974,
            "recall": 0.7269076305220884
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(90)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.753823776438567,
            "auditor_fn_violation": 0.006251923668821176,
            "auditor_fp_violation": 0.021518640350877208,
            "ave_precision_score": 0.7555755537761881,
            "fpr": 0.13925438596491227,
            "logloss": 0.6164449919942987,
            "mae": 0.2712764438868346,
            "precision": 0.7449799196787149,
            "recall": 0.8135964912280702
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.7485056359899277,
            "auditor_fn_violation": 0.012458175181516408,
            "auditor_fp_violation": 0.022934645960190618,
            "ave_precision_score": 0.7497393178914548,
            "fpr": 0.16465422612513722,
            "logloss": 0.7265862059814127,
            "mae": 0.3151853986165016,
            "precision": 0.719626168224299,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(91)",
        "seed": 6126,
        "test": {
            "accuracy": 0.6052631578947368,
            "auc_prc": 0.6153941484429795,
            "auditor_fn_violation": 0.09403374115112344,
            "auditor_fp_violation": 0.03147603108648815,
            "ave_precision_score": 0.616848579403809,
            "fpr": 0.06030701754385965,
            "logloss": 3.8492130635555997,
            "mae": 0.42105981668963305,
            "precision": 0.7330097087378641,
            "recall": 0.33114035087719296
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.6193020756420955,
            "auditor_fn_violation": 0.09406892112908274,
            "auditor_fp_violation": 0.03879141937524419,
            "ave_precision_score": 0.6207587110288768,
            "fpr": 0.07354555433589462,
            "logloss": 4.223938896326893,
            "mae": 0.46519787065395934,
            "precision": 0.7008928571428571,
            "recall": 0.3152610441767068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(92)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7724670816053751,
            "auditor_fn_violation": 0.009750596337334567,
            "auditor_fp_violation": 0.016764773776546633,
            "ave_precision_score": 0.7733070768842871,
            "fpr": 0.11842105263157894,
            "logloss": 1.5073878608361162,
            "mae": 0.31659782474162057,
            "precision": 0.7505773672055427,
            "recall": 0.7127192982456141
        },
        "train": {
            "accuracy": 0.6498353457738749,
            "auc_prc": 0.708111287495816,
            "auditor_fn_violation": 0.010328911695078899,
            "auditor_fp_violation": 0.020866833402880588,
            "ave_precision_score": 0.7089219816031962,
            "fpr": 0.14818880351262348,
            "logloss": 1.8128479205855752,
            "mae": 0.3852329660844953,
            "precision": 0.6993318485523385,
            "recall": 0.6305220883534136
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(93)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7379385964912281,
            "auc_prc": 0.7682488809437985,
            "auditor_fn_violation": 0.00782452293013235,
            "auditor_fp_violation": 0.018503289473684216,
            "ave_precision_score": 0.7688233677418708,
            "fpr": 0.14583333333333334,
            "logloss": 1.0700833299084742,
            "mae": 0.28958952590815407,
            "precision": 0.7246376811594203,
            "recall": 0.7675438596491229
        },
        "train": {
            "accuracy": 0.7145993413830956,
            "auc_prc": 0.765478368950003,
            "auditor_fn_violation": 0.006028504798557571,
            "auditor_fp_violation": 0.021712031851755385,
            "ave_precision_score": 0.7670082442046404,
            "fpr": 0.16136114160263446,
            "logloss": 0.9906596949083198,
            "mae": 0.3108119938632377,
            "precision": 0.7236842105263158,
            "recall": 0.7730923694779116
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(94)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7083333333333334,
            "auc_prc": 0.7834212385097583,
            "auditor_fn_violation": 0.006162953985841798,
            "auditor_fp_violation": 0.018943328716528162,
            "ave_precision_score": 0.7838478551595501,
            "fpr": 0.13267543859649122,
            "logloss": 0.6177886799992041,
            "mae": 0.3428023994125205,
            "precision": 0.7199074074074074,
            "recall": 0.6820175438596491
        },
        "train": {
            "accuracy": 0.6432491767288694,
            "auc_prc": 0.7458336222751942,
            "auditor_fn_violation": 0.011102588179281345,
            "auditor_fp_violation": 0.021688111140938174,
            "ave_precision_score": 0.7463640240359974,
            "fpr": 0.14709110867178923,
            "logloss": 0.7533676639556379,
            "mae": 0.390743420562072,
            "precision": 0.6961451247165533,
            "recall": 0.6164658634538153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(95)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7072368421052632,
            "auc_prc": 0.702773050860049,
            "auditor_fn_violation": 0.02428391428131733,
            "auditor_fp_violation": 0.03843009387503849,
            "ave_precision_score": 0.7047833816321059,
            "fpr": 0.21271929824561403,
            "logloss": 1.1963380453065777,
            "mae": 0.3362469132005163,
            "precision": 0.6637781629116117,
            "recall": 0.8399122807017544
        },
        "train": {
            "accuracy": 0.6871569703622393,
            "auc_prc": 0.7098141134506855,
            "auditor_fn_violation": 0.03673530565731642,
            "auditor_fp_violation": 0.033770727960387305,
            "ave_precision_score": 0.7105962001113459,
            "fpr": 0.18990120746432493,
            "logloss": 1.37905262836754,
            "mae": 0.36066814833061944,
            "precision": 0.6905187835420393,
            "recall": 0.7751004016064257
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(96)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8443057323729171,
            "auditor_fn_violation": 0.01798630347799323,
            "auditor_fp_violation": 0.02165089258233303,
            "ave_precision_score": 0.8442873286157896,
            "fpr": 0.1162280701754386,
            "logloss": 1.7907623354726647,
            "mae": 0.29535556798544305,
            "precision": 0.7579908675799086,
            "recall": 0.7280701754385965
        },
        "train": {
            "accuracy": 0.6783754116355654,
            "auc_prc": 0.7789605944503432,
            "auditor_fn_violation": 0.03360533241638342,
            "auditor_fp_violation": 0.02341837589004979,
            "ave_precision_score": 0.7793119572413217,
            "fpr": 0.13721185510428102,
            "logloss": 2.2245697735048333,
            "mae": 0.3547339106187175,
            "precision": 0.7252747252747253,
            "recall": 0.6626506024096386
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(97)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7675438596491229,
            "auc_prc": 0.8422799412838273,
            "auditor_fn_violation": 0.010762927054478304,
            "auditor_fp_violation": 0.01752462296091106,
            "ave_precision_score": 0.8426412710632477,
            "fpr": 0.14035087719298245,
            "logloss": 0.5970854946247828,
            "mae": 0.2552150674981245,
            "precision": 0.744,
            "recall": 0.8157894736842105
        },
        "train": {
            "accuracy": 0.7266739846322722,
            "auc_prc": 0.8339509602950794,
            "auditor_fn_violation": 0.012405274225331627,
            "auditor_fp_violation": 0.024933354241806493,
            "ave_precision_score": 0.8341950563993638,
            "fpr": 0.15697036223929747,
            "logloss": 0.7101286031143118,
            "mae": 0.294335077570266,
            "precision": 0.7327102803738318,
            "recall": 0.7871485943775101
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(98)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7653508771929824,
            "auc_prc": 0.7394680902264692,
            "auditor_fn_violation": 0.007252231455832565,
            "auditor_fp_violation": 0.019938827331486615,
            "ave_precision_score": 0.7407245991595371,
            "fpr": 0.13815789473684212,
            "logloss": 0.6266638463128235,
            "mae": 0.2756400866426686,
            "precision": 0.7449392712550608,
            "recall": 0.8070175438596491
        },
        "train": {
            "accuracy": 0.7102085620197585,
            "auc_prc": 0.7239621804015416,
            "auditor_fn_violation": 0.015451487618972049,
            "auditor_fp_violation": 0.022953250957492895,
            "ave_precision_score": 0.7257688164942584,
            "fpr": 0.15916575192096596,
            "logloss": 0.7490607428379435,
            "mae": 0.3269558624703211,
            "precision": 0.7232824427480916,
            "recall": 0.7610441767068273
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_lex",
        "model": "feat_lex:archive(99)",
        "seed": 6126,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8362532754468253,
            "auditor_fn_violation": 0.0038136734379809164,
            "auditor_fp_violation": 0.014485226223453369,
            "ave_precision_score": 0.8365117563358777,
            "fpr": 0.1611842105263158,
            "logloss": 0.5384531347155102,
            "mae": 0.31576129674846143,
            "precision": 0.7140077821011673,
            "recall": 0.8048245614035088
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7581775039283032,
            "auditor_fn_violation": 0.004430455080475588,
            "auditor_fp_violation": 0.01717772822351513,
            "ave_precision_score": 0.7587471727080989,
            "fpr": 0.1778265642151482,
            "logloss": 0.6529485658552632,
            "mae": 0.36489953260570274,
            "precision": 0.6896551724137931,
            "recall": 0.7228915662650602
        }
    }
]