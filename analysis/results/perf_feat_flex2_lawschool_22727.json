[
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(0)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5427631578947368,
            "auc_prc": 0.5348542032576235,
            "auditor_fn_violation": 0.008257807381524379,
            "auditor_fp_violation": 0.017143512851897188,
            "ave_precision_score": 0.556128552190101,
            "fpr": 0.06907894736842106,
            "logloss": 10.059004913017628,
            "mae": 0.4745174351721173,
            "precision": 0.6701570680628273,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5587266739846323,
            "auc_prc": 0.5494165292064559,
            "auditor_fn_violation": 0.007842006362909078,
            "auditor_fp_violation": 0.009664215398233188,
            "ave_precision_score": 0.57918708926879,
            "fpr": 0.04500548847420417,
            "logloss": 10.030360236538407,
            "mae": 0.45577407706766804,
            "precision": 0.7302631578947368,
            "recall": 0.23516949152542374
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(1)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7171052631578947,
            "auc_prc": 0.8109681386320606,
            "auditor_fn_violation": 0.03510364344471136,
            "auditor_fp_violation": 0.023102815177478583,
            "ave_precision_score": 0.8113425518307904,
            "fpr": 0.12609649122807018,
            "logloss": 1.2393343890762323,
            "mae": 0.2929626740028065,
            "precision": 0.7466960352422908,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8230631837493877,
            "auditor_fn_violation": 0.02216320303633556,
            "auditor_fp_violation": 0.027664910521617587,
            "ave_precision_score": 0.8239626563605804,
            "fpr": 0.11964873765093303,
            "logloss": 0.9432048679640002,
            "mae": 0.2572015492476194,
            "precision": 0.7640692640692641,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(2)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.641815811493801,
            "auditor_fn_violation": 0.011351641552012815,
            "auditor_fp_violation": 0.0019787841697266433,
            "ave_precision_score": 0.6385362435521627,
            "fpr": 0.03070175438596491,
            "logloss": 10.73382690641266,
            "mae": 0.46215589168301546,
            "precision": 0.8,
            "recall": 0.23236514522821577
        },
        "train": {
            "accuracy": 0.5653128430296378,
            "auc_prc": 0.6474026749347224,
            "auditor_fn_violation": 0.007260600197212977,
            "auditor_fp_violation": 0.007973915369978171,
            "ave_precision_score": 0.6421273876567095,
            "fpr": 0.03293084522502744,
            "logloss": 10.17534135936369,
            "mae": 0.45072493682996734,
            "precision": 0.7794117647058824,
            "recall": 0.2245762711864407
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(3)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6252484051089817,
            "auditor_fn_violation": 0.020849257479799096,
            "auditor_fp_violation": 0.010964912280701756,
            "ave_precision_score": 0.6178138513212967,
            "fpr": 0.08114035087719298,
            "logloss": 8.574907549885872,
            "mae": 0.42283904441268183,
            "precision": 0.7164750957854407,
            "recall": 0.3879668049792531
        },
        "train": {
            "accuracy": 0.6037321624588364,
            "auc_prc": 0.6205491619757197,
            "auditor_fn_violation": 0.01519098029730786,
            "auditor_fp_violation": 0.01042935120983975,
            "ave_precision_score": 0.6111798431321629,
            "fpr": 0.0845225027442371,
            "logloss": 8.593327907826467,
            "mae": 0.41149283883524745,
            "precision": 0.7094339622641509,
            "recall": 0.3983050847457627
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(4)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5471491228070176,
            "auc_prc": 0.7888789557330458,
            "auditor_fn_violation": 0.0008189561039528286,
            "auditor_fp_violation": 0.004929110567115469,
            "ave_precision_score": 0.6192392238204792,
            "fpr": 0.4418859649122807,
            "logloss": 11.464076393017645,
            "mae": 0.4494393436407814,
            "precision": 0.5394285714285715,
            "recall": 0.979253112033195
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7979145577721042,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.012219668991245946,
            "ave_precision_score": 0.6249290831267275,
            "fpr": 0.44127332601536773,
            "logloss": 11.316217605414947,
            "mae": 0.4480115227480741,
            "precision": 0.5363321799307958,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(5)",
        "seed": 22727,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8158289769527305,
            "auditor_fn_violation": 0.024666502875445882,
            "auditor_fp_violation": 0.025142798857609134,
            "ave_precision_score": 0.8161851642881837,
            "fpr": 0.1425438596491228,
            "logloss": 1.1244632405996755,
            "mae": 0.2845109776520986,
            "precision": 0.738430583501006,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8326594847593083,
            "auditor_fn_violation": 0.01719101750730247,
            "auditor_fp_violation": 0.0321031983177014,
            "ave_precision_score": 0.8329152699150548,
            "fpr": 0.13391877058177826,
            "logloss": 0.8747910733434064,
            "mae": 0.2540430392878232,
            "precision": 0.75,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(6)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6962719298245614,
            "auc_prc": 0.7735750194283656,
            "auditor_fn_violation": 0.022157312368057073,
            "auditor_fp_violation": 0.016100571195430444,
            "ave_precision_score": 0.7145412749418277,
            "fpr": 0.12719298245614036,
            "logloss": 3.667257239502485,
            "mae": 0.3218049654430757,
            "precision": 0.7345537757437071,
            "recall": 0.6659751037344398
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.7929707918364012,
            "auditor_fn_violation": 0.014332824796740412,
            "auditor_fp_violation": 0.03151059313028063,
            "ave_precision_score": 0.735651783620755,
            "fpr": 0.1163556531284303,
            "logloss": 3.3070102699844632,
            "mae": 0.29270991759846404,
            "precision": 0.7540603248259861,
            "recall": 0.6885593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(7)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.7868459627036445,
            "auditor_fn_violation": 0.0008189561039528286,
            "auditor_fp_violation": 0.006104651162790699,
            "ave_precision_score": 0.6137137697329403,
            "fpr": 0.4407894736842105,
            "logloss": 11.701417558985666,
            "mae": 0.44979936537689963,
            "precision": 0.540045766590389,
            "recall": 0.979253112033195
        },
        "train": {
            "accuracy": 0.5521405049396267,
            "auc_prc": 0.7981114277691761,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.011404524303063808,
            "ave_precision_score": 0.6245270552437824,
            "fpr": 0.44017563117453345,
            "logloss": 11.412444069914178,
            "mae": 0.44831745816314755,
            "precision": 0.5369515011547344,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(8)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6137482534808214,
            "auditor_fn_violation": 0.02043750454975613,
            "auditor_fp_violation": 0.00990922072623419,
            "ave_precision_score": 0.6340767941808696,
            "fpr": 0.05043859649122807,
            "logloss": 8.637839663753917,
            "mae": 0.4490768964925157,
            "precision": 0.7526881720430108,
            "recall": 0.29045643153526973
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6312664396519103,
            "auditor_fn_violation": 0.01563517460789969,
            "auditor_fp_violation": 0.009384165689409873,
            "ave_precision_score": 0.6540805020524407,
            "fpr": 0.048298572996706916,
            "logloss": 8.472221422345928,
            "mae": 0.42980567675239373,
            "precision": 0.7569060773480663,
            "recall": 0.2902542372881356
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(9)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7149122807017544,
            "auc_prc": 0.7993129142296627,
            "auditor_fn_violation": 0.023494940671180027,
            "auditor_fp_violation": 0.020384536923704615,
            "ave_precision_score": 0.7996629499499738,
            "fpr": 0.1513157894736842,
            "logloss": 1.1593076926400316,
            "mae": 0.29398783862120526,
            "precision": 0.7228915662650602,
            "recall": 0.7468879668049793
        },
        "train": {
            "accuracy": 0.7343578485181119,
            "auc_prc": 0.8120011644917761,
            "auditor_fn_violation": 0.014302591676124209,
            "auditor_fp_violation": 0.022201440755734148,
            "ave_precision_score": 0.8136328311523876,
            "fpr": 0.1525795828759605,
            "logloss": 0.9538977073964222,
            "mae": 0.2699749205632428,
            "precision": 0.7263779527559056,
            "recall": 0.7817796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(10)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7116228070175439,
            "auc_prc": 0.8055293348084569,
            "auditor_fn_violation": 0.03326326708888403,
            "auditor_fp_violation": 0.02093023255813954,
            "ave_precision_score": 0.8054209801419359,
            "fpr": 0.13267543859649122,
            "logloss": 2.1170008169501817,
            "mae": 0.2974263635442102,
            "precision": 0.737527114967462,
            "recall": 0.7053941908713693
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8151612563883668,
            "auditor_fn_violation": 0.02825168840350518,
            "auditor_fp_violation": 0.03404604317266315,
            "ave_precision_score": 0.8157278815482674,
            "fpr": 0.13172338090010977,
            "logloss": 1.4269627982069106,
            "mae": 0.26567790349778214,
            "precision": 0.7489539748953975,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(11)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6564109644508554,
            "auditor_fn_violation": 0.015307654509718292,
            "auditor_fp_violation": 0.015580375356997144,
            "ave_precision_score": 0.6767848359368878,
            "fpr": 0.06578947368421052,
            "logloss": 8.074325474671506,
            "mae": 0.4402099713344094,
            "precision": 0.7424892703862661,
            "recall": 0.35892116182572614
        },
        "train": {
            "accuracy": 0.6158068057080132,
            "auc_prc": 0.6478942930500626,
            "auditor_fn_violation": 0.01800033488995144,
            "auditor_fp_violation": 0.005140912511970877,
            "ave_precision_score": 0.6711765523486655,
            "fpr": 0.05817782656421515,
            "logloss": 8.157162480276268,
            "mae": 0.4327323668070023,
            "precision": 0.7675438596491229,
            "recall": 0.3707627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(12)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6337719298245614,
            "auc_prc": 0.8047245276698167,
            "auditor_fn_violation": 0.02502365873189198,
            "auditor_fp_violation": 0.002578029375764995,
            "ave_precision_score": 0.8052504582922094,
            "fpr": 0.020833333333333332,
            "logloss": 1.7513498031173587,
            "mae": 0.37250675935802763,
            "precision": 0.8978494623655914,
            "recall": 0.34647302904564314
        },
        "train": {
            "accuracy": 0.6421514818880352,
            "auc_prc": 0.8204626302511185,
            "auditor_fn_violation": 0.012530465683082475,
            "auditor_fp_violation": 0.008459001472761418,
            "ave_precision_score": 0.8217901520243294,
            "fpr": 0.027442371020856202,
            "logloss": 1.4917323811232566,
            "mae": 0.3603609864415294,
            "precision": 0.8724489795918368,
            "recall": 0.3622881355932203
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(13)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6041047485996139,
            "auditor_fn_violation": 0.017275424037271624,
            "auditor_fp_violation": 0.009297225622195024,
            "ave_precision_score": 0.6238364853735118,
            "fpr": 0.03508771929824561,
            "logloss": 9.906191286556627,
            "mae": 0.4611629700881436,
            "precision": 0.7762237762237763,
            "recall": 0.23029045643153526
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6122112094301464,
            "auditor_fn_violation": 0.008835048093918054,
            "auditor_fp_violation": 0.0032330738706120334,
            "ave_precision_score": 0.6354662621481503,
            "fpr": 0.02305159165751921,
            "logloss": 9.671487255846417,
            "mae": 0.4474002965283638,
            "precision": 0.8333333333333334,
            "recall": 0.22245762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(14)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7412280701754386,
            "auc_prc": 0.8364158932363689,
            "auditor_fn_violation": 0.03630705394190871,
            "auditor_fp_violation": 0.01593737250101999,
            "ave_precision_score": 0.8367961034872002,
            "fpr": 0.10964912280701754,
            "logloss": 1.7632724607544772,
            "mae": 0.2904599903925551,
            "precision": 0.7757847533632287,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.7837541163556532,
            "auc_prc": 0.8625654906789438,
            "auditor_fn_violation": 0.022884146681798733,
            "auditor_fp_violation": 0.03224072272828427,
            "ave_precision_score": 0.8626803482710124,
            "fpr": 0.09769484083424808,
            "logloss": 1.1238673687927367,
            "mae": 0.2635743063782549,
            "precision": 0.8035320088300221,
            "recall": 0.7711864406779662
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(15)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7791036920436727,
            "auditor_fn_violation": 0.0215840430952901,
            "auditor_fp_violation": 0.013667890656874742,
            "ave_precision_score": 0.7194490836599066,
            "fpr": 0.13267543859649122,
            "logloss": 4.100935522822451,
            "mae": 0.2997138961074912,
            "precision": 0.7420042643923241,
            "recall": 0.7219917012448133
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8062507931277144,
            "auditor_fn_violation": 0.015172375300005585,
            "auditor_fp_violation": 0.025319494210222324,
            "ave_precision_score": 0.7484900135762655,
            "fpr": 0.12294182217343579,
            "logloss": 3.49306478229252,
            "mae": 0.2673828630641848,
            "precision": 0.7622080679405521,
            "recall": 0.760593220338983
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(16)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7291666666666666,
            "auc_prc": 0.783255795928225,
            "auditor_fn_violation": 0.01909987624663318,
            "auditor_fp_violation": 0.011485108119135052,
            "ave_precision_score": 0.7235688426354976,
            "fpr": 0.13048245614035087,
            "logloss": 3.809233676361943,
            "mae": 0.2976536898027381,
            "precision": 0.7484143763213531,
            "recall": 0.7344398340248963
        },
        "train": {
            "accuracy": 0.7398463227222832,
            "auc_prc": 0.8067323204209387,
            "auditor_fn_violation": 0.011611843941282634,
            "auditor_fp_violation": 0.01977350979798915,
            "ave_precision_score": 0.7489967655865092,
            "fpr": 0.1251372118551043,
            "logloss": 3.3789467584249553,
            "mae": 0.2706540202565921,
            "precision": 0.7537796976241901,
            "recall": 0.739406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(17)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.8090376254568548,
            "auditor_fn_violation": 0.018312768435611852,
            "auditor_fp_violation": 0.01427478580171359,
            "ave_precision_score": 0.8093989110574583,
            "fpr": 0.12719298245614036,
            "logloss": 1.0384650205384667,
            "mae": 0.2887233070424025,
            "precision": 0.7483731019522777,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.8331894378016493,
            "auditor_fn_violation": 0.00796526447003665,
            "auditor_fp_violation": 0.024189293599613932,
            "ave_precision_score": 0.8336132352486563,
            "fpr": 0.11306256860592755,
            "logloss": 0.8273082762283163,
            "mae": 0.2585594391098727,
            "precision": 0.7760869565217391,
            "recall": 0.7563559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(18)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5822368421052632,
            "auc_prc": 0.6839630412466078,
            "auditor_fn_violation": 0.02579256751838102,
            "auditor_fp_violation": 0.007456140350877193,
            "ave_precision_score": 0.6820541231298287,
            "fpr": 0.046052631578947366,
            "logloss": 6.80732521959668,
            "mae": 0.43631771384474444,
            "precision": 0.772972972972973,
            "recall": 0.2966804979253112
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6968650550519722,
            "auditor_fn_violation": 0.01403049359057843,
            "auditor_fp_violation": 0.009339157700491839,
            "ave_precision_score": 0.6948060419728044,
            "fpr": 0.036223929747530186,
            "logloss": 6.446251309336472,
            "mae": 0.42162992177852315,
            "precision": 0.8081395348837209,
            "recall": 0.2944915254237288
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(19)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5953947368421053,
            "auc_prc": 0.6261686131474082,
            "auditor_fn_violation": 0.021711436267016087,
            "auditor_fp_violation": 0.014950530395756832,
            "ave_precision_score": 0.6187332306142936,
            "fpr": 0.08442982456140351,
            "logloss": 8.532386056859657,
            "mae": 0.4223273611140662,
            "precision": 0.7116104868913857,
            "recall": 0.3941908713692946
        },
        "train": {
            "accuracy": 0.5960482985729967,
            "auc_prc": 0.6205165826930511,
            "auditor_fn_violation": 0.014977022828331708,
            "auditor_fp_violation": 0.011289503886939932,
            "ave_precision_score": 0.6112559175342904,
            "fpr": 0.09659714599341383,
            "logloss": 8.557717507513347,
            "mae": 0.4111757483880737,
            "precision": 0.6857142857142857,
            "recall": 0.4067796610169492
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(20)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.7915050265518025,
            "auditor_fn_violation": 0.0019108975758899327,
            "auditor_fp_violation": 0.017135862913096694,
            "ave_precision_score": 0.6531528703535766,
            "fpr": 0.41228070175438597,
            "logloss": 9.415617995698586,
            "mae": 0.4248224346814625,
            "precision": 0.5550295857988166,
            "recall": 0.9730290456431535
        },
        "train": {
            "accuracy": 0.5784851811196488,
            "auc_prc": 0.8089834080970181,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.014620095066874369,
            "ave_precision_score": 0.6685723639051819,
            "fpr": 0.4138309549945115,
            "logloss": 9.164316612030053,
            "mae": 0.41926995034138587,
            "precision": 0.5522565320665083,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(21)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7773825653266804,
            "auditor_fn_violation": 0.019202245759627288,
            "auditor_fp_violation": 0.010827213382292948,
            "ave_precision_score": 0.7177580437218457,
            "fpr": 0.12719298245614036,
            "logloss": 4.337138705445192,
            "mae": 0.30067275048701864,
            "precision": 0.7483731019522777,
            "recall": 0.7157676348547718
        },
        "train": {
            "accuracy": 0.7464324917672887,
            "auc_prc": 0.8048108908786986,
            "auditor_fn_violation": 0.015265400286516961,
            "auditor_fp_violation": 0.02346416488926785,
            "ave_precision_score": 0.7471580059960938,
            "fpr": 0.1207464324917673,
            "logloss": 3.525223293849337,
            "mae": 0.2696394910018435,
            "precision": 0.7613882863340564,
            "recall": 0.7436440677966102
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(22)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7093896515409689,
            "auditor_fn_violation": 0.020023476741646656,
            "auditor_fp_violation": 0.007377090983272135,
            "ave_precision_score": 0.6742252168007488,
            "fpr": 0.09100877192982457,
            "logloss": 6.316200881669809,
            "mae": 0.3595947981185224,
            "precision": 0.7537091988130564,
            "recall": 0.5269709543568465
        },
        "train": {
            "accuracy": 0.6717892425905598,
            "auc_prc": 0.7173306141885093,
            "auditor_fn_violation": 0.01111648588810954,
            "auditor_fp_violation": 0.007466325272735911,
            "ave_precision_score": 0.6845598266466212,
            "fpr": 0.07793633369923161,
            "logloss": 6.238616067243973,
            "mae": 0.34488880229595636,
            "precision": 0.7746031746031746,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(23)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.5651398315267926,
            "auditor_fn_violation": 0.006669942491082481,
            "auditor_fp_violation": 0.011311709506323951,
            "ave_precision_score": 0.5823900166596527,
            "fpr": 0.07346491228070176,
            "logloss": 8.793974303290959,
            "mae": 0.4524880312483012,
            "precision": 0.7008928571428571,
            "recall": 0.3257261410788382
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.5823617049254081,
            "auditor_fn_violation": 0.01231650821410631,
            "auditor_fp_violation": 0.008659036979063789,
            "ave_precision_score": 0.6029955980740114,
            "fpr": 0.06256860592755215,
            "logloss": 8.747058690339037,
            "mae": 0.4371556444437326,
            "precision": 0.7135678391959799,
            "recall": 0.3008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(24)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5745614035087719,
            "auc_prc": 0.6189402461395448,
            "auditor_fn_violation": 0.01151315789473686,
            "auditor_fp_violation": 0.01125560995512036,
            "ave_precision_score": 0.6396984704845077,
            "fpr": 0.05592105263157895,
            "logloss": 8.287152823397655,
            "mae": 0.45057175598712146,
            "precision": 0.7397959183673469,
            "recall": 0.3008298755186722
        },
        "train": {
            "accuracy": 0.5883644346871569,
            "auc_prc": 0.6278533991812325,
            "auditor_fn_violation": 0.01193510576940968,
            "auditor_fp_violation": 0.007281292429406221,
            "ave_precision_score": 0.651272116637746,
            "fpr": 0.052689352360043906,
            "logloss": 8.292838911811074,
            "mae": 0.4319568913781792,
            "precision": 0.7512953367875648,
            "recall": 0.3072033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(25)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5592105263157895,
            "auc_prc": 0.6072408761435543,
            "auditor_fn_violation": 0.017675802576981887,
            "auditor_fp_violation": 0.006334149326805387,
            "ave_precision_score": 0.6283016008804649,
            "fpr": 0.03508771929824561,
            "logloss": 9.91895737244439,
            "mae": 0.4607681616432183,
            "precision": 0.7777777777777778,
            "recall": 0.23236514522821577
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6139257165240631,
            "auditor_fn_violation": 0.008130383821094368,
            "auditor_fp_violation": 0.005253432484265957,
            "ave_precision_score": 0.6368630531847026,
            "fpr": 0.020856201975850714,
            "logloss": 9.64215383679896,
            "mae": 0.45062677043311195,
            "precision": 0.8455284552845529,
            "recall": 0.22033898305084745
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(26)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7765190351109289,
            "auditor_fn_violation": 0.021859303341340914,
            "auditor_fp_violation": 0.01834710322317422,
            "ave_precision_score": 0.7168107734622021,
            "fpr": 0.1699561403508772,
            "logloss": 4.491053367433914,
            "mae": 0.30433505583605275,
            "precision": 0.6984435797665369,
            "recall": 0.7448132780082988
        },
        "train": {
            "accuracy": 0.7365532381997805,
            "auc_prc": 0.8012837000585802,
            "auditor_fn_violation": 0.013879327987497447,
            "auditor_fp_violation": 0.03444111329761033,
            "ave_precision_score": 0.7436143215123128,
            "fpr": 0.15367727771679474,
            "logloss": 3.620955874449473,
            "mae": 0.2682983784594007,
            "precision": 0.7265625,
            "recall": 0.788135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(27)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6875,
            "auc_prc": 0.8497524993342738,
            "auditor_fn_violation": 0.016629358666375483,
            "auditor_fp_violation": 0.025828743370053066,
            "ave_precision_score": 0.8502747427122062,
            "fpr": 0.2598684210526316,
            "logloss": 0.9352406617181473,
            "mae": 0.31729516043004713,
            "precision": 0.646795827123696,
            "recall": 0.9004149377593361
        },
        "train": {
            "accuracy": 0.7113062568605928,
            "auc_prc": 0.8813968871872768,
            "auditor_fn_violation": 0.009530409868090572,
            "auditor_fp_violation": 0.03872687402013858,
            "ave_precision_score": 0.8815453221875189,
            "fpr": 0.25466520307354557,
            "logloss": 0.8121720545594343,
            "mae": 0.2902134151908686,
            "precision": 0.6552748885586924,
            "recall": 0.934322033898305
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(28)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8155605398000577,
            "auditor_fn_violation": 0.024666502875445882,
            "auditor_fp_violation": 0.02510709914320686,
            "ave_precision_score": 0.8159276568348174,
            "fpr": 0.14692982456140352,
            "logloss": 1.124448192766519,
            "mae": 0.28467981292633293,
            "precision": 0.7325349301397206,
            "recall": 0.7614107883817427
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8323893863511048,
            "auditor_fn_violation": 0.01568401272581816,
            "auditor_fp_violation": 0.02836753523750466,
            "ave_precision_score": 0.8326553103330149,
            "fpr": 0.13611416026344675,
            "logloss": 0.8777559676913184,
            "mae": 0.25460160948456484,
            "precision": 0.7489878542510121,
            "recall": 0.7838983050847458
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(29)",
        "seed": 22727,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8162517215094827,
            "auditor_fn_violation": 0.026256642643954286,
            "auditor_fp_violation": 0.01652896776825786,
            "ave_precision_score": 0.8175300681556432,
            "fpr": 0.15460526315789475,
            "logloss": 0.9904319938288311,
            "mae": 0.29578649245487393,
            "precision": 0.7283236994219653,
            "recall": 0.7842323651452282
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8380370835284523,
            "auditor_fn_violation": 0.012351392584048082,
            "auditor_fp_violation": 0.026612223669701375,
            "ave_precision_score": 0.8383940283234592,
            "fpr": 0.15806805708013172,
            "logloss": 0.7584967535120322,
            "mae": 0.2650488286980024,
            "precision": 0.7308411214953271,
            "recall": 0.8283898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(30)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7192982456140351,
            "auc_prc": 0.7726298165245516,
            "auditor_fn_violation": 0.01428395937977725,
            "auditor_fp_violation": 0.017105263157894738,
            "ave_precision_score": 0.7700588818570824,
            "fpr": 0.14144736842105263,
            "logloss": 1.3886154610782968,
            "mae": 0.292600565154963,
            "precision": 0.7334710743801653,
            "recall": 0.7365145228215768
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.7959424761583649,
            "auditor_fn_violation": 0.013972352974008815,
            "auditor_fp_violation": 0.017968189353610272,
            "ave_precision_score": 0.7946468824830655,
            "fpr": 0.12623490669593854,
            "logloss": 1.0179184024354833,
            "mae": 0.2694559361295061,
            "precision": 0.7568710359408034,
            "recall": 0.7584745762711864
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(31)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.5902608578105393,
            "auditor_fn_violation": 0.015810402562422665,
            "auditor_fp_violation": 0.008108935128518973,
            "ave_precision_score": 0.6173461650919401,
            "fpr": 0.02850877192982456,
            "logloss": 10.030380874990003,
            "mae": 0.46638327188017875,
            "precision": 0.7868852459016393,
            "recall": 0.1991701244813278
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6050234979938545,
            "auditor_fn_violation": 0.005246609239241678,
            "auditor_fp_violation": 0.0032730809718725076,
            "ave_precision_score": 0.6375199059467678,
            "fpr": 0.014270032930845226,
            "logloss": 9.904799466268317,
            "mae": 0.4453256851940561,
            "precision": 0.8807339449541285,
            "recall": 0.2033898305084746
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(32)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6491228070175439,
            "auc_prc": 0.7323899979775703,
            "auditor_fn_violation": 0.01704793623061805,
            "auditor_fp_violation": 0.026762035903712775,
            "ave_precision_score": 0.7351844347528202,
            "fpr": 0.12609649122807018,
            "logloss": 5.125865863645526,
            "mae": 0.3655604366243334,
            "precision": 0.7066326530612245,
            "recall": 0.5746887966804979
        },
        "train": {
            "accuracy": 0.6849615806805708,
            "auc_prc": 0.7483861272360387,
            "auditor_fn_violation": 0.0017837541163556532,
            "auditor_fp_violation": 0.03194066946883072,
            "ave_precision_score": 0.7508694102061795,
            "fpr": 0.1207464324917673,
            "logloss": 4.968295270289898,
            "mae": 0.330916806621478,
            "precision": 0.7283950617283951,
            "recall": 0.625
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(33)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5986842105263158,
            "auc_prc": 0.7467447953596401,
            "auditor_fn_violation": 0.007980272257407005,
            "auditor_fp_violation": 0.011219910240718094,
            "ave_precision_score": 0.7218580067754522,
            "fpr": 0.3399122807017544,
            "logloss": 3.7208934901251127,
            "mae": 0.4045080240368155,
            "precision": 0.5788043478260869,
            "recall": 0.8838174273858921
        },
        "train": {
            "accuracy": 0.610318331503842,
            "auc_prc": 0.7219862337000684,
            "auditor_fn_violation": 0.005390797968334296,
            "auditor_fp_violation": 0.016337899977245964,
            "ave_precision_score": 0.6916030817301143,
            "fpr": 0.3380900109769484,
            "logloss": 3.793392718842422,
            "mae": 0.39256846916149224,
            "precision": 0.5798090040927695,
            "recall": 0.9004237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(34)",
        "seed": 22727,
        "test": {
            "accuracy": 0.731359649122807,
            "auc_prc": 0.8155957432264135,
            "auditor_fn_violation": 0.02240527407730946,
            "auditor_fp_violation": 0.022266421868625052,
            "ave_precision_score": 0.8159964289254309,
            "fpr": 0.14035087719298245,
            "logloss": 1.123285759040658,
            "mae": 0.2844560753564042,
            "precision": 0.7403651115618661,
            "recall": 0.7572614107883817
        },
        "train": {
            "accuracy": 0.7497255762897914,
            "auc_prc": 0.8331578204072079,
            "auditor_fn_violation": 0.016763102569350135,
            "auditor_fp_violation": 0.0321031983177014,
            "ave_precision_score": 0.8334214864691845,
            "fpr": 0.13391877058177826,
            "logloss": 0.8737319968736171,
            "mae": 0.2542081769673948,
            "precision": 0.75,
            "recall": 0.7754237288135594
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(35)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6313142320456321,
            "auditor_fn_violation": 0.019659496251000958,
            "auditor_fp_violation": 0.013060995512035906,
            "ave_precision_score": 0.65271445287001,
            "fpr": 0.06469298245614036,
            "logloss": 8.234254805506287,
            "mae": 0.4347576817961677,
            "precision": 0.7342342342342343,
            "recall": 0.3381742738589212
        },
        "train": {
            "accuracy": 0.601536772777168,
            "auc_prc": 0.6441276864367833,
            "auditor_fn_violation": 0.019032912240227726,
            "auditor_fp_violation": 0.010766911126724997,
            "ave_precision_score": 0.6675931508582946,
            "fpr": 0.06037321624588365,
            "logloss": 8.230615904533769,
            "mae": 0.41615594632424796,
            "precision": 0.7488584474885844,
            "recall": 0.3474576271186441
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(36)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.7774583789147642,
            "auditor_fn_violation": 0.022685084079493344,
            "auditor_fp_violation": 0.012392900856793149,
            "ave_precision_score": 0.7177858167904659,
            "fpr": 0.12390350877192982,
            "logloss": 4.365914063277056,
            "mae": 0.3021838879679136,
            "precision": 0.7483296213808464,
            "recall": 0.6970954356846473
        },
        "train": {
            "accuracy": 0.743139407244786,
            "auc_prc": 0.8051666102676825,
            "auditor_fn_violation": 0.014042121713892358,
            "auditor_fp_violation": 0.02260901309982522,
            "ave_precision_score": 0.7474042408243652,
            "fpr": 0.11525795828759605,
            "logloss": 3.5605543361613368,
            "mae": 0.2709488869496401,
            "precision": 0.765625,
            "recall": 0.7266949152542372
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(37)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7373678880565582,
            "auditor_fn_violation": 0.011169651306689973,
            "auditor_fp_violation": 0.007894736842105263,
            "ave_precision_score": 0.7389533076882131,
            "fpr": 0.10197368421052631,
            "logloss": 5.570944770154948,
            "mae": 0.3552331725351148,
            "precision": 0.7394957983193278,
            "recall": 0.5477178423236515
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7545464930084864,
            "auditor_fn_violation": 0.0010000186049973062,
            "auditor_fp_violation": 0.02140379917435345,
            "ave_precision_score": 0.7562612050581285,
            "fpr": 0.09330406147091108,
            "logloss": 5.217436384121443,
            "mae": 0.3265290306442251,
            "precision": 0.7578347578347578,
            "recall": 0.5635593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(38)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7378515200914175,
            "auditor_fn_violation": 0.01622898012666522,
            "auditor_fp_violation": 0.00420746634026928,
            "ave_precision_score": 0.7401539263152961,
            "fpr": 0.09868421052631579,
            "logloss": 5.187370925313385,
            "mae": 0.3544830915282348,
            "precision": 0.7413793103448276,
            "recall": 0.5352697095435685
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7541377113639397,
            "auditor_fn_violation": 0.0019744553387039745,
            "auditor_fp_violation": 0.016500428826116638,
            "ave_precision_score": 0.7565081527063211,
            "fpr": 0.09110867178924259,
            "logloss": 5.008205900515497,
            "mae": 0.3247829990814664,
            "precision": 0.7614942528735632,
            "recall": 0.5614406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(39)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6557017543859649,
            "auc_prc": 0.7390347188194608,
            "auditor_fn_violation": 0.01558291475576909,
            "auditor_fp_violation": 0.015503875968992255,
            "ave_precision_score": 0.7406044607580504,
            "fpr": 0.10964912280701754,
            "logloss": 5.550251891222306,
            "mae": 0.354844941886314,
            "precision": 0.7282608695652174,
            "recall": 0.5560165975103735
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7556877301534393,
            "auditor_fn_violation": 0.0012581629425663819,
            "auditor_fp_violation": 0.02495943029887806,
            "ave_precision_score": 0.7573980427214244,
            "fpr": 0.09989023051591657,
            "logloss": 5.204879891600215,
            "mae": 0.32700785567071805,
            "precision": 0.7486187845303868,
            "recall": 0.5741525423728814
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(40)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6387953710172447,
            "auditor_fn_violation": 0.013922253767198075,
            "auditor_fp_violation": 0.00773918808649531,
            "ave_precision_score": 0.6398612072683196,
            "fpr": 0.03399122807017544,
            "logloss": 10.807518158883978,
            "mae": 0.45779717833277556,
            "precision": 0.7960526315789473,
            "recall": 0.25103734439834025
        },
        "train": {
            "accuracy": 0.579582875960483,
            "auc_prc": 0.6490994063939111,
            "auditor_fn_violation": 0.007958287596048313,
            "auditor_fp_violation": 0.006373631319559223,
            "ave_precision_score": 0.6450343645230898,
            "fpr": 0.031833150384193196,
            "logloss": 10.21525519368943,
            "mae": 0.4465855167079811,
            "precision": 0.8027210884353742,
            "recall": 0.25
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(41)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7418988573453154,
            "auditor_fn_violation": 0.012730217660333417,
            "auditor_fp_violation": 0.011913504691962467,
            "ave_precision_score": 0.7441917503450122,
            "fpr": 0.1118421052631579,
            "logloss": 5.150490323136955,
            "mae": 0.3509772392700903,
            "precision": 0.7287234042553191,
            "recall": 0.5684647302904564
        },
        "train": {
            "accuracy": 0.6750823271130626,
            "auc_prc": 0.7560201215077478,
            "auditor_fn_violation": 0.002976799568364064,
            "auditor_fp_violation": 0.020976223279632136,
            "ave_precision_score": 0.7583783208634232,
            "fpr": 0.10318331503841932,
            "logloss": 4.990629309879446,
            "mae": 0.3256816002422317,
            "precision": 0.7417582417582418,
            "recall": 0.5720338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(42)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6885964912280702,
            "auc_prc": 0.8010564725430345,
            "auditor_fn_violation": 0.01985968552085609,
            "auditor_fp_violation": 0.014473684210526317,
            "ave_precision_score": 0.8011962576440387,
            "fpr": 0.09100877192982457,
            "logloss": 2.1449223537208897,
            "mae": 0.33159925733182993,
            "precision": 0.771978021978022,
            "recall": 0.58298755186722
        },
        "train": {
            "accuracy": 0.712403951701427,
            "auc_prc": 0.8074508333398367,
            "auditor_fn_violation": 0.008325736292768247,
            "auditor_fp_violation": 0.021333786747147622,
            "ave_precision_score": 0.8076285304738644,
            "fpr": 0.07574094401756312,
            "logloss": 1.7996856839369701,
            "mae": 0.325023192710803,
            "precision": 0.8017241379310345,
            "recall": 0.5911016949152542
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(43)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5635964912280702,
            "auc_prc": 0.6029480061268622,
            "auditor_fn_violation": 0.015578364999636036,
            "auditor_fp_violation": 0.01060281517747858,
            "ave_precision_score": 0.6231455484374744,
            "fpr": 0.02850877192982456,
            "logloss": 9.933087141327338,
            "mae": 0.4625433767925769,
            "precision": 0.8088235294117647,
            "recall": 0.22821576763485477
        },
        "train": {
            "accuracy": 0.5697036223929748,
            "auc_prc": 0.611922522765012,
            "auditor_fn_violation": 0.006209417849634418,
            "auditor_fp_violation": 0.006278614454065597,
            "ave_precision_score": 0.6348593685052717,
            "fpr": 0.024149286498353458,
            "logloss": 9.691965468986375,
            "mae": 0.4483752976075423,
            "precision": 0.8225806451612904,
            "recall": 0.21610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(44)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5657894736842105,
            "auc_prc": 0.6085575203594855,
            "auditor_fn_violation": 0.017973811603698056,
            "auditor_fp_violation": 0.00955732354141167,
            "ave_precision_score": 0.6342510712382496,
            "fpr": 0.03399122807017544,
            "logloss": 9.89168120691886,
            "mae": 0.4570766285325607,
            "precision": 0.7905405405405406,
            "recall": 0.24273858921161826
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6138341219920422,
            "auditor_fn_violation": 0.01471887849076263,
            "auditor_fp_violation": 0.004688332178961768,
            "ave_precision_score": 0.6457312218378607,
            "fpr": 0.024149286498353458,
            "logloss": 9.668716370059792,
            "mae": 0.44144172155234734,
            "precision": 0.8394160583941606,
            "recall": 0.24364406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(45)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.7899921301965765,
            "auditor_fn_violation": 0.0008189561039528286,
            "auditor_fp_violation": 0.005870053039575704,
            "ave_precision_score": 0.6316625919102364,
            "fpr": 0.43969298245614036,
            "logloss": 10.791331761291618,
            "mae": 0.4486407309413424,
            "precision": 0.5406643757159221,
            "recall": 0.979253112033195
        },
        "train": {
            "accuracy": 0.5532381997804611,
            "auc_prc": 0.8053985194613691,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.013354870489511889,
            "ave_precision_score": 0.6460098328561574,
            "fpr": 0.43907793633369924,
            "logloss": 10.51910132409643,
            "mae": 0.4455435405535553,
            "precision": 0.5375722543352601,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(46)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7532894736842105,
            "auc_prc": 0.7917731789268183,
            "auditor_fn_violation": 0.017623480381451558,
            "auditor_fp_violation": 0.0046715626274989866,
            "ave_precision_score": 0.7917043011749281,
            "fpr": 0.14692982456140352,
            "logloss": 0.8879400605402606,
            "mae": 0.2922150542451091,
            "precision": 0.7447619047619047,
            "recall": 0.8112033195020747
        },
        "train": {
            "accuracy": 0.7870472008781558,
            "auc_prc": 0.8314024823418296,
            "auditor_fn_violation": 0.009395523637649075,
            "auditor_fp_violation": 0.026742246748797913,
            "ave_precision_score": 0.8309232559838834,
            "fpr": 0.13391877058177826,
            "logloss": 0.7234456022988508,
            "mae": 0.267666898428847,
            "precision": 0.7662835249042146,
            "recall": 0.847457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(47)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6458333333333334,
            "auc_prc": 0.6887638994550034,
            "auditor_fn_violation": 0.001583315134308807,
            "auditor_fp_violation": 0.01540952672378621,
            "ave_precision_score": 0.6443797534127809,
            "fpr": 0.12171052631578948,
            "logloss": 6.591346041355907,
            "mae": 0.3736315939205397,
            "precision": 0.7086614173228346,
            "recall": 0.5601659751037344
        },
        "train": {
            "accuracy": 0.6575192096597146,
            "auc_prc": 0.6974850654308523,
            "auditor_fn_violation": 0.00838155128467508,
            "auditor_fp_violation": 0.010041782416378913,
            "ave_precision_score": 0.6576860788519728,
            "fpr": 0.09879253567508232,
            "logloss": 6.585148481168573,
            "mae": 0.358447270620246,
            "precision": 0.7352941176470589,
            "recall": 0.5296610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(48)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5603070175438597,
            "auc_prc": 0.6052763920010569,
            "auditor_fn_violation": 0.016583861105044773,
            "auditor_fp_violation": 0.005686454508363934,
            "ave_precision_score": 0.6253184567335406,
            "fpr": 0.03289473684210526,
            "logloss": 9.917454609261036,
            "mae": 0.45952878628783134,
            "precision": 0.7872340425531915,
            "recall": 0.23029045643153526
        },
        "train": {
            "accuracy": 0.575192096597146,
            "auc_prc": 0.6139486894695837,
            "auditor_fn_violation": 0.010474613481181047,
            "auditor_fp_violation": 0.0030130348136794285,
            "ave_precision_score": 0.6365738958893361,
            "fpr": 0.018660812294182216,
            "logloss": 9.660123948035992,
            "mae": 0.4474183600193918,
            "precision": 0.8571428571428571,
            "recall": 0.21610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(49)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.6360590294878399,
            "auditor_fn_violation": 0.01089211618257263,
            "auditor_fp_violation": 0.002430130558955528,
            "ave_precision_score": 0.6371364058571132,
            "fpr": 0.025219298245614034,
            "logloss": 10.601697634566838,
            "mae": 0.4644788911519996,
            "precision": 0.8099173553719008,
            "recall": 0.2033195020746888
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6449283095692511,
            "auditor_fn_violation": 0.008693184989488179,
            "auditor_fp_violation": 0.0023329140922513755,
            "ave_precision_score": 0.6409337822105465,
            "fpr": 0.018660812294182216,
            "logloss": 10.019795011456813,
            "mae": 0.4502936416754655,
            "precision": 0.8559322033898306,
            "recall": 0.21398305084745764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(50)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7456140350877193,
            "auc_prc": 0.842056685939902,
            "auditor_fn_violation": 0.04265851350367621,
            "auditor_fp_violation": 0.017974806201550397,
            "ave_precision_score": 0.8421615502744655,
            "fpr": 0.09758771929824561,
            "logloss": 1.7719606170556623,
            "mae": 0.29064389508339733,
            "precision": 0.7920560747663551,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.7826564215148188,
            "auc_prc": 0.8639220733105155,
            "auditor_fn_violation": 0.029088913282107574,
            "auditor_fp_violation": 0.027137316873745092,
            "ave_precision_score": 0.8640336161596044,
            "fpr": 0.08781558726673985,
            "logloss": 1.1346480613103516,
            "mae": 0.26922577894899463,
            "precision": 0.815668202764977,
            "recall": 0.75
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(51)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4725877192982456,
            "auc_prc": 0.374656876643146,
            "auditor_fn_violation": 0.0023021766033340697,
            "auditor_fp_violation": 0.002396980824153407,
            "ave_precision_score": 0.5219014299654197,
            "fpr": 0.005482456140350877,
            "logloss": 17.4971694978016,
            "mae": 0.5291391973620603,
            "precision": 0.5454545454545454,
            "recall": 0.012448132780082987
        },
        "train": {
            "accuracy": 0.4829857299670692,
            "auc_prc": 0.3317015753418241,
            "auditor_fn_violation": 0.002307019665482166,
            "auditor_fp_violation": 0.0002900514841384346,
            "ave_precision_score": 0.5168826031900168,
            "fpr": 0.003293084522502744,
            "logloss": 17.39853856645731,
            "mae": 0.5186831177440288,
            "precision": 0.5714285714285714,
            "recall": 0.00847457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(52)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7373837411187696,
            "auditor_fn_violation": 0.011169651306689973,
            "auditor_fp_violation": 0.007894736842105263,
            "ave_precision_score": 0.7389603452794284,
            "fpr": 0.10197368421052631,
            "logloss": 5.585466141601629,
            "mae": 0.35528320901707844,
            "precision": 0.7394957983193278,
            "recall": 0.5477178423236515
        },
        "train": {
            "accuracy": 0.6794731064763996,
            "auc_prc": 0.7546643769054372,
            "auditor_fn_violation": 0.0011256023367876647,
            "auditor_fp_violation": 0.02140379917435345,
            "ave_precision_score": 0.7563780109598418,
            "fpr": 0.09330406147091108,
            "logloss": 5.22110297783456,
            "mae": 0.3265325471480486,
            "precision": 0.7571428571428571,
            "recall": 0.5614406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(53)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6502192982456141,
            "auc_prc": 0.7748721643340769,
            "auditor_fn_violation": 0.0191772221008954,
            "auditor_fp_violation": 0.008088535291717668,
            "ave_precision_score": 0.7152377183218568,
            "fpr": 0.08662280701754387,
            "logloss": 5.498282688733056,
            "mae": 0.3439334782295474,
            "precision": 0.7538940809968847,
            "recall": 0.5020746887966805
        },
        "train": {
            "accuracy": 0.6761800219538968,
            "auc_prc": 0.8020163402223965,
            "auditor_fn_violation": 0.011618820815270992,
            "auditor_fp_violation": 0.015830309880003706,
            "ave_precision_score": 0.7443621880672395,
            "fpr": 0.0801317233809001,
            "logloss": 4.5738977039353825,
            "mae": 0.3186016931015424,
            "precision": 0.7739938080495357,
            "recall": 0.5296610169491526
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(54)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5341594583403967,
            "auditor_fn_violation": 0.007689087864890457,
            "auditor_fp_violation": 0.01884434924520604,
            "ave_precision_score": 0.5532022590841306,
            "fpr": 0.07346491228070176,
            "logloss": 10.187228241428329,
            "mae": 0.4748973034721219,
            "precision": 0.6616161616161617,
            "recall": 0.2717842323651452
        },
        "train": {
            "accuracy": 0.5543358946212953,
            "auc_prc": 0.5428408804254787,
            "auditor_fn_violation": 0.007628048893932913,
            "auditor_fp_violation": 0.010486861417901679,
            "ave_precision_score": 0.5718776732753461,
            "fpr": 0.04610318331503842,
            "logloss": 10.106603837327295,
            "mae": 0.4578621018196777,
            "precision": 0.72,
            "recall": 0.2288135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(55)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7368421052631579,
            "auc_prc": 0.838835990774896,
            "auditor_fn_violation": 0.03277871806071195,
            "auditor_fp_violation": 0.012114953080375359,
            "ave_precision_score": 0.8389804122881876,
            "fpr": 0.08662280701754387,
            "logloss": 1.648885359155865,
            "mae": 0.292184885196487,
            "precision": 0.8025,
            "recall": 0.6659751037344398
        },
        "train": {
            "accuracy": 0.7639956092206367,
            "auc_prc": 0.8597762187360725,
            "auditor_fn_violation": 0.02034456455003814,
            "auditor_fp_violation": 0.021506317371333416,
            "ave_precision_score": 0.8599076827765972,
            "fpr": 0.07354555433589462,
            "logloss": 1.0113294818376157,
            "mae": 0.2719758302392943,
            "precision": 0.8286445012787724,
            "recall": 0.6864406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(56)",
        "seed": 22727,
        "test": {
            "accuracy": 0.581140350877193,
            "auc_prc": 0.6200058310659438,
            "auditor_fn_violation": 0.013271638640168898,
            "auditor_fp_violation": 0.008833129334965321,
            "ave_precision_score": 0.6124286417838098,
            "fpr": 0.06359649122807018,
            "logloss": 9.220299322450893,
            "mae": 0.4319433073368273,
            "precision": 0.7314814814814815,
            "recall": 0.3278008298755187
        },
        "train": {
            "accuracy": 0.5938529088913282,
            "auc_prc": 0.6177580655448349,
            "auditor_fn_violation": 0.004811717427300984,
            "auditor_fp_violation": 0.009601704302513697,
            "ave_precision_score": 0.6074843564538508,
            "fpr": 0.06256860592755215,
            "logloss": 9.068393480768327,
            "mae": 0.4180491817116164,
            "precision": 0.7361111111111112,
            "recall": 0.336864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(57)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7211934841774238,
            "auditor_fn_violation": 0.020301011865763996,
            "auditor_fp_violation": 0.006527947776417794,
            "ave_precision_score": 0.6840542189258063,
            "fpr": 0.09320175438596491,
            "logloss": 6.525189590479864,
            "mae": 0.35107795867651587,
            "precision": 0.7592067988668555,
            "recall": 0.5560165975103735
        },
        "train": {
            "accuracy": 0.686059275521405,
            "auc_prc": 0.7274838094237672,
            "auditor_fn_violation": 0.017130551266070063,
            "auditor_fp_violation": 0.010969447076856143,
            "ave_precision_score": 0.6901589729434388,
            "fpr": 0.08781558726673985,
            "logloss": 6.185430508128388,
            "mae": 0.33238094232843707,
            "precision": 0.7687861271676301,
            "recall": 0.5635593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(58)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5482456140350878,
            "auc_prc": 0.617446447324628,
            "auditor_fn_violation": 0.010275624226541448,
            "auditor_fp_violation": 0.005201958384332926,
            "ave_precision_score": 0.638216656672745,
            "fpr": 0.03837719298245614,
            "logloss": 8.39400022471497,
            "mae": 0.45467706088750626,
            "precision": 0.75,
            "recall": 0.21784232365145229
        },
        "train": {
            "accuracy": 0.5828759604829857,
            "auc_prc": 0.6305661459702605,
            "auditor_fn_violation": 0.010800200933970877,
            "auditor_fp_violation": 0.005716014592590185,
            "ave_precision_score": 0.6540342130612565,
            "fpr": 0.026344676180021953,
            "logloss": 8.355334438557465,
            "mae": 0.43803382814710856,
            "precision": 0.8285714285714286,
            "recall": 0.2457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(59)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7160087719298246,
            "auc_prc": 0.8157072591941834,
            "auditor_fn_violation": 0.02707104899177404,
            "auditor_fp_violation": 0.0160062219502244,
            "ave_precision_score": 0.8158407663184888,
            "fpr": 0.09539473684210527,
            "logloss": 2.013397476931231,
            "mae": 0.3150893091072013,
            "precision": 0.7808564231738035,
            "recall": 0.6431535269709544
        },
        "train": {
            "accuracy": 0.7277716794731065,
            "auc_prc": 0.8277954322946437,
            "auditor_fn_violation": 0.011628123313922132,
            "auditor_fp_violation": 0.022909066359278772,
            "ave_precision_score": 0.8279462450939402,
            "fpr": 0.08122941822173436,
            "logloss": 1.51511961085716,
            "mae": 0.30798783479895486,
            "precision": 0.8010752688172043,
            "recall": 0.6313559322033898
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(60)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5537280701754386,
            "auc_prc": 0.5987278045572352,
            "auditor_fn_violation": 0.011253821795151801,
            "auditor_fp_violation": 0.019344145246838026,
            "ave_precision_score": 0.6194321087109849,
            "fpr": 0.09210526315789473,
            "logloss": 8.414252436704242,
            "mae": 0.45591616049306877,
            "precision": 0.654320987654321,
            "recall": 0.32987551867219916
        },
        "train": {
            "accuracy": 0.566410537870472,
            "auc_prc": 0.6085689299322663,
            "auditor_fn_violation": 0.016832871309233666,
            "auditor_fp_violation": 0.012679750655741397,
            "ave_precision_score": 0.632001304309298,
            "fpr": 0.0889132821075741,
            "logloss": 8.379886748855121,
            "mae": 0.4396010009848895,
            "precision": 0.6610878661087866,
            "recall": 0.3347457627118644
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(61)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5767543859649122,
            "auc_prc": 0.6189113318020731,
            "auditor_fn_violation": 0.014399978161170585,
            "auditor_fp_violation": 0.009434924520603837,
            "ave_precision_score": 0.6396796550944529,
            "fpr": 0.06798245614035088,
            "logloss": 8.248739146603718,
            "mae": 0.4479750345979327,
            "precision": 0.7181818181818181,
            "recall": 0.3278008298755187
        },
        "train": {
            "accuracy": 0.58397365532382,
            "auc_prc": 0.6252943891433682,
            "auditor_fn_violation": 0.012046735753223322,
            "auditor_fp_violation": 0.009524190543821528,
            "ave_precision_score": 0.6496276318963198,
            "fpr": 0.059275521405049394,
            "logloss": 8.269205728128103,
            "mae": 0.4304603769169312,
            "precision": 0.7313432835820896,
            "recall": 0.3114406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(62)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6183403067438302,
            "auditor_fn_violation": 0.019463856737278882,
            "auditor_fp_violation": 0.010959812321501427,
            "ave_precision_score": 0.6381347479654943,
            "fpr": 0.05263157894736842,
            "logloss": 8.890648300718185,
            "mae": 0.44688948230510656,
            "precision": 0.746031746031746,
            "recall": 0.2925311203319502
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6334799521543915,
            "auditor_fn_violation": 0.019244544084541126,
            "auditor_fp_violation": 0.010696898699519163,
            "ave_precision_score": 0.6561741289952374,
            "fpr": 0.04171240395170143,
            "logloss": 8.56913159113614,
            "mae": 0.42550447384067364,
            "precision": 0.7900552486187845,
            "recall": 0.3029661016949153
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(63)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5646929824561403,
            "auc_prc": 0.6127731710675435,
            "auditor_fn_violation": 0.016720353789036906,
            "auditor_fp_violation": 0.007463790289677684,
            "ave_precision_score": 0.6398159047603381,
            "fpr": 0.03618421052631579,
            "logloss": 9.304852614615019,
            "mae": 0.45479950088020005,
            "precision": 0.7814569536423841,
            "recall": 0.24481327800829875
        },
        "train": {
            "accuracy": 0.5740944017563118,
            "auc_prc": 0.6212392430445424,
            "auditor_fn_violation": 0.006025693501274453,
            "auditor_fp_violation": 0.00312805522980329,
            "ave_precision_score": 0.6537166218925532,
            "fpr": 0.02305159165751921,
            "logloss": 9.416193900204783,
            "mae": 0.4414482533320552,
            "precision": 0.8333333333333334,
            "recall": 0.22245762711864406
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(64)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6263284177467744,
            "auditor_fn_violation": 0.021097219189051483,
            "auditor_fp_violation": 0.008445532435740517,
            "ave_precision_score": 0.6472220669112432,
            "fpr": 0.05701754385964912,
            "logloss": 8.461244541557106,
            "mae": 0.43920958325964377,
            "precision": 0.7425742574257426,
            "recall": 0.3112033195020747
        },
        "train": {
            "accuracy": 0.5982436882546652,
            "auc_prc": 0.6422373026495263,
            "auditor_fn_violation": 0.021502725632104782,
            "auditor_fp_violation": 0.013772444608918086,
            "ave_precision_score": 0.6655080572619844,
            "fpr": 0.048298572996706916,
            "logloss": 8.356640204220597,
            "mae": 0.4179263312121559,
            "precision": 0.7731958762886598,
            "recall": 0.3177966101694915
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(65)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5515350877192983,
            "auc_prc": 0.7811317232844872,
            "auditor_fn_violation": 0.0008189561039528286,
            "auditor_fp_violation": 0.007838637290901673,
            "ave_precision_score": 0.6016491600647577,
            "fpr": 0.4375,
            "logloss": 12.126562351136108,
            "mae": 0.4497537173758023,
            "precision": 0.5419058553386912,
            "recall": 0.979253112033195
        },
        "train": {
            "accuracy": 0.5488474204171241,
            "auc_prc": 0.7926455761171005,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.01209464679980696,
            "ave_precision_score": 0.612256762936826,
            "fpr": 0.4434687156970362,
            "logloss": 11.850126083058997,
            "mae": 0.4493998678990984,
            "precision": 0.5350978135788262,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(66)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6071194027784481,
            "auditor_fn_violation": 0.016342724029991994,
            "auditor_fp_violation": 0.00860873113015096,
            "ave_precision_score": 0.6281725679511242,
            "fpr": 0.03399122807017544,
            "logloss": 9.94014834903666,
            "mae": 0.46055842141972986,
            "precision": 0.7801418439716312,
            "recall": 0.22821576763485477
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6139496637881432,
            "auditor_fn_violation": 0.009493199873486026,
            "auditor_fp_violation": 0.002145380805092904,
            "ave_precision_score": 0.6368895964620767,
            "fpr": 0.019758507135016465,
            "logloss": 9.65077626584819,
            "mae": 0.4489476147668571,
            "precision": 0.8487394957983193,
            "recall": 0.21398305084745764
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(67)",
        "seed": 22727,
        "test": {
            "accuracy": 0.569078947368421,
            "auc_prc": 0.6087084529087998,
            "auditor_fn_violation": 0.014977797190070632,
            "auditor_fp_violation": 0.01776825785393717,
            "ave_precision_score": 0.629472295301509,
            "fpr": 0.07456140350877193,
            "logloss": 8.391374205947097,
            "mae": 0.4480738966126961,
            "precision": 0.6977777777777778,
            "recall": 0.3257261410788382
        },
        "train": {
            "accuracy": 0.5773874862788145,
            "auc_prc": 0.6268271364762444,
            "auditor_fn_violation": 0.011144393384062963,
            "auditor_fp_violation": 0.014562584858812441,
            "ave_precision_score": 0.6502386026182103,
            "fpr": 0.07683863885839737,
            "logloss": 8.335006144921747,
            "mae": 0.42969829291474654,
            "precision": 0.6916299559471366,
            "recall": 0.3326271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(68)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6403508771929824,
            "auc_prc": 0.7112096344764021,
            "auditor_fn_violation": 0.020894755041129795,
            "auditor_fp_violation": 0.02233527131782946,
            "ave_precision_score": 0.7142438570477052,
            "fpr": 0.10855263157894737,
            "logloss": 5.488125775724393,
            "mae": 0.36663770984854765,
            "precision": 0.71875,
            "recall": 0.524896265560166
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.7196590471995306,
            "auditor_fn_violation": 0.0010000186049973023,
            "auditor_fp_violation": 0.02467938059005473,
            "ave_precision_score": 0.7222691847781513,
            "fpr": 0.09659714599341383,
            "logloss": 5.19756008432891,
            "mae": 0.33486849588567763,
            "precision": 0.7541899441340782,
            "recall": 0.5720338983050848
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(69)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7236842105263158,
            "auc_prc": 0.7797868023387116,
            "auditor_fn_violation": 0.022182336026788967,
            "auditor_fp_violation": 0.016829865361077116,
            "ave_precision_score": 0.720928687918829,
            "fpr": 0.13048245614035087,
            "logloss": 4.690776124488448,
            "mae": 0.2935224923087548,
            "precision": 0.7457264957264957,
            "recall": 0.7240663900414938
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8031996894235426,
            "auditor_fn_violation": 0.014604922882286188,
            "auditor_fp_violation": 0.026772252074743267,
            "ave_precision_score": 0.7459549779943283,
            "fpr": 0.11964873765093303,
            "logloss": 3.9047194302202346,
            "mae": 0.2654896650975367,
            "precision": 0.7635574837310195,
            "recall": 0.7457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(70)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5416666666666666,
            "auc_prc": 0.5337604455025465,
            "auditor_fn_violation": 0.01330348693310039,
            "auditor_fp_violation": 0.024316605467156263,
            "ave_precision_score": 0.5511023036546527,
            "fpr": 0.07456140350877193,
            "logloss": 10.27377930068833,
            "mae": 0.476032922516477,
            "precision": 0.66,
            "recall": 0.27385892116182575
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.5413931329697461,
            "auditor_fn_violation": 0.00971180859178776,
            "auditor_fp_violation": 0.013772444608918084,
            "ave_precision_score": 0.5704356252014964,
            "fpr": 0.04939626783754116,
            "logloss": 10.114469108553573,
            "mae": 0.4560950132774907,
            "precision": 0.7204968944099379,
            "recall": 0.2457627118644068
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(71)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6600877192982456,
            "auc_prc": 0.7391092734283358,
            "auditor_fn_violation": 0.014322632306908362,
            "auditor_fp_violation": 0.008363933088535296,
            "ave_precision_score": 0.7414687102275552,
            "fpr": 0.09868421052631579,
            "logloss": 5.215480960229153,
            "mae": 0.3518787018108687,
            "precision": 0.7443181818181818,
            "recall": 0.5435684647302904
        },
        "train": {
            "accuracy": 0.681668496158068,
            "auc_prc": 0.754490661604746,
            "auditor_fn_violation": 0.007637351392584051,
            "auditor_fp_violation": 0.018220734180317007,
            "ave_precision_score": 0.7569435365520103,
            "fpr": 0.09110867178924259,
            "logloss": 5.021942237996683,
            "mae": 0.32401422927943574,
            "precision": 0.7614942528735632,
            "recall": 0.5614406779661016
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(72)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6918859649122807,
            "auc_prc": 0.7723443251246345,
            "auditor_fn_violation": 0.021474848948096384,
            "auditor_fp_violation": 0.014764381884944928,
            "ave_precision_score": 0.7126623948802009,
            "fpr": 0.13267543859649122,
            "logloss": 4.065083627512919,
            "mae": 0.3214281874651661,
            "precision": 0.7268623024830699,
            "recall": 0.6680497925311203
        },
        "train": {
            "accuracy": 0.7189901207464325,
            "auc_prc": 0.79614324743524,
            "auditor_fn_violation": 0.015358425273028335,
            "auditor_fp_violation": 0.03117803410105294,
            "ave_precision_score": 0.7384142657064843,
            "fpr": 0.11964873765093303,
            "logloss": 3.5915509373092886,
            "mae": 0.2917465521395694,
            "precision": 0.7488479262672811,
            "recall": 0.6885593220338984
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(73)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6236749367752,
            "auditor_fn_violation": 0.01988015942345492,
            "auditor_fp_violation": 0.009037127702978378,
            "ave_precision_score": 0.6444133750408088,
            "fpr": 0.05921052631578947,
            "logloss": 8.490945328511067,
            "mae": 0.4402101686061048,
            "precision": 0.7313432835820896,
            "recall": 0.3049792531120332
        },
        "train": {
            "accuracy": 0.5971459934138309,
            "auc_prc": 0.6398044707964181,
            "auditor_fn_violation": 0.018809652272600428,
            "auditor_fp_violation": 0.012434707160520992,
            "ave_precision_score": 0.6630958297037073,
            "fpr": 0.05378704720087816,
            "logloss": 8.374695834826202,
            "mae": 0.4182440723850139,
            "precision": 0.7586206896551724,
            "recall": 0.326271186440678
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(74)",
        "seed": 22727,
        "test": {
            "accuracy": 0.4956140350877193,
            "auc_prc": 0.47040024782478757,
            "auditor_fn_violation": 0.022075416757661805,
            "auditor_fp_violation": 0.014611383108935129,
            "ave_precision_score": 0.4813957578252108,
            "fpr": 0.19736842105263158,
            "logloss": 10.854352152278485,
            "mae": 0.5232190979162656,
            "precision": 0.5287958115183246,
            "recall": 0.4190871369294606
        },
        "train": {
            "accuracy": 0.47420417124039516,
            "auc_prc": 0.44068918283867425,
            "auditor_fn_violation": 0.018867792889170034,
            "auditor_fp_violation": 0.013934973457788767,
            "ave_precision_score": 0.45752626136274477,
            "fpr": 0.21734357848518113,
            "logloss": 11.477428300746428,
            "mae": 0.5378880388503148,
            "precision": 0.4910025706940874,
            "recall": 0.4046610169491525
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(75)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5614035087719298,
            "auc_prc": 0.6012787343915595,
            "auditor_fn_violation": 0.010746523986314335,
            "auditor_fp_violation": 0.0007853937168502651,
            "ave_precision_score": 0.6220495792337744,
            "fpr": 0.02631578947368421,
            "logloss": 9.539441177997862,
            "mae": 0.46675748006811607,
            "precision": 0.8153846153846154,
            "recall": 0.21991701244813278
        },
        "train": {
            "accuracy": 0.5609220636663008,
            "auc_prc": 0.6055852327806908,
            "auditor_fn_violation": 0.006846639007237372,
            "auditor_fp_violation": 0.003908193704382528,
            "ave_precision_score": 0.6274314774714336,
            "fpr": 0.01756311745334797,
            "logloss": 9.644623959130312,
            "mae": 0.45574001155562244,
            "precision": 0.8461538461538461,
            "recall": 0.1864406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(76)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6951754385964912,
            "auc_prc": 0.7967555330272397,
            "auditor_fn_violation": 0.024878066535633684,
            "auditor_fp_violation": 0.013402692778457771,
            "ave_precision_score": 0.7969062864744598,
            "fpr": 0.09649122807017543,
            "logloss": 2.5117745614319724,
            "mae": 0.3145723302193353,
            "precision": 0.7684210526315789,
            "recall": 0.6058091286307054
        },
        "train": {
            "accuracy": 0.7354555433589463,
            "auc_prc": 0.8047448454857861,
            "auditor_fn_violation": 0.005479171705520105,
            "auditor_fp_violation": 0.023456663557781508,
            "ave_precision_score": 0.8050858589360684,
            "fpr": 0.07683863885839737,
            "logloss": 2.044974388241623,
            "mae": 0.2888765821050595,
            "precision": 0.8113207547169812,
            "recall": 0.6377118644067796
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(77)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7269736842105263,
            "auc_prc": 0.8343829242214655,
            "auditor_fn_violation": 0.017657603552449594,
            "auditor_fp_violation": 0.011768155854753161,
            "ave_precision_score": 0.8346869618182521,
            "fpr": 0.13048245614035087,
            "logloss": 1.4413254752233249,
            "mae": 0.2888815040150899,
            "precision": 0.7473460721868365,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7607025246981339,
            "auc_prc": 0.831385850379279,
            "auditor_fn_violation": 0.005321029228450765,
            "auditor_fp_violation": 0.022266452295282412,
            "ave_precision_score": 0.8335534938558087,
            "fpr": 0.11745334796926454,
            "logloss": 1.1097165102885842,
            "mae": 0.2676113254578968,
            "precision": 0.7713675213675214,
            "recall": 0.7648305084745762
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(78)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6017112420637143,
            "auditor_fn_violation": 0.01457741865036035,
            "auditor_fp_violation": 0.010182068543451654,
            "ave_precision_score": 0.6274359801618067,
            "fpr": 0.03179824561403509,
            "logloss": 9.921995722204946,
            "mae": 0.4619511045839896,
            "precision": 0.7883211678832117,
            "recall": 0.22406639004149378
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6088318520890117,
            "auditor_fn_violation": 0.008158291317047772,
            "auditor_fp_violation": 0.004238252289781436,
            "ave_precision_score": 0.6407379958152014,
            "fpr": 0.018660812294182216,
            "logloss": 9.694480086125957,
            "mae": 0.44878611834964566,
            "precision": 0.8547008547008547,
            "recall": 0.211864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(79)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6589912280701754,
            "auc_prc": 0.7364102608357347,
            "auditor_fn_violation": 0.011413063259809286,
            "auditor_fp_violation": 0.005497756017951858,
            "ave_precision_score": 0.7382709175508988,
            "fpr": 0.09210526315789473,
            "logloss": 5.480270251642398,
            "mae": 0.3549195457095189,
            "precision": 0.7522123893805309,
            "recall": 0.529045643153527
        },
        "train": {
            "accuracy": 0.6805708013172338,
            "auc_prc": 0.7535984249188105,
            "auditor_fn_violation": 0.0024605108932259324,
            "auditor_fp_violation": 0.02377421992403652,
            "ave_precision_score": 0.755210188855735,
            "fpr": 0.0845225027442371,
            "logloss": 5.2214079913297615,
            "mae": 0.32636054607206033,
            "precision": 0.7701492537313432,
            "recall": 0.5466101694915254
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(80)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5855263157894737,
            "auc_prc": 0.6891150208888173,
            "auditor_fn_violation": 0.02771938924073669,
            "auditor_fp_violation": 0.00923092615259078,
            "ave_precision_score": 0.6872187089255422,
            "fpr": 0.049342105263157895,
            "logloss": 6.7151528232694035,
            "mae": 0.430409838199499,
            "precision": 0.7680412371134021,
            "recall": 0.3091286307053942
        },
        "train": {
            "accuracy": 0.5993413830954994,
            "auc_prc": 0.6997757715536228,
            "auditor_fn_violation": 0.014042121713892377,
            "auditor_fp_violation": 0.012137154344896223,
            "ave_precision_score": 0.6977095334579938,
            "fpr": 0.042810098792535674,
            "logloss": 6.353622932469581,
            "mae": 0.4172376616296273,
            "precision": 0.7891891891891892,
            "recall": 0.3093220338983051
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(81)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.627681933962758,
            "auditor_fn_violation": 0.01953665283540804,
            "auditor_fp_violation": 0.0158328233374133,
            "ave_precision_score": 0.6224973250677373,
            "fpr": 0.0625,
            "logloss": 11.46059028584968,
            "mae": 0.4632097747963205,
            "precision": 0.6918918918918919,
            "recall": 0.26556016597510373
        },
        "train": {
            "accuracy": 0.5598243688254665,
            "auc_prc": 0.6429841033247419,
            "auditor_fn_violation": 0.013218850583266677,
            "auditor_fp_violation": 0.018035701336987314,
            "ave_precision_score": 0.6273869127829131,
            "fpr": 0.06147091108671789,
            "logloss": 10.784817764739138,
            "mae": 0.44644344151445914,
            "precision": 0.6939890710382514,
            "recall": 0.2690677966101695
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(82)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5789473684210527,
            "auc_prc": 0.6205980429193533,
            "auditor_fn_violation": 0.017484712819392883,
            "auditor_fp_violation": 0.007542839657282742,
            "ave_precision_score": 0.6402631846759301,
            "fpr": 0.0537280701754386,
            "logloss": 8.667065510644415,
            "mae": 0.44244705964265835,
            "precision": 0.75,
            "recall": 0.3049792531120332
        },
        "train": {
            "accuracy": 0.5872667398463227,
            "auc_prc": 0.6410611482319556,
            "auditor_fn_violation": 0.014474687901170251,
            "auditor_fp_violation": 0.011439530516666708,
            "ave_precision_score": 0.663705185968108,
            "fpr": 0.04610318331503842,
            "logloss": 8.43407191495476,
            "mae": 0.42436325245430856,
            "precision": 0.7666666666666667,
            "recall": 0.2923728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(83)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5504385964912281,
            "auc_prc": 0.7903154023368436,
            "auditor_fn_violation": 0.0008189561039528286,
            "auditor_fp_violation": 0.0066044471644226815,
            "ave_precision_score": 0.6228705984516041,
            "fpr": 0.43859649122807015,
            "logloss": 11.29532757492453,
            "mae": 0.4479007781160921,
            "precision": 0.5412844036697247,
            "recall": 0.979253112033195
        },
        "train": {
            "accuracy": 0.5510428100987925,
            "auc_prc": 0.7989898235278818,
            "auditor_fn_violation": 0.001907012223483228,
            "auditor_fp_violation": 0.012219668991245946,
            "ave_precision_score": 0.6278326914298832,
            "fpr": 0.44127332601536773,
            "logloss": 11.171524386907162,
            "mae": 0.4465099748010102,
            "precision": 0.5363321799307958,
            "recall": 0.9851694915254238
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(84)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7335526315789473,
            "auc_prc": 0.8156060439545095,
            "auditor_fn_violation": 0.01963219771420252,
            "auditor_fp_violation": 0.011533557731538153,
            "ave_precision_score": 0.8159515752840618,
            "fpr": 0.11732456140350878,
            "logloss": 0.8706163877037817,
            "mae": 0.2901797920060636,
            "precision": 0.7637969094922737,
            "recall": 0.7178423236514523
        },
        "train": {
            "accuracy": 0.75192096597146,
            "auc_prc": 0.8318045471947922,
            "auditor_fn_violation": 0.010958343411040213,
            "auditor_fp_violation": 0.026194649550295174,
            "ave_precision_score": 0.8321975203757673,
            "fpr": 0.1119648737650933,
            "logloss": 0.6935968969569872,
            "mae": 0.2681647368265438,
            "precision": 0.7733333333333333,
            "recall": 0.7372881355932204
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(85)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6567982456140351,
            "auc_prc": 0.7088294942245569,
            "auditor_fn_violation": 0.020023476741646656,
            "auditor_fp_violation": 0.009740922072623422,
            "ave_precision_score": 0.6738914702993077,
            "fpr": 0.09320175438596491,
            "logloss": 6.205289903842119,
            "mae": 0.3605621918467708,
            "precision": 0.7492625368731564,
            "recall": 0.5269709543568465
        },
        "train": {
            "accuracy": 0.6706915477497256,
            "auc_prc": 0.7167945345948041,
            "auditor_fn_violation": 0.011721148300433505,
            "auditor_fp_violation": 0.00964421184760295,
            "ave_precision_score": 0.6840242339655125,
            "fpr": 0.07903402854006586,
            "logloss": 6.226613426955785,
            "mae": 0.34448105299553133,
            "precision": 0.7721518987341772,
            "recall": 0.5169491525423728
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(86)",
        "seed": 22727,
        "test": {
            "accuracy": 0.6721491228070176,
            "auc_prc": 0.7762277727542028,
            "auditor_fn_violation": 0.011488134236004952,
            "auditor_fp_violation": 0.022365871073031427,
            "ave_precision_score": 0.7262677427127979,
            "fpr": 0.26206140350877194,
            "logloss": 4.262933410941999,
            "mae": 0.32959133685373165,
            "precision": 0.6384266263237519,
            "recall": 0.8755186721991701
        },
        "train": {
            "accuracy": 0.6992316136114161,
            "auc_prc": 0.7964457953391433,
            "auditor_fn_violation": 0.009402500511637428,
            "auditor_fp_violation": 0.02951773939874328,
            "ave_precision_score": 0.7472179473926166,
            "fpr": 0.2579582875960483,
            "logloss": 3.846648281691828,
            "mae": 0.30101709303901386,
            "precision": 0.6482035928143712,
            "recall": 0.9173728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(87)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7225877192982456,
            "auc_prc": 0.7839480006674397,
            "auditor_fn_violation": 0.018717696731455197,
            "auditor_fp_violation": 0.012757547939616486,
            "ave_precision_score": 0.724260886961253,
            "fpr": 0.13486842105263158,
            "logloss": 3.821556909397587,
            "mae": 0.2965704751675244,
            "precision": 0.7410526315789474,
            "recall": 0.7302904564315352
        },
        "train": {
            "accuracy": 0.7530186608122942,
            "auc_prc": 0.8069838824754604,
            "auditor_fn_violation": 0.012158365737036969,
            "auditor_fp_violation": 0.024046768301373495,
            "ave_precision_score": 0.7492481755534042,
            "fpr": 0.11964873765093303,
            "logloss": 3.3848551994910108,
            "mae": 0.26584878022796776,
            "precision": 0.7655913978494624,
            "recall": 0.7542372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(88)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6139712990946539,
            "auditor_fn_violation": 0.020043950644245478,
            "auditor_fp_violation": 0.014394634842921259,
            "ave_precision_score": 0.6347603016512005,
            "fpr": 0.06469298245614036,
            "logloss": 8.363376668650584,
            "mae": 0.4443338804267479,
            "precision": 0.7163461538461539,
            "recall": 0.3091286307053942
        },
        "train": {
            "accuracy": 0.5861690450054885,
            "auc_prc": 0.6405412566846855,
            "auditor_fn_violation": 0.01391886360676478,
            "auditor_fp_violation": 0.015547759727351604,
            "ave_precision_score": 0.6638202968967081,
            "fpr": 0.0570801317233809,
            "logloss": 8.291591894176738,
            "mae": 0.4230469568670598,
            "precision": 0.7386934673366834,
            "recall": 0.3114406779661017
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(89)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5701754385964912,
            "auc_prc": 0.6128607984570535,
            "auditor_fn_violation": 0.014411352551503245,
            "auditor_fp_violation": 0.011870155038759688,
            "ave_precision_score": 0.6336482636282942,
            "fpr": 0.0712719298245614,
            "logloss": 8.337919305432399,
            "mae": 0.45197075491489275,
            "precision": 0.7045454545454546,
            "recall": 0.3215767634854772
        },
        "train": {
            "accuracy": 0.5905598243688255,
            "auc_prc": 0.6201403723061163,
            "auditor_fn_violation": 0.009804833578299142,
            "auditor_fp_violation": 0.010151801944845211,
            "ave_precision_score": 0.6445198523145772,
            "fpr": 0.06586169045005488,
            "logloss": 8.339687688336547,
            "mae": 0.4265472745319281,
            "precision": 0.726027397260274,
            "recall": 0.336864406779661
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(90)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5493421052631579,
            "auc_prc": 0.5480489170942296,
            "auditor_fn_violation": 0.00403108393390116,
            "auditor_fp_violation": 0.01271164830681355,
            "ave_precision_score": 0.5723397231312648,
            "fpr": 0.0800438596491228,
            "logloss": 9.91016921541678,
            "mae": 0.4677535183011424,
            "precision": 0.663594470046083,
            "recall": 0.2987551867219917
        },
        "train": {
            "accuracy": 0.5675082327113062,
            "auc_prc": 0.5489132292011999,
            "auditor_fn_violation": 0.016074717669165926,
            "auditor_fp_violation": 0.0011677072680400797,
            "ave_precision_score": 0.5788515046995553,
            "fpr": 0.06366630076838639,
            "logloss": 9.905095014452383,
            "mae": 0.45154290936474223,
            "precision": 0.7010309278350515,
            "recall": 0.288135593220339
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(91)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7478070175438597,
            "auc_prc": 0.8433866616709388,
            "auditor_fn_violation": 0.04082723666011502,
            "auditor_fp_violation": 0.014922480620155039,
            "ave_precision_score": 0.8434848138173602,
            "fpr": 0.09539473684210527,
            "logloss": 1.7658831379483886,
            "mae": 0.28959662321925567,
            "precision": 0.795774647887324,
            "recall": 0.7033195020746889
        },
        "train": {
            "accuracy": 0.7815587266739846,
            "auc_prc": 0.8644222888512467,
            "auditor_fn_violation": 0.027900519079424736,
            "auditor_fp_violation": 0.02643969304551558,
            "ave_precision_score": 0.8645345871949475,
            "fpr": 0.08781558726673985,
            "logloss": 1.1308724838490425,
            "mae": 0.2691198228977062,
            "precision": 0.815242494226328,
            "recall": 0.7478813559322034
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(92)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7324561403508771,
            "auc_prc": 0.8344997586553443,
            "auditor_fn_violation": 0.021497597728761742,
            "auditor_fp_violation": 0.016391268869849044,
            "ave_precision_score": 0.8347867901398989,
            "fpr": 0.13815789473684212,
            "logloss": 0.7772753939180469,
            "mae": 0.2815544997434029,
            "precision": 0.7428571428571429,
            "recall": 0.7551867219917012
        },
        "train": {
            "accuracy": 0.7618002195389681,
            "auc_prc": 0.8451212739088686,
            "auditor_fn_violation": 0.011651379560549962,
            "auditor_fp_violation": 0.028995146638528344,
            "ave_precision_score": 0.845694544254199,
            "fpr": 0.13391877058177826,
            "logloss": 0.6509166128558727,
            "mae": 0.2557244659862793,
            "precision": 0.7555110220440882,
            "recall": 0.798728813559322
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(93)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5734649122807017,
            "auc_prc": 0.6127256160383495,
            "auditor_fn_violation": 0.02014177040110652,
            "auditor_fp_violation": 0.011949204406364749,
            "ave_precision_score": 0.6335143976442686,
            "fpr": 0.0581140350877193,
            "logloss": 8.394106793685687,
            "mae": 0.44691294542149623,
            "precision": 0.7336683417085427,
            "recall": 0.3029045643153527
        },
        "train": {
            "accuracy": 0.5850713501646543,
            "auc_prc": 0.6380244952805101,
            "auditor_fn_violation": 0.015046791568215236,
            "auditor_fp_violation": 0.012599736453220446,
            "ave_precision_score": 0.6613120111288169,
            "fpr": 0.052689352360043906,
            "logloss": 8.315383157765583,
            "mae": 0.4258751428683243,
            "precision": 0.7473684210526316,
            "recall": 0.3008474576271186
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(94)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5526315789473685,
            "auc_prc": 0.6214500383328782,
            "auditor_fn_violation": 0.01962764795806946,
            "auditor_fp_violation": 0.0011525907792737668,
            "ave_precision_score": 0.6421949901770293,
            "fpr": 0.02631578947368421,
            "logloss": 8.62510804732414,
            "mae": 0.45607982047499473,
            "precision": 0.8032786885245902,
            "recall": 0.2033195020746888
        },
        "train": {
            "accuracy": 0.5729967069154775,
            "auc_prc": 0.6349261217178896,
            "auditor_fn_violation": 0.012602560047628808,
            "auditor_fp_violation": 0.005661004828357034,
            "ave_precision_score": 0.6571140640545454,
            "fpr": 0.021953896816684963,
            "logloss": 8.508738556442216,
            "mae": 0.4397177994161193,
            "precision": 0.8373983739837398,
            "recall": 0.21822033898305085
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(95)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5581140350877193,
            "auc_prc": 0.6084670721358241,
            "auditor_fn_violation": 0.01844016160733786,
            "auditor_fp_violation": 0.00860873113015096,
            "ave_precision_score": 0.6284954872301985,
            "fpr": 0.03399122807017544,
            "logloss": 9.888489611553018,
            "mae": 0.46003332192723634,
            "precision": 0.7801418439716312,
            "recall": 0.22821576763485477
        },
        "train": {
            "accuracy": 0.5762897914379802,
            "auc_prc": 0.6152568949866625,
            "auditor_fn_violation": 0.004693110569498984,
            "auditor_fp_violation": 0.003770669293799649,
            "ave_precision_score": 0.6378780222725982,
            "fpr": 0.01756311745334797,
            "logloss": 9.63918592881938,
            "mae": 0.44815898619082484,
            "precision": 0.864406779661017,
            "recall": 0.21610169491525424
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(96)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7006578947368421,
            "auc_prc": 0.8090016531576251,
            "auditor_fn_violation": 0.03175729780883745,
            "auditor_fp_violation": 0.015146878824969408,
            "ave_precision_score": 0.8091323494263966,
            "fpr": 0.09649122807017543,
            "logloss": 1.8222279394360212,
            "mae": 0.3215316989438054,
            "precision": 0.7714285714285715,
            "recall": 0.6161825726141079
        },
        "train": {
            "accuracy": 0.7222832052689352,
            "auc_prc": 0.8342846923352812,
            "auditor_fn_violation": 0.015260749037191398,
            "auditor_fp_violation": 0.027907453573009208,
            "ave_precision_score": 0.8344708024797765,
            "fpr": 0.08562019758507135,
            "logloss": 1.1733109726658009,
            "mae": 0.2987886037749435,
            "precision": 0.792,
            "recall": 0.6292372881355932
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(97)",
        "seed": 22727,
        "test": {
            "accuracy": 0.7203947368421053,
            "auc_prc": 0.7784491603951482,
            "auditor_fn_violation": 0.022309729198514965,
            "auditor_fp_violation": 0.012214402284781729,
            "ave_precision_score": 0.7187948234847694,
            "fpr": 0.13157894736842105,
            "logloss": 4.202816869036846,
            "mae": 0.30011516972816105,
            "precision": 0.7430406852248393,
            "recall": 0.7199170124481328
        },
        "train": {
            "accuracy": 0.7486278814489572,
            "auc_prc": 0.8058403351385338,
            "auditor_fn_violation": 0.01467004037284415,
            "auditor_fp_violation": 0.025319494210222324,
            "ave_precision_score": 0.7480798439896982,
            "fpr": 0.12294182217343579,
            "logloss": 3.5361682184992507,
            "mae": 0.2681068253872405,
            "precision": 0.7601713062098501,
            "recall": 0.7521186440677966
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(98)",
        "seed": 22727,
        "test": {
            "accuracy": 0.39144736842105265,
            "auc_prc": 0.6172429849428566,
            "auditor_fn_violation": 0.020897029919196338,
            "auditor_fp_violation": 0.0025601795185638434,
            "ave_precision_score": 0.4782469624134744,
            "fpr": 0.3815789473684211,
            "logloss": 20.932370451586976,
            "mae": 0.6094971685359819,
            "precision": 0.44141252006420545,
            "recall": 0.5705394190871369
        },
        "train": {
            "accuracy": 0.38309549945115257,
            "auc_prc": 0.6020491697810211,
            "auditor_fn_violation": 0.01572122272042271,
            "auditor_fp_violation": 0.003910694148211312,
            "ave_precision_score": 0.4667240716785732,
            "fpr": 0.38638858397365533,
            "logloss": 21.064002532689365,
            "mae": 0.6165871006510769,
            "precision": 0.42671009771986973,
            "recall": 0.5550847457627118
        }
    },
    {
        "dataset": "lawschool",
        "method": "feat_flex2",
        "model": "feat_flex2:archive(99)",
        "seed": 22727,
        "test": {
            "accuracy": 0.5296052631578947,
            "auc_prc": 0.605805991388206,
            "auditor_fn_violation": 0.011030883744631305,
            "auditor_fp_violation": 0.0036362709098327222,
            "ave_precision_score": 0.6263685601869255,
            "fpr": 0.015350877192982455,
            "logloss": 8.701208391851589,
            "mae": 0.47795151130691954,
            "precision": 0.8271604938271605,
            "recall": 0.13900414937759337
        },
        "train": {
            "accuracy": 0.5367727771679474,
            "auc_prc": 0.6072543401919528,
            "auditor_fn_violation": 0.006567564047703212,
            "auditor_fp_violation": 0.001897836866043724,
            "ave_precision_score": 0.6306718034679759,
            "fpr": 0.015367727771679473,
            "logloss": 8.66023962144486,
            "mae": 0.46715216666133674,
            "precision": 0.8205128205128205,
            "recall": 0.13559322033898305
        }
    }
]